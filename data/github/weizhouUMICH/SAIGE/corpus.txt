tabl content introductionintroduct citationcit instal saig saigegenehowtoinstallandrunsaigeandsaigegen note user run jobsnotesforusersbeforerunningjob uk biobank gwa resultsukbiobankgwasresult log fix bugslogforfixingbug introduct manuscript saigegen httpswwwmedrxivorgcontentv current version updat januari comment part estim effect sampl size may convert take long put instead maxmaf genebas test current version updat august add extdataextractnglmmr extract effect sampl size without run step extdatacmd_extractneffsh pipelin effect sampl size nglmm differ calcul previou version previou version updat juli saigegen group test collpas ultrarar variant mac set method_to_collapseultrarareabsence_or_pres default collpas ultrarar varaint mac saigegen well control type error rate maximum maf cutoff maxmafforgrouptest lower eg test multipl maf cutoff variant annot combin use cauchi combin function cct pleas reinstal instal verion march bgen input bit requir bgen input step miss dosag pleas use version later saig r packag scalabl accur implement gener mix model chen h et al account sampl related feasibl genet associ test larg cohort biobank n saig perform singlevari associ test binari trait quantit tait binari trait saig use saddlepoint approxim spamhof j p kuonen dey r etal account casecontrol imbal saigegen implement saig r packag perform gene regionbas associ test burd skat skato binari trait quantit trait note saigegen account casecontrol imbal genebas test citat saig manuscript wei zhou jona b nielsen lar g fritsch maiken b elvestad brook wolford maoxuan lin kristian hveem hyun min kang goncalo r abecasi cristen j willer seunggeun lee effici control casecontrol imbal sampl related largescal genet associ studi natur genet saigegen preprint httpswwwbiorxivorgcontentv instal run saig saigegen instal saigesaigegen list depend r gcc cmake cgethttpscgetreadthedocsioenlatestsrcintrohtmlinstallingcget r packag rutil rcpp rcppparallel rcpparmadillo datat rcppeigen matrix method bh optpars spatest skatmetaskat extdatainstall_packagesr use instal r packag saig v depend spatest v metaskat current avail cran pleas instal github use r devtoolsinstall_githubleeshawnmetaskat instal saig conda warn pleas use bioconda version bgen input work issu rsaigehttpsanacondaorgbiocondarsaigebadgesversionsvg latest_updatehttpsanacondaorgbiocondarsaigebadgeslatest_release_datesvg instal saig conda simpli creat environ latest version r saig conda creat n saig c condaforg c bioconda rbase rsaig conda activ saig info rsaig conda packagehttpsanacondaorgbiocondarsaig avail version found issu httpsgithubcomweizhouumichsaigeissu instal saig use conda environ creat conda environ use conda environ filehttpsgithubcomweizhouumichsaigeblobmasterconda_envenvironmentrsaigeyml link download conda environ filehttpsrawgithubusercontentcomweizhouumichsaigemasterconda_envenvironmentrsaigeyml download environmentrsaigeyml run follow command conda env creat f environmentrsaigeyml activ conda environ rsaig conda activ rsaig flagpathwhich python sed sbinpython export ldflagslflagpathlib export cppflagsiflagpathinclud pleas make sure set ldflag cppflag use export last two command line librari link correctli saig sourc code compil note herehttpsgithubcomweizhouumichsaigeblobmasterconda_envcreatecondaenvsaige_stepstxt step creat conda environ file open r run follow script instal metaskat r librari devtoolsinstall_githubleeshawnmetaskat instal saig sourc code method src_branchmast repo_src_urlhttpsgithubcomweizhouumichsaig git clone depth b src_branch repo_src_url r cmd instal librarypath_to_final_saige_librari saig call saig r set liblocpath_to_final_saige_librari librarysaig liblocpath_to_final_saige_librari method open r run devtoolsinstall_githubweizhouumichsaig run saig use docker imag thank juha karjalainen share dockerfil docker imag pull docker pull wzhousaig function call step_fitnullglmmr help step_spatestsr help createsparsegrmr help run saig singlevari associ test saigegen gene regionbas test wiki page conta tutori run saig saigegen httpsgithubcomweizhouumichsaigewikigeneticassociationtestsusingsaig exampl exampl data script found extdata run bash cmdsh run singlevari genebas associ test extract effect sampl size v saige_extractneffr help bash cmd_extractneffsh note run job faq found herehttpsgithubcomweizhouumichsaigewikigeneticassociationtestsusingsaigefrequentlyaskedquest note sinc spa test alway provid close pvalu variant mac pleas use least minmac filter result queri use bgen file pleas make sure duplic snp id list error messag error setgenogenofil subsampleingeno memorychunk vector_m_range_check tri use smaller memeorychunk importantin version binari trait beta alt allel quantit trait beta minor allel pleas note loco work autosom genet variant nonautosom genet variant pleas leav locofals step saigegen output effect size burden test option isoutputbetaseinburdentest step pleas note magnitud effect size difficult interpret havent throughli test program small sampl size simul studi done use sampl similar boltlmm saig use asymptot approach feasibl larg sampl base previou realdata analysi saw perform sampl fine uk biobank gwa result gwa result binari phenotyp uk biobank phenotyp use saig current avail public download httpswwwleelabsgorgresourc pheweb browser uk biobank result httpphewebsphumichedusaigeukb research conduct use uk biobank resourc applic number exomewid genebas associ result quantit trait uk biobank trait use saigegen current avail public download httpswwwleelabsgorgresourc research conduct use uk biobank resourc applic number log fix bug januari comment part estim effect sampl size may convert take long put instead maxmaf genebas test august fix se issu isoutputlogpforsingletru august make isoutputlogpforsingl work quantit trait remov rsid output input bgen august add extdataextractnglmmr extract effect sampl size without run step extdatacmd_extractneffsh pipelin effect sampl size nglmm differ calcul previou version juli add function cct perform cauchi combin combin multipel test juli set method_to_collapseultrarareabsence_or_pres default collpas ultrarar varaint mac call version saigegen saigegen well control type error rate maximum maf cutoff maxmafforgrouptest lower eg april rewrit code leaveonechromosomeout step effici parallel comput step speed singlevari associ test run genebas test march add option usesparsegrmtofitnul allow fit null model use spars grm add option collaps ultrarar variant setbas test method_to_collapseultrarar maccutoff_to_collapseultrarar dosagecutoff_for_ultrararepres feb fix error x z nonconform argument monomorph variant merg jonathon code updat savvi savvi marker vcf sav file without imput info r valu imputationinfo column output file marker remov mininfo januari fix error phi_ccadjindexneg indexneg invers normal perform quantit trait step bgen input requir sampl file vcf input requir seper sampl file sampl file provid sampl id read vcf file januari error falis_rewrite_xnonpar_formaless found fix decemb add script calcuat effect sampl size step binari trait locotru remov model result chromosom save memori usag step novemb modifi spars version score test quantit trait caus slight differ assoc test variant maf quantit trait set loco true default valu step step step chrom need specifi locotru septemb uncom issparsefals quantit trait comment test septemb fix bug varianc ratio adjust account casecontrol imbal genebas test minmac set n instead is_rewrite_xnonpar_formalestru august improv loco featur implement loco gene region base test requir chrom specifi mininfo cutoff input vcf file contain info score info output na marker wont filter fix issu subset precalcu term regress x g drop miss dosag use spars matric genotypesdosag gene region base test memori usag dramat decreas august use spars matrix repres genotyp matrix genebas test save memori august add five option sexcol femalecod femaleonli malecod maleonli perform sexspecif step juli add three option samplefile_mal x_parregion is_rewrite_xnonpar_formal chromosom x associ test genotypesdosag nonpar region male multipli juli add option isoutputlogpforsingl output logp singlevari assoc test v requir spatest may fix error condit analysi conduct base vcf input introduc may fix bug output allel bgen input miss dosag use miss dosag drop samplefil longer need vcf file use step add isoverwritevarianceratiofil step overwrit varianc ratio file may fix issu ac valu bgen input use miss dosag mean imput default set april add option isoutputhethomcountsincasectrl output heterozyg homozyg count case control march add option spacutoff test statist lie within standard deviat cutoff mean pvalu base tradit score test return otherwis spa appli default valu spacutoff correspond pvaluena march fix typo extract pvalu fix issu locotru issu introduc option minmafforgrm introduc march fix bug unlistpvalu introduc march tri fix bug minmafforgrm set locotru march add option includenonautomarkersforvarratio step true nonautosom marker also use varianc ratio estim make algorithm appropri assoc test nonautosom marker use new function spars sigma pvalu singl variant genebas test assign af sampl miss genotyp dosag februari bug fix fix bug genebas condit test multipl condit marker add code recheck marker drop sampl miss dosagesgenotyp genebas test februari note v use spatest januari note v option isoutputbetaseinburdentest step ad output effect size burden test bug fix header output file condit analysi gene reigonbas test correct novemb note v user specifi custom weight marker gene regionbas test ad weight marker group file bug fix option weightsbetacommon fulli correctli develop make weightsbetacommon equal weightsbetarar instead output na skato p valu function skatmet_skat_get_pvalu fail output minskat p burden p novemb note v plain text dosag file longer allow input step get rid depend boost_iostream librari bug fix fix freq calcul mean imput miss genotyp plinkfil diagon element grm estim use marker plinkfil maf minmafforgrm condit analysi gene regionbas test binari trait account casecontrol imbal plain dosag file longer support step extern boost_iostream librari need minmafforgrm ad paramet step marker plinkfil maf minmafforgrm use grm weightsbetarar weightsbetacommon weightmafcutoff dosagezerodcutoff isoutputpvaluenaingrouptestforbinari isaccountforcasecontrolimbalanceingrouptest ad new paramet step fix matrix invers issu null model add option argument null comput remov binari covari low count juhi august fix matrix invers issu null model add option argument null comput remov binari covari low count juhi august fix bug covari specifi ad argument isoutputnincasectrl step allow output sampl size case control binari trait output file fix boundari bug loco august fix output bug genotyp matrix rank binari phenotyp add argument minmaftoconstructgrm step step allow user specifi minumum maf marker use construct grm default june account case control imbal binari trait genebas test may fix bug function getcovm_nopcg affect condit analysi binari trait merg hyaczmast use cget manag superlu april minor chang includ fix error messag chang mac maf add line check chomosom plink file numer add rsid header input file bgen fix error document warn messag casecontrol imbal binari trait run saigegen merg chang mastergen branch master merg chang master merg master fix bug updat predict valu model fit binari trait ad function creat spars grm data set clean version singlevari assoc test genebas test condit analysi version work conditon analysi genebas test version work r version work r updat saig bug read vcf sav file fix savvi librari version work r updat saig step use updat r libari spatest updat saig use updat r librari spatest colsum error covari fix beta tstat alt allel quantit binari trait note version binari trait beta alt allel quantit trait beta minor allel option leaveonechromosomeout loco cutoff coeffici variat cv trace estim varianc ratio estim ad three option extens test cv mainli automat determin whether number random marker select suffici number increas cv lower specifi cutoff fix bug tstat output allow model covari grm contruct use larg number genet marker centervari longer need qr transform covari matrix automat perform support dosag file vcfbcf sav format use savvi librari histori juli updat bgenix handl uk biobank interim file avoid extra index tabl index file march bgen spec implement updat alter probabl order unphas data number allel k ploidi greater two order better match order vcf gp field simpl enumer scheme nov major chang revis fff ive implement two new tool catbgen use concaten bgen file bgenix use index bgen file effici retriev specifi data purpos ive import sever extra piec code appcontext db sublib qctool sqlite boost note chang erron appli first master branch intend default first nov major chang revis affc ive chang behaviour bgen v respect sampl miss data store dummi zero probabl spec beta mean dont plan chang make unless major issu uncov final version format ive revamp setter api parse_probability_data somewhat document code wikihttpsbitbucketorggavinbandbgenwikithe_setter_api main break chang renam oper set_valu given index argument think make api consist ad initi ploidi argument set_number_of_entri request type data phase unphas alreadi report order_typ argument dont think anoth argument need ad two new method call option set_min_max_ploidi use set storag finalis see doc info ive also got rid max_id_s option write_snp_identifying_data need write bgen v file longer support ive also ad test code use catch frameworkhttpsgithubcomphilsquaredcatch seem pretti good test exhaust hope start q ive remov code warn thank robert v baron megahttpswatsonhgenpittedudocsmega_htmlmegahtml test code sep first version base qctool implement bgen refer implement repositori contain refer implement bgen formathttpwwwwelloxacukgavbgen_formatbgen_format_vhtml written c librari use basi bgen support softwar refer develop write implement bgen format what includ repositori contain librari set exampl data filesexampl number exampl program eg bgen_to_vcfexamplebgen_to_vcfcpp demonstr use librari api addit number util built use librari also includ repositori bgenixhttpsbitbucketorggavinbandbgenwikibgenix tool index effici retriev subset bgen file catbgenhttpsbitbucketorggavinbandbgenwikicatbgen tool effici concaten bgen file editbgenhttpsbitbucketorggavinbandbgenwikieditbgen tool edit bgen file metadata r packag call rbgenhttpsbitbucketorggavinbandbgenwikirbgen also construct build directori see rbgen wiki pagehttpsbitbucketorggavinbandbgenwikirbgen inform use packag cite bgen make use bgen librari tool exampl program pleas cite band g marchini j bgen binari file format imput genotyp haplotyp data bioarxiv biorxiv doi httpsdoiorg thank licens bgen implement releas boost softwar licens v rel permiss opensourc licens compat mani opensourc licens see pagehttpwwwboostorguserslicensehtml file license__txthttpsbitbucketorggavinbandbgensrctiplicense__txt full detail repositori also contain code sqlitewwwsqliteorg boostwwwboostorg zstandardhttpwwwzstdnet librari come respect licens respect public domainhttpwwwsqliteorgcopyrighthtml boost softwar licens bsd licensehttpsgithubcomfacebookzstdblobdevlicens librari use core bgen implement may use exampl program provid import note uk biobank data uk biobank releas imput genotyp datahttpwwwukbiobankacukscientistsgeneticdata almost half million individu bgen format accompani bgenix index file origin releas data version issu name index file pleas see herehttpsbitbucketorggavinbandbgenwikius uk biobank full releas index file inform work around recent version data version issu obtain instal bgen brief follow command type unix shell dollar symbol indic prompt shouldnt type perform basic download instal bgen librari exampl data tool bash get wget httpbitbucketorggavinbandbgengetmastertargz cd bgen compil waf configur waf test buildtestunittest_bgen buildappsbgenix g exampleexamplebitsbgen list follow section contain inform process download tarbal latest master branch avail httpbitbucketorggavinbandbgengetmastertargz altern use mercuri download master branch follow sh hg clone httpsgavinbandbitbucketorggavinbandbgen u master command take addit prebuilt version bgen util may avail pagehttpwwwwelloxacukgavresourc note recommend use download compil bgenix platform binari provid conveni get start quickli compil compil code use suppli waf build tool sh waf configur waf result appear build directori note full build requir compil support c eg gcc v specifi compil use set cxx environ variabl configur step exampl shell bash cxxpathtog waf configur waf sqlite zstd librari written c specifi c compil addit add ccpathtogcc test compil gcc use clang among other dont access compil c support still build core bgen implement wont abl build applic exampl program see wikihttpsbitbucketorggavinbandbgenwikitroubleshooting_compil inform test bgen test run type sh buildtesttest_bgen recent version sh buildtestunittest_bgen goe well messag like test pass print robot test frameworkhttprobotframeworkorg instal instead run full suit unit function test like sh testfunctionalrun_testssh test result place directori buildtestfunctionaltestreport tri exampl exampl program bgen_to_vcf read bgen file v v output vcf file stdout tri run type sh buildexamplebgen_to_vcf exampleexamplebitsbgen output vcfformat data stdout weve provid exampl bgen file exampl subdirectori instal command sh waf instal instal applic list specifi system user directori default usrloc chang specifi prefix configur step sh waf configur prefixpathtoinstallationdirectori waf instal program list instal folder call bin prefix dir eg bgenix instal pathtoinstallationdirectorybinbgenix etc note mani case there need instal execut selfcontain instal step simpli copi destin directori instal prefix need systemwid directori exampl typic specifi instal directori within home dir eg gavprojectssoftwar branch repo follow branch name practic master repres uptod code consid releas state interest use bgen code project therefor recommend clone master branch code develop take place default branch andor featur branch branch default branch command given download master branch peopl want inform see sourc codehttpsbitbucketorggavinbandbgensrc bgen releaseshttpsbitbucketorggavinbandbgenwikireleas wikihttpsbitbucketorggavinbandbgenwikihom informationbodi bgcolorffffff linke text vlinkab alinkff c boostboostpng hawick_circuit templat typenam graph typenam visitor typenam vertexindexmap void hawick_circuitsgraph const graph visitor visitor vertexindexmap const vim getvertex_index graph templat typenam graph typenam visitor typenam vertexindexmap void hawick_unique_circuitsgraph const graph visitor visitor vertexindexmap const vim getvertex_index graph enumer elementari circuit direct multigraph specif selfloop redund circuit caus parallel edg enumer hawick_unique_circuit may use redund circuit caus parallel edg desir algorithm describ detail httpwwwmasseyacnzkahawickcstncstnpdf defin includ boostgraphhawick_circuitshppboostgraphhawick_circuitshpp paramet __in__ graph const graph graph algorithm perform must model vertexlistgraph adjacencygraph concept __in__ visitor visitor visitor notifi circuit found algorithm visitorcyclecircuit graph express must valid circuit constrefer random access sequenc vertex_descriptor exampl circuit u v w u exist graph visitor call sequenc consist u v w __in__ vertexindexmap const vim getvertex_index graph model readablepropertymap concept map vertex_descriptor integ rang num_verticesgraph default use vertex index map provid graph div classfoot copi loui dionn div zstd short zstandard fast lossless compress algorithm target realtim compress scenario zliblevel better compress ratio provid opensourc bsdlicens c librari program languag consult list known port zstandard homepagehttpwwwzstdnetotherlanguag branch statu master build statushttpstravisciorgfacebookzstdsvgbranchmasterhttpstravisciorgfacebookzstd dev build statushttpstravisciorgfacebookzstdsvgbranchdevhttpstravisciorgfacebookzstd refer sever fast compress algorithm test compar core ik cpu ghz use lzbench opensourc inmemori benchmark inikep compil gcc silesia compress corpu lzbench httpsgithubcominikeplzbench silesia compress corpu httpsunaeipolslplsdeorindexphppagesilesia name ratio cspeed dspeed mb mb zstd zlib brotli quicklz lzo lz r snappi lzf zlibhttpwwwzlibnet lz httpwwwlzorg zstd also offer stronger compress ratio cost compress speed speed vs compress tradeoff configur small increment decompress speed preserv remain roughli set properti share lz compress algorithm zlib lzma follow test run core ik cpu ghz use lzbench opensourc inmemori benchmark inikep compil gcc silesia compress corpu compress speed vs ratio decompress speed compress speed vs ratioimagescspeedpng compress speed vs ratio decompress speedimagesdspeedpng decompress speed sever algorithm produc higher compress ratio slower speed fall outsid graph larger pictur includ slow mode click linkimagesdcspeedpng case small data compress previou chart provid result applic typic file stream scenario sever mb small data come differ perspect smaller amount data compress difficult achiev signific compress problem common mani compress algorithm reason compress algorithm learn past data compress futur data begin new file past build upon solv situat zstd offer __train mode__ use tune algorithm select type data provid sampl result train store file call dictionari load compress decompress use dictionari compress ratio achiev small data improv dramat compress small dataimagessmalldatapng compress small data compress gain achiev simultan provid faster compress decompress speed dictionari work correl famili small data _univers dictionary_ henc deploy one dictionari per type data provid greatest benefit dictionari gain mostli effect first kb compress algorithm reli previous decod content compress rest file dictionari compress creat dictionari zstd train fullpathtotrainingset dictionarynam compress dictionari zstd file dictionarynam decompress dictionari zstd decompress filezst dictionarynam build repositori clone multipl way provid build zstandard makefil system compat standard make gmake binari gener simpli run root directori gener zstd within root directori avail option includ make instal creat instal zstd binari librari man page make test creat run zstd test tool local platform cmake cmake project gener provid within buildcmak gener makefil build script creat zstd binari libzstd dynam static librari visual window go build directori find addit possibl project visual studio vs project compat vs vs vs autom build script visual compil krzysfr buildvs_script build zstd cli libzstd librari without need open visual studio solut statu zstandard current deploy within facebook use daili compress decompress larg amount data multipl format use case zstandard consid safe product environ licens zstandard bsdlicensedlicens also provid addit patent grantpat contribut dev branch one contribut merg reach master plan propos patch pleas commit dev branch featur branch direct commit master permit inform pleas read contributingcontributingmd miscellan zstd entropi stage provid huff fse finit state entropi libraryhttpsgithubcomcyanfinitestateentropi zstandard compress format notic copyright c yann collet permiss grant copi distribut document purpos without charg includ translat languag incorpor compil provid copyright notic notic preserv substant chang delet origin clearli mark distribut document unlimit version introduct purpos document defin lossless compress data format independ cpu type oper system file system charact set suitabl file compress pipe stream compress use zstandard algorithmhttpwwwzstandardorg data produc consum even arbitrarili long sequenti present input data stream use priori bound amount intermedi storag henc use data commun format use zstandard compress method option xxhash checksum methodhttpwwwxxhashorg detect data corrupt data format defin specif attempt allow random access compress data specif intend use implement softwar compress data zstandard format andor decompress data zstandard format text specif assum basic background program level bit primit data represent unless otherwis indic compliant compressor must produc data set conform specif present doesnt need support option though compliant decompressor must abl decompress least one work set paramet conform specif present may also ignor inform field checksum whenev support paramet defin compress stream must produc nonambigu error code associ error messag explain paramet unsupport overal convent document squar bracket ie use indic option field paramet name convent identifi mixed_case_with_underscor definit content compress zstandard transform zstandard __frame__ multipl frame append singl file stream frame total independ defin begin end set paramet tell decod decompress frame encapsul one multipl __blocks__ block compress guarante maximum content size depend frame paramet unlik frame block depend previou block proper decod howev block decompress without wait successor allow stream oper frame concaten circumst may requir append multipl frame exampl order add new data exist compress file without refram case frame bring set descriptor flag frame consid independ relat frame sequenti order abil decod multipl concaten frame within singl stream file left outsid specif exampl refer zstd command line util abl decod concaten frame sequenti order deliv final decompress result singl content skippabl frame magic_numb frame_s user_data byte byte n byte skippabl frame allow insert userdefin data flow concaten frame design pretti straightforward sole object allow decod quickli skip userdefin data continu decod skippabl frame defin specif compat lz one lzhttpwwwlzorg __magic_number__ byte littleendian format valu xdax mean valu xda xdaf valu valid identifi skippabl frame __frame_size__ size byte follow user_data without includ magic number size field field repres use byte littleendian format unsign bit mean user_data cant bigger byte __user_data__ user_data anyth data skip decod gener structur zstandard frame format structur singl zstandard frame follow magic_numb frame_head data_block data block content_checksum byte byte n byte byte __magic_number__ byte littleendian format valu xfdfb __frame_header__ byte detail next partthestructureofframe_head __data_block__ detail next chapterthestructureofdata_block that compress data store __content_checksum__ option bit checksum present content_checksum_flag set content checksum result xxh hash functionhttpwwwxxhashorg digest origin decod data input seed zero low byte checksum store littl endian format structur frame_head frame_head variabl size use minimum byte byte depend option paramet structur frame_head follow frame_header_descriptor window_descriptor dictionary_id frame_content_s byte byte byte byte frame_header_descriptor first header byte call frame_header_descriptor tell field present decod byte enough tell size frame_head bit number field name frame_content_size_flag single_segment_flag unused_bit reserved_bit content_checksum_flag dictionary_id_flag tabl bit highest bit bit lowest __frame_content_size_flag__ bit flag frame_header_descriptor specifi decompress data size provid within header flag_valu convert field_siz number byte use frame_content_s accord follow tabl flag_valu field_siz flag_valu field_siz depend single_segment_flag single_segment_flag set field_siz otherwis field_siz content size provid __single_segment_flag__ flag set data must regener within singl continu memori segment case frame_content_s necessarili present window_descriptor byte skip consequ decod must alloc memori segment size equal bigger frame_content_s order preserv decod unreason memori requir decod reject compress frame request memori size beyond decod author rang broader compat decod recommend support memori size least mb recommend decod free support higher lower limit depend local limit __unused_bit__ valu bit set zero decod compliant specif version shall interpret might use futur version signal properti mandatori properli decod frame __reserved_bit__ bit reserv futur featur valu _must zero_ decod compliant specif version must ensur set bit may use futur revis signal featur must interpret decod frame correctli __content_checksum_flag__ flag set bit content_checksum present frame end see content_checksum paragraph __dictionary_id_flag__ bit flag fhd tell dictionari id provid within header also specifi size field field_siz flag_valu field_siz window_descriptor provid guarante maximum backrefer distanc use within compress data inform import decod alloc enough memori window_descriptor byte option absent single_segment_flag set case maximum backrefer distanc content size valu byte eb bit number field name expon mantissa maximum distanc given follow formula windowlog expon windowbas windowlog windowadd windowbas mantissa window_s windowbas windowadd minimum window size kb maximum size byte tb properli decod compress data decod need alloc buffer least window_s byte order preserv decod unreason memori requir decod refus compress frame request memori size beyond decod author rang improv interoper decod recommend compat window size mb encod recommend request mb mere recommend though decod free support larger lower limit depend local limit dictionary_id variabl size field contain id dictionari requir properli decod frame note field option present caller make sure use correct dictionari format littleendian field size depend dictionary_id_flag byte repres id byte repres id byte repres id allow repres small id exampl larg byte dictionari id lose compac process _reserv rang _ frame go distribut privat environ dictionari id use howev public distribut compress frame use dictionari follow rang reserv futur use use low rang high rang frame_content_s origin uncompress size inform option field_siz provid accord valu frame_content_size_flag field_siz equal present byte format littleendian field_siz rang field_siz byte valu read directli field_siz _the offset added_ allow repres small size exampl use compat variant structur data_block structur data_block follow last_block block_typ block_siz block_cont bit bit bit n byte block header last_block block_typ block_siz use byte __last_block__ lowest bit signal block last one frame end right block may follow option content_checksum __block_typ block_size__ next bit repres block_typ remain bit repres block_siz format __littleendian__ block type valu block_typ raw_block rle_block compressed_block reserv raw_block uncompress block block_siz number byte read copi rle_block singl byte repeat n time case block_siz size regener compress block byte byte repeat compressed_block zstandard compress blocktheformatofcompressed_block detail anoth section specif block_siz compress size decompress size unknown maximum possibl valu guarante see reserv block valu use current version specif block size must respect rule compress mode compress size alway strictli decompress size block decompress size alway maximum backrefer distanc block decompress size alway kb __block_content__ block_cont actual data decod stand might compress depend previou field indic data block necessarili full sinc arbitrari flush may happen anytim block decompress content size block_maximum_decompressed_s smallest maximum backrefer distanc kb format compressed_block size compressed_block must provid use block_siz field data_block compressed_block guarante maximum regener size order properli alloc destin buffer see data_blockthestructureofdata_block detail compress block consist section literals_sectionliterals_sect sequences_sectionsequences_sect prerequisit decod compress block follow element necessari previou decod block distanc window_s previou block single_segment_flag set list recent offset previou compress block decod tabl previou compress block symbol type liter liter length match length offset literals_sect sequenc phase liter entangl match copi oper liter regroup first part block decod first copi sequenc oper decod flow need sequenc command literals_section_head huffman_tree_descript stream stream stream stream liter store uncompress compress use huffman prefix code compress option tree descript present follow stream literals_section_head header charg describ liter pack bytealign variables bitfield rang byte use littleendian convent literals_block_typ size_format regenerated_s compressed_s bit bit bit bit represent bit left smallest bit __literals_block_type__ field use lowest bit first byte describ differ block type literals_block_typ valu raw_literals_block rle_literals_block compressed_literals_block repeat_stats_literals_block raw_literals_block liter store uncompress rle_literals_block liter consist singl byte valu repeat n time compressed_literals_block standard huffmancompress block start huffman tree descript see detail repeat_stats_literals_block huffmancompress block use huffman tree _from previou huffmancompress liter block_ huffman tree descript skip __size_format__ size_format divid famili compressed_block requir decod compressed_s regenerated_s decompress size also decod number stream raw_literals_block rle_literals_block enough decod regenerated_s valu span sever byte convent littleendian __size_format raw_literals_block rle_literals_block__ valu x regenerated_s use bit literals_section_head byte regenerated_s header valu regenerated_s use bit literals_section_head byte regenerated_s header header valu regenerated_s use bit literals_section_head byte regenerated_s header header header note allow repres short valu exampl use long format accept increas compress data size __size_format compressed_literals_block repeat_stats_literals_block__ valu _a singl stream_ compressed_s regenerated_s use bit literals_section_head byte valu stream compressed_s regenerated_s use bit literals_section_head byte valu stream compressed_s regenerated_s use bit literals_section_head byte valu stream compressed_s regenerated_s use bit literals_section_head byte compressed_s regenerated_s field follow littleendian convent huffman_tree_descript section present literals_block_typ type compressed_literals_block prefix code repres symbol priori known alphabet bit sequenc codeword one codeword symbol manner differ symbol may repres bit sequenc differ length parser alway pars encod string unambigu symbolbysymbol given alphabet known symbol frequenc huffman algorithm allow construct optim prefix code use fewest bit possibl prefix code alphabet prefix code must exceed maximum code length bit improv accuraci cost header size requir memori complex decod oper specif limit maximum code length bit represent liter valu zero includ last present one exclud repres weight valu max_number_of_bit transform weight number_of_bit follow formula number_of_bit weight max_number_of_bit weight last symbol weight deduc previous decod one complet nearest power power give max_number_of_bit depth current tree __example__ let presum follow huffman tree must describ liter number_of_bit tree depth sinc smallest element use bit valu list valu valu list use weight instead number_of_bit weight formula weight number_of_bit max_number_of_bit number_of_bit give follow seri weight weight liter decod invers oper collect weight liter know last liter present nonzero weight weight deduct join nearest power sum weight exclud nearest power therefor max_number_of_bit weight huffman tree header singl byte valu tell decod list weight headerbyt direct represent weight written directli bit field full represent occupi number_of_symbol byte mean use last full byte even number_of_symbol odd number_of_symbol headerbyt note maximum number_of_symbol larger seri must necessarili use fse compress headerbyt seri weight compress fse length fsecompress seri equal headerbyt finit state entropi fse compress huffman weight seri weight compress use fse compress singl bitstream interleav state share singl distribut tabl decod fse bitstream necessari know compress size compress size provid headerbyt also necessari know _maximum possible_ decompress size sinc liter valu span last symbol valu repres fse bitstream start header describ probabl distribut creat decod tabl tabl must prealloc requir support maximum accuraci list huffman weight maximum accuraci bit fse header describ relev chapterfsedistributiontablecondensedformat fse bitstreambitstream main differ huffman header compress use state share fse distribut tabl bitstream contain fse symbol interleav raw bitfield number symbol decod discov track bitstream overflow condit state overflow bitstream end reach convers weight huffman prefix code present symbol shall weight valu possibl transform weight number_of_bit use formula number_of_bit number_of_bit max_number_of_bit weight symbol sort weight within weight symbol keep natur order symbol weight zero remov start lowest weight prefix code distribut order __example__ let presum follow list weight decod liter weight sort weight natur order give follow distribut liter weight number_of_bit prefix code na content huffmancompress liter stream bitstream size seen previou paragraph type huffmancompress liter singl stream stream encod use stream use cpu multipl execut unit outoford oper sinc stream decod independ possibl decod x faster singl stream presum cpu enough parallel avail singl stream header provid compress regener size stream though header provid compress regener size stream combin order properli decod stream necessari know compress regener size stream regener size stream calcul totals except last one byte smaller reach totals compress size provid explicitli stream variant bitstream preced unsign littleendian bit valu valu repres compress size one stream order last stream size deduct total compress size previous decod stream size streamcsiz totalcs streamcsiz streamcsiz streamcsiz bitstream read decod bitstream must read _backward_ start end begin therefor necessari know size bitstream also necessari know exactli _bit_ latest detect final bit flag highest bit latest byte finalbitflag consequ last byte possibl finalbitflag part use bitstream henc last byte contain use bit start end possibl read bitstream littleendian fashion keep track alreadi use bit read last max_number_of_bit bit possibl compar extract valu decod tabl determin symbol decod number bit discard process continu read requir number symbol per stream bitstream entir exactli consum henc reach exactli begin posit _all_ bit consum decod process consid faulti sequences_sect compress block success _sequences_ sequenc liter copi command follow match copi command liter copi command specifi length number byte copi extract liter section match copi command specifi offset length offset give posit copi within previou block _sequences_ decod liter left _liter section_ byte ad end block sequences_sect regroup symbol requir decod command symbol type liter length offset match length encod togeth interleav singl _bitstream_ sequences_sect start header follow option probabl tabl symbol type follow bitstream sequences_section_head literals_length_t offset_t match_length_t bitstream decod sequences_sect requir know size size deduct blocksiz literalsections sequences_section_head consist item number_of_sequ symbol compress mode __number_of_sequences__ variabl size field use byte let call first byte byte byte sequenc sequenc section stop regener content defin entir liter section byte number_of_sequ byte use byte byte number_of_sequ byte byte use byte byte number_of_sequ byte byte xf use byte __symbol compress modes__ singl byte defin compress mode symbol type bit number field name literals_lengths_mod offsets_mod match_lengths_mod reserv last field reserv must allzero literals_lengths_mod offsets_mod match_lengths_mod defin compression_mod liter length offset match length respect follow enumer valu compression_mod predefined_mod rle_mod fse_compressed_mod repeat_mod predefined_mod use predefin distribut tabl rle_mod singl code repeat number_of_sequ time repeat_mod reus distribut tabl previou compress block fse_compressed_mod standard fse compress distribut tabl present describ next partdistributiont code liter length match length offset symbol _code_ context specifi baselin number_of_bit add _codes_ fse compress interleav raw addit bit bitstream liter length code liter length code valu rang includ defin length byte literals_length_cod length literals_length_cod number_of_bit literals_length_cod baselin number_of_bit literals_length_cod baselin number_of_bit literals_length_cod baselin number_of_bit default distribut liter length code compression_mod predefined_mod predefin distribut use fse compress definit use accuraci bit state short literalslength_defaultdistribut match length code match length code valu rang includ defin length byte match_length_cod valu match_length_cod number_of_bit match_length_cod baselin number_of_bit match_length_cod baselin number_of_bit match_length_cod baselin number_of_bit default distribut match length code compression_mod defin predefined_mod predefin distribut use fse compress definit use accuraci bit state short matchlengths_defaultdistribut offset code offset code valu rang n decod free limit maximum n support recommend support least inform time write refer decod support maximum n valu bit mode offset code also number addit bit read translat offset_valu use follow formula offset_valu offsetcod readnbitsoffsetcod offset_valu offset offset_valu mean maximum offset_valu n support backrefer distanc n limit maximum backrefer distancewindow_descriptor offset_valu special defin repeat code mean one previou offset repeat sort recenc order mean recent one see repeat offsetsrepeatoffset paragraph default distribut offset code compression_mod defin predefined_mod predefin distribut use fse compress definit use accuraci bit state support maximum n allow offset valu sequenc compress block requir offset larger possibl use default distribut repres short offsetcodes_defaultdistribut distribut tabl follow header distribut tabl describ present order liter length offset match length content decod depend respect encod mode predefined_mod content use predefin distribut tabl rle_mod byte code use across whole compress block fse_compressed_mod distribut tabl present repeat_mod content reus distribut previou compress block fse distribut tabl condens format fse distribut tabl describ probabl symbol last present one includ normal scale accuracy_log bitstream read forward littleendian fashion necessari know exact size sinc discov report decod process bitstream start report scale oper accuracy_log lowbit note maximum accuracy_log liter match length offset higher valu consid error follow symbol valu last present one number bit use field variabl depend remain probabl __example__ presum accuracy_log presum probabl point alreadi distribut decod may read valu includ therefor must read logsup bit valu decod small valu use less bit __example__ presum valu includ possibl valu remain bit field use way first valu henc use bit valu use bit achiev scheme valu read valu decod number bit use symbol probabl read one one order probabl obtain valu decod follow formula proba valu mean valu becom neg probabl special probabl mean less effect distribut tabl describ next paragraph purpos calcul cumul distribut count one next paragraphfsedecodingfromnormalizeddistributiontodecodingt symbol probabl zero follow bit repeat flag repeat flag tell mani probabl zero follow current one provid number rang anoth bit repeat flag follow last symbol reach cumul total accuracy_log decod complet last symbol make cumul total go accuracy_log distribut consid corrupt decod tell mani byte use process mani symbol present bitstream consum round number byte remain bit within last byte unus fse decod normal distribut decod tabl distribut normal probabl enough creat uniqu decod tabl follow follow build rule tabl size tables accuracy_log cell describ symbol decod instruct get next state symbol scan natur order less probabl symbol probabl attribut singl cell start end tabl symbol defin full state reset read accuracy_log bit remain symbol sort natur order start symbol tabl posit symbol get attribut mani cell probabl cell alloc spread linear successor posit follow rule posit tables tables posit tables posit skip alreadi occupi typic less probabl symbol result list state valu state decod current symbol get number_of_bit baselin requir next state first necessari sort state natur order lower state need bit higher one __example__ presum symbol probabl receiv state valu state sort natur order next power space probabl divid equal part presum accuracy_log defin state divid share larg order reach lowest state count doubl take share twice larger requir one bit process number start higher state use less bit state order width number_of_bit rang number baselin rang next state determin current state read requir number_of_bit ad specifi baselin bitstream fse bitstream read revers direct written zstd compressor write bit forward block decompressor must read bitstream _backwards_ find start bitstream therefor necessari know offset last byte block found count block_siz byte block header write last bit contain inform compressor write singl bit fill byte bit pad last byte compress bitstream reason decompress last byte contain pad first byte read decompressor need skip initi bit first bit occur afterward use part bitstream begin start state bitstream start initi state valu use requir number bit respect _accuracy_ decod previous normal distribut start literals_length_st follow offset_st final match_length_st remind alway keep mind valu read _backward_ decod sequenc state give code code provid baselin number_of_bit add see symbol decod section detail symbol decod start read number_of_bit requir decod offset match_length literals_length offset match_length literals_length defin sequenc start insert number liter defin literals_length continu copi match_length byte currentpo offset next oper updat state use rule precalcul decod tabl literals_length_st updat follow match_length_st offset_st oper repeat number_of_sequ time end bitstream shall entir consum otherwis bitstream consid corrupt symbol decodingthecodesforliteralslengthsmatchlengthsandoffset repeat offset seen offset code first valu defin repeat offset call repeated_offset repeated_offset repeated_offset sort recenc order repeated_offset mean recent one except though current sequenc liter length case repeat offset push one repeated_offset becom repeated_offset repeated_offset becom repeated_offset repeated_offset becom repeated_offset _byte first block offset histori popul follow valu order block receiv start valu previou compress block note noncompress block skip contribut offset histori offset code offsetcod offset updat rule new offset take lead offset histori previou place alreadi present mean repeated_offset recent use histori unmodifi repeated_offset use swap repeated_offset dictionari format zstd compat raw content dictionari free format restrict dictionari creat zstd train follow format describ __prerequisites__ dictionari size defin either buffer limit file size magic_numb dictionary_id entropy_t content __magic_number__ byte id valu xeca littleendian format __dictionary_id__ byte store littleendian format dictionary_id valu except mean dictionary_id use decod check use correct dictionari _reserv rang _ frame go distribut privat environ dictionary_id use howev public distribut compress frame follow rang reserv futur use use low rang high rang __entropy_tables__ follow format compress block store follow order huffman tabl liter fse tabl offset fse tabl match length fse tabl liter length final follow offset valu popul recent offset store order byte littleendian total byte recent offset must valu dictionari size __content__ rest dictionari content content act past front data compress decompress compress block theformatofcompressed_block appendix decod tabl predefin code appendix contain fse decod tabl predefin liter length match length offset code tabl construct use algorithm given normal distribut decod tabl chapter tabl use exampl crosscheck implement implement decod tabl gener algorithm correctli liter length code state symbol number_of_bit base match length code state symbol number_of_bit base offset code state symbol number_of_bit base version chang ad predefin code johann rudolph clarifi field name przemyslaw skibinski numer format adjust zstd v limit huffman tree depth bit reserv dictid rang initi releas contribut zstandard want make contribut project easi transpar possibl develop process new version develop dev branch featur branch deem readi releas merg master consequ contribut must stage first dev featur branch pull request activ welcom pull request fork repo creat branch dev youv ad code test add test youv chang api updat document ensur test suit pass make sure code lint havent alreadi complet contributor licens agreement cla contributor licens agreement cla order accept pull request need submit cla need work facebook open sourc project complet cla httpscodefacebookcomcla issu use github issu track public bug pleas ensur descript clear suffici instruct abl reproduc issu facebook bounti programhttpswwwfacebookcomwhitehat safe disclosur secur bug case pleas go process outlin page file public issu code style space indent rather tab licens contribut zstandard agre contribut licens licenselicens file root directori sourc tree zstandard librari file __lib__ directori contain sever directori depend target use case enough includ file relev directori api zstandard stabl api expos within zstdhzstdh root lib directori advanc api addit api may use your look advanc featur commonerror_publich transform size_t function result enum precis error handl zstd_static_linking_onli defin macro _before_ includ zstdh give access advanc experiment api api shall ___never use dynam library___ stabl definit may chang futur static link allow modular build directori common requir circumst select support compress ad file compress directori similar way build decompressoronli librari decompress directori option function provid dictbuild sourc file creat dictionari api consult dictbuilderzdicth modul also depend common compress legaci sourc code decompress previou version zstd start v modul also depend common decompress librari compil must includ direct zstd_legacy_support main api consult legacyzstd_legacyh advanc api version found relev header file exampl advanc api version v legacyzstd_vh obsolet stream api stream provid within zstdh older stream api still provid within commonzbuffh consid obsolet remov futur version consid migrat toward newer stream api miscellan file sourc code licens contain bsd licens text makefil script compil instal zstd librari static dynam libzstdpcin pkgconfig make instal readmemd file program script autom test zstandard directori contain follow program script datagen synthet parametr data gener test fullbench precis measur speed zstd inner function fuzzer test tool check zstd integr target platform paramgril paramet tester zstd testzstdspeedpi script test zstd speed differ commit testzstdversionspi compat test zstd version store github v zbufftest test tool check zbuff buffer stream api integr zstreamtest fuzzer test tool zstd stream api testzstdversionspi script test zstd interoper version script creat versionstest directori zstd repositori clone tage releas version zstd compil follow step interoper zstd version check testzstdspeedpi script test zstd speed differ commit script creat speedtest directori zstd repositori clone compil branch zstd perform speed benchmark given list file testfilenam paramet sleeptim option paramet default second second script check repositori new commit new commit found compil speed benchmark commit perform result speed benchmark compar previou result compress decompress speed one zstd level lower lowerlimit option paramet default speed benchmark restart second result also lower lowerlimit warn email send recipi list email paramet addit remark sure speed result accur script run stabl target system job run parallel use script virtual machin lead larg variat speed result speed benchmark perform comput load averag lower maxloadavg option paramet default script send email use mutt mutt avail send email without attach use mail avail print warn exampl usag two test file one email address addit messag testzstdspeedpi silesiatar calgarytar emailgmailcom messag test laptop sleeptim run script background pleas use nohup testzstdspeedpi testfilenam email full list paramet posit argument testfilenam file name list speed benchmark email list email address send warn option argument h help show help messag exit messag messag attach addit messag email lowerlimit lowerlimit send email speed lower given limit maxloadavg maxloadavg maximum load averag start test lastclevel lastclevel last compress level test sleeptim sleeptim frequenc repositori check second zstandard wrapper zlib main object creat zstd wrapper zlibhttpzlibnet allow quick smooth transit zstd project alreadi use zlib requir file build zstd wrapper zlib follow file requir zlibh static dynam zlib librari zlibwrapperzstd_zlibwrapperh zlibwrapperzstd_zlibwrapperc static dynam zstd librari first two file requir project use zlib includ zstd distribut file suppli zstd distribut embed zstd wrapper within project let assum project use zlib compil gcc projecto lz compil zstd wrapper project follow chang refer includ zlibh includ zstd_zlibwrapperh compil project zstd_zlibwrapperc static dynam zstd librari link chang gcc projecto zstd_zlibwrappero lz lzstd enabl zstd compress within project embed zstd wrapper within project zstd librari turn default project work zlib two option enabl zstd compress compil dzwrap_use_zstd use defin zwrap_use_zstd includ zstd_zlibwrapperh use void zwrap_usezstdcompressionint turn_on function declar includ zstd_zlibwrapperh decompress zlib zstd stream automat detect decompress use proper librari behavior chang use zwrap_setdecompressiontypezwrap_force_zlib make zlib decompress slightli faster exampl take file testexamplec zlib librari distributionhttpzlibnet copi zlibwrapperexamplesexamplecexamplesexamplec compil execut show follow result zlib version x compil flag x uncompress hello hello gzread hello hello gzget gzseek hello inflat hello hello large_infl ok inflatesync hello hello inflat dictionari hello hello chang includ zlibh includ zstd_zlibwrapperh compil examplecexamplesexamplec file dzwrap_use_zstd link addit zstd_zlibwrappero lzstd forc turn follow function test_gzio test_flush test_sync use current unsupport featur run show follow result zlib version x compil flag x uncompress hello hello inflat hello hello large_infl ok inflat dictionari hello hello script use compil found zlibwrappermakefilemakefil measur performac zstandard wrapper zlib zstd distribut contain tool call zwrapbench measur speed ratio zlib zstd wrapper benchmark conduct use given filenam synthet data filenam provid file read memori join togeth make benchmark precis elimin io overhead mani filenam suppli multipl paramet paramet wildcard name directori use paramet r option one select compress level start b end e paramet select minim time use test level b option bigger file divid smaller independ compress block benchmark tool compil make zwrapbench use zlibwrappermakefilemakefil improv speed stream compress stream compress compressor never know big data compress zstandard compress improv provid size sourc data compressor default stream compressor assum data bigger kb hurt compress speed smaller data zstd wrapper provid zwrap_setpledgedsrcs function allow chang pledg sourc size given compress stream function chang zstd compress paramet may improv compress speed andor ratio call deflateinitor deflatereset deflat deflatesetdictionari function help data compress block chang case deflateinit deflatereset immedi follow deflatestrm z_finish case automat detect reus context ordinari zlib compress two filesstream alloc two context st file call deflateinit deflat deflat defalateend nd file call deflateinit deflat deflat defalateend speed compress improv reus singl context follow step initi context deflateinit st file call deflat deflat nd file call deflatereset deflat deflat free context deflateend check differ made experi use zwrapbench rib zstd zlib compress level input data decompress git repositori download httpsgithubcomgitgitarchivemasterzip contain file tabl show reus context minor influenc zlib give improv zstd exampl last line give better compress speed better decompress speed compress type compress decompress compr size ratio zlib mb mb zlib reus context mb mb zlib zlibwrapp reus context mb mb zlib zlibwrapp reus context mb mb zstd use zstd_cctx mb mb zstd use zstd_cstream mb mb zstd zlibwrapp reus context mb mb zstd zlibwrapp reus context mb mb compat issu enabl zstd compress nativ zlib function support call unsupport method put error messag strmmsg return z_stream_error support method deflateinit deflat except z_full_flush z_block z_tree deflatesetdictionari deflateend deflatereset deflatebound inflateinit inflat inflatesetdictionari inflatereset inflatereset compress compress compressbound uncompress ignor method noth deflateparam unsupport method gzip file access function deflatecopi deflatetun deflatepend deflateprim deflatesethead inflategetdictionari inflatecopi inflatesync inflateprim inflatemark inflategethead inflatebackinit inflateback inflatebackend zstandard librari usag exampl simpl compressionsimple_compressionc compress singl file introduc usag zstd_compress simpl decompressionsimple_decompressionc decompress singl file compat simpl compress result remain memori introduc usag zstd_decompress stream compressionstreaming_compressionc compress singl file introduc usag zstd_compressstream stream decompressionstreaming_decompressionc decompress singl file compress zstd compat simpl stream compress result sent stdout introduc usag zstd_decompressstream dictionari compressiondictionary_compressionc compress multipl file use dictionari introduc usag zstd_createcdict zstd_compress_usingcdict dictionari decompressiondictionary_decompressionc decompress multipl file use dictionari result remain memori introduc usag zstd_createddict zstd_decompress_usingddict command line interfac zstandard librari command line interfac cli creat use make command without addit paramet howev makefil target creat differ variat cli zstd default cli support gziplik argument includ dictionari builder benchmark support decompress legaci zstd version zstd zstd forc compil bit mode zstd_nolegaci zstd except support decompress legaci zstd version zstdsmall cli optim minim size without dictionari builder benchmark support decompress legaci zstd version zstdcompress compressoronli version cli without dictionari builder benchmark support decompress legaci zstd version zstddecompress decompressoronli version cli without dictionari builder benchmark support decompress legaci zstd version aggreg paramet cli support aggreg paramet ie b e join bei dictionari builder command line interfac zstd offer train mode use tune algorithm select type data provid sampl result train store file select option default name dictionari load compress decompress use dictionari compress ratio achiev small data improv dramat compress gain achiev simultan provid faster compress decompress speed dictionari work correl famili small data univers dictionari henc deploy one dictionari per type data provid greater benefit dictionari gain mostli effect first kb compress algorithm reli previous decod content compress rest file usag dictionari builder creat dictionari cli creat dictionari zstd train fullpathtotrainingset dictionarynam compress dictionari zstd file dictionarynam decompress dictionari zstd decompress filezst dictionarynam benchmark command line interfac cli includ inmemori compress benchmark modul zstd benchmark conduct use given filenam file read memori join togeth make benchmark precis elimin io overhead mani filenam suppli multipl paramet paramet wildcard name directori use paramet r option benchmark measur ratio compress size compress decompress speed one select compress level start b end e paramet select minim time use test level usag command line interfac full list option obtain h h paramet usag zstd arg file file file filenam file file read standard input argument compress level default decompress file use file dictionari file result store file input file f overwrit output without prompt rm remov sourc file success decompress k preserv sourc file default hh display helplong help exit advanc argument v display version number exit v verbos mode specifi multipl time increas log level default q suppress warn specifi twice suppress error c forc write standard output even consol r oper recurs directori ultra enabl level beyond requir memori nodictid dont write dictid header dictionari compress nocheck integr check defaulten test test compress file integr nospars spars mode defaulten file disabl stdout dictionari builder train creat dictionari train set file file file dictionari name default dictionari maxdict limit dictionari specifi size default dictionari select level default dictid forc dictionari id specifi valu default random benchmark argument b benchmark file use compress level default e test compress level bx default minimum evalu time second default b cut file independ block size default block parallel zstandard pzstandard parallel zstandard pigzlik tool zstandard provid zstandard format compat compress decompress abl util multipl core break input equal size chunk compress chunk independ zstandard frame concaten frame togeth produc final compress output pzstandard write byte header frame skippabl frame zstandard format tell pzstandard size next compress frame pzstandard support parallel decompress file compress pzstandard decompress file compress zstandard pzstandard io one thread decompress anoth usag pzstandard support command line interfac zstandard also provi p option specifi number thread dictionari mode current support basic usag pzstd inputfil outputfil p numthread compress pzstd inputfil outputfil p numthread decompress pzstandard also support pipe fifo pipe cat inputfil pzstd p numthread c devnul option pzstd help pzstandard tri pick smart default number thread specifi display pzstd help number suitabl compil defin pzstd_num_thread number thread prefer benchmark refer pzstandard pigz compar intel core ghz use thread silesia compress corpushttpsunaeipolslplsdeorindexphppagesilesia compress speed vs ratio thread decompress speed thread compress speed vs ratioimagescspeedpng compress speed vs ratio decompress speedimagesdspeedpng decompress speed test procedur run follow command time compress level take minimum time time pzstd p c silesiatar silesiatarzst time pzstd p c silesiatarzst devnul time pigz p k c silesiatar silesiatargz time pigz p k c silesiatargz devnul pzstandard test use compress level pigz test use compress level pigz parallel decompress simpli read decompress write separ thread test test requir gtesthttpsgithubcomgooglegoogletest instal modifi gtest_inc gtest_lib testmakefil utilstestmakefil work instal gtest run make test contribpzstd directori