BioEn - Bayesian Inference Of ENsembles
=======================================

.. image::  /img/bioen_logo_480.png
    :align: center

Authors
    César Allande, Jürgen Köfinger, Katrin Reichel, Klaus Reuter, Lukas
    S. Stelzl

Year
    2018

Licence
    GPLv3

Copyright
    © 2018 César Allande, Gerhard Hummer, Jürgen Köfinger, Katrin
    Reichel, Klaus Reuter, Lukas S. Stelzl

References

    -  [Hummer2015] Hummer G. and Koefinger J., Bayesian Ensemble
       Refinement by Replica Simulations and Reweighting. J. Chem. Phys.
       143(24):12B634\_1 (2015). https://doi.org/10.1063/1.4937786
    -  [Rozycki2011] Rozycki B., Kim Y. C., Hummer G., SAXS Ensemble
       Refinement of ESCRT-III Chmp3 Conformational Transitions
       Structure 19 109–116 (2011).
       https://doi.org/10.1016/j.str.2010.10.006
    -  [Reichel2018] Reichel K., Stelzl L. S., Köfinger J., Hummer G.,
       Precision DEER Distances from Spin-Label Reweighting, J. Phys.
       Chem. Lett. 9 19 5748-5752 (2018).
       https://doi.org/10.1021/acs.jpclett.8b02439
    -  [Köfinger2019] Koefinger J., Stelzl L. S. Reuter K.,
       Allande C., Reichel K., Hummer G., Efficient Ensemble Refinement
       by Reweighting J. Chem. Theory Comput. Article ASAP https://doi.org/10.1021/acs.jctc.8b01231 

Description
-----------

BioEn integrates a broad range of experimental data to refine ensembles
of structures. For a detailed description of the procedures and the
algorithm, we refer to [Hummer2015].

.. image::  /img/bioen.png

Overview of the BioEn software
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The BioEn software consists of two Python packages:

* `optimize <https://github.com/bio-phys/BioEn/tree/master/bioen/optimize>`_ provides algorithms to solve the optimization problem underlying ensemble refinement by reweighting. This package can be used independently of the 'analyze' package.
* `analyze <https://github.com/bio-phys/BioEn/tree/master/bioen/analyze>`_ uses the 'optimize' package to integrate a wide range of experimental data and simulations in a user friendly way.

Help
----

Please, if you have an issue with the software, open an issue on the github repository https://github.com/bio-phys/bioen/issues.

If you have any questions or suggestions, please contact bioen@biophys.mpg.de.

Dependencies and Software Requirements
--------------------------------------

-  Python 2.7 or Python 3
-  Python packages: numpy, scipy, Cython, pyyaml, MDAnalysis, pandas
-  GCC (>= 4.9)
-  GSL (>= 2.1)
-  LIBLBFGS (>= 1.10)

Copies of GSL and LIBLBFGS are included in the source distribution of
BioEn. To run Jupyter notebooks ``*.ipynb`` in ./examples/ you need
additionally

-  Jupyter (https://jupyter.org/)
-  Python packages: matplotlib

Installation
------------

Dependencies
~~~~~~~~~~~~

In addition to the multidimensional minimizers from SciPy, BioEN
supports the minimizers provided by the GSL library and by the LIBLBFGS
library which do increase the performance significantly. To obtain these
libraries, the following options are possible, where option 1 is
recommended for most users:

1. In the directory 'third-party', copies of the source codes of GSL and
   LIBLBFGS including a script to build and install them are provided.
   After having run the build script './install\_dependencies.sh', both
   the libraries are placed into the '~/.local' directory where BioEN's
   'setup.py' will find and use them automatically.
2. Alternatively, you may install GSL and LIBLBFGS to a default location
   using the package manager of your operating system, where 'setup.py'
   will find them typically, as well.
3. Finally, on some HPC systems, GSL and LIBLBFGS may already be
   provided via environment modules. In this case, load the respective
   modules before installing BioEN.

Note that the environment variables 'GSL\_HOME' and 'LIBLBFGS\_HOME' are
evaluated by 'setup.py'. If set, they are assumed to contain the path to
a valid installation of GSL or LIBLBFGS which will then be used. Setting
these variables is only necessary if the libraries were installed to a
non standard location, e.g. with Homebrew on the Mac.

Installation
~~~~~~~~~~~~

Once the dependencies are available (see above), install the package as
follows:

::

    BIOEN_OPENMP=1 python setup.py install [--user]

BIOEN\_OPENMP set to 1 enables OpenMP parallelism. On OSX use
BIOEN\_OPENMP=0.

You can use the optional '--user' flag for a local installation which
does not require root privileges. When you install BioEn locally, please
make sure that '$HOME/.local/bin' is on your path. You can add the
folder to the path, e.g., by adding 'export PATH=$HOME/.local/bin:$PATH'
to your '.bashrc' file. In a conda-environment, install the package
without the '--user' flag.

Usage
-----

We want to integrate a diverse set of experimental data with simulated
observables. Therefore, we implemented three types of chi-square
calculations to use different kinds of experimental data:

-  Generic data (chi-square optimization without nuisance parameters)
-  DEER/PELDOR data (includes the modulation depth as a nuisance
   parameter)
-  SAXS/WAXS/SANS data (includes the scaling parameter and constant
   offset as a nuisance parameter)

BioEn can also be used to obtain **precision DEER distances from
spin-label ensemble refinement** [Reichel2018], for which we provide an
`example <https://github.com/bio-phys/BioEn/tree/master/examples/DEER/rotamer-refinement/POTRA>`__.

(1) Generic data
~~~~~~~~~~~~~~~~

The term generic data refers to experimental data, where measurements
provide single data points including noise (e.g. NOE, PREs, chemical
shifts, J-couplings, distances, chemical cross-links etc). To use
generic data, the bioen options should contain
``--experiments generic``. In the experimental data file (e.g.
``./test/generic/data/exp-generic.dat``), the ID (first column) of a
data point (second column) and its noise (third column) has to be
provided. The ID refers than to the file from the simulated data (e.g.
``./test/generic/data/sim-noe_1-generic.dat``), in which each line is
the simulated data point from a single ensemble member (e.g., simualted
data extracted from a trajectory of a MD simulation).

The full list of options for generic data is:

.. code:: bash

    --sim_path
    --sim_prefix
    --sim_suffix
    --exp_path
    --exp_prefix
    --exp_suffix
    --data_IDs
    --data_weight
    --input_pkl
    --output_pkl

Please take note of the options ``--sim_path``, ``--sim_prefix``,
``--sim_sufffix``, ``--exp_path``, ``--exp_prefix``, and
``--exp_suffix``. These are useful to define the path to and names of
the files. Defaults are provided.

(2) Experimental data from DEER/PELDOR measurements
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For the reweighting with experimental data including a nuisance
parameter (here: modulation depth), the structure of the input files is
extended and more information is needed. To use DEER data, the bioen
options should contain ``--experiments deer``. In the case of DEER data,
we can either perform reweighting over an ensemble of conformations with
`averaged spin-label rotamer
states <https://github.com/bio-phys/BioEn/blob/master/examples/DEER/conformation-refinement/conformer_refinement.ipynb>`__
or over an `ensemble of spin-label rotamer states with a single protein
conformation <https://github.com/bio-phys/BioEn/blob/master/examples/DEER/rotamer-refinement/POTRA/rotamer_refinement_potra.ipynb>`__.

If an ensemble of conformations is investigated, provide for each label
pair (e.g. 319-259) a single file of the experimental data (e.g.,
``./test/deer/data/exp-319-259-deer.dat``) and ensemble member (e.g.,
``./test/deer/data/conf0-319-259-deer.dat``). The experimental data file
contains:

.. code:: bash

    #time   #raw        #polyfit
    0.0     0.9886054   1.0
    0.008   0.97737117  0.99091340848
    0.016   1.0         0.988879614369
    0.024   0.97842962  0.984631477624
    0.032   0.98185696  0.983339482409

The simulated data file (e.g. ``conf0-319-259-deer.dat``) contains:

.. code:: bash

    #time   #simulated_data
    0.0     1.0
    0.008   0.99984697806
    0.016   0.999388027044
    0.024   0.998623491217
    0.032   0.997553943855

Using DEER data in BioEn, the models file (``models-deer.dat``) is of
particular interest: listed numbers (model IDs) in this file have to be
the same as the deer file names
(``conf0-319-259-deer.dat, conf1-319-259-deer.dat, conf2-319-259-deer.dat``
and so on).

If an ensemble of spin-label rotamer states is investigated, we
recommend to use the Jupyter notebook
``deer_spin_label_reweighting.ipynb`` in
``./examples/DEER/rotamer-refinement/single_trace/``. Here, the user can
define the protein structure and a own rotamer library (or use the
default). By executing the cells in the notebook, data preparation,
BioEn run, and analysis can be performed in a smooth procedure. The
analysis of the BioEn data include also the L-curve analysis. More
details on the method are provided in [Reichel2018].

For both cases, refinement over an ensemble of protein conformations or
over spin-label rotamer states, the modulation depth as the nuisance
parameter is relevant. With the option ``--deer_modulation_depth``, an
initial guess ("<path\_to\_file>/modulation-depth.dat") can be provided
or an initial optimization ("initial-optimization") can be performed for
each spin-label pair. As indicated above, the modulation depth is needed
to calculate the consistency of the simulated data with the experimental
data correctly. To achieve this, we have to iteratively optimize the
weights of the ensemble members and the modulation depth. For all cases
tested with DEER data, 10 iterations seems to be sufficient until the
optimization converges. To do so, we recommend to set the option
``--number_of_iterations`` to **10** or higher.

The full list of options for DEER data is:

.. code:: bash

    --deer_sim_path
    --deer_sim_prefix
    --deer_sim_suffix
    --deer_exp_path
    --deer_exp_prefix
    --deer_exp_suffix
    --deer_labels
    --deer_noise
    --deer_modulation_depth
    --deer_input_pkl
    --deer_input_hd5
    --deer_output_pkl
    --deer_input_sim_pkl
    --deer_input_sim_hd5

Please take note of the options ``--deer-sim_path``,
``--deer_sim_prefix``, ``--deer_sim_suffix``, ``--deer_exp_path``,
``--deer_exp_prefix``, and ``--deer_exp_suffix``. These options are
useful to define the names of the simulated and experimental files. In
addition, please define the spin-label pairs with ``--deer_labels``
(e.g.; "319-259,370-259"), which is also part of the experimental and
simulated data file names (see above).

(3) Experimental data from SAXS/WAXS measurements
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

BioEn can be used with `scattering
data <https://github.com/bio-phys/BioEn/blob/master/examples/scattering/scattering_reweighting.ipynb>`__
like SAXS or WAXS, for which we provide also the optimization of the
nuisance parameter (here: coefficient). To use scattering data, the
bioen options should contain ``--experiments scattering``. The input
data is handled in a similar way as the DEER data, but just for a single
scattering curve and not different label-pairs. The standard file format
for experimental data (e.g. ``lyz-exp.dat``) is:

.. code:: bash

    #   q                 I(q)      error/noise
    4.138455E-02        5.904029    1.555333E-01
    4.371607E-02        5.652469    1.527037E-01
    4.604759E-02        5.533381    1.521723E-01
    4.837912E-02        5.547052    1.474577E-01
    5.071064E-02        5.296281    1.436712E-01

The simulated data file (e.g. ``lyz0-sim-saxs.dat``) contains:

.. code:: bash

    #   q               I(q)
    4.138454e-02    2.906550e+06
    4.371607e-02    2.865970e+06
    4.604758e-02    2.823741e+06
    4.837911e-02    2.779957e+06
    5.071064e-02    2.734716e+06

To handle different data input, we recommend to use the ipython notebook
``./examples/scattering/scattering_reweighting.ipynb``.

The full list of options for scattering data is:

.. code:: bash

    --scattering_sim_path
    --scattering_sim_prefix.
    --scattering_sim_suffix
    --scattering_exp_pPath
    --scattering_exp_prefix
    --scattering_exp_suffix
    --scattering_noise
    --scattering_coefficient
    --scattering_data_weight
    --scattering_input_pkl
    --scattering_input_hd5
    --scattering_input_sim_pkl
    --scattering_input_sim_hd5
    --scattering_output_pkl

Please take note of the options ``--scattering_sim_prefix``,
``--scattering_sim_sufffix``, ``--scattering_exp_prefix``, and
``--scattering_exp_suffix``. These options are useful to define the
names of the files of experimental and simulated.

As indicated above, a nuisance parameter (here: coefficient) is needed
to calculate the consistency of the simulated data with the experimental
data correctly. To achieve this, we have to iteratively optimize the
weights of the ensemble members and the coefficient. For all cases
tested with scattering data, 10 iterations seems to be sufficient until
the optimization converges. To do so, we recommend to set the option
``--number_of_iterations`` to **10** or higher.

(4) Experimental data from Circular dichroism (CD) measurements
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

BioEn can be used with `CD
data <https://github.com/bio-phys/BioEn/blob/master/examples/cd_data/cd_data_reweighting.ipynb>`__. To use CD data, the bioen options should contain ``--experiments cd``.  The standard file format
for experimental data (e.g. ``exp-cd.dat``) is:

.. code:: bash

   #wavelength   cd_raw          cd_poly_fit
   190           -5.808250e+03   -6.356057524681091309e+03
   191           -8.324000e+03   -8.437500596046447754e+03
   192           -1.228125e+04   -1.166270971298217773e+04
   193           -1.553750e+04   -1.528861761093139648e+04
   194           -1.938975e+04   -1.879757702350616455e+04 


The simulated data file (e.g. ``conf1-cd.dat``) contains:

.. code:: bash


   #wavelength   cd
   190           1.522400000000000000e+04
   191           1.838200000000000000e+04
   192           2.215800000000000000e+04
   193           2.556100000000000000e+04
   194           2.796400000000000000e+04


The full list of options for scattering data is:

.. code:: bash

    --cd_sim_path
    --cd_sim_prefix.
    --cd_sim_suffix
    --cd_exp_pPath
    --cd_exp_prefix
    --cd_exp_suffix
    --cd_noise
    --cd_data_weight
    --cd_input_pkl
    --cd_input_hd5
    --cd_input_sim_pkl
    --cd_input_sim_hd5
    --cd_output_pkl

Please take note of the options ``--cd_sim_prefix``,
``--cd_sim_sufffix``, ``--cd_exp_prefix``, and
``--cd_exp_suffix``. These options are useful to define the
names of the files of experimental and simulated.


Other options and settings
~~~~~~~~~~~~~~~~~~~~~~~~~~

The initial and reference weights can be set with
``--reference_weights`` and ``--initial_weights``. For both options, one
can either choose **uniform** (uniformly distributed weights; default),
**random** (randomly distributed weights), or provide a file as input.

As described in [Hummer2015], we have to balance the consistency with
the experimental data (chi-square) with the changes in the weights
(relative entropy) by the **confidence parameter theta**. We can achieve
this aim by the maximum-entropy principle and as such avoid
over-fitting. To decide for the correct confidence parameter theta for a
specific set of data, usually a theta-series is applied. This means,
that for each theta an independent ensemble refinement run is performed.
Subsequent L-curve analysis (relative entropy vs. chi-square) leads us
to the optimal weight distribution. Please note, that the choice of the
confidence parameter depends on the system and data. In the BioEn
software package, one can choose ``--theta`` by defining a single value
(e.g., 10.0) or a theta-series, which can be provided as a list (e.g.,
100.0,10.0,1.0) or a list in a file (e.g., <path\_to\_file>/thetas.dat).

To check the BioEn results quickly, a simple plot can be generated, that
compares experimental data and ensemble averaged simulated data for the
used confidence values. Therefore, the following three options have to
be set: ``--simple_plot``, ``--simple_plot_input`` and
``--simple_plot_output``. The file name of the output pkl file has to be
provided for ``--simple_plot_input``. The data in this pkl file is
visualized and saved in a pdf file, which can be specified with
``--simple_plot_output``.

Misc options
~~~~~~~~~~~~

The option ``--output_pkl_input_data`` can be used to generate a pkl
file of all settings, parameters and weights from the previous BioEn
run. This file can then be used afterwards with ``--input_pkl`` to
restart the BioEn calculation.

Minimal example
~~~~~~~~~~~~~~~

The minimal amount of input parameters are:

-  number of ensemble members (``--number_of_models``)
-  list of models (``--models_list``)
-  type of experiments (``--experiments``)
-  input experimental and simulated data

In case you have data from NMR measurements (e.g. NOEs), a typical
invocation would look like this:

.. code:: bash

    bioen \
        --number_of_models 10 \
        --models_list <path-to-data>/models-generic.dat \
        --experiments generic \
        --theta 0.01 \
        --sim_path <path-to-data> \
        --exp_path <path-to-data> \
        --data_ids all

We provide example test scripts ``run_bioen*.sh`` in
``./test/generic/``, ``./test/deer/``, and ``./test/scattering/`` to run
BioEn with the three mentioned types of data.

Default settings
~~~~~~~~~~~~~~~~

The default setting for reweighting is log-weights for the procedure and
bfgs2 for the optimization algorithm.

Output
~~~~~~

Three BioEn output files are generated by default, for which you can
choose the file names or leave it with the default naming.

(1) The most useful BioEn output file is in pickle (pkl) format. Choose
    the name of this file with the option ``--output_pkl``. The default
    file name is **bioen\_result.pkl**. This pkl file contains all
    relevant information from the weight optimization including
    experimental data, ensemble averaged data, (reference, initial, and
    optimized) weights, consistency of simulated data with
    experimental data (chi-squared), relative entropy, etc. For a
    complete analysis of your BioEn calculations, this file is
    essential.
(2) The second file contains a list of weights in text file format. The
    name can be choosen with ``--output_weights``. The default name is
    **bioen\_result\_weights.dat**. But careful, it generates this file
    only for the smallest confidence value theta.
(3) The third files contains for each ensemble member the corresponding
    weight. This file is similar to the second file, however, it
    includes also the IDs of each ensemble member and is as such in a
    tabular form. The name of the file can be chosen by
    ``--output_models_weights`` with the default file name
    **bioen\_result\_models\_weights.dat**. Also here, this file is
    generated from the smallest confidence value theta.

Misc information
~~~~~~~~~~~~~~~~

We recommend to have a close look at the files in the folders
``./test/generic/``, ``./test/deer/``, and ``./test/scatter/``. These
files can be used to understand and transfer the own scientific
questions to BioEn. Lines including ``#`` are in general ignored.

For further options and more information, type:

::

    bioen --help

FAQs
----

Q: All my optimization yield "fmin\_final = 0.0". What is going on?

A: This could indicate that the path to fast libraries was not properly
set before installing the package.


.. index::
   single: autoconf, using with GSL

.. _chap_autoconf-macros:

***************
Autoconf Macros
***************

.. include:: include.rst

For applications using :code:`autoconf` the standard macro
:code:`AC_CHECK_LIB` can be used to link with GSL automatically
from a :code:`configure` script.  The library itself depends on the
presence of a |cblas| and math library as well, so these must also be
located before linking with the main :code:`libgsl` file.  The following
commands should be placed in the :file:`configure.ac` file to perform
these tests::

  AC_CHECK_LIB([m],[cos])
  AC_CHECK_LIB([gslcblas],[cblas_dgemm])
  AC_CHECK_LIB([gsl],[gsl_blas_dgemm])

It is important to check for :code:`libm` and :code:`libgslcblas` before
:code:`libgsl`, otherwise the tests will fail.  Assuming the libraries
are found the output during the configure stage looks like this::

  checking for cos in -lm... yes
  checking for cblas_dgemm in -lgslcblas... yes
  checking for gsl_blas_dgemm in -lgsl... yes

If the library is found then the tests will define the macros
:code:`HAVE_LIBGSL`, :code:`HAVE_LIBGSLCBLAS`, :code:`HAVE_LIBM` and add
the options :code:`-lgsl -lgslcblas -lm` to the variable :code:`LIBS`.

The tests above will find any version of the library.  They are suitable
for general use, where the versions of the functions are not important.
An alternative macro is available in the file :file:`gsl.m4` to test for
a specific version of the library.  To use this macro simply add the
following line to your :file:`configure.in` file instead of the tests
above::

  AX_PATH_GSL(GSL_VERSION,
             [action-if-found],
             [action-if-not-found])

The argument :macro:`GSL_VERSION` should be the two or three digit
:code:`major.minor` or :code:`major.minor.micro` version number of the release
you require. A suitable choice for :code:`action-if-not-found` is::

  AC_MSG_ERROR(could not find required version of GSL)

Then you can add the variables :macro:`GSL_LIBS` and :macro:`GSL_CFLAGS` to
your Makefile.am files to obtain the correct compiler flags.
:macro:`GSL_LIBS` is equal to the output of the :code:`gsl-config --libs`
command and :macro:`GSL_CFLAGS` is equal to :code:`gsl-config --cflags`
command. For example::

  libfoo_la_LDFLAGS = -lfoo $(GSL_LIBS) -lgslcblas

Note that the macro :macro:`AX_PATH_GSL` needs to use the C compiler so it
should appear in the :file:`configure.in` file before the macro
:macro:`AC_LANG_CPLUSPLUS` for programs that use C++.

To test for :code:`inline` the following test should be placed in your
:file:`configure.in` file::

  AC_C_INLINE

  if test "$ac_cv_c_inline" != no ; then
    AC_DEFINE(HAVE_INLINE,1)
    AC_SUBST(HAVE_INLINE)
  fi

and the macro will then be defined in the compilation flags or by
including the file :file:`config.h` before any library headers.  

The following autoconf test will check for :code:`extern inline`::

  dnl Check for "extern inline", using a modified version
  dnl of the test for AC_C_INLINE from acspecific.mt
  dnl
  AC_CACHE_CHECK([for extern inline], ac_cv_c_extern_inline,
  [ac_cv_c_extern_inline=no
  AC_TRY_COMPILE([extern $ac_cv_c_inline double foo(double x);
  extern $ac_cv_c_inline double foo(double x) { return x+1.0; };
  double foo (double x) { return x + 1.0; };], 
  [  foo(1.0)  ],
  [ac_cv_c_extern_inline="yes"])
  ])

  if test "$ac_cv_c_extern_inline" != no ; then
    AC_DEFINE(HAVE_INLINE,1)
    AC_SUBST(HAVE_INLINE)
  fi

The substitution of portability functions can be made automatically if
you use :code:`autoconf`. For example, to test whether the BSD function
:func:`hypot` is available you can include the following line in the
configure file :file:`configure.in` for your application::

  AC_CHECK_FUNCS(hypot)

and place the following macro definitions in the file
:file:`config.h.in`::

  /* Substitute gsl_hypot for missing system hypot */

  #ifndef HAVE_HYPOT
  #define hypot gsl_hypot
  #endif

The application source files can then use the include command
:code:`#include <config.h>` to substitute :func:`gsl_hypot` for each
occurrence of :func:`hypot` when :func:`hypot` is not available.
.. index::
   single: fitting
   single: least squares fit
   single: regression, least squares
   single: weighted linear fits
   single: unweighted linear fits

****************************
Linear Least-Squares Fitting
****************************

This chapter describes routines for performing least squares fits to
experimental data using linear combinations of functions.  The data
may be weighted or unweighted, i.e. with known or unknown errors.  For
weighted data the functions compute the best fit parameters and their
associated covariance matrix.  For unweighted data the covariance
matrix is estimated from the scatter of the points, giving a
variance-covariance matrix.

The functions are divided into separate versions for simple one- or
two-parameter regression and multiple-parameter fits.

.. _sec_lls-overview:

Overview
========

Least-squares fits are found by minimizing :math:`\chi^2`
(chi-squared), the weighted sum of squared residuals over :math:`n`
experimental datapoints :math:`(x_i, y_i)` for the model :math:`Y(c,x)`,

.. math:: \chi^2 = \sum_i w_i (y_i - Y(c, x_i))^2

The :math:`p` parameters of the model are :math:`c = \{c_0, c_1, \dots\}`.
The weight factors :math:`w_i` are given by :math:`w_i = 1/\sigma_i^2`
where :math:`\sigma_i` is the experimental error on the data-point
:math:`y_i`.  The errors are assumed to be
Gaussian and uncorrelated. 
For unweighted data the chi-squared sum is computed without any weight factors. 

.. index::
   single: covariance matrix, linear fits

The fitting routines return the best-fit parameters :math:`c` and their
:math:`p \times p` covariance matrix.  The covariance matrix measures the
statistical errors on the best-fit parameters resulting from the 
errors on the data, :math:`\sigma_i`, and is defined
as

.. only:: not texinfo

   .. math:: C_{ab} = \langle \delta c_a \delta c_b \rangle

.. only:: texinfo

   ::

      C_{ab} = <\delta c_a \delta c_b>

where :math:`\langle \, \rangle`
denotes an average over the Gaussian error distributions of the underlying datapoints.

The covariance matrix is calculated by error propagation from the data
errors :math:`\sigma_i`.  The change in a fitted parameter :math:`\delta c_a`
caused by a small change in the data :math:`\delta y_i` is given
by

.. only:: not texinfo

   .. math:: \delta c_a = \sum_i {\partial c_a \over \partial y_i} \delta y_i

.. only:: texinfo

   ::

      \delta c_a = \sum_i (dc_a/dy_i) \delta y_i

allowing the covariance matrix to be written in terms of the errors on the data,

.. only:: not texinfo

   .. math::

      C_{ab} =  \sum_{i,j} {\partial c_a \over \partial y_i}
                           {\partial c_b \over \partial y_j} 
                           \langle \delta y_i \delta y_j \rangle

.. only:: texinfo

   ::

      C_{ab} = \sum_{i,j} (dc_a/dy_i) (dc_b/dy_j) <\delta y_i \delta y_j>

For uncorrelated data the fluctuations of the underlying datapoints satisfy

.. only:: not texinfo

   .. math:: \langle \delta y_i \delta y_j \rangle = \sigma_i^2 \delta_{ij}

.. only:: texinfo

   ::

      <\delta y_i \delta y_j> = \sigma_i^2 \delta_{ij}

giving a corresponding parameter covariance matrix of

.. only:: not texinfo

   .. math:: C_{ab} = \sum_{i} {1 \over w_i} {\partial c_a \over \partial y_i} {\partial c_b \over \partial y_i} 

.. only:: texinfo

   ::

      C_{ab} = \sum_i (1/w_i) (dc_a/dy_i) (dc_b/dy_i) 

.. index::
   single: variance-covariance matrix, linear fits

When computing the covariance matrix for unweighted data, i.e. data with unknown errors, 
the weight factors :math:`w_i` in this sum are replaced by the single estimate
:math:`w = 1/\sigma^2`, where :math:`\sigma^2` is the computed variance of the
residuals about the best-fit model, :math:`\sigma^2 = \sum (y_i - Y(c,x_i))^2 / (n-p)`.  
This is referred to as the *variance-covariance matrix*.

The standard deviations of the best-fit parameters are given by the
square root of the corresponding diagonal elements of
the covariance matrix, :math:`\sigma_{c_a} = \sqrt{C_{aa}}`.
The correlation coefficient of the fit parameters :math:`c_a` and :math:`c_b`
is given by :math:`\rho_{ab} = C_{ab} / \sqrt{C_{aa} C_{bb}}`.

.. index:: linear regression

Linear regression
=================

The functions in this section are used to fit simple one or two
parameter linear regression models. The functions are declared in
the header file :file:`gsl_fit.h`.

Linear regression with a constant term
--------------------------------------
The functions described in this section can be used to perform
least-squares fits to a straight line model, :math:`Y(c,x) = c_0 + c_1 x`.

.. index::
   single: covariance matrix, from linear regression

.. function:: int gsl_fit_linear (const double * x, const size_t xstride, const double * y, const size_t ystride, size_t n, double * c0, double * c1, double * cov00, double * cov01, double * cov11, double * sumsq)

   This function computes the best-fit linear regression coefficients
   (:data:`c0`, :data:`c1`) of the model :math:`Y = c_0 + c_1 X` for the dataset
   (:data:`x`, :data:`y`), two vectors of length :data:`n` with strides
   :data:`xstride` and :data:`ystride`.  The errors on :data:`y` are assumed unknown so 
   the variance-covariance matrix for the
   parameters (:data:`c0`, :data:`c1`) is estimated from the scatter of the
   points around the best-fit line and returned via the parameters
   (:data:`cov00`, :data:`cov01`, :data:`cov11`).   
   The sum of squares of the residuals from the best-fit line is returned
   in :data:`sumsq`.  Note: the correlation coefficient of the data can be computed using
   :func:`gsl_stats_correlation`, it does not depend on the fit.

.. function:: int gsl_fit_wlinear (const double * x, const size_t xstride, const double * w, const size_t wstride, const double * y, const size_t ystride, size_t n, double * c0, double * c1, double * cov00, double * cov01, double * cov11, double * chisq)

   This function computes the best-fit linear regression coefficients
   (:data:`c0`, :data:`c1`) of the model :math:`Y = c_0 + c_1 X` for the weighted
   dataset (:data:`x`, :data:`y`), two vectors of length :data:`n` with strides
   :data:`xstride` and :data:`ystride`.  The vector :data:`w`, of length :data:`n`
   and stride :data:`wstride`, specifies the weight of each datapoint. The
   weight is the reciprocal of the variance for each datapoint in :data:`y`.

   The covariance matrix for the parameters (:data:`c0`, :data:`c1`) is
   computed using the weights and returned via the parameters
   (:data:`cov00`, :data:`cov01`, :data:`cov11`).  The weighted sum of squares
   of the residuals from the best-fit line, :math:`\chi^2`, is returned in
   :data:`chisq`.

.. function:: int gsl_fit_linear_est (double x, double c0, double c1, double cov00, double cov01, double cov11, double * y, double * y_err)

   This function uses the best-fit linear regression coefficients
   :data:`c0`, :data:`c1` and their covariance
   :data:`cov00`, :data:`cov01`, :data:`cov11` to compute the fitted function
   :data:`y` and its standard deviation :data:`y_err` for the model :math:`Y = c_0 + c_1 X`
   at the point :data:`x`.

Linear regression without a constant term
-----------------------------------------

The functions described in this section can be used to perform
least-squares fits to a straight line model without a constant term,
:math:`Y = c_1 X`.

.. function:: int gsl_fit_mul (const double * x, const size_t xstride, const double * y, const size_t ystride, size_t n, double * c1, double * cov11, double * sumsq)

   This function computes the best-fit linear regression coefficient
   :data:`c1` of the model :math:`Y = c_1 X` for the datasets (:data:`x`,
   :data:`y`), two vectors of length :data:`n` with strides :data:`xstride` and
   :data:`ystride`.  The errors on :data:`y` are assumed unknown so the 
   variance of the parameter :data:`c1` is estimated from
   the scatter of the points around the best-fit line and returned via the
   parameter :data:`cov11`.  The sum of squares of the residuals from the
   best-fit line is returned in :data:`sumsq`.

.. function:: int gsl_fit_wmul (const double * x, const size_t xstride, const double * w, const size_t wstride, const double * y, const size_t ystride, size_t n, double * c1, double * cov11, double * sumsq)

   This function computes the best-fit linear regression coefficient
   :data:`c1` of the model :math:`Y = c_1 X` for the weighted datasets
   (:data:`x`, :data:`y`), two vectors of length :data:`n` with strides
   :data:`xstride` and :data:`ystride`.  The vector :data:`w`, of length :data:`n`
   and stride :data:`wstride`, specifies the weight of each datapoint. The
   weight is the reciprocal of the variance for each datapoint in :data:`y`.

   The variance of the parameter :data:`c1` is computed using the weights
   and returned via the parameter :data:`cov11`.  The weighted sum of
   squares of the residuals from the best-fit line, :math:`\chi^2`, is
   returned in :data:`chisq`.

.. function:: int gsl_fit_mul_est (double x, double c1, double cov11, double * y, double * y_err)

   This function uses the best-fit linear regression coefficient :data:`c1`
   and its covariance :data:`cov11` to compute the fitted function
   :data:`y` and its standard deviation :data:`y_err` for the model :math:`Y = c_1 X`
   at the point :data:`x`.

.. index::
   single: multi-parameter regression
   single: fits, multi-parameter linear

Multi-parameter regression
==========================

This section describes routines which perform least squares fits
to a linear model by minimizing the cost function

.. math:: \chi^2 = \sum_i w_i (y_i - \sum_j X_{ij} c_j)^2 = || y - Xc ||_W^2

where :math:`y` is a vector of :math:`n` observations, :math:`X` is an
:math:`n`-by-:math:`p` matrix of predictor variables, :math:`c`
is a vector of the :math:`p` unknown best-fit parameters to be estimated,
and :math:`||r||_W^2 = r^T W r`.
The matrix :math:`W = \diag(w_1,w_2,...,w_n)`
defines the weights or uncertainties of the observation vector.

This formulation can be used for fits to any number of functions and/or
variables by preparing the :math:`n`-by-:math:`p` matrix :math:`X`
appropriately.  For example, to fit to a :math:`p`-th order polynomial in
:data:`x`, use the following matrix,

.. math:: X_{ij} = x_i^j

where the index :math:`i` runs over the observations and the index
:math:`j` runs from 0 to :math:`p-1`.

To fit to a set of :math:`p` sinusoidal functions with fixed frequencies
:math:`\omega_1`, :math:`\omega_2`, :math:`\ldots`, :math:`\omega_p`, use,

.. math:: X_{ij} = \sin(\omega_j x_i)

To fit to :math:`p` independent variables :math:`x_1`, :math:`x_2`, :math:`\ldots`,
:math:`x_p`, use,

.. math:: X_{ij} = x_j(i)

where :math:`x_j(i)` is the :math:`i`-th value of the predictor variable
:math:`x_j`.

The solution of the general linear least-squares system requires an
additional working space for intermediate results, such as the singular
value decomposition of the matrix :math:`X`.

These functions are declared in the header file :file:`gsl_multifit.h`.

.. type:: gsl_multifit_linear_workspace

   This workspace contains internal variables for fitting multi-parameter models.

.. function:: gsl_multifit_linear_workspace * gsl_multifit_linear_alloc (const size_t n, const size_t p)

   This function allocates a workspace for fitting a model to a maximum of :data:`n`
   observations using a maximum of :data:`p` parameters. The user may later supply
   a smaller least squares system if desired. The size of the workspace is
   :math:`O(np + p^2)`.

.. function:: void gsl_multifit_linear_free (gsl_multifit_linear_workspace * work)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_multifit_linear_svd (const gsl_matrix * X, gsl_multifit_linear_workspace * work)

   This function performs a singular value decomposition of the
   matrix :data:`X` and stores the SVD factors internally in :data:`work`.

.. function:: int gsl_multifit_linear_bsvd (const gsl_matrix * X, gsl_multifit_linear_workspace * work)

   This function performs a singular value decomposition of the
   matrix :data:`X` and stores the SVD factors internally in :data:`work`.
   The matrix :data:`X` is first balanced by applying column scaling
   factors to improve the accuracy of the singular values.

.. function:: int gsl_multifit_linear (const gsl_matrix * X, const gsl_vector * y, gsl_vector * c, gsl_matrix * cov, double * chisq, gsl_multifit_linear_workspace * work)

   This function computes the best-fit parameters :data:`c` of the model
   :math:`y = X c` for the observations :data:`y` and the matrix of
   predictor variables :data:`X`, using the preallocated workspace provided
   in :data:`work`.  The :math:`p`-by-:math:`p` variance-covariance matrix of the model parameters
   :data:`cov` is set to :math:`\sigma^2 (X^T X)^{-1}`, where :math:`\sigma` is
   the standard deviation of the fit residuals.
   The sum of squares of the residuals from the best-fit,
   :math:`\chi^2`, is returned in :data:`chisq`. If the coefficient of
   determination is desired, it can be computed from the expression
   :math:`R^2 = 1 - \chi^2 / TSS`, where the total sum of squares (TSS) of
   the observations :data:`y` may be computed from :func:`gsl_stats_tss`.

   The best-fit is found by singular value decomposition of the matrix
   :data:`X` using the modified Golub-Reinsch SVD algorithm, with column
   scaling to improve the accuracy of the singular values. Any components
   which have zero singular value (to machine precision) are discarded
   from the fit.

.. function:: int gsl_multifit_linear_tsvd (const gsl_matrix * X, const gsl_vector * y, const double tol, gsl_vector * c, gsl_matrix * cov, double * chisq, size_t * rank, gsl_multifit_linear_workspace * work)

   This function computes the best-fit parameters :data:`c` of the model
   :math:`y = X c` for the observations :data:`y` and the matrix of
   predictor variables :data:`X`, using a truncated SVD expansion.
   Singular values which satisfy :math:`s_i \le tol \times s_0`
   are discarded from the fit, where :math:`s_0` is the largest singular value.
   The :math:`p`-by-:math:`p` variance-covariance matrix of the model parameters
   :data:`cov` is set to :math:`\sigma^2 (X^T X)^{-1}`, where :math:`\sigma` is
   the standard deviation of the fit residuals.
   The sum of squares of the residuals from the best-fit,
   :math:`\chi^2`, is returned in :data:`chisq`. The effective rank
   (number of singular values used in solution) is returned in :data:`rank`.
   If the coefficient of
   determination is desired, it can be computed from the expression
   :math:`R^2 = 1 - \chi^2 / TSS`, where the total sum of squares (TSS) of
   the observations :data:`y` may be computed from :func:`gsl_stats_tss`.

.. function:: int gsl_multifit_wlinear (const gsl_matrix * X, const gsl_vector * w, const gsl_vector * y, gsl_vector * c, gsl_matrix * cov, double * chisq, gsl_multifit_linear_workspace * work)

   This function computes the best-fit parameters :data:`c` of the weighted
   model :math:`y = X c` for the observations :data:`y` with weights :data:`w`
   and the matrix of predictor variables :data:`X`, using the preallocated
   workspace provided in :data:`work`.  The :math:`p`-by-:math:`p` covariance matrix of the model
   parameters :data:`cov` is computed as :math:`(X^T W X)^{-1}`. The weighted
   sum of squares of the residuals from the best-fit, :math:`\chi^2`, is
   returned in :data:`chisq`. If the coefficient of determination is
   desired, it can be computed from the expression :math:`R^2 = 1 - \chi^2 / WTSS`,
   where the weighted total sum of squares (WTSS) of the
   observations :data:`y` may be computed from :func:`gsl_stats_wtss`.

.. function:: int gsl_multifit_wlinear_tsvd (const gsl_matrix * X, const gsl_vector * w, const gsl_vector * y, const double tol, gsl_vector * c, gsl_matrix * cov, double * chisq, size_t * rank, gsl_multifit_linear_workspace * work)

   This function computes the best-fit parameters :data:`c` of the weighted
   model :math:`y = X c` for the observations :data:`y` with weights :data:`w`
   and the matrix of predictor variables :data:`X`, using a truncated SVD expansion.
   Singular values which satisfy :math:`s_i \le tol \times s_0`
   are discarded from the fit, where :math:`s_0` is the largest singular value.
   The :math:`p`-by-:math:`p` covariance matrix of the model
   parameters :data:`cov` is computed as :math:`(X^T W X)^{-1}`. The weighted
   sum of squares of the residuals from the best-fit, :math:`\chi^2`, is
   returned in :data:`chisq`. The effective rank of the system (number of
   singular values used in the solution) is returned in :data:`rank`.
   If the coefficient of determination is
   desired, it can be computed from the expression :math:`R^2 = 1 - \chi^2 / WTSS`,
   where the weighted total sum of squares (WTSS) of the
   observations :data:`y` may be computed from :func:`gsl_stats_wtss`.

.. function:: int gsl_multifit_linear_est (const gsl_vector * x, const gsl_vector * c, const gsl_matrix * cov, double * y, double * y_err)

   This function uses the best-fit multilinear regression coefficients
   :data:`c` and their covariance matrix
   :data:`cov` to compute the fitted function value
   :data:`y` and its standard deviation :data:`y_err` for the model :math:`y = x.c` 
   at the point :data:`x`.

.. function:: int gsl_multifit_linear_residuals (const gsl_matrix * X, const gsl_vector * y, const gsl_vector * c, gsl_vector * r)

   This function computes the vector of residuals :math:`r = y - X c` for
   the observations :data:`y`, coefficients :data:`c` and matrix of predictor
   variables :data:`X`.

.. function:: size_t gsl_multifit_linear_rank (const double tol, const gsl_multifit_linear_workspace * work)

   This function returns the rank of the matrix :math:`X` which must first have its
   singular value decomposition computed. The rank is computed by counting the number
   of singular values :math:`\sigma_j` which satisfy :math:`\sigma_j > tol \times \sigma_0`,
   where :math:`\sigma_0` is the largest singular value.

.. index::
   single: ridge regression
   single: Tikhonov regression
   single: regression, ridge
   single: regression, Tikhonov
   single: least squares, regularized

.. _sec_regularized-regression:

Regularized regression
======================

Ordinary weighted least squares models seek a solution vector :math:`c`
which minimizes the residual

.. math:: \chi^2 = || y - Xc ||_W^2

where :math:`y` is the :math:`n`-by-:math:`1` observation vector,
:math:`X` is the :math:`n`-by-:math:`p` design matrix, :math:`c` is
the :math:`p`-by-:math:`1` solution vector,
:math:`W = \diag(w_1,...,w_n)` is the data weighting matrix,
and :math:`||r||_W^2 = r^T W r`.
In cases where the least squares matrix :math:`X` is ill-conditioned,
small perturbations (ie: noise) in the observation vector could lead to
widely different solution vectors :math:`c`.
One way of dealing with ill-conditioned matrices is to use a "truncated SVD"
in which small singular values, below some given tolerance, are discarded
from the solution. The truncated SVD method is available using the functions
:func:`gsl_multifit_linear_tsvd` and :func:`gsl_multifit_wlinear_tsvd`. Another way
to help solve ill-posed problems is to include a regularization term in the least squares
minimization

.. math:: \chi^2 = || y - Xc ||_W^2 + \lambda^2 || L c ||^2

for a suitably chosen regularization parameter :math:`\lambda` and
matrix :math:`L`. This type of regularization is known as Tikhonov, or ridge,
regression. In some applications, :math:`L` is chosen as the identity matrix, giving
preference to solution vectors :math:`c` with smaller norms.
Including this regularization term leads to the explicit "normal equations" solution

.. only:: not texinfo

   .. math:: c = \left( X^T W X + \lambda^2 L^T L \right)^{-1} X^T W y

.. only:: texinfo

   ::

      c = ( X^T W X + \lambda^2 L^T L )^-1 X^T W y

which reduces to the ordinary least squares solution when :math:`L = 0`.
In practice, it is often advantageous to transform a regularized least
squares system into the form

.. only:: not texinfo

   .. math:: \chi^2 = || \tilde{y} - \tilde{X} \tilde{c} ||^2 + \lambda^2 || \tilde{c} ||^2

.. only:: texinfo

   ::

      \chi^2 = || y~ - X~ c~ ||^2 + \lambda^2 || c~ ||^2

This is known as the Tikhonov "standard form" and has the normal equations solution

.. only:: not texinfo

   .. math:: \tilde{c} = \left( \tilde{X}^T \tilde{X} + \lambda^2 I \right)^{-1} \tilde{X}^T \tilde{y}

.. only:: texinfo

   ::

      \tilde{c} = ( \tilde{X}^T \tilde{X} + \lambda^2 I )^{-1} \tilde{X}^T \tilde{y}

For an :math:`m`-by-:math:`p` matrix :math:`L` which is full rank and has :math:`m >= p` (ie: :math:`L` is
square or has more rows than columns), we can calculate the "thin" QR decomposition of :math:`L`, and
note that :math:`||L c|| = ||R c||` since the :math:`Q` factor will not change the norm. Since
:math:`R` is :math:`p`-by-:math:`p`, we can then use the transformation

.. only:: not texinfo

   .. math::

      \tilde{X} &= W^{1 \over 2} X R^{-1} \\
      \tilde{y} &= W^{1 \over 2} y \\
      \tilde{c} &= R c

.. only:: texinfo

   ::

      X~ = sqrt(W) X R^-1
      y~ = sqrt(W) y
      c~ = R c

to achieve the standard form. For a rectangular matrix :math:`L` with :math:`m < p`,
a more sophisticated approach is needed (see Hansen 1998, chapter 2.3).
In practice, the normal equations solution above is not desirable due to
numerical instabilities, and so the system is solved using the
singular value decomposition of the matrix :math:`\tilde{X}`.
The matrix :math:`L` is often chosen as the identity matrix, or as a first
or second finite difference operator, to ensure a smoothly varying
coefficient vector :math:`c`, or as a diagonal matrix to selectively damp
each model parameter differently. If :math:`L \ne I`, the user must first
convert the least squares problem to standard form using
:func:`gsl_multifit_linear_stdform1` or :func:`gsl_multifit_linear_stdform2`,
solve the system, and then backtransform the solution vector to recover
the solution of the original problem (see
:func:`gsl_multifit_linear_genform1` and :func:`gsl_multifit_linear_genform2`).

In many regularization problems, care must be taken when choosing
the regularization parameter :math:`\lambda`. Since both the
residual norm :math:`||y - X c||` and solution norm :math:`||L c||`
are being minimized, the parameter :math:`\lambda` represents
a tradeoff between minimizing either the residuals or the
solution vector. A common tool for visualizing the comprimise between
the minimization of these two quantities is known as the L-curve.
The L-curve is a log-log plot of the residual norm :math:`||y - X c||`
on the horizontal axis and the solution norm :math:`||L c||` on the
vertical axis. This curve nearly always as an :math:`L` shaped
appearance, with a distinct corner separating the horizontal
and vertical sections of the curve. The regularization parameter
corresponding to this corner is often chosen as the optimal
value. GSL provides routines to calculate the L-curve for all
relevant regularization parameters as well as locating the corner.

Another method of choosing the regularization parameter is known
as Generalized Cross Validation (GCV). This method is based on
the idea that if an arbitrary element :math:`y_i` is left out of the
right hand side, the resulting regularized solution should predict this element
accurately. This leads to choosing the parameter :math:`\lambda`
which minimizes the GCV function

.. only:: not texinfo

   .. math:: G(\lambda) = {||y - X c_{\lambda}||^2 \over \textrm{Tr}(I_n - X X_{\lambda}^I)^2}

.. only:: texinfo

   ::

      G(\lambda) = (||y - X c_{\lambda}||^2) / Tr(I_n - X X^I)^2

where :math:`X_{\lambda}^I` is the matrix which relates the solution :math:`c_{\lambda}`
to the right hand side :math:`y`, ie: :math:`c_{\lambda} = X_{\lambda}^I y`. GSL
provides routines to compute the GCV curve and its minimum.

For most applications, the steps required to solve a regularized least
squares problem are as follows:

#. Construct the least squares system (:math:`X`, :math:`y`, :math:`W`, :math:`L`)

#. Transform the system to standard form (:math:`\tilde{X}`, :math:`\tilde{y}`). This
   step can be skipped if :math:`L = I_p` and :math:`W = I_n`.

#. Calculate the SVD of :math:`\tilde{X}`.

#. Determine an appropriate regularization parameter :math:`\lambda` (using for example
   L-curve or GCV analysis).

#. Solve the standard form system using the chosen :math:`\lambda` and the SVD of :math:`\tilde{X}`.

#. Backtransform the standard form solution :math:`\tilde{c}` to recover the
   original solution vector :math:`c`.

.. function:: int gsl_multifit_linear_stdform1 (const gsl_vector * L, const gsl_matrix * X, const gsl_vector * y, gsl_matrix * Xs, gsl_vector * ys, gsl_multifit_linear_workspace * work)
              int gsl_multifit_linear_wstdform1 (const gsl_vector * L, const gsl_matrix * X, const gsl_vector * w, const gsl_vector * y, gsl_matrix * Xs, gsl_vector * ys, gsl_multifit_linear_workspace * work)

   These functions define a regularization matrix
   :math:`L = \diag(l_0,l_1,...,l_{p-1})`.
   The diagonal matrix element :math:`l_i` is provided by the
   :math:`i`-th element of the input vector :data:`L`.
   The :math:`n`-by-:math:`p` least squares matrix :data:`X` and
   vector :data:`y` of length :math:`n` are then
   converted to standard form as described above and the parameters
   (:math:`\tilde{X}`, :math:`\tilde{y}`) are stored in :data:`Xs` and :data:`ys`
   on output.  :data:`Xs` and :data:`ys` have the same dimensions as
   :data:`X` and :data:`y`. Optional data weights may be supplied in the
   vector :data:`w` of length :math:`n`. In order to apply this transformation,
   :math:`L^{-1}` must exist and so none of the :math:`l_i`
   may be zero. After the standard form system has been solved,
   use :func:`gsl_multifit_linear_genform1` to recover the original solution vector.
   It is allowed to have :data:`X` = :data:`Xs` and :data:`y` = :data:`ys` for an in-place transform.
   In order to perform a weighted regularized fit with :math:`L = I`, the user may
   call :func:`gsl_multifit_linear_applyW` to convert to standard form.

.. function:: int gsl_multifit_linear_L_decomp (gsl_matrix * L, gsl_vector * tau)

   This function factors the :math:`m`-by-:math:`p` regularization matrix
   :data:`L` into a form needed for the later transformation to standard form. :data:`L`
   may have any number of rows :math:`m`. If :math:`m \ge p` the QR decomposition of
   :data:`L` is computed and stored in :data:`L` on output. If :math:`m < p`, the QR decomposition
   of :math:`L^T` is computed and stored in :data:`L` on output. On output,
   the Householder scalars are stored in the vector :data:`tau` of size :math:`MIN(m,p)`.
   These outputs will be used by :func:`gsl_multifit_linear_wstdform2` to complete the
   transformation to standard form.

.. function:: int gsl_multifit_linear_stdform2 (const gsl_matrix * LQR, const gsl_vector * Ltau, const gsl_matrix * X, const gsl_vector * y, gsl_matrix * Xs, gsl_vector * ys, gsl_matrix * M, gsl_multifit_linear_workspace * work)
              int gsl_multifit_linear_wstdform2 (const gsl_matrix * LQR, const gsl_vector * Ltau, const gsl_matrix * X, const gsl_vector * w, const gsl_vector * y, gsl_matrix * Xs, gsl_vector * ys, gsl_matrix * M, gsl_multifit_linear_workspace * work)

   These functions convert the least squares system (:data:`X`, :data:`y`, :data:`W`, :math:`L`) to standard
   form (:math:`\tilde{X}`, :math:`\tilde{y}`) which are stored in :data:`Xs` and :data:`ys`
   respectively. The :math:`m`-by-:math:`p` regularization matrix :data:`L` is specified by the inputs
   :data:`LQR` and :data:`Ltau`, which are outputs from :func:`gsl_multifit_linear_L_decomp`.
   The dimensions of the standard form parameters (:math:`\tilde{X}`, :math:`\tilde{y}`)
   depend on whether :math:`m` is larger or less than :math:`p`. For :math:`m \ge p`,
   :data:`Xs` is :math:`n`-by-:math:`p`, :data:`ys` is :math:`n`-by-1, and :data:`M` is
   not used. For :math:`m < p`, :data:`Xs` is :math:`(n - p + m)`-by-:math:`m`,
   :data:`ys` is :math:`(n - p + m)`-by-1, and :data:`M` is additional :math:`n`-by-:math:`p` workspace,
   which is required to recover the original solution vector after the system has been
   solved (see :func:`gsl_multifit_linear_genform2`). Optional data weights may be supplied in the
   vector :data:`w` of length :math:`n`, where :math:`W = \diag(w)`.

.. function:: int gsl_multifit_linear_solve (const double lambda, const gsl_matrix * Xs, const gsl_vector * ys, gsl_vector * cs, double * rnorm, double * snorm, gsl_multifit_linear_workspace * work)

   This function computes the regularized best-fit parameters :math:`\tilde{c}`
   which minimize the cost function
   :math:`\chi^2 = || \tilde{y} - \tilde{X} \tilde{c} ||^2 + \lambda^2 || \tilde{c} ||^2`
   which is in standard form. The least squares system must therefore be converted
   to standard form prior to calling this function.
   The observation vector :math:`\tilde{y}` is provided in :data:`ys` and the matrix of
   predictor variables :math:`\tilde{X}` in :data:`Xs`. The solution vector :math:`\tilde{c}` is
   returned in :data:`cs`, which has length min(:math:`m,p`). The SVD of :data:`Xs` must be computed prior
   to calling this function, using :func:`gsl_multifit_linear_svd`.
   The regularization parameter :math:`\lambda` is provided in :data:`lambda`.
   The residual norm :math:`|| \tilde{y} - \tilde{X} \tilde{c} || = ||y - X c||_W`
   is returned in :data:`rnorm`.
   The solution norm :math:`|| \tilde{c} || = ||L c||` is returned in
   :data:`snorm`.

.. function:: int gsl_multifit_linear_genform1 (const gsl_vector * L, const gsl_vector * cs, gsl_vector * c, gsl_multifit_linear_workspace * work)

   After a regularized system has been solved with
   :math:`L = \diag(\l_0,\l_1,...,\l_{p-1})`,
   this function backtransforms the standard form solution vector :data:`cs`
   to recover the solution vector of the original problem :data:`c`. The
   diagonal matrix elements :math:`l_i` are provided in
   the vector :data:`L`. It is allowed to have :data:`c` = :data:`cs` for an
   in-place transform.

.. function:: int gsl_multifit_linear_genform2 (const gsl_matrix * LQR, const gsl_vector * Ltau, const gsl_matrix * X, const gsl_vector * y, const gsl_vector * cs, const gsl_matrix * M, gsl_vector * c, gsl_multifit_linear_workspace * work)
              int gsl_multifit_linear_wgenform2 (const gsl_matrix * LQR, const gsl_vector * Ltau, const gsl_matrix * X, const gsl_vector * w, const gsl_vector * y, const gsl_vector * cs, const gsl_matrix * M, gsl_vector * c, gsl_multifit_linear_workspace * work)

   After a regularized system has been solved with a general rectangular matrix :math:`L`,
   specified by (:data:`LQR`, :data:`Ltau`), this function backtransforms the standard form solution :data:`cs`
   to recover the solution vector of the original problem, which is stored in :data:`c`,
   of length :math:`p`. The original least squares matrix and observation vector are provided in
   :data:`X` and :data:`y` respectively. :data:`M` is the matrix computed by
   :func:`gsl_multifit_linear_stdform2`. For weighted fits, the weight vector
   :data:`w` must also be supplied.

.. function:: int gsl_multifit_linear_applyW (const gsl_matrix * X, const gsl_vector * w, const gsl_vector * y, gsl_matrix * WX, gsl_vector * Wy)

   For weighted least squares systems with :math:`L = I`, this function may be used to
   convert the system to standard form by applying the weight matrix :math:`W = \diag(w)`
   to the least squares matrix :data:`X` and observation vector :data:`y`. On output, :data:`WX`
   is equal to :math:`W^{1/2} X` and :data:`Wy` is equal to :math:`W^{1/2} y`. It is allowed
   for :data:`WX` = :data:`X` and :data:`Wy` = :data:`y` for an in-place transform.

.. function:: int gsl_multifit_linear_lcurve (const gsl_vector * y, gsl_vector * reg_param, gsl_vector * rho, gsl_vector * eta, gsl_multifit_linear_workspace * work)

   This function computes the L-curve for a least squares system
   using the right hand side vector :data:`y` and the SVD decomposition
   of the least squares matrix :data:`X`, which must be provided
   to :func:`gsl_multifit_linear_svd` prior to
   calling this function. The output vectors :data:`reg_param`,
   :data:`rho`, and :data:`eta` must all be the same size, and will
   contain the regularization parameters :math:`\lambda_i`, residual norms
   :math:`||y - X c_i||`, and solution norms :math:`|| L c_i ||`
   which compose the L-curve, where :math:`c_i` is the regularized
   solution vector corresponding to :math:`\lambda_i`.
   The user may determine the number of points on the L-curve by
   adjusting the size of these input arrays. The regularization
   parameters :math:`\lambda_i` are estimated from the singular values
   of :data:`X`, and chosen to represent the most relevant portion of
   the L-curve.

.. function:: int gsl_multifit_linear_lcorner (const gsl_vector * rho, const gsl_vector * eta, size_t * idx)

   This function attempts to locate the corner of the L-curve
   :math:`(||y - X c||, ||L c||)` defined by the :data:`rho` and :data:`eta`
   input arrays respectively. The corner is defined as the point of maximum
   curvature of the L-curve in log-log scale. The :data:`rho` and :data:`eta`
   arrays can be outputs of :func:`gsl_multifit_linear_lcurve`. The
   algorithm used simply fits a circle to 3 consecutive points on the L-curve
   and uses the circle's radius to determine the curvature at
   the middle point. Therefore, the input array sizes must be
   :math:`\ge 3`. With more points provided for the L-curve, a better
   estimate of the curvature can be obtained. The array index
   corresponding to maximum curvature (ie: the corner) is returned
   in :data:`idx`. If the input arrays contain colinear points,
   this function could fail and return :macro:`GSL_EINVAL`.

.. function:: int gsl_multifit_linear_lcorner2 (const gsl_vector * reg_param, const gsl_vector * eta, size_t * idx)

   This function attempts to locate the corner of an alternate L-curve
   :math:`(\lambda^2, ||L c||^2)` studied by Rezghi and Hosseini, 2009.
   This alternate L-curve can provide better estimates of the
   regularization parameter for smooth solution vectors. The regularization
   parameters :math:`\lambda` and solution norms :math:`||L c||` are provided
   in the :data:`reg_param` and :data:`eta` input arrays respectively. The
   corner is defined as the point of maximum curvature of this
   alternate L-curve in linear scale. The :data:`reg_param` and :data:`eta`
   arrays can be outputs of :func:`gsl_multifit_linear_lcurve`. The
   algorithm used simply fits a circle to 3 consecutive points on the L-curve
   and uses the circle's radius to determine the curvature at
   the middle point. Therefore, the input array sizes must be
   :math:`\ge 3`. With more points provided for the L-curve, a better
   estimate of the curvature can be obtained. The array index
   corresponding to maximum curvature (ie: the corner) is returned
   in :data:`idx`. If the input arrays contain colinear points,
   this function could fail and return :macro:`GSL_EINVAL`.

.. function:: int gsl_multifit_linear_gcv_init(const gsl_vector * y, gsl_vector * reg_param, gsl_vector * UTy, double * delta0, gsl_multifit_linear_workspace * work)

   This function performs some initialization in preparation for computing
   the GCV curve and its minimum. The right hand side vector is provided
   in :data:`y`. On output, :data:`reg_param` is set to a vector of regularization
   parameters in decreasing order and may be of any size. The vector
   :data:`UTy` of size :math:`p` is set to :math:`U^T y`. The parameter
   :data:`delta0` is needed for subsequent steps of the GCV calculation.

.. function:: int gsl_multifit_linear_gcv_curve(const gsl_vector * reg_param, const gsl_vector * UTy, const double delta0, gsl_vector * G, gsl_multifit_linear_workspace * work)

   This funtion calculates the GCV curve :math:`G(\lambda)` and stores it in
   :data:`G` on output, which must be the same size as :data:`reg_param`. The
   inputs :data:`reg_param`, :data:`UTy` and :data:`delta0` are computed in
   :func:`gsl_multifit_linear_gcv_init`.

.. function:: int gsl_multifit_linear_gcv_min(const gsl_vector * reg_param, const gsl_vector * UTy, const gsl_vector * G, const double delta0, double * lambda, gsl_multifit_linear_workspace * work)

   This function computes the value of the regularization parameter
   which minimizes the GCV curve :math:`G(\lambda)` and stores it in
   :data:`lambda`. The input :data:`G` is calculated by
   :func:`gsl_multifit_linear_gcv_curve` and the inputs
   :data:`reg_param`, :data:`UTy` and :data:`delta0` are computed by
   :func:`gsl_multifit_linear_gcv_init`.

.. function:: double gsl_multifit_linear_gcv_calc(const double lambda, const gsl_vector * UTy, const double delta0, gsl_multifit_linear_workspace * work)

   This function returns the value of the GCV curve :math:`G(\lambda)` corresponding
   to the input :data:`lambda`.

.. function:: int gsl_multifit_linear_gcv(const gsl_vector * y, gsl_vector * reg_param, gsl_vector * G, double * lambda, double * G_lambda, gsl_multifit_linear_workspace * work)

   This function combines the steps :code:`gcv_init`, :code:`gcv_curve`,
   and :code:`gcv_min` defined above into a single function. The input
   :data:`y` is the right hand side vector. On output, :data:`reg_param` and
   :data:`G`, which must be the same size, are set to vectors of
   :math:`\lambda` and :math:`G(\lambda)` values respectively. The
   output :data:`lambda` is set to the optimal value of :math:`\lambda`
   which minimizes the GCV curve. The minimum value of the GCV curve is
   returned in :data:`G_lambda`.

.. function:: int gsl_multifit_linear_Lk (const size_t p, const size_t k, gsl_matrix * L)

   This function computes the discrete approximation to the derivative operator :math:`L_k` of
   order :data:`k` on a regular grid of :data:`p` points and stores it in :data:`L`. The dimensions of :data:`L` are
   :math:`(p-k)`-by-:math:`p`.

.. function:: int gsl_multifit_linear_Lsobolev (const size_t p, const size_t kmax, const gsl_vector * alpha, gsl_matrix * L, gsl_multifit_linear_workspace * work)

   This function computes the regularization matrix :data:`L` corresponding to the
   weighted Sobolov norm
   :math:`||L c||^2 = \sum_k \alpha_k^2 ||L_k c||^2` where :math:`L_k` approximates
   the derivative operator of order :math:`k`. This regularization norm can be useful
   in applications where it is necessary to smooth several derivatives of the solution.
   :data:`p` is the number of model parameters, :data:`kmax` is the highest derivative
   to include in the summation above, and :data:`alpha` is the vector of weights of
   size :data:`kmax` + 1, where :code:`alpha[k]` = :math:`\alpha_k` is the weight
   assigned to the derivative of order :math:`k`.  The output matrix :data:`L` is size
   :data:`p`-by-:data:`p` and upper triangular.

.. function:: double gsl_multifit_linear_rcond (const gsl_multifit_linear_workspace * work)

   This function returns the reciprocal condition number of the least squares matrix :math:`X`,
   defined as the ratio of the smallest and largest singular values,
   rcond = :math:`\sigma_{min}/\sigma_{max}`.
   The routine :func:`gsl_multifit_linear_svd` must first be called to compute the SVD
   of :math:`X`.

.. index::
   single: robust regression
   single: regression, robust
   single: least squares, robust

Robust linear regression
========================

Ordinary least squares (OLS) models are often heavily influenced by the presence of outliers.
Outliers are data points which do not follow the general trend of the other observations,
although there is strictly no precise definition of an outlier. Robust linear regression
refers to regression algorithms which are robust to outliers. The most common type of
robust regression is M-estimation. The general M-estimator minimizes the objective function

.. math:: \sum_i \rho(e_i) = \sum_i \rho (y_i - Y(c, x_i))

where :math:`e_i = y_i - Y(c, x_i)` is the residual of the ith data point, and
:math:`\rho(e_i)` is a function which should have the following properties:

* :math:`\rho(e) \ge 0`
* :math:`\rho(0) = 0`
* :math:`\rho(-e) = \rho(e)`
* :math:`\rho(e_1) > \rho(e_2)` for :math:`|e_1| > |e_2|`

The special case of ordinary least squares is given by :math:`\rho(e_i) = e_i^2`.
Letting :math:`\psi = \rho'` be the derivative of :math:`\rho`, differentiating
the objective function with respect to the coefficients :math:`c`
and setting the partial derivatives to zero produces the system of equations

.. math:: \sum_i \psi(e_i) X_i = 0

where :math:`X_i` is a vector containing row :math:`i` of the design matrix :math:`X`.
Next, we define a weight function :math:`w(e) = \psi(e)/e`, and let
:math:`w_i = w(e_i)`:

.. math:: \sum_i w_i e_i X_i = 0

This system of equations is equivalent to solving a weighted ordinary least squares
problem, minimizing :math:`\chi^2 = \sum_i w_i e_i^2`. The weights however, depend
on the residuals :math:`e_i`, which depend on the coefficients :math:`c`, which depend
on the weights. Therefore, an iterative solution is used, called Iteratively Reweighted
Least Squares (IRLS).

#. Compute initial estimates of the coefficients :math:`c^{(0)}` using ordinary least squares

#. For iteration :math:`k`, form the residuals :math:`e_i^{(k)} = (y_i - X_i c^{(k-1)})/(t \sigma^{(k)} \sqrt{1 - h_i})`,
   where :math:`t` is a tuning constant depending on the choice of :math:`\psi`, and :math:`h_i` are the
   statistical leverages (diagonal elements of the matrix :math:`X (X^T X)^{-1} X^T`). Including :math:`t`
   and :math:`h_i` in the residual calculation has been shown to improve the convergence of the method.
   The residual standard deviation is approximated as :math:`\sigma^{(k)} = MAD / 0.6745`, where MAD is the
   Median-Absolute-Deviation of the :math:`n-p` largest residuals from the previous iteration.

#. Compute new weights :math:`w_i^{(k)} = \psi(e_i^{(k)})/e_i^{(k)}`.

#. Compute new coefficients :math:`c^{(k)}` by solving the weighted least squares problem with
   weights :math:`w_i^{(k)}`.

#. Steps 2 through 4 are iterated until the coefficients converge or until some maximum iteration
   limit is reached. Coefficients are tested for convergence using the critera:

  .. only:: not texinfo

     .. math:: |c_i^{(k)} - c_i^{(k-1)}| \le \epsilon \times \hbox{max}(|c_i^{(k)}|, |c_i^{(k-1)}|)

  .. only:: texinfo

     ::

        |c_i^(k) - c_i^(k-1)| <= \epsilon * max(|c_i^(k)|, |c_i^(k-1)|)

  for all :math:`0 \le i < p` where :math:`\epsilon` is a small tolerance factor.

The key to this method lies in selecting the function :math:`\psi(e_i)` to assign
smaller weights to large residuals, and larger weights to smaller residuals. As
the iteration proceeds, outliers are assigned smaller and smaller weights, eventually
having very little or no effect on the fitted model.

.. type:: gsl_multifit_robust_workspace

   This workspace is used for robust least squares fitting.

.. function:: gsl_multifit_robust_workspace * gsl_multifit_robust_alloc (const gsl_multifit_robust_type * T, const size_t n, const size_t p)

   This function allocates a workspace for fitting a model to :data:`n`
   observations using :data:`p` parameters. The size of the workspace
   is :math:`O(np + p^2)`. The type :data:`T` specifies the
   function :math:`\psi` and can be selected from the following choices.

   .. type:: gsl_multifit_robust_type

      .. var:: gsl_multifit_robust_default

         This specifies the :data:`gsl_multifit_robust_bisquare` type (see below) and is a good
         general purpose choice for robust regression.

      .. var:: gsl_multifit_robust_bisquare

         This is Tukey's biweight (bisquare) function and is a good general purpose choice for
         robust regression. The weight function is given by

         .. only:: not texinfo

            .. math::

               w(e) =
               \left\{
                 \begin{array}{cc}
                   (1 - e^2)^2, & |e| \le 1 \\
                    0, & |e| > 1
                 \end{array}
               \right.

         .. only:: texinfo

            ::

               w(e) = { (1 - e^2)^2, |e| <= 1
                      {     0,       |e| > 1

         and the default tuning constant is :math:`t = 4.685`.

      .. var:: gsl_multifit_robust_cauchy

         This is Cauchy's function, also known as the Lorentzian function.
         This function does not guarantee a unique solution,
         meaning different choices of the coefficient vector :data:`c`
         could minimize the objective function. Therefore this option should
         be used with care. The weight function is given by

         .. only:: not texinfo

            .. math:: w(e) = {1 \over 1 + e^2}

         .. only:: texinfo

            ::

               w(e) = 1 / (1 + e^2)

         and the default tuning constant is :math:`t = 2.385`.

      .. var:: gsl_multifit_robust_fair

         This is the fair :math:`\rho` function, which guarantees a unique solution and
         has continuous derivatives to three orders. The weight function is given by

         .. only:: not texinfo

            .. math:: w(e) = {1 \over 1 + |e|}

         .. only:: texinfo

            ::

               w(e) = 1 / (1 + |e|)

         and the default tuning constant is :math:`t = 1.400`.

      .. var:: gsl_multifit_robust_huber

         This specifies Huber's :math:`\rho` function, which is a parabola in the vicinity of zero and
         increases linearly for a given threshold :math:`|e| > t`. This function is also considered
         an excellent general purpose robust estimator, however, occasional difficulties can
         be encountered due to the discontinuous first derivative of the :math:`\psi` function.
         The weight function is given by

         .. only:: not texinfo

            .. math::

               w(e) =
               \left\{
                 \begin{array}{cc}
                   1, & |e| \le 1 \\
                   {1 \over |e|}, & |e| > 1
                 \end{array}
               \right.

         .. only:: texinfo

            ::

               w(e) = 1/max(1,|e|)

         and the default tuning constant is :math:`t = 1.345`.

      .. var:: gsl_multifit_robust_ols

         This specifies the ordinary least squares solution, which can be useful for quickly
         checking the difference between the various robust and OLS solutions. The
         weight function is given by

         .. math:: w(e) = 1

         and the default tuning constant is :math:`t = 1`.

      .. var:: gsl_multifit_robust_welsch

         This specifies the Welsch function which can perform well in cases where the
         residuals have an exponential distribution. The weight function is given by

         .. math:: w(e) = \exp{(-e^2)}

         and the default tuning constant is :math:`t = 2.985`.

.. function:: void gsl_multifit_robust_free (gsl_multifit_robust_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: const char * gsl_multifit_robust_name (const gsl_multifit_robust_workspace * w)

   This function returns the name of the robust type :data:`T` specified to
   :func:`gsl_multifit_robust_alloc`.

.. function:: int gsl_multifit_robust_tune (const double tune, gsl_multifit_robust_workspace * w)

   This function sets the tuning constant :math:`t` used to adjust the residuals at each
   iteration to :data:`tune`.  Decreasing the tuning constant increases the downweight
   assigned to large residuals, while increasing the tuning constant decreases the
   downweight assigned to large residuals.

.. function:: int gsl_multifit_robust_maxiter (const size_t maxiter, gsl_multifit_robust_workspace * w)

   This function sets the maximum number of iterations in the iteratively
   reweighted least squares algorithm to :data:`maxiter`. By default,
   this value is set to 100 by :func:`gsl_multifit_robust_alloc`.

.. function:: int gsl_multifit_robust_weights (const gsl_vector * r, gsl_vector * wts, gsl_multifit_robust_workspace * w)

   This function assigns weights to the vector :data:`wts` using the residual vector
   :data:`r` and previously specified weighting function. The output weights are given
   by :math:`wts_i = w(r_i / (t \sigma))`, where the weighting functions :math:`w` are
   detailed in :func:`gsl_multifit_robust_alloc`. :math:`\sigma` is an estimate of the
   residual standard deviation based on the Median-Absolute-Deviation and :math:`t`
   is the tuning constant. This function is useful if the user wishes to implement
   their own robust regression rather than using
   the supplied :func:`gsl_multifit_robust` routine below.

.. function:: int gsl_multifit_robust (const gsl_matrix * X, const gsl_vector * y, gsl_vector * c, gsl_matrix * cov, gsl_multifit_robust_workspace * w)

   This function computes the best-fit parameters :data:`c` of the model
   :math:`y = X c` for the observations :data:`y` and the matrix of
   predictor variables :data:`X`, attemping to reduce the influence
   of outliers using the algorithm outlined above.
   The :math:`p`-by-:math:`p` variance-covariance matrix of the model parameters
   :data:`cov` is estimated as :math:`\sigma^2 (X^T X)^{-1}`, where :math:`\sigma` is
   an approximation of the residual standard deviation using the theory of robust
   regression. Special care must be taken when estimating :math:`\sigma` and
   other statistics such as :math:`R^2`, and so these
   are computed internally and are available by calling the function
   :func:`gsl_multifit_robust_statistics`.

   If the coefficients do not converge within the maximum iteration
   limit, the function returns :macro:`GSL_EMAXITER`. In this case,
   the current estimates of the coefficients and covariance matrix
   are returned in :data:`c` and :data:`cov` and the internal fit statistics
   are computed with these estimates.

.. function:: int gsl_multifit_robust_est (const gsl_vector * x, const gsl_vector * c, const gsl_matrix * cov, double * y, double * y_err)

   This function uses the best-fit robust regression coefficients
   :data:`c` and their covariance matrix
   :data:`cov` to compute the fitted function value
   :data:`y` and its standard deviation :data:`y_err` for the model :math:`y = x \cdot c` 
   at the point :data:`x`.

.. function:: int gsl_multifit_robust_residuals (const gsl_matrix * X, const gsl_vector * y, const gsl_vector * c, gsl_vector * r, gsl_multifit_robust_workspace * w)

   This function computes the vector of studentized residuals
   :math:`r_i = {y_i - (X c)_i \over \sigma \sqrt{1 - h_i}}` for
   the observations :data:`y`, coefficients :data:`c` and matrix of predictor
   variables :data:`X`. The routine :func:`gsl_multifit_robust` must
   first be called to compute the statisical leverages :math:`h_i` of
   the matrix :data:`X` and residual standard deviation estimate :math:`\sigma`.

.. function:: gsl_multifit_robust_stats gsl_multifit_robust_statistics (const gsl_multifit_robust_workspace * w)

   This function returns a structure containing relevant statistics from a robust regression.
   The function :func:`gsl_multifit_robust` must be called first to perform the regression and
   calculate these statistics.  The returned :type:`gsl_multifit_robust_stats` structure
   contains the following fields.

   .. type:: gsl_multifit_robust_stats

      :code:`double sigma_ols`
      
         This contains the standard deviation of the residuals as computed from ordinary
         least squares (OLS).

      :code:`double sigma_mad`
      
         This contains an estimate of the standard deviation of the final residuals using
         the Median-Absolute-Deviation statistic

      :code:`double sigma_rob`
      
         This contains an estimate of the standard deviation of the final residuals
         from the theory of robust regression (see Street et al, 1988).

      :code:`double sigma`
      
         This contains an estimate of the standard deviation of the final residuals
         by attemping to reconcile :code:`sigma_rob` and :code:`sigma_ols`
         in a reasonable way.

      :code:`double Rsq`
      
         This contains the :math:`R^2` coefficient of determination statistic using
         the estimate :code:`sigma`.

      :code:`double adj_Rsq`
      
         This contains the adjusted :math:`R^2` coefficient of determination statistic
         using the estimate :code:`sigma`.

      :code:`double rmse`
      
         This contains the root mean squared error of the final residuals

      :code:`double sse`
      
         This contains the residual sum of squares taking into account the robust
         covariance matrix.

      :code:`size_t dof`
      
         This contains the number of degrees of freedom :math:`n - p`

      :code:`size_t numit`
      
         Upon successful convergence, this contains the number of iterations performed

      :code:`gsl_vector * weights`
      
         This contains the final weight vector of length :data:`n`

      :code:`gsl_vector * r`
      
         This contains the final residual vector of length :data:`n`, :math:`r = y - X c`

.. index::
   single: large dense linear least squares
   single: linear least squares, large

Large dense linear systems
==========================

This module is concerned with solving large dense least squares systems
:math:`X c = y` where the :math:`n`-by-:math:`p` matrix
:math:`X` has :math:`n >> p` (ie: many more rows than columns).
This type of matrix is called a "tall skinny" matrix, and for
some applications, it may not be possible to fit the
entire matrix in memory at once to use the standard SVD approach.
Therefore, the algorithms in this module are designed to allow
the user to construct smaller blocks of the matrix :math:`X` and
accumulate those blocks into the larger system one at a time. The
algorithms in this module never need to store the entire matrix
:math:`X` in memory. The large linear least squares routines
support data weights and Tikhonov regularization, and are
designed to minimize the residual

.. math:: \chi^2 = || y - Xc ||_W^2 + \lambda^2 || L c ||^2

where :math:`y` is the :math:`n`-by-:math:`1` observation vector,
:math:`X` is the :math:`n`-by-:math:`p` design matrix, :math:`c` is
the :math:`p`-by-:math:`1` solution vector,
:math:`W = \diag(w_1,...,w_n)` is the data weighting matrix,
:math:`L` is an :math:`m`-by-:math:`p` regularization matrix,
:math:`\lambda` is a regularization parameter,
and :math:`||r||_W^2 = r^T W r`. In the discussion which follows,
we will assume that the system has been converted into Tikhonov
standard form,

.. only:: not texinfo

   .. math:: \chi^2 = || \tilde{y} - \tilde{X} \tilde{c} ||^2 + \lambda^2 || \tilde{c} ||^2

.. only:: texinfo

   ::

      \chi^2 = || y~ - X~ c~ ||^2 + \lambda^2 || c~ ||^2

and we will drop the tilde characters from the various parameters.
For a discussion of the transformation to standard form,
see :ref:`sec_regularized-regression`.

The basic idea is to partition the matrix :math:`X` and observation
vector :math:`y` as

.. only:: not texinfo

   .. math::

      \left(
        \begin{array}{c}
          X_1 \\
          X_2 \\
          X_3 \\
          \vdots \\
          X_k
        \end{array}
      \right)
      c =
      \left(
        \begin{array}{c}
          y_1 \\
          y_2 \\
          y_3 \\
          \vdots \\
          y_k
        \end{array}
      \right)

.. only:: texinfo

   ::

      [ X_1 ] c = [ y_1 ]
      [ X_2 ]     [ y_2 ]
      [ X_3 ]     [ y_3 ]
      [ ... ]     [ ... ]
      [ X_k ]     [ y_k ]

into :math:`k` blocks, where each block (:math:`X_i,y_i`) may have
any number of rows, but each :math:`X_i` has :math:`p` columns.
The sections below describe the methods available for solving
this partitioned system. The functions are declared in
the header file :file:`gsl_multilarge.h`.

.. index::
   single: large linear least squares, normal equations

Normal Equations Approach
-------------------------

The normal equations approach to the large linear least squares
problem described above is popular due to its speed and simplicity.
Since the normal equations solution to the problem is given by

.. only:: not texinfo

   .. math:: c = \left( X^T X + \lambda^2 I \right)^{-1} X^T y

.. only:: texinfo

   ::

      c = ( X^T X + \lambda^2 I )^-1 X^T y

only the :math:`p`-by-:math:`p` matrix :math:`X^T X` and
:math:`p`-by-1 vector :math:`X^T y` need to be stored. Using
the partition scheme described above, these are given by

.. only:: not texinfo

   .. math::

      X^T X &= \sum_i X_i^T X_i \\
      X^T y &= \sum_i X_i^T y_i

.. only:: texinfo

   ::

      X^T X = \sum_i X_i^T X_i
      X^T y = \sum_i X_i^T y_i

Since the matrix :math:`X^T X` is symmetric, only half of it
needs to be calculated. Once all of the blocks :math:`(X_i,y_i)`
have been accumulated into the final :math:`X^T X` and :math:`X^T y`,
the system can be solved with a Cholesky factorization of the
:math:`X^T X` matrix. The :math:`X^T X` matrix is first transformed via
a diagonal scaling transformation to attempt to reduce its condition
number as much as possible to recover a more accurate solution vector.
The normal equations approach is the fastest method for solving the
large least squares problem, and is accurate for well-conditioned
matrices :math:`X`. However, for ill-conditioned matrices, as is often
the case for large systems, this method can suffer from numerical
instabilities (see Trefethen and Bau, 1997).  The number of operations
for this method is :math:`O(np^2 + {1 \over 3}p^3)`.

.. index::
   single: large linear least squares, TSQR

Tall Skinny QR (TSQR) Approach
------------------------------

An algorithm which has better numerical stability for ill-conditioned
problems is known as the Tall Skinny QR (TSQR) method. This method
is based on computing the thin QR decomposition of the least squares
matrix :math:`X = Q R`, where :math:`Q` is an :math:`n`-by-:math:`p` matrix
with orthogonal columns, and :math:`R` is a :math:`p`-by-:math:`p`
upper triangular matrix. Once these factors are calculated, the
residual becomes

.. math:: \chi^2 = || Q^T y - R c ||^2 + \lambda^2 || c ||^2

which can be written as the matrix equation

.. only:: not texinfo

   .. math::

      \left(
        \begin{array}{c}
          R \\
          \lambda I
        \end{array}
      \right) c =
      \left(
        \begin{array}{c}
          Q^T y \\
          0
        \end{array}
      \right)

.. only:: texinfo

   ::

      [ R ; \lambda I ] c = [ Q^T b ; 0 ]

The matrix on the left hand side is now a much
smaller :math:`2p`-by-:math:`p` matrix which can
be solved with a standard SVD approach. The
:math:`Q` matrix is just as large as the original
matrix :math:`X`, however it does not need to be
explicitly constructed. The TSQR algorithm
computes only the :math:`p`-by-:math:`p` matrix
:math:`R` and the :math:`p`-by-1 vector :math:`Q^T y`,
and updates these quantities as new blocks
are added to the system. Each time a new block of rows
(:math:`X_i,y_i`) is added, the algorithm performs a QR decomposition
of the matrix

.. only:: not texinfo

   .. math::

      \left(
        \begin{array}{c}
          R_{i-1} \\
          X_i
        \end{array}
      \right)

.. only:: texinfo

   ::

      [ R_(i-1) ; X_i ]

where :math:`R_{i-1}` is the upper triangular
:math:`R` factor for the matrix

.. only:: not texinfo

   .. math::

      \left(
        \begin{array}{c}
          X_1 \\
          \vdots \\
          X_{i-1}
        \end{array}
      \right)

.. only:: texinfo

   ::

      [ X_1 ; ... ; X_(i-1) ]

This QR decomposition is done efficiently taking into account
the sparse structure of :math:`R_{i-1}`. See Demmel et al, 2008 for
more details on how this is accomplished. The number
of operations for this method is :math:`O(2np^2 - {2 \over 3}p^3)`.

.. index::
   single: large linear least squares, steps

Large Dense Linear Systems Solution Steps
-----------------------------------------

The typical steps required to solve large regularized linear least
squares problems are as follows:

#. Choose the regularization matrix :math:`L`.

#. Construct a block of rows of the least squares matrix, right
   hand side vector, and weight vector (:math:`X_i`, :math:`y_i`, :math:`w_i`).

#. Transform the block to standard form (:math:`\tilde{X_i}`, :math:`\tilde{y_i}`). This
   step can be skipped if :math:`L = I` and :math:`W = I`.

#. Accumulate the standard form block (:math:`\tilde{X_i}`, :math:`\tilde{y_i}`) into
   the system.

#. Repeat steps 2-4 until the entire matrix and right hand side vector have
   been accumulated.

#. Determine an appropriate regularization parameter :math:`\lambda` (using for example
   L-curve analysis).

#. Solve the standard form system using the chosen :math:`\lambda`.

#. Backtransform the standard form solution :math:`\tilde{c}` to recover the
   original solution vector :math:`c`.

.. index::
   single: large linear least squares, routines

Large Dense Linear Least Squares Routines
-----------------------------------------

.. type:: gsl_multilarge_linear_workspace

   This workspace contains parameters for solving large linear least squares problems.

.. function:: gsl_multilarge_linear_workspace * gsl_multilarge_linear_alloc (const gsl_multilarge_linear_type * T, const size_t p)

   This function allocates a workspace for solving large linear least squares
   systems. The least squares matrix :math:`X` has :data:`p` columns,
   but may have any number of rows.
   
   .. type:: gsl_multilarge_linear_type

      The parameter :data:`T` specifies
      the method to be used for solving the large least squares system
      and may be selected from the following choices

      .. var:: gsl_multilarge_linear_normal

         This specifies the normal equations approach for
         solving the least squares system. This method is suitable
         in cases where performance is critical and it is known that the
         least squares matrix :math:`X` is well conditioned. The size
         of this workspace is :math:`O(p^2)`.

      .. var:: gsl_multilarge_linear_tsqr

         This specifies the sequential Tall Skinny QR (TSQR) approach for
         solving the least squares system. This method is a good
         general purpose choice for large systems, but requires about
         twice as many operations as the normal equations method for
         :math:`n >> p`. The size of this workspace is :math:`O(p^2)`.

.. function:: void gsl_multilarge_linear_free (gsl_multilarge_linear_workspace * w)

   This function frees the memory associated with the
   workspace :data:`w`.

.. function:: const char * gsl_multilarge_linear_name (gsl_multilarge_linear_workspace * w)

   This function returns a string pointer to the name
   of the multilarge solver.

.. function:: int gsl_multilarge_linear_reset (gsl_multilarge_linear_workspace * w)

   This function resets the workspace :data:`w` so
   it can begin to accumulate a new least squares
   system.

.. function:: int gsl_multilarge_linear_stdform1 (const gsl_vector * L, const gsl_matrix * X, const gsl_vector * y, gsl_matrix * Xs, gsl_vector * ys, gsl_multilarge_linear_workspace * work)
              int gsl_multilarge_linear_wstdform1 (const gsl_vector * L, const gsl_matrix * X, const gsl_vector * w, const gsl_vector * y, gsl_matrix * Xs, gsl_vector * ys, gsl_multilarge_linear_workspace * work)

   These functions define a regularization matrix
   :math:`L = \diag(l_0,l_1,...,l_{p-1})`.
   The diagonal matrix element :math:`l_i` is provided by the
   :math:`i`-th element of the input vector :data:`L`.
   The block (:data:`X`, :data:`y`) is converted to standard form and
   the parameters (:math:`\tilde{X}`, :math:`\tilde{y}`) are stored in :data:`Xs`
   and :data:`ys` on output.  :data:`Xs` and :data:`ys` have the same dimensions as
   :data:`X` and :data:`y`. Optional data weights may be supplied in the
   vector :data:`w`. In order to apply this transformation,
   :math:`L^{-1}` must exist and so none of the :math:`l_i`
   may be zero. After the standard form system has been solved,
   use :func:`gsl_multilarge_linear_genform1` to recover the original solution vector.
   It is allowed to have :data:`X` = :data:`Xs` and :data:`y` = :data:`ys` for an
   in-place transform.

.. function:: int gsl_multilarge_linear_L_decomp (gsl_matrix * L, gsl_vector * tau)

   This function calculates the QR decomposition of the :math:`m`-by-:math:`p`
   regularization matrix :data:`L`. :data:`L` must have :math:`m \ge p`.  On output,
   the Householder scalars are stored in the vector :data:`tau` of size :math:`p`.
   These outputs will be used by :func:`gsl_multilarge_linear_wstdform2` to complete the
   transformation to standard form.

.. function:: int gsl_multilarge_linear_stdform2 (const gsl_matrix * LQR, const gsl_vector * Ltau, const gsl_matrix * X, const gsl_vector * y, gsl_matrix * Xs, gsl_vector * ys, gsl_multilarge_linear_workspace * work)
              int gsl_multilarge_linear_wstdform2 (const gsl_matrix * LQR, const gsl_vector * Ltau, const gsl_matrix * X, const gsl_vector * w, const gsl_vector * y, gsl_matrix * Xs, gsl_vector * ys, gsl_multilarge_linear_workspace * work)

   These functions convert a block of rows (:data:`X`, :data:`y`, :data:`w`) to standard
   form (:math:`\tilde{X}`, :math:`\tilde{y}`) which are stored in :data:`Xs` and :data:`ys`
   respectively. :data:`X`, :data:`y`, and :data:`w` must all have the same number of rows.
   The :math:`m`-by-:math:`p` regularization matrix :data:`L` is specified by the inputs
   :data:`LQR` and :data:`Ltau`, which are outputs from :func:`gsl_multilarge_linear_L_decomp`.
   :data:`Xs` and :data:`ys` have the same dimensions as :data:`X` and :data:`y`. After the
   standard form system has been solved, use :func:`gsl_multilarge_linear_genform2` to
   recover the original solution vector. Optional data weights may be supplied in the
   vector :data:`w`, where :math:`W = \diag(w)`.

.. function:: int gsl_multilarge_linear_accumulate (gsl_matrix * X, gsl_vector * y, gsl_multilarge_linear_workspace * w)

   This function accumulates the standard form block (:math:`X,y`) into the
   current least squares system. :data:`X` and :data:`y` have the same number
   of rows, which can be arbitrary.  :data:`X` must have :math:`p` columns.
   For the TSQR method, :data:`X` and :data:`y` are destroyed on output.
   For the normal equations method, they are both unchanged.

.. function:: int gsl_multilarge_linear_solve (const double lambda, gsl_vector * c, double * rnorm, double * snorm, gsl_multilarge_linear_workspace * w)

   After all blocks (:math:`X_i,y_i`) have been accumulated into
   the large least squares system, this function will compute
   the solution vector which is stored in :data:`c` on output.
   The regularization parameter :math:`\lambda` is provided in
   :data:`lambda`. On output, :data:`rnorm` contains the residual norm
   :math:`||y - X c||_W` and :data:`snorm` contains the solution
   norm :math:`||L c||`.

.. function:: int gsl_multilarge_linear_genform1 (const gsl_vector * L, const gsl_vector * cs, gsl_vector * c, gsl_multilarge_linear_workspace * work)

   After a regularized system has been solved with
   :math:`L = \diag(\l_0,\l_1,...,\l_{p-1})`,
   this function backtransforms the standard form solution vector :data:`cs`
   to recover the solution vector of the original problem :data:`c`. The
   diagonal matrix elements :math:`l_i` are provided in
   the vector :data:`L`. It is allowed to have :data:`c` = :data:`cs` for an
   in-place transform.

.. function:: int gsl_multilarge_linear_genform2 (const gsl_matrix * LQR, const gsl_vector * Ltau, const gsl_vector * cs, gsl_vector * c, gsl_multilarge_linear_workspace * work)

   After a regularized system has been solved with a regularization matrix :math:`L`,
   specified by (:data:`LQR`, :data:`Ltau`), this function backtransforms the standard form
   solution :data:`cs`
   to recover the solution vector of the original problem, which is stored in :data:`c`,
   of length :math:`p`.

.. function:: int gsl_multilarge_linear_lcurve (gsl_vector * reg_param, gsl_vector * rho, gsl_vector * eta, gsl_multilarge_linear_workspace * work)

   This function computes the L-curve for a large least squares system
   after it has been fully accumulated into the workspace :data:`work`.
   The output vectors :data:`reg_param`, :data:`rho`, and :data:`eta` must all
   be the same size, and will contain the regularization parameters
   :math:`\lambda_i`, residual norms :math:`||y - X c_i||`, and solution
   norms :math:`|| L c_i ||` which compose the L-curve, where :math:`c_i`
   is the regularized solution vector corresponding to :math:`\lambda_i`.
   The user may determine the number of points on the L-curve by
   adjusting the size of these input arrays. For the TSQR method,
   the regularization parameters :math:`\lambda_i` are estimated from the
   singular values of the triangular :math:`R` factor. For the normal
   equations method, they are estimated from the eigenvalues of the
   :math:`X^T X` matrix.

.. function:: int gsl_multilarge_linear_rcond (double * rcond, gsl_multilarge_linear_workspace * work)

   This function computes the reciprocal condition number, stored in
   :data:`rcond`, of the least squares matrix after it has been accumulated
   into the workspace :data:`work`. For the TSQR algorithm, this is
   accomplished by calculating the SVD of the :math:`R` factor, which
   has the same singular values as the matrix :math:`X`. For the normal
   equations method, this is done by computing the eigenvalues of
   :math:`X^T X`, which could be inaccurate for ill-conditioned matrices
   :math:`X`.

.. index:: least squares troubleshooting

Troubleshooting
===============

When using models based on polynomials, care should be taken when constructing the design matrix
:math:`X`. If the :math:`x` values are large, then the matrix :math:`X` could be ill-conditioned
since its columns are powers of :math:`x`, leading to unstable least-squares solutions.
In this case it can often help to center and scale the :math:`x` values using the mean and standard deviation:

.. only:: not texinfo

   .. math:: x' = {x - \mu(x) \over \sigma(x)}

.. only:: texinfo

   ::

      x' = (x - mu)/sigma

and then construct the :math:`X` matrix using the transformed values :math:`x'`.

Examples
========

The example programs in this section demonstrate the various linear regression methods.

Simple Linear Regression Example
--------------------------------

The following program computes a least squares straight-line fit to a
simple dataset, and outputs the best-fit line and its
associated one standard-deviation error bars.

.. include:: examples/fitting.c
   :code:

The following commands extract the data from the output of the program
and display it using the GNU plotutils "graph" utility::

  $ ./demo > tmp
  $ more tmp
  # best fit: Y = -106.6 + 0.06 X
  # covariance matrix:
  # [ 39602, -19.9
  #   -19.9, 0.01]
  # chisq = 0.8

  $ for n in data fit hi lo ; 
     do 
       grep "^$n" tmp | cut -d: -f2 > $n ; 
     done
  $ graph -T X -X x -Y y -y 0 20 -m 0 -S 2 -Ie data 
       -S 0 -I a -m 1 fit -m 2 hi -m 2 lo

The result is shown in :numref:`fig_fit-wlinear`.

.. _fig_fit-wlinear:

.. figure:: /images/fit-wlinear.png

   Straight line fit with 1-:math:`\sigma` error bars

Multi-parameter Linear Regression Example
-----------------------------------------

The following program performs a quadratic fit :math:`y = c_0 + c_1 x + c_2 x^2`
to a weighted dataset using the generalised linear fitting function
:func:`gsl_multifit_wlinear`.  The model matrix :math:`X` for a quadratic
fit is given by,

.. only:: not texinfo

   .. math::

      X =
      \left(
        \begin{array}{ccc}
          1 & x_0 & x_0^2 \\
          1 & x_1 & x_1^2 \\
          1 & x_2 & x_2^2 \\
          \dots & \dots & \dots
        \end{array}
      \right)

.. only:: texinfo

   ::

      X = [ 1   , x_0  , x_0^2 ;
            1   , x_1  , x_1^2 ;
            1   , x_2  , x_2^2 ;
            ... , ...  , ...   ]

where the column of ones corresponds to the constant term :math:`c_0`.
The two remaining columns corresponds to the terms :math:`c_1 x` and
:math:`c_2 x^2`.

The program reads :data:`n` lines of data in the format (:data:`x`, :data:`y`,
:data:`err`) where :data:`err` is the error (standard deviation) in the
value :data:`y`.

.. include:: examples/fitting2.c
   :code:

A suitable set of data for fitting can be generated using the following
program.  It outputs a set of points with gaussian errors from the curve
:math:`y = e^x` in the region :math:`0 < x < 2`.

.. include:: examples/fitting3.c
   :code:

The data can be prepared by running the resulting executable program::

  $ GSL_RNG_TYPE=mt19937_1999 ./generate > exp.dat
  $ more exp.dat
  0.1 0.97935 0.110517
  0.2 1.3359 0.12214
  0.3 1.52573 0.134986
  0.4 1.60318 0.149182
  0.5 1.81731 0.164872
  0.6 1.92475 0.182212
  ....

To fit the data use the previous program, with the number of data points
given as the first argument.  In this case there are 19 data points::

  $ ./fit 19 < exp.dat
  0.1 0.97935 +/- 0.110517
  0.2 1.3359 +/- 0.12214
  ...
  # best fit: Y = 1.02318 + 0.956201 X + 0.876796 X^2
  # covariance matrix:
  [ +1.25612e-02, -3.64387e-02, +1.94389e-02  
    -3.64387e-02, +1.42339e-01, -8.48761e-02  
    +1.94389e-02, -8.48761e-02, +5.60243e-02 ]
  # chisq = 23.0987

The parameters of the quadratic fit match the coefficients of the
expansion of :math:`e^x`, taking into account the errors on the
parameters and the :math:`O(x^3)` difference between the exponential and
quadratic functions for the larger values of :math:`x`.  The errors on
the parameters are given by the square-root of the corresponding
diagonal elements of the covariance matrix.  The chi-squared per degree
of freedom is 1.4, indicating a reasonable fit to the data.

:numref:`fig_fit-wlinear2` shows the resulting fit.

.. _fig_fit-wlinear2:

.. figure:: /images/fit-wlinear2.png

   Weighted fit example with error bars

Regularized Linear Regression Example 1
---------------------------------------

The next program demonstrates the difference between ordinary and
regularized least squares when the design matrix is near-singular.
In this program, we generate two random normally distributed variables
:math:`u` and :math:`v`, with :math:`v = u + noise` so that :math:`u`
and :math:`v` are nearly colinear. We then set a third dependent
variable :math:`y = u + v + noise` and solve for the coefficients
:math:`c_1,c_2` of the model :math:`Y(c_1,c_2) = c_1 u + c_2 v`.
Since :math:`u \approx v`, the design matrix :math:`X` is nearly
singular, leading to unstable ordinary least squares solutions.

Here is the program output::

  matrix condition number = 1.025113e+04

  === Unregularized fit ===
  best fit: y = -43.6588 u + 45.6636 v
  residual norm = 31.6248
  solution norm = 63.1764
  chisq/dof = 1.00213

  === Regularized fit (L-curve) ===
  optimal lambda: 4.51103
  best fit: y = 1.00113 u + 1.0032 v
  residual norm = 31.6547
  solution norm = 1.41728
  chisq/dof = 1.04499

  === Regularized fit (GCV) ===
  optimal lambda: 0.0232029
  best fit: y = -19.8367 u + 21.8417 v
  residual norm = 31.6332
  solution norm = 29.5051
  chisq/dof = 1.00314

We see that the ordinary least squares solution is completely wrong,
while the L-curve regularized method with the optimal
:math:`\lambda = 4.51103` finds the correct solution
:math:`c_1 \approx c_2 \approx 1`. The GCV regularized method finds
a regularization parameter :math:`\lambda = 0.0232029` which is too
small to give an accurate solution, although it performs better than OLS.
The L-curve and its computed corner, as well as the GCV curve and its
minimum are plotted in :numref:`fig_regularized`.

.. _fig_regularized:

.. figure:: /images/regularized.png

   L-curve and GCV curve for example program.

The program is given below.

.. include:: examples/fitreg.c
   :code:

Regularized Linear Regression Example 2
---------------------------------------

The following example program minimizes the cost function

.. math:: ||y - X c||^2 + \lambda^2 ||x||^2

where :math:`X` is the :math:`10`-by-:math:`8` Hilbert matrix whose
entries are given by

.. only:: not texinfo

   .. math:: X_{ij} = {1 \over i + j - 1}

.. only:: texinfo

   ::

      X_{ij} = 1 / (i + j - 1)

and the right hand side vector is given by
:math:`y = [1,-1,1,-1,1,-1,1,-1,1,-1]^T`. Solutions
are computed for :math:`\lambda = 0` (unregularized) as
well as for optimal parameters :math:`\lambda` chosen by
analyzing the L-curve and GCV curve.

Here is the program output::

  matrix condition number = 3.565872e+09

  === Unregularized fit ===
  residual norm = 2.15376
  solution norm = 2.92217e+09
  chisq/dof = 2.31934

  === Regularized fit (L-curve) ===
  optimal lambda: 7.11407e-07
  residual norm = 2.60386
  solution norm = 424507
  chisq/dof = 3.43565

  === Regularized fit (GCV) ===
  optimal lambda: 1.72278
  residual norm = 3.1375
  solution norm = 0.139357
  chisq/dof = 4.95076

Here we see the unregularized solution results in a large solution
norm due to the ill-conditioned matrix. The L-curve solution finds
a small value of :math:`\lambda = 7.11e-7` which still results in
a badly conditioned system and a large solution norm. The GCV method
finds a parameter :math:`\lambda = 1.72` which results in a well-conditioned
system and small solution norm.

The L-curve and its computed corner, as well as the GCV curve and its
minimum are plotted in :numref:`fig_regularized2`.

.. _fig_regularized2:

.. figure:: /images/regularized2.png

   L-curve and GCV curve for example program.

The program is given below.

.. include:: examples/fitreg2.c
   :code:

Robust Linear Regression Example
--------------------------------

The next program demonstrates the advantage of robust least squares on
a dataset with outliers. The program generates linear :math:`(x,y)`
data pairs on the line :math:`y = 1.45 x + 3.88`, adds some random
noise, and inserts 3 outliers into the dataset. Both the robust
and ordinary least squares (OLS) coefficients are computed for
comparison.

.. include:: examples/robfit.c
   :code:

The output from the program is shown in :numref:`fig_robust`.

.. _fig_robust:

.. figure:: /images/robust.png

   Linear fit to dataset with outliers.

Large Dense Linear Regression Example
-------------------------------------

The following program demostrates the large dense linear least squares
solvers. This example is adapted from Trefethen and Bau,
and fits the function :math:`f(t) = \exp{(\sin^3{(10t)}})` on
the interval :math:`[0,1]` with a degree 15 polynomial. The
program generates :math:`n = 50000` equally spaced points
:math:`t_i` on this interval, calculates the function value
and adds random noise to determine the observation value
:math:`y_i`. The entries of the least squares matrix are
:math:`X_{ij} = t_i^j`, representing a polynomial fit. The
matrix is highly ill-conditioned, with a condition number
of about :math:`1.4 \cdot 10^{11}`. The program accumulates the
matrix into the least squares system in 5 blocks, each with
10000 rows. This way the full matrix :math:`X` is never
stored in memory. We solve the system with both the
normal equations and TSQR methods. The results are shown
in :numref:`fig_multilarge`. In the top left plot, we see the unregularized
normal equations solution has larger error than TSQR due to
the ill-conditioning of the matrix. In the bottom left plot,
we show the L-curve, which exhibits multiple corners.
In the top right panel, we plot a regularized solution using
:math:`\lambda = 10^{-6}`. The TSQR and normal solutions now agree,
however they are unable to provide a good fit due to the damping.
This indicates that for some ill-conditioned
problems, regularizing the normal equations does not improve the
solution. This is further illustrated in the bottom right panel,
where we plot the L-curve calculated from the normal equations.
The curve agrees with the TSQR curve for larger damping parameters,
but for small :math:`\lambda`, the normal equations approach cannot
provide accurate solution vectors leading to numerical
inaccuracies in the left portion of the curve.

.. _fig_multilarge:

.. figure:: /images/multilarge.png

.. include:: examples/largefit.c
   :code:

References and Further Reading
==============================

A summary of formulas and techniques for least squares fitting can be
found in the "Statistics" chapter of the Annual Review of Particle
Physics prepared by the Particle Data Group,

* *Review of Particle Properties*,
  R.M. Barnett et al., Physical Review D54, 1 (1996)
  http://pdg.lbl.gov

The Review of Particle Physics is available online at the website given
above.

.. index::
   single: NIST Statistical Reference Datasets
   single: Statistical Reference Datasets (StRD)

The tests used to prepare these routines are based on the NIST
Statistical Reference Datasets. The datasets and their documentation are
available from NIST at the following website,

http://www.nist.gov/itl/div898/strd/index.html

More information on Tikhonov regularization can be found in

* Hansen, P. C. (1998), Rank-Deficient and Discrete Ill-Posed Problems:
  Numerical Aspects of Linear Inversion. SIAM Monogr. on Mathematical
  Modeling and Computation, Society for Industrial and Applied Mathematics

* M. Rezghi and S. M. Hosseini (2009), A new variant of L-curve for
  Tikhonov regularization, Journal of Computational and Applied Mathematics,
  Volume 231, Issue 2, pages 914-924.

The GSL implementation of robust linear regression closely follows the publications

* DuMouchel, W. and F. O'Brien (1989), "Integrating a robust
  option into a multiple regression computing environment,"
  Computer Science and Statistics:  Proceedings of the 21st
  Symposium on the Interface, American Statistical Association

* Street, J.O., R.J. Carroll, and D. Ruppert (1988), "A note on
  computing robust regression estimates via iteratively
  reweighted least squares," The American Statistician, v. 42, 
  pp. 152-154.

More information about the normal equations and TSQR approach for solving
large linear least squares systems can be found in the publications

* Trefethen, L. N. and Bau, D. (1997), "Numerical Linear Algebra", SIAM.

* Demmel, J., Grigori, L., Hoemmen, M. F., and Langou, J.
  "Communication-optimal parallel and sequential QR and LU factorizations",
  UCB Technical Report No. UCB/EECS-2008-89, 2008.
.. index::
   single: nonlinear least squares
   single: least squares, nonlinear

*******************************
Nonlinear Least-Squares Fitting
*******************************

.. include:: include.rst

This chapter describes functions for multidimensional nonlinear
least-squares fitting.  There are generally two classes of
algorithms for solving nonlinear least squares problems, which
fall under line search methods and trust region methods.
GSL currently implements only trust region methods and
provides the user with
full access to intermediate steps of the iteration. The user
also has the ability to tune a number of parameters which affect
low-level aspects of the algorithm which can help to accelerate
convergence for the specific problem at hand. GSL provides
two separate interfaces for nonlinear least squares fitting. The
first is designed for small to moderate sized problems, and the
second is designed for very large problems, which may or may not
have significant sparse structure.

The header file :file:`gsl_multifit_nlinear.h` contains prototypes for the
multidimensional nonlinear fitting functions and related declarations
relating to the small to moderate sized systems.

The header file :file:`gsl_multilarge_nlinear.h` contains prototypes for the
multidimensional nonlinear fitting functions and related declarations
relating to large systems.

.. index::
   single: nonlinear least squares, overview

Overview
========

The problem of multidimensional nonlinear least-squares fitting requires
the minimization of the squared residuals of :math:`n` functions,
:math:`f_i`, in :math:`p` parameters, :math:`x_i`,

.. only:: not texinfo

   .. math::

      \Phi(x) &= {1 \over 2} || f(x) ||^2 \\
              &= {1 \over 2} \sum_{i=1}^{n} f_i (x_1, \dots, x_p)^2

.. only:: texinfo

   ::

      \Phi(x) = (1/2) || f(x) ||^2
              = (1/2) \sum_{i=1}^{n} f_i(x_1, ..., x_p)^2 

In trust region methods, the objective (or cost) function :math:`\Phi(x)` is approximated
by a model function :math:`m_k(\delta)` in the vicinity of some point :math:`x_k`. The
model function is often simply a second order Taylor series expansion around the
point :math:`x_k`, ie:

.. only:: not texinfo

   .. math:: \Phi(x_k + \delta) \approx m_k(\delta) = \Phi(x_k) + g_k^T \delta + {1 \over 2} \delta^T B_k \delta

.. only:: texinfo

   ::

      \Phi(x_k + \delta) ~=~ m_k(\delta) = \Phi(x_k) + g_k^T \delta + 1/2 \delta^T B_k \delta

where :math:`g_k = \nabla \Phi(x_k) = J^T f` is the gradient vector at the point :math:`x_k`,
:math:`B_k = \nabla^2 \Phi(x_k)` is the Hessian matrix at :math:`x_k`, or some
approximation to it, and :math:`J` is the :math:`n`-by-:math:`p` Jacobian matrix

.. only:: not texinfo

   .. math:: J_{ij} = \partial f_i / \partial x_j

.. only:: texinfo

   ::

      J_{ij} = d f_i / d x_j

In order to find the next step :math:`\delta`, we minimize the model function
:math:`m_k(\delta)`, but search for solutions only within a region where
we trust that :math:`m_k(\delta)` is a good approximation to the objective
function :math:`\Phi(x_k + \delta)`. In other words,
we seek a solution of the trust region subproblem (TRS)

.. only:: not texinfo

   .. math:: \min_{\delta \in R^p} m_k(\delta) = \Phi(x_k) + g_k^T \delta + {1 \over 2} \delta^T B_k \delta, \qquad\hbox{s.t.}\quad || D_k \delta || \le \Delta_k

.. only:: texinfo

   ::

      \min_(\delta \in R^p) m_k(\delta), s.t. || D_k \delta || <= \Delta_k

where :math:`\Delta_k > 0` is the trust region radius and :math:`D_k` is
a scaling matrix. If :math:`D_k = I`, then the trust region is a ball
of radius :math:`\Delta_k` centered at :math:`x_k`. In some applications,
the parameter vector :math:`x` may have widely different scales. For
example, one parameter might be a temperature on the order of
:math:`10^3` K, while another might be a length on the order of
:math:`10^{-6}` m. In such cases, a spherical trust region may not
be the best choice, since if :math:`\Phi` changes rapidly along
directions with one scale, and more slowly along directions with
a different scale, the model function :math:`m_k` may be a poor
approximation to :math:`\Phi` along the rapidly changing directions.
In such problems, it may be best to use an elliptical trust region,
by setting :math:`D_k` to a diagonal matrix whose entries are designed
so that the scaled step :math:`D_k \delta` has entries of approximately the same
order of magnitude.

The trust region subproblem above normally amounts to solving a
linear least squares system (or multiple systems) for the step
:math:`\delta`. Once :math:`\delta` is computed, it is checked whether
or not it reduces the objective function :math:`\Phi(x)`. A useful
statistic for this is to look at the ratio

.. only:: not texinfo

   .. math:: \rho_k = { \Phi(x_k) - \Phi(x_k + \delta_k) \over m_k(0) - m_k(\delta_k) }

.. only:: texinfo

   ::

      \rho_k = ( \Phi(x_k) - \Phi(x_k + \delta_k) / ( m_k(0) - m_k(\delta_k) )

where the numerator is the actual reduction of the objective function
due to the step :math:`\delta_k`, and the denominator is the predicted
reduction due to the model :math:`m_k`. If :math:`\rho_k` is negative,
it means that the step :math:`\delta_k` increased the objective function
and so it is rejected. If :math:`\rho_k` is positive,
then we have found a step which reduced the objective function and
it is accepted. Furthermore, if :math:`\rho_k` is close to 1,
then this indicates that the model function is a good approximation
to the objective function in the trust region, and so on the next
iteration the trust region is enlarged in order to take more ambitious
steps. When a step is rejected, the trust region is made smaller and
the TRS is solved again. An outline for the general trust region method
used by GSL can now be given.

**Trust Region Algorithm**

1. Initialize: given :math:`x_0`, construct :math:`m_0(\delta)`, :math:`D_0` and :math:`\Delta_0 > 0`

2. For k = 0, 1, 2, ...

   a. If converged, then stop
   b. Solve TRS for trial step :math:`\delta_k`
   c. Evaluate trial step by computing :math:`\rho_k`

      1). if step is accepted, set :math:`x_{k+1} = x_k + \delta_k` and increase radius,
          :math:`\Delta_{k+1} = \alpha \Delta_k`
      2). if step is rejected, set :math:`x_{k+1} = x_k` and decrease radius,
          :math:`\Delta_{k+1} = {\Delta_k \over \beta}`; goto 2(b)

   d. Construct :math:`m_{k+1}(\delta)` and :math:`D_{k+1}`

GSL offers the user a number of different algorithms for solving the trust
region subproblem in 2(b), as well as different choices of scaling matrices
:math:`D_k` and different methods of updating the trust region radius
:math:`\Delta_k`. Therefore, while reasonable default methods are provided,
the user has a lot of control to fine-tune the various steps of the
algorithm for their specific problem.

Solving the Trust Region Subproblem (TRS)
=========================================

Below we describe the methods available for solving the trust region
subproblem. The methods available provide either exact or approximate
solutions to the trust region subproblem. In all algorithms below,
the Hessian matrix :math:`B_k` is approximated as :math:`B_k \approx J_k^T J_k`,
where :math:`J_k = J(x_k)`. In all methods, the solution of the TRS
involves solving a linear least squares system involving the Jacobian
matrix. For small to moderate sized problems (:code:`gsl_multifit_nlinear` interface),
this is accomplished by factoring the full Jacobian matrix, which is provided
by the user, with the Cholesky, QR, or SVD decompositions. For large systems
(:code:`gsl_multilarge_nlinear` interface), the user has two choices. One
is to solve the system iteratively, without needing to store the full
Jacobian matrix in memory. With this method, the user must provide a routine
to calculate the matrix-vector products :math:`J u` or :math:`J^T u` for a given vector :math:`u`.
This iterative method is particularly useful for systems where the Jacobian has
sparse structure, since forming matrix-vector products can be done cheaply. The
second option for large systems involves forming the normal equations matrix
:math:`J^T J` and then factoring it using a Cholesky decomposition. The normal
equations matrix is :math:`p`-by-:math:`p`, typically much smaller than the full
:math:`n`-by-:math:`p` Jacobian, and can usually be stored in memory even if the full
Jacobian matrix cannot. This option is useful for large, dense systems, or if the
iterative method has difficulty converging.

.. index::
   single: Levenberg-Marquardt algorithm
   single: nonlinear least squares, levenberg-marquardt

Levenberg-Marquardt
-------------------

There is a theorem which states that if :math:`\delta_k` is a solution
to the trust region subproblem given above, then there exists
:math:`\mu_k \ge 0` such that

.. only:: not texinfo

   .. math:: \left( B_k + \mu_k D_k^T D_k \right) \delta_k = -g_k

.. only:: texinfo

   ::

      ( B_k + \mu_k D_k^T D_k ) \delta_k = -g_k

with :math:`\mu_k (\Delta_k - ||D_k \delta_k||) = 0`. This
forms the basis of the Levenberg-Marquardt algorithm, which controls
the trust region size by adjusting the parameter :math:`\mu_k`
rather than the radius :math:`\Delta_k` directly. For each radius
:math:`\Delta_k`, there is a unique parameter :math:`\mu_k` which
solves the TRS, and they have an inverse relationship, so that large values of
:math:`\mu_k` correspond to smaller trust regions, while small
values of :math:`\mu_k` correspond to larger trust regions.

With the approximation :math:`B_k \approx J_k^T J_k`, on each iteration,
in order to calculate the step :math:`\delta_k`,
the following linear least squares problem is solved:

.. only:: not texinfo

   .. math::

      \left[
        \begin{array}{c}
          J_k \\
          \sqrt{\mu_k} D_k
        \end{array}
      \right]
      \delta_k =
      -
      \left[
        \begin{array}{c}
          f_k \cr
          0
        \end{array}
      \right]

.. only:: texinfo

   ::

      [J_k; sqrt(mu_k) D_k] \delta_k = - [f_k; 0]

If the step :math:`\delta_k` is accepted, then
:math:`\mu_k` is decreased on the next iteration in order
to take a larger step, otherwise it is increased to take
a smaller step. The Levenberg-Marquardt algorithm provides
an exact solution of the trust region subproblem, but
typically has a higher computational cost per iteration
than the approximate methods discussed below, since it
may need to solve the least squares system above several
times for different values of :math:`\mu_k`.

.. index::
   single: Levenberg-Marquardt algorithm, geodesic acceleration
   single: nonlinear least squares, levenberg-marquardt, geodesic acceleration

Levenberg-Marquardt with Geodesic Acceleration
----------------------------------------------

This method applies a so-called geodesic acceleration correction to
the standard Levenberg-Marquardt step :math:`\delta_k` (Transtrum et al, 2011).
By interpreting :math:`\delta_k` as a first order step along a geodesic in the
model parameter space (ie: a velocity :math:`\delta_k = v_k`), the geodesic
acceleration :math:`a_k` is a second order correction along the
geodesic which is determined by solving the linear least squares system

.. only:: not texinfo

   .. math::

      \left[
        \begin{array}{c}
          J_k \\
          \sqrt{\mu_k} D_k
        \end{array}
      \right]
      a_k =
      -
      \left[
        \begin{array}{c}
          f_{vv}(x_k) \\
          0
        \end{array}
      \right]

.. only:: texinfo

   ::

      [J_k; sqrt(mu_k) D_k] a_k = - [f_vv(x_k); 0]

where :math:`f_{vv}` is the second directional derivative of
the residual vector in the velocity direction :math:`v`,
:math:`f_{vv}(x) = D_v^2 f = \sum_{\alpha\beta} v_{\alpha} v_{\beta} \partial_{\alpha} \partial_{\beta} f(x)`,
where :math:`\alpha` and :math:`\beta` are summed over the :math:`p`
parameters. The new total step is then :math:`\delta_k' = v_k + {1 \over 2}a_k`.
The second order correction :math:`a_k` can be calculated with a modest additional
cost, and has been shown to dramatically reduce the number of iterations
(and expensive Jacobian evaluations) required to reach convergence on a variety
of different problems. In order to utilize the geodesic acceleration, the user must supply a
function which provides the second directional derivative vector
:math:`f_{vv}(x)`, or alternatively the library can use a finite
difference method to estimate this vector with one additional function
evaluation of :math:`f(x + h v)` where :math:`h` is a tunable step size
(see the :code:`h_fvv` parameter description).

.. index::
   single: Dogleg algorithm
   single: nonlinear least squares, dogleg

Dogleg
------

This is Powell's dogleg method, which finds an approximate
solution to the trust region subproblem, by restricting
its search to a piecewise linear "dogleg" path,
composed of the origin, the Cauchy point which represents
the model minimizer along the steepest descent direction,
and the Gauss-Newton point, which is the overall minimizer
of the unconstrained model. The Gauss-Newton step is calculated by
solving

.. math:: J_k \delta_{gn} = -f_k

which is the main computational task for each iteration,
but only needs to be performed once per iteration. If
the Gauss-Newton point is inside the trust region, it is
selected as the step. If it is outside, the method then
calculates the Cauchy point, which is located along the
gradient direction. If the Cauchy point is also outside
the trust region, the method assumes that it is still far
from the minimum and so proceeds along the gradient
direction, truncating the step at the trust region
boundary. If the Cauchy point is inside the trust region,
with the Gauss-Newton point outside, the method
uses a dogleg step, which is a linear combination of the
gradient direction and the Gauss-Newton direction, stopping at the trust
region boundary.

.. index::
   single: double Dogleg algorithm
   single: Dogleg algorithm, double
   single: nonlinear least squares, double dogleg

Double Dogleg
-------------

This method is an improvement over the classical dogleg
algorithm, which attempts to include information about
the Gauss-Newton step while the iteration is still far from
the minimum. When the Cauchy point is inside the trust region
and the Gauss-Newton point is outside, the method computes
a scaled Gauss-Newton point and then takes a dogleg step
between the Cauchy point and the scaled Gauss-Newton point.
The scaling is calculated to ensure that the reduction
in the model :math:`m_k` is about the same as the reduction
provided by the Cauchy point.

Two Dimensional Subspace
------------------------

The dogleg methods restrict the search for the TRS solution
to a 1D curve defined by the Cauchy and Gauss-Newton points.
An improvement to this is to search for a solution using
the full two dimensional subspace spanned by the Cauchy
and Gauss-Newton directions. The dogleg path is of course
inside this subspace, and so this method solves the TRS
at least as accurately as the dogleg methods. Since this
method searches a larger subspace for a solution, it can
converge more quickly than dogleg on some problems. Because
the subspace is only two dimensional, this method is
very efficient and the main computation per iteration is
to determine the Gauss-Newton point.

Steihaug-Toint Conjugate Gradient
---------------------------------

One difficulty of the dogleg methods is calculating the
Gauss-Newton step when the Jacobian matrix is singular. The
Steihaug-Toint method also computes a generalized dogleg
step, but avoids solving for the Gauss-Newton step directly,
instead using an iterative conjugate gradient algorithm. This
method performs well at points where the Jacobian is singular,
and is also suitable for large-scale problems where factoring
the Jacobian matrix could be prohibitively expensive.

Weighted Nonlinear Least-Squares
================================

Weighted nonlinear least-squares fitting minimizes the function

.. only:: not texinfo

   .. math::

      \Phi(x) &= {1 \over 2} || f ||_W^2 \\
              &= {1 \over 2} \sum_{i=1}^{n} w_i f_i (x_1, \dots, x_p)^2

.. only:: texinfo

   ::

      \Phi(x) = (1/2) || f(x) ||_W^2
              = (1/2) \sum_{i=1}^{n} f_i(x_1, ..., x_p)^2 

where :math:`W = \diag(w_1,w_2,...,w_n)` is the weighting matrix,
and :math:`||f||_W^2 = f^T W f`.
The weights :math:`w_i` are commonly defined as :math:`w_i = 1/\sigma_i^2`,
where :math:`\sigma_i` is the error in the :math:`i`-th measurement.
A simple change of variables :math:`\tilde{f} = W^{1 \over 2} f` yields
:math:`\Phi(x) = {1 \over 2} ||\tilde{f}||^2`, which is in the
same form as the unweighted case. The user can either perform this
transform directly on their function residuals and Jacobian, or use
the :func:`gsl_multifit_nlinear_winit` interface which automatically
performs the correct scaling. To manually perform this transformation,
the residuals and Jacobian should be modified according to

.. only:: not texinfo

   .. math::

      \tilde{f}_i & = \sqrt{w_i} f_i = {f_i \over \sigma_i} \\
      \tilde{J}_{ij} & = \sqrt{w_i} { \partial f_i \over \partial x_j } = { 1 \over \sigma_i} { \partial f_i \over \partial x_j }

.. only:: texinfo

   ::

      f~_i = f_i / \sigma_i
      J~_ij = 1 / \sigma_i df_i/dx_j

For large systems, the user must perform their own weighting.

.. _sec_tunable-parameters:

Tunable Parameters
==================

The user can tune nearly all aspects of the iteration at allocation
time. For the :code:`gsl_multifit_nlinear` interface, the user may
modify the :type:`gsl_multifit_nlinear_parameters` structure, which is
defined as follows:

.. type:: gsl_multifit_nlinear_parameters

   ::

      typedef struct
      {
        const gsl_multifit_nlinear_trs *trs;        /* trust region subproblem method */
        const gsl_multifit_nlinear_scale *scale;    /* scaling method */
        const gsl_multifit_nlinear_solver *solver;  /* solver method */
        gsl_multifit_nlinear_fdtype fdtype;         /* finite difference method */
        double factor_up;                           /* factor for increasing trust radius */
        double factor_down;                         /* factor for decreasing trust radius */
        double avmax;                               /* max allowed |a|/|v| */
        double h_df;                                /* step size for finite difference Jacobian */
        double h_fvv;                               /* step size for finite difference fvv */
      } gsl_multifit_nlinear_parameters;

For the :code:`gsl_multilarge_nlinear` interface, the user may
modify the :type:`gsl_multilarge_nlinear_parameters` structure, which is
defined as follows:

.. type:: gsl_multilarge_nlinear_parameters

   ::

      typedef struct
      {
        const gsl_multilarge_nlinear_trs *trs;       /* trust region subproblem method */
        const gsl_multilarge_nlinear_scale *scale;   /* scaling method */
        const gsl_multilarge_nlinear_solver *solver; /* solver method */
        gsl_multilarge_nlinear_fdtype fdtype;        /* finite difference method */
        double factor_up;                            /* factor for increasing trust radius */
        double factor_down;                          /* factor for decreasing trust radius */
        double avmax;                                /* max allowed |a|/|v| */
        double h_df;                                 /* step size for finite difference Jacobian */
        double h_fvv;                                /* step size for finite difference fvv */
        size_t max_iter;                             /* maximum iterations for trs method */
        double tol;                                  /* tolerance for solving trs */
      } gsl_multilarge_nlinear_parameters;

Each of these parameters is discussed in further detail below.

.. type:: gsl_multifit_nlinear_trs
          gsl_multilarge_nlinear_trs

   The parameter :data:`trs` determines the method used to solve the trust region
   subproblem, and may be selected from the following choices,

   .. var:: gsl_multifit_nlinear_trs_lm
            gsl_multilarge_nlinear_trs_lm

      This selects the Levenberg-Marquardt algorithm.

   .. var:: gsl_multifit_nlinear_trs_lmaccel
            gsl_multilarge_nlinear_trs_lmaccel

      This selects the Levenberg-Marquardt algorithm with geodesic
      acceleration.

   .. var:: gsl_multifit_nlinear_trs_dogleg
            gsl_multilarge_nlinear_trs_dogleg

      This selects the dogleg algorithm.

   .. var:: gsl_multifit_nlinear_trs_ddogleg
            gsl_multilarge_nlinear_trs_ddogleg

      This selects the double dogleg algorithm.

   .. var:: gsl_multifit_nlinear_trs_subspace2D
            gsl_multilarge_nlinear_trs_subspace2D

      This selects the 2D subspace algorithm.

   .. var:: gsl_multilarge_nlinear_trs_cgst

      This selects the Steihaug-Toint conjugate gradient algorithm. This
      method is available only for large systems.

.. type:: gsl_multifit_nlinear_scale
          gsl_multilarge_nlinear_scale

   The parameter :data:`scale` determines the diagonal scaling matrix :math:`D` and
   may be selected from the following choices,

   .. var:: gsl_multifit_nlinear_scale_more
            gsl_multilarge_nlinear_scale_more

      This damping strategy was suggested by |More|, and
      corresponds to :math:`D^T D = \max(\diag(J^T J))`,
      in other words the maximum elements of
      :math:`\diag(J^T J)` encountered thus far in the iteration.
      This choice of :math:`D` makes the problem scale-invariant,
      so that if the model parameters :math:`x_i` are each scaled
      by an arbitrary constant, :math:`\tilde{x}_i = a_i x_i`, then
      the sequence of iterates produced by the algorithm would
      be unchanged. This method can work very well in cases
      where the model parameters have widely different scales
      (ie: if some parameters are measured in nanometers, while others
      are measured in degrees Kelvin). This strategy has been proven
      effective on a large class of problems and so it is the library
      default, but it may not be the best choice for all problems.

   .. var:: gsl_multifit_nlinear_scale_levenberg
            gsl_multilarge_nlinear_scale_levenberg

      This damping strategy was originally suggested by Levenberg, and
      corresponds to :math:`D^T D = I`. This method has also proven
      effective on a large class of problems, but is not scale-invariant.
      However, some authors (e.g. Transtrum and Sethna 2012) argue
      that this choice is better for problems which are susceptible
      to parameter evaporation (ie: parameters go to infinity)

   .. var:: gsl_multifit_nlinear_scale_marquardt
            gsl_multilarge_nlinear_scale_marquardt

      This damping strategy was suggested by Marquardt, and
      corresponds to :math:`D^T D = \diag(J^T J)`. This
      method is scale-invariant, but it is generally considered
      inferior to both the Levenberg and |More| strategies, though
      may work well on certain classes of problems.

.. type:: gsl_multifit_nlinear_solver
          gsl_multilarge_nlinear_solver

   Solving the trust region subproblem on each iteration almost always
   requires the solution of the following linear least squares system

   .. only:: not texinfo

      .. math::

         \left[
           \begin{array}{c}
             J \\
             \sqrt{\mu} D
           \end{array}
         \right]
         \delta =
         -
         \left[
           \begin{array}{c}
             f \\
             0
           \end{array}
         \right]

   .. only:: texinfo

      ::

         [J; sqrt(mu) D] \delta = - [f; 0]

   The :data:`solver` parameter determines how the system is
   solved and can be selected from the following choices:

   .. var:: gsl_multifit_nlinear_solver_qr

      This method solves the system using a rank revealing QR
      decomposition of the Jacobian :math:`J`. This method will
      produce reliable solutions in cases where the Jacobian
      is rank deficient or near-singular but does require about
      twice as many operations as the Cholesky method discussed
      below.

   .. var:: gsl_multifit_nlinear_solver_cholesky
            gsl_multilarge_nlinear_solver_cholesky

      This method solves the alternate normal equations problem

      .. only:: not texinfo

         .. math:: \left( J^T J + \mu D^T D \right) \delta = -J^T f

      .. only:: texinfo

         ::

            ( J^T J + \mu D^T D ) \delta = -J^T f

      by using a Cholesky decomposition of the matrix
      :math:`J^T J + \mu D^T D`. This method is faster than the
      QR approach, however it is susceptible to numerical instabilities
      if the Jacobian matrix is rank deficient or near-singular. In
      these cases, an attempt is made to reduce the condition number
      of the matrix using Jacobi preconditioning, but for highly
      ill-conditioned problems the QR approach is better. If it is
      known that the Jacobian matrix is well conditioned, this method
      is accurate and will perform faster than the QR approach.

   .. var:: gsl_multifit_nlinear_solver_svd

      This method solves the system using a singular value
      decomposition of the Jacobian :math:`J`. This method will
      produce the most reliable solutions for ill-conditioned Jacobians
      but is also the slowest solver method.

.. type:: gsl_multifit_nlinear_fdtype

   The parameter :data:`fdtype` specifies whether to use forward or centered
   differences when approximating the Jacobian. This is only
   used when an analytic Jacobian is not provided to the solver.
   This parameter may be set to one of the following choices.

   .. macro:: GSL_MULTIFIT_NLINEAR_FWDIFF

      This specifies a forward finite difference to approximate
      the Jacobian matrix. The Jacobian matrix will be calculated as

      .. only:: not texinfo

         .. math:: J_{ij} = {1 \over \Delta_j} \left( f_i(x + \Delta_j e_j) - f_i(x) \right)

      .. only:: texinfo

         ::

            J_ij = 1 / \Delta_j ( f_i(x + \Delta_j e_j) - f_i(x) )

      where :math:`\Delta_j = h |x_j|` and :math:`e_j` is the standard
      :math:`j`-th Cartesian unit basis vector so that
      :math:`x + \Delta_j e_j` represents a small (forward) perturbation of
      the :math:`j`-th parameter by an amount :math:`\Delta_j`. The perturbation
      :math:`\Delta_j` is proportional to the current value :math:`|x_j|` which
      helps to calculate an accurate Jacobian when the various parameters have
      different scale sizes. The value of :math:`h` is specified by the :code:`h_df`
      parameter. The accuracy of this method is :math:`O(h)`, and evaluating this
      matrix requires an additional :math:`p` function evaluations.

   .. macro:: GSL_MULTIFIT_NLINEAR_CTRDIFF

      This specifies a centered finite difference to approximate
      the Jacobian matrix. The Jacobian matrix will be calculated as

      .. only:: not texinfo

         .. math:: J_{ij} = {1 \over \Delta_j} \left( f_i(x + {1 \over 2} \Delta_j e_j) - f_i(x - {1 \over 2} \Delta_j e_j) \right)

      .. only:: texinfo

         ::

            J_ij = 1 / \Delta_j ( f_i(x + 1/2 \Delta_j e_j) - f_i(x - 1/2 \Delta_j e_j) )

      See above for a description of :math:`\Delta_j`. The accuracy of this
      method is :math:`O(h^2)`, but evaluating this
      matrix requires an additional :math:`2p` function evaluations.

:code:`double factor_up`

When a step is accepted, the trust region radius will be increased
by this factor. The default value is :math:`3`.

:code:`double factor_down`

When a step is rejected, the trust region radius will be decreased
by this factor. The default value is :math:`2`.

:code:`double avmax`

When using geodesic acceleration to solve a nonlinear least squares problem,
an important parameter to monitor is the ratio of the acceleration term
to the velocity term,

.. only:: not texinfo

   .. math:: { ||a|| \over ||v|| }

.. only:: texinfo

   ::

      |a| / |v|

If this ratio is small, it means the acceleration correction
is contributing very little to the step. This could be because
the problem is not "nonlinear" enough to benefit from
the acceleration. If the ratio is large (:math:`> 1`) it
means that the acceleration is larger than the velocity,
which shouldn't happen since the step represents a truncated
series and so the second order term :math:`a` should be smaller than
the first order term :math:`v` to guarantee convergence.
Therefore any steps with a ratio larger than the parameter
:data:`avmax` are rejected. :data:`avmax` is set to 0.75 by default.
For problems which experience difficulty converging, this threshold
could be lowered.

:code:`double h_df`

This parameter specifies the step size for approximating the
Jacobian matrix with finite differences. It is set to
:math:`\sqrt{\epsilon}` by default, where :math:`\epsilon`
is :macro:`GSL_DBL_EPSILON`.

:code:`double h_fvv`

When using geodesic acceleration, the user must either supply
a function to calculate :math:`f_{vv}(x)` or the library
can estimate this second directional derivative using a finite
difference method. When using finite differences, the library
must calculate :math:`f(x + h v)` where :math:`h` represents
a small step in the velocity direction. The parameter
:data:`h_fvv` defines this step size and is set to 0.02 by
default.

Initializing the Solver
=======================

.. type:: gsl_multifit_nlinear_type

   This structure specifies the type of algorithm which will be used
   to solve a nonlinear least squares problem. It may be selected from the
   following choices,

   .. var:: gsl_multifit_nlinear_trust

      This specifies a trust region method. It is currently the only implemented
      nonlinear least squares method.

.. function:: gsl_multifit_nlinear_workspace * gsl_multifit_nlinear_alloc (const gsl_multifit_nlinear_type * T, const gsl_multifit_nlinear_parameters * params, const size_t n, const size_t p)
              gsl_multilarge_nlinear_workspace * gsl_multilarge_nlinear_alloc (const gsl_multilarge_nlinear_type * T, const gsl_multilarge_nlinear_parameters * params, const size_t n, const size_t p)

   These functions return a pointer to a newly allocated instance of a
   derivative solver of type :data:`T` for :data:`n` observations and :data:`p`
   parameters. The :data:`params` input specifies a tunable set of
   parameters which will affect important details in each iteration
   of the trust region subproblem algorithm. It is recommended to start
   with the suggested default parameters (see
   :func:`gsl_multifit_nlinear_default_parameters` and
   :func:`gsl_multilarge_nlinear_default_parameters`) and then tune
   the parameters once the code is working correctly. See
   :ref:`sec_tunable-parameters`.
   for descriptions of the various parameters.
   For example, the following code creates an instance of a
   Levenberg-Marquardt solver for 100 data points and 3 parameters,
   using suggested defaults::

      const gsl_multifit_nlinear_type * T = gsl_multifit_nlinear_trust;
      gsl_multifit_nlinear_parameters params = gsl_multifit_nlinear_default_parameters();
      gsl_multifit_nlinear_workspace * w = gsl_multifit_nlinear_alloc (T, &params, 100, 3);

   The number of observations :data:`n` must be greater than or equal to
   parameters :data:`p`.

   If there is insufficient memory to create the solver then the function
   returns a null pointer and the error handler is invoked with an error
   code of :macro:`GSL_ENOMEM`.

.. function:: gsl_multifit_nlinear_parameters gsl_multifit_nlinear_default_parameters (void)
              gsl_multilarge_nlinear_parameters gsl_multilarge_nlinear_default_parameters (void)

   These functions return a set of recommended default parameters
   for use in solving nonlinear least squares problems. The user
   can tune each parameter to improve the performance on their
   particular problem, see :ref:`sec_tunable-parameters`.

.. function:: int gsl_multifit_nlinear_init (const gsl_vector * x, gsl_multifit_nlinear_fdf * fdf, gsl_multifit_nlinear_workspace * w)
              int gsl_multifit_nlinear_winit (const gsl_vector * x, const gsl_vector * wts, gsl_multifit_nlinear_fdf * fdf, gsl_multifit_nlinear_workspace * w)
              int gsl_multilarge_nlinear_init (const gsl_vector * x, gsl_multilarge_nlinear_fdf * fdf, gsl_multilarge_nlinear_workspace * w)

   These functions initialize, or reinitialize, an existing workspace :data:`w`
   to use the system :data:`fdf` and the initial guess
   :data:`x`. See :ref:`sec_providing-function-minimized`
   for a description of the :data:`fdf` structure.

   Optionally, a weight vector :data:`wts` can be given to perform
   a weighted nonlinear regression. Here, the weighting matrix is
   :math:`W = \diag(w_1,w_2,...,w_n)`.

.. function:: void gsl_multifit_nlinear_free (gsl_multifit_nlinear_workspace * w)
              void gsl_multilarge_nlinear_free (gsl_multilarge_nlinear_workspace * w)

   These functions free all the memory associated with the workspace :data:`w`.

.. function:: const char * gsl_multifit_nlinear_name (const gsl_multifit_nlinear_workspace * w)
              const char * gsl_multilarge_nlinear_name (const gsl_multilarge_nlinear_workspace * w)

   These functions return a pointer to the name of the solver.  For example::

      printf ("w is a '%s' solver\n", gsl_multifit_nlinear_name (w));

   would print something like :code:`w is a 'trust-region' solver`.

.. function:: const char * gsl_multifit_nlinear_trs_name (const gsl_multifit_nlinear_workspace * w)
              const char * gsl_multilarge_nlinear_trs_name (const gsl_multilarge_nlinear_workspace * w)

   These functions return a pointer to the name of the trust region subproblem
   method.  For example::

      printf ("w is a '%s' solver\n", gsl_multifit_nlinear_trs_name (w));

   would print something like :code:`w is a 'levenberg-marquardt' solver`.

.. _sec_providing-function-minimized:

Providing the Function to be Minimized
======================================

The user must provide :math:`n` functions of :math:`p` variables for the
minimization algorithm to operate on.  In order to allow for
arbitrary parameters the functions are defined by the following data
types:

.. type:: gsl_multifit_nlinear_fdf

   This data type defines a general system of functions with arbitrary parameters,
   the corresponding Jacobian matrix of derivatives, and optionally the
   second directional derivative of the functions for geodesic acceleration.

   :code:`int (* f) (const gsl_vector * x, void * params, gsl_vector * f)`

      This function should store the :math:`n` components of the vector
      :math:`f(x)` in :data:`f` for argument :data:`x` and arbitrary parameters :data:`params`,
      returning an appropriate error code if the function cannot be computed.

   :code:`int (* df) (const gsl_vector * x, void * params, gsl_matrix * J)`

      This function should store the :data:`n`-by-:data:`p` matrix result

      .. only:: not texinfo

         .. math:: J_{ij} = \partial f_i(x) / \partial x_j

      .. only:: texinfo

         ::

            J_ij = d f_i(x) / d x_j

      in :data:`J` for argument :data:`x` 
      and arbitrary parameters :data:`params`, returning an appropriate error code if the
      matrix cannot be computed. If an analytic Jacobian is unavailable, or too expensive
      to compute, this function pointer may be set to :code:`NULL`, in which
      case the Jacobian will be internally computed using finite difference approximations
      of the function :data:`f`.

   :code:`int (* fvv) (const gsl_vector * x, const gsl_vector * v, void * params, gsl_vector * fvv)`

      When geodesic acceleration is enabled, this function should store the
      :math:`n` components of the vector
      :math:`f_{vv}(x) = \sum_{\alpha\beta} v_{\alpha} v_{\beta} {\partial \over \partial x_{\alpha}} {\partial \over \partial x_{\beta}} f(x)`,
      representing second directional derivatives of the function to be minimized,
      into the output :data:`fvv`. The parameter vector is provided in :data:`x` and
      the velocity vector is provided in :data:`v`, both of which have :math:`p`
      components. The arbitrary parameters are given in :data:`params`. If
      analytic expressions for :math:`f_{vv}(x)` are unavailable or too difficult
      to compute, this function pointer may be set to :code:`NULL`, in which case
      :math:`f_{vv}(x)` will be computed internally using a finite difference
      approximation.

   :code:`size_t n`

       the number of functions, i.e. the number of components of the
       vector :data:`f`.

   :code:`size_t p`

      the number of independent variables, i.e. the number of components of
      the vector :data:`x`.

   :code:`void * params`

      a pointer to the arbitrary parameters of the function.

   :code:`size_t nevalf`

      This does not need to be set by the user. It counts the number of
      function evaluations and is initialized by the :code:`_init` function.

   :code:`size_t nevaldf`

      This does not need to be set by the user. It counts the number of
      Jacobian evaluations and is initialized by the :code:`_init` function.

   :code:`size_t nevalfvv`

      This does not need to be set by the user. It counts the number of
      :math:`f_{vv}(x)` evaluations and is initialized by the :code:`_init` function.

.. type:: gsl_multilarge_nlinear_fdf

   This data type defines a general system of functions with arbitrary parameters,
   a function to compute :math:`J u` or :math:`J^T u` for a given vector :math:`u`,
   the normal equations matrix :math:`J^T J`,
   and optionally the second directional derivative of the functions for geodesic acceleration.

   :code:`int (* f) (const gsl_vector * x, void * params, gsl_vector * f)`

      This function should store the :math:`n` components of the vector
      :math:`f(x)` in :data:`f` for argument :data:`x` and arbitrary parameters :data:`params`,
      returning an appropriate error code if the function cannot be computed.

   :code:`int (* df) (CBLAS_TRANSPOSE_t TransJ, const gsl_vector * x, const gsl_vector * u, void * params, gsl_vector * v, gsl_matrix * JTJ)`

      If :data:`TransJ` is equal to :code:`CblasNoTrans`, then this function should
      compute the matrix-vector product :math:`J u` and store the result in :data:`v`.
      If :data:`TransJ` is equal to :code:`CblasTrans`, then this function should
      compute the matrix-vector product :math:`J^T u` and store the result in :data:`v`.
      Additionally, the normal equations matrix :math:`J^T J` should be stored in the
      lower half of :data:`JTJ`. The input matrix :data:`JTJ` could be set to :code:`NULL`,
      for example by iterative methods which do not require this matrix, so the user
      should check for this prior to constructing the matrix.
      The input :data:`params` contains the arbitrary parameters.

   :code:`int (* fvv) (const gsl_vector * x, const gsl_vector * v, void * params, gsl_vector * fvv)`

      When geodesic acceleration is enabled, this function should store the
      :math:`n` components of the vector
      :math:`f_{vv}(x) = \sum_{\alpha\beta} v_{\alpha} v_{\beta} {\partial \over \partial x_{\alpha}} {\partial \over \partial x_{\beta}} f(x)`,
      representing second directional derivatives of the function to be minimized,
      into the output :data:`fvv`. The parameter vector is provided in :data:`x` and
      the velocity vector is provided in :data:`v`, both of which have :math:`p`
      components. The arbitrary parameters are given in :data:`params`. If
      analytic expressions for :math:`f_{vv}(x)` are unavailable or too difficult
      to compute, this function pointer may be set to :code:`NULL`, in which case
      :math:`f_{vv}(x)` will be computed internally using a finite difference
      approximation.

   :code:`size_t n`

      the number of functions, i.e. the number of components of the
      vector :data:`f`.

   :code:`size_t p`

      the number of independent variables, i.e. the number of components of
      the vector :data:`x`.

   :code:`void * params`

      a pointer to the arbitrary parameters of the function.

   :code:`size_t nevalf`

      This does not need to be set by the user. It counts the number of
      function evaluations and is initialized by the :code:`_init` function.

   :code:`size_t nevaldfu`

      This does not need to be set by the user. It counts the number of
      Jacobian matrix-vector evaluations (:math:`J u` or :math:`J^T u`) and
      is initialized by the :code:`_init` function.

   :code:`size_t nevaldf2`

      This does not need to be set by the user. It counts the number of
      :math:`J^T J` evaluations and is initialized by the :code:`_init` function.

   :code:`size_t nevalfvv`

      This does not need to be set by the user. It counts the number of
      :math:`f_{vv}(x)` evaluations and is initialized by the :code:`_init` function.

Note that when fitting a non-linear model against experimental data,
the data is passed to the functions above using the
:data:`params` argument and the trial best-fit parameters through the
:data:`x` argument.

Iteration
=========

The following functions drive the iteration of each algorithm.  Each
function performs one iteration of the trust region method and updates
the state of the solver.

.. function:: int gsl_multifit_nlinear_iterate (gsl_multifit_nlinear_workspace * w)
              int gsl_multilarge_nlinear_iterate (gsl_multilarge_nlinear_workspace * w)

   These functions perform a single iteration of the solver :data:`w`.  If
   the iteration encounters an unexpected problem then an error code will
   be returned.  The solver workspace maintains a current estimate of the
   best-fit parameters at all times.

The solver workspace :data:`w` contains the following entries, which can
be used to track the progress of the solution:

:code:`gsl_vector * x`

  The current position, length :math:`p`.

:code:`gsl_vector * f`

  The function residual vector at the current position :math:`f(x)`, length
  :math:`n`.

:code:`gsl_matrix * J`

  The Jacobian matrix at the current position :math:`J(x)`, size
  :math:`n`-by-:math:`p` (only for :code:`gsl_multifit_nlinear` interface).

:code:`gsl_vector * dx`

  The difference between the current position and the previous position,
  i.e. the last step :math:`\delta`, taken as a vector, length :math:`p`.

These quantities can be accessed with the following functions,

.. function:: gsl_vector * gsl_multifit_nlinear_position (const gsl_multifit_nlinear_workspace * w)
              gsl_vector * gsl_multilarge_nlinear_position (const gsl_multilarge_nlinear_workspace * w)

   These functions return the current position :math:`x` (i.e. best-fit
   parameters) of the solver :data:`w`.

.. function:: gsl_vector * gsl_multifit_nlinear_residual (const gsl_multifit_nlinear_workspace * w)
              gsl_vector * gsl_multilarge_nlinear_residual (const gsl_multilarge_nlinear_workspace * w)

   These functions return the current residual vector :math:`f(x)` of the
   solver :data:`w`.  For weighted systems, the residual vector includes the
   weighting factor :math:`\sqrt{W}`.

.. function:: gsl_matrix * gsl_multifit_nlinear_jac (const gsl_multifit_nlinear_workspace * w)

   This function returns a pointer to the :math:`n`-by-:math:`p` Jacobian matrix for the
   current iteration of the solver :data:`w`. This function is available only for the
   :code:`gsl_multifit_nlinear` interface.

.. function:: size_t gsl_multifit_nlinear_niter (const gsl_multifit_nlinear_workspace * w)
              size_t gsl_multilarge_nlinear_niter (const gsl_multilarge_nlinear_workspace * w)

   These functions return the number of iterations performed so far.
   The iteration counter is updated on each call to the
   :code:`_iterate` functions above, and reset to 0 in the
   :code:`_init` functions.

.. function:: int gsl_multifit_nlinear_rcond (double * rcond, const gsl_multifit_nlinear_workspace * w)
              int gsl_multilarge_nlinear_rcond (double * rcond, const gsl_multilarge_nlinear_workspace * w)

   This function estimates the reciprocal condition number
   of the Jacobian matrix at the current position :math:`x` and
   stores it in :data:`rcond`. The computed value is only an estimate
   to give the user a guideline as to the conditioning of their particular
   problem. Its calculation is based on which factorization
   method is used (Cholesky, QR, or SVD). 

   * For the Cholesky solver, the matrix :math:`J^T J` is factored at each
     iteration. Therefore this function will estimate the 1-norm condition number
     :math:`rcond^2 = 1/(||J^T J||_1 \cdot ||(J^T J)^{-1}||_1)`

   * For the QR solver, :math:`J` is factored as :math:`J = Q R` at each
     iteration. For simplicity, this function calculates the 1-norm conditioning of
     only the :math:`R` factor, :math:`rcond = 1 / (||R||_1 \cdot ||R^{-1}||_1)`.
     This can be computed efficiently since :math:`R` is upper triangular.

   * For the SVD solver, in order to efficiently solve the trust region
     subproblem, the matrix which is factored is :math:`J D^{-1}`, instead of
     :math:`J` itself. The resulting singular values are used to provide
     the 2-norm reciprocal condition number, as :math:`rcond = \sigma_{min} / \sigma_{max}`.
     Note that when using |More| scaling, :math:`D \ne I` and the resulting
     :data:`rcond` estimate may be significantly different from the true
     :data:`rcond` of :math:`J` itself.

.. function:: double gsl_multifit_nlinear_avratio (const gsl_multifit_nlinear_workspace * w)
              double gsl_multilarge_nlinear_avratio (const gsl_multilarge_nlinear_workspace * w)

   This function returns the current ratio :math:`|a| / |v|` of the acceleration correction term to
   the velocity step term. The acceleration term is computed only by the
   :type:`gsl_multifit_nlinear_trs_lmaccel` and :type:`gsl_multilarge_nlinear_trs_lmaccel` methods, so
   this ratio will be zero for other TRS methods.

.. index::
   single: nonlinear fitting, stopping parameters, convergence

Testing for Convergence
=======================

A minimization procedure should stop when one of the following conditions is
true:

* A minimum has been found to within the user-specified precision.
* A user-specified maximum number of iterations has been reached.
* An error has occurred.

The handling of these conditions is under user control.  The functions
below allow the user to test the current estimate of the best-fit
parameters in several standard ways.

.. function:: int gsl_multifit_nlinear_test (const double xtol, const double gtol, const double ftol, int * info, const gsl_multifit_nlinear_workspace * w)
              int gsl_multilarge_nlinear_test (const double xtol, const double gtol, const double ftol, int * info, const gsl_multilarge_nlinear_workspace * w)

   These functions test for convergence of the minimization method
   using the following criteria:

   * Testing for a small step size relative to the current parameter vector

     .. math:: |\delta_i| \le xtol (|x_i| + xtol)

     for each :math:`0 <= i < p`. Each element of the step vector :math:`\delta`
     is tested individually in case the different parameters have widely
     different scales. Adding :data:`xtol` to :math:`|x_i|` helps the test avoid
     breaking down in situations where the true solution value :math:`x_i = 0`.
     If this test succeeds, :data:`info` is set to 1 and the function
     returns :macro:`GSL_SUCCESS`.

     A general guideline for selecting the step tolerance is to choose
     :math:`xtol = 10^{-d}` where :math:`d` is the number of accurate
     decimal digits desired in the solution :math:`x`. See Dennis and
     Schnabel for more information.

   * Testing for a small gradient (:math:`g = \nabla \Phi(x) = J^T f`)
     indicating a local function minimum:

     .. only:: not texinfo

        .. math:: \max_i |g_i \times \max(x_i, 1)| \le gtol \times \max(\Phi(x), 1)

     .. only:: texinfo

        ::

           ||g||_inf <= gtol

     This expression tests whether the ratio
     :math:`(\nabla \Phi)_i x_i / \Phi` is small. Testing this scaled gradient
     is a better than :math:`\nabla \Phi` alone since it is a dimensionless
     quantity and so independent of the scale of the problem. The
     :code:`max` arguments help ensure the test doesn't break down in
     regions where :math:`x_i` or :math:`\Phi(x)` are close to 0.
     If this test succeeds, :data:`info` is set to 2 and the function
     returns :macro:`GSL_SUCCESS`.

     A general guideline for choosing the gradient tolerance is to set
     :code:`gtol = GSL_DBL_EPSILON^(1/3)`. See Dennis and Schnabel for
     more information.

   If none of the tests succeed, :data:`info` is set to 0 and the
   function returns :macro:`GSL_CONTINUE`, indicating further iterations
   are required.

High Level Driver
=================

These routines provide a high level wrapper that combines the iteration
and convergence testing for easy use.

.. function:: int gsl_multifit_nlinear_driver (const size_t maxiter, const double xtol, const double gtol, const double ftol, void (* callback)(const size_t iter, void * params, const gsl_multifit_linear_workspace * w), void * callback_params, int * info, gsl_multifit_nlinear_workspace * w)
              int gsl_multilarge_nlinear_driver (const size_t maxiter, const double xtol, const double gtol, const double ftol, void (* callback)(const size_t iter, void * params, const gsl_multilarge_linear_workspace * w), void * callback_params, int * info, gsl_multilarge_nlinear_workspace * w)

   These functions iterate the nonlinear least squares solver :data:`w` for a
   maximum of :data:`maxiter` iterations. After each iteration, the system is
   tested for convergence with the error tolerances :data:`xtol`, :data:`gtol` and :data:`ftol`.
   Additionally, the user may supply a callback function :data:`callback`
   which is called after each iteration, so that the user may save or print
   relevant quantities for each iteration. The parameter :data:`callback_params`
   is passed to the :data:`callback` function. The parameters :data:`callback`
   and :data:`callback_params` may be set to :code:`NULL` to disable this feature.
   Upon successful convergence, the function returns :macro:`GSL_SUCCESS`
   and sets :data:`info` to the reason for convergence (see
   :func:`gsl_multifit_nlinear_test`). If the function has not
   converged after :data:`maxiter` iterations, :macro:`GSL_EMAXITER` is
   returned. In rare cases, during an iteration the algorithm may
   be unable to find a new acceptable step :math:`\delta` to take. In
   this case, :macro:`GSL_ENOPROG` is returned indicating no further
   progress can be made. If your problem is having difficulty converging,
   see :ref:`sec_nlinear-troubleshooting` for further guidance.

.. index::
   single: best-fit parameters, covariance
   single: least squares, covariance of best-fit parameters
   single: covariance matrix, nonlinear fits

Covariance matrix of best fit parameters
========================================

.. function:: int gsl_multifit_nlinear_covar (const gsl_matrix * J, const double epsrel, gsl_matrix * covar)
              int gsl_multilarge_nlinear_covar (gsl_matrix * covar, gsl_multilarge_nlinear_workspace * w)

   This function computes the covariance matrix of best-fit parameters
   using the Jacobian matrix :data:`J` and stores it in :data:`covar`.
   The parameter :data:`epsrel` is used to remove linear-dependent columns
   when :data:`J` is rank deficient.

   The covariance matrix is given by,

   .. math:: C = (J^T J)^{-1}

   or in the weighted case,

   .. math:: C = (J^T W J)^{-1}

   and is computed using the factored form of the Jacobian (Cholesky, QR, or SVD).
   Any columns of :math:`R` which satisfy 

   .. math:: |R_{kk}| \leq epsrel |R_{11}|

   are considered linearly-dependent and are excluded from the covariance
   matrix (the corresponding rows and columns of the covariance matrix are
   set to zero).

   If the minimisation uses the weighted least-squares function
   :math:`f_i = (Y(x, t_i) - y_i) / \sigma_i` then the covariance
   matrix above gives the statistical error on the best-fit parameters
   resulting from the Gaussian errors :math:`\sigma_i` on 
   the underlying data :math:`y_i`.  This can be verified from the relation 
   :math:`\delta f = J \delta c` and the fact that the fluctuations in :math:`f`
   from the data :math:`y_i` are normalised by :math:`\sigma_i` and 
   so satisfy
   
   .. only:: not texinfo
   
      .. math:: \langle \delta f \delta f^T \rangle = I

   .. only:: texinfo

      ::

         <\delta f \delta f^T> = I

   For an unweighted least-squares function :math:`f_i = (Y(x, t_i) - y_i)`
   the covariance matrix above should be multiplied by the variance
   of the residuals about the best-fit :math:`\sigma^2 = \sum (y_i - Y(x,t_i))^2 / (n-p)`
   to give the variance-covariance
   matrix :math:`\sigma^2 C`.  This estimates the statistical error on the
   best-fit parameters from the scatter of the underlying data.

   For more information about covariance matrices see
   :ref:`Linear Least-Squares Overview <sec_lls-overview>`.

.. _sec_nlinear-troubleshooting:

Troubleshooting
===============

When developing a code to solve a nonlinear least squares problem,
here are a few considerations to keep in mind.

#. The most common difficulty is the accurate implementation of the Jacobian
   matrix. If the analytic Jacobian is not properly provided to the
   solver, this can hinder and many times prevent convergence of the method.
   When developing a new nonlinear least squares code, it often helps
   to compare the program output with the internally computed finite
   difference Jacobian and the user supplied analytic Jacobian. If there
   is a large difference in coefficients, it is likely the analytic
   Jacobian is incorrectly implemented.

#. If your code is having difficulty converging, the next thing to
   check is the starting point provided to the solver. The methods
   of this chapter are local methods, meaning if you provide a starting
   point far away from the true minimum, the method may converge to
   a local minimum or not converge at all. Sometimes it is possible
   to solve a linearized approximation to the nonlinear problem,
   and use the linear solution as the starting point to the nonlinear
   problem.

#. If the various parameters of the coefficient vector :math:`x`
   vary widely in magnitude, then the problem is said to be badly scaled.
   The methods of this chapter do attempt to automatically rescale
   the elements of :math:`x` to have roughly the same order of magnitude,
   but in extreme cases this could still cause problems for convergence.
   In these cases it is recommended for the user to scale their
   parameter vector :math:`x` so that each parameter spans roughly the
   same range, say :math:`[-1,1]`. The solution vector can be backscaled
   to recover the original units of the problem.

Examples
========

The following example programs demonstrate the nonlinear least
squares fitting capabilities.

Exponential Fitting Example
---------------------------

The following example program fits a weighted exponential model with
background to experimental data, :math:`Y = A \exp(-\lambda t) + b`. The
first part of the program sets up the functions :func:`expb_f` and
:func:`expb_df` to calculate the model and its Jacobian.  The appropriate
fitting function is given by,

.. math:: f_i = (A \exp(-\lambda t_i) + b) - y_i

where we have chosen :math:`t_i = i T / (N - 1)`, where :math:`N` is the number
of data points fitted, so that :math:`t_i \in [0, T]`. The Jacobian matrix :math:`J` is
the derivative of these functions with respect to the three parameters
(:math:`A`, :math:`\lambda`, :math:`b`).  It is given by,

.. only:: not texinfo

   .. math:: J_{ij} = {\partial f_i \over \partial x_j}

.. only:: texinfo

   ::

      J_{ij} = d f_i / d x_j

where :math:`x_0 = A`, :math:`x_1 = \lambda` and :math:`x_2 = b`.
The :math:`i`-th row of the Jacobian is therefore

.. only:: not texinfo

   .. math::

      J_{i\cdot} =
      \left(
        \begin{array}{ccc}
          \exp(-\lambda t_i) & -t_i A \exp(-\lambda t_i) & 1
        \end{array}
      \right)

.. only:: texinfo

   ::

      J(i,:) = [ \exp(-\lambda t_i) ; -t_i A \exp(-\lambda t_i) ; 1 ]

The main part of the program sets up a Levenberg-Marquardt solver and
some simulated random data. The data uses the known parameters
(5.0,0.1,1.0) combined with Gaussian noise (standard deviation = 0.1)
with a maximum time :math:`T = 40` and :math:`N = 100` timesteps.
The initial guess for the parameters is
chosen as (1.0, 1.0, 0.0). The iteration terminates when the relative
change in x is smaller than :math:`10^{-8}`, or when the magnitude of
the gradient falls below :math:`10^{-8}`. Here are the results of running
the program::

  iter  0: A = 1.0000, lambda = 1.0000, b = 0.0000, cond(J) =      inf, |f(x)| = 100.8779
  iter  1: A = 1.2692, lambda = 0.3924, b = 0.0443, cond(J) =  69.5973, |f(x)| = 97.1734
  iter  2: A = 1.6749, lambda = 0.1685, b = 0.1072, cond(J) =  29.5220, |f(x)| = 88.6636
  iter  3: A = 2.5579, lambda = 0.0544, b = 0.2552, cond(J) =  22.9334, |f(x)| = 42.7765
  iter  4: A = 3.0167, lambda = 0.0472, b = 0.3704, cond(J) = 120.2912, |f(x)| = 23.0102
  iter  5: A = 3.3590, lambda = 0.0455, b = 0.4321, cond(J) = 266.5620, |f(x)| = 16.0680
  iter  6: A = 3.6552, lambda = 0.0479, b = 0.4426, cond(J) = 343.8946, |f(x)| = 14.6421
  iter  7: A = 3.9546, lambda = 0.0532, b = 0.4897, cond(J) = 301.4985, |f(x)| = 13.5266
  iter  8: A = 4.1421, lambda = 0.0633, b = 0.6783, cond(J) = 203.9164, |f(x)| = 12.3149
  iter  9: A = 4.3752, lambda = 0.0800, b = 0.9228, cond(J) = 158.2267, |f(x)| = 11.2475
  iter 10: A = 4.6371, lambda = 0.0891, b = 0.9588, cond(J) = 136.6189, |f(x)| = 10.5457
  iter 11: A = 4.7684, lambda = 0.0937, b = 0.9860, cond(J) = 125.4740, |f(x)| = 10.4753
  iter 12: A = 4.7977, lambda = 0.0948, b = 0.9917, cond(J) = 120.1098, |f(x)| = 10.4723
  iter 13: A = 4.8006, lambda = 0.0949, b = 0.9924, cond(J) = 118.9113, |f(x)| = 10.4723
  iter 14: A = 4.8008, lambda = 0.0949, b = 0.9925, cond(J) = 118.7661, |f(x)| = 10.4723
  iter 15: A = 4.8008, lambda = 0.0949, b = 0.9925, cond(J) = 118.7550, |f(x)| = 10.4723
  iter 16: A = 4.8008, lambda = 0.0949, b = 0.9925, cond(J) = 118.7543, |f(x)| = 10.4723
  iter 17: A = 4.8008, lambda = 0.0949, b = 0.9925, cond(J) = 118.7543, |f(x)| = 10.4723
  iter 18: A = 4.8008, lambda = 0.0949, b = 0.9925, cond(J) = 118.7543, |f(x)| = 10.4723
  summary from method 'trust-region/levenberg-marquardt'
  number of iterations: 18
  function evaluations: 25
  Jacobian evaluations: 19
  reason for stopping: small step size
  initial |f(x)| = 100.877904
  final   |f(x)| = 10.472268
  chisq/dof = 1.1306
  A      = 4.80085 +/- 0.17652
  lambda = 0.09488 +/- 0.00527
  b      = 0.99249 +/- 0.04419
  status = success

The approximate values of the parameters are found correctly, and the
chi-squared value indicates a good fit (the chi-squared per degree of
freedom is approximately 1).  In this case the errors on the parameters
can be estimated from the square roots of the diagonal elements of the
covariance matrix. If the chi-squared value shows a poor fit (i.e.
:math:`\chi^2/(n-p) \gg 1`
then the error estimates obtained from the
covariance matrix will be too small.  In the example program the error estimates
are multiplied by :math:`\sqrt{\chi^2/(n-p)}`
in this case, a common way of increasing the
errors for a poor fit.  Note that a poor fit will result from the use
of an inappropriate model, and the scaled error estimates may then
be outside the range of validity for Gaussian errors.

Additionally, we see that the condition number of :math:`J(x)` stays
reasonably small throughout the iteration. This indicates we could
safely switch to the Cholesky solver for speed improvement,
although this particular system is too small to really benefit.

:numref:`fig_fit-exp` shows the fitted curve with the original data.

.. _fig_fit-exp:

.. figure:: /images/fit-exp.png
   :scale: 60%

   Exponential fitted curve with data

.. include:: examples/nlfit.c
   :code:

Geodesic Acceleration Example 1
-------------------------------

The following example program minimizes a modified Rosenbrock function,
which is characterized by a narrow canyon with steep walls. The
starting point is selected high on the canyon wall, so the solver
must first find the canyon bottom and then navigate to the minimum.
The problem is solved both with and without using geodesic acceleration
for comparison. The cost function is given by

.. only:: not texinfo

   .. math::

      \Phi(x) &= {1 \over 2} (f_1^2 + f_2^2) \\
      f_1 &= 100 \left( x_2 - x_1^2 \right) \\
      f_2 &= 1 - x_1

.. only:: texinfo

   ::

      Phi(x) = 1/2 (f1^2 + f2^2)
      f1 = 100 ( x2 - x1^2 )
      f2 = 1 - x1

The Jacobian matrix is

.. only:: not texinfo

   .. math::

      J =
      \left(
        \begin{array}{cc}
          {\partial f_1 \over \partial x_1} & {\partial f_1 \over \partial x_2} \\
          {\partial f_2 \over \partial x_1} & {\partial f_2 \over \partial x_2}
        \end{array}
      \right) =
      \left(
        \begin{array}{cc}
          -200 x_1 & 100 \\
          -1 & 0
        \end{array}
      \right)

.. only:: texinfo

   ::

      J = [ -200*x1 100  ]
          [   -1     0   ]

In order to use geodesic acceleration, the user must provide
the second directional derivative of each residual in the
velocity direction,
:math:`D_v^2 f_i = \sum_{\alpha\beta} v_{\alpha} v_{\beta} \partial_{\alpha} \partial_{\beta} f_i`.
The velocity vector :math:`v` is provided by the solver. For this example,
these derivatives are

.. only:: not texinfo

   .. math::

      f_{vv} =
      D_v^2
      \left(
        \begin{array}{c}
          f_1 \\
          f_2
        \end{array}
      \right) =
      \left(
        \begin{array}{c}
          -200 v_1^2 \\
          0
        \end{array}
      \right)

.. only:: texinfo

   ::

      fvv = [ -200 v1^2 ]
            [     0     ]

The solution of this minimization problem is

.. only:: not texinfo

   .. math::

      x^{*} &=
      \left(
        \begin{array}{c}
          1 \\
          1
        \end{array}
      \right) \\
      \Phi(x^{*}) &= 0

.. only:: texinfo

   ::

      x* = [ 1 ; 1 ]
      Phi(x*) = 0

The program output is shown below::

  === Solving system without acceleration ===
  NITER         = 53
  NFEV          = 56
  NJEV          = 54
  NAEV          = 0
  initial cost  = 2.250225000000e+04
  final cost    = 6.674986031430e-18
  final x       = (9.999999974165e-01, 9.999999948328e-01)
  final cond(J) = 6.000096055094e+02
  === Solving system with acceleration ===
  NITER         = 15
  NFEV          = 17
  NJEV          = 16
  NAEV          = 16
  initial cost  = 2.250225000000e+04
  final cost    = 7.518932873279e-19
  final x       = (9.999999991329e-01, 9.999999982657e-01)
  final cond(J) = 6.000097233278e+02

.. _fig_nlfit2:

.. figure:: /images/nlfit2.png

   Paths taken by solver for Rosenbrock function

We can see that enabling geodesic acceleration requires less
than a third of the number of Jacobian evaluations in order to locate
the minimum. The path taken by both methods is shown in :numref:`fig_nlfit2`.
The contours show the cost function
:math:`\Phi(x_1,x_2)`. We see that both methods quickly
find the canyon bottom, but the geodesic acceleration method
navigates along the bottom to the solution with significantly
fewer iterations.

The program is given below.

.. include:: examples/nlfit2.c
   :code:

Geodesic Acceleration Example 2
-------------------------------

The following example fits a set of data to a Gaussian model
using the Levenberg-Marquardt method with geodesic acceleration.
The cost function is

.. only:: not texinfo

   .. math::

      \Phi(x) &= {1 \over 2} \sum_i f_i^2 \\
      f_i &= y_i - Y(a,b,c;t_i)

.. only:: texinfo

   ::

      Phi(x) = 1/2 \sum_i f_i^2
      f_i = y_i - Y(a,b,c;t_i)

where :math:`y_i` is the measured data point at time :math:`t_i`, and
the model is specified by

.. only:: not texinfo

   .. math::

      Y(a,b,c;t) = a \exp{
      \left[
      -{1 \over 2}
      \left(
      { t - b \over c }
      \right)^2
      \right]
      }

.. only:: texinfo

   ::

      Y(a,b,c;t) = a exp(-1/2 ((t-b)/c)^2)

The parameters :math:`a,b,c` represent the amplitude, mean, and width of the Gaussian
respectively. The program below generates the :math:`y_i` data on :math:`[0,1]` using
the values :math:`a = 5`, :math:`b = 0.4`, :math:`c = 0.15` and adding random noise.
The :math:`i`-th row of the Jacobian is

.. only:: not texinfo

   .. math::

      J_{i,:} =
      \left(
        \begin{array}{ccc}
          {\partial f_i \over \partial a} & {\partial f_i \over \partial b} & {\partial f_i \over \partial c}
        \end{array}
      \right) =
      \left(
        \begin{array}{ccc}
          -e_i & -{a \over c} z_i e_i & -{a \over c} z_i^2 e_i
        \end{array}
      \right)

.. only:: texinfo

   ::

      J(i,:) = ( -e_i  -(a/c)*z_i*e_i  -(a/c)*z_i^2*e_i )

where

.. only:: not texinfo

   .. math::

      z_i &= { t_i - b \over c} \\
      e_i &= \exp{\left( -{1 \over 2} z_i^2 \right)}

.. only:: texinfo

   ::

      z_i = (t_i - b) / c
      e_i = \exp(-1/2 z_i^2)

In order to use geodesic acceleration, we need the second directional derivative
of the residuals in the velocity direction,
:math:`D_v^2 f_i = \sum_{\alpha\beta} v_{\alpha} v_{\beta} \partial_{\alpha} \partial_{\beta} f_i`,
where :math:`v` is provided by the solver. To compute this, it is helpful to make a table of
all second derivatives of the residuals :math:`f_i` with respect to each combination of model parameters.
This table is

.. only:: not texinfo

   .. math::

      \begin{array}{cccc}
        & {\partial \over \partial a} & {\partial \over \partial b} & {\partial \over \partial c} \cr
        {\partial \over \partial a} & 0 & -{z_i \over c} e_i & -{z_i^2 \over c} e_i \cr
        {\partial \over \partial b} & & {a \over c^2} \left( 1 - z_i^2 \right) e_i & {a \over c^2} z_i \left( 2 - z_i^2 \right) e_i \cr
        {\partial \over \partial c} & & & {a \over c^2} z_i^2 \left( 3 - z_i^2 \right) e_i
      \end{array}

The lower half of the table is omitted since it is symmetric. Then, the second directional derivative
of :math:`f_i` is

.. only:: not texinfo

   .. math:: D_v^2 f_i = v_a^2 \partial_a^2 f_i + 2 v_a v_b \partial_a \partial_b f_i + 2 v_a v_c \partial_a \partial_c f_i + v_b^2 \partial_b^2 f_i + 2 v_b v_c \partial_b \partial_c f_i + v_c^2 \partial_c^2 f_i

.. only:: texinfo

   ::

      D_v^2 f_i = v_a^2 (d/da)^2 f_i + 2 v_a v_b (d/da) (d/db) f_i + 2 v_a v_c (d/da) (d/dc) f_i + v_b^2 (d/db)^2 f_i + 2 v_b v_c (d/db) (d/dc) f_i + v_c^2 (d/dc)^2 f_i

The factors of 2 come from the symmetry of the mixed second partial derivatives.
The iteration is started using the initial guess :math:`a = 1, b = 0, c = 1`.
The program output is shown below::

  iter  0: a = 1.0000, b = 0.0000, c = 1.0000, |a|/|v| = 0.0000 cond(J) =      inf, |f(x)| = 35.4785
  iter  1: a = 1.5708, b = 0.5321, c = 0.5219, |a|/|v| = 0.3093 cond(J) =  29.0443, |f(x)| = 31.1042
  iter  2: a = 1.7387, b = 0.4040, c = 0.4568, |a|/|v| = 0.1199 cond(J) =   3.5256, |f(x)| = 28.7217
  iter  3: a = 2.2340, b = 0.3829, c = 0.3053, |a|/|v| = 0.3308 cond(J) =   4.5121, |f(x)| = 23.8074
  iter  4: a = 3.2275, b = 0.3952, c = 0.2243, |a|/|v| = 0.2784 cond(J) =   8.6499, |f(x)| = 15.6003
  iter  5: a = 4.3347, b = 0.3974, c = 0.1752, |a|/|v| = 0.2029 cond(J) =  15.1732, |f(x)| = 7.5908
  iter  6: a = 4.9352, b = 0.3992, c = 0.1536, |a|/|v| = 0.1001 cond(J) =  26.6621, |f(x)| = 4.8402
  iter  7: a = 5.0716, b = 0.3994, c = 0.1498, |a|/|v| = 0.0166 cond(J) =  34.6922, |f(x)| = 4.7103
  iter  8: a = 5.0828, b = 0.3994, c = 0.1495, |a|/|v| = 0.0012 cond(J) =  36.5422, |f(x)| = 4.7095
  iter  9: a = 5.0831, b = 0.3994, c = 0.1495, |a|/|v| = 0.0000 cond(J) =  36.6929, |f(x)| = 4.7095
  iter 10: a = 5.0831, b = 0.3994, c = 0.1495, |a|/|v| = 0.0000 cond(J) =  36.6975, |f(x)| = 4.7095
  iter 11: a = 5.0831, b = 0.3994, c = 0.1495, |a|/|v| = 0.0000 cond(J) =  36.6976, |f(x)| = 4.7095
  NITER         = 11
  NFEV          = 18
  NJEV          = 12
  NAEV          = 17
  initial cost  = 1.258724737288e+03
  final cost    = 2.217977560180e+01
  final x       = (5.083101559156e+00, 3.994484109594e-01, 1.494898e-01)
  final cond(J) = 3.669757713403e+01

We see the method converges after 11 iterations. For comparison the standard
Levenberg-Marquardt method requires 26 iterations and so the Gaussian fitting
problem benefits substantially from the geodesic acceleration correction. The
column marked :code:`|a|/|v|` above shows the ratio of the acceleration term
to the velocity term as the iteration progresses. Larger values of this
ratio indicate that the geodesic acceleration correction term is contributing
substantial information to the solver relative to the standard LM velocity step.

The data and fitted model are shown in :numref:`fig_nlfit2b`.

.. _fig_nlfit2b:

.. figure:: /images/nlfit2b.png

   Gaussian model fitted to data

The program is given below.

.. include:: examples/nlfit2b.c
   :code:

Comparing TRS Methods Example
-----------------------------

The following program compares all available nonlinear least squares
trust-region subproblem (TRS) methods on the Branin function, a common
optimization test problem. The cost function is

.. only:: not texinfo

   .. math::

      \Phi(x) &= {1 \over 2} (f_1^2 + f_2^2) \\
      f_1 &= x_2 + a_1 x_1^2 + a_2 x_1 + a_3 \\
      f_2 &= \sqrt{a_4} \sqrt{1 + (1 - a_5) \cos{x_1}}

.. only:: texinfo

   ::

      \Phi(x) &= 1/2 (f_1^2 + f_2^2)
      f_1 &= x_2 + a_1 x_1^2 + a_2 x_1 + a_3
      f_2 &= sqrt(a_4) sqrt(1 + (1 - a_5) cos(x_1))

with :math:`a_1 = -{5.1 \over 4 \pi^2}, a_2 = {5 \over \pi}, a_3 = -6, a_4 = 10, a_5 = {1 \over 8\pi}`.
There are three minima of this function in the range
:math:`(x_1,x_2) \in [-5,15] \times [-5,15]`. The program
below uses the starting point :math:`(x_1,x_2) = (6,14.5)`
and calculates the solution with all available nonlinear
least squares TRS methods. The program output is shown below::

  Method                    NITER  NFEV  NJEV  Initial Cost  Final cost   Final cond(J) Final x        
  levenberg-marquardt       20     27    21    1.9874e+02    3.9789e-01   6.1399e+07    (-3.14e+00, 1.23e+01)
  levenberg-marquardt+accel 27     36    28    1.9874e+02    3.9789e-01   1.4465e+07    (3.14e+00, 2.27e+00)
  dogleg                    23     64    23    1.9874e+02    3.9789e-01   5.0692e+08    (3.14e+00, 2.28e+00)
  double-dogleg             24     69    24    1.9874e+02    3.9789e-01   3.4879e+07    (3.14e+00, 2.27e+00)
  2D-subspace               23     54    24    1.9874e+02    3.9789e-01   2.5142e+07    (3.14e+00, 2.27e+00)

The first row of output above corresponds to standard Levenberg-Marquardt, while
the second row includes geodesic acceleration. We see that the standard LM method
converges to the minimum at :math:`(-\pi,12.275)` and also uses the least number
of iterations and Jacobian evaluations. All other methods converge to the minimum
:math:`(\pi,2.275)` and perform similarly in terms of number of Jacobian evaluations.
We see that :math:`J` is fairly ill-conditioned
at both minima, indicating that the QR (or SVD) solver is the best choice for this problem.
Since there are only two parameters in this optimization problem, we can easily
visualize the paths taken by each method, which are shown in :numref:`fig_nlfit3`.
The figure shows contours of the cost function :math:`\Phi(x_1,x_2)` which exhibits
three global minima in the range :math:`[-5,15] \times [-5,15]`. The paths taken
by each solver are shown as colored lines.

.. _fig_nlfit3:

.. figure:: /images/nlfit3.png
   :scale: 60%

   Paths taken for different TRS methods for the Branin function

The program is given below.

.. include:: examples/nlfit3.c
   :code:

Large Nonlinear Least Squares Example
-------------------------------------

The following program illustrates the large nonlinear least
squares solvers on a system with significant sparse structure
in the Jacobian. The cost function is

.. only:: not texinfo

   .. math::

      \Phi(x) &= {1 \over 2} \sum_{i=1}^{p+1} f_i^2 \\
      f_i &= \sqrt{\alpha} (x_i - 1), \quad 1 \le i \le p \\
      f_{p+1} &= ||x||^2 - {1 \over 4}

.. only:: texinfo

   ::

      \Phi(x) &= 1/2 \sum_{i=1}^{p+1} f_i^2
      f_i &= \sqrt{\alpha} (x_i - 1), 1 \le i \le p
      f_{p+1} &= ||x||^2 - 1/4

with :math:`\alpha = 10^{-5}`. The residual :math:`f_{p+1}` imposes a constraint on the :math:`p`
parameters :math:`x`, to ensure that :math:`||x||^2 \approx {1 \over 4}`.
The :math:`(p+1)`-by-:math:`p` Jacobian for this system is

.. only:: not texinfo

   .. math::

      J(x) =
      \left(
        \begin{array}{c}
          \sqrt{\alpha} I_p \\
          2 x^T
        \end{array}
      \right)

.. only:: texinfo

   ::

     J(x) = [ \sqrt{alpha} I_p; 2 x^T ]

and the normal equations matrix is

.. math:: J^T J = \alpha I_p + 4 x x^T

Finally, the second directional derivative of :math:`f` for the
geodesic acceleration method is

.. only:: not texinfo

   .. math::

      f_{vv} = D_v^2 f =
      \left(
        \begin{array}{c}
          0 \\
          2 ||v||^2
        \end{array}
      \right)

.. only:: texinfo

   ::

      fvv = [     0     ]
            [ 2 ||v||^2 ]

Since the upper :math:`p`-by-:math:`p` block of :math:`J` is diagonal,
this sparse structure should be exploited in the nonlinear solver.
For comparison, the following program solves the system for :math:`p = 2000`
using the dense direct Cholesky solver based on the normal equations matrix
:math:`J^T J`, as well as the iterative Steihaug-Toint solver, based on
sparse matrix-vector products :math:`J u` and :math:`J^T u`. The
program output is shown below::

  Method                    NITER NFEV NJUEV NJTJEV NAEV Init Cost  Final cost cond(J) Final |x|^2 Time (s)  
  levenberg-marquardt       25    31   26    26     0    7.1218e+18 1.9555e-02 447.50  2.5044e-01  46.28
  levenberg-marquardt+accel 22    23   45    23     22   7.1218e+18 1.9555e-02 447.64  2.5044e-01  33.92
  dogleg                    37    87   36    36     0    7.1218e+18 1.9555e-02 447.59  2.5044e-01  56.05
  double-dogleg             35    88   34    34     0    7.1218e+18 1.9555e-02 447.62  2.5044e-01  52.65
  2D-subspace               37    88   36    36     0    7.1218e+18 1.9555e-02 447.71  2.5044e-01  59.75
  steihaug-toint            35    88   345   0      0    7.1218e+18 1.9555e-02 inf     2.5044e-01  0.09

The first five rows use methods based on factoring the dense :math:`J^T J` matrix
while the last row uses the iterative Steihaug-Toint method. While the number
of Jacobian matrix-vector products (NJUEV) is less for the dense methods, the added time
to construct and factor the :math:`J^T J` matrix (NJTJEV) results in a much larger runtime than the
iterative method (see last column).

The program is given below.

.. include:: examples/nlfit4.c
   :code:

References and Further Reading
==============================

The following publications are relevant to the algorithms described
in this section,

* J.J. |More|, *The Levenberg-Marquardt Algorithm: Implementation and
  Theory*, Lecture Notes in Mathematics, v630 (1978), ed G. Watson.

* H. B. Nielsen, "Damping Parameter in Marquardt's Method",
  IMM Department of Mathematical Modeling, DTU, Tech. Report IMM-REP-1999-05
  (1999).

* K. Madsen and H. B. Nielsen, "Introduction to Optimization and Data
  Fitting", IMM Department of Mathematical Modeling, DTU, 2010.

* J. E. Dennis and R. B. Schnabel, Numerical Methods for Unconstrained
  Optimization and Nonlinear Equations, SIAM, 1996.

* M. K. Transtrum, B. B. Machta, and J. P. Sethna,
  Geometry of nonlinear least squares with applications to sloppy models and optimization,
  Phys. Rev. E 83, 036701, 2011.

* M. K. Transtrum and J. P. Sethna, Improvements to the Levenberg-Marquardt
  algorithm for nonlinear least-squares minimization, arXiv:1201.5885, 2012.

* J.J. |More|, B.S. Garbow, K.E. Hillstrom, "Testing Unconstrained
  Optimization Software", ACM Transactions on Mathematical Software, Vol
  7, No 1 (1981), p 17--41.

* H. B. Nielsen, "UCTP Test Problems for Unconstrained Optimization",
  IMM Department of Mathematical Modeling, DTU, Tech. Report IMM-REP-2000-17
  (2000).
*******************
Contributors to GSL
*******************

.. include:: include.rst

(See the :file:`AUTHORS` file in the distribution for up-to-date information.)

Mark Galassi

  Conceived GSL (with James Theiler) and wrote the design document.  Wrote
  the simulated annealing package and the relevant chapter in the manual.

James Theiler

  Conceived GSL (with Mark Galassi).  Wrote the random number generators
  and the relevant chapter in this manual.

Jim Davies

  Wrote the statistical routines and the relevant chapter in this
  manual.

Brian Gough

  FFTs, numerical integration, random number generators and distributions,
  root finding, minimization and fitting, polynomial solvers, complex
  numbers, physical constants, permutations, vector and matrix functions,
  histograms, statistics, ieee-utils, revised |cblas| Level 2 & 3,
  matrix decompositions, eigensystems, cumulative distribution functions,
  testing, documentation and releases.

Reid Priedhorsky

  Wrote and documented the initial version of the root finding routines
  while at Los Alamos National Laboratory, Mathematical Modeling and
  Analysis Group.  

.. email: reid@reidster.net

Gerard Jungman

  Special Functions, Series acceleration, ODEs, BLAS, Linear Algebra,
  Eigensystems, Hankel Transforms.

Patrick Alken

  Implementation of nonsymmetric and generalized eigensystems, B-splines,
  linear and nonlinear least squares, matrix decompositions,
  associated Legendre functions, running statistics, sparse matrices,
  and sparse linear algebra.

Mike Booth

  Wrote the Monte Carlo library.

Jorma Olavi Tähtinen

  Wrote the initial complex arithmetic functions.

Thomas Walter 

  Wrote the initial heapsort routines and Cholesky decomposition.

Fabrice Rossi

  Multidimensional minimization.

Carlo Perassi

  Implementation of the random number generators in Knuth's
  *Seminumerical Algorithms*, 3rd Ed.

Szymon Jaroszewicz 

  Wrote the routines for generating combinations.

.. <sj@cs.umb.edu>

Nicolas Darnis

  Wrote the cyclic functions and the initial functions for canonical 
  permutations.

Jason H. Stover

  Wrote the major cumulative distribution functions.

.. (jason@sakla.net) 

Ivo Alxneit

  Wrote the routines for wavelet transforms.

Tuomo Keskitalo

  Improved the implementation of the ODE solvers and wrote the
  ode-initval2 routines.

Lowell Johnson

  Implementation of the Mathieu functions.

Rhys Ulerich 

  Wrote the multiset routines.

Pavel Holoborodko 

  Wrote the fixed order Gauss-Legendre quadrature routines.

Pedro Gonnet

  Wrote the |cquad| integration routines.

Thanks to Nigel Lowry for help in proofreading the manual.

The non-symmetric eigensystems routines contain code based on the
LAPACK linear algebra library.  LAPACK is distributed under the
following license::

  Copyright (c) 1992-2006 The University of Tennessee.  All rights reserved.

  Redistribution and use in source and binary forms, with or without
  modification, are permitted provided that the following conditions are
  met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer. 
  
  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer listed
    in this license in the documentation and/or other materials
    provided with the distribution.
  
  * Neither the name of the copyright holders nor the names of its
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.
  
  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
  ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT  
  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT 
  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  
  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
.. index::
   single: polynomials, roots of

***********
Polynomials
***********

.. include:: include.rst

This chapter describes functions for evaluating and solving polynomials.
There are routines for finding real and complex roots of quadratic and
cubic equations using analytic methods.  An iterative polynomial solver
is also available for finding the roots of general polynomials with real
coefficients (of any order).  The functions are declared in the header
file :file:`gsl_poly.h`.

.. index::
   single: polynomial evaluation
   single: evaluation of polynomials

Polynomial Evaluation
=====================

The functions described here evaluate the polynomial 

.. only:: not texinfo

   .. math::

      P(x) = c[0] + c[1] x + c[2] x^2 + \dots + c[len-1] x^{len-1}

.. only:: texinfo

   P(x) = c[0] + c[1] x + c[2] x^2 + ... + c[len-1] x^{len-1}
   
using Horner's method for stability. |inlinefns|

.. function:: double gsl_poly_eval (const double c[], const int len, const double x)

   This function evaluates a polynomial with real coefficients for the real variable :data:`x`.

.. function:: gsl_complex gsl_poly_complex_eval (const double c[], const int len, const gsl_complex z)

   This function evaluates a polynomial with real coefficients for the complex variable :data:`z`.

.. function:: gsl_complex gsl_complex_poly_complex_eval (const gsl_complex c[], const int len, const gsl_complex z)

   This function evaluates a polynomial with complex coefficients for the complex variable :data:`z`.

.. function:: int gsl_poly_eval_derivs (const double c[], const size_t lenc, const double x, double res[], const size_t lenres)

   This function evaluates a polynomial and its derivatives storing the
   results in the array :data:`res` of size :data:`lenres`.  The output array
   contains the values of :math:`d^k P(x)/d x^k` for the specified value of
   :data:`x` starting with :math:`k = 0`.

.. index::
   single: divided differences, polynomials
   single: evaluation of polynomials, in divided difference form

Divided Difference Representation of Polynomials
================================================

The functions described here manipulate polynomials stored in Newton's
divided-difference representation.  The use of divided-differences is
described in Abramowitz & Stegun sections 25.1.4 and 25.2.26, and
Burden and Faires, chapter 3, and discussed briefly below.

Given a function :math:`f(x)`, an :math:`n`\ th degree interpolating polynomial :math:`P_{n}(x)`
can be constructed which agrees with :math:`f` at :math:`n+1` distinct points
:math:`x_0,x_1,...,x_{n}`. This polynomial can be written in a
form known as Newton's divided-difference representation

.. only:: not texinfo

   .. math::

      P_{n}(x) = f(x_0) + \sum_{k=1}^n [x_0,x_1,...,x_k] (x-x_0)(x-x_1) \cdots (x-x_{k-1})

.. only:: texinfo

   P_{n}(x) = f(x_0) + \sum_{k=1}^n [x_0,x_1,...,x_k] (x-x_0)(x-x_1) ... (x-x_{k-1})

where the divided differences :math:`[x_0,x_1,...,x_k]` are defined in section 25.1.4 of
Abramowitz and Stegun. Additionally, it is possible to construct an interpolating
polynomial of degree :math:`2n+1` which also matches the first derivatives of :math:`f`
at the points :math:`x_0,x_1,...,x_n`. This is called the Hermite interpolating
polynomial and is defined as

.. only:: not texinfo

   .. math::

      H_{2n+1}(x) = f(z_0) + \sum_{k=1}^{2n+1} [z_0,z_1,...,z_k] (x-z_0)(x-z_1) \cdots (x-z_{k-1})

.. only:: texinfo

   H_{2n+1}(x) = f(z_0) + \sum_{k=1}^{2n+1} [z_0,z_1,...,z_k] (x-z_0)(x-z_1) ... (x-z_{k-1})

where the elements of :math:`z = \{x_0,x_0,x_1,x_1,...,x_n,x_n\}` are defined by
:math:`z_{2k} = z_{2k+1} = x_k`. The divided-differences :math:`[z_0,z_1,...,z_k]`
are discussed in Burden and Faires, section 3.4.

.. function:: int gsl_poly_dd_init (double dd[], const double xa[], const double ya[], size_t size)

   This function computes a divided-difference representation of the
   interpolating polynomial for the points :math:`(x, y)` stored in
   the arrays :data:`xa` and :data:`ya` of length :data:`size`.  On output the
   divided-differences of (:data:`xa`, :data:`ya`) are stored in the array
   :data:`dd`, also of length :data:`size`. Using the notation above,
   :math:`dd[k] = [x_0,x_1,...,x_k]`.

.. function:: double gsl_poly_dd_eval (const double dd[], const double xa[], const size_t size, const double x)

   This function evaluates the polynomial stored in divided-difference form
   in the arrays :data:`dd` and :data:`xa` of length :data:`size` at the point
   :data:`x`. |inlinefn|

.. function:: int gsl_poly_dd_taylor (double c[], double xp, const double dd[], const double xa[], size_t size, double w[])

   This function converts the divided-difference representation of a
   polynomial to a Taylor expansion.  The divided-difference representation
   is supplied in the arrays :data:`dd` and :data:`xa` of length :data:`size`.
   On output the Taylor coefficients of the polynomial expanded about the
   point :data:`xp` are stored in the array :data:`c` also of length
   :data:`size`.  A workspace of length :data:`size` must be provided in the
   array :data:`w`.

.. function:: int gsl_poly_dd_hermite_init (double dd[], double za[], const double xa[], const double ya[], const double dya[], const size_t size)

   This function computes a divided-difference representation of the
   interpolating Hermite polynomial for the points :math:`(x,y)` stored in
   the arrays :data:`xa` and :data:`ya` of length :data:`size`. Hermite interpolation
   constructs polynomials which also match first derivatives :math:`dy/dx` which are
   provided in the array :data:`dya` also of length :data:`size`. The first derivatives can be
   incorported into the usual divided-difference algorithm by forming a new
   dataset :math:`z = \{x_0,x_0,x_1,x_1,...\}`, which is stored in the array
   :data:`za` of length 2*\ :data:`size` on output. On output the
   divided-differences of the Hermite representation are stored in the array
   :data:`dd`, also of length 2*\ :data:`size`. Using the notation above,
   :math:`dd[k] = [z_0,z_1,...,z_k]`. The resulting Hermite polynomial
   can be evaluated by calling :func:`gsl_poly_dd_eval` and using
   :data:`za` for the input argument :data:`xa`.

.. index::
   single: quadratic equation, solving

Quadratic Equations
===================

.. function:: int gsl_poly_solve_quadratic (double a, double b, double c, double * x0, double * x1)

   This function finds the real roots of the quadratic equation,

   .. math::

      a x^2 + b x + c = 0

   The number of real roots (either zero, one or two) is returned, and
   their locations are stored in :data:`x0` and :data:`x1`.  If no real roots
   are found then :data:`x0` and :data:`x1` are not modified.  If one real root
   is found (i.e. if :math:`a=0`) then it is stored in :data:`x0`.  When two
   real roots are found they are stored in :data:`x0` and :data:`x1` in
   ascending order.  The case of coincident roots is not considered
   special.  For example :math:`(x-1)^2=0` will have two roots, which happen
   to have exactly equal values.

   The number of roots found depends on the sign of the discriminant
   :math:`b^2 - 4 a c`.  This will be subject to rounding and cancellation
   errors when computed in double precision, and will also be subject to
   errors if the coefficients of the polynomial are inexact.  These errors
   may cause a discrete change in the number of roots.  However, for
   polynomials with small integer coefficients the discriminant can always
   be computed exactly.

.. function:: int gsl_poly_complex_solve_quadratic (double a, double b, double c, gsl_complex * z0, gsl_complex * z1)

   This function finds the complex roots of the quadratic equation,

   .. math::

      a z^2 + b z + c = 0

   The number of complex roots is returned (either one or two) and the
   locations of the roots are stored in :data:`z0` and :data:`z1`.  The roots
   are returned in ascending order, sorted first by their real components
   and then by their imaginary components.  If only one real root is found
   (i.e. if :math:`a=0`) then it is stored in :data:`z0`.

.. index::
   single: cubic equation, solving

Cubic Equations
===============

.. function:: int gsl_poly_solve_cubic (double a, double b, double c, double * x0, double * x1, double * x2)

   This function finds the real roots of the cubic equation,

   .. math::

      x^3 + a x^2 + b x + c = 0

   with a leading coefficient of unity.  The number of real roots (either
   one or three) is returned, and their locations are stored in :data:`x0`,
   :data:`x1` and :data:`x2`.  If one real root is found then only :data:`x0`
   is modified.  When three real roots are found they are stored in
   :data:`x0`, :data:`x1` and :data:`x2` in ascending order.  The case of
   coincident roots is not considered special.  For example, the equation
   :math:`(x-1)^3=0` will have three roots with exactly equal values.  As
   in the quadratic case, finite precision may cause equal or
   closely-spaced real roots to move off the real axis into the complex
   plane, leading to a discrete change in the number of real roots.

.. function:: int gsl_poly_complex_solve_cubic (double a, double b, double c, gsl_complex * z0, gsl_complex * z1, gsl_complex * z2)

   This function finds the complex roots of the cubic equation,

   .. math::

      z^3 + a z^2 + b z + c = 0

   The number of complex roots is returned (always three) and the locations
   of the roots are stored in :data:`z0`, :data:`z1` and :data:`z2`.  The roots
   are returned in ascending order, sorted first by their real components
   and then by their imaginary components.

.. index::
   single: general polynomial equations, solving

General Polynomial Equations
============================

The roots of polynomial equations cannot be found analytically beyond
the special cases of the quadratic, cubic and quartic equation.  The
algorithm described in this section uses an iterative method to find the
approximate locations of roots of higher order polynomials.

.. type:: gsl_poly_complex_workspace

   This workspace contains parameters used for finding roots of general polynomials

.. function:: gsl_poly_complex_workspace * gsl_poly_complex_workspace_alloc (size_t n)

   This function allocates space for a :type:`gsl_poly_complex_workspace`
   struct and a workspace suitable for solving a polynomial with :data:`n`
   coefficients using the routine :func:`gsl_poly_complex_solve`.

   The function returns a pointer to the newly allocated
   :type:`gsl_poly_complex_workspace` if no errors were detected, and a null
   pointer in the case of error.

.. function:: void gsl_poly_complex_workspace_free (gsl_poly_complex_workspace * w)

   This function frees all the memory associated with the workspace
   :data:`w`.

.. function:: int gsl_poly_complex_solve (const double * a, size_t n, gsl_poly_complex_workspace * w, gsl_complex_packed_ptr z)

   This function computes the roots of the general polynomial 

   .. only:: not texinfo

      .. math::

         P(x) = a_0 + a_1 x + a_2 x^2 + \cdots + a_{n-1} x^{n-1}

   .. only:: texinfo

      P(x) = a_0 + a_1 x + a_2 x^2 + ... + a_{n-1} x^{n-1}
      
   using balanced-QR reduction of the companion matrix.  The parameter :data:`n`
   specifies the length of the coefficient array.  The coefficient of the
   highest order term must be non-zero.  The function requires a workspace
   :data:`w` of the appropriate size.  The :math:`n-1` roots are returned in
   the packed complex array :data:`z` of length :math:`2(n-1)`, alternating
   real and imaginary parts.

   The function returns :data:`GSL_SUCCESS` if all the roots are found. If
   the QR reduction does not converge, the error handler is invoked with
   an error code of :data:`GSL_EFAILED`.  Note that due to finite precision,
   roots of higher multiplicity are returned as a cluster of simple roots
   with reduced accuracy.  The solution of polynomials with higher-order
   roots requires specialized algorithms that take the multiplicity
   structure into account (see e.g. Z. Zeng, Algorithm 835, ACM
   Transactions on Mathematical Software, Volume 30, Issue 2 (2004), pp
   218--236).

Examples
========

To demonstrate the use of the general polynomial solver we will take the
polynomial :math:`P(x) = x^5 - 1` which has these roots:

.. only:: not texinfo

   .. math::

      1, e^{2\pi i / 5}, e^{4\pi i / 5}, e^{6\pi i / 5}, e^{8\pi i / 5}

.. only:: texinfo

   1, e^{2*pi i / 5}, e^{4*pi i / 5}, e^{6*pi i / 5}, e^{8*pi i / 5}

The following program will find these roots.

.. include:: examples/polyroots.c
   :code:

The output of the program is

.. include:: examples/polyroots.txt
   :code:

which agrees with the analytic result, :math:`z_n = \exp(2 \pi n i/5)`.

References and Further Reading
==============================

The balanced-QR method and its error analysis are described in the
following papers,

* R.S. Martin, G. Peters and J.H. Wilkinson, "The QR Algorithm for Real
  Hessenberg Matrices", Numerische Mathematik, 14 (1970), 219--231.

* B.N. Parlett and C. Reinsch, "Balancing a Matrix for Calculation of
  Eigenvalues and Eigenvectors", Numerische Mathematik, 13 (1969),
  293--304.

* A. Edelman and H. Murakami, "Polynomial roots from companion matrix
  eigenvalues", Mathematics of Computation, Vol.: 64, No.: 210
  (1995), 763--776.

The formulas for divided differences are given in the following texts,

* Abramowitz and Stegun, Handbook of Mathematical Functions,
  Sections 25.1.4 and 25.2.26.

* R. L. Burden and J. D. Faires, Numerical Analysis, 9th edition,
  ISBN 0-538-73351-9, 2011.
.. index:: Bessel functions

The routines described in this section compute the Cylindrical Bessel
functions :math:`J_n(x)`, :math:`Y_n(x)`, Modified cylindrical Bessel
functions :math:`I_n(x)`, :math:`K_n(x)`, Spherical Bessel functions
:math:`j_l(x)`, :math:`y_l(x)`, and Modified Spherical Bessel functions
:math:`i_l(x)`, :math:`k_l(x)`.  For more information see Abramowitz & Stegun,
Chapters 9 and 10.  The Bessel functions are defined in the header file
:file:`gsl_sf_bessel.h`.

Regular Cylindrical Bessel Functions
------------------------------------
.. index:: Cylindrical Bessel Functions
.. index:: Regular Cylindrical Bessel Functions
.. index::
   single: J(x), Bessel Functions

.. function:: double gsl_sf_bessel_J0 (double x)
              int gsl_sf_bessel_J0_e (double x, gsl_sf_result * result)

   These routines compute the regular cylindrical Bessel function of zeroth
   order, :math:`J_0(x)`.

.. function:: double gsl_sf_bessel_J1 (double x)
              int gsl_sf_bessel_J1_e (double x, gsl_sf_result * result)

   These routines compute the regular cylindrical Bessel function of first
   order, :math:`J_1(x)`.

.. function:: double gsl_sf_bessel_Jn (int n, double x)
              int gsl_sf_bessel_Jn_e (int n, double x, gsl_sf_result * result)

   These routines compute the regular cylindrical Bessel function of 
   order :data:`n`, :math:`J_n(x)`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_Jn_array (int nmin, int nmax, double x, double result_array[])

   This routine computes the values of the regular cylindrical Bessel
   functions :math:`J_n(x)` for :math:`n` from :data:`nmin` to :data:`nmax`
   inclusive, storing the results in the array :data:`result_array`.  The
   values are computed using recurrence relations for efficiency, and
   therefore may differ slightly from the exact values.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW


Irregular Cylindrical Bessel Functions
--------------------------------------
.. index:: Irregular Cylindrical Bessel Functions
.. index::
   single: Y(x), Bessel Functions

.. function:: double gsl_sf_bessel_Y0 (double x)
              int gsl_sf_bessel_Y0_e (double x, gsl_sf_result * result)

   These routines compute the irregular cylindrical Bessel function of zeroth
   order, :math:`Y_0(x)`, for :math:`x>0`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_Y1 (double x)
              int gsl_sf_bessel_Y1_e (double x, gsl_sf_result * result)

   These routines compute the irregular cylindrical Bessel function of first
   order, :math:`Y_1(x)`, for :math:`x>0`.
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_Yn (int n, double x)
              int gsl_sf_bessel_Yn_e (int n, double x, gsl_sf_result * result)

   These routines compute the irregular cylindrical Bessel function of 
   order :data:`n`, :math:`Y_n(x)`, for :math:`x>0`.
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_Yn_array (int nmin, int nmax, double x, double result_array[])

   This routine computes the values of the irregular cylindrical Bessel
   functions :math:`Y_n(x)` for :math:`n` from :data:`nmin` to :data:`nmax`
   inclusive, storing the results in the array :data:`result_array`.  The
   domain of the function is :math:`x>0`.  The values are computed using
   recurrence relations for efficiency, and therefore may differ slightly
   from the exact values.
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

Regular Modified Cylindrical Bessel Functions
---------------------------------------------
.. index:: Modified Cylindrical Bessel Functions
.. index:: Regular Modified Cylindrical Bessel Functions
.. index::
   single: I(x), Bessel Functions

.. function:: double gsl_sf_bessel_I0 (double x)
              int gsl_sf_bessel_I0_e (double x, gsl_sf_result * result)

   These routines compute the regular modified cylindrical Bessel function
   of zeroth order, :math:`I_0(x)`.
.. Exceptional Return Values: GSL_EOVRFLW

.. function:: double gsl_sf_bessel_I1 (double x)
              int gsl_sf_bessel_I1_e (double x, gsl_sf_result * result)

   These routines compute the regular modified cylindrical Bessel function
   of first order, :math:`I_1(x)`.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_In (int n, double x)
              int gsl_sf_bessel_In_e (int n, double x, gsl_sf_result * result)

   These routines compute the regular modified cylindrical Bessel function
   of order :data:`n`, :math:`I_n(x)`.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_In_array (int nmin, int nmax, double x, double result_array[])

   This routine computes the values of the regular modified cylindrical
   Bessel functions :math:`I_n(x)` for :math:`n` from :data:`nmin` to
   :data:`nmax` inclusive, storing the results in the array
   :data:`result_array`.  The start of the range :data:`nmin` must be positive
   or zero.  The values are computed using recurrence relations for
   efficiency, and therefore may differ slightly from the exact values.
.. Domain: nmin >=0, nmax >= nmin 
.. Conditions: n=nmin,...,nmax, nmin >=0, nmax >= nmin 
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_I0_scaled (double x)
              int gsl_sf_bessel_I0_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled regular modified cylindrical Bessel
   function of zeroth order :math:`\exp(-|x|) I_0(x)`.
.. Exceptional Return Values: none

.. function:: double gsl_sf_bessel_I1_scaled (double x)
              int gsl_sf_bessel_I1_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled regular modified cylindrical Bessel
   function of first order :math:`\exp(-|x|) I_1(x)`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_In_scaled (int n, double x)
              int gsl_sf_bessel_In_scaled_e (int n, double x, gsl_sf_result * result)

   These routines compute the scaled regular modified cylindrical Bessel
   function of order :data:`n`, :math:`\exp(-|x|) I_n(x)` 
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_In_scaled_array (int nmin, int nmax, double x, double result_array[])

   This routine computes the values of the scaled regular cylindrical
   Bessel functions :math:`\exp(-|x|) I_n(x)` for :math:`n` from
   :data:`nmin` to :data:`nmax` inclusive, storing the results in the array
   :data:`result_array`. The start of the range :data:`nmin` must be positive
   or zero.  The values are computed using recurrence relations for
   efficiency, and therefore may differ slightly from the exact values.
.. Domain: nmin >=0, nmax >= nmin 
.. Conditions:  n=nmin,...,nmax 
.. Exceptional Return Values: GSL_EUNDRFLW

Irregular Modified Cylindrical Bessel Functions
-----------------------------------------------
.. index:: Irregular Modified Cylindrical Bessel Functions
.. index::
   single: K(x), Bessel Functions

.. function:: double gsl_sf_bessel_K0 (double x)
              int gsl_sf_bessel_K0_e (double x, gsl_sf_result * result)

   These routines compute the irregular modified cylindrical Bessel
   function of zeroth order, :math:`K_0(x)`, for :math:`x > 0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_K1 (double x)
              int gsl_sf_bessel_K1_e (double x, gsl_sf_result * result)

   These routines compute the irregular modified cylindrical Bessel
   function of first order, :math:`K_1(x)`, for :math:`x > 0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_Kn (int n, double x)
              int gsl_sf_bessel_Kn_e (int n, double x, gsl_sf_result * result)

   These routines compute the irregular modified cylindrical Bessel
   function of order :data:`n`, :math:`K_n(x)`, for :math:`x > 0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_Kn_array (int nmin, int nmax, double x, double result_array[])

   This routine computes the values of the irregular modified cylindrical
   Bessel functions :math:`K_n(x)` for :math:`n` from :data:`nmin` to
   :data:`nmax` inclusive, storing the results in the array
   :data:`result_array`. The start of the range :data:`nmin` must be positive
   or zero. The domain of the function is :math:`x>0`. The values are
   computed using recurrence relations for efficiency, and therefore
   may differ slightly from the exact values.
.. Conditions: n=nmin,...,nmax 
.. Domain: x > 0.0, nmin>=0, nmax >= nmin
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_K0_scaled (double x)
              int gsl_sf_bessel_K0_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled irregular modified cylindrical Bessel
   function of zeroth order :math:`\exp(x) K_0(x)` for :math:`x>0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_bessel_K1_scaled (double x) 
              int gsl_sf_bessel_K1_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled irregular modified cylindrical Bessel
   function of first order :math:`\exp(x) K_1(x)` for :math:`x>0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_Kn_scaled (int n, double x)
              int gsl_sf_bessel_Kn_scaled_e (int n, double x, gsl_sf_result * result)

   These routines compute the scaled irregular modified cylindrical Bessel
   function of order :data:`n`, :math:`\exp(x) K_n(x)`, for :math:`x>0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_Kn_scaled_array (int nmin, int nmax, double x, double result_array[])

   This routine computes the values of the scaled irregular cylindrical
   Bessel functions :math:`\exp(x) K_n(x)` for :math:`n` from :data:`nmin` to
   :data:`nmax` inclusive, storing the results in the array
   :data:`result_array`. The start of the range :data:`nmin` must be positive
   or zero.  The domain of the function is :math:`x>0`. The values are
   computed using recurrence relations for efficiency, and therefore
   may differ slightly from the exact values.
.. Domain: x > 0.0, nmin >=0, nmax >= nmin 
.. Conditions: n=nmin,...,nmax 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

Regular Spherical Bessel Functions
----------------------------------
.. index:: Spherical Bessel Functions
.. index:: Regular Spherical Bessel Functions
.. index::
   single: j(x), Bessel Functions

.. function:: double gsl_sf_bessel_j0 (double x)
              int gsl_sf_bessel_j0_e (double x, gsl_sf_result * result)

   These routines compute the regular spherical Bessel function of zeroth
   order, :math:`j_0(x) = \sin(x)/x`.
.. Exceptional Return Values: none

.. function:: double gsl_sf_bessel_j1 (double x)
              int gsl_sf_bessel_j1_e (double x, gsl_sf_result * result)

   These routines compute the regular spherical Bessel function of first
   order, :math:`j_1(x) = (\sin(x)/x - \cos(x))/x`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_j2 (double x)
              int gsl_sf_bessel_j2_e (double x, gsl_sf_result * result)

   These routines compute the regular spherical Bessel function of second
   order, :math:`j_2(x) = ((3/x^2 - 1)\sin(x) - 3\cos(x)/x)/x`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_jl (int l, double x)
              int gsl_sf_bessel_jl_e (int l, double x, gsl_sf_result * result)

   These routines compute the regular spherical Bessel function of 
   order :data:`l`, :math:`j_l(x)`, for
   :math:`l \geq 0` and :math:`x \geq 0`.
.. Domain: l >= 0, x >= 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_jl_array (int lmax, double x, double result_array[])

   This routine computes the values of the regular spherical Bessel
   functions :math:`j_l(x)` for :math:`l` from 0 to :data:`lmax`
   inclusive  for
   :math:`lmax \geq 0` and
   :math:`x \geq 0`, storing the results in the array :data:`result_array`.
   The values are computed using recurrence relations for
   efficiency, and therefore may differ slightly from the exact values.
.. Domain: lmax >= 0 
.. Conditions: l=0,1,...,lmax 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_jl_steed_array (int lmax, double x, double * result_array)

   This routine uses Steed's method to compute the values of the regular
   spherical Bessel functions :math:`j_l(x)` for :math:`l` from 0 to
   :data:`lmax` inclusive for
   :math:`lmax \geq 0` and
   :math:`x \geq 0`, storing the results in the array
   :data:`result_array`.
   The Steed/Barnett algorithm is described in Comp. Phys. Comm. 21,
   297 (1981).  Steed's method is more stable than the
   recurrence used in the other functions but is also slower.
.. Domain: lmax >= 0 
.. Conditions: l=0,1,...,lmax 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

Irregular Spherical Bessel Functions
------------------------------------
.. index:: Irregular Spherical Bessel Functions
.. index::
   single: y(x), Bessel Functions

.. function:: double gsl_sf_bessel_y0 (double x)
              int gsl_sf_bessel_y0_e (double x, gsl_sf_result * result)

   These routines compute the irregular spherical Bessel function of zeroth
   order, :math:`y_0(x) = -\cos(x)/x`.
.. Exceptional Return Values: none

.. function:: double gsl_sf_bessel_y1 (double x)
              int gsl_sf_bessel_y1_e (double x, gsl_sf_result * result)

   These routines compute the irregular spherical Bessel function of first
   order, :math:`y_1(x) = -(\cos(x)/x + \sin(x))/x`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_y2 (double x)
              int gsl_sf_bessel_y2_e (double x, gsl_sf_result * result)

   These routines compute the irregular spherical Bessel function of second
   order, :math:`y_2(x) = (-3/x^3 + 1/x)\cos(x) - (3/x^2)\sin(x)`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_yl (int l, double x)
              int gsl_sf_bessel_yl_e (int l, double x, gsl_sf_result * result)

   These routines compute the irregular spherical Bessel function of 
   order :data:`l`, :math:`y_l(x)`, for
   :math:`l \geq 0`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_yl_array (int lmax, double x, double result_array[])

   This routine computes the values of the irregular spherical Bessel
   functions :math:`y_l(x)` for :math:`l` from 0 to :data:`lmax`
   inclusive for
   :math:`lmax \geq 0`, storing the results in the array :data:`result_array`.
   The values are computed using recurrence relations for
   efficiency, and therefore may differ slightly from the exact values.
.. Domain: lmax >= 0 
.. Conditions: l=0,1,...,lmax 
.. Exceptional Return Values: GSL_EUNDRFLW

Regular Modified Spherical Bessel Functions
-------------------------------------------
.. index:: Modified Spherical Bessel Functions
.. index:: Regular Modified Spherical Bessel Functions
.. index::
   single: i(x), Bessel Functions

The regular modified spherical Bessel functions :math:`i_l(x)` 
are related to the modified Bessel functions of fractional order,
:math:`i_l(x) = \sqrt{\pi/(2x)} I_{l+1/2}(x)`

.. function:: double gsl_sf_bessel_i0_scaled (double x)
              int gsl_sf_bessel_i0_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled regular modified spherical Bessel
   function of zeroth order, :math:`\exp(-|x|) i_0(x)`.
.. Exceptional Return Values: none

.. function:: double gsl_sf_bessel_i1_scaled (double x)
              int gsl_sf_bessel_i1_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled regular modified spherical Bessel
   function of first order, :math:`\exp(-|x|) i_1(x)`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_i2_scaled (double x)
              int gsl_sf_bessel_i2_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled regular modified spherical Bessel
   function of second order, :math:`\exp(-|x|) i_2(x)` 
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_il_scaled (int l, double x)
              int gsl_sf_bessel_il_scaled_e (int l, double x, gsl_sf_result * result)

   These routines compute the scaled regular modified spherical Bessel
   function of order :data:`l`, :math:`\exp(-|x|) i_l(x)`
.. Domain: l >= 0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_il_scaled_array (int lmax, double x, double result_array[])

   This routine computes the values of the scaled regular modified
   spherical Bessel functions :math:`\exp(-|x|) i_l(x)` for :math:`l` from
   0 to :data:`lmax` inclusive for
   :math:`lmax \geq 0`, storing the results in
   the array :data:`result_array`. 
   The values are computed using recurrence relations for
   efficiency, and therefore may differ slightly from the exact values.
.. Domain: lmax >= 0 
.. Conditions: l=0,1,...,lmax 
.. Exceptional Return Values: GSL_EUNDRFLW

Irregular Modified Spherical Bessel Functions
---------------------------------------------
.. index:: Irregular Modified Spherical Bessel Functions
.. index::
   single: k(x), Bessel Functions

The irregular modified spherical Bessel functions :math:`k_l(x)`
are related to the irregular modified Bessel functions of fractional order,
:math:`k_l(x) = \sqrt{\pi/(2x)} K_{l+1/2}(x)`.

.. function:: double gsl_sf_bessel_k0_scaled (double x)
              int gsl_sf_bessel_k0_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled irregular modified spherical Bessel
   function of zeroth order, :math:`\exp(x) k_0(x)`, for :math:`x>0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_k1_scaled (double x)
              int gsl_sf_bessel_k1_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled irregular modified spherical Bessel
   function of first order, :math:`\exp(x) k_1(x)`, for :math:`x>0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW, GSL_EOVRFLW

.. function:: double gsl_sf_bessel_k2_scaled (double x)
              int gsl_sf_bessel_k2_scaled_e (double x, gsl_sf_result * result)

   These routines compute the scaled irregular modified spherical Bessel
   function of second order, :math:`\exp(x) k_2(x)`, for :math:`x>0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW, GSL_EOVRFLW

.. function:: double gsl_sf_bessel_kl_scaled (int l, double x)
              int gsl_sf_bessel_kl_scaled_e (int l, double x, gsl_sf_result * result)

   These routines compute the scaled irregular modified spherical Bessel
   function of order :data:`l`, :math:`\exp(x) k_l(x)`, for :math:`x>0`.
.. Domain: x > 0.0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_kl_scaled_array (int lmax, double x, double result_array[])

   This routine computes the values of the scaled irregular modified
   spherical Bessel functions :math:`\exp(x) k_l(x)` for :math:`l` from
   0 to :data:`lmax` inclusive for
   :math:`lmax \geq 0` and :math:`x>0`, storing the results in
   the array :data:`result_array`. 
   The values are computed using recurrence relations for
   efficiency, and therefore may differ slightly from the exact values.
.. Domain: lmax >= 0 
.. Conditions: l=0,1,...,lmax 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

Regular Bessel Function---Fractional Order
------------------------------------------
.. index::
   single: Fractional Order Bessel Functions
   single: Bessel Functions, Fractional Order
   single: Regular Bessel Functions, Fractional Order

.. function:: double gsl_sf_bessel_Jnu (double nu, double x)
              int gsl_sf_bessel_Jnu_e (double nu, double x, gsl_sf_result * result)

   These routines compute the regular cylindrical Bessel function of
   fractional order :math:`\nu`, :math:`J_\nu(x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: int gsl_sf_bessel_sequence_Jnu_e (double nu, gsl_mode_t mode, size_t size, double v[])

   This function computes the regular cylindrical Bessel function of
   fractional order :math:`\nu`, :math:`J_\nu(x)`, evaluated at a series of
   :math:`x` values.  The array :data:`v` of length :data:`size` contains the
   :math:`x` values.  They are assumed to be strictly ordered and positive.
   The array is over-written with the values of :math:`J_\nu(x_i)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EINVAL

Irregular Bessel Functions---Fractional Order
---------------------------------------------

.. function:: double gsl_sf_bessel_Ynu (double nu, double x)
              int gsl_sf_bessel_Ynu_e (double nu, double x, gsl_sf_result * result)

   These routines compute the irregular cylindrical Bessel function of
   fractional order :math:`\nu`, :math:`Y_\nu(x)`.
.. Exceptional Return Values: 

Regular Modified Bessel Functions---Fractional Order
----------------------------------------------------
.. index::
   single: Modified Bessel Functions, Fractional Order
   single: Regular Modified Bessel Functions, Fractional Order

.. function:: double gsl_sf_bessel_Inu (double nu, double x)
              int gsl_sf_bessel_Inu_e (double nu, double x, gsl_sf_result * result)

   These routines compute the regular modified Bessel function of
   fractional order :math:`\nu`, :math:`I_\nu(x)` for :math:`x>0`,
   :math:`\nu>0`.
.. Domain: x >= 0, nu >= 0 
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW

.. function:: double gsl_sf_bessel_Inu_scaled (double nu, double x)
              int gsl_sf_bessel_Inu_scaled_e (double nu, double x, gsl_sf_result * result)

   These routines compute the scaled regular modified Bessel function of
   fractional order :math:`\nu`, :math:`\exp(-|x|)I_\nu(x)` for :math:`x>0`,
   :math:`\nu>0`.
.. Domain: x >= 0, nu >= 0 
.. Exceptional Return Values: GSL_EDOM

Irregular Modified Bessel Functions---Fractional Order
------------------------------------------------------
.. index::
   single: Irregular Modified Bessel Functions, Fractional Order

.. function:: double gsl_sf_bessel_Knu (double nu, double x)
              int gsl_sf_bessel_Knu_e (double nu, double x, gsl_sf_result * result)

   These routines compute the irregular modified Bessel function of
   fractional order :math:`\nu`, :math:`K_\nu(x)` for :math:`x>0`,
   :math:`\nu>0`.
.. Domain: x > 0, nu >= 0 
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_bessel_lnKnu (double nu, double x)
              int gsl_sf_bessel_lnKnu_e (double nu, double x, gsl_sf_result * result)

   These routines compute the logarithm of the irregular modified Bessel
   function of fractional order :math:`\nu`, :math:`\ln(K_\nu(x))` for
   :math:`x>0`, :math:`\nu>0`. 
.. Domain: x > 0, nu >= 0 
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_bessel_Knu_scaled (double nu, double x)
              int gsl_sf_bessel_Knu_scaled_e (double nu, double x, gsl_sf_result * result)

   These routines compute the scaled irregular modified Bessel function of
   fractional order :math:`\nu`, :math:`\exp(+|x|) K_\nu(x)` for :math:`x>0`,
   :math:`\nu>0`.
.. Domain: x > 0, nu >= 0 
.. Exceptional Return Values: GSL_EDOM

Zeros of Regular Bessel Functions
---------------------------------
.. index::
   single: Zeros of Regular Bessel Functions
   single: Regular Bessel Functions, Zeros of 

.. function:: double gsl_sf_bessel_zero_J0 (unsigned int s)
              int gsl_sf_bessel_zero_J0_e (unsigned int s, gsl_sf_result * result)

   These routines compute the location of the :data:`s`-th positive zero of
   the Bessel function :math:`J_0(x)`.
.. Exceptional Return Values: 

.. function:: double gsl_sf_bessel_zero_J1 (unsigned int s)
              int gsl_sf_bessel_zero_J1_e (unsigned int s, gsl_sf_result * result)

   These routines compute the location of the :data:`s`-th positive zero of
   the Bessel function :math:`J_1(x)`.
.. Exceptional Return Values: 

.. function:: double gsl_sf_bessel_zero_Jnu (double nu, unsigned int s)
              int gsl_sf_bessel_zero_Jnu_e (double nu, unsigned int s, gsl_sf_result * result)

   These routines compute the location of the :data:`s`-th positive zero of
   the Bessel function :math:`J_\nu(x)`.  The current implementation does not
   support negative values of :data:`nu`. 
.. Exceptional Return Values: 
.. |inlinefns| replace:: Inline versions of these functions are used when :code:`HAVE_INLINE` is defined.
.. |inlinefn| replace:: An inline version of this function is used when :code:`HAVE_INLINE` is defined.
.. |lapack| replace:: LAPACK
.. |octave| replace:: GNU octave
.. |fftpack| replace:: FFTPACK
.. |quadpack| replace:: QUADPACK
.. |minpack| replace:: MINPACK
.. |cquad| replace:: CQUAD
.. |blas| replace:: BLAS
.. |cblas| replace:: CBLAS
.. |atlas| replace:: ATLAS
.. |More| replace:: Moré

.. |newpage| raw:: latex

   \newpage
.. index:: multisets

*********
Multisets
*********

.. include:: include.rst

This chapter describes functions for creating and manipulating multisets. A
multiset :math:`c` is represented by an array of :math:`k` integers in the range
0 to :math:`n - 1`, where each value :math:`c_i` may occur more than once.  The
multiset :math:`c` corresponds to indices of :math:`k` elements chosen from an
:math:`n` element vector with replacement.  In mathematical terms, :math:`n` is
the cardinality of the multiset while :math:`k` is the maximum multiplicity of
any value.  Multisets are useful, for example, when iterating over the indices
of a :math:`k`-th order symmetric tensor in :math:`n`-space.

The functions described in this chapter are defined in the header file
:file:`gsl_multiset.h`.

The Multiset struct
===================

.. type:: gsl_multiset

   A multiset is defined by a structure containing three components, the
   values of :math:`n` and :math:`k`, and a pointer to the multiset array.
   The elements of the multiset array are all of type :code:`size_t`, and
   are stored in increasing order.  The :type:`gsl_multiset` structure
   looks like this::

      typedef struct
      {
        size_t n;
        size_t k;
        size_t *data;
      } gsl_multiset;

Multiset allocation
===================

.. function:: gsl_multiset * gsl_multiset_alloc (size_t n, size_t k)

   This function allocates memory for a new multiset with parameters :data:`n`,
   :data:`k`.  The multiset is not initialized and its elements are undefined.  Use
   the function :func:`gsl_multiset_calloc` if you want to create a multiset which
   is initialized to the lexicographically first multiset element. A null pointer
   is returned if insufficient memory is available to create the multiset.

.. function:: gsl_multiset * gsl_multiset_calloc (size_t n, size_t k)

   This function allocates memory for a new multiset with parameters :data:`n`,
   :data:`k` and initializes it to the lexicographically first multiset element. A
   null pointer is returned if insufficient memory is available to create the
   multiset.

.. function:: void gsl_multiset_init_first (gsl_multiset * c)

   This function initializes the multiset :data:`c` to the lexicographically first
   multiset element, i.e. :math:`0` repeated :math:`k` times.

.. function:: void gsl_multiset_init_last (gsl_multiset * c)

   This function initializes the multiset :data:`c` to the lexicographically last
   multiset element, i.e. :math:`n-1` repeated :math:`k` times.

.. function:: void gsl_multiset_free (gsl_multiset * c)

   This function frees all the memory used by the multiset :data:`c`.

.. function:: int gsl_multiset_memcpy (gsl_multiset * dest, const gsl_multiset * src)

   This function copies the elements of the multiset :data:`src` into the
   multiset :data:`dest`.  The two multisets must have the same size.

Accessing multiset elements
===========================

The following function can be used to access the elements of a multiset.

.. function:: size_t gsl_multiset_get (const gsl_multiset * c, const size_t i)

   This function returns the value of the :data:`i`-th element of the
   multiset :data:`c`.  If :data:`i` lies outside the allowed range of 0 to
   :math:`k - 1` then the error handler is invoked and 0 is returned. |inlinefn|

Multiset properties
===================

.. function:: size_t gsl_multiset_n (const gsl_multiset * c)

   This function returns the range (:math:`n`) of the multiset :data:`c`.

.. function:: size_t gsl_multiset_k (const gsl_multiset * c)

   This function returns the number of elements (:math:`k`) in the multiset :data:`c`.

.. function:: size_t * gsl_multiset_data (const gsl_multiset * c)

   This function returns a pointer to the array of elements in the
   multiset :data:`c`.

.. index::
   single: checking multiset for validity
   single: testing multiset for validity

.. function:: int gsl_multiset_valid (gsl_multiset * c)

   This function checks that the multiset :data:`c` is valid.  The :data:`k`
   elements should lie in the range 0 to :math:`n - 1`, with each
   value occurring in nondecreasing order.

Multiset functions
==================

.. index:: iterating through multisets

.. function:: int gsl_multiset_next (gsl_multiset * c)

   This function advances the multiset :data:`c` to the next multiset element in
   lexicographic order and returns :macro:`GSL_SUCCESS`.  If no further multisets
   elements are available it returns :macro:`GSL_FAILURE` and leaves :data:`c`
   unmodified.  Starting with the first multiset and repeatedly applying this
   function will iterate through all possible multisets of a given order.

.. function:: int gsl_multiset_prev (gsl_multiset * c)

   This function steps backwards from the multiset :data:`c` to the previous
   multiset element in lexicographic order, returning :macro:`GSL_SUCCESS`.  If no
   previous multiset is available it returns :macro:`GSL_FAILURE` and leaves :data:`c`
   unmodified.

Reading and writing multisets
=============================

The library provides functions for reading and writing multisets to a
file as binary data or formatted text.

.. function:: int gsl_multiset_fwrite (FILE * stream, const gsl_multiset * c)

   This function writes the elements of the multiset :data:`c` to the
   stream :data:`stream` in binary format.  The function returns
   :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since the
   data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_multiset_fread (FILE * stream, gsl_multiset * c)

   This function reads elements from the open stream :data:`stream` into the
   multiset :data:`c` in binary format.  The multiset :data:`c` must be
   preallocated with correct values of :math:`n` and :math:`k` since the
   function uses the size of :data:`c` to determine how many bytes to read.
   The function returns :macro:`GSL_EFAILED` if there was a problem reading
   from the file.  The data is assumed to have been written in the native
   binary format on the same architecture.

.. function:: int gsl_multiset_fprintf (FILE * stream, const gsl_multiset * c, const char * format)

   This function writes the elements of the multiset :data:`c`
   line-by-line to the stream :data:`stream` using the format specifier
   :data:`format`, which should be suitable for a type of :code:`size_t`.
   In ISO C99 the type modifier :code:`z` represents :code:`size_t`, so
   :code:`"%zu\n"` is a suitable format [#f1]_.
   The function returns :macro:`GSL_EFAILED` if there was a problem writing to the file.

.. function:: int gsl_multiset_fscanf (FILE * stream, gsl_multiset * c)

   This function reads formatted data from the stream :data:`stream` into the
   multiset :data:`c`.  The multiset :data:`c` must be preallocated with
   correct values of :math:`n` and :math:`k` since the function uses the size of :data:`c` to
   determine how many numbers to read.  The function returns
   :macro:`GSL_EFAILED` if there was a problem reading from the file.

Examples
========

The example program below prints all multisets elements containing the values
:math:`{0,1,2,3}` ordered by size.  Multiset elements of the same size are
ordered lexicographically.

.. include:: examples/multiset.c
   :code:

Here is the output from the program,

.. include:: examples/multiset.txt
   :code:

All 70 multisets are generated and sorted lexicographically.

.. rubric:: Footnotes

.. [#f1] In versions of the GNU C library prior to the ISO C99 standard,
         the type modifier :code:`Z` was used instead.
.. index:: interpolation, spline

.. _sec_interpolation:

*************
Interpolation
*************

.. include:: include.rst

This chapter describes functions for performing interpolation.  The
library provides a variety of interpolation methods, including Cubic,
Akima, and Steffen splines.  The interpolation types are interchangeable,
allowing different methods to be used without recompiling.
Interpolations can be defined for both normal and periodic boundary
conditions.  Additional functions are available for computing
derivatives and integrals of interpolating functions. Routines
are provided for interpolating both one and two dimensional datasets.

These interpolation methods produce curves that pass through each
datapoint.  To interpolate noisy data with a smoothing curve see
:ref:`chap_basis-splines`.

The functions described in this section are declared in the header files
:file:`gsl_interp.h` and :file:`gsl_spline.h`.

Introduction to 1D Interpolation
================================

Given a set of data points :math:`(x_1, y_1) \dots (x_n, y_n)` the
routines described in this section compute a continuous interpolating
function :math:`y(x)` such that :math:`y(x_i) = y_i`.  The interpolation
is piecewise smooth, and its behavior at the end-points is determined by
the type of interpolation used.

1D Interpolation Functions
==========================

The interpolation function for a given dataset is stored in a
:type:`gsl_interp` object.  These are created by the following functions.

.. type:: gsl_interp

   Workspace for 1D interpolation

.. function:: gsl_interp * gsl_interp_alloc (const gsl_interp_type * T, size_t size)

   This function returns a pointer to a newly allocated interpolation
   object of type :data:`T` for :data:`size` data-points.

.. function:: int gsl_interp_init (gsl_interp * interp, const double xa[], const double ya[], size_t size)

   This function initializes the interpolation object :data:`interp` for the
   data (:data:`xa`, :data:`ya`) where :data:`xa` and :data:`ya` are arrays of size
   :data:`size`.  The interpolation object (:type:`gsl_interp`) does not save
   the data arrays :data:`xa` and :data:`ya` and only stores the static state
   computed from the data.  The :data:`xa` data array is always assumed to be
   strictly ordered, with increasing :math:`x` values; 
   the behavior for other arrangements is not defined.

.. function:: void gsl_interp_free (gsl_interp * interp)

   This function frees the interpolation object :data:`interp`.

1D Interpolation Types
======================

The interpolation library provides the following interpolation types:

.. type:: gsl_interp_type

   .. index:: linear interpolation

   .. var:: gsl_interp_linear

      Linear interpolation.  This interpolation method does not require any
      additional memory.

   .. index:: polynomial interpolation

   .. var:: gsl_interp_polynomial

      Polynomial interpolation.  This method should only be used for
      interpolating small numbers of points because polynomial interpolation
      introduces large oscillations, even for well-behaved datasets.  The
      number of terms in the interpolating polynomial is equal to the number
      of points.

   .. index:: cubic splines

   .. var:: gsl_interp_cspline

      Cubic spline with natural boundary conditions.  The resulting curve is
      piecewise cubic on each interval, with matching first and second
      derivatives at the supplied data-points.  The second derivative is
      chosen to be zero at the first point and last point.

   .. var:: gsl_interp_cspline_periodic

      Cubic spline with periodic boundary conditions.  The resulting curve
      is piecewise cubic on each interval, with matching first and second
      derivatives at the supplied data-points.  The derivatives at the first
      and last points are also matched.  Note that the last point in the
      data must have the same y-value as the first point, otherwise the
      resulting periodic interpolation will have a discontinuity at the
      boundary.

   .. index:: Akima splines

   .. var:: gsl_interp_akima

      Non-rounded Akima spline with natural boundary conditions.  This method
      uses the non-rounded corner algorithm of Wodicka.

   .. var:: gsl_interp_akima_periodic

      Non-rounded Akima spline with periodic boundary conditions.  This method
      uses the non-rounded corner algorithm of Wodicka.

   .. var:: gsl_interp_steffen

      Steffen's method guarantees the monotonicity of the interpolating function
      between the given data points. Therefore, minima and maxima can only occur
      exactly at the data points, and there can never be spurious oscillations
      between data points. The interpolated function is piecewise cubic
      in each interval. The resulting curve and its first derivative
      are guaranteed to be continuous, but the second derivative may be
      discontinuous.

The following related functions are available:

.. function:: const char * gsl_interp_name (const gsl_interp * interp)

   This function returns the name of the interpolation type used by :data:`interp`.
   For example::

      printf ("interp uses '%s' interpolation.\n", gsl_interp_name (interp));

   would print something like::

      interp uses 'cspline' interpolation.

.. function:: unsigned int gsl_interp_min_size (const gsl_interp * interp)
              unsigned int gsl_interp_type_min_size (const gsl_interp_type * T)

   These functions return the minimum number of points required by the
   interpolation object :data:`interp` or interpolation type :data:`T`.  For
   example, Akima spline interpolation requires a minimum of 5 points.

1D Index Look-up and Acceleration
=================================

The state of searches can be stored in a :type:`gsl_interp_accel` object,
which is a kind of iterator for interpolation lookups.

.. type:: gsl_interp_accel

   This workspace stores state variables for interpolation lookups.
   It caches the previous value of an index lookup.  When the subsequent interpolation
   point falls in the same interval its index value can be returned
   immediately.

.. function:: size_t gsl_interp_bsearch (const double x_array[], double x, size_t index_lo, size_t index_hi)

   This function returns the index :math:`i` of the array :data:`x_array` such
   that :code:`x_array[i] <= x < x_array[i+1]`.  The index is searched for
   in the range [:data:`index_lo`, :data:`index_hi`]. |inlinefn|

.. function:: gsl_interp_accel * gsl_interp_accel_alloc (void)

   This function returns a pointer to an accelerator object, which is a
   kind of iterator for interpolation lookups.  It tracks the state of
   lookups, thus allowing for application of various acceleration
   strategies.

.. function:: size_t gsl_interp_accel_find (gsl_interp_accel * a, const double x_array[], size_t size, double x)

   This function performs a lookup action on the data array :data:`x_array`
   of size :data:`size`, using the given accelerator :data:`a`.  This is how
   lookups are performed during evaluation of an interpolation.  The
   function returns an index :math:`i` such that :code:`x_array[i] <= x < x_array[i+1]`.
   |inlinefn|

.. function:: int gsl_interp_accel_reset (gsl_interp_accel * acc);

   This function reinitializes the accelerator object :data:`acc`.  It
   should be used when the cached information is no longer
   applicable---for example, when switching to a new dataset.

.. function:: void gsl_interp_accel_free (gsl_interp_accel* acc)

   This function frees the accelerator object :data:`acc`.

1D Evaluation of Interpolating Functions
========================================

.. function::  double gsl_interp_eval (const gsl_interp * interp, const double xa[], const double ya[], double x, gsl_interp_accel * acc)
               int gsl_interp_eval_e (const gsl_interp * interp, const double xa[], const double ya[], double x, gsl_interp_accel * acc, double * y)

   These functions return the interpolated value of :data:`y` for a given
   point :data:`x`, using the interpolation object :data:`interp`, data
   arrays :data:`xa` and :data:`ya` and the accelerator :data:`acc`.  When
   :data:`x` is outside the range of :data:`xa`, the error code
   :macro:`GSL_EDOM` is returned with a value of :macro:`GSL_NAN` for
   :data:`y`.

.. function:: double gsl_interp_eval_deriv (const gsl_interp * interp, const double xa[], const double ya[], double x, gsl_interp_accel * acc)
              int gsl_interp_eval_deriv_e (const gsl_interp * interp, const double xa[], const double ya[], double x, gsl_interp_accel * acc, double * d)

   These functions return the derivative :data:`d` of an interpolated
   function for a given point :data:`x`, using the interpolation object
   :data:`interp`, data arrays :data:`xa` and :data:`ya` and the accelerator
   :data:`acc`. 

.. function:: double gsl_interp_eval_deriv2 (const gsl_interp * interp, const double xa[], const double ya[], double x, gsl_interp_accel * acc)
              int gsl_interp_eval_deriv2_e (const gsl_interp * interp, const double xa[], const double ya[], double x, gsl_interp_accel * acc, double * d2)

   These functions return the second derivative :data:`d2` of an interpolated
   function for a given point :data:`x`, using the interpolation object
   :data:`interp`, data arrays :data:`xa` and :data:`ya` and the accelerator
   :data:`acc`. 

.. function:: double gsl_interp_eval_integ (const gsl_interp * interp, const double xa[], const double ya[], double a, double b, gsl_interp_accel * acc)
              int gsl_interp_eval_integ_e (const gsl_interp * interp, const double xa[], const double ya[], double a, double b, gsl_interp_accel * acc, double * result)

   These functions return the numerical integral :data:`result` of an
   interpolated function over the range [:data:`a`, :data:`b`], using the
   interpolation object :data:`interp`, data arrays :data:`xa` and :data:`ya` and
   the accelerator :data:`acc`.

1D Higher-level Interface
=========================

The functions described in the previous sections required the user to
supply pointers to the :math:`x` and :math:`y` arrays on each call.  The
following functions are equivalent to the corresponding
:type:`gsl_interp` functions but maintain a copy of this data in the
:type:`gsl_spline` object.  This removes the need to pass both :data:`xa`
and :data:`ya` as arguments on each evaluation. These functions are
defined in the header file :file:`gsl_spline.h`.

.. type:: gsl_spline

   This workspace provides a higher level interface for the
   :type:`gsl_interp` object

.. function:: gsl_spline * gsl_spline_alloc (const gsl_interp_type * T, size_t size)

.. function:: int gsl_spline_init (gsl_spline * spline, const double xa[], const double ya[], size_t size)

.. function:: void gsl_spline_free (gsl_spline * spline)

.. function:: const char * gsl_spline_name (const gsl_spline * spline)

.. function:: unsigned int gsl_spline_min_size (const gsl_spline * spline)

.. function:: double gsl_spline_eval (const gsl_spline * spline, double x, gsl_interp_accel * acc)
              int gsl_spline_eval_e (const gsl_spline * spline, double x, gsl_interp_accel * acc, double * y)

.. function:: double gsl_spline_eval_deriv (const gsl_spline * spline, double x, gsl_interp_accel * acc)
              int gsl_spline_eval_deriv_e (const gsl_spline * spline, double x, gsl_interp_accel * acc, double * d)

.. function:: double gsl_spline_eval_deriv2 (const gsl_spline * spline, double x, gsl_interp_accel * acc)
              int gsl_spline_eval_deriv2_e (const gsl_spline * spline, double x, gsl_interp_accel * acc, double * d2)

.. function:: double gsl_spline_eval_integ (const gsl_spline * spline, double a, double b, gsl_interp_accel * acc)
              int gsl_spline_eval_integ_e (const gsl_spline * spline, double a, double b, gsl_interp_accel * acc, double * result)

1D Interpolation Example Programs
=================================

The following program demonstrates the use of the interpolation and
spline functions.  It computes a cubic spline interpolation of the
10-point dataset :math:`(x_i, y_i)` where :math:`x_i = i + \sin(i)/2` and
:math:`y_i = i + \cos(i^2)` for :math:`i = 0 \dots 9`.

.. include:: examples/interp.c
   :code:

The output is designed to be used with the GNU plotutils
:code:`graph` program::

  $ ./a.out > interp.dat
  $ graph -T ps < interp.dat > interp.ps

.. _fig_interp:

.. figure:: /images/interp.png
   :scale: 60%

   Cubic spline interpolation

:numref:`fig_interp` shows a smooth interpolation of the original points.  The
interpolation method can be changed simply by varying the first argument of
:func:`gsl_spline_alloc`.

The next program demonstrates a periodic cubic spline with 4 data
points.  Note that the first and last points must be supplied with 
the same y-value for a periodic spline.

.. include:: examples/interpp.c
   :code:

The output can be plotted with GNU :code:`graph`::

  $ ./a.out > interp.dat
  $ graph -T ps < interp.dat > interp.ps

.. _fig_interpp:

.. figure:: /images/interpp.png
   :scale: 60%

   Periodic cubic spline interpolation

:numref:`fig_interpp` shows a periodic interpolation of the original points. The
slope of the fitted curve is the same at the beginning and end of the
data, and the second derivative is also.

The next program illustrates the difference between the cubic spline,
Akima, and Steffen interpolation types on a difficult dataset.

.. include:: examples/interp_compare.c
   :code:

.. _fig_interp-compare:

.. figure:: /images/interp_compare.png
   :scale: 60%

   Comparison of different 1D interpolation methods

The output is shown in :numref:`fig_interp-compare`.
The cubic method exhibits a local maxima between the 6th and 7th data points
and continues oscillating for the rest of the data. Akima also shows a
local maxima but recovers and follows the data well after the 7th grid point.
Steffen preserves monotonicity in all intervals and does not exhibit oscillations,
at the expense of having a discontinuous second derivative.

Introduction to 2D Interpolation
================================

Given a set of :math:`x` coordinates :math:`x_1,...,x_m` and a set of
:math:`y` coordinates :math:`y_1,...,y_n`, each in increasing order,
plus a set of function values :math:`z_{ij}`
for each grid point :math:`(x_i,y_j)`, the routines described in this
section compute a continuous interpolation function :math:`z(x,y)` such
that :math:`z(x_i,y_j) = z_{ij}`.

2D Interpolation Functions
==========================

The interpolation function for a given dataset is stored in a
:type:`gsl_interp2d` object. These are created by the following functions.

.. type:: gsl_interp2d

   Workspace for 2D interpolation

.. function:: gsl_interp2d * gsl_interp2d_alloc (const gsl_interp2d_type * T, const size_t xsize, const size_t ysize)

   This function returns a pointer to a newly allocated interpolation
   object of type :data:`T` for :data:`xsize` grid points in the :math:`x`
   direction and :data:`ysize` grid points in the :math:`y` direction.

.. function:: int gsl_interp2d_init (gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const size_t xsize, const size_t ysize)

   This function initializes the interpolation object :data:`interp` for the
   data (:data:`xa`, :data:`ya`, :data:`za`) where :data:`xa` and :data:`ya` are arrays of
   the :math:`x` and :math:`y` grid points of size :data:`xsize` and :data:`ysize`
   respectively, and :data:`za` is an array of function values of size
   :data:`xsize` * :data:`ysize`.  The interpolation object (:type:`gsl_interp2d`) does
   not save the data arrays :data:`xa`, :data:`ya`, and :data:`za` and only stores the
   static state computed from the data. The :data:`xa` and :data:`ya` data arrays
   are always assumed to be strictly ordered, with increasing :math:`x,y` values; 
   the behavior for other arrangements is not defined.

.. function:: void gsl_interp2d_free (gsl_interp2d * interp)

   This function frees the interpolation object :data:`interp`.

2D Interpolation Grids
======================

The 2D interpolation routines access the function values :math:`z_{ij}`
with the following ordering:

.. math:: z_{ij} = za[j*xsize + i]

with :math:`i = 0,...,xsize-1` and :math:`j = 0,...,ysize-1`. However,
for ease of use, the following functions are provided to add and retrieve
elements from the function grid without requiring knowledge of the
internal ordering.

.. function:: int gsl_interp2d_set (const gsl_interp2d * interp, double za[], const size_t i, const size_t j, const double z)

   This function sets the value :math:`z_{ij}` for grid point
   (:data:`i`, :data:`j`) of the array :data:`za` to :data:`z`.

.. function:: double gsl_interp2d_get (const gsl_interp2d * interp, const double za[], const size_t i, const size_t j)

   This function returns the value :math:`z_{ij}` for grid point
   (:data:`i`, :data:`j`) stored in the array :data:`za`.

.. function:: size_t gsl_interp2d_idx (const gsl_interp2d * interp, const size_t i, const size_t j)

   This function returns the index corresponding to the grid point
   (:data:`i`, :data:`j`). The index is given by :math:`j*xsize + i`.

2D Interpolation Types
======================

.. type:: gsl_interp2d_type

   The interpolation library provides the following 2D interpolation types:

   .. index:: bilinear interpolation

   .. var:: gsl_interp2d_bilinear

      Bilinear interpolation.  This interpolation method does not require any
      additional memory.

   .. index:: bicubic interpolation

   .. var:: gsl_interp2d_bicubic

      Bicubic interpolation.

.. function:: const char * gsl_interp2d_name (const gsl_interp2d * interp)

   This function returns the name of the interpolation type used by :data:`interp`.
   For example::

      printf ("interp uses '%s' interpolation.\n", gsl_interp2d_name (interp));

   would print something like::

      interp uses 'bilinear' interpolation.

.. function:: unsigned int gsl_interp2d_min_size (const gsl_interp2d * interp)
              unsigned int gsl_interp2d_type_min_size (const gsl_interp2d_type * T)

   These functions return the minimum number of points required by the
   interpolation object :data:`interp` or interpolation type :data:`T`.  For
   example, bicubic interpolation requires a minimum of 4 points.

2D Evaluation of Interpolating Functions
========================================

.. function:: double gsl_interp2d_eval (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_interp2d_eval_e (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * z)

   These functions return the interpolated value of :data:`z` for a given
   point (:data:`x`, :data:`y`), using the interpolation object :data:`interp`, data
   arrays :data:`xa`, :data:`ya`, and :data:`za` and the accelerators :data:`xacc`
   and :data:`yacc`.  When :data:`x` is outside the range of :data:`xa` or :data:`y`
   is outside the range of :data:`ya`, the error code
   :macro:`GSL_EDOM` is returned.

.. function:: double gsl_interp2d_eval_extrap (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_interp2d_eval_extrap_e (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * z)

   These functions return the interpolated value of :data:`z` for a given
   point (:data:`x`, :data:`y`), using the interpolation object :data:`interp`, data
   arrays :data:`xa`, :data:`ya`, and :data:`za` and the accelerators :data:`xacc`
   and :data:`yacc`. The functions perform no bounds checking, so
   when :data:`x` is outside the range of :data:`xa` or :data:`y`
   is outside the range of :data:`ya`, extrapolation is performed.

.. function:: double gsl_interp2d_eval_deriv_x (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_interp2d_eval_deriv_x_e (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

   These functions return the interpolated value :data:`d`
   :math:`= \partial z / \partial x` for a given point (:data:`x`, :data:`y`),
   using the interpolation object :data:`interp`, data
   arrays :data:`xa`, :data:`ya`, and :data:`za` and the accelerators :data:`xacc`
   and :data:`yacc`.  When :data:`x` is outside the range of :data:`xa` or :data:`y`
   is outside the range of :data:`ya`, the error code
   :macro:`GSL_EDOM` is returned.

.. function:: double gsl_interp2d_eval_deriv_y (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_interp2d_eval_deriv_y_e (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

   These functions return the interpolated value :data:`d`
   :math:`= \partial z / \partial y` for a given point (:data:`x`, :data:`y`),
   using the interpolation object :data:`interp`, data
   arrays :data:`xa`, :data:`ya`, and :data:`za` and the accelerators :data:`xacc`
   and :data:`yacc`.  When :data:`x` is outside the range of :data:`xa` or :data:`y`
   is outside the range of :data:`ya`, the error code
   :macro:`GSL_EDOM` is returned.

.. function:: double gsl_interp2d_eval_deriv_xx (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_interp2d_eval_deriv_xx_e (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

   These functions return the interpolated value :data:`d`
   :math:`= \partial^2 z / \partial x^2` for a given point (:data:`x`, :data:`y`),
   using the interpolation object :data:`interp`, data
   arrays :data:`xa`, :data:`ya`, and :data:`za` and the accelerators :data:`xacc`
   and :data:`yacc`.  When :data:`x` is outside the range of :data:`xa` or :data:`y`
   is outside the range of :data:`ya`, the error code
   :macro:`GSL_EDOM` is returned.

.. function:: double gsl_interp2d_eval_deriv_yy (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_interp2d_eval_deriv_yy_e (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

   These functions return the interpolated value :data:`d`
   :math:`= \partial^2 z / \partial y^2` for a given point (:data:`x`, :data:`y`),
   using the interpolation object :data:`interp`, data
   arrays :data:`xa`, :data:`ya`, and :data:`za` and the accelerators :data:`xacc`
   and :data:`yacc`.  When :data:`x` is outside the range of :data:`xa` or :data:`y`
   is outside the range of :data:`ya`, the error code
   :macro:`GSL_EDOM` is returned.

.. function:: double gsl_interp2d_eval_deriv_xy (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_interp2d_eval_deriv_xy_e (const gsl_interp2d * interp, const double xa[], const double ya[], const double za[], const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

   These functions return the interpolated value :data:`d`
   :math:`= \partial^2 z / \partial x \partial y` for a given point (:data:`x`, :data:`y`),
   using the interpolation object :data:`interp`, data
   arrays :data:`xa`, :data:`ya`, and :data:`za` and the accelerators :data:`xacc`
   and :data:`yacc`.  When :data:`x` is outside the range of :data:`xa` or :data:`y`
   is outside the range of :data:`ya`, the error code
   :macro:`GSL_EDOM` is returned.

2D Higher-level Interface
=========================

The functions described in the previous sections required the user to
supply pointers to the :math:`x`, :math:`y`, and :math:`z` arrays on each call.
The following functions are equivalent to the corresponding
:code:`gsl_interp2d` functions but maintain a copy of this data in the
:type:`gsl_spline2d` object.  This removes the need to pass :data:`xa`,
:data:`ya`, and :data:`za` as arguments on each evaluation. These functions are
defined in the header file :file:`gsl_spline2d.h`.

.. type:: gsl_spline2d

   This workspace provides a higher level interface for the
   :type:`gsl_interp2d` object

.. function:: gsl_spline2d * gsl_spline2d_alloc (const gsl_interp2d_type * T, size_t xsize, size_t ysize)

.. function:: int gsl_spline2d_init (gsl_spline2d * spline, const double xa[], const double ya[], const double za[], size_t xsize, size_t ysize)

.. function:: void gsl_spline2d_free (gsl_spline2d * spline)

.. function:: const char * gsl_spline2d_name (const gsl_spline2d * spline)

.. function:: unsigned int gsl_spline2d_min_size (const gsl_spline2d * spline)

.. function:: double gsl_spline2d_eval (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_spline2d_eval_e (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * z)

.. function:: double gsl_spline2d_eval_deriv_x (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_spline2d_eval_deriv_x_e (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

.. function:: double gsl_spline2d_eval_deriv_y (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_spline2d_eval_deriv_y_e (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

.. function:: double gsl_spline2d_eval_deriv_xx (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_spline2d_eval_deriv_xx_e (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

.. function:: double gsl_spline2d_eval_deriv_yy (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_spline2d_eval_deriv_yy_e (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

.. function:: double gsl_spline2d_eval_deriv_xy (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc)
              int gsl_spline2d_eval_deriv_xy_e (const gsl_spline2d * spline, const double x, const double y, gsl_interp_accel * xacc, gsl_interp_accel * yacc, double * d)

.. function:: int gsl_spline2d_set (const gsl_spline2d * spline, double za[], const size_t i, const size_t j, const double z)

.. function:: double gsl_spline2d_get (const gsl_spline2d * spline, const double za[], const size_t i, const size_t j)

   This function returns the value :math:`z_{ij}` for grid point
   (:data:`i`, :data:`j`) stored in the array :data:`za`.

2D Interpolation Example programs
=================================

The following example performs bilinear interpolation on the unit
square, using :math:`z` values of :math:`(0,1,0.5,1)` going clockwise
around the square.

.. include:: examples/interp2d.c
   :code:

The results of the interpolation are shown in :numref:`fig_interp2d`,
where the corners are labeled with their fixed :math:`z` values.

.. _fig_interp2d:

.. figure:: /images/interp2d.png
   :scale: 60%

   2D interpolation example

References and Further Reading
==============================

Descriptions of the interpolation algorithms and further references can
be found in the following publications:

* C.W. Ueberhuber,
  *Numerical Computation (Volume 1), Chapter 9 "Interpolation"*,
  Springer (1997), ISBN 3-540-62058-3.

* D.M. Young, R.T. Gregory,
  *A Survey of Numerical Mathematics (Volume 1), Chapter 6.8*,
  Dover (1988), ISBN 0-486-65691-8.

* M. Steffen,
  *A simple method for monotonic interpolation in one dimension*,
  Astron. Astrophys. 239, 443-450, 1990.
.. index::
   single: quadrature
   single: numerical integration (quadrature)
   single: integration, numerical (quadrature)
   single: QUADPACK

*********************
Numerical Integration
*********************

.. include:: include.rst

This chapter describes routines for performing numerical integration
(quadrature) of a function in one dimension.  There are routines for
adaptive and non-adaptive integration of general functions, with
specialised routines for specific cases.  These include integration over
infinite and semi-infinite ranges, singular integrals, including
logarithmic singularities, computation of Cauchy principal values and
oscillatory integrals.  The library reimplements the algorithms used in
|quadpack|, a numerical integration package written by Piessens,
de Doncker-Kapenga, Ueberhuber and Kahaner.  Fortran code for |quadpack| is
available on Netlib.  Also included are non-adaptive, fixed-order
Gauss-Legendre integration routines with high precision coefficients, as
well as fixed-order quadrature rules for a variety of weighting functions
from IQPACK.

The functions described in this chapter are declared in the header file
:file:`gsl_integration.h`.

Introduction
============

Each algorithm computes an approximation to a definite integral of the
form,

.. math:: I = \int_a^b f(x) w(x) dx

where :math:`w(x)` is a weight function (for general integrands :math:`w(x) = 1`).
The user provides absolute and relative error bounds 
:math:`(epsabs, epsrel)` which specify the following accuracy requirement,

.. only:: not texinfo

   .. math:: |RESULT - I| \leq \max{(epsabs, epsrel |I|)}

.. only:: texinfo

   .. math:: |RESULT - I| <= max(epsabs, epsrel |I|)

where :math:`RESULT` is the numerical approximation obtained by the
algorithm.  The algorithms attempt to estimate the absolute error
:math:`ABSERR = |RESULT - I|` in such a way that the following inequality
holds,

.. only:: not texinfo

   .. math:: |RESULT - I| \leq ABSERR \leq \max{(epsabs, epsrel |I|)}

.. only:: texinfo

   .. math:: |RESULT - I| <= ABSERR <= max(epsabs, epsrel |I|)

In short, the routines return the first approximation 
which has an absolute error smaller than
:math:`epsabs` or a relative error smaller than :math:`epsrel`.   

Note that this is an *either-or* constraint, 
not simultaneous.  To compute to a specified absolute error, set
:math:`epsrel` to zero.  To compute to a specified relative error,
set :math:`epsabs` to zero.  
The routines will fail to converge if the error bounds are too
stringent, but always return the best approximation obtained up to
that stage.

The algorithms in |quadpack| use a naming convention based on the
following letters::

  Q - quadrature routine

  N - non-adaptive integrator
  A - adaptive integrator

  G - general integrand (user-defined)
  W - weight function with integrand

  S - singularities can be more readily integrated
  P - points of special difficulty can be supplied
  I - infinite range of integration
  O - oscillatory weight function, cos or sin
  F - Fourier integral
  C - Cauchy principal value

The algorithms are built on pairs of quadrature rules, a higher order
rule and a lower order rule.  The higher order rule is used to compute
the best approximation to an integral over a small range.  The
difference between the results of the higher order rule and the lower
order rule gives an estimate of the error in the approximation.

.. index:: Gauss-Kronrod quadrature

Integrands without weight functions
-----------------------------------

The algorithms for general functions (without a weight function) are
based on Gauss-Kronrod rules. 

A Gauss-Kronrod rule begins with a classical Gaussian quadrature rule of
order :math:`m`.  This is extended with additional points between each of
the abscissae to give a higher order Kronrod rule of order :math:`2m + 1`.
The Kronrod rule is efficient because it reuses existing function
evaluations from the Gaussian rule.  

The higher order Kronrod rule is used as the best approximation to the
integral, and the difference between the two rules is used as an
estimate of the error in the approximation.

Integrands with weight functions
--------------------------------

.. index::
   single: Clenshaw-Curtis quadrature
   single: Modified Clenshaw-Curtis quadrature

For integrands with weight functions the algorithms use Clenshaw-Curtis
quadrature rules.  

A Clenshaw-Curtis rule begins with an :math:`n`-th order Chebyshev
polynomial approximation to the integrand.  This polynomial can be
integrated exactly to give an approximation to the integral of the
original function.  The Chebyshev expansion can be extended to higher
orders to improve the approximation and provide an estimate of the
error.

Integrands with singular weight functions
-----------------------------------------

The presence of singularities (or other behavior) in the integrand can
cause slow convergence in the Chebyshev approximation.  The modified
Clenshaw-Curtis rules used in |quadpack| separate out several common
weight functions which cause slow convergence.  

These weight functions are integrated analytically against the Chebyshev
polynomials to precompute *modified Chebyshev moments*.  Combining
the moments with the Chebyshev approximation to the function gives the
desired integral.  The use of analytic integration for the singular part
of the function allows exact cancellations and substantially improves
the overall convergence behavior of the integration.

QNG non-adaptive Gauss-Kronrod integration
==========================================
.. index:: QNG quadrature algorithm

The QNG algorithm is a non-adaptive procedure which uses fixed
Gauss-Kronrod-Patterson abscissae to sample the integrand at a maximum of 87
points.  It is provided for fast integration of smooth functions.

.. function:: int gsl_integration_qng (const gsl_function * f, double a, double b, double epsabs, double epsrel, double * result, double * abserr, size_t * neval)

   This function applies the Gauss-Kronrod 10-point, 21-point, 43-point and
   87-point integration rules in succession until an estimate of the
   integral of :math:`f` over :math:`(a,b)` is achieved within the desired
   absolute and relative error limits, :data:`epsabs` and :data:`epsrel`.  The
   function returns the final approximation, :data:`result`, an estimate of
   the absolute error, :data:`abserr` and the number of function evaluations
   used, :data:`neval`.  The Gauss-Kronrod rules are designed in such a way
   that each rule uses all the results of its predecessors, in order to
   minimize the total number of function evaluations.


QAG adaptive integration
========================
.. index:: QAG quadrature algorithm

The QAG algorithm is a simple adaptive integration procedure.  The
integration region is divided into subintervals, and on each iteration
the subinterval with the largest estimated error is bisected.  This
reduces the overall error rapidly, as the subintervals become
concentrated around local difficulties in the integrand.  These
subintervals are managed by the following struct,

.. type:: gsl_integration_workspace

   This workspace handles the memory for the subinterval ranges, results and error
   estimates.

.. index:: gsl_integration_workspace

.. function:: gsl_integration_workspace * gsl_integration_workspace_alloc (size_t n) 

   This function allocates a workspace sufficient to hold :data:`n` double
   precision intervals, their integration results and error estimates.
   One workspace may be used multiple times as all necessary reinitialization
   is performed automatically by the integration routines.

.. function:: void gsl_integration_workspace_free (gsl_integration_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_integration_qag (const gsl_function * f, double a, double b, double epsabs, double epsrel, size_t limit, int key, gsl_integration_workspace * workspace,  double * result, double * abserr)

   This function applies an integration rule adaptively until an estimate
   of the integral of :math:`f` over :math:`(a,b)` is achieved within the
   desired absolute and relative error limits, :data:`epsabs` and
   :data:`epsrel`.  The function returns the final approximation,
   :data:`result`, and an estimate of the absolute error, :data:`abserr`.  The
   integration rule is determined by the value of :data:`key`, which should
   be chosen from the following symbolic names,

   * .. macro:: GSL_INTEG_GAUSS15  (key = 1)

   * .. macro:: GSL_INTEG_GAUSS21  (key = 2)

   * .. macro:: GSL_INTEG_GAUSS31  (key = 3)

   * .. macro:: GSL_INTEG_GAUSS41  (key = 4)

   * .. macro:: GSL_INTEG_GAUSS51  (key = 5)

   * .. macro:: GSL_INTEG_GAUSS61  (key = 6)

   corresponding to the 15, 21, 31, 41, 51 and 61 point Gauss-Kronrod
   rules.  The higher-order rules give better accuracy for smooth functions,
   while lower-order rules save time when the function contains local
   difficulties, such as discontinuities.

   On each iteration the adaptive integration strategy bisects the interval
   with the largest error estimate.  The subintervals and their results are
   stored in the memory provided by :data:`workspace`.  The maximum number of
   subintervals is given by :data:`limit`, which may not exceed the allocated
   size of the workspace.

QAGS adaptive integration with singularities
============================================
.. index:: QAGS quadrature algorithm

The presence of an integrable singularity in the integration region
causes an adaptive routine to concentrate new subintervals around the
singularity.  As the subintervals decrease in size the successive
approximations to the integral converge in a limiting fashion.  This
approach to the limit can be accelerated using an extrapolation
procedure.  The QAGS algorithm combines adaptive bisection with the Wynn
epsilon-algorithm to speed up the integration of many types of
integrable singularities.

.. function:: int gsl_integration_qags (const gsl_function * f, double a, double b, double epsabs, double epsrel, size_t limit, gsl_integration_workspace * workspace, double * result, double * abserr)

   This function applies the Gauss-Kronrod 21-point integration rule
   adaptively until an estimate of the integral of :math:`f` over
   :math:`(a,b)` is achieved within the desired absolute and relative error
   limits, :data:`epsabs` and :data:`epsrel`.  The results are extrapolated
   using the epsilon-algorithm, which accelerates the convergence of the
   integral in the presence of discontinuities and integrable
   singularities.  The function returns the final approximation from the
   extrapolation, :data:`result`, and an estimate of the absolute error,
   :data:`abserr`.  The subintervals and their results are stored in the
   memory provided by :data:`workspace`.  The maximum number of subintervals
   is given by :data:`limit`, which may not exceed the allocated size of the
   workspace.

QAGP adaptive integration with known singular points
====================================================
.. index::
   single: QAGP quadrature algorithm
   single: singular points, specifying positions in quadrature

.. function:: int gsl_integration_qagp (const gsl_function * f, double * pts, size_t npts, double epsabs, double epsrel, size_t limit, gsl_integration_workspace * workspace, double * result, double * abserr)

   This function applies the adaptive integration algorithm QAGS taking
   account of the user-supplied locations of singular points.  The array
   :data:`pts` of length :data:`npts` should contain the endpoints of the
   integration ranges defined by the integration region and locations of
   the singularities.  For example, to integrate over the region
   :math:`(a,b)` with break-points at :math:`x_1, x_2, x_3` (where 
   :math:`a < x_1 < x_2 < x_3 < b`) the following :data:`pts` array should be used::

     pts[0] = a
     pts[1] = x_1
     pts[2] = x_2
     pts[3] = x_3
     pts[4] = b

   with :data:`npts` = 5.

   If you know the locations of the singular points in the integration
   region then this routine will be faster than :func:`gsl_integration_qags`.

QAGI adaptive integration on infinite intervals
===============================================
.. index:: QAGI quadrature algorithm

.. function:: int gsl_integration_qagi (gsl_function * f, double epsabs, double epsrel, size_t limit, gsl_integration_workspace * workspace, double * result, double * abserr)

   This function computes the integral of the function :data:`f` over the
   infinite interval :math:`(-\infty,+\infty)`.  The integral is mapped onto the
   semi-open interval :math:`(0,1]` using the transformation :math:`x = (1-t)/t`,

   .. math:: \int_{-\infty}^{+\infty} dx f(x) = \int_0^1 dt (f((1-t)/t) + f(-(1-t)/t))/t^2.

   It is then integrated using the QAGS algorithm.  The normal 21-point
   Gauss-Kronrod rule of QAGS is replaced by a 15-point rule, because the
   transformation can generate an integrable singularity at the origin.  In
   this case a lower-order rule is more efficient.

.. function:: int gsl_integration_qagiu (gsl_function * f, double a, double epsabs, double epsrel, size_t limit, gsl_integration_workspace * workspace, double * result, double * abserr)

   This function computes the integral of the function :data:`f` over the
   semi-infinite interval :math:`(a,+\infty)`.  The integral is mapped onto the
   semi-open interval :math:`(0,1]` using the transformation :math:`x = a + (1-t)/t`,

   .. math:: \int_{a}^{+\infty} dx f(x) = \int_0^1 dt f(a + (1-t)/t)/t^2

   and then integrated using the QAGS algorithm.

.. function:: int gsl_integration_qagil (gsl_function * f, double b, double epsabs, double epsrel, size_t limit, gsl_integration_workspace * workspace, double * result, double * abserr)

   This function computes the integral of the function :data:`f` over the
   semi-infinite interval :math:`(-\infty,b)`.  The integral is mapped onto the
   semi-open interval :math:`(0,1]` using the transformation :math:`x = b - (1-t)/t`,

   .. math:: \int_{-\infty}^{b} dx f(x) = \int_0^1 dt f(b - (1-t)/t)/t^2

   and then integrated using the QAGS algorithm.

QAWC adaptive integration for Cauchy principal values
=====================================================
.. index::
   single: QAWC quadrature algorithm
   single: Cauchy principal value, by numerical quadrature

.. function:: int gsl_integration_qawc (gsl_function * f, double a, double b, double c, double epsabs, double epsrel, size_t limit, gsl_integration_workspace * workspace, double * result, double * abserr)

   This function computes the Cauchy principal value of the integral of
   :math:`f` over :math:`(a,b)`, with a singularity at :data:`c`,

   .. only:: not texinfo

      .. math::

         I = \int_a^b dx\, {f(x) \over x - c}
           = \lim_{\epsilon \to 0} 
         \left\{
         \int_a^{c-\epsilon} dx\, {f(x) \over x - c}
         +
         \int_{c+\epsilon}^b dx\, {f(x) \over x - c}
         \right\}

   .. only:: texinfo

      .. math:: I = \int_a^b dx f(x) / (x - c)

   The adaptive bisection algorithm of QAG is used, with modifications to
   ensure that subdivisions do not occur at the singular point :math:`x = c`.
   When a subinterval contains the point :math:`x = c` or is close to
   it then a special 25-point modified Clenshaw-Curtis rule is used to control
   the singularity.  Further away from the
   singularity the algorithm uses an ordinary 15-point Gauss-Kronrod
   integration rule.

QAWS adaptive integration for singular functions
================================================
.. index::
   single: QAWS quadrature algorithm
   single: singular functions, numerical integration of

The QAWS algorithm is designed for integrands with algebraic-logarithmic
singularities at the end-points of an integration region.  In order to
work efficiently the algorithm requires a precomputed table of
Chebyshev moments.

.. type:: gsl_integration_qaws_table

   This structure contains precomputed quantities for the QAWS algorithm.

.. function:: gsl_integration_qaws_table * gsl_integration_qaws_table_alloc (double alpha, double beta, int mu, int nu)

   This function allocates space for a :type:`gsl_integration_qaws_table`
   struct describing a singular weight function
   :math:`w(x)` with the parameters :math:`(\alpha, \beta, \mu, \nu)`,

   .. math:: w(x) = (x - a)^\alpha (b - x)^\beta \log^\mu (x - a) \log^\nu (b - x)

   where :math:`\alpha > -1`, :math:`\beta > -1`, and :math:`\mu = 0, 1`,
   :math:`\nu = 0, 1`.  The weight function can take four different forms
   depending on the values of :math:`\mu` and :math:`\nu`,

   ============================================================      =================
   Weight function :math:`w(x)`                                      :math:`(\mu,\nu)`
   ============================================================      =================
   :math:`(x - a)^\alpha (b - x)^\beta`                              :math:`(0,0)`
   :math:`(x - a)^\alpha (b - x)^\beta \log{(x-a)}`                  :math:`(1,0)`
   :math:`(x - a)^\alpha (b - x)^\beta \log{(b-x)}`                  :math:`(0,1)`
   :math:`(x - a)^\alpha (b - x)^\beta \log{(x-a)} \log{(b-x)}`      :math:`(1,1)`
   ============================================================      =================

   The singular points :math:`(a,b)` do not have to be specified until the
   integral is computed, where they are the endpoints of the integration
   range.

   The function returns a pointer to the newly allocated table
   :type:`gsl_integration_qaws_table` if no errors were detected, and 0 in
   the case of error.

.. function:: int gsl_integration_qaws_table_set (gsl_integration_qaws_table * t, double alpha, double beta, int mu, int nu)

   This function modifies the parameters :math:`(\alpha, \beta, \mu, \nu)` of
   an existing :type:`gsl_integration_qaws_table` struct :data:`t`.

.. function:: void gsl_integration_qaws_table_free (gsl_integration_qaws_table * t)

   This function frees all the memory associated with the
   :type:`gsl_integration_qaws_table` struct :data:`t`.

.. function:: int gsl_integration_qaws (gsl_function * f, const double a, const double b, gsl_integration_qaws_table * t, const double epsabs, const double epsrel, const size_t limit, gsl_integration_workspace * workspace, double * result, double * abserr)

   This function computes the integral of the function :math:`f(x)` over the
   interval :math:`(a,b)` with the singular weight function
   :math:`(x-a)^\alpha (b-x)^\beta \log^\mu (x-a) \log^\nu (b-x)`.  The parameters 
   of the weight function :math:`(\alpha, \beta, \mu, \nu)` are taken from the
   table :data:`t`.  The integral is,

   .. math:: I = \int_a^b dx f(x) (x - a)^\alpha (b - x)^\beta \log^\mu (x - a) \log^\nu (b - x).

   The adaptive bisection algorithm of QAG is used.  When a subinterval
   contains one of the endpoints then a special 25-point modified
   Clenshaw-Curtis rule is used to control the singularities.  For
   subintervals which do not include the endpoints an ordinary 15-point
   Gauss-Kronrod integration rule is used.

QAWO adaptive integration for oscillatory functions
===================================================
.. index::
   single: QAWO quadrature algorithm
   single: oscillatory functions, numerical integration of

The QAWO algorithm is designed for integrands with an oscillatory
factor, :math:`\sin(\omega x)` or :math:`\cos(\omega x)`.  In order to
work efficiently the algorithm requires a table of Chebyshev moments
which must be pre-computed with calls to the functions below.

.. index:: gsl_integration_qawo_table

.. function:: gsl_integration_qawo_table * gsl_integration_qawo_table_alloc (double omega, double L, enum gsl_integration_qawo_enum sine, size_t n)

   This function allocates space for a :type:`gsl_integration_qawo_table`
   struct and its associated workspace describing a sine or cosine weight
   function :math:`w(x)` with the parameters :math:`(\omega, L)`,

   .. only:: not texinfo

      .. math::

         w(x) =
         \left\{
         \begin{array}{c}
         \sin{(\omega x)} \\
         \cos{(\omega x)} \\
         \end{array}
         \right\}

   .. only:: texinfo

      | w(x) = sin(\omega x)
      | w(x) = cos(\omega x)

   The parameter :data:`L` must be the length of the interval over which the
   function will be integrated :math:`L = b - a`.  The choice of sine or
   cosine is made with the parameter :data:`sine` which should be chosen from
   one of the two following symbolic values:

   .. macro:: GSL_INTEG_COSINE

   .. macro:: GSL_INTEG_SINE

   The :type:`gsl_integration_qawo_table` is a table of the trigonometric
   coefficients required in the integration process.  The parameter :data:`n`
   determines the number of levels of coefficients that are computed.  Each
   level corresponds to one bisection of the interval :math:`L`, so that
   :data:`n` levels are sufficient for subintervals down to the length
   :math:`L/2^n`.  The integration routine :func:`gsl_integration_qawo`
   returns the error :code:`GSL_ETABLE` if the number of levels is
   insufficient for the requested accuracy.

.. function:: int gsl_integration_qawo_table_set (gsl_integration_qawo_table * t, double omega, double L, enum gsl_integration_qawo_enum sine)

   This function changes the parameters :data:`omega`, :data:`L` and :data:`sine`
   of the existing workspace :data:`t`.

.. function:: int gsl_integration_qawo_table_set_length (gsl_integration_qawo_table * t, double L)

   This function allows the length parameter :data:`L` of the workspace
   :data:`t` to be changed.

.. function:: void gsl_integration_qawo_table_free (gsl_integration_qawo_table * t)

   This function frees all the memory associated with the workspace :data:`t`.

.. function:: int gsl_integration_qawo (gsl_function * f, const double a, const double epsabs, const double epsrel, const size_t limit, gsl_integration_workspace * workspace, gsl_integration_qawo_table * wf, double * result, double * abserr)

   This function uses an adaptive algorithm to compute the integral of
   :math:`f` over :math:`(a,b)` with the weight function 
   :math:`\sin(\omega x)` or :math:`\cos(\omega x)` defined 
   by the table :data:`wf`,
 
   .. only:: not texinfo

      .. math::

         I = \int_a^b dx f(x)
         \left\{
         \begin{array}{c}
         \sin{(\omega x)} \\
         \cos{(\omega x)}
         \end{array}
         \right\}

   .. only:: texinfo

      | I = \int_a^b dx f(x) sin(omega x)
      | I = \int_a^b dx f(x) cos(omega x)

   The results are extrapolated using the epsilon-algorithm to accelerate
   the convergence of the integral.  The function returns the final
   approximation from the extrapolation, :data:`result`, and an estimate of
   the absolute error, :data:`abserr`.  The subintervals and their results are
   stored in the memory provided by :data:`workspace`.  The maximum number of
   subintervals is given by :data:`limit`, which may not exceed the allocated
   size of the workspace.

   Those subintervals with "large" widths :math:`d` where :math:`d\omega > 4` are
   computed using a 25-point Clenshaw-Curtis integration rule, which handles the
   oscillatory behavior.  Subintervals with a "small" widths where
   :math:`d\omega < 4` are computed using a 15-point Gauss-Kronrod integration.

QAWF adaptive integration for Fourier integrals
===============================================
.. index::
   single: QAWF quadrature algorithm
   single: Fourier integrals, numerical

.. function:: int gsl_integration_qawf (gsl_function * f, const double a, const double epsabs, const size_t limit, gsl_integration_workspace * workspace, gsl_integration_workspace * cycle_workspace, gsl_integration_qawo_table * wf, double * result, double * abserr)

   This function attempts to compute a Fourier integral of the function
   :data:`f` over the semi-infinite interval :math:`[a,+\infty)`

   .. only:: not texinfo

      .. math::

         I = \int_a^{+\infty} dx f(x)
         \left\{
         \begin{array}{c}
         \sin{(\omega x)} \\
         \cos{(\omega x)}
         \end{array}
         \right\}

   .. only:: texinfo

      ::

        I = \int_a^{+\infty} dx f(x) sin(omega x)
        I = \int_a^{+\infty} dx f(x) cos(omega x)

   The parameter :math:`\omega` and choice of :math:`\sin` or :math:`\cos` is
   taken from the table :data:`wf` (the length :data:`L` can take any value,
   since it is overridden by this function to a value appropriate for the
   Fourier integration).  The integral is computed using the QAWO algorithm
   over each of the subintervals,

   .. only:: not texinfo

      .. math::

         C_1 &= [a,a+c] \\
         C_2 &= [a+c,a+2c] \\
         \dots &= \dots \\
         C_k &= [a+(k-1)c,a+kc]

   .. only:: texinfo

      ::

        C_1 = [a, a + c]
        C_2 = [a + c, a + 2 c]
        ... = ...
        C_k = [a + (k-1) c, a + k c]

   where 
   :math:`c = (2 floor(|\omega|) + 1) \pi/|\omega|`.  The width :math:`c` is
   chosen to cover an odd number of periods so that the contributions from
   the intervals alternate in sign and are monotonically decreasing when
   :data:`f` is positive and monotonically decreasing.  The sum of this
   sequence of contributions is accelerated using the epsilon-algorithm.

   This function works to an overall absolute tolerance of
   :data:`abserr`.  The following strategy is used: on each interval
   :math:`C_k` the algorithm tries to achieve the tolerance

   .. math:: TOL_k = u_k abserr

   where 
   :math:`u_k = (1 - p)p^{k-1}` and :math:`p = 9/10`.
   The sum of the geometric series of contributions from each interval
   gives an overall tolerance of :data:`abserr`.

   If the integration of a subinterval leads to difficulties then the
   accuracy requirement for subsequent intervals is relaxed,

   .. only:: not texinfo

      .. math:: TOL_k = u_k \max{(abserr, \max_{i<k}{(E_i)})}

   .. only:: texinfo

      .. math:: TOL_k = u_k max(abserr, max_{i<k}(E_i))

   where :math:`E_k` is the estimated error on the interval :math:`C_k`.

   The subintervals and their results are stored in the memory provided by
   :data:`workspace`.  The maximum number of subintervals is given by
   :data:`limit`, which may not exceed the allocated size of the workspace.
   The integration over each subinterval uses the memory provided by
   :data:`cycle_workspace` as workspace for the QAWO algorithm.

.. index::
   single: cquad, doubly-adaptive integration

CQUAD doubly-adaptive integration
=================================

|cquad| is a new doubly-adaptive general-purpose quadrature
routine which can handle most types of singularities,
non-numerical function values such as :code:`Inf` or :code:`NaN`,
as well as some divergent integrals. It generally requires more
function evaluations than the integration routines in
|quadpack|, yet fails less often for difficult integrands.

The underlying algorithm uses a doubly-adaptive scheme in which
Clenshaw-Curtis quadrature rules of increasing degree are used
to compute the integral in each interval. The :math:`L_2`-norm of
the difference between the underlying interpolatory polynomials
of two successive rules is used as an error estimate. The
interval is subdivided if the difference between two successive
rules is too large or a rule of maximum degree has been reached.
     
.. index:: gsl_integration_cquad_workspace

.. function:: gsl_integration_cquad_workspace * gsl_integration_cquad_workspace_alloc (size_t n) 

   This function allocates a workspace sufficient to hold the data for
   :data:`n` intervals. The number :data:`n` is not the maximum number of
   intervals that will be evaluated. If the workspace is full, intervals
   with smaller error estimates will be discarded. A minimum of 3
   intervals is required and for most functions, a workspace of size 100
   is sufficient.

.. function:: void gsl_integration_cquad_workspace_free (gsl_integration_cquad_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_integration_cquad (const gsl_function * f, double a, double b, double epsabs, double epsrel, gsl_integration_cquad_workspace * workspace,  double * result, double * abserr, size_t * nevals)

   This function computes the integral of :math:`f` over :math:`(a,b)`
   within the desired absolute and relative error limits, :data:`epsabs`
   and :data:`epsrel` using the |cquad| algorithm.  The function returns
   the final approximation, :data:`result`, an estimate of the absolute
   error, :data:`abserr`, and the number of function evaluations required,
   :data:`nevals`.

   The |cquad| algorithm divides the integration region into
   subintervals, and in each iteration, the subinterval with the largest
   estimated error is processed.  The algorithm uses Clenshaw-Curits
   quadrature rules of degree 4, 8, 16 and 32 over 5, 9, 17 and 33 nodes
   respectively. Each interval is initialized with the lowest-degree
   rule. When an interval is processed, the next-higher degree rule is
   evaluated and an error estimate is computed based on the
   :math:`L_2`-norm of the difference between the underlying interpolating
   polynomials of both rules. If the highest-degree rule has already been
   used, or the interpolatory polynomials differ significantly, the
   interval is bisected.

   The subintervals and their results are stored in the memory 
   provided by :data:`workspace`. If the error estimate or the number of 
   function evaluations is not needed, the pointers :data:`abserr` and :data:`nevals`
   can be set to :code:`NULL`.

Romberg integration
===================

The Romberg integration method estimates the definite integral

.. math:: I = \int_a^b f(x) dx

by applying Richardson extrapolation on the trapezoidal rule, using
equally spaced points with spacing

.. math:: h_k = (b - a) 2^{-k}

for :math:`k = 1, \dots, n`. For each :math:`k`, Richardson extrapolation
is used :math:`k-1` times on previous approximations to improve the order
of accuracy as much as possible. Romberg integration typically works
well (and converges quickly) for smooth integrands with no singularities in
the interval or at the end points.

.. function:: gsl_integration_romberg_workspace * gsl_integration_romberg_alloc(const size_t n)

   This function allocates a workspace for Romberg integration, specifying
   a maximum of :math:`n` iterations, or divisions of the interval. Since
   the number of divisions is :math:`2^n + 1`, :math:`n` can be kept relatively
   small (i.e. :math:`10` or :math:`20`). It is capped at a maximum value of
   :math:`30` to prevent overflow. The size of the workspace is :math:`O(2n)`.

.. function:: void gsl_integration_romberg_free(gsl_integration_romberg_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_integration_romberg(const gsl_function * f, const double a, const double b, const double epsabs, const double epsrel, double * result, size_t * neval, gsl_integration_romberg_workspace * w)

   This function integrates :math:`f(x)`, specified by :data:`f`, from :data:`a` to
   :data:`b`, storing the answer in :data:`result`. At each step in the iteration,
   convergence is tested by checking:

   .. math:: | I_k - I_{k-1} | \le \textrm{max} \left( epsabs, epsrel \times |I_k| \right)

   where :math:`I_k` is the current approximation and :math:`I_{k-1}` is the approximation
   of the previous iteration. If the method does not converge within the previously
   specified :math:`n` iterations, the function stores the best current estimate in
   :data:`result` and returns :macro:`GSL_EMAXITER`. If the method converges, the function
   returns :macro:`GSL_SUCCESS`. The total number of function evaluations is returned
   in :data:`neval`.

Gauss-Legendre integration
==========================

The fixed-order Gauss-Legendre integration routines are provided for fast
integration of smooth functions with known polynomial order.  The
:math:`n`-point Gauss-Legendre rule is exact for polynomials of order
:math:`2n - 1` or less.  For example, these rules are useful when integrating
basis functions to form mass matrices for the Galerkin method.  Unlike other
numerical integration routines within the library, these routines do not accept
absolute or relative error bounds.

.. index:: gsl_integration_glfixed_table

.. function:: gsl_integration_glfixed_table * gsl_integration_glfixed_table_alloc (size_t n)

   This function determines the Gauss-Legendre abscissae and weights necessary for
   an :math:`n`-point fixed order integration scheme.  If possible, high precision
   precomputed coefficients are used.  If precomputed weights are not available,
   lower precision coefficients are computed on the fly.

.. function:: double gsl_integration_glfixed (const gsl_function * f, double a, double b, const gsl_integration_glfixed_table * t)

   This function applies the Gauss-Legendre integration rule
   contained in table :data:`t` and returns the result.

.. function:: int gsl_integration_glfixed_point (double a, double b, size_t i, double * xi, double * wi, const gsl_integration_glfixed_table * t)

   For :data:`i` in :math:`[0, \dots, n - 1]`, this function obtains the
   :data:`i`-th Gauss-Legendre point :data:`xi` and weight :data:`wi` on the interval
   [:data:`a`, :data:`b`].  The points and weights are ordered by increasing point
   value.  A function :math:`f` may be integrated on [:data:`a`, :data:`b`] by summing
   :math:`wi * f(xi)` over :data:`i`.

.. index:: gsl_integration_glfixed_table

.. function:: void gsl_integration_glfixed_table_free (gsl_integration_glfixed_table * t)

   This function frees the memory associated with the table :data:`t`.

Fixed point quadratures
=======================

.. index::
   single: interpolating quadrature
   single: quadrature, interpolating
   single: quadrature, fixed point

The routines in this section approximate an integral by the sum

.. math:: \int_a^b w(x) f(x) dx = \sum_{i=1}^n w_i f(x_i)

where :math:`f(x)` is the function to be integrated and :math:`w(x)` is
a weighting function. The :math:`n` weights :math:`w_i` and nodes :math:`x_i` are carefully chosen
so that the result is exact when :math:`f(x)` is a polynomial of degree :math:`2n - 1`
or less. Once the user chooses the order :math:`n` and weighting function :math:`w(x)`, the
weights :math:`w_i` and nodes :math:`x_i` can be precomputed and used to efficiently evaluate
integrals for any number of functions :math:`f(x)`.

This method works best when :math:`f(x)` is well approximated by a polynomial on the interval
:math:`(a,b)`, and so is not suitable for functions with singularities.
Since the user specifies ahead of time how many quadrature nodes will be used, these
routines do not accept absolute or relative error bounds.  The table below lists
the weighting functions currently supported.

.. _tab_fixed-quadratures:

================ ======================== =========================================== =======================================================
Name             Interval                 Weighting function :math:`w(x)`             Constraints
================ ======================== =========================================== =======================================================
Legendre         :math:`(a,b)`            :math:`1`                                   :math:`b > a`
Chebyshev Type 1 :math:`(a,b)`            :math:`1 / \sqrt{(b - x) (x - a)}`          :math:`b > a`
Gegenbauer       :math:`(a,b)`            :math:`((b - x) (x - a))^{\alpha}`          :math:`\alpha > -1, b > a`
Jacobi           :math:`(a,b)`            :math:`(b - x)^{\alpha} (x - a)^{\beta}`    :math:`\alpha,\beta > -1, b > a`
Laguerre         :math:`(a,\infty)`       :math:`(x-a)^{\alpha} \exp{( -b (x - a) )}` :math:`\alpha > -1, b > 0`
Hermite          :math:`(-\infty,\infty)` :math:`|x-a|^{\alpha} \exp{( -b (x-a)^2 )}` :math:`\alpha > -1, b > 0`
Exponential      :math:`(a,b)`            :math:`|x - (a + b)/2|^{\alpha}`            :math:`\alpha > -1, b > a`
Rational         :math:`(a,\infty)`       :math:`(x - a)^{\alpha} (x + b)^{\beta}`    :math:`\alpha > -1, \alpha + \beta + 2n < 0, a + b > 0`
Chebyshev Type 2 :math:`(a,b)`            :math:`\sqrt{(b - x) (x - a)}`              :math:`b > a`
================ ======================== =========================================== =======================================================

The fixed point quadrature routines use the following workspace to store the nodes and weights,
as well as additional variables for intermediate calculations:

.. type:: gsl_integration_fixed_workspace

   This workspace is used for fixed point quadrature rules and looks like this::

     typedef struct
     {
       size_t n;        /* number of nodes/weights */
       double *weights; /* quadrature weights */
       double *x;       /* quadrature nodes */
       double *diag;    /* diagonal of Jacobi matrix */
       double *subdiag; /* subdiagonal of Jacobi matrix */
       const gsl_integration_fixed_type * type;
     } gsl_integration_fixed_workspace;

.. function:: gsl_integration_fixed_workspace * gsl_integration_fixed_alloc(const gsl_integration_fixed_type * T, const size_t n, const double a, const double b, const double alpha, const double beta)

   This function allocates a workspace for computing integrals with interpolating quadratures using :data:`n`
   quadrature nodes. The parameters :data:`a`, :data:`b`, :data:`alpha`, and :data:`beta` specify the integration
   interval and/or weighting function for the various quadrature types. See the :ref:`table <tab_fixed-quadratures>` above
   for constraints on these parameters. The size of the workspace is :math:`O(4n)`.

   .. type:: gsl_integration_fixed_type

      The type of quadrature used is specified by :data:`T` which can be set to the following choices:

      .. var:: gsl_integration_fixed_legendre

         This specifies Legendre quadrature integration. The parameters :data:`alpha` and
         :data:`beta` are ignored for this type.

      .. var:: gsl_integration_fixed_chebyshev

         This specifies Chebyshev type 1 quadrature integration. The parameters :data:`alpha` and
         :data:`beta` are ignored for this type.

      .. var:: gsl_integration_fixed_gegenbauer

         This specifies Gegenbauer quadrature integration. The parameter :data:`beta` is ignored for this type.

      .. var:: gsl_integration_fixed_jacobi

         This specifies Jacobi quadrature integration.

      .. var:: gsl_integration_fixed_laguerre

         This specifies Laguerre quadrature integration. The parameter :data:`beta` is ignored for this type.

      .. var:: gsl_integration_fixed_hermite

         This specifies Hermite quadrature integration. The parameter :data:`beta` is ignored for this type.

      .. var:: gsl_integration_fixed_exponential

         This specifies exponential quadrature integration. The parameter :data:`beta` is ignored for this type.

      .. var:: gsl_integration_fixed_rational

         This specifies rational quadrature integration.

      .. var:: gsl_integration_fixed_chebyshev2

         This specifies Chebyshev type 2 quadrature integration. The parameters :data:`alpha` and
         :data:`beta` are ignored for this type.

.. function:: void gsl_integration_fixed_free(gsl_integration_fixed_workspace * w)

   This function frees the memory assocated with the workspace :data:`w`

.. function:: size_t gsl_integration_fixed_n(const gsl_integration_fixed_workspace * w)

   This function returns the number of quadrature nodes and weights.

.. function:: double * gsl_integration_fixed_nodes(const gsl_integration_fixed_workspace * w)

   This function returns a pointer to an array of size :data:`n` containing the quadrature nodes :math:`x_i`.

.. function:: double * gsl_integration_fixed_weights(const gsl_integration_fixed_workspace * w)

   This function returns a pointer to an array of size :data:`n` containing the quadrature weights :math:`w_i`.

.. function:: int gsl_integration_fixed(const gsl_function * func, double * result, const gsl_integration_fixed_workspace * w)

   This function integrates the function :math:`f(x)` provided in :data:`func` using previously
   computed fixed quadrature rules. The integral is approximated as
   
   .. math:: \sum_{i=1}^n w_i f(x_i)

   where :math:`w_i` are the quadrature weights and :math:`x_i` are the quadrature nodes computed
   previously by :func:`gsl_integration_fixed_alloc`. The sum is stored in :data:`result` on output.

Error codes
===========

In addition to the standard error codes for invalid arguments the
functions can return the following values,

===================== ============================================================================================================
:macro:`GSL_EMAXITER` the maximum number of subdivisions was exceeded.
:macro:`GSL_EROUND`   cannot reach tolerance because of roundoff error, or roundoff error was detected in the extrapolation table.
:macro:`GSL_ESING`    a non-integrable singularity or other bad integrand behavior was found in the integration interval.
:macro:`GSL_EDIVERGE` the integral is divergent, or too slowly convergent to be integrated numerically.
:macro:`GSL_EDOM`     error in the values of the input arguments
===================== ============================================================================================================

Examples
========

Adaptive integration example
----------------------------

The integrator :code:`QAGS` will handle a large class of definite
integrals.  For example, consider the following integral, which has an
algebraic-logarithmic singularity at the origin,

.. math:: \int_0^1 x^{-1/2} \log(x) dx = -4

The program below computes this integral to a relative accuracy bound of
:code:`1e-7`.

.. include:: examples/integration.c
   :code:

The results below show that the desired accuracy is achieved after 8
subdivisions. 

.. include:: examples/integration.txt
   :code:

In fact, the extrapolation procedure used by :code:`QAGS` produces an
accuracy of almost twice as many digits.  The error estimate returned by
the extrapolation procedure is larger than the actual error, giving a
margin of safety of one order of magnitude.

Fixed-point quadrature example
------------------------------

In this example, we use a fixed-point quadrature rule to integrate the
integral

.. math::
   
   \int_{-\infty}^{\infty} e^{-x^2} \left( x^m + 1 \right) dx =
     \left\{
       \begin{array}{cc}
         \sqrt{\pi} + \Gamma{\left( \frac{m+1}{2} \right)}, & m \textrm{ even} \\
         \sqrt{\pi}, & m \textrm{ odd}
       \end{array}
     \right.

for integer :math:`m`. Consulting our :ref:`table <tab_fixed-quadratures>` of fixed point quadratures,
we see that this integral can be evaluated with a Hermite quadrature rule,
setting :math:`\alpha = 0, a = 0, b = 1`. Since we are integrating a polynomial
of degree :math:`m`, we need to choose the number of nodes :math:`n \ge (m+1)/2`
to achieve the best results.

First we will try integrating for :math:`m = 10, n = 5`, which does not satisfy
our criteria above::

  $ ./integration2 10 5

The output is,

.. include:: examples/integration2a.txt
   :code:

So, we find a large error. Now we try integrating for :math:`m = 10, n = 6` which
does satisfy the criteria above::

  $ ./integration2 10 6

The output is,

.. include:: examples/integration2b.txt
   :code:

The program is given below.

.. include:: examples/integration2.c
   :code:

References and Further Reading
==============================

The following book is the definitive reference for |quadpack|, and was
written by the original authors.  It provides descriptions of the
algorithms, program listings, test programs and examples.  It also
includes useful advice on numerical integration and many references to
the numerical integration literature used in developing |quadpack|.

* R. Piessens, E. de Doncker-Kapenga, C.W. Ueberhuber, D.K. Kahaner.
  |quadpack| A subroutine package for automatic integration
  Springer Verlag, 1983.

The |cquad| integration algorithm is described in the following paper:

* P. Gonnet, "Increasing the Reliability of Adaptive Quadrature Using
  Explicit Interpolants", ACM Transactions on Mathematical
  Software, Volume 37 (2010), Issue 3, Article 26.

The fixed-point quadrature routines are based on IQPACK, described in the
following papers:

* S. Elhay, J. Kautsky, Algorithm 655: IQPACK, FORTRAN Subroutines for the
  Weights of Interpolatory Quadrature, ACM Transactions on Mathematical Software,
  Volume 13, Number 4, December 1987, pages 399-415.

* J. Kautsky, S. Elhay, Calculation of the Weights of Interpolatory Quadratures,
  Numerische Mathematik, Volume 40, Number 3, October 1982, pages 407-422.
.. index::
   single: sparse BLAS
   single: BLAS, sparse

*******************
Sparse BLAS Support
*******************

.. include:: include.rst

The Sparse Basic Linear Algebra Subprograms (|blas|) define a set of
fundamental operations on vectors and sparse matrices which can be used
to create optimized higher-level linear algebra functionality.
GSL supports a limited number of BLAS operations for sparse matrices.

The header file :file:`gsl_spblas.h` contains the prototypes for the
sparse BLAS functions and related declarations.

.. index::
   single: sparse matrices, BLAS operations

Sparse BLAS operations
======================

.. function:: int gsl_spblas_dgemv (const CBLAS_TRANSPOSE_t TransA, const double alpha, const gsl_spmatrix * A, const gsl_vector * x, const double beta, gsl_vector * y)

   This function computes the matrix-vector product and sum
   :math:`y \leftarrow \alpha op(A) x + \beta y`, where
   :math:`op(A) = A, A^T` for :data:`TransA` = :code:`CblasNoTrans`,
   :code:`CblasTrans`. In-place computations are not supported, so
   :data:`x` and :data:`y` must be distinct vectors.
   The matrix :data:`A` may be in triplet or compressed format.

.. function:: int gsl_spblas_dgemm (const double alpha, const gsl_spmatrix * A, const gsl_spmatrix * B, gsl_spmatrix * C)

   This function computes the sparse matrix-matrix product
   :math:`C = \alpha A B`. The matrices must be in compressed format.

.. index::
   single: sparse BLAS, references

References and Further Reading
==============================

The algorithms used by these functions are described in the
following sources:

* Davis, T. A., Direct Methods for Sparse Linear Systems, SIAM, 2006.

* CSparse software library, https://www.cise.ufl.edu/research/sparse/CSparse
.. index:: Debye functions

The Debye functions :math:`D_n(x)` are defined by the following integral,

.. only:: not texinfo

   .. math:: D_n(x) = {n \over x^n} \int_0^x dt {t^n \over e^t - 1}

.. only:: texinfo

   .. math:: D_n(x) = n/x^n \int_0^x dt (t^n/(e^t - 1))

For further information see Abramowitz &
Stegun, Section 27.1.  The Debye functions are declared in the header
file :file:`gsl_sf_debye.h`.

.. function:: double gsl_sf_debye_1 (double x)
              int gsl_sf_debye_1_e (double x, gsl_sf_result * result)

   These routines compute the first-order Debye function :math:`D_1(x)`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_debye_2 (double x)
              int gsl_sf_debye_2_e (double x, gsl_sf_result * result)

   These routines compute the second-order Debye function :math:`D_2(x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_debye_3 (double x)
              int gsl_sf_debye_3_e (double x, gsl_sf_result * result)

   These routines compute the third-order Debye function :math:`D_3(x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_debye_4 (double x)
              int gsl_sf_debye_4_e (double x, gsl_sf_result * result)

   These routines compute the fourth-order Debye function :math:`D_4(x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_debye_5 (double x)
              int gsl_sf_debye_5_e (double x, gsl_sf_result * result)

   These routines compute the fifth-order Debye function :math:`D_5(x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_debye_6 (double x)
              int gsl_sf_debye_6_e (double x, gsl_sf_result * result)

   These routines compute the sixth-order Debye function :math:`D_6(x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW
.. index::
   single: quasi-random sequences
   single: low discrepancy sequences
   single: Sobol sequence
   single: Niederreiter sequence

**********************
Quasi-Random Sequences
**********************

.. include:: include.rst

This chapter describes functions for generating quasi-random sequences
in arbitrary dimensions.  A quasi-random sequence progressively covers a
:math:`d`-dimensional space with a set of points that are uniformly
distributed.  Quasi-random sequences are also known as low-discrepancy
sequences.  The quasi-random sequence generators use an interface that
is similar to the interface for random number generators, except that
seeding is not required---each generator produces a single sequence.

The functions described in this section are declared in the header file
:file:`gsl_qrng.h`.

Quasi-random number generator initialization
============================================

.. type:: gsl_qrng

   This is a workspace for computing quasi-random sequences.

.. function:: gsl_qrng * gsl_qrng_alloc (const gsl_qrng_type * T, unsigned int d)

   This function returns a pointer to a newly-created instance of a
   quasi-random sequence generator of type :data:`T` and dimension :data:`d`.
   If there is insufficient memory to create the generator then the
   function returns a null pointer and the error handler is invoked with an
   error code of :macro:`GSL_ENOMEM`.

.. function:: void gsl_qrng_free (gsl_qrng * q)

   This function frees all the memory associated with the generator
   :data:`q`.

.. function:: void gsl_qrng_init (gsl_qrng * q)

   This function reinitializes the generator :data:`q` to its starting point.
   Note that quasi-random sequences do not use a seed and always produce
   the same set of values.

Sampling from a quasi-random number generator
=============================================

.. function:: int gsl_qrng_get (const gsl_qrng * q, double x[])

   This function stores the next point from the sequence generator :data:`q`
   in the array :data:`x`.  The space available for :data:`x` must match the
   dimension of the generator.  The point :data:`x` will lie in the range
   :math:`0 < x_i < 1` for each :math:`x_i`. |inlinefn|

Auxiliary quasi-random number generator functions
=================================================

.. function:: const char * gsl_qrng_name (const gsl_qrng * q)

   This function returns a pointer to the name of the generator.

.. function:: size_t gsl_qrng_size (const gsl_qrng * q)
              void * gsl_qrng_state (const gsl_qrng * q)

   These functions return a pointer to the state of generator :data:`r` and
   its size.  You can use this information to access the state directly.  For
   example, the following code will write the state of a generator to a
   stream::

      void * state = gsl_qrng_state (q);
      size_t n = gsl_qrng_size (q);
      fwrite (state, n, 1, stream);

Saving and restoring quasi-random number generator state
========================================================

.. function:: int gsl_qrng_memcpy (gsl_qrng * dest, const gsl_qrng * src)

   This function copies the quasi-random sequence generator :data:`src` into the
   pre-existing generator :data:`dest`, making :data:`dest` into an exact copy
   of :data:`src`.  The two generators must be of the same type.

.. function:: gsl_qrng * gsl_qrng_clone (const gsl_qrng * q)

   This function returns a pointer to a newly created generator which is an
   exact copy of the generator :data:`q`.

Quasi-random number generator algorithms
========================================

The following quasi-random sequence algorithms are available,

.. type:: gsl_qrng_type

   .. var:: gsl_qrng_niederreiter_2

      This generator uses the algorithm described in Bratley, Fox,
      Niederreiter, ACM Trans. Model. Comp. Sim. 2, 195 (1992). It is
      valid up to 12 dimensions.

   .. var:: gsl_qrng_sobol

      This generator uses the Sobol sequence described in Antonov, Saleev,
      USSR Comput. Maths. Math. Phys. 19, 252 (1980). It is valid up to
      40 dimensions.

   .. var:: gsl_qrng_halton
            gsl_qrng_reversehalton

      These generators use the Halton and reverse Halton sequences described
      in J.H. Halton, Numerische Mathematik, 2, 84-90 (1960) and
      B. Vandewoestyne and R. Cools Computational and Applied
      Mathematics, 189, 1&2, 341-361 (2006).  They are valid up to 1229
      dimensions.

Examples
========

The following program prints the first 1024 points of the 2-dimensional
Sobol sequence.

.. include:: examples/qrng.c
   :code:

Here is the output from the program::

  $ ./a.out
  0.50000 0.50000
  0.75000 0.25000
  0.25000 0.75000
  0.37500 0.37500
  0.87500 0.87500
  0.62500 0.12500
  0.12500 0.62500
  ....

It can be seen that successive points progressively fill-in the spaces
between previous points. 

:numref:`fig_qrng` shows the distribution in the x-y plane of the first
1024 points from the Sobol sequence,

.. _fig_qrng:

.. figure:: /images/qrng.png
   :scale: 60%

   Distribution of the first 1024 points 
   from the quasi-random Sobol sequence

References
==========

The implementations of the quasi-random sequence routines are based on
the algorithms described in the following paper,

* P. Bratley and B.L. Fox and H. Niederreiter, "Algorithm 738: Programs
  to Generate Niederreiter's Low-discrepancy Sequences", ACM
  Transactions on Mathematical Software, Vol.: 20, No.: 4, December, 1994,
  p.: 494--495.
.. index::
   single: acceleration of series
   single: summation, acceleration
   single: series, acceleration
   single: u-transform for series
   single: Levin u-transform
   single: convergence, accelerating a series

*******************
Series Acceleration
*******************

The functions described in this chapter accelerate the convergence of a
series using the Levin :math:`u`-transform.  This method takes a small number of
terms from the start of a series and uses a systematic approximation to
compute an extrapolated value and an estimate of its error.  The
:math:`u`-transform works for both convergent and divergent series, including
asymptotic series.

These functions are declared in the header file :file:`gsl_sum.h`.

Acceleration functions
======================

The following functions compute the full Levin :math:`u`-transform of a series
with its error estimate.  The error estimate is computed by propagating
rounding errors from each term through to the final extrapolation. 

These functions are intended for summing analytic series where each term
is known to high accuracy, and the rounding errors are assumed to
originate from finite precision. They are taken to be relative errors of
order :macro:`GSL_DBL_EPSILON` for each term.

The calculation of the error in the extrapolated value is an
:math:`O(N^2)` process, which is expensive in time and memory.  A faster
but less reliable method which estimates the error from the convergence
of the extrapolated value is described in the next section.  For the
method described here a full table of intermediate values and
derivatives through to :math:`O(N)` must be computed and stored, but this
does give a reliable error estimate.

.. type:: gsl_sum_levin_u_workspace

   Workspace for a Leven :math:`u`-transform.

.. function:: gsl_sum_levin_u_workspace * gsl_sum_levin_u_alloc (size_t n)

   This function allocates a workspace for a Levin :math:`u`-transform of :data:`n`
   terms.  The size of the workspace is :math:`O(2n^2 + 3n)`.

.. function:: void gsl_sum_levin_u_free (gsl_sum_levin_u_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_sum_levin_u_accel (const double * array, size_t array_size, gsl_sum_levin_u_workspace * w, double * sum_accel, double * abserr)

   This function takes the terms of a series in :data:`array` of size
   :data:`array_size` and computes the extrapolated limit of the series using
   a Levin :math:`u`-transform.  Additional working space must be provided in
   :data:`w`.  The extrapolated sum is stored in :data:`sum_accel`, with an
   estimate of the absolute error stored in :data:`abserr`.  The actual
   term-by-term sum is returned in :code:`w->sum_plain`. The algorithm
   calculates the truncation error (the difference between two successive
   extrapolations) and round-off error (propagated from the individual
   terms) to choose an optimal number of terms for the extrapolation.  
   All the terms of the series passed in through :data:`array` should be non-zero.

Acceleration functions without error estimation
===============================================

The functions described in this section compute the Levin :math:`u`-transform of
series and attempt to estimate the error from the "truncation error" in
the extrapolation, the difference between the final two approximations.
Using this method avoids the need to compute an intermediate table of
derivatives because the error is estimated from the behavior of the
extrapolated value itself. Consequently this algorithm is an :math:`O(N)`
process and only requires :math:`O(N)` terms of storage.  If the series
converges sufficiently fast then this procedure can be acceptable.  It
is appropriate to use this method when there is a need to compute many
extrapolations of series with similar convergence properties at high-speed.
For example, when numerically integrating a function defined by a
parameterized series where the parameter varies only slightly. A
reliable error estimate should be computed first using the full
algorithm described above in order to verify the consistency of the
results.

.. type:: gsl_sum_levin_utrunc_workspace

   Workspace for a Levin :math:`u`-transform without error estimation

.. function:: gsl_sum_levin_utrunc_workspace * gsl_sum_levin_utrunc_alloc (size_t n)

   This function allocates a workspace for a Levin :math:`u`-transform of :data:`n`
   terms, without error estimation.  The size of the workspace is
   :math:`O(3n)`.

.. function:: void gsl_sum_levin_utrunc_free (gsl_sum_levin_utrunc_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_sum_levin_utrunc_accel (const double * array, size_t array_size, gsl_sum_levin_utrunc_workspace * w, double * sum_accel, double * abserr_trunc)

   This function takes the terms of a series in :data:`array` of size
   :data:`array_size` and computes the extrapolated limit of the series using
   a Levin :math:`u`-transform.  Additional working space must be provided in
   :data:`w`.  The extrapolated sum is stored in :data:`sum_accel`.  The actual
   term-by-term sum is returned in :code:`w->sum_plain`. The algorithm
   terminates when the difference between two successive extrapolations
   reaches a minimum or is sufficiently small. The difference between these
   two values is used as estimate of the error and is stored in
   :data:`abserr_trunc`.  To improve the reliability of the algorithm the
   extrapolated values are replaced by moving averages when calculating the
   truncation error, smoothing out any fluctuations.

Examples
========

The following code calculates an estimate of :math:`\zeta(2) = \pi^2 / 6`
using the series,

.. math:: \zeta(2) = 1 + 1/2^2 + 1/3^2 + 1/4^2 + \dots

After :data:`N` terms the error in the sum is :math:`O(1/N)`, making direct
summation of the series converge slowly.

.. include:: examples/sum.c
   :code:

The output below shows that the Levin :math:`u`-transform is able to obtain an 
estimate of the sum to 1 part in 
:math:`10^{10}`
using the first eleven terms of the series.  The
error estimate returned by the function is also accurate, giving
the correct number of significant digits. 

.. include:: examples/sum.txt
   :code:

Note that a direct summation of this series would require 
:math:`10^{10}`
terms to achieve the same precision as the accelerated 
sum does in 13 terms.

References and Further Reading
==============================

The algorithms used by these functions are described in the following papers,

* T. Fessler, W.F. Ford, D.A. Smith,
  HURRY: An acceleration algorithm for scalar sequences and series
  *ACM Transactions on Mathematical Software*, 9(3):346--354, 1983.
  and Algorithm 602 9(3):355--357, 1983.

The theory of the :math:`u`-transform was presented by Levin,

* D. Levin,
  Development of Non-Linear Transformations for Improving Convergence of
  Sequences, *Intern.: J.: Computer Math.* B3:371--388, 1973.

A review paper on the Levin Transform is available online,

* Herbert H. H. Homeier, Scalar Levin-Type Sequence Transformations,
  http://arxiv.org/abs/math/0005209
.. index:: eigenvalues and eigenvectors

************
Eigensystems
************

.. include:: include.rst

This chapter describes functions for computing eigenvalues and
eigenvectors of matrices.  There are routines for real symmetric,
real nonsymmetric, complex hermitian, real generalized symmetric-definite,
complex generalized hermitian-definite, and real generalized nonsymmetric
eigensystems. Eigenvalues can be computed with or without eigenvectors.
The hermitian and real symmetric matrix algorithms are symmetric bidiagonalization
followed by QR reduction. The nonsymmetric algorithm is the Francis QR
double-shift.  The generalized nonsymmetric algorithm is the QZ method due
to Moler and Stewart.

The functions described in this chapter are declared in the header file
:file:`gsl_eigen.h`.

Real Symmetric Matrices
=======================
.. index::
   single: symmetric matrix, real, eigensystem
   single: real symmetric matrix, eigensystem

For real symmetric matrices, the library uses the symmetric
bidiagonalization and QR reduction method.  This is described in Golub
& van Loan, section 8.3.  The computed eigenvalues are accurate to an
absolute accuracy of :math:`\epsilon ||A||_2`, where :math:`\epsilon` is
the machine precision.

.. type:: gsl_eigen_symm_workspace

   This workspace contains internal parameters used for solving symmetric eigenvalue
   problems.

.. function:: gsl_eigen_symm_workspace * gsl_eigen_symm_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues of
   :data:`n`-by-:data:`n` real symmetric matrices.  The size of the workspace
   is :math:`O(2n)`.

.. function:: void gsl_eigen_symm_free (gsl_eigen_symm_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_symm (gsl_matrix * A, gsl_vector * eval, gsl_eigen_symm_workspace * w)

   This function computes the eigenvalues of the real symmetric matrix
   :data:`A`.  Additional workspace of the appropriate size must be provided
   in :data:`w`.  The diagonal and lower triangular part of :data:`A` are
   destroyed during the computation, but the strict upper triangular part
   is not referenced.  The eigenvalues are stored in the vector :data:`eval`
   and are unordered.

.. type:: gsl_eigen_symmv_workspace

   This workspace contains internal parameters used for solving symmetric eigenvalue
   and eigenvector problems.

.. function:: gsl_eigen_symmv_workspace * gsl_eigen_symmv_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues and
   eigenvectors of :data:`n`-by-:data:`n` real symmetric matrices.  The size of
   the workspace is :math:`O(4n)`.

.. function:: void gsl_eigen_symmv_free (gsl_eigen_symmv_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_symmv (gsl_matrix * A, gsl_vector * eval, gsl_matrix * evec, gsl_eigen_symmv_workspace * w)

   This function computes the eigenvalues and eigenvectors of the real
   symmetric matrix :data:`A`.  Additional workspace of the appropriate size
   must be provided in :data:`w`.  The diagonal and lower triangular part of
   :data:`A` are destroyed during the computation, but the strict upper
   triangular part is not referenced.  The eigenvalues are stored in the
   vector :data:`eval` and are unordered.  The corresponding eigenvectors are
   stored in the columns of the matrix :data:`evec`.  For example, the
   eigenvector in the first column corresponds to the first eigenvalue.
   The eigenvectors are guaranteed to be mutually orthogonal and normalised
   to unit magnitude.

Complex Hermitian Matrices
==========================

For hermitian matrices, the library uses the complex form of
the symmetric bidiagonalization and QR reduction method.

.. index::
   single: hermitian matrix, complex, eigensystem
   single: complex hermitian matrix, eigensystem

.. type:: gsl_eigen_herm_workspace

   This workspace contains internal parameters used for solving hermitian eigenvalue
   problems.

.. function:: gsl_eigen_herm_workspace * gsl_eigen_herm_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues of
   :data:`n`-by-:data:`n` complex hermitian matrices.  The size of the workspace
   is :math:`O(3n)`.

.. function:: void gsl_eigen_herm_free (gsl_eigen_herm_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_herm (gsl_matrix_complex * A, gsl_vector * eval, gsl_eigen_herm_workspace * w)

   This function computes the eigenvalues of the complex hermitian matrix
   :data:`A`.  Additional workspace of the appropriate size must be provided
   in :data:`w`.  The diagonal and lower triangular part of :data:`A` are
   destroyed during the computation, but the strict upper triangular part
   is not referenced.  The imaginary parts of the diagonal are assumed to be
   zero and are not referenced. The eigenvalues are stored in the vector
   :data:`eval` and are unordered.

.. type:: gsl_eigen_hermv_workspace

   This workspace contains internal parameters used for solving hermitian eigenvalue
   and eigenvector problems.

.. function:: gsl_eigen_hermv_workspace * gsl_eigen_hermv_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues and
   eigenvectors of :data:`n`-by-:data:`n` complex hermitian matrices.  The size of
   the workspace is :math:`O(5n)`.

.. function:: void gsl_eigen_hermv_free (gsl_eigen_hermv_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_hermv (gsl_matrix_complex * A, gsl_vector * eval, gsl_matrix_complex * evec, gsl_eigen_hermv_workspace * w)

   This function computes the eigenvalues and eigenvectors of the complex
   hermitian matrix :data:`A`.  Additional workspace of the appropriate size
   must be provided in :data:`w`.  The diagonal and lower triangular part of
   :data:`A` are destroyed during the computation, but the strict upper
   triangular part is not referenced. The imaginary parts of the diagonal
   are assumed to be zero and are not referenced.  The eigenvalues are
   stored in the vector :data:`eval` and are unordered.  The corresponding
   complex eigenvectors are stored in the columns of the matrix :data:`evec`.
   For example, the eigenvector in the first column corresponds to the
   first eigenvalue.  The eigenvectors are guaranteed to be mutually
   orthogonal and normalised to unit magnitude.

Real Nonsymmetric Matrices
==========================
.. index::
   single: nonsymmetric matrix, real, eigensystem
   single: real nonsymmetric matrix, eigensystem

The solution of the real nonsymmetric eigensystem problem for a
matrix :math:`A` involves computing the Schur decomposition

.. math:: A = Z T Z^T

where :math:`Z` is an orthogonal matrix of Schur vectors and :math:`T`,
the Schur form, is quasi upper triangular with diagonal
:math:`1`-by-:math:`1` blocks which are real eigenvalues of :math:`A`, and
diagonal :math:`2`-by-:math:`2` blocks whose eigenvalues are complex
conjugate eigenvalues of :math:`A`. The algorithm used is the double-shift 
Francis method.

.. type:: gsl_eigen_nonsymm_workspace

   This workspace contains internal parameters used for solving nonsymmetric eigenvalue
   problems.

.. function:: gsl_eigen_nonsymm_workspace * gsl_eigen_nonsymm_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues of
   :data:`n`-by-:data:`n` real nonsymmetric matrices. The size of the workspace
   is :math:`O(2n)`.

.. function:: void gsl_eigen_nonsymm_free (gsl_eigen_nonsymm_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: void gsl_eigen_nonsymm_params (const int compute_t, const int balance, gsl_eigen_nonsymm_workspace * w)

   This function sets some parameters which determine how the eigenvalue
   problem is solved in subsequent calls to :func:`gsl_eigen_nonsymm`.

   If :data:`compute_t` is set to 1, the full Schur form :math:`T` will be
   computed by :func:`gsl_eigen_nonsymm`. If it is set to 0,
   :math:`T` will not be computed (this is the default setting). Computing
   the full Schur form :math:`T` requires approximately 1.5--2 times the
   number of flops.

   If :data:`balance` is set to 1, a balancing transformation is applied
   to the matrix prior to computing eigenvalues. This transformation is
   designed to make the rows and columns of the matrix have comparable
   norms, and can result in more accurate eigenvalues for matrices
   whose entries vary widely in magnitude. See :ref:`Balancing <balancing>` for more
   information. Note that the balancing transformation does not preserve
   the orthogonality of the Schur vectors, so if you wish to compute the
   Schur vectors with :func:`gsl_eigen_nonsymm_Z` you will obtain the Schur
   vectors of the balanced matrix instead of the original matrix. The
   relationship will be

   .. math:: T = Q^T D^{-1} A D Q

   where :data:`Q` is the matrix of Schur vectors for the balanced matrix, and
   :data:`D` is the balancing transformation. Then :func:`gsl_eigen_nonsymm_Z`
   will compute a matrix :data:`Z` which satisfies

   .. math:: T = Z^{-1} A Z

   with :math:`Z = D Q`. Note that :data:`Z` will not be orthogonal. For
   this reason, balancing is not performed by default.

.. function:: int gsl_eigen_nonsymm (gsl_matrix * A, gsl_vector_complex * eval, gsl_eigen_nonsymm_workspace * w)

   This function computes the eigenvalues of the real nonsymmetric matrix
   :data:`A` and stores them in the vector :data:`eval`. If :math:`T` is
   desired, it is stored in the upper portion of :data:`A` on output.
   Otherwise, on output, the diagonal of :data:`A` will contain the
   :math:`1`-by-:math:`1` real eigenvalues and :math:`2`-by-:math:`2`
   complex conjugate eigenvalue systems, and the rest of :data:`A` is
   destroyed. In rare cases, this function may fail to find all
   eigenvalues. If this happens, an error code is returned
   and the number of converged eigenvalues is stored in :code:`w->n_evals`.
   The converged eigenvalues are stored in the beginning of :data:`eval`.

.. function:: int gsl_eigen_nonsymm_Z (gsl_matrix * A, gsl_vector_complex * eval, gsl_matrix * Z, gsl_eigen_nonsymm_workspace * w)

   This function is identical to :func:`gsl_eigen_nonsymm` except that it also
   computes the Schur vectors and stores them into :data:`Z`.

.. type:: gsl_eigen_nonsymmv_workspace

   This workspace contains internal parameters used for solving nonsymmetric eigenvalue
   and eigenvector problems.

.. function:: gsl_eigen_nonsymmv_workspace * gsl_eigen_nonsymmv_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues and
   eigenvectors of :data:`n`-by-:data:`n` real nonsymmetric matrices. The
   size of the workspace is :math:`O(5n)`.

.. function:: void gsl_eigen_nonsymmv_free (gsl_eigen_nonsymmv_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: void gsl_eigen_nonsymmv_params (const int balance, gsl_eigen_nonsymm_workspace * w)

   This function sets parameters which determine how the eigenvalue
   problem is solved in subsequent calls to :func:`gsl_eigen_nonsymmv`.
   If :data:`balance` is set to 1, a balancing transformation is applied
   to the matrix. See :func:`gsl_eigen_nonsymm_params` for more information.
   Balancing is turned off by default since it does not preserve the
   orthogonality of the Schur vectors.

.. function:: int gsl_eigen_nonsymmv (gsl_matrix * A, gsl_vector_complex * eval, gsl_matrix_complex * evec, gsl_eigen_nonsymmv_workspace * w)

   This function computes eigenvalues and right eigenvectors of the
   :data:`n`-by-:data:`n` real nonsymmetric matrix :data:`A`. It first calls
   :func:`gsl_eigen_nonsymm` to compute the eigenvalues, Schur form :math:`T`, and
   Schur vectors. Then it finds eigenvectors of :math:`T` and backtransforms
   them using the Schur vectors. The Schur vectors are destroyed in the
   process, but can be saved by using :func:`gsl_eigen_nonsymmv_Z`. The
   computed eigenvectors are normalized to have unit magnitude. On
   output, the upper portion of :data:`A` contains the Schur form
   :math:`T`. If :func:`gsl_eigen_nonsymm` fails, no eigenvectors are
   computed, and an error code is returned.

.. function:: int gsl_eigen_nonsymmv_Z (gsl_matrix * A, gsl_vector_complex * eval, gsl_matrix_complex * evec, gsl_matrix * Z, gsl_eigen_nonsymmv_workspace * w)

   This function is identical to :func:`gsl_eigen_nonsymmv` except that it also saves
   the Schur vectors into :data:`Z`.

Real Generalized Symmetric-Definite Eigensystems
================================================
.. index:: generalized symmetric eigensystems

The real generalized symmetric-definite eigenvalue problem is to find
eigenvalues :math:`\lambda` and eigenvectors :math:`x` such that

.. math:: A x = \lambda B x

where :math:`A` and :math:`B` are symmetric matrices, and :math:`B` is
positive-definite. This problem reduces to the standard symmetric
eigenvalue problem by applying the Cholesky decomposition to :math:`B`:

.. only:: not texinfo

   .. math::

      A x & = \lambda B x \\
      A x & = \lambda L L^T x \\
      \left( L^{-1} A L^{-T} \right) L^T x & = \lambda L^T x

.. only:: texinfo

   ::

      A x = \lambda B x
      A x = \lambda L L^T x
      ( L^{-1} A L^{-T} ) L^T x = \lambda L^T x

Therefore, the problem becomes :math:`C y = \lambda y` where
:math:`C = L^{-1} A L^{-T}`
is symmetric, and :math:`y = L^T x`. The standard
symmetric eigensolver can be applied to the matrix :math:`C`.
The resulting eigenvectors are backtransformed to find the
vectors of the original problem. The eigenvalues and eigenvectors
of the generalized symmetric-definite eigenproblem are always real.

.. type:: gsl_eigen_gensymm_workspace

   This workspace contains internal parameters used for solving generalized symmetric eigenvalue
   problems.

.. function:: gsl_eigen_gensymm_workspace * gsl_eigen_gensymm_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues of
   :data:`n`-by-:data:`n` real generalized symmetric-definite eigensystems. The
   size of the workspace is :math:`O(2n)`.

.. function:: void gsl_eigen_gensymm_free (gsl_eigen_gensymm_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_gensymm (gsl_matrix * A, gsl_matrix * B, gsl_vector * eval, gsl_eigen_gensymm_workspace * w)

   This function computes the eigenvalues of the real generalized
   symmetric-definite matrix pair (:data:`A`, :data:`B`), and stores them 
   in :data:`eval`, using the method outlined above. On output, :data:`B`
   contains its Cholesky decomposition and :data:`A` is destroyed.

.. type:: gsl_eigen_gensymmv_workspace

   This workspace contains internal parameters used for solving generalized symmetric eigenvalue
   and eigenvector problems.

.. function:: gsl_eigen_gensymmv_workspace * gsl_eigen_gensymmv_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues and
   eigenvectors of :data:`n`-by-:data:`n` real generalized symmetric-definite
   eigensystems. The size of the workspace is :math:`O(4n)`.

.. function:: void gsl_eigen_gensymmv_free (gsl_eigen_gensymmv_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_gensymmv (gsl_matrix * A, gsl_matrix * B, gsl_vector * eval, gsl_matrix * evec, gsl_eigen_gensymmv_workspace * w)

   This function computes the eigenvalues and eigenvectors of the real
   generalized symmetric-definite matrix pair (:data:`A`, :data:`B`), and
   stores them in :data:`eval` and :data:`evec` respectively. The computed
   eigenvectors are normalized to have unit magnitude. On output,
   :data:`B` contains its Cholesky decomposition and :data:`A` is destroyed.

Complex Generalized Hermitian-Definite Eigensystems
===================================================
.. index:: generalized hermitian definite eigensystems

The complex generalized hermitian-definite eigenvalue problem is to find
eigenvalues :math:`\lambda` and eigenvectors :math:`x` such that

.. math:: A x = \lambda B x

where :math:`A` and :math:`B` are hermitian matrices, and :math:`B` is
positive-definite. Similarly to the real case, this can be reduced
to :math:`C y = \lambda y` where
:math:`C = L^{-1} A L^{-\dagger}`
is hermitian, and
:math:`y = L^{\dagger} x`.  The standard
hermitian eigensolver can be applied to the matrix :math:`C`.
The resulting eigenvectors are backtransformed to find the
vectors of the original problem. The eigenvalues
of the generalized hermitian-definite eigenproblem are always real.

.. type:: gsl_eigen_genherm_workspace

   This workspace contains internal parameters used for solving generalized hermitian eigenvalue
   problems.

.. function:: gsl_eigen_genherm_workspace * gsl_eigen_genherm_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues of
   :data:`n`-by-:data:`n` complex generalized hermitian-definite eigensystems. The
   size of the workspace is :math:`O(3n)`.

.. function:: void gsl_eigen_genherm_free (gsl_eigen_genherm_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_genherm (gsl_matrix_complex * A, gsl_matrix_complex * B, gsl_vector * eval, gsl_eigen_genherm_workspace * w)

   This function computes the eigenvalues of the complex generalized
   hermitian-definite matrix pair (:data:`A`, :data:`B`), and stores them 
   in :data:`eval`, using the method outlined above. On output, :data:`B`
   contains its Cholesky decomposition and :data:`A` is destroyed.

.. type:: gsl_eigen_genhermv_workspace

   This workspace contains internal parameters used for solving generalized hermitian eigenvalue
   and eigenvector problems.

.. function:: gsl_eigen_genhermv_workspace * gsl_eigen_genhermv_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues and
   eigenvectors of :data:`n`-by-:data:`n` complex generalized hermitian-definite
   eigensystems. The size of the workspace is :math:`O(5n)`.

.. function:: void gsl_eigen_genhermv_free (gsl_eigen_genhermv_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_genhermv (gsl_matrix_complex * A, gsl_matrix_complex * B, gsl_vector * eval, gsl_matrix_complex * evec, gsl_eigen_genhermv_workspace * w)

   This function computes the eigenvalues and eigenvectors of the complex
   generalized hermitian-definite matrix pair (:data:`A`, :data:`B`), and
   stores them in :data:`eval` and :data:`evec` respectively. The computed
   eigenvectors are normalized to have unit magnitude. On output,
   :data:`B` contains its Cholesky decomposition and :data:`A` is destroyed.

Real Generalized Nonsymmetric Eigensystems
==========================================
.. index:: generalized eigensystems

Given two square matrices (:math:`A`, :math:`B`), the generalized
nonsymmetric eigenvalue problem is to find eigenvalues :math:`\lambda` and
eigenvectors :math:`x` such that

.. math:: A x = \lambda B x

We may also define the problem as finding eigenvalues :math:`\mu` and
eigenvectors :math:`y` such that

.. math:: \mu A y = B y

Note that these two problems are equivalent (with :math:`\lambda = 1/\mu`)
if neither :math:`\lambda` nor :math:`\mu` is zero. If say, :math:`\lambda`
is zero, then it is still a well defined eigenproblem, but its alternate
problem involving :math:`\mu` is not. Therefore, to allow for zero
(and infinite) eigenvalues, the problem which is actually solved is

.. math:: \beta A x = \alpha B x

The eigensolver routines below will return two values :math:`\alpha`
and :math:`\beta` and leave it to the user to perform the divisions
:math:`\lambda = \alpha / \beta` and :math:`\mu = \beta / \alpha`.

If the determinant of the matrix pencil :math:`A - \lambda B` is zero
for all :math:`\lambda`, the problem is said to be singular; otherwise
it is called regular.  Singularity normally leads to some
:math:`\alpha = \beta = 0` which means the eigenproblem is ill-conditioned
and generally does not have well defined eigenvalue solutions. The
routines below are intended for regular matrix pencils and could yield
unpredictable results when applied to singular pencils.

The solution of the real generalized nonsymmetric eigensystem problem for a
matrix pair :math:`(A, B)` involves computing the generalized Schur
decomposition

.. only:: not texinfo

   .. math::

      A &= Q S Z^T \\
      B &= Q T Z^T

.. only:: texinfo

   ::

      A = Q S Z^T
      B = Q T Z^T

where :math:`Q` and :math:`Z` are orthogonal matrices of left and right
Schur vectors respectively, and :math:`(S, T)` is the generalized Schur
form whose diagonal elements give the :math:`\alpha` and :math:`\beta`
values. The algorithm used is the QZ method due to Moler and Stewart
(see references).

.. type:: gsl_eigen_gen_workspace

   This workspace contains internal parameters used for solving generalized eigenvalue
   problems.

.. function:: gsl_eigen_gen_workspace * gsl_eigen_gen_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues of
   :data:`n`-by-:data:`n` real generalized nonsymmetric eigensystems. The
   size of the workspace is :math:`O(n)`.

.. function:: void gsl_eigen_gen_free (gsl_eigen_gen_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: void gsl_eigen_gen_params (const int compute_s, const int compute_t, const int balance, gsl_eigen_gen_workspace * w)

   This function sets some parameters which determine how the eigenvalue
   problem is solved in subsequent calls to :func:`gsl_eigen_gen`.

   If :data:`compute_s` is set to 1, the full Schur form :math:`S` will be
   computed by :func:`gsl_eigen_gen`. If it is set to 0,
   :math:`S` will not be computed (this is the default setting). :math:`S`
   is a quasi upper triangular matrix with 1-by-1 and 2-by-2 blocks
   on its diagonal. 1-by-1 blocks correspond to real eigenvalues, and
   2-by-2 blocks correspond to complex eigenvalues.

   If :data:`compute_t` is set to 1, the full Schur form :math:`T` will be
   computed by :func:`gsl_eigen_gen`. If it is set to 0,
   :math:`T` will not be computed (this is the default setting). :math:`T`
   is an upper triangular matrix with non-negative elements on its diagonal.
   Any 2-by-2 blocks in :math:`S` will correspond to a 2-by-2 diagonal
   block in :math:`T`.

   The :data:`balance` parameter is currently ignored, since generalized
   balancing is not yet implemented.

.. function:: int gsl_eigen_gen (gsl_matrix * A, gsl_matrix * B, gsl_vector_complex * alpha, gsl_vector * beta, gsl_eigen_gen_workspace * w)

   This function computes the eigenvalues of the real generalized nonsymmetric
   matrix pair (:data:`A`, :data:`B`), and stores them as pairs in
   (:data:`alpha`, :data:`beta`), where :data:`alpha` is complex and :data:`beta` is
   real. If :math:`\beta_i` is non-zero, then
   :math:`\lambda = \alpha_i / \beta_i` is an eigenvalue. Likewise,
   if :math:`\alpha_i` is non-zero, then
   :math:`\mu = \beta_i / \alpha_i` is an eigenvalue of the alternate
   problem :math:`\mu A y = B y`. The elements of :data:`beta` are normalized
   to be non-negative.

   If :math:`S` is desired, it is stored in :data:`A` on output. If :math:`T`
   is desired, it is stored in :data:`B` on output. The ordering of
   eigenvalues in (:data:`alpha`, :data:`beta`) follows the ordering
   of the diagonal blocks in the Schur forms :math:`S` and :math:`T`. In rare
   cases, this function may fail to find all eigenvalues. If this occurs, an
   error code is returned.

.. function:: int gsl_eigen_gen_QZ (gsl_matrix * A, gsl_matrix * B, gsl_vector_complex * alpha, gsl_vector * beta, gsl_matrix * Q, gsl_matrix * Z, gsl_eigen_gen_workspace * w)

   This function is identical to :func:`gsl_eigen_gen` except that it also
   computes the left and right Schur vectors and stores them into :data:`Q`
   and :data:`Z` respectively.

.. type:: gsl_eigen_genv_workspace

   This workspace contains internal parameters used for solving generalized eigenvalue
   and eigenvector problems.

.. function:: gsl_eigen_genv_workspace * gsl_eigen_genv_alloc (const size_t n)

   This function allocates a workspace for computing eigenvalues and
   eigenvectors of :data:`n`-by-:data:`n` real generalized nonsymmetric
   eigensystems. The size of the workspace is :math:`O(7n)`.

.. function:: void gsl_eigen_genv_free (gsl_eigen_genv_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_eigen_genv (gsl_matrix * A, gsl_matrix * B, gsl_vector_complex * alpha, gsl_vector * beta, gsl_matrix_complex * evec, gsl_eigen_genv_workspace * w)

   This function computes eigenvalues and right eigenvectors of the
   :data:`n`-by-:data:`n` real generalized nonsymmetric matrix pair
   (:data:`A`, :data:`B`). The eigenvalues are stored in (:data:`alpha`, :data:`beta`)
   and the eigenvectors are stored in :data:`evec`. It first calls
   :func:`gsl_eigen_gen` to compute the eigenvalues, Schur forms, and
   Schur vectors. Then it finds eigenvectors of the Schur forms and
   backtransforms them using the Schur vectors. The Schur vectors are
   destroyed in the process, but can be saved by using
   :func:`gsl_eigen_genv_QZ`. The computed eigenvectors are normalized
   to have unit magnitude. On output, (:data:`A`, :data:`B`) contains
   the generalized Schur form (:math:`S`, :math:`T`). If :func:`gsl_eigen_gen`
   fails, no eigenvectors are computed, and an error code is returned.

.. function:: int gsl_eigen_genv_QZ (gsl_matrix * A, gsl_matrix * B, gsl_vector_complex * alpha, gsl_vector * beta, gsl_matrix_complex * evec, gsl_matrix * Q, gsl_matrix * Z, gsl_eigen_genv_workspace * w)

   This function is identical to :func:`gsl_eigen_genv` except that it also
   computes the left and right Schur vectors and stores them into :data:`Q`
   and :data:`Z` respectively.

Sorting Eigenvalues and Eigenvectors
====================================
.. index:: sorting eigenvalues and eigenvectors

.. function:: int gsl_eigen_symmv_sort (gsl_vector * eval, gsl_matrix * evec, gsl_eigen_sort_t sort_type)

   This function simultaneously sorts the eigenvalues stored in the vector
   :data:`eval` and the corresponding real eigenvectors stored in the columns
   of the matrix :data:`evec` into ascending or descending order according to
   the value of the parameter :data:`sort_type`,

   .. type:: gsl_eigen_sort_t

      ================================= ===================================
      :macro:`GSL_EIGEN_SORT_VAL_ASC`   ascending order in numerical value
      :macro:`GSL_EIGEN_SORT_VAL_DESC`  descending order in numerical value
      :macro:`GSL_EIGEN_SORT_ABS_ASC`   ascending order in magnitude
      :macro:`GSL_EIGEN_SORT_ABS_DESC`  descending order in magnitude
      ================================= ===================================

.. function:: int gsl_eigen_hermv_sort (gsl_vector * eval, gsl_matrix_complex * evec, gsl_eigen_sort_t sort_type)

   This function simultaneously sorts the eigenvalues stored in the vector
   :data:`eval` and the corresponding complex eigenvectors stored in the
   columns of the matrix :data:`evec` into ascending or descending order
   according to the value of the parameter :data:`sort_type` as shown above.

.. function:: int gsl_eigen_nonsymmv_sort (gsl_vector_complex * eval, gsl_matrix_complex * evec, gsl_eigen_sort_t sort_type)

   This function simultaneously sorts the eigenvalues stored in the vector
   :data:`eval` and the corresponding complex eigenvectors stored in the
   columns of the matrix :data:`evec` into ascending or descending order
   according to the value of the parameter :data:`sort_type` as shown above.
   Only :macro:`GSL_EIGEN_SORT_ABS_ASC` and :macro:`GSL_EIGEN_SORT_ABS_DESC` are
   supported due to the eigenvalues being complex.

.. function:: int gsl_eigen_gensymmv_sort (gsl_vector * eval, gsl_matrix * evec, gsl_eigen_sort_t sort_type)

   This function simultaneously sorts the eigenvalues stored in the vector
   :data:`eval` and the corresponding real eigenvectors stored in the columns
   of the matrix :data:`evec` into ascending or descending order according to
   the value of the parameter :data:`sort_type` as shown above.

.. function:: int gsl_eigen_genhermv_sort (gsl_vector * eval, gsl_matrix_complex * evec, gsl_eigen_sort_t sort_type)

   This function simultaneously sorts the eigenvalues stored in the vector
   :data:`eval` and the corresponding complex eigenvectors stored in the columns
   of the matrix :data:`evec` into ascending or descending order according to
   the value of the parameter :data:`sort_type` as shown above.

.. function:: int gsl_eigen_genv_sort (gsl_vector_complex * alpha, gsl_vector * beta, gsl_matrix_complex * evec, gsl_eigen_sort_t sort_type)

   This function simultaneously sorts the eigenvalues stored in the vectors
   (:data:`alpha`, :data:`beta`) and the corresponding complex eigenvectors
   stored in the columns of the matrix :data:`evec` into ascending or
   descending order according to the value of the parameter :data:`sort_type`
   as shown above. Only :macro:`GSL_EIGEN_SORT_ABS_ASC` and
   :macro:`GSL_EIGEN_SORT_ABS_DESC` are supported due to the eigenvalues being
   complex.

Examples
========

The following program computes the eigenvalues and eigenvectors of the 4-th order Hilbert matrix, :math:`H(i,j) = 1/(i + j + 1)`.

.. include:: examples/eigen.c
   :code:

Here is the beginning of the output from the program::

   $ ./a.out 
   eigenvalue = 9.67023e-05
   eigenvector = 
   -0.0291933
   0.328712
   -0.791411
   0.514553
   ...

This can be compared with the corresponding output from |octave|::

   octave> [v,d] = eig(hilb(4));
   octave> diag(d)  
   ans =
   
      9.6702e-05
      6.7383e-03
      1.6914e-01
      1.5002e+00

   octave> v 
   v =
   
      0.029193   0.179186  -0.582076   0.792608
     -0.328712  -0.741918   0.370502   0.451923
      0.791411   0.100228   0.509579   0.322416
     -0.514553   0.638283   0.514048   0.252161

Note that the eigenvectors can differ by a change of sign, since the
sign of an eigenvector is arbitrary.

The following program illustrates the use of the nonsymmetric
eigensolver, by computing the eigenvalues and eigenvectors of
the Vandermonde matrix
:math:`V(x;i,j) = x_i^{n - j}`
with :math:`x = (-1,-2,3,4)`.

.. include:: examples/eigen_nonsymm.c
   :code:

Here is the beginning of the output from the program::

   $ ./a.out 
   eigenvalue = -6.41391 + 0i
   eigenvector = 
   -0.0998822 + 0i
   -0.111251 + 0i
   0.292501 + 0i
   0.944505 + 0i
   eigenvalue = 5.54555 + 3.08545i
   eigenvector = 
   -0.043487 + -0.0076308i
   0.0642377 + -0.142127i
   -0.515253 + 0.0405118i
   -0.840592 + -0.00148565i
   ...

This can be compared with the corresponding output from |octave|::

   octave> [v,d] = eig(vander([-1 -2 3 4]));
   octave> diag(d)
   ans =
   
     -6.4139 + 0.0000i
      5.5456 + 3.0854i
      5.5456 - 3.0854i
      2.3228 + 0.0000i
   
   octave> v
   v =
   
    Columns 1 through 3:
   
     -0.09988 + 0.00000i  -0.04350 - 0.00755i  -0.04350 + 0.00755i
     -0.11125 + 0.00000i   0.06399 - 0.14224i   0.06399 + 0.14224i
      0.29250 + 0.00000i  -0.51518 + 0.04142i  -0.51518 - 0.04142i
      0.94451 + 0.00000i  -0.84059 + 0.00000i  -0.84059 - 0.00000i
   
    Column 4:
   
     -0.14493 + 0.00000i
      0.35660 + 0.00000i
      0.91937 + 0.00000i
      0.08118 + 0.00000i

Note that the eigenvectors corresponding to the eigenvalue
:math:`5.54555 + 3.08545i` differ by the multiplicative constant
:math:`0.9999984 + 0.0017674i` which is an arbitrary phase factor 
of magnitude 1.

References and Further Reading
==============================

Further information on the algorithms described in this section can be
found in the following book,

* G. H. Golub, C. F. Van Loan, "Matrix Computations" (3rd Ed, 1996),
  Johns Hopkins University Press, ISBN 0-8018-5414-8.

Further information on the generalized eigensystems QZ algorithm
can be found in this paper,

* C. Moler, G. Stewart, "An Algorithm for Generalized Matrix Eigenvalue
  Problems", SIAM J. Numer. Anal., Vol 10, No 2, 1973.

.. index:: LAPACK

Eigensystem routines for very large matrices can be found in the
Fortran library |lapack|. The |lapack| library is described in,

* LAPACK Users' Guide (Third Edition, 1999), Published by SIAM,
  ISBN 0-89871-447-8.

The |lapack| source code can be found at the website http://www.netlib.org/lapack
along with an online copy of the users guide.
.. index:: Zeta functions

The Riemann zeta function is defined in Abramowitz & Stegun, Section
23.2.  The functions described in this section are declared in the
header file :file:`gsl_sf_zeta.h`.

Riemann Zeta Function
---------------------
.. index:: Riemann Zeta Function

The Riemann zeta function is defined by the infinite sum

.. math:: \zeta(s) = \sum_{k=1}^\infty k^{-s}

.. function:: double gsl_sf_zeta_int (int n)
              int gsl_sf_zeta_int_e (int n, gsl_sf_result * result)

   These routines compute the Riemann zeta function :math:`\zeta(n)` 
   for integer :data:`n`,
   :math:`n \ne 1`.
.. Domain: n integer, n != 1
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW

.. function:: double gsl_sf_zeta (double s)
              int gsl_sf_zeta_e (double s, gsl_sf_result * result)

   These routines compute the Riemann zeta function :math:`\zeta(s)`
   for arbitrary :data:`s`,
   :math:`s \ne 1`.
.. Domain: s != 1.0
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW

Riemann Zeta Function Minus One
-------------------------------

For large positive argument, the Riemann zeta function approaches one.
In this region the fractional part is interesting, and therefore we
need a function to evaluate it explicitly.

.. function:: double gsl_sf_zetam1_int (int n)
              int gsl_sf_zetam1_int_e (int n, gsl_sf_result * result)

   These routines compute :math:`\zeta(n) - 1` for integer :data:`n`,
   :math:`n \ne 1`.
.. Domain: n integer, n != 1
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW

.. function:: double gsl_sf_zetam1 (double s)
              int gsl_sf_zetam1_e (double s, gsl_sf_result * result)

   These routines compute :math:`\zeta(s) - 1` for arbitrary :data:`s`,
   :math:`s \ne 1`.
.. Domain: s != 1.0
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW

Hurwitz Zeta Function
---------------------
.. index:: Hurwitz Zeta Function

The Hurwitz zeta function is defined by

.. math:: \zeta(s,q) = \sum_0^\infty (k+q)^{-s}

.. function:: double gsl_sf_hzeta (double s, double q)
              int gsl_sf_hzeta_e (double s, double q, gsl_sf_result * result)

   These routines compute the Hurwitz zeta function :math:`\zeta(s,q)` for
   :math:`s > 1`, :math:`q > 0`.
.. Domain: s > 1.0, q > 0.0
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW, GSL_EOVRFLW

Eta Function
------------
.. index:: Eta Function

The eta function is defined by

.. math:: \eta(s) = (1-2^{1-s}) \zeta(s)

.. function:: double gsl_sf_eta_int (int n)
              int gsl_sf_eta_int_e (int n, gsl_sf_result * result)

   These routines compute the eta function :math:`\eta(n)` for integer :data:`n`.
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EOVRFLW

.. function:: double gsl_sf_eta (double s)
              int gsl_sf_eta_e (double s, gsl_sf_result * result)

   These routines compute the eta function :math:`\eta(s)` for arbitrary :data:`s`.
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EOVRFLW
.. index:: sorting, heapsort

*******
Sorting
*******

This chapter describes functions for sorting data, both directly and
indirectly (using an index).  All the functions use the *heapsort*
algorithm.  Heapsort is an :math:`O(N \log N)` algorithm which operates
in-place and does not require any additional storage.  It also provides
consistent performance, the running time for its worst-case (ordered
data) being not significantly longer than the average and best cases.
Note that the heapsort algorithm does not preserve the relative ordering
of equal elements---it is an *unstable* sort.  However the resulting
order of equal elements will be consistent across different platforms
when using these functions.

Sorting objects
===============

The following function provides a simple alternative to the standard
library function :func:`qsort`.  It is intended for systems lacking
:func:`qsort`, not as a replacement for it.  The function :func:`qsort`
should be used whenever possible, as it will be faster and can provide
stable ordering of equal elements.  Documentation for :func:`qsort` is
available in the GNU C Library Reference Manual.

The functions described in this section are defined in the header file
:file:`gsl_heapsort.h`.

.. index::
   single: comparison functions, definition

.. function:: void gsl_heapsort (void * array, size_t count, size_t size, gsl_comparison_fn_t compare)

   This function sorts the :data:`count` elements of the array :data:`array`,
   each of size :data:`size`, into ascending order using the comparison
   function :data:`compare`.  The type of the comparison function is defined by

   .. type:: gsl_comparison_fn_t

      ::

         int (*gsl_comparison_fn_t) (const void * a, const void * b)

   A comparison function should return a negative integer if the first
   argument is less than the second argument, :code:`0` if the two arguments
   are equal and a positive integer if the first argument is greater than
   the second argument.

   For example, the following function can be used to sort doubles into
   ascending numerical order.

   ::

      int
      compare_doubles (const double * a, const double * b)
      {
        if (*a > *b)
          return 1;
        else if (*a < *b)
          return -1;
        else
          return 0;
      }

   The appropriate function call to perform the sort is::

      gsl_heapsort (array, count, sizeof(double), compare_doubles);

   Note that unlike :func:`qsort` the heapsort algorithm cannot be made into
   a stable sort by pointer arithmetic.  The trick of comparing pointers for
   equal elements in the comparison function does not work for the heapsort
   algorithm.  The heapsort algorithm performs an internal rearrangement of
   the data which destroys its initial ordering.

.. index:: indirect sorting

.. function:: int gsl_heapsort_index (size_t * p, const void * array, size_t count, size_t size, gsl_comparison_fn_t compare)

   This function indirectly sorts the :data:`count` elements of the array
   :data:`array`, each of size :data:`size`, into ascending order using the
   comparison function :data:`compare`.  The resulting permutation is stored
   in :data:`p`, an array of length :data:`n`.  The elements of :data:`p` give the
   index of the array element which would have been stored in that position
   if the array had been sorted in place.  The first element of :data:`p`
   gives the index of the least element in :data:`array`, and the last
   element of :data:`p` gives the index of the greatest element in
   :data:`array`.  The array itself is not changed.

Sorting vectors
===============

The following functions will sort the elements of an array or vector,
either directly or indirectly.  They are defined for all real and integer
types using the normal suffix rules.  For example, the :code:`float`
versions of the array functions are :func:`gsl_sort_float` and
:func:`gsl_sort_float_index`.  The corresponding vector functions are
:func:`gsl_sort_vector_float` and :func:`gsl_sort_vector_float_index`.  The
prototypes are available in the header files :file:`gsl_sort_float.h`
:file:`gsl_sort_vector_float.h`.  The complete set of prototypes can be
included using the header files :file:`gsl_sort.h` and
:file:`gsl_sort_vector.h`.

There are no functions for sorting complex arrays or vectors, since the
ordering of complex numbers is not uniquely defined.  To sort a complex
vector by magnitude compute a real vector containing the magnitudes
of the complex elements, and sort this vector indirectly.  The resulting
index gives the appropriate ordering of the original complex vector.

.. index::
   single: sorting vector elements
   single: vector, sorting elements of

.. function:: void gsl_sort (double * data, const size_t stride, size_t n)

   This function sorts the :data:`n` elements of the array :data:`data` with
   stride :data:`stride` into ascending numerical order.

.. function:: void gsl_sort2 (double * data1, const size_t stride1, double * data2, const size_t stride2, size_t n)

   This function sorts the :data:`n` elements of the array :data:`data1` with
   stride :data:`stride1` into ascending numerical order, while making the
   same rearrangement of the array :data:`data2` with stride :data:`stride2`,
   also of size :data:`n`.

.. function:: void gsl_sort_vector (gsl_vector * v)

   This function sorts the elements of the vector :data:`v` into ascending
   numerical order.

.. function:: void gsl_sort_vector2 (gsl_vector * v1, gsl_vector * v2)

   This function sorts the elements of the vector :data:`v1` into ascending
   numerical order, while making the same rearrangement of the vector :data:`v2`.

.. index::
   single: indirect sorting, of vector elements

.. function:: void gsl_sort_index (size_t * p, const double * data, size_t stride, size_t n)

   This function indirectly sorts the :data:`n` elements of the array
   :data:`data` with stride :data:`stride` into ascending order, storing the
   resulting permutation in :data:`p`.  The array :data:`p` must be allocated with
   a sufficient length to store the :data:`n` elements of the permutation.
   The elements of :data:`p` give the index of the array element which would
   have been stored in that position if the array had been sorted in place.
   The array :data:`data` is not changed.

.. function:: int gsl_sort_vector_index (gsl_permutation * p, const gsl_vector * v)

   This function indirectly sorts the elements of the vector :data:`v` into
   ascending order, storing the resulting permutation in :data:`p`.  The
   elements of :data:`p` give the index of the vector element which would
   have been stored in that position if the vector had been sorted in
   place.  The first element of :data:`p` gives the index of the least element
   in :data:`v`, and the last element of :data:`p` gives the index of the
   greatest element in :data:`v`.  The vector :data:`v` is not changed.

Selecting the k smallest or largest elements
============================================

The functions described in this section select the :math:`k` smallest
or largest elements of a data set of size :math:`N`.  The routines use an
:math:`O(kN)` direct insertion algorithm which is suited to subsets that
are small compared with the total size of the dataset. For example, the
routines are useful for selecting the 10 largest values from one million
data points, but not for selecting the largest 100,000 values.  If the
subset is a significant part of the total dataset it may be faster
to sort all the elements of the dataset directly with an :math:`O(N \log N)`
algorithm and obtain the smallest or largest values that way.

.. function:: int gsl_sort_smallest (double * dest, size_t k, const double * src, size_t stride, size_t n)

   This function copies the :data:`k` smallest elements of the array
   :data:`src`, of size :data:`n` and stride :data:`stride`, in ascending
   numerical order into the array :data:`dest`.  The size :data:`k` of the subset must be
   less than or equal to :data:`n`.  The data :data:`src` is not modified by
   this operation.

.. function:: int gsl_sort_largest (double * dest, size_t k, const double * src, size_t stride, size_t n)

   This function copies the :data:`k` largest elements of the array
   :data:`src`, of size :data:`n` and stride :data:`stride`, in descending
   numerical order into the array :data:`dest`. :data:`k` must be
   less than or equal to :data:`n`. The data :data:`src` is not modified by
   this operation.

.. function:: int gsl_sort_vector_smallest (double * dest, size_t k, const gsl_vector * v)
              int gsl_sort_vector_largest (double * dest, size_t k, const gsl_vector * v)

   These functions copy the :data:`k` smallest or largest elements of the
   vector :data:`v` into the array :data:`dest`. :data:`k`
   must be less than or equal to the length of the vector :data:`v`.

The following functions find the indices of the :math:`k` smallest or
largest elements of a dataset.

.. function:: int gsl_sort_smallest_index (size_t * p, size_t k, const double * src, size_t stride, size_t n)

   This function stores the indices of the :data:`k` smallest elements of
   the array :data:`src`, of size :data:`n` and stride :data:`stride`, in the
   array :data:`p`.  The indices are chosen so that the corresponding data is
   in ascending numerical order.  :data:`k` must be
   less than or equal to :data:`n`. The data :data:`src` is not modified by
   this operation.

.. function:: int gsl_sort_largest_index (size_t * p, size_t k, const double * src, size_t stride, size_t n)

   This function stores the indices of the :data:`k` largest elements of
   the array :data:`src`, of size :data:`n` and stride :data:`stride`, in the
   array :data:`p`.  The indices are chosen so that the corresponding data is
   in descending numerical order.  :data:`k` must be
   less than or equal to :data:`n`. The data :data:`src` is not modified by
   this operation.

.. function:: int gsl_sort_vector_smallest_index (size_t * p, size_t k, const gsl_vector * v)
              int gsl_sort_vector_largest_index (size_t * p, size_t k, const gsl_vector * v)

   These functions store the indices of the :data:`k` smallest or largest
   elements of the vector :data:`v` in the array :data:`p`. :data:`k` must be less than or equal to the length of the vector
   :data:`v`.

Computing the rank
==================

The *rank* of an element is its order in the sorted data.  The rank
is the inverse of the index permutation, :math:`p`.  It can be computed
using the following algorithm::

  for (i = 0; i < p->size; i++) 
    {
      size_t pi = p->data[i];
      rank->data[pi] = i;
    }

This can be computed directly from the function
:code:`gsl_permutation_inverse(rank,p)`.

The following function will print the rank of each element of the vector
:math:`v`::

  void
  print_rank (gsl_vector * v)
  {
    size_t i;
    size_t n = v->size;
    gsl_permutation * perm = gsl_permutation_alloc(n);
    gsl_permutation * rank = gsl_permutation_alloc(n);

    gsl_sort_vector_index (perm, v);
    gsl_permutation_inverse (rank, perm);

    for (i = 0; i < n; i++)
      {
        double vi = gsl_vector_get(v, i);
        printf ("element = %d, value = %g, rank = %d\n",
                 i, vi, rank->data[i]);
      }

    gsl_permutation_free (perm);
    gsl_permutation_free (rank);
  }

Examples
========

The following example shows how to use the permutation :math:`p` to print
the elements of the vector :math:`v` in ascending order::

  gsl_sort_vector_index (p, v);

  for (i = 0; i < v->size; i++)
    {
      double vpi = gsl_vector_get (v, p->data[i]);
      printf ("order = %d, value = %g\n", i, vpi);
    }

The next example uses the function :func:`gsl_sort_smallest` to select
the 5 smallest numbers from 100000 uniform random variates stored in an
array,

.. include:: examples/sortsmall.c
   :code:

The output lists the 5 smallest values, in ascending order,

.. include:: examples/sortsmall.txt
   :code:

References and Further Reading
==============================

The subject of sorting is covered extensively in the following,

* Donald E. Knuth, The Art of Computer Programming: Sorting and
  Searching (Vol 3, 3rd Ed, 1997), Addison-Wesley, ISBN 0201896850.

The Heapsort algorithm is described in the following book,

* Robert Sedgewick, Algorithms in C, Addison-Wesley, 
  ISBN 0201514257.
.. index::
   single: power function
   single: integer powers

The following functions are equivalent to the function :func:`gsl_pow_int`
with an error estimate.  These functions are
declared in the header file :file:`gsl_sf_pow_int.h`.

.. function:: double gsl_sf_pow_int (double x, int n)
              int gsl_sf_pow_int_e (double x, int n, gsl_sf_result * result)

   These routines compute the power :math:`x^n` for integer :data:`n`.  The
   power is computed using the minimum number of multiplications. For
   example, :math:`x^8` is computed as :math:`((x^2)^2)^2`, requiring only 3
   multiplications.  For reasons of efficiency, these functions do not
   check for overflow or underflow conditions. The following is a simple example::

      #include <gsl/gsl_sf_pow_int.h>
      /* compute 3.0**12 */
      double y = gsl_sf_pow_int(3.0, 12); 
.. index::
   single: standards conformance, ANSI C
   single: ANSI C, use of
   single: C extensions, compatible use of
   single: compatibility

*****************
Using the Library
*****************

.. include:: include.rst

This chapter describes how to compile programs that use GSL, and
introduces its conventions.  

An Example Program
==================

The following short program demonstrates the use of the library by
computing the value of the Bessel function :math:`J_0(x)` for :math:`x=5`:

.. include:: examples/intro.c
   :code:

The output is shown below, and should be correct to double-precision
accuracy [#f1]_,

.. include:: examples/intro.txt
   :code:

The steps needed to compile this program are described
in the following sections.

.. index::
   single: compiling programs, include paths
   single: including GSL header files
   single: header files, including

Compiling and Linking
=====================

The library header files are installed in their own :file:`gsl`
directory.  You should write any preprocessor include statements with a
:file:`gsl/` directory prefix thus::

    #include <gsl/gsl_math.h>

If the directory is not installed on the standard search path of your
compiler you will also need to provide its location to the preprocessor
as a command line flag.  The default location of the :file:`gsl`
directory is :file:`/usr/local/include/gsl`.  A typical compilation
command for a source file :file:`example.c` with the GNU C compiler
:code:`gcc` is::

    $ gcc -Wall -I/usr/local/include -c example.c

This results in an object file :file:`example.o`. The default
include path for :code:`gcc` searches :file:`/usr/local/include` automatically so
the :code:`-I` option can actually be omitted when GSL is installed 
in its default location.

.. index::
   single: compiling programs, library paths
   single: linking with GSL libraries
   single: libraries, linking with

Linking programs with the library
---------------------------------

The library is installed as a single file, :file:`libgsl.a`.  A shared
version of the library :file:`libgsl.so` is also installed on systems
that support shared libraries.  The default location of these files is
:file:`/usr/local/lib`.  If this directory is not on the standard search
path of your linker you will also need to provide its location as a
command line flag.

To link against the library you need to specify
both the main library and a supporting |cblas| library, which
provides standard basic linear algebra subroutines.  A suitable
|cblas| implementation is provided in the library
:file:`libgslcblas.a` if your system does not provide one.  The following
example shows how to link an application with the library::

    $ gcc -L/usr/local/lib example.o -lgsl -lgslcblas -lm

The default library path for :code:`gcc` searches :file:`/usr/local/lib`
automatically so the :code:`-L` option can be omitted when GSL is
installed in its default location.  

The option :code:`-lm` links with the system math library. On some
systems it is not needed. [#f2]_

For a tutorial introduction to the GNU C Compiler and related programs,
see "An Introduction to GCC" (ISBN 0954161793). [#f3]_

Linking with an alternative BLAS library
----------------------------------------

The following command line shows how you would link the same application
with an alternative |cblas| library :file:`libcblas.a`::

    $ gcc example.o -lgsl -lcblas -lm

For the best performance an optimized platform-specific |cblas|
library should be used for :code:`-lcblas`.  The library must conform to
the |cblas| standard.  The |atlas| package provides a portable
high-performance |blas| library with a |cblas| interface.  It is
free software and should be installed for any work requiring fast vector
and matrix operations.  The following command line will link with the
|atlas| library and its |cblas| interface::

    $ gcc example.o -lgsl -lcblas -latlas -lm

If the |atlas| library is installed in a non-standard directory use
the :code:`-L` option to add it to the search path, as described above.  

For more information about |blas| functions see :ref:`chap_blas-support`.

.. index::
   single: shared libraries
   single: libraries, shared
   single: LD_LIBRARY_PATH

Shared Libraries
================

To run a program linked with the shared version of the library the
operating system must be able to locate the corresponding :file:`.so`
file at runtime.  If the library cannot be found, the following error
will occur::

    $ ./a.out 
    ./a.out: error while loading shared libraries: 
    libgsl.so.0: cannot open shared object file: No such file or directory

To avoid this error, either modify the system dynamic linker
configuration [#f4]_ or
define the shell variable :code:`LD_LIBRARY_PATH` to include the
directory where the library is installed.

For example, in the Bourne shell (:code:`/bin/sh` or :code:`/bin/bash`),
the library search path can be set with the following commands::

    $ LD_LIBRARY_PATH=/usr/local/lib
    $ export LD_LIBRARY_PATH
    $ ./example

In the C-shell (:code:`/bin/csh` or :code:`/bin/tcsh`) the equivalent
command is::

    % setenv LD_LIBRARY_PATH /usr/local/lib

The standard prompt for the C-shell in the example above is the percent
character %, and should not be typed as part of the command.

To save retyping these commands each session they can be placed in an
individual or system-wide login file.

To compile a statically linked version of the program, use the
:code:`-static` flag in :code:`gcc`::

    $ gcc -static example.o -lgsl -lgslcblas -lm

ANSI C Compliance
=================

The library is written in ANSI C and is intended to conform to the ANSI
C standard (C89).  It should be portable to any system with a working
ANSI C compiler.

The library does not rely on any non-ANSI extensions in the interface it
exports to the user.  Programs you write using GSL can be ANSI
compliant.  Extensions which can be used in a way compatible with pure
ANSI C are supported, however, via conditional compilation.  This allows
the library to take advantage of compiler extensions on those platforms
which support them.

When an ANSI C feature is known to be broken on a particular system the
library will exclude any related functions at compile-time.  This should
make it impossible to link a program that would use these functions and
give incorrect results.

To avoid namespace conflicts all exported function names and variables
have the prefix :code:`gsl_`, while exported macros have the prefix
:code:`GSL_`.

.. index::
   single: inline functions
   single: HAVE_INLINE
   single: GSL_C99_INLINE
   single: C99, inline keyword
   single: extern inline

.. _sec_inline-functions:

Inline functions
================

The :code:`inline` keyword is not part of the original ANSI C standard
(C89) so the library does not export any inline function definitions
by default.  Inline functions were introduced officially in the newer
C99 standard but most C89 compilers have also included :code:`inline` as
an extension for a long time.

To allow the use of inline functions, the library provides optional
inline versions of performance-critical routines by conditional
compilation in the exported header files.  The inline versions of these
functions can be included by defining the macro :code:`HAVE_INLINE`
when compiling an application::

    $ gcc -Wall -c -DHAVE_INLINE example.c

If you use :code:`autoconf` this macro can be defined automatically.  If
you do not define the macro :code:`HAVE_INLINE` then the slower
non-inlined versions of the functions will be used instead.

By default, the actual form of the inline keyword is :code:`extern
inline`, which is a :code:`gcc` extension that eliminates unnecessary
function definitions.  If the form :code:`extern inline` causes
problems with other compilers a stricter autoconf test can be used,
see :ref:`chap_autoconf-macros`.

When compiling with :code:`gcc` in C99 mode (:code:`gcc -std=c99`) the
header files automatically switch to C99-compatible inline function
declarations instead of :code:`extern inline`.  With other C99
compilers, define the macro :code:`GSL_C99_INLINE` to use these
declarations.

Long double
===========
.. index:
   long double

In general, the algorithms in the library are written for double
precision only.  The :code:`long double` type is not supported for
actual computation.

One reason for this choice is that the precision of :code:`long double`
is platform dependent.  The IEEE standard only specifies the minimum
precision of extended precision numbers, while the precision of
:code:`double` is the same on all platforms.

However, it is sometimes necessary to interact with external data in
long-double format, so the vector and matrix datatypes include
long-double versions.

It should be noted that in some system libraries the :code:`stdio.h`
formatted input/output functions :code:`printf` and :code:`scanf` are
not implemented correctly for :code:`long double`.  Undefined or
incorrect results are avoided by testing these functions during the
:code:`configure` stage of library compilation and eliminating certain
GSL functions which depend on them if necessary.  The corresponding
line in the :code:`configure` output looks like this::

    checking whether printf works with long double... no

Consequently when :code:`long double` formatted input/output does not
work on a given system it should be impossible to link a program which
uses GSL functions dependent on this.

If it is necessary to work on a system which does not support formatted
:code:`long double` input/output then the options are to use binary
formats or to convert :code:`long double` results into :code:`double` for
reading and writing.

.. _portability-functions:

Portability functions
=====================

To help in writing portable applications GSL provides some
implementations of functions that are found in other libraries, such as
the BSD math library.  You can write your application to use the native
versions of these functions, and substitute the GSL versions via a
preprocessor macro if they are unavailable on another platform. 

For example, after determining whether the BSD function :func:`hypot` is
available you can include the following macro definitions in a file
:file:`config.h` with your application::

    /* Substitute gsl_hypot for missing system hypot */

    #ifndef HAVE_HYPOT
    #define hypot gsl_hypot
    #endif

The application source files can then use the include command
:code:`#include <config.h>` to replace each occurrence of :func:`hypot` by
:func:`gsl_hypot` when :func:`hypot` is not available.  This substitution
can be made automatically if you use :code:`autoconf`, see :ref:`chap_autoconf-macros`.

In most circumstances the best strategy is to use the native versions of
these functions when available, and fall back to GSL versions otherwise,
since this allows your application to take advantage of any
platform-specific optimizations in the system library.  This is the
strategy used within GSL itself.

.. index::
   single: alternative optimized functions
   single: optimized functions, alternatives

Alternative optimized functions
===============================

The main implementation of some functions in the library will not be
optimal on all architectures.  For example, there are several ways to
compute a Gaussian random variate and their relative speeds are
platform-dependent.  In cases like this the library provides alternative
implementations of these functions with the same interface.  If you
write your application using calls to the standard implementation you
can select an alternative version later via a preprocessor definition.
It is also possible to introduce your own optimized functions this way
while retaining portability.  The following lines demonstrate the use of
a platform-dependent choice of methods for sampling from the Gaussian
distribution::

    #ifdef SPARC
    #define gsl_ran_gaussian gsl_ran_gaussian_ratio_method
    #endif
    #ifdef INTEL
    #define gsl_ran_gaussian my_gaussian
    #endif

These lines would be placed in the configuration header file
:file:`config.h` of the application, which should then be included by all
the source files.  Note that the alternative implementations will not
produce bit-for-bit identical results, and in the case of random number
distributions will produce an entirely different stream of random
variates.

Support for different numeric types
===================================

Many functions in the library are defined for different numeric types.
This feature is implemented by varying the name of the function with a
type-related modifier---a primitive form of C++ templates.  The
modifier is inserted into the function name after the initial module
prefix.  The following table shows the function names defined for all
the numeric types of an imaginary module :code:`gsl_foo` with function
:func:`fn`::

    gsl_foo_fn               double        
    gsl_foo_long_double_fn   long double   
    gsl_foo_float_fn         float         
    gsl_foo_long_fn          long          
    gsl_foo_ulong_fn         unsigned long 
    gsl_foo_int_fn           int           
    gsl_foo_uint_fn          unsigned int  
    gsl_foo_short_fn         short         
    gsl_foo_ushort_fn        unsigned short
    gsl_foo_char_fn          char          
    gsl_foo_uchar_fn         unsigned char 

The normal numeric precision :code:`double` is considered the default and
does not require a suffix.  For example, the function
:func:`gsl_stats_mean` computes the mean of double precision numbers,
while the function :func:`gsl_stats_int_mean` computes the mean of
integers.

A corresponding scheme is used for library defined types, such as
:code:`gsl_vector` and :code:`gsl_matrix`.  In this case the modifier is
appended to the type name.  For example, if a module defines a new
type-dependent struct or typedef :code:`gsl_foo` it is modified for other
types in the following way::

    gsl_foo                  double        
    gsl_foo_long_double      long double   
    gsl_foo_float            float         
    gsl_foo_long             long          
    gsl_foo_ulong            unsigned long 
    gsl_foo_int              int           
    gsl_foo_uint             unsigned int  
    gsl_foo_short            short         
    gsl_foo_ushort           unsigned short
    gsl_foo_char             char          
    gsl_foo_uchar            unsigned char 

When a module contains type-dependent definitions the library provides
individual header files for each type.  The filenames are modified as
shown in the below.  For convenience the default header includes the
definitions for all the types.  To include only the double precision
header file, or any other specific type, use its individual filename::

    #include <gsl/gsl_foo.h>               All types
    #include <gsl/gsl_foo_double.h>        double        
    #include <gsl/gsl_foo_long_double.h>   long double   
    #include <gsl/gsl_foo_float.h>         float         
    #include <gsl/gsl_foo_long.h>          long          
    #include <gsl/gsl_foo_ulong.h>         unsigned long 
    #include <gsl/gsl_foo_int.h>           int           
    #include <gsl/gsl_foo_uint.h>          unsigned int  
    #include <gsl/gsl_foo_short.h>         short         
    #include <gsl/gsl_foo_ushort.h>        unsigned short
    #include <gsl/gsl_foo_char.h>          char          
    #include <gsl/gsl_foo_uchar.h>         unsigned char 

.. index::
   single: C++, compatibility
   single: exceptions, C++

Compatibility with C++
======================

The library header files automatically define functions to have
:code:`extern "C"` linkage when included in C++ programs.  This allows
the functions to be called directly from C++.

To use C++ exception handling within user-defined functions passed to
the library as parameters, the library must be built with the
additional :code:`CFLAGS` compilation option :code:`-fexceptions`.

.. index:: aliasing of arrays

.. _aliasing-of-arrays:

Aliasing of arrays
==================

The library assumes that arrays, vectors and matrices passed as
modifiable arguments are not aliased and do not overlap with each other.
This removes the need for the library to handle overlapping memory
regions as a special case, and allows additional optimizations to be
used.  If overlapping memory regions are passed as modifiable arguments
then the results of such functions will be undefined.  If the arguments
will not be modified (for example, if a function prototype declares them
as :code:`const` arguments) then overlapping or aliased memory regions
can be safely used.

Thread-safety
=============

The library can be used in multi-threaded programs.  All the functions
are thread-safe, in the sense that they do not use static variables.
Memory is always associated with objects and not with functions.  For
functions which use *workspace* objects as temporary storage the
workspaces should be allocated on a per-thread basis.  For functions
which use *table* objects as read-only memory the tables can be used
by multiple threads simultaneously.  Table arguments are always declared
:code:`const` in function prototypes, to indicate that they may be
safely accessed by different threads.

There are a small number of static global variables which are used to
control the overall behavior of the library (e.g. whether to use
range-checking, the function to call on fatal error, etc).  These
variables are set directly by the user, so they should be initialized
once at program startup and not modified by different threads.

.. index:: deprecated functions

Deprecated Functions
====================

From time to time, it may be necessary for the definitions of some
functions to be altered or removed from the library.  In these
circumstances the functions will first be declared *deprecated* and
then removed from subsequent versions of the library.  Functions that
are deprecated can be disabled in the current release by setting the
preprocessor definition :code:`GSL_DISABLE_DEPRECATED`.  This allows
existing code to be tested for forwards compatibility.

.. index::
   single: code reuse in applications
   single: source code, reuse in applications

Code Reuse
==========

Where possible the routines in the library have been written to avoid
dependencies between modules and files.  This should make it possible to
extract individual functions for use in your own applications, without
needing to have the whole library installed.  You may need to define
certain macros such as :code:`GSL_ERROR` and remove some :code:`#include`
statements in order to compile the files as standalone units. Reuse of
the library code in this way is encouraged, subject to the terms of the
GNU General Public License.

.. rubric:: Footnotes

.. [#f1] The last few digits may vary slightly depending on the compiler and platform used---this is normal
.. [#f2] It is not needed on MacOS X
.. [#f3] http://www.network-theory.co.uk/gcc/intro/
.. [#f4] :file:`/etc/ld.so.conf` on GNU/Linux systems
.. index:: ntuples

********
N-tuples
********

This chapter describes functions for creating and manipulating
*ntuples*, sets of values associated with events.  The ntuples
are stored in files. Their values can be extracted in any combination
and *booked* in a histogram using a selection function.

The values to be stored are held in a user-defined data structure, and
an ntuple is created associating this data structure with a file.  The
values are then written to the file (normally inside a loop) using
the ntuple functions described below.

A histogram can be created from ntuple data by providing a selection
function and a value function.  The selection function specifies whether
an event should be included in the subset to be analyzed or not. The value
function computes the entry to be added to the histogram for each
event.

All the ntuple functions are defined in the header file
:file:`gsl_ntuple.h`.

The ntuple struct
=================

.. type:: gsl_ntuple

   Ntuples are manipulated using the :type:`gsl_ntuple` struct. This struct
   contains information on the file where the ntuple data is stored, a
   pointer to the current ntuple data row and the size of the user-defined
   ntuple data struct::

      typedef struct
        {
          FILE * file;
          void * ntuple_data;
          size_t size;
        } gsl_ntuple;

Creating ntuples
================

.. function:: gsl_ntuple * gsl_ntuple_create (char * filename, void * ntuple_data, size_t size)

   This function creates a new write-only ntuple file :data:`filename` for
   ntuples of size :data:`size` and returns a pointer to the newly created
   ntuple struct.  Any existing file with the same name is truncated to
   zero length and overwritten.  A pointer to memory for the current ntuple
   row :data:`ntuple_data` must be supplied---this is used to copy ntuples
   in and out of the file.

Opening an existing ntuple file
===============================

.. function:: gsl_ntuple * gsl_ntuple_open (char * filename, void * ntuple_data, size_t size)

   This function opens an existing ntuple file :data:`filename` for reading
   and returns a pointer to a corresponding ntuple struct. The ntuples in
   the file must have size :data:`size`.  A pointer to memory for the current
   ntuple row :data:`ntuple_data` must be supplied---this is used to copy
   ntuples in and out of the file.

Writing ntuples
===============

.. function:: int gsl_ntuple_write (gsl_ntuple * ntuple)

   This function writes the current ntuple :code:`ntuple->ntuple_data` of
   size :code:`ntuple->size` to the corresponding file.

.. function:: int gsl_ntuple_bookdata (gsl_ntuple * ntuple)

   This function is a synonym for :func:`gsl_ntuple_write`.

Reading ntuples
===============

.. function:: int gsl_ntuple_read (gsl_ntuple * ntuple)

   This function reads the current row of the ntuple file for :data:`ntuple`
   and stores the values in :code:`ntuple->data`.

Closing an ntuple file
======================

.. function:: int gsl_ntuple_close (gsl_ntuple * ntuple)

   This function closes the ntuple file :data:`ntuple` and frees its
   associated allocated memory.

Histogramming ntuple values
===========================

Once an ntuple has been created its contents can be histogrammed in
various ways using the function :func:`gsl_ntuple_project`.  Two
user-defined functions must be provided, a function to select events and
a function to compute scalar values. The selection function and the
value function both accept the ntuple row as a first argument and other
parameters as a second argument.

.. index::
   single: selection function, ntuples

.. type:: gsl_ntuple_select_fn

   The *selection function* determines which ntuple rows are selected
   for histogramming.  It is defined by the following struct::

      typedef struct
        {
          int (* function) (void * ntuple_data, void * params);
          void * params;
        } gsl_ntuple_select_fn;

   The struct component :data:`function` should return a non-zero value for
   each ntuple row that is to be included in the histogram.

.. index::
   single: value function, ntuples

.. type:: gsl_ntuple_value_fn

   The *value function* computes scalar values for those ntuple rows
   selected by the selection function::

      typedef struct
        {
          double (* function) (void * ntuple_data, void * params);
          void * params;
        } gsl_ntuple_value_fn;

   In this case the struct component :data:`function` should return the value
   to be added to the histogram for the ntuple row.  

.. index::
   single: histogram, from ntuple
   single: projection of ntuples

.. function:: int gsl_ntuple_project (gsl_histogram * h, gsl_ntuple * ntuple, gsl_ntuple_value_fn * value_func, gsl_ntuple_select_fn * select_func)

   This function updates the histogram :data:`h` from the ntuple :data:`ntuple`
   using the functions :data:`value_func` and :data:`select_func`. For each
   ntuple row where the selection function :data:`select_func` is non-zero the
   corresponding value of that row is computed using the function
   :data:`value_func` and added to the histogram.  Those ntuple rows where
   :data:`select_func` returns zero are ignored.  New entries are added to
   the histogram, so subsequent calls can be used to accumulate further
   data in the same histogram.

Examples
========

The following example programs demonstrate the use of ntuples in
managing a large dataset.  The first program creates a set of 10,000
simulated "events", each with 3 associated values :math:`(x,y,z)`.  These
are generated from a Gaussian distribution with unit variance, for
demonstration purposes, and written to the ntuple file :file:`test.dat`.

.. include:: examples/ntuplew.c
   :code:

The next program analyses the ntuple data in the file :file:`test.dat`.
The analysis procedure is to compute the squared-magnitude of each
event, :math:`E^2=x^2+y^2+z^2`, and select only those which exceed a
lower limit of 1.5.  The selected events are then histogrammed using
their :math:`E^2` values.

.. include:: examples/ntupler.c
   :code:

:numref:`fig_ntuples` shows the distribution of the selected events.
Note the cut-off at the lower bound.

.. _fig_ntuples:

.. figure:: /images/ntuple.png
   :scale: 60%

   Distribution of selected events

References and Further Reading
==============================

.. index:: PAW, HBOOK

Further information on the use of ntuples can be found in the
documentation for the CERN packages PAW and HBOOK
(available online).
.. index::
   single: error function
   single: erf(x)
   single: erfc(x)

The error function is described in Abramowitz & Stegun, Chapter 7.  The
functions in this section are declared in the header file
:file:`gsl_sf_erf.h`.

Error Function
--------------

.. function:: double gsl_sf_erf (double x)
              int gsl_sf_erf_e (double x, gsl_sf_result * result)

   These routines compute the error function :math:`\erf(x)`,
   where
   :math:`\erf(x) = (2/\sqrt{\pi}) \int_0^x dt \exp(-t^2)`.
.. Exceptional Return Values: none

Complementary Error Function
----------------------------

.. function:: double gsl_sf_erfc (double x)
              int gsl_sf_erfc_e (double x, gsl_sf_result * result)

   These routines compute the complementary error function 
   :math:`\erfc(x) = 1 - \erf(x) = (2/\sqrt{\pi}) \int_x^\infty \exp(-t^2)`
.. Exceptional Return Values: none

Log Complementary Error Function
--------------------------------

.. function:: double gsl_sf_log_erfc (double x)
              int gsl_sf_log_erfc_e (double x, gsl_sf_result * result)

   These routines compute the logarithm of the complementary error function
   :math:`\log(\erfc(x))`.
.. Exceptional Return Values: none

Probability functions
---------------------

The probability functions for the Normal or Gaussian distribution are
described in Abramowitz & Stegun, Section 26.2.

.. function:: double gsl_sf_erf_Z (double x)
              int gsl_sf_erf_Z_e (double x, gsl_sf_result * result)

   These routines compute the Gaussian probability density function 
   :math:`Z(x) = (1/\sqrt{2\pi}) \exp(-x^2/2)`

.. function:: double gsl_sf_erf_Q (double x)
              int gsl_sf_erf_Q_e (double x, gsl_sf_result * result)

   These routines compute the upper tail of the Gaussian probability function 
   :math:`Q(x) = (1/\sqrt{2\pi}) \int_x^\infty dt \exp(-t^2/2)`

.. Exceptional Return Values: none

.. index::
   single: hazard function, normal distribution
   single:  Mills' ratio, inverse

The *hazard function* for the normal distribution, 
also known as the inverse Mills' ratio, is defined as,

.. only:: not texinfo

   .. math:: h(x) = {Z(x) \over Q(x)} = \sqrt{2 \over \pi} {\exp(-x^2 / 2) \over \erfc(x/\sqrt 2)}

.. only:: texinfo

   ::

      h(x) = Z(x)/Q(x) = \sqrt{2/\pi} \exp(-x^2 / 2) / \erfc(x/\sqrt 2)

It decreases rapidly as :math:`x` approaches :math:`-\infty` and asymptotes
to :math:`h(x) \sim x` as :math:`x` approaches :math:`+\infty`.

.. function:: double gsl_sf_hazard (double x)
              int gsl_sf_hazard_e (double x, gsl_sf_result * result)

   These routines compute the hazard function for the normal distribution.
.. Exceptional Return Values: GSL_EUNDRFLW
.. index::
   single: differentiation of functions, numeric
   single: functions, numerical differentiation
   single: derivatives, calculating numerically
   single: numerical derivatives
   single: slope, see numerical derivative

*************************
Numerical Differentiation
*************************

The functions described in this chapter compute numerical derivatives by
finite differencing.  An adaptive algorithm is used to find the best
choice of finite difference and to estimate the error in the derivative.
These functions are declared in the header file :file:`gsl_deriv.h`.

Functions
=========

.. function:: int gsl_deriv_central (const gsl_function * f, double x, double h, double * result, double * abserr)

   This function computes the numerical derivative of the function :data:`f`
   at the point :data:`x` using an adaptive central difference algorithm with
   a step-size of :data:`h`.   The derivative is returned in :data:`result` and an
   estimate of its absolute error is returned in :data:`abserr`.

   The initial value of :data:`h` is used to estimate an optimal step-size,
   based on the scaling of the truncation error and round-off error in the
   derivative calculation.  The derivative is computed using a 5-point rule
   for equally spaced abscissae at :math:`x - h`, :math:`x - h/2`, :math:`x`,
   :math:`x + h/2`, :math:`x+h`, with an error estimate taken from the difference
   between the 5-point rule and the corresponding 3-point rule :math:`x-h`,
   :math:`x`, :math:`x+h`.  Note that the value of the function at :math:`x`
   does not contribute to the derivative calculation, so only 4-points are
   actually used.

.. function:: int gsl_deriv_forward (const gsl_function * f, double x, double h, double * result, double * abserr)

   This function computes the numerical derivative of the function :data:`f`
   at the point :data:`x` using an adaptive forward difference algorithm with
   a step-size of :data:`h`. The function is evaluated only at points greater
   than :data:`x`, and never at :data:`x` itself.  The derivative is returned in
   :data:`result` and an estimate of its absolute error is returned in
   :data:`abserr`.  This function should be used if :math:`f(x)` has a
   discontinuity at :data:`x`, or is undefined for values less than :data:`x`.

   The initial value of :data:`h` is used to estimate an optimal step-size,
   based on the scaling of the truncation error and round-off error in the
   derivative calculation.  The derivative at :math:`x` is computed using an
   "open" 4-point rule for equally spaced abscissae at :math:`x+h/4`,
   :math:`x + h/2`, :math:`x + 3h/4`, :math:`x+h`, with an error estimate taken
   from the difference between the 4-point rule and the corresponding
   2-point rule :math:`x+h/2`, :math:`x+h`. 

.. function:: int gsl_deriv_backward (const gsl_function * f, double x, double h, double * result, double * abserr)

   This function computes the numerical derivative of the function :data:`f`
   at the point :data:`x` using an adaptive backward difference algorithm
   with a step-size of :data:`h`. The function is evaluated only at points
   less than :data:`x`, and never at :data:`x` itself.  The derivative is
   returned in :data:`result` and an estimate of its absolute error is
   returned in :data:`abserr`.  This function should be used if :math:`f(x)`
   has a discontinuity at :data:`x`, or is undefined for values greater than
   :data:`x`.

   This function is equivalent to calling :func:`gsl_deriv_forward` with a
   negative step-size.

Examples
========

The following code estimates the derivative of the function 
:math:`f(x) = x^{3/2}`
at :math:`x = 2` and at :math:`x = 0`.  The function :math:`f(x)` is
undefined for :math:`x < 0` so the derivative at :math:`x=0` is computed
using :func:`gsl_deriv_forward`.

.. include:: examples/diff.c
   :code:

Here is the output of the program,

.. include:: examples/diff.txt
   :code:

References and Further Reading
==============================

The algorithms used by these functions are described in the following sources:

* Abramowitz and Stegun, *Handbook of Mathematical Functions*,
  Section 25.3.4, and Table 25.5 (Coefficients for Differentiation).

* S.D. Conte and Carl de Boor, *Elementary Numerical Analysis: An
  Algorithmic Approach*, McGraw-Hill, 1972.
****************************
Debugging Numerical Programs
****************************

This chapter describes some tips and tricks for debugging numerical
programs which use GSL.

.. index::
   single: gdb
   single: debugging numerical programs
   single: breakpoints

Using gdb
=========

Any errors reported by the library are passed to the function
:func:`gsl_error`.  By running your programs under gdb and setting a
breakpoint in this function you can automatically catch any library
errors.  You can add a breakpoint for every session by putting::

  break gsl_error

into your :file:`.gdbinit` file in the directory where your program is
started.  

If the breakpoint catches an error then you can use a backtrace
(:code:`bt`) to see the call-tree, and the arguments which possibly
caused the error.  By moving up into the calling function you can
investigate the values of variables at that point.  Here is an example
from the program :code:`fft/test_trap`, which contains the following
line::

  status = gsl_fft_complex_wavetable_alloc (0, &complex_wavetable);

The function :func:`gsl_fft_complex_wavetable_alloc` takes the length of
an FFT as its first argument.  When this line is executed an error will
be generated because the length of an FFT is not allowed to be zero.

To debug this problem we start :code:`gdb`, using the file
:file:`.gdbinit` to define a breakpoint in :func:`gsl_error`::

  $ gdb test_trap

  GDB is free software and you are welcome to distribute copies
  of it under certain conditions; type "show copying" to see
  the conditions.  There is absolutely no warranty for GDB;
  type "show warranty" for details.  GDB 4.16 (i586-debian-linux), 
  Copyright 1996 Free Software Foundation, Inc.

  Breakpoint 1 at 0x8050b1e: file error.c, line 14.

When we run the program this breakpoint catches the error and shows the
reason for it::

  (gdb) run
  Starting program: test_trap 

  Breakpoint 1, gsl_error (reason=0x8052b0d 
      "length n must be positive integer", 
      file=0x8052b04 "c_init.c", line=108, gsl_errno=1) 
      at error.c:14
  14        if (gsl_error_handler) 

The first argument of :func:`gsl_error` is always a string describing the
error.  Now we can look at the backtrace to see what caused the problem::

  (gdb) bt
  #0  gsl_error (reason=0x8052b0d 
      "length n must be positive integer", 
      file=0x8052b04 "c_init.c", line=108, gsl_errno=1)
      at error.c:14
  #1  0x8049376 in gsl_fft_complex_wavetable_alloc (n=0,
      wavetable=0xbffff778) at c_init.c:108
  #2  0x8048a00 in main (argc=1, argv=0xbffff9bc) 
      at test_trap.c:94
  #3  0x80488be in ___crt_dummy__ ()

We can see that the error was generated in the function
:func:`gsl_fft_complex_wavetable_alloc` when it was called with an
argument of :code:`n = 0`.  The original call came from line 94 in the
file :file:`test_trap.c`.

By moving up to the level of the original call we can find the line that
caused the error::

  (gdb) up
  #1  0x8049376 in gsl_fft_complex_wavetable_alloc (n=0,
      wavetable=0xbffff778) at c_init.c:108
  108   GSL_ERROR ("length n must be positive integer", GSL_EDOM);
  (gdb) up
  #2  0x8048a00 in main (argc=1, argv=0xbffff9bc) 
    at test_trap.c:94
  94    status = gsl_fft_complex_wavetable_alloc (0,
          &complex_wavetable);

Thus we have found the line that caused the problem.  From this point we
could also print out the values of other variables such as
:code:`complex_wavetable`.

.. index:: floating point registers

Examining floating point registers
==================================

The contents of floating point registers can be examined using the
command :code:`info float` (on supported platforms)::

  (gdb) info float
       st0: 0xc4018b895aa17a945000  Valid Normal -7.838871e+308
       st1: 0x3ff9ea3f50e4d7275000  Valid Normal 0.0285946
       st2: 0x3fe790c64ce27dad4800  Valid Normal 6.7415931e-08
       st3: 0x3ffaa3ef0df6607d7800  Spec  Normal 0.0400229
       st4: 0x3c028000000000000000  Valid Normal 4.4501477e-308
       st5: 0x3ffef5412c22219d9000  Zero  Normal 0.9580257
       st6: 0x3fff8000000000000000  Valid Normal 1
       st7: 0xc4028b65a1f6d243c800  Valid Normal -1.566206e+309
     fctrl: 0x0272 53 bit; NEAR; mask DENOR UNDER LOS;
     fstat: 0xb9ba flags 0001; top 7; excep DENOR OVERF UNDER LOS
      ftag: 0x3fff
       fip: 0x08048b5c
       fcs: 0x051a0023
    fopoff: 0x08086820
    fopsel: 0x002b

Individual registers can be examined using the variables :code:`$reg`,
where :code:`reg` is the register name::

  (gdb) p $st1 
  $1 = 0.02859464454261210347719

.. index::
   single: exceptions, floating point
   single: floating point exceptions

Handling floating point exceptions
==================================

It is possible to stop the program whenever a :code:`SIGFPE` floating
point exception occurs.  This can be useful for finding the cause of an
unexpected infinity or :code:`NaN`.  The current handler settings can be
shown with the command :code:`info signal SIGFPE`::

  (gdb) info signal SIGFPE
  Signal  Stop  Print  Pass to program Description
  SIGFPE  Yes   Yes    Yes             Arithmetic exception

Unless the program uses a signal handler the default setting should be
changed so that SIGFPE is not passed to the program, as this would cause
it to exit.  The command :code:`handle SIGFPE stop nopass` prevents this::

  (gdb) handle SIGFPE stop nopass
  Signal  Stop  Print  Pass to program Description
  SIGFPE  Yes   Yes    No              Arithmetic exception

Depending on the platform it may be necessary to instruct the kernel to
generate signals for floating point exceptions.  For programs using GSL
this can be achieved using the :macro:`GSL_IEEE_MODE` environment variable
in conjunction with the function :func:`gsl_ieee_env_setup` as described
in :ref:`chap_ieee`::

  (gdb) set env GSL_IEEE_MODE=double-precision

.. index::
   single: warning options
   single: gcc warning options

GCC warning options for numerical programs
==========================================

Writing reliable numerical programs in C requires great care.  The
following GCC warning options are recommended when compiling numerical
programs::

  gcc -ansi -pedantic -Werror -Wall -W 
    -Wmissing-prototypes -Wstrict-prototypes 
    -Wconversion -Wshadow -Wpointer-arith 
    -Wcast-qual -Wcast-align 
    -Wwrite-strings -Wnested-externs 
    -fshort-enums -fno-common -Dinline= -g -O2

.. Uninitialized variables, conversions to and from integers or from
.. signed to unsigned integers can all cause hard-to-find problems.  For
.. many non-numerical programs compiling with :code:`gcc`'s warning option
.. :code:`-Wall` provides a good check against common errors.  However, for
.. numerical programs :code:`-Wall` is not enough. 

.. If you are unconvinced take a look at this program which contains an
.. error that can occur in numerical code,

.. @example
.. #include <math.h>
.. #include <stdio.h>

.. double f (int x);

.. int main ()
.. @{
..   double a = 1.5;
..   double y = f(a);
..   printf("a = %g, sqrt(a) = %g\n", a, y);  
..   return 0;
.. @}

.. double f(x) @{
..   return sqrt(x);
.. @}
.. @end example

.. @noindent
.. This code compiles cleanly with :code:`-Wall` but produces some strange
.. output,

.. @example
.. bash$ gcc -Wall tmp.c -lm
.. bash$ ./a.out 
.. a = 1.5, sqrt(a) = 1
.. @end example

.. @noindent
.. Note that adding :code:`-ansi` does not help here, since the program does
.. not contain any invalid constructs.  What is happening is that the
.. prototype for the function :code:`f(int x)` is not consistent with the
.. function call :code:`f(y)`, where :code:`y` is a floating point
.. number.  This results in the argument being silently converted to an
.. integer.  This is valid C, but in a numerical program it also likely to
.. be a programming error so we would like to be warned about it. (If we
.. genuinely wanted to convert :code:`y` to an integer then we could use an
.. explicit cast, :code:`(int)y`).  

.. Fortunately GCC provides many additional warnings which can alert you to
.. problems such as this.  You just have to remember to use them.  Here is a
.. set of recommended warning options for numerical programs.

For details of each option consult the manual *Using and Porting
GCC*.  The following table gives a brief explanation of what types of
errors these options catch.

:code:`-ansi -pedantic`

  Use ANSI C, and reject any non-ANSI extensions.  These flags help in
  writing portable programs that will compile on other systems.

:code:`-Werror`

  Consider warnings to be errors, so that compilation stops.  This prevents
  warnings from scrolling off the top of the screen and being lost.  You
  won't be able to compile the program until it is completely
  warning-free.

:code:`-Wall`

  This turns on a set of warnings for common programming problems.  You
  need :code:`-Wall`, but it is not enough on its own.

:code:`-O2`

  Turn on optimization.  The warnings for uninitialized variables in
  :code:`-Wall` rely on the optimizer to analyze the code.  If there is no
  optimization then these warnings aren't generated.

:code:`-W`

  This turns on some extra warnings not included in :code:`-Wall`, such as
  missing return values and comparisons between signed and unsigned
  integers.

:code:`-Wmissing-prototypes -Wstrict-prototypes`

  Warn if there are any missing or inconsistent prototypes.  Without
  prototypes it is harder to detect problems with incorrect arguments.

:code:`-Wconversion`

  The main use of this option is to warn about conversions from signed to
  unsigned integers.  For example, :code:`unsigned int x = -1`.  If you need
  to perform such a conversion you can use an explicit cast.

:code:`-Wshadow`

  This warns whenever a local variable shadows another local variable.  If
  two variables have the same name then it is a potential source of
  confusion.

:code:`-Wpointer-arith -Wcast-qual -Wcast-align`

  These options warn if you try to do pointer arithmetic for types which
  don't have a size, such as :code:`void`, if you remove a :code:`const`
  cast from a pointer, or if you cast a pointer to a type which has a
  different size, causing an invalid alignment.

:code:`-Wwrite-strings`

  This option gives string constants a :code:`const` qualifier so that it
  will be a compile-time error to attempt to overwrite them.

:code:`-fshort-enums`

  This option makes the type of :code:`enum` as short as possible.  Normally
  this makes an :code:`enum` different from an :code:`int`.  Consequently any
  attempts to assign a pointer-to-int to a pointer-to-enum will generate a
  cast-alignment warning.

:code:`-fno-common`

  This option prevents global variables being simultaneously defined in
  different object files (you get an error at link time).  Such a variable
  should be defined in one file and referred to in other files with an
  :code:`extern` declaration.

:code:`-Wnested-externs`

  This warns if an :code:`extern` declaration is encountered within a
  function.

:code:`-Dinline=`

  The :code:`inline` keyword is not part of ANSI C. Thus if you want to use
  :code:`-ansi` with a program which uses inline functions you can use this
  preprocessor definition to remove the :code:`inline` keywords.

:code:`-g`

  It always makes sense to put debugging symbols in the executable so that
  you can debug it using :code:`gdb`.  The only effect of debugging symbols
  is to increase the size of the file, and you can use the :code:`strip`
  command to remove them later if necessary.

.. For comparison, this is what happens when the test program above is
.. compiled with these options.

.. @example
.. bash$ gcc -ansi -pedantic -Werror -W -Wall -Wtraditional 
.. -Wconversion -Wshadow -Wpointer-arith -Wcast-qual -Wcast-align 
.. -Wwrite-strings -Waggregate-return -Wstrict-prototypes -fshort-enums 
.. -fno-common -Wmissing-prototypes -Wnested-externs -Dinline= 
.. -g -O4 tmp.c 
.. cc1: warnings being treated as errors
.. tmp.c:7: warning: function declaration isn't a prototype
.. tmp.c: In function `main':
.. tmp.c:9: warning: passing arg 1 of `f' as integer rather than floating 
.. due to prototype
.. tmp.c: In function `f':
.. tmp.c:14: warning: type of `x' defaults to `int'
.. tmp.c:15: warning: passing arg 1 of `sqrt' as floating rather than integer 
.. due to prototype
.. make: *** [tmp] Error 1
.. @end example

.. @noindent
.. The error in the prototype is flagged, plus the fact that we should have
.. defined main as :code:`int main (void)` in ANSI C. Clearly there is some
.. work to do before this program is ready to run.

References and Further Reading
==============================

The following books are essential reading for anyone writing and
debugging numerical programs with :code:`gcc` and :code:`gdb`.

* R.M. Stallman, *Using and Porting GNU CC*, Free Software
  Foundation, ISBN 1882114388

* R.M. Stallman, R.H. Pesch, *Debugging with GDB: The GNU
  Source-Level Debugger*, Free Software Foundation, ISBN 1882114779

For a tutorial introduction to the GNU C Compiler and related programs,
see 

* B.J. Gough, http://www.network-theory.co.uk/gcc/intro/,'
  *An Introduction to GCC*, Network Theory
  Ltd, ISBN 0954161793
.. index:: dilogarithm

The dilogarithm is defined as

.. only:: not texinfo

   .. math:: Li_2(z) = - \int_0^z ds {\log{(1-s)} \over s}

.. only:: texinfo

   .. math:: Li_2(z) = - \int_0^z ds log(1-s) / s

The functions described in this section are declared in the header file
:file:`gsl_sf_dilog.h`.

Real Argument
-------------

.. function:: double gsl_sf_dilog (double x)
              int gsl_sf_dilog_e (double x, gsl_sf_result * result)

   These routines compute the dilogarithm for a real argument. In Lewin's
   notation this is :math:`Li_2(x)`, the real part of the dilogarithm of a
   real :math:`x`.  It is defined by the integral representation

   .. math:: Li_2(x) = - \Re \int_0^x ds \log(1-s) / s

   Note that :math:`\Im(Li_2(x)) = 0` for
   :math:`x \le 1`, and :math:`-\pi\log(x)` for :math:`x > 1`.

   Note that Abramowitz & Stegun refer to the Spence integral
   :math:`S(x) = Li_2(1 - x)` as the dilogarithm rather than :math:`Li_2(x)`.

Complex Argument
----------------

.. function:: int gsl_sf_complex_dilog_e (double r, double theta, gsl_sf_result * result_re, gsl_sf_result * result_im)

   This function computes the full complex-valued dilogarithm for the
   complex argument :math:`z = r \exp(i \theta)`. The real and imaginary
   parts of the result are returned in :data:`result_re`, :data:`result_im`.
.. index::
   single: physical constants
   single: constants, physical
   single: conversion of units
   single: units, conversion of

******************
Physical Constants
******************

This chapter describes macros for the values of physical constants, such
as the speed of light, :math:`c`, and gravitational constant, :math:`G`.
The values are available in different unit systems, including the
standard MKSA system (meters, kilograms, seconds, amperes) and the CGSM
system (centimeters, grams, seconds, gauss), which is commonly used in
Astronomy.

The definitions of constants in the MKSA system are available in the file
:file:`gsl_const_mksa.h`.  The constants in the CGSM system are defined in
:file:`gsl_const_cgsm.h`.  Dimensionless constants, such as the fine
structure constant, which are pure numbers are defined in
:file:`gsl_const_num.h`.

The full list of constants is described briefly below.  Consult the
header files themselves for the values of the constants used in the
library.

.. index::
   single: fundamental constants
   single: constants, fundamental

Fundamental Constants
=====================

.. macro:: GSL_CONST_MKSA_SPEED_OF_LIGHT

   The speed of light in vacuum, :math:`c`.

.. macro:: GSL_CONST_MKSA_VACUUM_PERMEABILITY

   The permeability of free space, :math:`\mu_0`. This constant is defined
   in the MKSA system only.

.. macro:: GSL_CONST_MKSA_VACUUM_PERMITTIVITY

   The permittivity of free space, :math:`\epsilon_0`.  This constant is
   defined in the MKSA system only.

.. macro:: GSL_CONST_MKSA_PLANCKS_CONSTANT_H

   Planck's constant, :math:`h`.

.. macro:: GSL_CONST_MKSA_PLANCKS_CONSTANT_HBAR

   Planck's constant divided by :math:`2\pi`, :math:`\hbar`.

.. macro:: GSL_CONST_NUM_AVOGADRO

   Avogadro's number, :math:`N_a`.

.. macro:: GSL_CONST_MKSA_FARADAY

   The molar charge of 1 Faraday.

.. macro:: GSL_CONST_MKSA_BOLTZMANN

   The Boltzmann constant, :math:`k`.

.. macro:: GSL_CONST_MKSA_MOLAR_GAS

   The molar gas constant, :math:`R_0`.

.. macro:: GSL_CONST_MKSA_STANDARD_GAS_VOLUME

   The standard gas volume, :math:`V_0`.

.. macro:: GSL_CONST_MKSA_STEFAN_BOLTZMANN_CONSTANT

   The Stefan-Boltzmann radiation constant, :math:`\sigma`.

.. macro:: GSL_CONST_MKSA_GAUSS

   The magnetic field of 1 Gauss.

.. index:: astronomical constants

Astronomy and Astrophysics
==========================

.. macro:: GSL_CONST_MKSA_ASTRONOMICAL_UNIT

   The length of 1 astronomical unit (mean earth-sun distance), :math:`au`.

.. macro:: GSL_CONST_MKSA_GRAVITATIONAL_CONSTANT

   The gravitational constant, :math:`G`.

.. macro:: GSL_CONST_MKSA_LIGHT_YEAR

   The distance of 1 light-year, :math:`ly`.

.. macro:: GSL_CONST_MKSA_PARSEC

   The distance of 1 parsec, :math:`pc`.

.. macro:: GSL_CONST_MKSA_GRAV_ACCEL

   The standard gravitational acceleration on Earth, :math:`g`.

.. macro:: GSL_CONST_MKSA_SOLAR_MASS

   The mass of the Sun.

.. index::
   single: atomic physics, constants
   single: nuclear physics, constants

Atomic and Nuclear Physics
==========================

.. macro:: GSL_CONST_MKSA_ELECTRON_CHARGE

   The charge of the electron, :math:`e`.

.. macro:: GSL_CONST_MKSA_ELECTRON_VOLT

   The energy of 1 electron volt, :math:`eV`.

.. macro:: GSL_CONST_MKSA_UNIFIED_ATOMIC_MASS

   The unified atomic mass, :math:`amu`.

.. macro:: GSL_CONST_MKSA_MASS_ELECTRON

   The mass of the electron, :math:`m_e`.

.. macro:: GSL_CONST_MKSA_MASS_MUON

   The mass of the muon, :math:`m_\mu`.

.. macro:: GSL_CONST_MKSA_MASS_PROTON

   The mass of the proton, :math:`m_p`.

.. macro:: GSL_CONST_MKSA_MASS_NEUTRON

   The mass of the neutron, :math:`m_n`.

.. macro:: GSL_CONST_NUM_FINE_STRUCTURE

   The electromagnetic fine structure constant :math:`\alpha`.

.. macro:: GSL_CONST_MKSA_RYDBERG

   The Rydberg constant, :math:`Ry`, in units of energy.  This is related to
   the Rydberg inverse wavelength :math:`R_\infty` by :math:`Ry = h c R_\infty`.

.. macro:: GSL_CONST_MKSA_BOHR_RADIUS

   The Bohr radius, :math:`a_0`.

.. macro:: GSL_CONST_MKSA_ANGSTROM

   The length of 1 angstrom.

.. macro:: GSL_CONST_MKSA_BARN

   The area of 1 barn.

.. macro:: GSL_CONST_MKSA_BOHR_MAGNETON

   The Bohr Magneton, :math:`\mu_B`.

.. macro:: GSL_CONST_MKSA_NUCLEAR_MAGNETON

   The Nuclear Magneton, :math:`\mu_N`.

.. macro:: GSL_CONST_MKSA_ELECTRON_MAGNETIC_MOMENT

   The absolute value of the magnetic moment of the electron, :math:`\mu_e`.
   The physical magnetic moment of the electron is negative.

.. macro:: GSL_CONST_MKSA_PROTON_MAGNETIC_MOMENT

   The magnetic moment of the proton, :math:`\mu_p`.

.. macro:: GSL_CONST_MKSA_THOMSON_CROSS_SECTION

   The Thomson cross section, :math:`\sigma_T`.

.. macro:: GSL_CONST_MKSA_DEBYE

   The electric dipole moment of 1 Debye, :math:`D`.

.. index:: time units

Measurement of Time
===================

.. macro:: GSL_CONST_MKSA_MINUTE

   The number of seconds in 1 minute.

.. macro:: GSL_CONST_MKSA_HOUR

   The number of seconds in 1 hour.

.. macro:: GSL_CONST_MKSA_DAY

   The number of seconds in 1 day.

.. macro:: GSL_CONST_MKSA_WEEK

   The number of seconds in 1 week.

.. index::
   single: imperial units
   single: units, imperial

Imperial Units
==============

.. macro:: GSL_CONST_MKSA_INCH

   The length of 1 inch.

.. macro:: GSL_CONST_MKSA_FOOT

   The length of 1 foot.

.. macro:: GSL_CONST_MKSA_YARD

   The length of 1 yard.

.. macro:: GSL_CONST_MKSA_MILE

   The length of 1 mile.

.. macro:: GSL_CONST_MKSA_MIL

   The length of 1 mil (1/1000th of an inch).

.. index:: nautical units

Speed and Nautical Units
========================

.. macro:: GSL_CONST_MKSA_KILOMETERS_PER_HOUR

   The speed of 1 kilometer per hour.

.. macro:: GSL_CONST_MKSA_MILES_PER_HOUR

   The speed of 1 mile per hour.

.. macro:: GSL_CONST_MKSA_NAUTICAL_MILE

   The length of 1 nautical mile.

.. macro:: GSL_CONST_MKSA_FATHOM

   The length of 1 fathom.

.. macro:: GSL_CONST_MKSA_KNOT

   The speed of 1 knot.

.. index:: printers units

Printers Units
==============

.. macro:: GSL_CONST_MKSA_POINT

   The length of 1 printer's point (1/72 inch).

.. macro:: GSL_CONST_MKSA_TEXPOINT

   The length of 1 TeX point (1/72.27 inch).

.. index:: volume units

Volume, Area and Length
=======================

.. macro:: GSL_CONST_MKSA_MICRON

   The length of 1 micron.

.. macro:: GSL_CONST_MKSA_HECTARE

   The area of 1 hectare.

.. macro:: GSL_CONST_MKSA_ACRE

   The area of 1 acre.

.. macro:: GSL_CONST_MKSA_LITER

   The volume of 1 liter.

.. macro:: GSL_CONST_MKSA_US_GALLON

   The volume of 1 US gallon.

.. macro:: GSL_CONST_MKSA_CANADIAN_GALLON

   The volume of 1 Canadian gallon.

.. macro:: GSL_CONST_MKSA_UK_GALLON

   The volume of 1 UK gallon.

.. macro:: GSL_CONST_MKSA_QUART

   The volume of 1 quart.

.. macro:: GSL_CONST_MKSA_PINT

   The volume of 1 pint.

.. @node Cookery
.. @section Cookery
.. @commentindex cookery units

.. @table @commentode
.. @item GSL_CONST_MKSA_CUP
.. The volume of 1 cup.

.. @item GSL_CONST_MKSA_FLUID_OUNCE
.. The volume of 1 fluid ounce.

.. @item GSL_CONST_MKSA_TABLESPOON
.. The volume of 1 tablespoon.

.. @item GSL_CONST_MKSA_TEASPOON
.. The volume of 1 teaspoon.
.. @end table

.. index::
   single: mass, units of
   single: weight, units of

Mass and Weight
===============

.. macro:: GSL_CONST_MKSA_POUND_MASS

   The mass of 1 pound.

.. macro:: GSL_CONST_MKSA_OUNCE_MASS

   The mass of 1 ounce.

.. macro:: GSL_CONST_MKSA_TON

   The mass of 1 ton.

.. macro:: GSL_CONST_MKSA_METRIC_TON

   The mass of 1 metric ton (1000 kg).

.. macro:: GSL_CONST_MKSA_UK_TON

   The mass of 1 UK ton.

.. macro:: GSL_CONST_MKSA_TROY_OUNCE

   The mass of 1 troy ounce.

.. macro:: GSL_CONST_MKSA_CARAT

   The mass of 1 carat.

.. macro:: GSL_CONST_MKSA_GRAM_FORCE

   The force of 1 gram weight.

.. macro:: GSL_CONST_MKSA_POUND_FORCE

   The force of 1 pound weight.

.. macro:: GSL_CONST_MKSA_KILOPOUND_FORCE

   The force of 1 kilopound weight.

.. macro:: GSL_CONST_MKSA_POUNDAL

   The force of 1 poundal.

.. index::
   single: energy, units of
   single: power, units of
   single: thermal energy, units of

Thermal Energy and Power
========================

.. macro:: GSL_CONST_MKSA_CALORIE

   The energy of 1 calorie.

.. macro:: GSL_CONST_MKSA_BTU

   The energy of 1 British Thermal Unit, :math:`btu`.

.. macro:: GSL_CONST_MKSA_THERM

   The energy of 1 Therm.

.. macro:: GSL_CONST_MKSA_HORSEPOWER

   The power of 1 horsepower.

.. index:: pressure, units of

Pressure
========

.. macro:: GSL_CONST_MKSA_BAR

   The pressure of 1 bar.

.. macro:: GSL_CONST_MKSA_STD_ATMOSPHERE

   The pressure of 1 standard atmosphere.

.. macro:: GSL_CONST_MKSA_TORR

   The pressure of 1 torr.

.. macro:: GSL_CONST_MKSA_METER_OF_MERCURY

   The pressure of 1 meter of mercury.

.. macro:: GSL_CONST_MKSA_INCH_OF_MERCURY

   The pressure of 1 inch of mercury.

.. macro:: GSL_CONST_MKSA_INCH_OF_WATER

   The pressure of 1 inch of water.

.. macro:: GSL_CONST_MKSA_PSI

   The pressure of 1 pound per square inch.

.. index:: viscosity, units of

Viscosity
=========

.. macro:: GSL_CONST_MKSA_POISE

   The dynamic viscosity of 1 poise.

.. macro:: GSL_CONST_MKSA_STOKES

   The kinematic viscosity of 1 stokes.

.. index::
   single: light, units of
   single: illumination, units of

Light and Illumination
======================

.. macro:: GSL_CONST_MKSA_STILB

   The luminance of 1 stilb.

.. macro:: GSL_CONST_MKSA_LUMEN

   The luminous flux of 1 lumen.

.. macro:: GSL_CONST_MKSA_LUX

   The illuminance of 1 lux.

.. macro:: GSL_CONST_MKSA_PHOT

   The illuminance of 1 phot.

.. macro:: GSL_CONST_MKSA_FOOTCANDLE

   The illuminance of 1 footcandle.

.. macro:: GSL_CONST_MKSA_LAMBERT

   The luminance of 1 lambert.

.. macro:: GSL_CONST_MKSA_FOOTLAMBERT

   The luminance of 1 footlambert.

.. index:: radioactivity, units of

Radioactivity
=============

.. macro:: GSL_CONST_MKSA_CURIE

   The activity of 1 curie.

.. macro:: GSL_CONST_MKSA_ROENTGEN

   The exposure of 1 roentgen.

.. macro:: GSL_CONST_MKSA_RAD

   The absorbed dose of 1 rad.

.. index:: force and energy, units of

Force and Energy
================

.. macro:: GSL_CONST_MKSA_NEWTON

   The SI unit of force, 1 Newton.

.. macro:: GSL_CONST_MKSA_DYNE

   The force of 1 Dyne = :math:`10^{-5}` Newton.

.. macro:: GSL_CONST_MKSA_JOULE

   The SI unit of energy, 1 Joule.

.. macro:: GSL_CONST_MKSA_ERG 

   The energy 1 erg = :math:`10^{-7}` Joule.

.. index::
   single: prefixes
   single: constants, prefixes

Prefixes
========

These constants are dimensionless scaling factors.

.. macro:: GSL_CONST_NUM_YOTTA

   :math:`10^{24}`

.. macro:: GSL_CONST_NUM_ZETTA

   :math:`10^{21}`

.. macro:: GSL_CONST_NUM_EXA

   :math:`10^{18}`

.. macro:: GSL_CONST_NUM_PETA

   :math:`10^{15}`

.. macro:: GSL_CONST_NUM_TERA

   :math:`10^{12}`

.. macro:: GSL_CONST_NUM_GIGA

   :math:`10^9`

.. macro:: GSL_CONST_NUM_MEGA

   :math:`10^6`

.. macro:: GSL_CONST_NUM_KILO

   :math:`10^3`

.. macro:: GSL_CONST_NUM_MILLI

   :math:`10^{-3}`

.. macro:: GSL_CONST_NUM_MICRO

   :math:`10^{-6}`

.. macro:: GSL_CONST_NUM_NANO

   :math:`10^{-9}`

.. macro:: GSL_CONST_NUM_PICO

   :math:`10^{-12}`

.. macro:: GSL_CONST_NUM_FEMTO

   :math:`10^{-15}`

.. macro:: GSL_CONST_NUM_ATTO
 
   :math:`10^{-18}`

.. macro:: GSL_CONST_NUM_ZEPTO

   :math:`10^{-21}`

.. macro:: GSL_CONST_NUM_YOCTO

   :math:`10^{-24}`

Examples
========

The following program demonstrates the use of the physical constants in
a calculation.  In this case, the goal is to calculate the range of
light-travel times from Earth to Mars.

The required data is the average distance of each planet from the Sun in
astronomical units (the eccentricities and inclinations of the orbits
will be neglected for the purposes of this calculation).  The average
radius of the orbit of Mars is 1.52 astronomical units, and for the
orbit of Earth it is 1 astronomical unit (by definition).  These values
are combined with the MKSA values of the constants for the speed of
light and the length of an astronomical unit to produce a result for the
shortest and longest light-travel times in seconds.  The figures are
converted into minutes before being displayed.

.. include:: examples/const.c
   :code:

Here is the output from the program,

.. include:: examples/const.txt
   :code:

References and Further Reading
==============================

The authoritative sources for physical constants are the 2006 CODATA
recommended values, published in the article below. Further
information on the values of physical constants is also available from
the NIST website.

* P.J. Mohr, B.N. Taylor, D.B. Newell, "CODATA Recommended
  Values of the Fundamental Physical Constants: 2006", Reviews of
  Modern Physics, 80(2), pp. 633--730 (2008).

* http://www.physics.nist.gov/cuu/Constants/index.html

* http://physics.nist.gov/Pubs/SP811/appenB9.html
*****************
Digital Filtering
*****************

Introduction
============

The filters discussed in this chapter are based on the following moving data
window which is centered on :math:`i`-th sample:

.. only:: not texinfo

   .. math:: W_i^H = \left\{ x_{i-H}, \dots, x_i, \dots, x_{i+H} \right\}

.. only:: texinfo

   ::

      W_i^H = { x_{i-H}, ..., x_i, ..., x_{i+H} }

Here, :math:`H` is a non-negative integer called the *window half-length*, which
represents the number of samples before and after sample :math:`i`.
The total window length is :math:`K = 2 H + 1`.

Handling Endpoints
==================

When processing samples near the ends of the input signal, there will not
be enough samples to fill the window :math:`W_i^H` defined above.
Therefore the user must specify how to construct the windows near the end points.
This is done by passing an input argument of type :type:`gsl_filter_end_t`:

.. type:: gsl_filter_end_t

   This data type specifies how to construct windows near end points and can
   be selected from the following choices:

   .. macro:: GSL_FILTER_END_PADZERO

      With this option, a full window of length :math:`K` will be constructed
      by inserting zeros into the window near the signal end points. Effectively,
      the input signal is modified to

      .. only:: not texinfo

         .. math:: \tilde{x} = \{ \underbrace{0, \dots, 0}_{H \textrm{ zeros}}, x_1, x_2, \dots, x_{n-1}, x_n, \underbrace{0, \dots, 0}_{H \textrm{ zeros} } \}

      .. only:: texinfo

         ::

            x~ = { 0, ..., 0, x_1, x_2, ..., x_{n-1}, x_n, 0, ..., 0 }

      to ensure a well-defined window for all :math:`x_i`.

   .. macro:: GSL_FILTER_END_PADVALUE

      With this option, a full window of length :math:`K` will be constructed
      by padding the window with the first and last sample in the input signal.
      Effectively, the input signal is modified to

      .. only:: not texinfo

         .. math:: \tilde{x} = \{ \underbrace{x_1, \dots, x_1}_{H}, x_1, x_2, \dots, x_{n-1}, x_n, \underbrace{x_n, \dots, x_n}_{H} \}

      .. only:: texinfo

         ::

            x~ = { x_1, ..., x_1, x_1, x_2, ..., x_{n-1}, x_n, x_n, ..., x_n }

   .. macro:: GSL_FILTER_END_TRUNCATE

      With this option, no padding is performed, and the windows are simply truncated
      as the end points are approached.

Linear Digital Filters
======================

Gaussian Filter
---------------

The Gaussian filter convolves the input signal with a Gaussian kernel or window. This filter
is often used as a smoothing or noise reduction filter. The Gaussian kernel is
defined by

.. only:: not texinfo

   .. math:: G(k) = e^{-\frac{1}{2} \left( \alpha \frac{k}{(K-1)/2} \right)^2} = e^{-k^2/2\sigma^2}

.. only:: texinfo

   ::

      G(k) = e^{-1/2 ( \alpha k/((K-1)/2) )^2} = e^{-k^2/2\sigma^2}

for :math:`-(K-1)/2 \le k \le (K-1)/2`, and :math:`K` is the size of the kernel. The
parameter :math:`\alpha` specifies the number of standard deviations :math:`\sigma` desired
in the kernel. So for example setting :math:`\alpha = 3` would define a Gaussian window
of length :math:`K` which spans :math:`\pm 3 \sigma`. It is often more convenient to specify
the parameter :math:`\alpha` rather than the standard deviation :math:`\sigma` when constructing
the kernel, since a fixed value of :math:`\alpha` would correspond to the same shape of
Gaussian regardless of the size :math:`K`. The appropriate value of the standard deviation
depends on :math:`K` and is related to :math:`\alpha` as

.. only:: not texinfo

   .. math:: \sigma = \frac{K - 1}{2\alpha}

.. only:: texinfo

   ::

      \sigma = (K - 1)/(2 \alpha)

The routines below accept :math:`\alpha` as an input argument instead of :math:`\sigma`.

The Gaussian filter offers a convenient way of differentiating and smoothing an input signal
in a single pass. Using the derivative property of a convolution,

.. only:: not texinfo

   .. math:: \frac{d}{dt} \left( G * x \right) = \frac{dG}{dt} * x

.. only:: texinfo

   ::

      d/dt ( G * x ) = dG/dt * x

the input signal :math:`x(t)` can be smoothed and differentiated at the same time by
convolution with a derivative Gaussian kernel, which can be readily computed from the
analytic expression above. The same principle applies to higher order derivatives.

.. function:: gsl_filter_gaussian_workspace * gsl_filter_gaussian_alloc(const size_t K)

   This function initializes a workspace for Gaussian filtering using a kernel of
   size :data:`K`. Here, :math:`H = K / 2`. If :math:`K` is even, it is rounded up to the next
   odd integer to ensure a symmetric window. The size of the workspace is :math:`O(K)`.

.. function:: void gsl_filter_gaussian_free(gsl_filter_gaussian_workspace * w)

   This function frees the memory associated with :data:`w`.

.. function:: int gsl_filter_gaussian(const gsl_filter_end_t endtype, const double alpha, const size_t order, const gsl_vector * x, gsl_vector * y, gsl_filter_gaussian_workspace * w)

   This function applies a Gaussian filter parameterized by :data:`alpha` to the input vector :data:`x`,
   storing the output in :data:`y`. The derivative order is specified by :data:`order`, with
   :code:`0` corresponding to a Gaussian, :code:`1` corresponding to a first derivative
   Gaussian, and so on. The parameter :data:`endtype` specifies how the signal end points are handled.
   It is allowed for :data:`x` = :data:`y` for an in-place filter.

.. function:: int gsl_filter_gaussian_kernel(const double alpha, const size_t order, const int normalize, gsl_vector * kernel)

   This function constructs a Gaussian kernel parameterized by :data:`alpha` and
   stores the output in :data:`kernel`. The parameter :data:`order` specifies the
   derivative order, with :code:`0` corresponding to a Gaussian, :code:`1` corresponding
   to a first derivative Gaussian, and so on. If :data:`normalize` is set to :code:`1`, then
   the kernel will be normalized to sum to one on output. If :data:`normalize` is set to
   :code:`0`, no normalization is performed.

Nonlinear Digital Filters
=========================

The nonlinear digital filters described below are based on the window median, which is given
by

.. only:: not texinfo

   .. math:: m_i = \textrm{median} \left\{ W_i^H \right\} = \textrm{median} \left\{ x_{i-H}, \dots, x_i, \dots, x_{i+H} \right\}

.. only:: texinfo

   ::

      m_i = median { W_i^H } = median { x_{i-H}, ..., x_i, ..., x_{i+H} }

The median is considered robust to local outliers, unlike the mean.
Median filters can preserve sharp edges while at the same removing signal noise, and are used
in a wide range of applications.

Standard Median Filter
----------------------

The *standard median filter* (SMF) simply replaces the sample :math:`x_i` by the median
:math:`m_i` of the window :math:`W_i^H`: This filter has one tuning parameter given
by :math:`H`. The standard median filter is considered highly resistant to
local outliers and local noise in the data sequence :math:`\{x_i\}`.

.. function:: gsl_filter_median_workspace * gsl_filter_median_alloc(const size_t K)

   This function initializes a workspace for standard median filtering using a symmetric centered moving window of
   size :data:`K`. Here, :math:`H = K / 2`. If :math:`K` is even, it is rounded up to the next
   odd integer to ensure a symmetric window. The size of the workspace is :math:`O(7K)`.

.. function:: void gsl_filter_median_free(gsl_filter_median_workspace * w)

   This function frees the memory associated with :data:`w`.

.. function:: int gsl_filter_median(const gsl_filter_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_filter_median_workspace * w)

   This function applies a standard median filter to the input :data:`x`, storing the output in :data:`y`.
   The parameter :data:`endtype` specifies how the signal end points are handled. It
   is allowed to have :data:`x` = :data:`y` for an in-place filter.

Recursive Median Filter
-----------------------

The *recursive median filter* (RMF) is a modification of the SMF to include previous filter outputs
in the window before computing the median. The filter's response is

.. only:: not texinfo

   .. math:: y_i = \textrm{median} \left( y_{i-H}, \dots, y_{i-1}, x_i, x_{i+1}, \dots, x_{i+H} \right)

.. only:: texinfo

   ::

      y_i = median ( y_{i-H}, ..., y_{i-1}, x_i, x_{i+1}, ..., x_{i+H} )

Sometimes, the SMF must be applied several times in a row to achieve adequate smoothing (i.e. a cascade filter).
The RMF, on the other hand, converges to a *root sequence* in one pass,
and can sometimes provide a smoother result than several passes of the SMF. A root sequence is an input which is
left unchanged by the filter.  So there is no need to apply a recursive median filter twice to an input vector.

.. function:: gsl_filter_rmedian_workspace * gsl_filter_rmedian_alloc(const size_t K)

   This function initializes a workspace for recursive median filtering using a symmetric centered moving window of
   size :data:`K`. Here, :math:`H = K / 2`. If :math:`K` is even, it is rounded up to the next
   odd integer to ensure a symmetric window. The size of the workspace is :math:`O(K)`.

.. function:: void gsl_filter_rmedian_free(gsl_filter_rmedian_workspace * w)

   This function frees the memory associated with :data:`w`.

.. function:: int gsl_filter_rmedian(const gsl_filter_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_filter_rmedian_workspace * w)

   This function applies a recursive median filter to the input :data:`x`, storing the output in :data:`y`.
   The parameter :data:`endtype` specifies how the signal end points are handled. It
   is allowed to have :data:`x` = :data:`y` for an in-place filter.

Impulse Detection Filter
------------------------

Impulsive noise is characterized by short sequences of data points distinct from those in the
surrounding neighborhood. This section describes a powerful class of filters, also known as
*impulse rejection filters* and *decision-based filters*, designed to detect and remove such outliers from data.
The filter's response is given by

.. only:: not texinfo

   .. math:: y_i = \left\{
                     \begin{array}{cc}
                       x_i, & |x_i - m_i| \le t S_i \\
                       m_i, & |x_i - m_i| > t S_i
                     \end{array}
                   \right.

.. only:: texinfo

   ::

      y_i = { x_i, |x_i - m_i| <= t * S_i
            { m_i, |x_i - m_i| > t * S_i

where :math:`m_i` is the median value of the window :math:`W_i^H`, :math:`S_i` is a robust estimate
of the scatter or dispersion for the window :math:`W_i^H`, and :math:`t` is a tuning parameter specifying
the number of scale factors needed to determine that a point is an outlier. The main idea is that the median
:math:`m_i` will be unaffected by a small number of outliers in the window, and so a given
sample :math:`x_i` is tested to determine how far away it is from the median in terms of the local
scale estimate :math:`S_i`. Samples which are more than :math:`t` scale estimates away from the median
are labeled as outliers and replaced by the window median :math:`m_i`. Samples which are less than
:math:`t` scale estimates from the median are left unchanged by the filter.

Note that when :math:`t = 0`, the impulse detection filter is equivalent to the standard median filter. When
:math:`t \rightarrow \infty`, it becomes the identity filter. This means the impulse detection filter can
be viewed as a "less aggressive" version of the standard median filter, becoming less aggressive as :math:`t` is
increased. Note that this filter modifies only samples identified as outliers, while the standard median
filter changes all samples to the local median, regardless of whether they are outliers. This fact, plus
the additional flexibility offered by the additional tuning parameter :math:`t` can make the impulse detection filter
a better choice for some applications.

It is important to have a robust and accurate scale estimate :math:`S_i` in order to
detect impulse outliers even in the presence of noise. The window standard deviation is not
typically a good choice, as it can be significantly perturbed by the presence of even one outlier.
GSL offers the following choices (specified by a parameter of type :type:`gsl_filter_scale_t`) for
computing the scale estimate :math:`S_i`, all of which are robust to the presence of impulse outliers.

.. type:: gsl_filter_scale_t

   This type specifies how the scale estimate :math:`S_i` of the window :math:`W_i^H` is calculated.

   .. macro:: GSL_FILTER_SCALE_MAD

      This option specifies the median absolute deviation (MAD) scale estimate, defined by

      .. only:: not texinfo

         .. math:: S_i = 1.4826 \times \textrm{median} \left\{ | W_i^H - m_i | \right\}

      .. only:: texinfo

         ::

            S_i = 1.4826 median { | W_i^H - m_i | }

      This choice of scale estimate is also known as the *Hampel filter* in the statistical literature.
      See :ref:`here <sec_mad-statistic>` for more information.

   .. macro:: GSL_FILTER_SCALE_IQR

      This option specifies the interquartile range (IQR) scale estimate, defined as the difference between
      the 75th and 25th percentiles of the window :math:`W_i^H`,

      .. only:: not texinfo

         .. math:: S_i = 0.7413 \left( Q_{0.75} - Q_{0.25} \right)

      .. only:: texinfo

         ::

            S_i = 0.7413 ( Q_{0.75} - Q_{0.25} )

      where :math:`Q_p` is the p-quantile of the window :math:`W_i^H`. The idea is to throw away the largest
      and smallest 25% of the window samples (where the outliers would be), and estimate a scale from the middle 50%.
      The factor :math:`0.7413` provides an unbiased estimate of the standard deviation for Gaussian data.

   .. macro:: GSL_FILTER_SCALE_SN

      This option specifies the so-called :math:`S_n` statistic proposed by Croux and Rousseeuw.
      See :ref:`here <sec_Sn-statistic>` for more information.

   .. macro:: GSL_FILTER_SCALE_QN

      This option specifies the so-called :math:`Q_n` statistic proposed by Croux and Rousseeuw.
      See :ref:`here <sec_Qn-statistic>` for more information.

.. warning::

   While the scale estimates defined above are much less sensitive to outliers than the standard deviation,
   they can suffer from an effect called *implosion*. The standard deviation of a window :math:`W_i^H` will be zero
   if and only if all samples in the window are equal. However, it is possible for the MAD of a window
   to be zero even if all the samples in the window are not equal. For example, if :math:`K/2 + 1` or more
   of the :math:`K` samples in the window are equal to some value :math:`x^{*}`, then the window median will
   be equal to :math:`x^{*}`. Consequently, at least :math:`K/2 + 1` of the absolute deviations
   :math:`|x_j - x^{*}|` will be zero, and so the MAD will be zero. In such a case, the Hampel
   filter will act like the standard median filter regardless of the value of :math:`t`. Caution should also
   be exercised if dividing by :math:`S_i`.

.. function:: gsl_filter_impulse_workspace * gsl_filter_impulse_alloc(const size_t K)

   This function initializes a workspace for impulse detection filtering using a symmetric moving window of
   size :data:`K`. Here, :math:`H = K / 2`. If :math:`K` is even, it is rounded up to the next
   odd integer to ensure a symmetric window. The size of the workspace is :math:`O(6K)`.

.. function:: void gsl_filter_impulse_free(gsl_filter_impulse_workspace * w)

   This function frees the memory associated with :data:`w`.

.. function:: int gsl_filter_impulse(const gsl_filter_end_t endtype, const gsl_filter_scale_t scale_type, const double t, const gsl_vector * x, gsl_vector * y, gsl_vector * xmedian, gsl_vector * xsigma, size_t * noutlier, gsl_vector_int * ioutlier, gsl_filter_impulse_workspace * w)

   These functions apply an impulse detection filter to the input vector :data:`x`, storing the filtered output
   in :data:`y`. The tuning parameter :math:`t` is provided in :data:`t`.
   The window medians :math:`m_i` are stored in :data:`xmedian` and the :math:`S_i` are stored in :data:`xsigma` on output.
   The number of outliers detected is stored in :data:`noutlier` on output, while
   the locations of flagged outliers are stored in the boolean array :data:`ioutlier`. The input
   :data:`ioutlier` may be :code:`NULL` if not desired. It  is allowed to have :data:`x` = :data:`y` for an
   in-place filter.

Examples
========

Gaussian Example 1
------------------

This example program illustrates the Gaussian filter applied to smoothing a time series of length
:math:`N = 500` with a kernel size of :math:`K = 51`. Three filters are applied with
parameters :math:`\alpha = 0.5, 3, 10`. The results are shown in :numref:`fig_filt-gaussian`.

.. _fig_filt-gaussian:

.. figure:: /images/gaussfilt.png
   :scale: 60%

   Top panel: Gaussian kernels (unnormalized) for :math:`\alpha = 0.5, 3, 10`.
   Bottom panel: Time series (gray) with Gaussian filter output for same :math:`\alpha`
   values.

We see that the filter corresponding to :math:`\alpha = 0.5` applies the most smoothing,
while :math:`\alpha = 10` corresponds to the least amount of smoothing.
The program is given below.

.. include:: examples/gaussfilt.c
   :code:

Gaussian Example 2
------------------

A common application of the Gaussian filter is to detect edges, or sudden jumps, in a noisy
input signal. It is used both for 1D edge detection in time series, as well as 2D edge
detection in images. Here we will examine a noisy time series of length :math:`N = 1000`
with a single edge. The input signal is defined as

.. only:: not texinfo

   .. math:: x(n) = e(n) +
               \left\{
                 \begin{array}{cc}
                   0, & n \le N/2 \\
                   0.5, & n > N/2
                 \end{array}
               \right.

.. only:: texinfo

   ::

      x(n) = e(n) + { 0,   n <= N/2
                    { 0.5, n >  N/2

where :math:`e(n)` is Gaussian random noise. The program smooths the input signal
with order :math:`0,1,` and :math:`2` Gaussian filters of length :math:`K = 61` with
:math:`\alpha = 3`. For comparison, the program also computes finite differences
of the input signal without smoothing. The results are shown in :numref:`fig_filt-gaussian2`.

.. _fig_filt-gaussian2:

.. figure:: /images/gaussfilt2.png
   :scale: 60%

   Top row: original input signal :math:`x(n)` (black) with Gaussian smoothed signal in red.
   Second row: First finite differences of input signal.
   Third row: Input signal smoothed with a first order Gaussian filter.
   Fourth row: Input signal smoothed with a second order Gaussian filter.

The finite difference approximation of the first derivative (second row) shows
the common problem with differentiating a noisy signal. The noise is amplified
and makes it extremely difficult to detect the sharp gradient at sample :math:`500`.
The third row shows the first order Gaussian smoothed signal with a clear peak
at the location of the edge. Alternatively, one could examine the second order
Gaussian smoothed signal (fourth row) and look for zero crossings to determine
the edge location.

The program is given below.

.. include:: examples/gaussfilt2.c
   :code:

Square Wave Signal Example
--------------------------

The following example program illustrates the median filters on a noisy
square wave signal. Median filters are well known for preserving sharp
edges in the input signal while reducing noise. The program constructs
a 5 Hz square wave signal with Gaussian noise added. Then the signal is
filtered with a standard median filter and recursive median filter using
a symmetric window of length :math:`K = 7`. The results are shown in
:numref:`fig_filt-edge`.

.. _fig_filt-edge:

.. figure:: /images/filt_edge.png
   :scale: 60%

   Original time series is in gray. The standard median filter output is in
   green and the recursive median filter output is in red.

Both filters preserve the sharp signal edges while reducing the noise. The
recursive median filter achieves a smoother result than the standard median
filter. The "blocky" nature of the output is characteristic of all median
filters. The program is given below.

.. include:: examples/filt_edge.c
   :code:

Impulse Detection Example
-------------------------

The following example program illustrates the impulse detection filter. First,
it constructs a sinusoid signal of length :math:`N = 1000` with Gaussian noise
added. Then, about 1% of the data are perturbed to represent large outliers. An
impulse detecting filter is applied with a window size :math:`K = 25` and
tuning parameter :math:`t = 4`, using the :math:`Q_n` statistic as the robust
measure of scale. The results are plotted in :numref:`fig_impulse`.

.. _fig_impulse:

.. figure:: /images/impulse.png
   :scale: 60%

   Original time series is in blue, filter output is in green, upper and
   lower intervals for detecting outliers are in red and yellow respectively.
   Detected outliers are marked with squares.

The program is given below.

.. include:: examples/impulse.c
   :code:

References and Further Reading
==============================

The following publications are relevant to the algorithms described
in this chapter,

* F. J. Harris, *On the use of windows for harmonic analysis with the discrete Fourier transform*,
  Proceedings of the IEEE, 66 (1), 1978.

* S-J. Ko, Y-H. Lee, and A. T. Fam. *Efficient implementation of one-dimensional recursive median filters*,
  IEEE transactions on circuits and systems 37.11 (1990): 1447-1450.

* R. K. Pearson and M. Gabbouj, *Nonlinear Digital Filtering with Python: An Introduction*.
  CRC Press, 2015.
.. index::
   single: random number distributions
   single: cumulative distribution functions (CDFs)
   single: CDFs, cumulative distribution functions
   single: inverse cumulative distribution functions
   single: quantile functions

.. _chap_random-number-distributions:

***************************
Random Number Distributions
***************************

.. include:: include.rst

This chapter describes functions for generating random variates and
computing their probability distributions.  Samples from the
distributions described in this chapter can be obtained using any of the
random number generators in the library as an underlying source of
randomness.  

In the simplest cases a non-uniform distribution can be obtained
analytically from the uniform distribution of a random number generator
by applying an appropriate transformation.  This method uses one call to
the random number generator.  More complicated distributions are created
by the *acceptance-rejection* method, which compares the desired
distribution against a distribution which is similar and known
analytically.  This usually requires several samples from the generator.

The library also provides cumulative distribution functions and inverse
cumulative distribution functions, sometimes referred to as quantile
functions.  The cumulative distribution functions and their inverses are
computed separately for the upper and lower tails of the distribution,
allowing full accuracy to be retained for small results.

The functions for random variates and probability density functions
described in this section are declared in :file:`gsl_randist.h`.  The
corresponding cumulative distribution functions are declared in
:file:`gsl_cdf.h`.

Note that the discrete random variate functions always
return a value of type :code:`unsigned int`, and on most platforms this
has a maximum value of

.. only:: not texinfo
   
   .. math:: 2^{32}-1 \approx 4.29 \times 10^9

.. only:: texinfo

   ::

      2^32-1 ~=~ 4.29e9

They should only be called with
a safe range of parameters (where there is a negligible probability of
a variate exceeding this limit) to prevent incorrect results due to
overflow.

Introduction
============

Continuous random number distributions are defined by a probability
density function, :math:`p(x)`, such that the probability of :math:`x`
occurring in the infinitesimal range :math:`x` to :math:`x + dx` is
:math:`p(x) dx`.

The cumulative distribution function for the lower tail :math:`P(x)` is
defined by the integral,

.. math:: P(x) = \int_{-\infty}^{x} dx' p(x')

and gives the probability of a variate taking a value less than :math:`x`.

The cumulative distribution function for the upper tail :math:`Q(x)` is
defined by the integral,

.. math:: Q(x) = \int_{x}^{+\infty} dx' p(x')

and gives the probability of a variate taking a value greater than :math:`x`.

The upper and lower cumulative distribution functions are related by
:math:`P(x) + Q(x) = 1` and satisfy :math:`0 \le P(x) \le 1`,
:math:`0 \le Q(x) \le 1`.

The inverse cumulative distributions, :math:`x = P^{-1}(P)`
and :math:`x = Q^{-1}(Q)`
give the values of :math:`x`
which correspond to a specific value of :math:`P` or :math:`Q`.  
They can be used to find confidence limits from probability values.

For discrete distributions the probability of sampling the integer
value :math:`k` is given by :math:`p(k)`, where :math:`\sum_k p(k) = 1`.
The cumulative distribution for the lower tail :math:`P(k)` of a
discrete distribution is defined as,

.. math:: P(k) = \sum_{i \le k} p(i) 

where the sum is over the allowed range of the distribution less than
or equal to :math:`k`.  

The cumulative distribution for the upper tail of a discrete
distribution :math:`Q(k)` is defined as

.. math:: Q(k) = \sum_{i > k} p(i) 

giving the sum of probabilities for all values greater than :math:`k`.
These two definitions satisfy the identity :math:`P(k)+Q(k)=1`.

If the range of the distribution is 1 to :math:`n` inclusive then
:math:`P(n) = 1`, :math:`Q(n) = 0` while :math:`P(1) = p(1)`,
:math:`Q(1) = 1 - p(1)`.

|newpage|

The Gaussian Distribution
=========================

.. index:: Gaussian distribution

.. function:: double gsl_ran_gaussian (const gsl_rng * r, double sigma)

   This function returns a Gaussian random variate, with mean zero and
   standard deviation :data:`sigma`.  The probability distribution for
   Gaussian random variates is,

   .. math:: p(x) dx = {1 \over \sqrt{2 \pi \sigma^2}} \exp (-x^2 / 2\sigma^2) dx

   for :math:`x` in the range :math:`-\infty` to :math:`+\infty`.  Use the
   transformation :math:`z = \mu + x` on the numbers returned by
   :func:`gsl_ran_gaussian` to obtain a Gaussian distribution with mean
   :math:`\mu`.  This function uses the Box-Muller algorithm which requires two
   calls to the random number generator :data:`r`.

.. function:: double gsl_ran_gaussian_pdf (double x, double sigma)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Gaussian distribution with standard deviation :data:`sigma`, using
   the formula given above.

   .. image:: /images/rand-gaussian.png

.. index:: Ziggurat method

.. function:: double gsl_ran_gaussian_ziggurat (const gsl_rng * r, double sigma)
              double gsl_ran_gaussian_ratio_method (const gsl_rng * r, double sigma)

   This function computes a Gaussian random variate using the alternative
   Marsaglia-Tsang ziggurat and Kinderman-Monahan-Leva ratio methods.  The
   Ziggurat algorithm is the fastest available algorithm in most cases.

.. function:: double gsl_ran_ugaussian (const gsl_rng * r)
              double gsl_ran_ugaussian_pdf (double x)
              double gsl_ran_ugaussian_ratio_method (const gsl_rng * r)

   These functions compute results for the unit Gaussian distribution.  They
   are equivalent to the functions above with a standard deviation of one,
   :data:`sigma` = 1.

.. function:: double gsl_cdf_gaussian_P (double x, double sigma)
              double gsl_cdf_gaussian_Q (double x, double sigma)
              double gsl_cdf_gaussian_Pinv (double P, double sigma)
              double gsl_cdf_gaussian_Qinv (double Q, double sigma)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the Gaussian
   distribution with standard deviation :data:`sigma`.

.. function:: double gsl_cdf_ugaussian_P (double x)
              double gsl_cdf_ugaussian_Q (double x)
              double gsl_cdf_ugaussian_Pinv (double P)
              double gsl_cdf_ugaussian_Qinv (double Q)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the unit Gaussian
   distribution.

|newpage|

The Gaussian Tail Distribution
==============================

.. index:: Gaussian Tail distribution

.. function:: double gsl_ran_gaussian_tail (const gsl_rng * r, double a, double sigma)

   This function provides random variates from the upper tail of a Gaussian
   distribution with standard deviation :data:`sigma`.  The values returned
   are larger than the lower limit :data:`a`, which must be positive.  The
   method is based on Marsaglia's famous rectangle-wedge-tail algorithm (Ann. 
   Math. Stat. 32, 894--899 (1961)), with this aspect explained in Knuth, v2,
   3rd ed, p139,586 (exercise 11).

   The probability distribution for Gaussian tail random variates is,

   .. math:: p(x) dx = {1 \over N(a;\sigma) \sqrt{2 \pi \sigma^2}} \exp (- x^2 / 2\sigma^2) dx

   for :math:`x > a` where :math:`N(a;\sigma)` is the normalization constant,

   .. only:: not texinfo

      .. math:: N(a;\sigma) = {1 \over 2} \hbox{erfc}\left({a \over \sqrt{2 \sigma^2}}\right).

   .. only:: texinfo

      ::

         N(a;\sigma) = (1/2) erfc(a / sqrt(2 sigma^2)).

.. function:: double gsl_ran_gaussian_tail_pdf (double x, double a, double sigma)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Gaussian tail distribution with standard deviation :data:`sigma` and
   lower limit :data:`a`, using the formula given above.

   .. image:: /images/rand-gaussian-tail.png

.. function:: double gsl_ran_ugaussian_tail (const gsl_rng * r, double a)
              double gsl_ran_ugaussian_tail_pdf (double :data:`x`, double :data:`a`)

   These functions compute results for the tail of a unit Gaussian
   distribution.  They are equivalent to the functions above with a standard
   deviation of one, :data:`sigma` = 1.

|newpage|

The Bivariate Gaussian Distribution
===================================

.. index::
   single: Bivariate Gaussian distribution
   single: two dimensional Gaussian distribution
   single: Gaussian distribution, bivariate

.. function:: void gsl_ran_bivariate_gaussian (const gsl_rng * r, double sigma_x, double sigma_y, double rho, double * x, double * y)

   This function generates a pair of correlated Gaussian variates, with
   mean zero, correlation coefficient :data:`rho` and standard deviations
   :data:`sigma_x` and :data:`sigma_y` in the :math:`x` and :math:`y` directions.
   The probability distribution for bivariate Gaussian random variates is,

   .. only:: not texinfo

      .. math:: p(x,y) dx dy = {1 \over 2 \pi \sigma_x \sigma_y \sqrt{1-\rho^2}} \exp \left(-{(x^2/\sigma_x^2 + y^2/\sigma_y^2 - 2 \rho x y/(\sigma_x\sigma_y)) \over 2(1-\rho^2)}\right) dx dy

   .. only:: texinfo

      ::

         p(x,y) dx dy = {1 \over 2 \pi \sigma_x \sigma_y \sqrt{1-\rho^2}} \exp (-(x^2/\sigma_x^2 + y^2/\sigma_y^2 - 2 \rho x y/(\sigma_x\sigma_y))/2(1-\rho^2)) dx dy

   for :math:`x,y` in the range :math:`-\infty` to :math:`+\infty`.  The
   correlation coefficient :data:`rho` should lie between :math:`1` and
   :math:`-1`.

.. function:: double gsl_ran_bivariate_gaussian_pdf (double x, double y, double sigma_x, double sigma_y, double rho)

   This function computes the probability density :math:`p(x,y)` at
   (:data:`x`, :data:`y`) for a bivariate Gaussian distribution with standard
   deviations :data:`sigma_x`, :data:`sigma_y` and correlation coefficient
   :data:`rho`, using the formula given above.

   .. image:: /images/rand-bivariate-gaussian.png

|newpage|

The Multivariate Gaussian Distribution
======================================

.. index::
   single: Bivariate Gaussian distribution
   single: two dimensional Gaussian distribution
   single: Gaussian distribution, bivariate

.. function:: int gsl_ran_multivariate_gaussian (const gsl_rng * r, const gsl_vector * mu, const gsl_matrix * L, gsl_vector * result)

   This function generates a random vector satisfying the :math:`k`-dimensional multivariate Gaussian
   distribution with mean :math:`\mu` and variance-covariance matrix
   :math:`\Sigma`. On input, the :math:`k`-vector :math:`\mu` is given in :data:`mu`, and
   the Cholesky factor of the :math:`k`-by-:math:`k` matrix :math:`\Sigma = L L^T` is
   given in the lower triangle of :data:`L`, as output from :func:`gsl_linalg_cholesky_decomp`.
   The random vector is stored in :data:`result` on output. The probability distribution
   for multivariate Gaussian random variates is

   .. only:: not texinfo

      .. math:: p(x_1,\dots,x_k) dx_1 \dots dx_k = {1 \over \sqrt{(2 \pi)^k |\Sigma|}} \exp \left(-{1 \over 2} (x - \mu)^T \Sigma^{-1} (x - \mu)\right) dx_1 \dots dx_k

   .. only:: texinfo

      ::

         p(x_1,...,x_k) dx_1 ... dx_k = 1 / ( \sqrt{(2 \pi)^k |\Sigma| ) \exp (-1/2 (x - \mu)^T \Sigma^{-1} (x - \mu)) dx_1 ... dx_k

.. function:: int gsl_ran_multivariate_gaussian_pdf (const gsl_vector * x, const gsl_vector * mu, const gsl_matrix * L, double * result, gsl_vector * work)
              int gsl_ran_multivariate_gaussian_log_pdf (const gsl_vector * x, const gsl_vector * mu, const gsl_matrix * L, double * result, gsl_vector * work)

   These functions compute :math:`p(x)` or :math:`\log{p(x)}` at the point :data:`x`, using mean vector
   :data:`mu` and variance-covariance matrix specified by its Cholesky factor :data:`L` using the formula
   above. Additional workspace of length :math:`k` is required in :data:`work`.

.. function:: int gsl_ran_multivariate_gaussian_mean (const gsl_matrix * X, gsl_vector * mu_hat)

   Given a set of :math:`n` samples :math:`X_j` from a :math:`k`-dimensional multivariate Gaussian distribution,
   this function computes the maximum likelihood estimate of the mean of the distribution, given by

   .. math:: \Hat{\mu} = {1 \over n} \sum_{j=1}^n X_j

   The samples :math:`X_1,X_2,\dots,X_n` are given in the :math:`n`-by-:math:`k` matrix :data:`X`, and the maximum
   likelihood estimate of the mean is stored in :data:`mu_hat` on output.

.. function:: int gsl_ran_multivariate_gaussian_vcov (const gsl_matrix * X, gsl_matrix * sigma_hat)

   Given a set of :math:`n` samples :math:`X_j` from a :math:`k`-dimensional multivariate Gaussian distribution,
   this function computes the maximum likelihood estimate of the variance-covariance matrix of the distribution,
   given by

   .. only:: not texinfo

      .. math:: \Hat{\Sigma} = {1 \over n} \sum_{j=1}^n \left( X_j - \Hat{\mu} \right) \left( X_j - \Hat{\mu} \right)^T

   .. only:: texinfo

      ::

         \Hat{\Sigma} = (1 / n) \sum_{j=1}^n ( X_j - \Hat{\mu} ) ( X_j - \Hat{\mu} )^T

   The samples :math:`X_1,X_2,\dots,X_n` are given in the :math:`n`-by-:math:`k` matrix :data:`X` and the maximum
   likelihood estimate of the variance-covariance matrix is stored in :data:`sigma_hat` on output.

|newpage|

The Exponential Distribution
============================

.. index:: Exponential distribution

.. function:: double gsl_ran_exponential (const gsl_rng * r, double mu)

   This function returns a random variate from the exponential distribution
   with mean :data:`mu`. The distribution is,

   .. math:: p(x) dx = {1 \over \mu} \exp(-x/\mu) dx

   for :math:`x \ge 0`.

.. function:: double gsl_ran_exponential_pdf (double x, double mu)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for an exponential distribution with mean :data:`mu`, using the formula
   given above.

   .. image:: /images/rand-exponential.png

.. function:: double gsl_cdf_exponential_P (double x, double mu)
              double gsl_cdf_exponential_Q (double x, double mu)
              double gsl_cdf_exponential_Pinv (double P, double mu)
              double gsl_cdf_exponential_Qinv (double Q, double mu)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the exponential
   distribution with mean :data:`mu`.

|newpage|

The Laplace Distribution
========================

.. index::
   single: two-sided exponential distribution
   single: Laplace distribution

.. function:: double gsl_ran_laplace (const gsl_rng * r, double a)

   This function returns a random variate from the Laplace distribution
   with width :data:`a`.  The distribution is,

   .. math:: p(x) dx = {1 \over 2 a}  \exp(-|x/a|) dx

   for :math:`-\infty < x < \infty`.

.. function:: double gsl_ran_laplace_pdf (double x, double a)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Laplace distribution with width :data:`a`, using the formula
   given above.

   .. image:: /images/rand-laplace.png

.. function:: double gsl_cdf_laplace_P (double x, double a)
              double gsl_cdf_laplace_Q (double x, double a)
              double gsl_cdf_laplace_Pinv (double P, double a)
              double gsl_cdf_laplace_Qinv (double Q, double a)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the Laplace
   distribution with width :data:`a`.

|newpage|

The Exponential Power Distribution
==================================

.. index:: Exponential power distribution

.. function:: double gsl_ran_exppow (const gsl_rng * r, double a, double b)

   This function returns a random variate from the exponential power distribution
   with scale parameter :data:`a` and exponent :data:`b`.  The distribution is,

   .. math:: p(x) dx = {1 \over 2 a \Gamma(1+1/b)} \exp(-|x/a|^b) dx

   for :math:`x \ge 0`.
   For :math:`b = 1` this reduces to the Laplace
   distribution.  For :math:`b = 2` it has the same form as a Gaussian
   distribution, but with :math:`a = \sqrt{2} \sigma`.

.. function:: double gsl_ran_exppow_pdf (double x, double a, double b)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for an exponential power distribution with scale parameter :data:`a`
   and exponent :data:`b`, using the formula given above.

   .. image:: /images/rand-exppow.png

.. function:: double gsl_cdf_exppow_P (double x, double a, double b)
              double gsl_cdf_exppow_Q (double x, double a, double b)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` for the exponential power distribution with
   parameters :data:`a` and :data:`b`.

|newpage|

The Cauchy Distribution
=======================

.. index:: Cauchy distribution

.. function:: double gsl_ran_cauchy (const gsl_rng * r, double a)

   This function returns a random variate from the Cauchy distribution with
   scale parameter :data:`a`.  The probability distribution for Cauchy
   random variates is,

   .. math:: p(x) dx = {1 \over a\pi (1 + (x/a)^2) } dx

   for :math:`x` in the range :math:`-\infty` to :math:`+\infty`.  The Cauchy
   distribution is also known as the Lorentz distribution.

.. function:: double gsl_ran_cauchy_pdf (double x, double a)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Cauchy distribution with scale parameter :data:`a`, using the formula
   given above.

   .. image:: /images/rand-cauchy.png

.. function:: double gsl_cdf_cauchy_P (double x, double a)
              double gsl_cdf_cauchy_Q (double x, double a)
              double gsl_cdf_cauchy_Pinv (double P, double a)
              double gsl_cdf_cauchy_Qinv (double Q, double a)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the Cauchy
   distribution with scale parameter :data:`a`.

|newpage|

The Rayleigh Distribution
=========================

.. index:: Rayleigh distribution

.. function:: double gsl_ran_rayleigh (const gsl_rng * r, double sigma)

   This function returns a random variate from the Rayleigh distribution with
   scale parameter :data:`sigma`.  The distribution is,

   .. math:: p(x) dx = {x \over \sigma^2} \exp(- x^2/(2 \sigma^2)) dx

   for :math:`x > 0`.

.. function:: double gsl_ran_rayleigh_pdf (double x, double sigma)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Rayleigh distribution with scale parameter :data:`sigma`, using the
   formula given above.

   .. image:: /images/rand-rayleigh.png

.. function:: double gsl_cdf_rayleigh_P (double x, double sigma)
              double gsl_cdf_rayleigh_Q (double x, double sigma)
              double gsl_cdf_rayleigh_Pinv (double P, double sigma)
              double gsl_cdf_rayleigh_Qinv (double Q, double sigma)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the Rayleigh
   distribution with scale parameter :data:`sigma`.

|newpage|

The Rayleigh Tail Distribution
==============================

.. index:: Rayleigh Tail distribution

.. function:: double gsl_ran_rayleigh_tail (const gsl_rng * r, double a, double sigma)

   This function returns a random variate from the tail of the Rayleigh
   distribution with scale parameter :data:`sigma` and a lower limit of
   :data:`a`.  The distribution is,

   .. math:: p(x) dx = {x \over \sigma^2} \exp ((a^2 - x^2) /(2 \sigma^2)) dx

   for :math:`x > a`.

.. function:: double gsl_ran_rayleigh_tail_pdf (double x, double a, double sigma)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Rayleigh tail distribution with scale parameter :data:`sigma` and
   lower limit :data:`a`, using the formula given above.

   .. image:: /images/rand-rayleigh-tail.png

|newpage|

The Landau Distribution
=======================

.. index:: Landau distribution

.. function:: double gsl_ran_landau (const gsl_rng * r)

   This function returns a random variate from the Landau distribution.  The
   probability distribution for Landau random variates is defined
   analytically by the complex integral,

   .. only:: not texinfo

      .. math:: p(x) = {1 \over {2 \pi i}} \int_{c-i\infty}^{c+i\infty} ds\, \exp(s \log(s) + x s) 

   .. only:: texinfo

      ::

         p(x) = (1/(2 \pi i)) \int_{c-i\infty}^{c+i\infty} ds exp(s log(s) + x s) 

   For numerical purposes it is more convenient to use the following
   equivalent form of the integral,

   .. math:: p(x) = (1/\pi) \int_0^\infty dt \exp(-t \log(t) - x t) \sin(\pi t).

.. function:: double gsl_ran_landau_pdf (double x)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for the Landau distribution using an approximation to the formula given
   above.

   .. image:: /images/rand-landau.png

|newpage|

The Levy alpha-Stable Distributions
===================================

.. index:: Levy distribution

.. function:: double gsl_ran_levy (const gsl_rng * r, double c, double alpha)

   This function returns a random variate from the Levy symmetric stable
   distribution with scale :data:`c` and exponent :data:`alpha`.  The symmetric
   stable probability distribution is defined by a Fourier transform,

   .. only:: not texinfo

      .. math:: p(x) = {1 \over 2 \pi} \int_{-\infty}^{+\infty} dt \exp(-it x - |c t|^\alpha)

   .. only:: texinfo

      ::

         p(x) = 1 / (2 \pi) \int_{-\infty}^{+\infty} dt \exp(-it x - |c t|^alpha)

   There is no explicit solution for the form of :math:`p(x)` and the
   library does not define a corresponding :code:`pdf` function.  For
   :math:`\alpha = 1` the distribution reduces to the Cauchy distribution.  For
   :math:`\alpha = 2` it is a Gaussian distribution with :math:`\sigma = \sqrt{2} c`.
   For :math:`\alpha < 1` the tails of the distribution become extremely wide.

   The algorithm only works for :math:`0 < \alpha \le 2`.

   .. image:: /images/rand-levy.png

|newpage|

The Levy skew alpha-Stable Distribution
=======================================

.. index::
   single: Levy distribution, skew
   single: Skew Levy distribution

.. function:: double gsl_ran_levy_skew (const gsl_rng * r, double c, double alpha, double beta)

   This function returns a random variate from the Levy skew stable
   distribution with scale :data:`c`, exponent :data:`alpha` and skewness
   parameter :data:`beta`.  The skewness parameter must lie in the range
   :math:`[-1,1]`.  The Levy skew stable probability distribution is defined
   by a Fourier transform,

   .. only:: not texinfo

      .. math:: p(x) = {1 \over 2 \pi} \int_{-\infty}^{+\infty} dt \exp(-it x - |c t|^\alpha (1-i \beta \sgn(t) \tan(\pi\alpha/2)))

   .. only:: texinfo

      ::

         p(x) = 1 / (2 \pi) \int_{-\infty}^{+\infty} dt \exp(-it x - |c t|^alpha (1-i beta sign(t) tan(pi alpha/2)))

   When :math:`\alpha = 1` the term :math:`\tan(\pi \alpha/2)` is replaced by
   :math:`-(2/\pi)\log|t|`.  There is no explicit solution for the form of
   :math:`p(x)` and the library does not define a corresponding :code:`pdf`
   function.  For :math:`\alpha = 2` the distribution reduces to a Gaussian
   distribution with :math:`\sigma = \sqrt{2} c`
   and the skewness parameter has no effect.  
   For :math:`\alpha < 1` the tails of the distribution become extremely
   wide.  The symmetric distribution corresponds to :math:`\beta = 0`.

   The algorithm only works for :math:`0 < \alpha \le 2`.

The Levy alpha-stable distributions have the property that if :math:`N`
alpha-stable variates are drawn from the distribution :math:`p(c, \alpha, \beta)`
then the sum :math:`Y = X_1 + X_2 + \dots + X_N` will also be
distributed as an alpha-stable variate,
:math:`p(N^{1/\alpha} c, \alpha, \beta)`.

.. PDF not available because there is no analytic expression for it
..
.. @deftypefun double gsl_ran_levy_pdf (double x, double mu)
.. This function computes the probability density :math:`p(x)` at :data:`x`
.. for a symmetric Levy distribution with scale parameter :data:`mu` and
.. exponent :data:`a`, using the formula given above.
.. @end deftypefun

.. image:: /images/rand-levyskew.png

|newpage|

The Gamma Distribution
======================

.. index::
   single: Gamma distribution
   single: Erlang distribution

.. function:: double gsl_ran_gamma (const gsl_rng * r, double a, double b)

   This function returns a random variate from the gamma
   distribution.  The distribution function is,

   .. math:: p(x) dx = {1 \over \Gamma(a) b^a} x^{a-1} e^{-x/b} dx

   for :math:`x > 0`.

   The gamma distribution with an integer parameter :data:`a` is known as the Erlang distribution.

   The variates are computed using the Marsaglia-Tsang fast gamma method.
   This function for this method was previously called
   :func:`gsl_ran_gamma_mt` and can still be accessed using this name.

.. If @xmath{X} and @xmath{Y} are independent gamma-distributed random
.. variables of order @xmath{a} and @xmath{b}, then @xmath{X+Y} has a gamma
.. distribution of order @xmath{a+b}.

.. function:: double gsl_ran_gamma_knuth (const gsl_rng * r, double a, double b)

   This function returns a gamma variate using the algorithms from Knuth (vol 2).

.. function:: double gsl_ran_gamma_pdf (double x, double a, double b)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a gamma distribution with parameters :data:`a` and :data:`b`, using the
   formula given above.

   .. image:: /images/rand-gamma.png

.. function:: double gsl_cdf_gamma_P (double x, double a, double b)
              double gsl_cdf_gamma_Q (double x, double a, double b)
              double gsl_cdf_gamma_Pinv (double P, double a, double b)
              double gsl_cdf_gamma_Qinv (double Q, double a, double b)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the gamma
   distribution with parameters :data:`a` and :data:`b`.

|newpage|

The Flat (Uniform) Distribution
===============================

.. index::
   single: flat distribution
   single: uniform distribution

.. function:: double gsl_ran_flat (const gsl_rng * r, double a, double b)

   This function returns a random variate from the flat (uniform)
   distribution from :data:`a` to :data:`b`. The distribution is,

   .. math:: p(x) dx = {1 \over (b-a)} dx

   if :math:`a \le x < b` and 0 otherwise.

.. function:: double gsl_ran_flat_pdf (double x, double a, double b)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a uniform distribution from :data:`a` to :data:`b`, using the formula
   given above.

   .. image:: /images/rand-flat.png

.. function:: double gsl_cdf_flat_P (double x, double a, double b)
              double gsl_cdf_flat_Q (double x, double a, double b)
              double gsl_cdf_flat_Pinv (double P, double a, double b)
              double gsl_cdf_flat_Qinv (double Q, double a, double b)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for a uniform distribution
   from :data:`a` to :data:`b`.

|newpage|

The Lognormal Distribution
==========================

.. index:: Lognormal distribution

.. function:: double gsl_ran_lognormal (const gsl_rng * r, double zeta, double sigma)

   This function returns a random variate from the lognormal
   distribution.  The distribution function is,

   .. math:: p(x) dx = {1 \over x \sqrt{2 \pi \sigma^2}} \exp(-(\ln(x) - \zeta)^2/2 \sigma^2) dx

   for :math:`x > 0`.

.. function:: double gsl_ran_lognormal_pdf (double x, double zeta, double sigma)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a lognormal distribution with parameters :data:`zeta` and :data:`sigma`,
   using the formula given above.

   .. image:: /images/rand-lognormal.png

.. function:: double gsl_cdf_lognormal_P (double x, double zeta, double sigma)
              double gsl_cdf_lognormal_Q (double x, double zeta, double sigma)
              double gsl_cdf_lognormal_Pinv (double P, double zeta, double sigma)
              double gsl_cdf_lognormal_Qinv (double Q, double zeta, double sigma)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the lognormal
   distribution with parameters :data:`zeta` and :data:`sigma`.

|newpage|

The Chi-squared Distribution
============================

The chi-squared distribution arises in statistics.  If :math:`Y_i` are
:math:`n` independent Gaussian random variates with unit variance then the
sum-of-squares,

.. math:: X_i = \sum_i Y_i^2

has a chi-squared distribution with :math:`n` degrees of freedom.

.. index:: Chi-squared distribution

.. function:: double gsl_ran_chisq (const gsl_rng * r, double nu)

   This function returns a random variate from the chi-squared distribution
   with :data:`nu` degrees of freedom. The distribution function is,

   .. math:: p(x) dx = {1 \over 2 \Gamma(\nu/2) } (x/2)^{\nu/2 - 1} \exp(-x/2) dx

   for :math:`x \ge 0`.

.. function:: double gsl_ran_chisq_pdf (double x, double nu)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a chi-squared distribution with :data:`nu` degrees of freedom, using
   the formula given above.

   .. image:: /images/rand-chisq.png

.. function:: double gsl_cdf_chisq_P (double x, double nu)
              double gsl_cdf_chisq_Q (double x, double nu)
              double gsl_cdf_chisq_Pinv (double P, double nu)
              double gsl_cdf_chisq_Qinv (double Q, double nu)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the chi-squared
   distribution with :data:`nu` degrees of freedom.

|newpage|

The F-distribution
==================

The F-distribution arises in statistics.  If :math:`Y_1` and :math:`Y_2`
are chi-squared deviates with :math:`\nu_1` and :math:`\nu_2` degrees of
freedom then the ratio,

.. math:: X = { (Y_1 / \nu_1) \over (Y_2 / \nu_2) }

has an F-distribution :math:`F(x;\nu_1,\nu_2)`.

.. index:: F-distribution

.. function:: double gsl_ran_fdist (const gsl_rng * r, double nu1, double nu2)

   This function returns a random variate from the F-distribution with degrees of freedom :data:`nu1` and :data:`nu2`.
   The distribution function is,

   .. only:: not texinfo

      .. math::

         p(x) dx = 
            { \Gamma((\nu_1 + \nu_2)/2)
                 \over \Gamma(\nu_1/2) \Gamma(\nu_2/2) } 
            \nu_1^{\nu_1/2} \nu_2^{\nu_2/2} 
            x^{\nu_1/2 - 1} (\nu_2 + \nu_1 x)^{-\nu_1/2 -\nu_2/2}

   .. only:: texinfo

      ::

         p(x) dx = 
            { \Gamma((\nu_1 + \nu_2)/2)
                 \over \Gamma(\nu_1/2) \Gamma(\nu_2/2) } 
            \nu_1^{\nu_1/2} \nu_2^{\nu_2/2} 
            x^{\nu_1/2 - 1} (\nu_2 + \nu_1 x)^{-\nu_1/2 -\nu_2/2}

   for :math:`x \ge 0`.

.. function:: double gsl_ran_fdist_pdf (double x, double nu1, double nu2)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for an F-distribution with :data:`nu1` and :data:`nu2` degrees of freedom,
   using the formula given above.

   .. image:: /images/rand-fdist.png

.. function:: double gsl_cdf_fdist_P (double x, double nu1, double nu2)
              double gsl_cdf_fdist_Q (double x, double nu1, double nu2)
              double gsl_cdf_fdist_Pinv (double P, double nu1, double nu2)
              double gsl_cdf_fdist_Qinv (double Q, double nu1, double nu2)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the F-distribution
   with :data:`nu1` and :data:`nu2` degrees of freedom.

|newpage|

The t-distribution
==================

The t-distribution arises in statistics.  If :math:`Y_1` has a normal
distribution and :math:`Y_2` has a chi-squared distribution with
:math:`\nu` degrees of freedom then the ratio,

.. math:: X = { Y_1 \over \sqrt{Y_2 / \nu} }

has a t-distribution :math:`t(x;\nu)` with :math:`\nu` degrees of freedom.

.. index::
   single: t-distribution
   single: Student t-distribution

.. function:: double gsl_ran_tdist (const gsl_rng * r, double nu)

   This function returns a random variate from the t-distribution.  The
   distribution function is,

   .. math::

      p(x) dx = {\Gamma((\nu + 1)/2) \over \sqrt{\pi \nu} \Gamma(\nu/2)}
         (1 + x^2/\nu)^{-(\nu + 1)/2} dx

   for :math:`-\infty < x < +\infty`.

.. function:: double gsl_ran_tdist_pdf (double x, double nu)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a t-distribution with :data:`nu` degrees of freedom, using the formula
   given above.

   .. image:: /images/rand-tdist.png

.. function:: double gsl_cdf_tdist_P (double x, double nu)
              double gsl_cdf_tdist_Q (double x, double nu)
              double gsl_cdf_tdist_Pinv (double P, double nu)
              double gsl_cdf_tdist_Qinv (double Q, double nu)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the t-distribution
   with :data:`nu` degrees of freedom.

|newpage|

The Beta Distribution
=====================

.. index:: Beta distribution

.. function:: double gsl_ran_beta (const gsl_rng * r, double a, double b)

   This function returns a random variate from the beta
   distribution.  The distribution function is,

   .. math:: p(x) dx = {\Gamma(a+b) \over \Gamma(a) \Gamma(b)} x^{a-1} (1-x)^{b-1} dx

   for :math:`0 \le x \le 1`.

.. function:: double gsl_ran_beta_pdf (double x, double a, double b)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a beta distribution with parameters :data:`a` and :data:`b`, using the
   formula given above.

   .. image:: /images/rand-beta.png

.. function:: double gsl_cdf_beta_P (double x, double a, double b)
              double gsl_cdf_beta_Q (double x, double a, double b)
              double gsl_cdf_beta_Pinv (double P, double a, double b)
              double gsl_cdf_beta_Qinv (double Q, double a, double b)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the beta
   distribution with parameters :data:`a` and :data:`b`.

|newpage|

The Logistic Distribution
=========================

.. index:: Logistic distribution

.. function:: double gsl_ran_logistic (const gsl_rng * r, double a)

   This function returns a random variate from the logistic
   distribution.  The distribution function is,

   .. math:: p(x) dx = { \exp(-x/a) \over a (1 + \exp(-x/a))^2 } dx

   for :math:`-\infty < x < +\infty`.

.. function:: double gsl_ran_logistic_pdf (double x, double a)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a logistic distribution with scale parameter :data:`a`, using the
   formula given above.

   .. image:: /images/rand-logistic.png

.. function:: double gsl_cdf_logistic_P (double x, double a)
              double gsl_cdf_logistic_Q (double x, double a)
              double gsl_cdf_logistic_Pinv (double P, double a)
              double gsl_cdf_logistic_Qinv (double Q, double a)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the logistic
   distribution with scale parameter :data:`a`.

|newpage|

The Pareto Distribution
=======================

.. index:: Pareto distribution

.. function:: double gsl_ran_pareto (const gsl_rng * r, double a, double b)

   This function returns a random variate from the Pareto distribution of
   order :data:`a`.  The distribution function is,

   .. math:: p(x) dx = (a/b) / (x/b)^{a+1} dx

   for :math:`x \ge b`.

.. function:: double gsl_ran_pareto_pdf (double x, double a, double b)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Pareto distribution with exponent :data:`a` and scale :data:`b`, using
   the formula given above.

   .. image:: /images/rand-pareto.png

.. function:: double gsl_cdf_pareto_P (double x, double a, double b)
              double gsl_cdf_pareto_Q (double x, double a, double b)
              double gsl_cdf_pareto_Pinv (double P, double a, double b)
              double gsl_cdf_pareto_Qinv (double Q, double a, double b)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the Pareto
   distribution with exponent :data:`a` and scale :data:`b`.

|newpage|

Spherical Vector Distributions
==============================

The spherical distributions generate random vectors, located on a
spherical surface.  They can be used as random directions, for example in
the steps of a random walk.

.. index::
   single: 2D random direction vector
   single: direction vector, random 2D
   single: spherical random variates, 2D

.. function:: void gsl_ran_dir_2d (const gsl_rng * r, double * x, double * y)
              void gsl_ran_dir_2d_trig_method (const gsl_rng * r, double * x, double * y)

   This function returns a random direction vector :math:`v` =
   (:data:`x`, :data:`y`) in two dimensions.  The vector is normalized such that
   :math:`|v|^2 = x^2 + y^2 = 1`.  The obvious way to do this is to take a
   uniform random number between 0 and :math:`2\pi` and let :data:`x` and
   :data:`y` be the sine and cosine respectively.  Two trig functions would
   have been expensive in the old days, but with modern hardware
   implementations, this is sometimes the fastest way to go.  This is the
   case for the Pentium (but not the case for the Sun Sparcstation).
   One can avoid the trig evaluations by choosing :data:`x` and
   :data:`y` in the interior of a unit circle (choose them at random from the
   interior of the enclosing square, and then reject those that are outside
   the unit circle), and then dividing by :math:`\sqrt{x^2 + y^2}`.
   A much cleverer approach, attributed to von Neumann (See Knuth, v2, 3rd
   ed, p140, exercise 23), requires neither trig nor a square root.  In
   this approach, :data:`u` and :data:`v` are chosen at random from the
   interior of a unit circle, and then :math:`x=(u^2-v^2)/(u^2+v^2)` and
   :math:`y=2uv/(u^2+v^2)`.

.. index::
   single: 3D random direction vector
   single: direction vector, random 3D
   single: spherical random variates, 3D

.. function:: void gsl_ran_dir_3d (const gsl_rng * r, double * x, double * y, double * z)

   This function returns a random direction vector :math:`v` =
   (:data:`x`, :data:`y`, :data:`z`) in three dimensions.  The vector is normalized
   such that :math:`|v|^2 = x^2 + y^2 + z^2 = 1`.  The method employed is
   due to Robert E. Knop (CACM 13, 326 (1970)), and explained in Knuth, v2,
   3rd ed, p136.  It uses the surprising fact that the distribution
   projected along any axis is actually uniform (this is only true for 3
   dimensions).

.. index::
   single: N-dimensional random direction vector
   single: direction vector, random N-dimensional
   single: spherical random variates, N-dimensional

.. function:: void gsl_ran_dir_nd (const gsl_rng * r, size_t n, double * x)

   This function returns a random direction vector
   :math:`v = (x_1,x_2,\ldots,x_n)`
   in :data:`n` dimensions.  The vector is normalized such that 
   :math:`|v|^2 = x_1^2 + x_2^2 + \cdots + x_n^2 = 1`.
   The method
   uses the fact that a multivariate Gaussian distribution is spherically
   symmetric.  Each component is generated to have a Gaussian distribution,
   and then the components are normalized.  The method is described by
   Knuth, v2, 3rd ed, p135--136, and attributed to G. W. Brown, Modern
   Mathematics for the Engineer (1956).

|newpage|

The Weibull Distribution
========================

.. index:: Weibull distribution

.. function:: double gsl_ran_weibull (const gsl_rng * r, double a, double b)

   This function returns a random variate from the Weibull distribution.  The
   distribution function is,

   .. math:: p(x) dx = {b \over a^b} x^{b-1}  \exp(-(x/a)^b) dx

   for :math:`x \ge 0`.

.. function:: double gsl_ran_weibull_pdf (double x, double a, double b)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Weibull distribution with scale :data:`a` and exponent :data:`b`,
   using the formula given above.

   .. image:: /images/rand-weibull.png

.. function:: double gsl_cdf_weibull_P (double x, double a, double b)
              double gsl_cdf_weibull_Q (double x, double a, double b)
              double gsl_cdf_weibull_Pinv (double P, double a, double b)
              double gsl_cdf_weibull_Qinv (double Q, double a, double b)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the Weibull
   distribution with scale :data:`a` and exponent :data:`b`.

|newpage|

The Type-1 Gumbel Distribution
==============================

.. index::
   single: Gumbel distribution (Type 1)
   single: Type 1 Gumbel distribution, random variates

.. function:: double gsl_ran_gumbel1 (const gsl_rng * r, double a, double b)

   This function returns  a random variate from the Type-1 Gumbel
   distribution.  The Type-1 Gumbel distribution function is,

   .. math:: p(x) dx = a b \exp(-(b \exp(-ax) + ax)) dx

   for :math:`-\infty < x < \infty`. 

.. function:: double gsl_ran_gumbel1_pdf (double x, double a, double b)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Type-1 Gumbel distribution with parameters :data:`a` and :data:`b`,
   using the formula given above.

   .. image:: /images/rand-gumbel1.png

.. function:: double gsl_cdf_gumbel1_P (double x, double a, double b)
              double gsl_cdf_gumbel1_Q (double x, double a, double b)
              double gsl_cdf_gumbel1_Pinv (double P, double a, double b)
              double gsl_cdf_gumbel1_Qinv (double Q, double a, double b)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the Type-1 Gumbel
   distribution with parameters :data:`a` and :data:`b`.

|newpage|

The Type-2 Gumbel Distribution
==============================

.. index::
   single: Gumbel distribution (Type 2)
   single: Type 2 Gumbel distribution

.. function:: double gsl_ran_gumbel2 (const gsl_rng * r, double a, double b)

   This function returns a random variate from the Type-2 Gumbel
   distribution.  The Type-2 Gumbel distribution function is,

   .. math:: p(x) dx = a b x^{-a-1} \exp(-b x^{-a}) dx

   for :math:`0 < x < \infty`.

.. function:: double gsl_ran_gumbel2_pdf (double x, double a, double b)

   This function computes the probability density :math:`p(x)` at :data:`x`
   for a Type-2 Gumbel distribution with parameters :data:`a` and :data:`b`,
   using the formula given above.

   .. image:: /images/rand-gumbel2.png

.. function:: double gsl_cdf_gumbel2_P (double x, double a, double b)
              double gsl_cdf_gumbel2_Q (double x, double a, double b)
              double gsl_cdf_gumbel2_Pinv (double P, double a, double b)
              double gsl_cdf_gumbel2_Qinv (double Q, double a, double b)

   These functions compute the cumulative distribution functions
   :math:`P(x)`, :math:`Q(x)` and their inverses for the Type-2 Gumbel
   distribution with parameters :data:`a` and :data:`b`.

|newpage|

The Dirichlet Distribution
==========================

.. index:: Dirichlet distribution 

.. function:: void gsl_ran_dirichlet (const gsl_rng * r, size_t K, const double alpha[], double theta[])

   This function returns an array of :data:`K` random variates from a Dirichlet
   distribution of order :data:`K`-1. The distribution function is

   .. only:: not texinfo

      .. math::

         p(\theta_1,\ldots,\theta_K) \, d\theta_1 \cdots d\theta_K = 
                 {1 \over Z} \prod_{i=1}^{K} \theta_i^{\alpha_i - 1} 
                   \; \delta(1 -\sum_{i=1}^K \theta_i) d\theta_1 \cdots d\theta_K

   .. only:: texinfo

      ::

         p(\theta_1, ..., \theta_K) d\theta_1 ... d\theta_K = 
           (1/Z) \prod_{i=1}^K \theta_i^{\alpha_i - 1} \delta(1 -\sum_{i=1}^K \theta_i) d\theta_1 ... d\theta_K

   for :math:`\theta_i \ge 0`
   and :math:`\alpha_i > 0`.
   The delta function ensures that :math:`\sum \theta_i = 1`.
   The normalization factor :math:`Z` is

   .. math:: Z = {\prod_{i=1}^K \Gamma(\alpha_i) \over \Gamma( \sum_{i=1}^K \alpha_i)}

   The random variates are generated by sampling :data:`K` values 
   from gamma distributions with parameters 
   :math:`a=\alpha_i$, $b=1`,
   and renormalizing. 
   See A.M. Law, W.D. Kelton, *Simulation Modeling and Analysis* (1991).

.. function:: double gsl_ran_dirichlet_pdf (size_t K, const double alpha[], const double theta[]) 

   This function computes the probability density 
   :math:`p(\theta_1, \ldots , \theta_K)`
   at :code:`theta[K]` for a Dirichlet distribution with parameters 
   :code:`alpha[K]`, using the formula given above.

.. function:: double gsl_ran_dirichlet_lnpdf (size_t K, const double alpha[], const double theta[]) 

   This function computes the logarithm of the probability density 
   :math:`p(\theta_1, \ldots , \theta_K)`
   for a Dirichlet distribution with parameters 
   :code:`alpha[K]`.

|newpage|

General Discrete Distributions
==============================

Given :math:`K` discrete events with different probabilities :math:`P[k]`,
produce a random value :math:`k` consistent with its probability.

The obvious way to do this is to preprocess the probability list by
generating a cumulative probability array with :math:`K + 1` elements:

.. only:: not texinfo

   .. math::

      C[0] & = 0 \\
      C[k+1] &= C[k] + P[k]

.. only:: texinfo

   ::

     C[0] = 0 
     C[k+1] = C[k] + P[k]

Note that this construction produces :math:`C[K] = 1`.  Now choose a
uniform deviate :math:`u` between 0 and 1, and find the value of :math:`k`
such that :math:`C[k] \le u < C[k+1]`.
Although this in principle requires of order :math:`\log K` steps per
random number generation, they are fast steps, and if you use something
like :math:`\lfloor uK \rfloor` as a starting point, you can often do
pretty well.

But faster methods have been devised.  Again, the idea is to preprocess
the probability list, and save the result in some form of lookup table;
then the individual calls for a random discrete event can go rapidly.
An approach invented by G. Marsaglia (Generating discrete random variables
in a computer, Comm ACM 6, 37--38 (1963)) is very clever, and readers
interested in examples of good algorithm design are directed to this
short and well-written paper.  Unfortunately, for large :math:`K`,
Marsaglia's lookup table can be quite large.  

A much better approach is due to Alastair J. Walker (An efficient method
for generating discrete random variables with general distributions, ACM
Trans on Mathematical Software 3, 253--256 (1977); see also Knuth, v2,
3rd ed, p120--121,139).  This requires two lookup tables, one floating
point and one integer, but both only of size :math:`K`.  After
preprocessing, the random numbers are generated in O(1) time, even for
large :math:`K`.  The preprocessing suggested by Walker requires
:math:`O(K^2)` effort, but that is not actually necessary, and the
implementation provided here only takes :math:`O(K)` effort.  In general,
more preprocessing leads to faster generation of the individual random
numbers, but a diminishing return is reached pretty early.  Knuth points
out that the optimal preprocessing is combinatorially difficult for
large :math:`K`.

This method can be used to speed up some of the discrete random number
generators below, such as the binomial distribution.  To use it for
something like the Poisson Distribution, a modification would have to
be made, since it only takes a finite set of :math:`K` outcomes.

.. index::
   single: Discrete random numbers
   single: Discrete random numbers, preprocessing

.. type:: gsl_ran_discrete_t

   This structure contains the lookup table for the discrete random number generator.

.. function:: gsl_ran_discrete_t * gsl_ran_discrete_preproc (size_t K, const double * P)

   This function returns a pointer to a structure that contains the lookup
   table for the discrete random number generator.  The array :data:`P` contains
   the probabilities of the discrete events; these array elements must all be 
   positive, but they needn't add up to one (so you can think of them more
   generally as "weights")---the preprocessor will normalize appropriately.
   This return value is used
   as an argument for the :func:`gsl_ran_discrete` function below.

.. index:: Discrete random numbers

.. function:: size_t gsl_ran_discrete (const gsl_rng * r, const gsl_ran_discrete_t * g)

   After the preprocessor, above, has been called, you use this function to
   get the discrete random numbers.

.. index:: Discrete random numbers

.. function:: double gsl_ran_discrete_pdf (size_t k, const gsl_ran_discrete_t * g)

   Returns the probability :math:`P[k]` of observing the variable :data:`k`.
   Since :math:`P[k]` is not stored as part of the lookup table, it must be
   recomputed; this computation takes :math:`O(K)`, so if :data:`K` is large
   and you care about the original array :math:`P[k]` used to create the
   lookup table, then you should just keep this original array :math:`P[k]`
   around.

.. index:: Discrete random numbers

.. function:: void gsl_ran_discrete_free (gsl_ran_discrete_t * g)

   De-allocates the lookup table pointed to by :data:`g`.

|newpage|

The Poisson Distribution
========================

.. index:: Poisson random numbers

.. function:: unsigned int gsl_ran_poisson (const gsl_rng * r, double mu)

   This function returns a random integer from the Poisson distribution
   with mean :data:`mu`.  The probability distribution for Poisson variates is,

   .. math:: p(k) = {\mu^k \over k!} \exp(-\mu)

   for :math:`k \ge 0`.

.. function:: double gsl_ran_poisson_pdf (unsigned int k, double mu)

   This function computes the probability :math:`p(k)` of obtaining  :data:`k`
   from a Poisson distribution with mean :data:`mu`, using the formula
   given above.

   .. image:: /images/rand-poisson.png

.. function:: double gsl_cdf_poisson_P (unsigned int k, double mu)
              double gsl_cdf_poisson_Q (unsigned int k, double mu)

   These functions compute the cumulative distribution functions
   :math:`P(k)`, :math:`Q(k)` for the Poisson distribution with parameter
   :data:`mu`.

|newpage|

The Bernoulli Distribution
==========================

.. index::
   single: Bernoulli trial, random variates

.. function:: unsigned int gsl_ran_bernoulli (const gsl_rng * r, double p)

   This function returns either 0 or 1, the result of a Bernoulli trial
   with probability :data:`p`.  The probability distribution for a Bernoulli
   trial is,

   .. only:: not texinfo

      .. math::

         p(0) & = 1 - p \\
         p(1) & = p

   .. only:: texinfo

      ::

         p(0) = 1 - p
         p(1) = p

.. function:: double gsl_ran_bernoulli_pdf (unsigned int k, double p)

   This function computes the probability :math:`p(k)` of obtaining
   :data:`k` from a Bernoulli distribution with probability parameter
   :data:`p`, using the formula given above.

   .. image:: /images/rand-bernoulli.png

|newpage|

The Binomial Distribution
=========================

.. index:: Binomial random variates

.. function:: unsigned int gsl_ran_binomial (const gsl_rng * r, double p, unsigned int n)

   This function returns a random integer from the binomial distribution,
   the number of successes in :data:`n` independent trials with probability
   :data:`p`.  The probability distribution for binomial variates is,

   .. math:: p(k) = {n! \over k! (n-k)!} p^k (1-p)^{n-k}

   for :math:`0 \le k \le n`.

.. function:: double gsl_ran_binomial_pdf (unsigned int k, double p, unsigned int n)

   This function computes the probability :math:`p(k)` of obtaining :data:`k`
   from a binomial distribution with parameters :data:`p` and :data:`n`, using
   the formula given above.

   .. image:: /images/rand-binomial.png

.. function:: double gsl_cdf_binomial_P (unsigned int k, double p, unsigned int n)
              double gsl_cdf_binomial_Q (unsigned int k, double p, unsigned int n)

   These functions compute the cumulative distribution functions
   :math:`P(k)`, :math:`Q(k)`  for the binomial
   distribution with parameters :data:`p` and :data:`n`.

|newpage|

The Multinomial Distribution
============================

.. index:: Multinomial distribution 

.. function:: void gsl_ran_multinomial (const gsl_rng * r, size_t K, unsigned int N, const double p[], unsigned int n[])

   This function computes a random sample :data:`n` from the multinomial
   distribution formed by :data:`N` trials from an underlying distribution
   :data:`p[K]`. The distribution function for :data:`n` is,

   .. only:: not texinfo

      .. math::

         P(n_1, n_2,\cdots, n_K) = {{ N!}\over{n_1 ! n_2 ! \cdots n_K !}} \,
           p_1^{n_1} p_2^{n_2} \cdots p_K^{n_K}

   .. only:: texinfo

      ::

         P(n_1, n_2, ..., n_K) = 
           (N!/(n_1! n_2! ... n_K!)) p_1^n_1 p_2^n_2 ... p_K^n_K

   where :math:`(n_1, n_2, \ldots, n_K)`
   are nonnegative integers with 
   :math:`\sum_{k=1}^{K} n_k = N`,
   and
   :math:`(p_1, p_2, \ldots, p_K)`
   is a probability distribution with :math:`\sum p_i = 1`.  
   If the array :code:`p[K]` is not normalized then its entries will be
   treated as weights and normalized appropriately.  The arrays :data:`n`
   and :data:`p` must both be of length :data:`K`.

   Random variates are generated using the conditional binomial method (see
   C.S. Davis, *The computer generation of multinomial random
   variates*, Comp. Stat. Data Anal. 16 (1993) 205--217 for details).

.. function:: double gsl_ran_multinomial_pdf (size_t K, const double p[], const unsigned int n[]) 

   This function computes the probability 
   :math:`P(n_1, n_2, \ldots, n_K)`
   of sampling :code:`n[K]` from a multinomial distribution 
   with parameters :code:`p[K]`, using the formula given above.

.. function:: double gsl_ran_multinomial_lnpdf (size_t K, const double p[], const unsigned int n[]) 

   This function returns the logarithm of the probability for the
   multinomial distribution :math:`P(n_1, n_2, \ldots, n_K)`
   with parameters :code:`p[K]`.

|newpage|

The Negative Binomial Distribution
==================================

.. index::
   single: Negative Binomial distribution, random variates

.. function:: unsigned int gsl_ran_negative_binomial (const gsl_rng * r, double p, double n)

   This function returns a random integer from the negative binomial
   distribution, the number of failures occurring before :data:`n` successes
   in independent trials with probability :data:`p` of success.  The
   probability distribution for negative binomial variates is,

   .. math:: p(k) = {\Gamma(n + k) \over \Gamma(k+1) \Gamma(n) } p^n (1-p)^k

   Note that :math:`n` is not required to be an integer.

.. function:: double gsl_ran_negative_binomial_pdf (unsigned int k, double p, double  n)

   This function computes the probability :math:`p(k)` of obtaining :data:`k`
   from a negative binomial distribution with parameters :data:`p` and
   :data:`n`, using the formula given above.

   .. image:: /images/rand-nbinomial.png

.. function:: double gsl_cdf_negative_binomial_P (unsigned int k, double p, double n)
              double gsl_cdf_negative_binomial_Q (unsigned int k, double p, double n)

   These functions compute the cumulative distribution functions
   :math:`P(k)`, :math:`Q(k)` for the negative binomial distribution with
   parameters :data:`p` and :data:`n`.

|newpage|

The Pascal Distribution
=======================

.. function:: unsigned int gsl_ran_pascal (const gsl_rng * r, double p, unsigned int n)

   This function returns a random integer from the Pascal distribution.  The
   Pascal distribution is simply a negative binomial distribution with an
   integer value of :math:`n`.

   .. math:: p(k) = {(n + k - 1)! \over k! (n - 1)! } p^n (1-p)^k

   for :math:`k \ge 0`.

.. function:: double gsl_ran_pascal_pdf (unsigned int k, double p, unsigned int n)

   This function computes the probability :math:`p(k)` of obtaining :data:`k`
   from a Pascal distribution with parameters :data:`p` and
   :data:`n`, using the formula given above.

   .. image:: /images/rand-pascal.png

.. function:: double gsl_cdf_pascal_P (unsigned int k, double p, unsigned int n)
              double gsl_cdf_pascal_Q (unsigned int k, double p, unsigned int n)

   These functions compute the cumulative distribution functions
   :math:`P(k)`, :math:`Q(k)` for the Pascal distribution with
   parameters :data:`p` and :data:`n`.

|newpage|

The Geometric Distribution
==========================

.. index:: Geometric random variates

.. function:: unsigned int gsl_ran_geometric (const gsl_rng * r, double p)

   This function returns a random integer from the geometric distribution,
   the number of independent trials with probability :data:`p` until the
   first success.  The probability distribution for geometric variates
   is,

   .. math:: p(k) = p (1-p)^{k-1}

   for :math:`k \ge 1`.
   Note that the distribution begins with :math:`k = 1` with this
   definition.  There is another convention in which the exponent :math:`k - 1` 
   is replaced by :math:`k`.

.. function:: double gsl_ran_geometric_pdf (unsigned int k, double p)

   This function computes the probability :math:`p(k)` of obtaining :data:`k`
   from a geometric distribution with probability parameter :data:`p`, using
   the formula given above.

   .. image:: /images/rand-geometric.png

.. function:: double gsl_cdf_geometric_P (unsigned int k, double p)
              double gsl_cdf_geometric_Q (unsigned int k, double p)

   These functions compute the cumulative distribution functions
   :math:`P(k)`, :math:`Q(k)` for the geometric distribution with parameter
   :data:`p`.

|newpage|

The Hypergeometric Distribution
===============================

.. index::
   single: hypergeometric random variates
   single: Geometric random variates

.. function:: unsigned int gsl_ran_hypergeometric (const gsl_rng * r, unsigned int n1, unsigned int n2, unsigned int t)

   This function returns a random integer from the hypergeometric
   distribution.  The probability distribution for hypergeometric
   random variates is,

   .. math:: p(k) = C(n_1, k) C(n_2, t - k) / C(n_1 + n_2, t)

   where :math:`C(a,b) = a!/(b!(a-b)!)` and 
   :math:`t \leq n_1 + n_2`.
   The domain of :math:`k` is 
   :math:`\max(0, t - n_2), \ldots, \min(t, n_1)`

   If a population contains :math:`n_1` elements of "type 1" and
   :math:`n_2` elements of "type 2" then the hypergeometric
   distribution gives the probability of obtaining :math:`k` elements of
   "type 1" in :math:`t` samples from the population without
   replacement.

.. function:: double gsl_ran_hypergeometric_pdf (unsigned int k, unsigned int n1, unsigned int n2, unsigned int t)

   This function computes the probability :math:`p(k)` of obtaining :data:`k`
   from a hypergeometric distribution with parameters :data:`n1`, :data:`n2`,
   :data:`t`, using the formula given above.

   .. image:: /images/rand-hypergeometric.png

.. function:: double gsl_cdf_hypergeometric_P (unsigned int k, unsigned int n1, unsigned int n2, unsigned int t)
              double gsl_cdf_hypergeometric_Q (unsigned int k, unsigned int n1, unsigned int n2, unsigned int t)

   These functions compute the cumulative distribution functions
   :math:`P(k)`, :math:`Q(k)` for the hypergeometric distribution with
   parameters :data:`n1`, :data:`n2` and :data:`t`.

|newpage|

.. index:: Logarithmic random variates

The Logarithmic Distribution
============================

.. function:: unsigned int gsl_ran_logarithmic (const gsl_rng * r, double p)

   This function returns a random integer from the logarithmic
   distribution.  The probability distribution for logarithmic random variates
   is,

   .. only:: not texinfo

      .. math:: p(k) = {-1 \over \log(1-p)} {\left( p^k \over k \right)}

   .. only:: texinfo
      
      ::

         p(k) = {-1 \over \log(1-p)} {(p^k \over k)}

   for :math:`k \ge 1`.

.. function:: double gsl_ran_logarithmic_pdf (unsigned int k, double p)

   This function computes the probability :math:`p(k)` of obtaining :data:`k`
   from a logarithmic distribution with probability parameter :data:`p`,
   using the formula given above.

   .. image:: /images/rand-logarithmic.png

|newpage|

.. index:: Wishart random variates

The Wishart Distribution
========================

.. function:: int gsl_ran_wishart (const gsl_rng * r, const double n, const gsl_matrix * L, gsl_matrix * result, gsl_matrix * work)

   This function computes a random symmetric :math:`p`-by-:math:`p` matrix from the Wishart distribution.
   The probability distribution for Wishart random variates is,

   .. only:: not texinfo

      .. math:: p(X) = \frac{|X|^{(n-p-1)/2} e^{-\textrm{tr}\left( V^{-1} X\right)/2}}{2^{\frac{np}{2}} \left| V \right|^{n/2} \Gamma_p(\frac{n}{2})}

   .. only:: texinfo

      .. math:: p(X) = \frac{|X|^{(n-p-1)/2} e^{-tr( V^{-1} X)/2}}{2^{(np)/2} |V|^{n/2} \Gamma_p(n/2)}

   Here, :math:`n > p - 1` is the number of degrees of freedom, :math:`V` is a symmetric positive definite
   :math:`p`-by-:math:`p` scale matrix, whose Cholesky factor is specified by :data:`L`, and :data:`work` is
   :math:`p`-by-:math:`p` workspace. The :math:`p`-by-:math:`p` Wishart distributed matrix :math:`X` is stored
   in :data:`result` on output.

.. function:: int gsl_ran_wishart_pdf (const gsl_matrix * X, const gsl_matrix * L_X, const double n, const gsl_matrix * L, double * result, gsl_matrix * work)
              int gsl_ran_wishart_log_pdf (const gsl_matrix * X, const gsl_matrix * L_X, const double n, const gsl_matrix * L, double * result, gsl_matrix * work)

   These functions compute :math:`p(X)` or :math:`\log{p(X)}` for the :math:`p`-by-:math:`p` matrix
   :data:`X`, whose Cholesky factor is specified in :data:`L_X`. The degrees of freedom is
   given by :data:`n`, the Cholesky factor of the scale matrix :math:`V` is specified in :data:`L`,
   and :data:`work` is :math:`p`-by-:math:`p` workspace. The probably density value is returned
   in :data:`result`.

|newpage|

Shuffling and Sampling
======================

The following functions allow the shuffling and sampling of a set of
objects.  The algorithms rely on a random number generator as a source of
randomness and a poor quality generator can lead to correlations in the
output.  In particular it is important to avoid generators with a short
period.  For more information see Knuth, v2, 3rd ed, Section 3.4.2,
"Random Sampling and Shuffling".

.. function:: void gsl_ran_shuffle (const gsl_rng * r, void * base, size_t n, size_t size)

   This function randomly shuffles the order of :data:`n` objects, each of
   size :data:`size`, stored in the array :code:`base[0..n-1]`.  The
   output of the random number generator :data:`r` is used to produce the
   permutation.  The algorithm generates all possible :math:`n!`
   permutations with equal probability, assuming a perfect source of random
   numbers.

   The following code shows how to shuffle the numbers from 0 to 51::

      int a[52];

      for (i = 0; i < 52; i++)
        {
          a[i] = i;
        }

      gsl_ran_shuffle (r, a, 52, sizeof (int));

.. function:: int gsl_ran_choose (const gsl_rng * r, void * dest, size_t k, void * src, size_t n, size_t size)

   This function fills the array :code:`dest[k]` with :data:`k` objects taken
   randomly from the :data:`n` elements of the array
   :code:`src[0..n-1]`.  The objects are each of size :data:`size`.  The
   output of the random number generator :data:`r` is used to make the
   selection.  The algorithm ensures all possible samples are equally
   likely, assuming a perfect source of randomness.

   The objects are sampled **without** replacement, thus each object can
   only appear once in :data:`dest`.  It is required that :data:`k` be less
   than or equal to :data:`n`.  The objects in :data:`dest` will be in the
   same relative order as those in :data:`src`.  You will need to call
   :code:`gsl_ran_shuffle(r, dest, n, size)` if you want to randomize the
   order.

   The following code shows how to select a random sample of three unique
   numbers from the set 0 to 99::

      double a[3], b[100];

      for (i = 0; i < 100; i++)
        {
          b[i] = (double) i;
        }

      gsl_ran_choose (r, a, 3, b, 100, sizeof (double));

.. function:: void gsl_ran_sample (const gsl_rng * r, void * dest, size_t k, void * src, size_t n, size_t size)

   This function is like :func:`gsl_ran_choose` but samples :data:`k` items
   from the original array of :data:`n` items :data:`src` with replacement, so
   the same object can appear more than once in the output sequence
   :data:`dest`.  There is no requirement that :data:`k` be less than :data:`n`
   in this case.

Examples
========

The following program demonstrates the use of a random number generator
to produce variates from a distribution.  It prints 10 samples from the
Poisson distribution with a mean of 3.

.. include:: examples/randpoisson.c
   :code:

If the library and header files are installed under :file:`/usr/local`
(the default location) then the program can be compiled with these
options::

  $ gcc -Wall demo.c -lgsl -lgslcblas -lm

Here is the output of the program,

.. include:: examples/randpoisson.txt
   :code:

The variates depend on the seed used by the generator.  The seed for the
default generator type :type:`gsl_rng_default` can be changed with the
:macro:`GSL_RNG_SEED` environment variable to produce a different stream
of variates::

  $ GSL_RNG_SEED=123 ./a.out

giving output

.. include:: examples/randpoisson2.txt
   :code:

The following program generates a random walk in two dimensions.

.. include:: examples/randwalk.c
   :code:

:numref:`fig_rand-walk` shows the output from the program.

.. _fig_rand-walk:

.. figure:: /images/random-walk.png
   :scale: 60%

   Four 10-step random walks from the origin.

The following program computes the upper and lower cumulative
distribution functions for the standard normal distribution at
:math:`x = 2`.

.. include:: examples/cdf.c
   :code:

Here is the output of the program,

.. include:: examples/cdf.txt
   :code:

References and Further Reading
==============================

For an encyclopaedic coverage of the subject readers are advised to
consult the book "Non-Uniform Random Variate Generation" by Luc
Devroye.  It covers every imaginable distribution and provides hundreds
of algorithms.

* Luc Devroye, "Non-Uniform Random Variate Generation",
  Springer-Verlag, ISBN 0-387-96305-7.  Available online at
  http://cg.scs.carleton.ca/~luc/rnbookindex.html.

The subject of random variate generation is also reviewed by Knuth, who
describes algorithms for all the major distributions.

* Donald E. Knuth, "The Art of Computer Programming: Seminumerical
  Algorithms" (Vol 2, 3rd Ed, 1997), Addison-Wesley, ISBN 0201896842.

The Particle Data Group provides a short review of techniques for
generating distributions of random numbers in the "Monte Carlo"
section of its Annual Review of Particle Physics.

* Review of Particle Properties,
  R.M. Barnett et al., Physical Review D54, 1 (1996)
  http://pdg.lbl.gov/.

The Review of Particle Physics is available online in postscript and pdf
format.

An overview of methods used to compute cumulative distribution functions
can be found in *Statistical Computing* by W.J. Kennedy and
J.E. Gentle. Another general reference is *Elements of Statistical
Computing* by R.A. Thisted.

* William E. Kennedy and James E. Gentle, Statistical Computing (1980),
  Marcel Dekker, ISBN 0-8247-6898-1.

* Ronald A. Thisted, Elements of Statistical Computing (1988), 
  Chapman & Hall, ISBN 0-412-01371-1.

The cumulative distribution functions for the Gaussian distribution
are based on the following papers,

* Rational Chebyshev Approximations Using Linear Equations,
  W.J. Cody, W. Fraser, J.F. Hart. Numerische Mathematik 12, 242--251 (1968).

* Rational Chebyshev Approximations for the Error Function,
  W.J. Cody. Mathematics of Computation 23, n107, 631--637 (July 1969).
.. index:: Dawson function

The Dawson integral is defined by

.. math:: \exp(-x^2) \int_0^x dt \exp(t^2)

A table of Dawson's integral can be found in Abramowitz &
Stegun, Table 7.5.  The Dawson functions are declared in the header file
:file:`gsl_sf_dawson.h`.

.. function:: double gsl_sf_dawson (double x)
              int gsl_sf_dawson_e (double x, gsl_sf_result * result)

   These routines compute the value of Dawson's integral for :data:`x`.
.. Exceptional Return Values: GSL_EUNDRFLW
.. index::
   single: discrete Hankel transforms
   single: Hankel transforms, discrete
   single: transforms, Hankel

**************************
Discrete Hankel Transforms
**************************

This chapter describes functions for performing Discrete Hankel
Transforms (DHTs). The functions are declared in the header file
:file:`gsl_dht.h`.

Definitions
===========

The discrete Hankel transform acts on a vector of sampled data, where
the samples are assumed to have been taken at points related to the
zeros of a Bessel function of fixed order; compare this to the case of
the discrete Fourier transform, where samples are taken at points
related to the zeroes of the sine or cosine function.

Starting with its definition, the Hankel transform (or Bessel transform) of
order :math:`\nu` of a function :math:`f` with :math:`\nu > -1/2` is defined as
(see Johnson, 1987 and Lemoine, 1994)

.. math:: F_\nu(u) = \int_0^\infty f(t) J_\nu(u t) t dt

If the integral exists, :math:`F_\nu` is called the Hankel transformation
of :math:`f`. The reverse transform is given by

.. math:: f(t) = \int_0^\infty F_\nu(u) J_\nu(u t) u du

where :math:`\int_0^\infty f(t) t^{1/2} dt` must exist and be
absolutely convergent, and where :math:`f(t)` satisfies Dirichlet's
conditions (of limited total fluctuations) in the interval
:math:`[0,\infty]`.

Now the discrete Hankel transform works on a discrete function
:math:`f`, which is sampled on points :math:`n=1...M` located at
positions :math:`t_n=(j_{\nu,n}/j_{\nu,M}) X` in real space and
at :math:`u_n=j_{\nu,n}/X` in reciprocal space. Here,
:math:`j_{\nu,m}` are the m-th zeros of the Bessel function
:math:`J_\nu(x)` arranged in ascending order. Moreover, the
discrete functions are assumed to be band limited, so
:math:`f(t_n)=0` and :math:`F(u_n)=0` for :math:`n>M`. Accordingly,
the function :math:`f` is defined on the interval :math:`[0,X]`.

Following the work of Johnson, 1987 and
Lemoine, 1994, the discrete Hankel transform is given by

.. only:: not texinfo

   .. math::

      F_\nu(u_m) = {{2 X^2}\over{j_{\nu,M}^2}}
            \sum_{k=1}^{M-1} f\left({{j_{\nu,k} X}\over{j_{\nu,M}}}\right)
                {{J_\nu(j_{\nu,m} j_{\nu,k} / j_{\nu,M})}\over{J_{\nu+1}(j_{\nu,k})^2}}.

.. only:: texinfo

   ::

      F_\nu(u_m) = (2 X^2 / j_(\nu,M)^2)
            \sum_{k=1}^{M-1} f(j_(\nu,k) X/j_(\nu,M))
                (J_\nu(j_(\nu,m) j_(\nu,k) / j_(\nu,M)) / J_(\nu+1)(j_(\nu,k))^2).

It is this discrete expression which defines the discrete Hankel
transform calculated by GSL. In GSL, forward and backward transforms
are defined equally and calculate :math:`F_\nu(u_m)`.
Following Johnson, the backward transform reads

.. only:: not texinfo

   .. math::

      f(t_k) = {{2}\over{X^2}}
            \sum_{m=1}^{M-1} F\left({{j_{\nu,m}}\over{X}}\right)
                {{J_\nu(j_{\nu,m} j_{\nu,k} / j_{\nu,M})}\over{J_{\nu+1}(j_{\nu,m})^2}}.

.. only:: texinfo

   ::

      f(t_k) = (2 / X^2)
            \sum_{m=1}^{M-1} F(j_(\nu,m)/X)
                (J_\nu(j_(\nu,m) j_(\nu,k) / j_(\nu,M)) / J_(\nu+1)(j_(\nu,m))^2).

Obviously, using the forward transform instead of the backward transform gives an
additional factor :math:`X^4/j_{\nu,M}^2=t_m^2/u_m^2`.

The kernel in the summation above defines the matrix of the
:math:`\nu`-Hankel transform of size :math:`M-1`. The coefficients of
this matrix, being dependent on :math:`\nu` and :math:`M`, must be
precomputed and stored; the :type:`gsl_dht` object encapsulates this
data. The allocation function :func:`gsl_dht_alloc` returns a
:type:`gsl_dht` object which must be properly initialized with
:func:`gsl_dht_init` before it can be used to perform transforms on data
sample vectors, for fixed :math:`\nu` and :math:`M`, using the
:func:`gsl_dht_apply` function. The implementation allows to define the
length :math:`X` of the fundamental interval, for convenience, while
discrete Hankel transforms are often defined on the unit interval
instead of :math:`[0,X]`.

Notice that by assumption :math:`f(t)` vanishes at the endpoints
of the interval, consistent with the inversion formula
and the sampling formula given above. Therefore, this transform
corresponds to an orthogonal expansion in eigenfunctions
of the Dirichlet problem for the Bessel differential equation.

Functions
=========

.. type:: gsl_dht

   Workspace for computing discrete Hankel transforms

.. function:: gsl_dht * gsl_dht_alloc (size_t size)

   This function allocates a Discrete Hankel transform object of size
   :data:`size`.

.. function:: int gsl_dht_init (gsl_dht * t, double nu, double xmax)

   This function initializes the transform :data:`t` for the given values of
   :data:`nu` and :data:`xmax`.

.. function:: gsl_dht * gsl_dht_new (size_t size, double nu, double xmax)

   This function allocates a Discrete Hankel transform object of size
   :data:`size` and initializes it for the given values of :data:`nu` and
   :data:`xmax`.

.. function:: void gsl_dht_free (gsl_dht * t)

   This function frees the transform :data:`t`.

.. function:: int gsl_dht_apply (const gsl_dht * t, double * f_in, double * f_out)

   This function applies the transform :data:`t` to the array :data:`f_in`
   whose size is equal to the size of the transform.  The result is stored
   in the array :data:`f_out` which must be of the same length.   

   Applying this function to its output gives the original data
   multiplied by :math:`(X^2/j_{\nu,M})^2`,
   up to numerical errors.

.. function:: double gsl_dht_x_sample (const gsl_dht * t, int n)

   This function returns the value of the :data:`n`-th sample point in the unit interval,
   :math:`{({j_{\nu,n+1}} / {j_{\nu,M}}}) X`.
   These are the points where the function :math:`f(t)` is assumed to be sampled.

.. function:: double gsl_dht_k_sample (const gsl_dht * t, int n)

   This function returns the value of the :data:`n`-th sample point in "k-space",
   :math:`{{j_{\nu,n+1}} / X}`.

References and Further Reading
==============================

The algorithms used by these functions are described in the following papers,

* H. Fisk Johnson, Comp.: Phys.: Comm.: 43, 181 (1987).

* D. Lemoine, J. Chem.: Phys.: 101, 3936 (1994).
********************
Vectors and Matrices
********************

.. include:: include.rst

The functions described in this chapter provide a simple vector and
matrix interface to ordinary C arrays. The memory management of these
arrays is implemented using a single underlying type, known as a
block. By writing your functions in terms of vectors and matrices you
can pass a single structure containing both data and dimensions as an
argument without needing additional function parameters.  The structures
are compatible with the vector and matrix formats used by BLAS
routines.

Data types
==========

All the functions are available for each of the standard data-types.
The versions for :code:`double` have the prefix :code:`gsl_block`,
:code:`gsl_vector` and :code:`gsl_matrix`.  Similarly the versions for
single-precision :code:`float` arrays have the prefix
:code:`gsl_block_float`, :code:`gsl_vector_float` and
:code:`gsl_matrix_float`.  The full list of available types is given
below,

=============================== ====================
Prefix                          Type
=============================== ====================
gsl_block                       double         
gsl_block_float                 float         
gsl_block_long_double           long double   
gsl_block_int                   int           
gsl_block_uint                  unsigned int  
gsl_block_long                  long          
gsl_block_ulong                 unsigned long 
gsl_block_short                 short         
gsl_block_ushort                unsigned short
gsl_block_char                  char          
gsl_block_uchar                 unsigned char 
gsl_block_complex               complex double        
gsl_block_complex_float         complex float         
gsl_block_complex_long_double   complex long double   
=============================== ====================

Corresponding types exist for the :code:`gsl_vector` and
:code:`gsl_matrix` functions.

.. index:: blocks

Blocks
======

For consistency all memory is allocated through a :code:`gsl_block`
structure.  The structure contains two components, the size of an area of
memory and a pointer to the memory.  The :code:`gsl_block` structure looks
like this,

.. type:: gsl_block

   ::
   
      typedef struct
      {
        size_t size;
        double * data;
      } gsl_block;

Vectors and matrices are made by *slicing* an underlying block. A
slice is a set of elements formed from an initial offset and a
combination of indices and step-sizes. In the case of a matrix the
step-size for the column index represents the row-length.  The step-size
for a vector is known as the *stride*.

The functions for allocating and deallocating blocks are defined in
:file:`gsl_block.h`.

Block allocation
----------------

The functions for allocating memory to a block follow the style of
:code:`malloc` and :code:`free`.  In addition they also perform their own
error checking.  If there is insufficient memory available to allocate a
block then the functions call the GSL error handler (with an error
number of :macro:`GSL_ENOMEM`) in addition to returning a null
pointer.  Thus if you use the library error handler to abort your program
then it isn't necessary to check every :code:`alloc`.  

.. function:: gsl_block * gsl_block_alloc (size_t n)

   This function allocates memory for a block of :data:`n` double-precision
   elements, returning a pointer to the block struct.  The block is not
   initialized and so the values of its elements are undefined.  Use the
   function :func:`gsl_block_calloc` if you want to ensure that all the
   elements are initialized to zero.

   Zero-sized requests are valid and return a non-null result.  A null pointer
   is returned if insufficient memory is available to create the block.

.. function:: gsl_block * gsl_block_calloc (size_t n)

   This function allocates memory for a block and initializes all the
   elements of the block to zero.

.. function:: void gsl_block_free (gsl_block * b)

   This function frees the memory used by a block :data:`b` previously
   allocated with :func:`gsl_block_alloc` or :func:`gsl_block_calloc`.

Reading and writing blocks
--------------------------

The library provides functions for reading and writing blocks to a file
as binary data or formatted text.

.. function:: int gsl_block_fwrite (FILE * stream, const gsl_block * b)

   This function writes the elements of the block :data:`b` to the stream
   :data:`stream` in binary format.  The return value is 0 for success and
   :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since the
   data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_block_fread (FILE * stream, gsl_block * b)

   This function reads into the block :data:`b` from the open stream
   :data:`stream` in binary format.  The block :data:`b` must be preallocated
   with the correct length since the function uses the size of :data:`b` to
   determine how many bytes to read.  The return value is 0 for success and
   :macro:`GSL_EFAILED` if there was a problem reading from the file.  The
   data is assumed to have been written in the native binary format on the
   same architecture.

.. function:: int gsl_block_fprintf (FILE * stream, const gsl_block * b, const char * format)

   This function writes the elements of the block :data:`b` line-by-line to
   the stream :data:`stream` using the format specifier :data:`format`, which
   should be one of the :code:`%g`, :code:`%e` or :code:`%f` formats for
   floating point numbers and :code:`%d` for integers.  The function returns
   0 for success and :macro:`GSL_EFAILED` if there was a problem writing to
   the file.

.. function:: int gsl_block_fscanf (FILE * stream, gsl_block * b)

   This function reads formatted data from the stream :data:`stream` into the
   block :data:`b`.  The block :data:`b` must be preallocated with the correct
   length since the function uses the size of :data:`b` to determine how many
   numbers to read.  The function returns 0 for success and
   :macro:`GSL_EFAILED` if there was a problem reading from the file.

Example programs for blocks
---------------------------

The following program shows how to allocate a block,

.. include:: examples/block.c
   :code:

Here is the output from the program,

.. include:: examples/block.txt
   :code:

.. index::
   single: vectors
   single: stride, of vector index

Vectors
=======

Vectors are defined by a :type:`gsl_vector` structure which describes a
slice of a block.  Different vectors can be created which point to the
same block.  A vector slice is a set of equally-spaced elements of an
area of memory.

The :type:`gsl_vector` structure contains five components, the
*size*, the *stride*, a pointer to the memory where the elements
are stored, :data:`data`, a pointer to the block owned by the vector,
:data:`block`, if any, and an ownership flag, :data:`owner`.  The structure
is very simple and looks like this,

.. type:: gsl_vector

   ::

      typedef struct
      {
        size_t size;
        size_t stride;
        double * data;
        gsl_block * block;
        int owner;
      } gsl_vector;

The :data:`size` is simply the number of vector elements.  The range of
valid indices runs from 0 to :code:`size-1`.  The :data:`stride` is the
step-size from one element to the next in physical memory, measured in
units of the appropriate datatype.  The pointer :data:`data` gives the
location of the first element of the vector in memory.  The pointer
:data:`block` stores the location of the memory block in which the vector
elements are located (if any).  If the vector owns this block then the
:data:`owner` field is set to one and the block will be deallocated when the
vector is freed.  If the vector points to a block owned by another
object then the :data:`owner` field is zero and any underlying block will not be
deallocated with the vector.

The functions for allocating and accessing vectors are defined in
:file:`gsl_vector.h`.

Vector allocation
-----------------

The functions for allocating memory to a vector follow the style of
:code:`malloc` and :code:`free`.  In addition they also perform their own
error checking.  If there is insufficient memory available to allocate a
vector then the functions call the GSL error handler (with an error
number of :macro:`GSL_ENOMEM`) in addition to returning a null
pointer.  Thus if you use the library error handler to abort your program
then it isn't necessary to check every :code:`alloc`.

.. function:: gsl_vector * gsl_vector_alloc (size_t n)

   This function creates a vector of length n, returning a pointer to
   a newly initialized vector struct. A new block is allocated for the
   elements of the vector, and stored in the :data:`block` component of the
   vector struct.  The block is "owned" by the vector, and will be
   deallocated when the vector is deallocated.
   Zero-sized requests are valid and return a non-null result.

.. function:: gsl_vector * gsl_vector_calloc (size_t n)

   This function allocates memory for a vector of length :data:`n` and
   initializes all the elements of the vector to zero.

.. function:: void gsl_vector_free (gsl_vector * v)

   This function frees a previously allocated vector :data:`v`.  If the
   vector was created using :func:`gsl_vector_alloc` then the block
   underlying the vector will also be deallocated.  If the vector has
   been created from another object then the memory is still owned by
   that object and will not be deallocated.

.. index::
   single: vectors, range-checking
   single: range-checking for vectors
   single: bounds checking, extension to GCC
   single: gcc extensions, range-checking
   single: Fortran range checking, equivalent in gcc

Accessing vector elements
-------------------------

Unlike Fortran compilers, C compilers do not usually provide
support for range checking of vectors and matrices. [#f1]_
The functions :func:`gsl_vector_get` and
:func:`gsl_vector_set` can perform portable range checking for you and
report an error if you attempt to access elements outside the allowed
range.

The functions for accessing the elements of a vector or matrix are
defined in :file:`gsl_vector.h` and declared :code:`extern inline` to
eliminate function-call overhead.  You must compile your program with
the preprocessor macro :macro:`HAVE_INLINE` defined to use these
functions.

.. macro:: GSL_RANGE_CHECK_OFF

   If necessary you can turn off range checking completely without
   modifying any source files by recompiling your program with the
   preprocessor definition :macro:`GSL_RANGE_CHECK_OFF`.  Provided your
   compiler supports inline functions the effect of turning off range
   checking is to replace calls to :code:`gsl_vector_get(v,i)` by
   :code:`v->data[i*v->stride]` and calls to :code:`gsl_vector_set(v,i,x)` by
   :code:`v->data[i*v->stride]=x`.  Thus there should be no performance
   penalty for using the range checking functions when range checking is
   turned off.

.. macro:: GSL_C99_INLINE

   If you use a C99 compiler which requires inline functions in header
   files to be declared :code:`inline` instead of :code:`extern inline`,
   define the macro :macro:`GSL_C99_INLINE` (see :ref:`sec_inline-functions`).
   With GCC this is selected automatically when compiling in C99 mode
   (:code:`-std=c99`).

.. var:: gsl_check_range

   If inline functions are not used, calls to the functions
   :func:`gsl_vector_get` and :func:`gsl_vector_set` will link to the
   compiled versions of these functions in the library itself.  The range
   checking in these functions is controlled by the global integer
   variable :code:`gsl_check_range`.  It is enabled by default---to
   disable it, set :code:`gsl_check_range` to zero.  Due to function-call
   overhead, there is less benefit in disabling range checking here than
   for inline functions.

.. function:: double gsl_vector_get (const gsl_vector * v, const size_t i)

   This function returns the :data:`i`-th element of a vector :data:`v`.  If
   :data:`i` lies outside the allowed range of 0 to :code:`size - 1` then the error
   handler is invoked and 0 is returned. |inlinefn|

.. function:: void gsl_vector_set (gsl_vector * v, const size_t i, double x)

   This function sets the value of the :data:`i`-th element of a vector
   :data:`v` to :data:`x`.  If :data:`i` lies outside the allowed range of 0 to
   :code:`size - 1` then the error handler is invoked. |inlinefn|

.. function:: double * gsl_vector_ptr (gsl_vector * v, size_t i)
              const double * gsl_vector_const_ptr (const gsl_vector * v, size_t i)

   These functions return a pointer to the :data:`i`-th element of a vector
   :data:`v`.  If :data:`i` lies outside the allowed range of 0 to :code:`size - 1`
   then the error handler is invoked and a null pointer is returned. |inlinefns|

.. index::
   single: vectors, initializing
   single: initializing vectors

Initializing vector elements
----------------------------

.. function:: void gsl_vector_set_all (gsl_vector * v, double x)

   This function sets all the elements of the vector :data:`v` to the value
   :data:`x`.

.. function:: void gsl_vector_set_zero (gsl_vector * v)

   This function sets all the elements of the vector :data:`v` to zero.

.. function:: int gsl_vector_set_basis (gsl_vector * v, size_t i)

   This function makes a basis vector by setting all the elements of the
   vector :data:`v` to zero except for the :data:`i`-th element which is set to
   one.

Reading and writing vectors
---------------------------

The library provides functions for reading and writing vectors to a file
as binary data or formatted text.

.. function:: int gsl_vector_fwrite (FILE * stream, const gsl_vector * v)

   This function writes the elements of the vector :data:`v` to the stream
   :data:`stream` in binary format.  The return value is 0 for success and
   :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since the
   data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_vector_fread (FILE * stream, gsl_vector * v)

   This function reads into the vector :data:`v` from the open stream
   :data:`stream` in binary format.  The vector :data:`v` must be preallocated
   with the correct length since the function uses the size of :data:`v` to
   determine how many bytes to read.  The return value is 0 for success and
   :macro:`GSL_EFAILED` if there was a problem reading from the file.  The
   data is assumed to have been written in the native binary format on the
   same architecture.

.. function:: int gsl_vector_fprintf (FILE * stream, const gsl_vector * v, const char * format)

   This function writes the elements of the vector :data:`v` line-by-line to
   the stream :data:`stream` using the format specifier :data:`format`, which
   should be one of the :code:`%g`, :code:`%e` or :code:`%f` formats for
   floating point numbers and :code:`%d` for integers.  The function returns
   0 for success and :macro:`GSL_EFAILED` if there was a problem writing to
   the file.

.. function:: int gsl_vector_fscanf (FILE * stream, gsl_vector * v)

   This function reads formatted data from the stream :data:`stream` into the
   vector :data:`v`.  The vector :data:`v` must be preallocated with the correct
   length since the function uses the size of :data:`v` to determine how many
   numbers to read.  The function returns 0 for success and
   :macro:`GSL_EFAILED` if there was a problem reading from the file.

Vector views
------------

In addition to creating vectors from slices of blocks it is also
possible to slice vectors and create vector views.  For example, a
subvector of another vector can be described with a view, or two views
can be made which provide access to the even and odd elements of a
vector.

.. type:: gsl_vector_view
          gsl_vector_const_view

   A vector view is a temporary object, stored on the stack, which can be
   used to operate on a subset of vector elements.  Vector views can be
   defined for both constant and non-constant vectors, using separate types
   that preserve constness.  A vector view has the type
   :type:`gsl_vector_view` and a constant vector view has the type
   :type:`gsl_vector_const_view`.  In both cases the elements of the view
   can be accessed as a :type:`gsl_vector` using the :code:`vector` component
   of the view object.  A pointer to a vector of type :code:`gsl_vector *`
   or :code:`const gsl_vector *` can be obtained by taking the address of
   this component with the :code:`&` operator.  

   When using this pointer it is important to ensure that the view itself
   remains in scope---the simplest way to do so is by always writing the
   pointer as :code:`&view.vector`, and never storing this value
   in another variable.  

.. function:: gsl_vector_view gsl_vector_subvector (gsl_vector * v, size_t offset, size_t n)
              gsl_vector_const_view gsl_vector_const_subvector (const gsl_vector * v, size_t offset, size_t n)

   These functions return a vector view of a subvector of another vector
   :data:`v`.  The start of the new vector is offset by :data:`offset` elements
   from the start of the original vector.  The new vector has :data:`n`
   elements.  Mathematically, the :data:`i`-th element of the new vector
   :data:`v'` is given by::

      v'(i) = v->data[(offset + i)*v->stride]

   where the index :data:`i` runs from 0 to :code:`n - 1`.

   The :code:`data` pointer of the returned vector struct is set to null if
   the combined parameters (:data:`offset`, :data:`n`) overrun the end of the
   original vector.

   The new vector is only a view of the block underlying the original
   vector, :data:`v`.  The block containing the elements of :data:`v` is not
   owned by the new vector.  When the view goes out of scope the original
   vector :data:`v` and its block will continue to exist.  The original
   memory can only be deallocated by freeing the original vector.  Of
   course, the original vector should not be deallocated while the view is
   still in use.

   The function :func:`gsl_vector_const_subvector` is equivalent to
   :func:`gsl_vector_subvector` but can be used for vectors which are
   declared :code:`const`.

.. function:: gsl_vector_view gsl_vector_subvector_with_stride (gsl_vector * v, size_t offset, size_t stride, size_t n)
              gsl_vector_const_view gsl_vector_const_subvector_with_stride (const gsl_vector * v, size_t offset, size_t stride, size_t n)

   These functions return a vector view of a subvector of another vector
   :data:`v` with an additional stride argument. The subvector is formed in
   the same way as for :func:`gsl_vector_subvector` but the new vector has
   :data:`n` elements with a step-size of :data:`stride` from one element to
   the next in the original vector.  Mathematically, the :data:`i`-th element
   of the new vector :data:`v'` is given by::

      v'(i) = v->data[(offset + i*stride)*v->stride]

   where the index :data:`i` runs from 0 to :code:`n - 1`.

   Note that subvector views give direct access to the underlying elements
   of the original vector. For example, the following code will zero the
   even elements of the vector :data:`v` of length :code:`n`, while leaving the
   odd elements untouched::

      gsl_vector_view v_even = gsl_vector_subvector_with_stride (v, 0, 2, n/2);
      gsl_vector_set_zero (&v_even.vector);

   A vector view can be passed to any subroutine which takes a vector
   argument just as a directly allocated vector would be, using
   :code:`&view.vector`.  For example, the following code
   computes the norm of the odd elements of :data:`v` using the BLAS
   routine :code:`dnrm2`::

      gsl_vector_view v_odd = gsl_vector_subvector_with_stride (v, 1, 2, n/2);
      double r = gsl_blas_dnrm2 (&v_odd.vector);

   The function :func:`gsl_vector_const_subvector_with_stride` is equivalent
   to :func:`gsl_vector_subvector_with_stride` but can be used for vectors
   which are declared :code:`const`.

.. function:: gsl_vector_view gsl_vector_complex_real (gsl_vector_complex * v)
              gsl_vector_const_view gsl_vector_complex_const_real (const gsl_vector_complex * v)

   These functions return a vector view of the real parts of the complex
   vector :data:`v`.

   The function :func:`gsl_vector_complex_const_real` is equivalent to
   :func:`gsl_vector_complex_real` but can be used for vectors which are
   declared :code:`const`.

.. function:: gsl_vector_view gsl_vector_complex_imag (gsl_vector_complex * v)
              gsl_vector_const_view gsl_vector_complex_const_imag (const gsl_vector_complex * v)

   These functions return a vector view of the imaginary parts of the
   complex vector :data:`v`.

   The function :func:`gsl_vector_complex_const_imag` is equivalent to
   :func:`gsl_vector_complex_imag` but can be used for vectors which are
   declared :code:`const`.

.. function:: gsl_vector_view gsl_vector_view_array (double * base, size_t n) 
              gsl_vector_const_view gsl_vector_const_view_array (const double * base, size_t n)

   These functions return a vector view of an array.  The start of the new
   vector is given by :data:`base` and has :data:`n` elements.  Mathematically,
   the :data:`i`-th element of the new vector :data:`v'` is given by::

      v'(i) = base[i]

   where the index :data:`i` runs from 0 to :code:`n - 1`.

   The array containing the elements of :data:`v` is not owned by the new
   vector view.  When the view goes out of scope the original array will
   continue to exist.  The original memory can only be deallocated by
   freeing the original pointer :data:`base`.  Of course, the original array
   should not be deallocated while the view is still in use.

   The function :func:`gsl_vector_const_view_array` is equivalent to
   :func:`gsl_vector_view_array` but can be used for arrays which are
   declared :code:`const`.

.. function:: gsl_vector_view gsl_vector_view_array_with_stride (double * base, size_t stride, size_t n)
              gsl_vector_const_view gsl_vector_const_view_array_with_stride (const double * base, size_t stride, size_t n)

   These functions return a vector view of an array :data:`base` with an
   additional stride argument. The subvector is formed in the same way as
   for :func:`gsl_vector_view_array` but the new vector has :data:`n` elements
   with a step-size of :data:`stride` from one element to the next in the
   original array.  Mathematically, the :data:`i`-th element of the new
   vector :data:`v'` is given by::

      v'(i) = base[i*stride]

   where the index :data:`i` runs from 0 to :code:`n - 1`.

   Note that the view gives direct access to the underlying elements of the
   original array.  A vector view can be passed to any subroutine which
   takes a vector argument just as a directly allocated vector would be,
   using :code:`&view.vector`.

   The function :func:`gsl_vector_const_view_array_with_stride` is
   equivalent to :func:`gsl_vector_view_array_with_stride` but can be used
   for arrays which are declared :code:`const`.

.. @node Modifying subvector views
.. @subsection Modifying subvector views
.. 
.. @deftypefun int gsl_vector_view_from_vector (gsl_vector * v, gsl_vector * base, size_t offset, size_t n, size_t stride)
.. This function modifies and existing vector view :data:`v` to form a new
.. view of a vector :data:`base`, starting from element :data:`offset`.  The
.. vector has :data:`n` elements separated by stride :data:`stride`.  Any
.. existing view in :data:`v` will be lost as a result of this function.
.. @end deftypefun
.. 
.. @deftypefun int gsl_vector_view_from_array (gsl_vector * v, double * base, size_t offset, size_t n, size_t stride)
.. This function modifies and existing vector view :data:`v` to form a new
.. view of an array :data:`base`, starting from element :data:`offset`.  The
.. vector has :data:`n` elements separated by stride :data:`stride`.  Any
.. existing view in :data:`v` will be lost as a result of this function.
.. @end deftypefun

.. @deftypefun {gsl_vector *} gsl_vector_alloc_from_block (gsl_block * b, size_t offset, size_t n, size_t stride)
.. This function creates a vector as a slice of an existing block :data:`b`,
.. returning a pointer to a newly initialized vector struct.  The start of
.. the vector is offset by :data:`offset` elements from the start of the
.. block.  The vector has :data:`n` elements, with a step-size of :data:`stride`
.. from one element to the next.  Mathematically, the :data:`i`-th element of
.. the vector is given by,
.. 
.. @example
.. v(i) = b->data[offset + i*stride]
.. @end example
.. @noindent
.. where the index :data:`i` runs from 0 to :code:`n-1`.
.. 
.. A null pointer is returned if the combined parameters
.. (:data:`offset`, :data:`n`, :data:`stride`) overrun the end of the block or if
.. insufficient memory is available to store the vector.
.. 
.. The vector is only a view of the block :data:`b`, and the block is not
.. owned by the vector.  When the vector is deallocated the block :data:`b`
.. will continue to exist.  This memory can only be deallocated by freeing
.. the block itself.  Of course, this block should not be deallocated while
.. the vector is still in use.
.. @end deftypefun
.. 
.. @deftypefun {gsl_vector *} gsl_vector_alloc_from_vector (gsl_vector * :data:`v`, size_t offset, size_t n, size_t stride)
.. This function creates a vector as a slice of another vector :data:`v`,
.. returning a pointer to a newly initialized vector struct.  The start of
.. the new vector is offset by :data:`offset` elements from the start of the
.. original vector.  The new vector has :data:`n` elements, with a step-size
.. of :data:`stride` from one element to the next in the original vector.
.. Mathematically, the :data:`i`-th element of the new vector :data:`v'` is
.. given by,
.. 
.. @example
.. v'(i) = v->data[(offset + i*stride)*v->stride]
.. @end example
.. @noindent
.. where the index :data:`i` runs from 0 to :code:`n-1`.
.. 
.. A null pointer is returned if the combined parameters
.. (:data:`offset`, :data:`n`, :data:`stride`) overrun the end of the original
.. vector or if insufficient memory is available store the new vector.
.. 
.. The new vector is only a view of the block underlying the original
.. vector, :data:`v`.  The block is not owned by the new vector.  When the new
.. vector is deallocated the original vector :data:`v` and its block will
.. continue to exist.  The original memory can only be deallocated by
.. freeing the original vector.  Of course, the original vector should not
.. be deallocated while the new vector is still in use.
.. @end deftypefun

Copying vectors
---------------

Common operations on vectors such as addition and multiplication are
available in the BLAS part of the library (see :ref:`chap_blas-support`).
However, it is useful to have a small number of utility
functions which do not require the full BLAS code.  The following
functions fall into this category.

.. function:: int gsl_vector_memcpy (gsl_vector * dest, const gsl_vector * src)

   This function copies the elements of the vector :data:`src` into the
   vector :data:`dest`.  The two vectors must have the same length.

.. function:: int gsl_vector_swap (gsl_vector * v, gsl_vector * w)

   This function exchanges the elements of the vectors :data:`v` and :data:`w`
   by copying.  The two vectors must have the same length.

Exchanging elements
-------------------

The following functions can be used to exchange, or permute, the elements
of a vector.

.. function:: int gsl_vector_swap_elements (gsl_vector * v, size_t i, size_t j)

   This function exchanges the :data:`i`-th and :data:`j`-th elements of the
   vector :data:`v` in-place.

.. function:: int gsl_vector_reverse (gsl_vector * v)

   This function reverses the order of the elements of the vector :data:`v`.

Vector operations
-----------------

.. function:: int gsl_vector_add (gsl_vector * a, const gsl_vector * b)

   This function adds the elements of vector :data:`b` to the elements of
   vector :data:`a`.  The result :math:`a_i \leftarrow a_i + b_i` is stored
   in :data:`a` and :data:`b` remains unchanged.  The two vectors must have
   the same length.

.. function:: int gsl_vector_sub (gsl_vector * a, const gsl_vector * b)

   This function subtracts the elements of vector :data:`b` from the elements of
   vector :data:`a`.  The result :math:`a_i \leftarrow a_i - b_i` is stored
   in :data:`a` and :data:`b` remains unchanged.  The two vectors must have the
   same length.

.. function:: int gsl_vector_mul (gsl_vector * a, const gsl_vector * b)

   This function multiplies the elements of vector :data:`a` by the
   elements of vector :data:`b`.  The result :math:`a_i \leftarrow a_i * b_i`
   is stored in :data:`a` and :data:`b` remains unchanged. The two
   vectors must have the same length.

.. function:: int gsl_vector_div (gsl_vector * a, const gsl_vector * b)

   This function divides the elements of vector :data:`a` by the elements
   of vector :data:`b`.  The result :math:`a_i \leftarrow a_i / b_i` is
   stored in :data:`a` and :data:`b` remains unchanged. The two vectors must
   have the same length.

.. function:: int gsl_vector_scale (gsl_vector * a, const double x)

   This function multiplies the elements of vector :data:`a` by the
   constant factor :data:`x`.  The result :math:`a_i \leftarrow x a_i` is
   stored in :data:`a`.

.. function:: int gsl_vector_add_constant (gsl_vector * a, const double x)

   This function adds the constant value :data:`x` to the elements of the
   vector :data:`a`.  The result :math:`a_i \leftarrow a_i + x` is stored in
   :data:`a`.

Finding maximum and minimum elements of vectors
-----------------------------------------------

The following operations are only defined for real vectors.

.. function:: double gsl_vector_max (const gsl_vector * v)

   This function returns the maximum value in the vector :data:`v`.

.. function:: double gsl_vector_min (const gsl_vector * v)

   This function returns the minimum value in the vector :data:`v`.

.. function:: void gsl_vector_minmax (const gsl_vector * v, double * min_out, double * max_out)

   This function returns the minimum and maximum values in the vector
   :data:`v`, storing them in :data:`min_out` and :data:`max_out`.

.. function:: size_t gsl_vector_max_index (const gsl_vector * v)

   This function returns the index of the maximum value in the vector :data:`v`.
   When there are several equal maximum elements then the lowest index is
   returned.

.. function:: size_t gsl_vector_min_index (const gsl_vector * v)

   This function returns the index of the minimum value in the vector :data:`v`.
   When there are several equal minimum elements then the lowest index is
   returned.

.. function:: void gsl_vector_minmax_index (const gsl_vector * v, size_t * imin, size_t * imax)

   This function returns the indices of the minimum and maximum values in
   the vector :data:`v`, storing them in :data:`imin` and :data:`imax`. When
   there are several equal minimum or maximum elements then the lowest
   indices are returned.

Vector properties
-----------------

The following functions are defined for real and complex vectors.  For
complex vectors both the real and imaginary parts must satisfy the
conditions.

.. function:: int gsl_vector_isnull (const gsl_vector * v)
              int gsl_vector_ispos (const gsl_vector * v)
              int gsl_vector_isneg (const gsl_vector * v)
              int gsl_vector_isnonneg (const gsl_vector * v)

   These functions return 1 if all the elements of the vector :data:`v` are
   zero, strictly positive, strictly negative, or non-negative
   respectively, and 0 otherwise.

.. function:: int gsl_vector_equal (const gsl_vector * u, const gsl_vector * v)

   This function returns 1 if the vectors :data:`u` and :data:`v` are equal
   (by comparison of element values) and 0 otherwise.

Example programs for vectors
----------------------------

This program shows how to allocate, initialize and read from a vector
using the functions :func:`gsl_vector_alloc`, :func:`gsl_vector_set` and
:func:`gsl_vector_get`.

.. include:: examples/vector.c
   :code:

Here is the output from the program.  The final loop attempts to read
outside the range of the vector :code:`v`, and the error is trapped by
the range-checking code in :func:`gsl_vector_get`.

::

  $ ./a.out
  v_0 = 1.23
  v_1 = 2.23
  v_2 = 3.23
  gsl: vector_source.c:12: ERROR: index out of range
  Default GSL error handler invoked.
  Aborted (core dumped)

The next program shows how to write a vector to a file.

.. include:: examples/vectorw.c
   :code:

After running this program the file :file:`test.dat` should contain the
elements of :code:`v`, written using the format specifier
:code:`%.5g`.  The vector could then be read back in using the function
:code:`gsl_vector_fscanf (f, v)` as follows:

.. include:: examples/vectorr.c
   :code:

.. index::
   single: matrices
   single: physical dimension, matrices
   single: trailing dimension, matrices
   single: leading dimension, matrices
   single: ordering, matrix elements

Matrices
========

Matrices are defined by a :type:`gsl_matrix` structure which describes a
generalized slice of a block.  Like a vector it represents a set of
elements in an area of memory, but uses two indices instead of one.

.. type:: gsl_matrix

   The :type:`gsl_matrix` structure contains six components, the two
   dimensions of the matrix, a physical dimension, a pointer to the memory
   where the elements of the matrix are stored, :data:`data`, a pointer to
   the block owned by the matrix :data:`block`, if any, and an ownership
   flag, :data:`owner`.  The physical dimension determines the memory layout
   and can differ from the matrix dimension to allow the use of
   submatrices.  The :type:`gsl_matrix` structure is very simple and looks
   like this::

      typedef struct
      {
        size_t size1;
        size_t size2;
        size_t tda;
        double * data;
        gsl_block * block;
        int owner;
      } gsl_matrix;

Matrices are stored in row-major order, meaning that each row of
elements forms a contiguous block in memory.  This is the standard
"C-language ordering" of two-dimensional arrays. Note that Fortran
stores arrays in column-major order. The number of rows is :data:`size1`.
The range of valid row indices runs from 0 to :code:`size1 - 1`.  Similarly
:data:`size2` is the number of columns.  The range of valid column indices
runs from 0 to :code:`size2 - 1`.  The physical row dimension :data:`tda`, or
*trailing dimension*, specifies the size of a row of the matrix as
laid out in memory.

For example, in the following matrix :data:`size1` is 3, :data:`size2` is 4,
and :data:`tda` is 8.  The physical memory layout of the matrix begins in
the top left hand-corner and proceeds from left to right along each row
in turn.

::

   00 01 02 03 XX XX XX XX
   10 11 12 13 XX XX XX XX
   20 21 22 23 XX XX XX XX

Each unused memory location is represented by ":code:`XX`".  The
pointer :data:`data` gives the location of the first element of the matrix
in memory.  The pointer :data:`block` stores the location of the memory
block in which the elements of the matrix are located (if any).  If the
matrix owns this block then the :data:`owner` field is set to one and the
block will be deallocated when the matrix is freed.  If the matrix is
only a slice of a block owned by another object then the :data:`owner` field is
zero and any underlying block will not be freed.

The functions for allocating and accessing matrices are defined in
:file:`gsl_matrix.h`.

Matrix allocation
-----------------

The functions for allocating memory to a matrix follow the style of
:code:`malloc` and :code:`free`.  They also perform their own error
checking.  If there is insufficient memory available to allocate a matrix
then the functions call the GSL error handler (with an error number of
:macro:`GSL_ENOMEM`) in addition to returning a null pointer.  Thus if you
use the library error handler to abort your program then it isn't
necessary to check every :code:`alloc`.

.. function:: gsl_matrix * gsl_matrix_alloc (size_t n1, size_t n2)

   This function creates a matrix of size :data:`n1` rows by :data:`n2` columns,
   returning a pointer to a newly initialized matrix struct. A new block is
   allocated for the elements of the matrix, and stored in the :data:`block`
   component of the matrix struct.  The block is "owned" by the matrix,
   and will be deallocated when the matrix is deallocated.  Requesting zero
   for :data:`n1` or :data:`n2` is valid and returns a non-null result.

.. function:: gsl_matrix * gsl_matrix_calloc (size_t n1, size_t n2)

   This function allocates memory for a matrix of size :data:`n1` rows by
   :data:`n2` columns and initializes all the elements of the matrix to zero.

.. function:: void gsl_matrix_free (gsl_matrix * m)

   This function frees a previously allocated matrix :data:`m`.  If the
   matrix was created using :func:`gsl_matrix_alloc` then the block
   underlying the matrix will also be deallocated.  If the matrix has
   been created from another object then the memory is still owned by
   that object and will not be deallocated.

.. index::
   single: matrices, range-checking
   single: range-checking for matrices

Accessing matrix elements
-------------------------

The functions for accessing the elements of a matrix use the same range
checking system as vectors.  You can turn off range checking by recompiling
your program with the preprocessor definition
:macro:`GSL_RANGE_CHECK_OFF`.

The elements of the matrix are stored in "C-order", where the second
index moves continuously through memory.  More precisely, the element
accessed by the function :code:`gsl_matrix_get(m,i,j)` and
:code:`gsl_matrix_set(m,i,j,x)` is::

   m->data[i * m->tda + j]

where :data:`tda` is the physical row-length of the matrix.

.. function:: double gsl_matrix_get (const gsl_matrix * m, const size_t i, const size_t j)

   This function returns the :math:`(i,j)`-th element of a matrix
   :data:`m`.  If :data:`i` or :data:`j` lie outside the allowed range of 0 to
   :code:`n1 - 1` and 0 to :code:`n2 - 1` then the error handler is invoked and 0
   is returned. |inlinefn|

.. function:: void gsl_matrix_set (gsl_matrix * m, const size_t i, const size_t j, double x)

   This function sets the value of the :math:`(i,j)`-th element of a
   matrix :data:`m` to :data:`x`.  If :data:`i` or :data:`j` lies outside the
   allowed range of 0 to :code:`n1 - 1` and 0 to :code:`n2 - 1` then the error
   handler is invoked. |inlinefn|

.. function:: double * gsl_matrix_ptr (gsl_matrix * m, size_t i, size_t j)
              const double * gsl_matrix_const_ptr (const gsl_matrix * m, size_t i, size_t j)

   These functions return a pointer to the :math:`(i,j)`-th element of a
   matrix :data:`m`.  If :data:`i` or :data:`j` lie outside the allowed range of
   0 to :code:`n1 - 1` and 0 to :code:`n2 - 1` then the error handler is invoked
   and a null pointer is returned. |inlinefns|

.. index::
   single: matrices, initializing
   single: initializing matrices
   single: identity matrix
   single: matrix, identity
   single: zero matrix
   single: matrix, zero
   single: constant matrix
   single: matrix, constant

Initializing matrix elements
----------------------------

.. function:: void gsl_matrix_set_all (gsl_matrix * m, double x)

   This function sets all the elements of the matrix :data:`m` to the value
   :data:`x`.

.. function:: void gsl_matrix_set_zero (gsl_matrix * m)

   This function sets all the elements of the matrix :data:`m` to zero.

.. function:: void gsl_matrix_set_identity (gsl_matrix * m)

   This function sets the elements of the matrix :data:`m` to the
   corresponding elements of the identity matrix, :math:`m(i,j) = \delta(i,j)`,
   i.e. a unit diagonal with all off-diagonal elements zero.
   This applies to both square and rectangular matrices.

Reading and writing matrices
----------------------------

The library provides functions for reading and writing matrices to a file
as binary data or formatted text.

.. function:: int gsl_matrix_fwrite (FILE * stream, const gsl_matrix * m)

   This function writes the elements of the matrix :data:`m` to the stream
   :data:`stream` in binary format.  The return value is 0 for success and
   :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since the
   data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_matrix_fread (FILE * stream, gsl_matrix * m)

   This function reads into the matrix :data:`m` from the open stream
   :data:`stream` in binary format.  The matrix :data:`m` must be preallocated
   with the correct dimensions since the function uses the size of :data:`m` to
   determine how many bytes to read.  The return value is 0 for success and
   :macro:`GSL_EFAILED` if there was a problem reading from the file.  The
   data is assumed to have been written in the native binary format on the
   same architecture.

.. function:: int gsl_matrix_fprintf (FILE * stream, const gsl_matrix * m, const char * format)

   This function writes the elements of the matrix :data:`m` line-by-line to
   the stream :data:`stream` using the format specifier :data:`format`, which
   should be one of the :code:`%g`, :code:`%e` or :code:`%f` formats for
   floating point numbers and :code:`%d` for integers.  The function returns
   0 for success and :macro:`GSL_EFAILED` if there was a problem writing to
   the file.

.. function:: int gsl_matrix_fscanf (FILE * stream, gsl_matrix * m)

   This function reads formatted data from the stream :data:`stream` into the
   matrix :data:`m`.  The matrix :data:`m` must be preallocated with the correct
   dimensions since the function uses the size of :data:`m` to determine how many
   numbers to read.  The function returns 0 for success and
   :macro:`GSL_EFAILED` if there was a problem reading from the file.

Matrix views
------------

.. type:: gsl_matrix_view
          gsl_matrix_const_view

   A matrix view is a temporary object, stored on the stack, which can be
   used to operate on a subset of matrix elements.  Matrix views can be
   defined for both constant and non-constant matrices using separate types
   that preserve constness.  A matrix view has the type
   :type:`gsl_matrix_view` and a constant matrix view has the type
   :type:`gsl_matrix_const_view`.  In both cases the elements of the view
   can by accessed using the :code:`matrix` component of the view object.  A
   pointer :code:`gsl_matrix *` or :code:`const gsl_matrix *` can be obtained
   by taking the address of the :code:`matrix` component with the :code:`&`
   operator.  In addition to matrix views it is also possible to create
   vector views of a matrix, such as row or column views.

.. function:: gsl_matrix_view gsl_matrix_submatrix (gsl_matrix * m, size_t k1, size_t k2, size_t n1, size_t n2)
              gsl_matrix_const_view gsl_matrix_const_submatrix (const gsl_matrix * m, size_t k1, size_t k2, size_t n1, size_t n2)

   These functions return a matrix view of a submatrix of the matrix
   :data:`m`.  The upper-left element of the submatrix is the element
   (:data:`k1`, :data:`k2`) of the original matrix.  The submatrix has :data:`n1`
   rows and :data:`n2` columns.  The physical number of columns in memory
   given by :data:`tda` is unchanged.  Mathematically, the
   :math:`(i,j)`-th element of the new matrix is given by::

      m'(i,j) = m->data[(k1*m->tda + k2) + i*m->tda + j]

   where the index :data:`i` runs from 0 to :code:`n1 - 1` and the index :data:`j`
   runs from 0 to :code:`n2 - 1`.

   The :code:`data` pointer of the returned matrix struct is set to null if
   the combined parameters (:data:`i`, :data:`j`, :data:`n1`, :data:`n2`, :data:`tda`)
   overrun the ends of the original matrix.

   The new matrix view is only a view of the block underlying the existing
   matrix, :data:`m`.  The block containing the elements of :data:`m` is not
   owned by the new matrix view.  When the view goes out of scope the
   original matrix :data:`m` and its block will continue to exist.  The
   original memory can only be deallocated by freeing the original matrix.
   Of course, the original matrix should not be deallocated while the view
   is still in use.

   The function :func:`gsl_matrix_const_submatrix` is equivalent to
   :func:`gsl_matrix_submatrix` but can be used for matrices which are
   declared :code:`const`.

.. function:: gsl_matrix_view gsl_matrix_view_array (double * base, size_t n1, size_t n2)
              gsl_matrix_const_view gsl_matrix_const_view_array (const double * base, size_t n1, size_t n2)

   These functions return a matrix view of the array :data:`base`.  The
   matrix has :data:`n1` rows and :data:`n2` columns.  The physical number of
   columns in memory is also given by :data:`n2`.  Mathematically, the
   :math:`(i,j)`-th element of the new matrix is given by::

      m'(i,j) = base[i*n2 + j]

   where the index :data:`i` runs from 0 to :code:`n1 - 1` and the index :data:`j`
   runs from 0 to :code:`n2 - 1`.

   The new matrix is only a view of the array :data:`base`.  When the view
   goes out of scope the original array :data:`base` will continue to exist.
   The original memory can only be deallocated by freeing the original
   array.  Of course, the original array should not be deallocated while
   the view is still in use.

   The function :func:`gsl_matrix_const_view_array` is equivalent to
   :func:`gsl_matrix_view_array` but can be used for matrices which are
   declared :code:`const`.

.. function:: gsl_matrix_view gsl_matrix_view_array_with_tda (double * base, size_t n1, size_t n2, size_t tda)
              gsl_matrix_const_view gsl_matrix_const_view_array_with_tda (const double * base, size_t n1, size_t n2, size_t tda)

   These functions return a matrix view of the array :data:`base` with a
   physical number of columns :data:`tda` which may differ from the corresponding
   dimension of the matrix.  The matrix has :data:`n1` rows and :data:`n2`
   columns, and the physical number of columns in memory is given by
   :data:`tda`.  Mathematically, the :math:`(i,j)`-th element of the new
   matrix is given by::

      m'(i,j) = base[i*tda + j]

   where the index :data:`i` runs from 0 to :code:`n1 - 1` and the index :data:`j`
   runs from 0 to :code:`n2 - 1`.

   The new matrix is only a view of the array :data:`base`.  When the view
   goes out of scope the original array :data:`base` will continue to exist.
   The original memory can only be deallocated by freeing the original
   array.  Of course, the original array should not be deallocated while
   the view is still in use.

   The function :func:`gsl_matrix_const_view_array_with_tda` is equivalent
   to :func:`gsl_matrix_view_array_with_tda` but can be used for matrices
   which are declared :code:`const`.

.. function:: gsl_matrix_view gsl_matrix_view_vector (gsl_vector * v, size_t n1, size_t n2)
              gsl_matrix_const_view gsl_matrix_const_view_vector (const gsl_vector * v, size_t n1, size_t n2)

   These functions return a matrix view of the vector :data:`v`.  The matrix
   has :data:`n1` rows and :data:`n2` columns. The vector must have unit
   stride. The physical number of columns in memory is also given by
   :data:`n2`.  Mathematically, the :math:`(i,j)`-th element of the new
   matrix is given by::

      m'(i,j) = v->data[i*n2 + j]

   where the index :data:`i` runs from 0 to :code:`n1 - 1` and the index :data:`j`
   runs from 0 to :code:`n2 - 1`.

   The new matrix is only a view of the vector :data:`v`.  When the view
   goes out of scope the original vector :data:`v` will continue to exist.
   The original memory can only be deallocated by freeing the original
   vector.  Of course, the original vector should not be deallocated while
   the view is still in use.

   The function :func:`gsl_matrix_const_view_vector` is equivalent to
   :func:`gsl_matrix_view_vector` but can be used for matrices which are
   declared :code:`const`.

.. function:: gsl_matrix_view gsl_matrix_view_vector_with_tda (gsl_vector * v, size_t n1, size_t n2, size_t tda)
              gsl_matrix_const_view gsl_matrix_const_view_vector_with_tda (const gsl_vector * v, size_t n1, size_t n2, size_t tda)

   These functions return a matrix view of the vector :data:`v` with a
   physical number of columns :data:`tda` which may differ from the
   corresponding matrix dimension.  The vector must have unit stride. The
   matrix has :data:`n1` rows and :data:`n2` columns, and the physical number
   of columns in memory is given by :data:`tda`.  Mathematically, the
   :math:`(i,j)`-th element of the new matrix is given by::

      m'(i,j) = v->data[i*tda + j]

   where the index :data:`i` runs from 0 to :code:`n1 - 1` and the index :data:`j`
   runs from 0 to :code:`n2 - 1`.

   The new matrix is only a view of the vector :data:`v`.  When the view
   goes out of scope the original vector :data:`v` will continue to exist.
   The original memory can only be deallocated by freeing the original
   vector.  Of course, the original vector should not be deallocated while
   the view is still in use.

   The function :func:`gsl_matrix_const_view_vector_with_tda` is equivalent
   to :func:`gsl_matrix_view_vector_with_tda` but can be used for matrices
   which are declared :code:`const`.

.. @node Modifying matrix views
.. @subsection Modifying matrix views
.. 
.. @deftypefun int gsl_matrix_view_from_matrix (gsl_matrix * m, gsl_matrix * mm, const size_t k1, const size_t k2, const size_t n1, const size_t n2)
.. This function modifies and existing matrix view :data:`m` to form a new
.. view of a matrix :data:`mm`, starting from element (:data:`k1`, :data:`k2`).
.. The matrix view has :data:`n1` rows and :data:`n2` columns.  Any existing
.. view in :data:`m` will be lost as a result of this function.
.. @end deftypefun
.. 
.. @deftypefun int gsl_matrix_view_from_vector (gsl_matrix * m, gsl_vector * v, const size_t offset, const size_t n1, const size_t n2)
.. This function modifies and existing matrix view :data:`m` to form a new
.. view of a vector :data:`v`, starting from element :data:`offset`.  The
.. vector has :data:`n1` rows and :data:`n2` columns.  Any
.. existing view in :data:`m` will be lost as a result of this function.
.. @end deftypefun
.. 
.. @deftypefun int gsl_matrix_view_from_array (gsl_matrix * m, double * base, const size_t offset, const size_t n1, const size_t n2)
.. This function modifies and existing matrix view :data:`m` to form a new
.. view of an array :data:`base`, starting from element :data:`offset`.  The
.. matrix has :data:`n1` rows and :data:`n2` columns.  Any
.. existing view in :data:`m` will be lost as a result of this function.
.. @end deftypefun
.. 
.. @deftypefun {gsl_matrix *} gsl_matrix_alloc_from_block (gsl_block * b, size_t offset, size_t n1, size_t n2, size_t tda)
.. This function creates a matrix as a slice of the block :data:`b`,
.. returning a pointer to a newly initialized matrix struct.  The start of
.. the matrix is offset by :data:`offset` elements from the start of the
.. block.  The matrix has :data:`n1` rows and :data:`n2` columns, with the
.. physical number of columns in memory given by :data:`tda`.
.. Mathematically, the (:data:`i`, :data:`j`)-th element of the matrix is given by,
.. 
.. @example
.. m(i,j) = b->data[offset + i*tda + j]
.. @end example
.. @noindent
.. where the index :data:`i` runs from 0 to :code:`n1-1` and the index :data:`j`
.. runs from 0 to :code:`n2-1`.
.. 
.. A null pointer is returned if the combined parameters
.. (:data:`offset`, :data:`n1`, :data:`n2`, :data:`tda`) overrun the end of the block
.. or if insufficient memory is available to store the matrix.
.. 
.. The matrix is only a view of the block :data:`b`, and the block is not
.. owned by the matrix.  When the matrix is deallocated the block :data:`b`
.. will continue to exist.  This memory can only be deallocated by freeing
.. the block itself.  Of course, this block should not be deallocated while
.. the matrix is still in use.
.. @end deftypefun
.. 
.. @deftypefun {gsl_matrix *} gsl_matrix_alloc_from_matrix (gsl_matrix * m, size_t k1, size_t k2, size_t n1, size_t n2)
.. 
.. This function creates a matrix as a submatrix of the matrix :data:`m`,
.. returning a pointer to a newly initialized matrix struct.  The upper-left
.. element of the submatrix is the element (:data:`k1`, :data:`k2`) of the
.. original matrix.  The submatrix has :data:`n1` rows and :data:`n2` columns.
.. The physical number of columns in memory given by :data:`tda` is
.. unchanged.  Mathematically, the (:data:`i`, :data:`j`)-th element of the
.. new matrix is given by,
.. 
.. @example
.. m'(i,j) = m->data[(k1*m->tda + k2) + i*m->tda + j]
.. @end example
.. @noindent
.. where the index :data:`i` runs from 0 to :code:`n1-1` and the index :data:`j`
.. runs from 0 to :code:`n2-1`.
.. 
.. A null pointer is returned if the combined parameters
.. (:data:`k1`, :data:`k2`, :data:`n1`, :data:`n2`, :data:`tda`) overrun the end of the
.. original matrix or if insufficient memory is available to store the matrix.
.. 
.. The new matrix is only a view of the block underlying the existing
.. matrix, :data:`m`.  The block is not owned by the new matrix.  When the new
.. matrix is deallocated the original matrix :data:`m` and its block will
.. continue to exist.  The original memory can only be deallocated by
.. freeing the original matrix.  Of course, the original matrix should not
.. be deallocated while the new matrix is still in use.
.. @end deftypefun

Creating row and column views
-----------------------------

In general there are two ways to access an object, by reference or by
copying.  The functions described in this section create vector views
which allow access to a row or column of a matrix by reference.
Modifying elements of the view is equivalent to modifying the matrix,
since both the vector view and the matrix point to the same memory
block.

.. function:: gsl_vector_view gsl_matrix_row (gsl_matrix * m, size_t i)
              gsl_vector_const_view gsl_matrix_const_row (const gsl_matrix * m, size_t i)

   These functions return a vector view of the :data:`i`-th row of the matrix
   :data:`m`.  The :code:`data` pointer of the new vector is set to null if
   :data:`i` is out of range.

   The function :func:`gsl_matrix_const_row` is equivalent to
   :func:`gsl_matrix_row` but can be used for matrices which are declared
   :code:`const`.

.. function:: gsl_vector_view gsl_matrix_column (gsl_matrix * m, size_t j)
              gsl_vector_const_view gsl_matrix_const_column (const gsl_matrix * m, size_t j)

   These functions return a vector view of the :data:`j`-th column of the
   matrix :data:`m`.  The :code:`data` pointer of the new vector is set to
   null if :data:`j` is out of range.

   The function :func:`gsl_matrix_const_column` is equivalent to
   :func:`gsl_matrix_column` but can be used for matrices which are declared
   :code:`const`.

.. function:: gsl_vector_view gsl_matrix_subrow (gsl_matrix * m, size_t i, size_t offset, size_t n)
              gsl_vector_const_view gsl_matrix_const_subrow (const gsl_matrix * m, size_t i, size_t offset, size_t n)

   These functions return a vector view of the :data:`i`-th row of the matrix
   :data:`m` beginning at :data:`offset` elements past the first column and
   containing :data:`n` elements. The :code:`data` pointer of the new vector
   is set to null if :data:`i`, :data:`offset`, or :data:`n` are out of range.

   The function :func:`gsl_matrix_const_subrow` is equivalent to
   :func:`gsl_matrix_subrow` but can be used for matrices which are declared
   :code:`const`.

.. function:: gsl_vector_view gsl_matrix_subcolumn (gsl_matrix * m, size_t j, size_t offset, size_t n)
              gsl_vector_const_view gsl_matrix_const_subcolumn (const gsl_matrix * m, size_t j, size_t offset, size_t n)

   These functions return a vector view of the :data:`j`-th column of the matrix
   :data:`m` beginning at :data:`offset` elements past the first row and
   containing :data:`n` elements. The :code:`data` pointer of the new vector
   is set to null if :data:`j`, :data:`offset`, or :data:`n` are out of range.

   The function :func:`gsl_matrix_const_subcolumn` is equivalent to
   :func:`gsl_matrix_subcolumn` but can be used for matrices which are declared
   :code:`const`.

.. index::
   single: matrix diagonal
   single: diagonal, of a matrix

.. function:: gsl_vector_view gsl_matrix_diagonal (gsl_matrix * m)
              gsl_vector_const_view gsl_matrix_const_diagonal (const gsl_matrix * m)

   These functions return a vector view of the diagonal of the matrix
   :data:`m`. The matrix :data:`m` is not required to be square. For a
   rectangular matrix the length of the diagonal is the same as the smaller
   dimension of the matrix.

   The function :func:`gsl_matrix_const_diagonal` is equivalent to
   :func:`gsl_matrix_diagonal` but can be used for matrices which are
   declared :code:`const`.

.. index::
   single: matrix subdiagonal
   single: subdiagonal, of a matrix

.. function:: gsl_vector_view gsl_matrix_subdiagonal (gsl_matrix * m, size_t k) 
              gsl_vector_const_view gsl_matrix_const_subdiagonal (const gsl_matrix * m, size_t k)

   These functions return a vector view of the :data:`k`-th subdiagonal of
   the matrix :data:`m`. The matrix :data:`m` is not required to be square.
   The diagonal of the matrix corresponds to :math:`k = 0`.

   The function :func:`gsl_matrix_const_subdiagonal` is equivalent to
   :func:`gsl_matrix_subdiagonal` but can be used for matrices which are
   declared :code:`const`.

.. index::
   single: matrix superdiagonal
   single: superdiagonal, matrix

.. function:: gsl_vector_view gsl_matrix_superdiagonal (gsl_matrix * m, size_t k) 
              gsl_vector_const_view gsl_matrix_const_superdiagonal (const gsl_matrix * m, size_t k)

   These functions return a vector view of the :data:`k`-th superdiagonal of
   the matrix :data:`m`. The matrix :data:`m` is not required to be square. The
   diagonal of the matrix corresponds to :math:`k = 0`.

   The function :func:`gsl_matrix_const_superdiagonal` is equivalent to
   :func:`gsl_matrix_superdiagonal` but can be used for matrices which are
   declared :code:`const`.

.. @deftypefun {gsl_vector *} gsl_vector_alloc_row_from_matrix (gsl_matrix * m, size_t i)
.. This function allocates a new :type:`gsl_vector` struct which points to
.. the :data:`i`-th row of the matrix :data:`m`.
.. @end deftypefun
.. 
.. @deftypefun {gsl_vector *} gsl_vector_alloc_col_from_matrix (gsl_matrix * m, size_t j)
.. This function allocates a new :type:`gsl_vector` struct which points to
.. the :data:`j`-th column of the matrix :data:`m`.
.. @end deftypefun

Copying matrices
----------------

.. function:: int gsl_matrix_memcpy (gsl_matrix * dest, const gsl_matrix * src)

   This function copies the elements of the matrix :data:`src` into the
   matrix :data:`dest`.  The two matrices must have the same size.

.. function:: int gsl_matrix_swap (gsl_matrix * m1, gsl_matrix * m2)

   This function exchanges the elements of the matrices :data:`m1` and
   :data:`m2` by copying.  The two matrices must have the same size.

Copying rows and columns
------------------------

The functions described in this section copy a row or column of a matrix
into a vector.  This allows the elements of the vector and the matrix to
be modified independently.  Note that if the matrix and the vector point
to overlapping regions of memory then the result will be undefined.  The
same effect can be achieved with more generality using
:func:`gsl_vector_memcpy` with vector views of rows and columns.

.. function:: int gsl_matrix_get_row (gsl_vector * v, const gsl_matrix * m, size_t i)

   This function copies the elements of the :data:`i`-th row of the matrix
   :data:`m` into the vector :data:`v`.  The length of the vector must be the
   same as the length of the row.

.. function:: int gsl_matrix_get_col (gsl_vector * v, const gsl_matrix * m, size_t j)

   This function copies the elements of the :data:`j`-th column of the matrix
   :data:`m` into the vector :data:`v`.  The length of the vector must be the
   same as the length of the column.

.. function:: int gsl_matrix_set_row (gsl_matrix * m, size_t i, const gsl_vector * v)

   This function copies the elements of the vector :data:`v` into the
   :data:`i`-th row of the matrix :data:`m`.  The length of the vector must be
   the same as the length of the row.

.. function:: int gsl_matrix_set_col (gsl_matrix * m, size_t j, const gsl_vector * v)

   This function copies the elements of the vector :data:`v` into the
   :data:`j`-th column of the matrix :data:`m`.  The length of the vector must be
   the same as the length of the column.

Exchanging rows and columns
---------------------------

The following functions can be used to exchange the rows and columns of
a matrix.

.. function:: int gsl_matrix_swap_rows (gsl_matrix * m, size_t i, size_t j)

   This function exchanges the :data:`i`-th and :data:`j`-th rows of the matrix
   :data:`m` in-place.

.. function:: int gsl_matrix_swap_columns (gsl_matrix * m, size_t i, size_t j)

   This function exchanges the :data:`i`-th and :data:`j`-th columns of the
   matrix :data:`m` in-place.

.. function:: int gsl_matrix_swap_rowcol (gsl_matrix * m, size_t i, size_t j)

   This function exchanges the :data:`i`-th row and :data:`j`-th column of the
   matrix :data:`m` in-place.  The matrix must be square for this operation to
   be possible.

.. function:: int gsl_matrix_transpose_memcpy (gsl_matrix * dest, const gsl_matrix * src)

   This function makes the matrix :data:`dest` the transpose of the matrix
   :data:`src` by copying the elements of :data:`src` into :data:`dest`.  This
   function works for all matrices provided that the dimensions of the matrix
   :data:`dest` match the transposed dimensions of the matrix :data:`src`.

.. function:: int gsl_matrix_transpose (gsl_matrix * m)

   This function replaces the matrix :data:`m` by its transpose by copying
   the elements of the matrix in-place.  The matrix must be square for this
   operation to be possible.

Matrix operations
-----------------

The following operations are defined for real and complex matrices.

.. function:: int gsl_matrix_add (gsl_matrix * a, const gsl_matrix * b)

   This function adds the elements of matrix :data:`b` to the elements of
   matrix :data:`a`.  The result :math:`a(i,j) \leftarrow a(i,j) + b(i,j)`
   is stored in :data:`a` and :data:`b` remains unchanged. The two matrices
   must have the same dimensions.

.. function:: int gsl_matrix_sub (gsl_matrix * a, const gsl_matrix * b)

   This function subtracts the elements of matrix :data:`b` from the
   elements of matrix :data:`a`.  The result :math:`a(i,j) \leftarrow a(i,j) - b(i,j)`
   is stored in :data:`a` and :data:`b` remains unchanged. The two
   matrices must have the same dimensions.

.. function:: int gsl_matrix_mul_elements (gsl_matrix * a, const gsl_matrix * b)

   This function multiplies the elements of matrix :data:`a` by the
   elements of matrix :data:`b`.  The result :math:`a(i,j) \leftarrow a(i,j) * b(i,j)`
   is stored in :data:`a` and :data:`b` remains unchanged.  The two
   matrices must have the same dimensions.

.. function:: int gsl_matrix_div_elements (gsl_matrix * a, const gsl_matrix * b)

   This function divides the elements of matrix :data:`a` by the elements
   of matrix :data:`b`.  The result :math:`a(i,j) \leftarrow a(i,j) / b(i,j)`
   is stored in :data:`a` and :data:`b` remains unchanged. The two
   matrices must have the same dimensions.

.. function:: int gsl_matrix_scale (gsl_matrix * a, const double x)

   This function multiplies the elements of matrix :data:`a` by the
   constant factor :data:`x`.  The result :math:`a(i,j) \leftarrow x a(i,j)`
   is stored in :data:`a`.

.. function:: int gsl_matrix_add_constant (gsl_matrix * a, const double x)

   This function adds the constant value :data:`x` to the elements of the
   matrix :data:`a`.  The result :math:`a(i,j) \leftarrow a(i,j) + x` is
   stored in :data:`a`.

Finding maximum and minimum elements of matrices
------------------------------------------------

The following operations are only defined for real matrices.

.. function:: double gsl_matrix_max (const gsl_matrix * m)

   This function returns the maximum value in the matrix :data:`m`.

.. function:: double gsl_matrix_min (const gsl_matrix * m)

   This function returns the minimum value in the matrix :data:`m`.

.. function:: void gsl_matrix_minmax (const gsl_matrix * m, double * min_out, double * max_out)

   This function returns the minimum and maximum values in the matrix
   :data:`m`, storing them in :data:`min_out` and :data:`max_out`.

.. function:: void gsl_matrix_max_index (const gsl_matrix * m, size_t * imax, size_t * jmax)

   This function returns the indices of the maximum value in the matrix
   :data:`m`, storing them in :data:`imax` and :data:`jmax`.  When there are
   several equal maximum elements then the first element found is returned,
   searching in row-major order.

.. function:: void gsl_matrix_min_index (const gsl_matrix * m, size_t * imin, size_t * jmin)

   This function returns the indices of the minimum value in the matrix
   :data:`m`, storing them in :data:`imin` and :data:`jmin`.  When there are
   several equal minimum elements then the first element found is returned,
   searching in row-major order.

.. function:: void gsl_matrix_minmax_index (const gsl_matrix * m, size_t * imin, size_t * jmin, size_t * imax, size_t * jmax)

   This function returns the indices of the minimum and maximum values in
   the matrix :data:`m`, storing them in (:data:`imin`, :data:`jmin`) and
   (:data:`imax`, :data:`jmax`). When there are several equal minimum or maximum
   elements then the first elements found are returned, searching in
   row-major order.

Matrix properties
-----------------

The following functions are defined for real and complex matrices.
For complex matrices both the real and imaginary parts must satisfy
the conditions.

.. function:: int gsl_matrix_isnull (const gsl_matrix * m)
              int gsl_matrix_ispos (const gsl_matrix * m)
              int gsl_matrix_isneg (const gsl_matrix * m)
              int gsl_matrix_isnonneg (const gsl_matrix * m)

   These functions return 1 if all the elements of the matrix :data:`m` are
   zero, strictly positive, strictly negative, or non-negative
   respectively, and 0 otherwise. To test whether a matrix is
   positive-definite, use the :ref:`Cholesky decomposition <sec_cholesky-decomposition>`.

.. function:: int gsl_matrix_equal (const gsl_matrix * a, const gsl_matrix * b)

   This function returns 1 if the matrices :data:`a` and :data:`b` are equal
   (by comparison of element values) and 0 otherwise.

Example programs for matrices
-----------------------------

The program below shows how to allocate, initialize and read from a matrix
using the functions :func:`gsl_matrix_alloc`, :func:`gsl_matrix_set` and
:func:`gsl_matrix_get`.

.. include:: examples/matrix.c
   :code:

Here is the output from the program.  The final loop attempts to read
outside the range of the matrix :code:`m`, and the error is trapped by
the range-checking code in :func:`gsl_matrix_get`.

::

   $ ./a.out
   m(0,0) = 0.23
   m(0,1) = 1.23
   m(0,2) = 2.23
   m(1,0) = 100.23
   m(1,1) = 101.23
   m(1,2) = 102.23
   ...
   m(9,2) = 902.23
   gsl: matrix_source.c:13: ERROR: first index out of range
   Default GSL error handler invoked.
   Aborted (core dumped)

The next program shows how to write a matrix to a file.

.. include:: examples/matrixw.c
   :code:

After running this program the file :file:`test.dat` should contain the
elements of :code:`m`, written in binary format.  The matrix which is read
back in using the function :func:`gsl_matrix_fread` should be exactly
equal to the original matrix.

The following program demonstrates the use of vector views.  The program
computes the column norms of a matrix.

.. include:: examples/vectorview.c
   :code:

Here is the output of the program, 

.. include:: examples/vectorview.txt
   :code:

The results can be confirmed using |octave|::

   $ octave
   GNU Octave, version 2.0.16.92
   octave> m = sin(0:9)' * ones(1,10) 
                  + ones(10,1) * cos(0:9); 
   octave> sqrt(sum(m.^2))
   ans =
     4.3146  3.1205  2.1932  3.2611  2.5342  2.5728
     4.2047  3.6520  2.0852  3.0731

References and Further Reading
------------------------------

The block, vector and matrix objects in GSL follow the :code:`valarray`
model of C++.  A description of this model can be found in the following
reference,

* B. Stroustrup, The C++ Programming Language (3rd Ed), 
  Section 22.4 Vector Arithmetic. Addison-Wesley 1997, ISBN 0-201-88954-4.

.. rubric:: Footnotes

.. [#f1] Range checking is available in the GNU C Compiler bounds-checking extension,
         but it is not part of the default installation of GCC. Memory accesses
         can also be checked with Valgrind or the :code:`gcc -fmudflap`
         memory protection option.
.. index::
   single: W function
   single: Lambert function

Lambert's W functions, :math:`W(x)`, are defined to be solutions
of the equation :math:`W(x) \exp(W(x)) = x`. This function has
multiple branches for :math:`x < 0`; however, it has only
two real-valued branches. We define :math:`W_0(x)` to be the
principal branch, where :math:`W > -1` for :math:`x < 0`, and 
:math:`W_{-1}(x)`
to be the other real branch, where
:math:`W < -1` for :math:`x < 0`.  The Lambert functions are
declared in the header file :file:`gsl_sf_lambert.h`.

.. function:: double gsl_sf_lambert_W0 (double x)
              int gsl_sf_lambert_W0_e (double x, gsl_sf_result * result)

   These compute the principal branch of the Lambert W function, :math:`W_0(x)`.
.. exceptions: GSL_EDOM, GSL_EMAXITER

.. function:: double gsl_sf_lambert_Wm1 (double x)
              int gsl_sf_lambert_Wm1_e (double x, gsl_sf_result * result)

   These compute the secondary real-valued branch of the Lambert W function, 
   :math:`W_{-1}(x)`.
.. exceptions: GSL_EDOM, GSL_EMAXITER
.. index::
   single: Low-level CBLAS
   single: CBLAS, Low-level interface
   single: BLAS, Low-level C interface
   single: Basic Linear Algebra Subroutines (BLAS)

.. _chap_cblas:

*****************
GSL CBLAS Library
*****************

.. include:: include.rst

The prototypes for the low-level |cblas| functions are declared in
the file :file:`gsl_cblas.h`.  For the definition of the functions
consult the documentation available from Netlib (:ref:`see BLAS References and
Further Reading <sec_blas-references>`).

Level 1
=======

.. function:: float cblas_sdsdot (const int N, const float alpha, const float * x, const int incx, const float * y, const int incy)

.. function:: double cblas_dsdot (const int N, const float * x, const int incx, const float * y, const int incy)

.. function:: float cblas_sdot (const int N, const float * x, const int incx, const float * y, const int incy)

.. function:: double cblas_ddot (const int N, const double * x, const int incx, const double * y, const int incy)

.. function:: void cblas_cdotu_sub (const int N, const void * x, const int incx, const void * y, const int incy, void * dotu)

.. function:: void cblas_cdotc_sub (const int N, const void * x, const int incx, const void * y, const int incy, void * dotc)

.. function:: void cblas_zdotu_sub (const int N, const void * x, const int incx, const void * y, const int incy, void * dotu)

.. function:: void cblas_zdotc_sub (const int N, const void * x, const int incx, const void * y, const int incy, void * dotc)

.. function:: float cblas_snrm2 (const int N, const float * x, const int incx)

.. function:: float cblas_sasum (const int N, const float * x, const int incx)

.. function:: double cblas_dnrm2 (const int N, const double * x, const int incx)

.. function:: double cblas_dasum (const int N, const double * x, const int incx)

.. function:: float cblas_scnrm2 (const int N, const void * x, const int incx)

.. function:: float cblas_scasum (const int N, const void * x, const int incx)

.. function:: double cblas_dznrm2 (const int N, const void * x, const int incx)

.. function:: double cblas_dzasum (const int N, const void * x, const int incx)

.. function:: CBLAS_INDEX cblas_isamax (const int N, const float * x, const int incx)

.. function:: CBLAS_INDEX cblas_idamax (const int N, const double * x, const int incx)

.. function:: CBLAS_INDEX cblas_icamax (const int N, const void * x, const int incx)

.. function:: CBLAS_INDEX cblas_izamax (const int N, const void * x, const int incx)

.. function:: void cblas_sswap (const int N, float * x, const int incx, float * y, const int incy)

.. function:: void cblas_scopy (const int N, const float * x, const int incx, float * y, const int incy)

.. function:: void cblas_saxpy (const int N, const float alpha, const float * x, const int incx, float * y, const int incy)

.. function:: void cblas_dswap (const int N, double * x, const int incx, double * y, const int incy)

.. function:: void cblas_dcopy (const int N, const double * x, const int incx, double * y, const int incy)

.. function:: void cblas_daxpy (const int N, const double alpha, const double * x, const int incx, double * y, const int incy)

.. function:: void cblas_cswap (const int N, void * x, const int incx, void * y, const int incy)

.. function:: void cblas_ccopy (const int N, const void * x, const int incx, void * y, const int incy)

.. function:: void cblas_caxpy (const int N, const void * alpha, const void * x, const int incx, void * y, const int incy)

.. function:: void cblas_zswap (const int N, void * x, const int incx, void * y, const int incy)

.. function:: void cblas_zcopy (const int N, const void * x, const int incx, void * y, const int incy)

.. function:: void cblas_zaxpy (const int N, const void * alpha, const void * x, const int incx, void * y, const int incy)

.. function:: void cblas_srotg (float * a, float * b, float * c, float * s)

.. function:: void cblas_srotmg (float * d1, float * d2, float * b1, const float b2, float * P)

.. function:: void cblas_srot (const int N, float * x, const int incx, float * y, const int incy, const float c, const float s)

.. function:: void cblas_srotm (const int N, float * x, const int incx, float * y, const int incy, const float * P)

.. function:: void cblas_drotg (double * a, double * b, double * c, double * s)

.. function:: void cblas_drotmg (double * d1, double * d2, double * b1, const double b2, double * P)

.. function:: void cblas_drot (const int N, double * x, const int incx, double * y, const int incy, const double c, const double s)

.. function:: void cblas_drotm (const int N, double * x, const int incx, double * y, const int incy, const double * P)

.. function:: void cblas_sscal (const int N, const float alpha, float * x, const int incx)

.. function:: void cblas_dscal (const int N, const double alpha, double * x, const int incx)

.. function:: void cblas_cscal (const int N, const void * alpha, void * x, const int incx)

.. function:: void cblas_zscal (const int N, const void * alpha, void * x, const int incx)

.. function:: void cblas_csscal (const int N, const float alpha, void * x, const int incx)

.. function:: void cblas_zdscal (const int N, const double alpha, void * x, const int incx)

Level 2
=======

.. function:: void cblas_sgemv (const enum CBLAS_ORDER order, const enum CBLAS_TRANSPOSE TransA, const int M, const int N, const float alpha, const float * A, const int lda, const float * x, const int incx, const float beta, float * y, const int incy)

.. function:: void cblas_sgbmv (const enum CBLAS_ORDER order, const enum CBLAS_TRANSPOSE TransA, const int M, const int N, const int KL, const int KU, const float alpha, const float * A, const int lda, const float * x, const int incx, const float beta, float * y, const int incy)

.. function:: void cblas_strmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const float * A, const int lda, float * x, const int incx)

.. function:: void cblas_stbmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const int K, const float * A, const int lda, float * x, const int incx)

.. function:: void cblas_stpmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const float * Ap, float * x, const int incx)

.. function:: void cblas_strsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const float * A, const int lda, float * x, const int incx)

.. function:: void cblas_stbsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const int K, const float * A, const int lda, float * x, const int incx)

.. function:: void cblas_stpsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const float * Ap, float * x, const int incx)

.. function:: void cblas_dgemv (const enum CBLAS_ORDER order, const enum CBLAS_TRANSPOSE TransA, const int M, const int N, const double alpha, const double * A, const int lda, const double * x, const int incx, const double beta, double * y, const int incy)

.. function:: void cblas_dgbmv (const enum CBLAS_ORDER order, const enum CBLAS_TRANSPOSE TransA, const int M, const int N, const int KL, const int KU, const double alpha, const double * A, const int lda, const double * x, const int incx, const double beta, double * y, const int incy)

.. function:: void cblas_dtrmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const double * A, const int lda, double * x, const int incx)

.. function:: void cblas_dtbmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const int K, const double * A, const int lda, double * x, const int incx)

.. function:: void cblas_dtpmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const double * Ap, double * x, const int incx)

.. function:: void cblas_dtrsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const double * A, const int lda, double * x, const int incx)

.. function:: void cblas_dtbsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const int K, const double * A, const int lda, double * x, const int incx)

.. function:: void cblas_dtpsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const double * Ap, double * x, const int incx)

.. function:: void cblas_cgemv (const enum CBLAS_ORDER order, const enum CBLAS_TRANSPOSE TransA, const int M, const int N, const void * alpha, const void * A, const int lda, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_cgbmv (const enum CBLAS_ORDER order, const enum CBLAS_TRANSPOSE TransA, const int M, const int N, const int KL, const int KU, const void * alpha, const void * A, const int lda, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_ctrmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const void * A, const int lda, void * x, const int incx)

.. function:: void cblas_ctbmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const int K, const void * A, const int lda, void * x, const int incx)

.. function:: void cblas_ctpmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const void * Ap, void * x, const int incx)

.. function:: void cblas_ctrsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const void * A, const int lda, void * x, const int incx)

.. function:: void cblas_ctbsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const int K, const void * A, const int lda, void * x, const int incx)

.. function:: void cblas_ctpsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const void * Ap, void * x, const int incx)

.. function:: void cblas_zgemv (const enum CBLAS_ORDER order, const enum CBLAS_TRANSPOSE TransA, const int M, const int N, const void * alpha, const void * A, const int lda, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_zgbmv (const enum CBLAS_ORDER order, const enum CBLAS_TRANSPOSE TransA, const int M, const int N, const int KL, const int KU, const void * alpha, const void * A, const int lda, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_ztrmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const void * A, const int lda, void * x, const int incx)

.. function:: void cblas_ztbmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const int K, const void * A, const int lda, void * x, const int incx)

.. function:: void cblas_ztpmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const void * Ap, void * x, const int incx)

.. function:: void cblas_ztrsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const void * A, const int lda, void * x, const int incx)

.. function:: void cblas_ztbsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const int K, const void * A, const int lda, void * x, const int incx)

.. function:: void cblas_ztpsv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int N, const void * Ap, void * x, const int incx)

.. function:: void cblas_ssymv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const float alpha, const float * A, const int lda, const float * x, const int incx, const float beta, float * y, const int incy)

.. function:: void cblas_ssbmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const int K, const float alpha, const float * A, const int lda, const float * x, const int incx, const float beta, float * y, const int incy)

.. function:: void cblas_sspmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const float alpha, const float * Ap, const float * x, const int incx, const float beta, float * y, const int incy)

.. function:: void cblas_sger (const enum CBLAS_ORDER order, const int M, const int N, const float alpha, const float * x, const int incx, const float * y, const int incy, float * A, const int lda)

.. function:: void cblas_ssyr (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const float alpha, const float * x, const int incx, float * A, const int lda)

.. function:: void cblas_sspr (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const float alpha, const float * x, const int incx, float * Ap)

.. function:: void cblas_ssyr2 (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const float alpha, const float * x, const int incx, const float * y, const int incy, float * A, const int lda)

.. function:: void cblas_sspr2 (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const float alpha, const float * x, const int incx, const float * y, const int incy, float * A)

.. function:: void cblas_dsymv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const double alpha, const double * A, const int lda, const double * x, const int incx, const double beta, double * y, const int incy)

.. function:: void cblas_dsbmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const int K, const double alpha, const double * A, const int lda, const double * x, const int incx, const double beta, double * y, const int incy)

.. function:: void cblas_dspmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const double alpha, const double * Ap, const double * x, const int incx, const double beta, double * y, const int incy)

.. function:: void cblas_dger (const enum CBLAS_ORDER order, const int M, const int N, const double alpha, const double * x, const int incx, const double * y, const int incy, double * A, const int lda)

.. function:: void cblas_dsyr (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const double alpha, const double * x, const int incx, double * A, const int lda)

.. function:: void cblas_dspr (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const double alpha, const double * x, const int incx, double * Ap)

.. function:: void cblas_dsyr2 (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const double alpha, const double * x, const int incx, const double * y, const int incy, double * A, const int lda)

.. function:: void cblas_dspr2 (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const double alpha, const double * x, const int incx, const double * y, const int incy, double * A)

.. function:: void cblas_chemv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const void * alpha, const void * A, const int lda, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_chbmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const int K, const void * alpha, const void * A, const int lda, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_chpmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const void * alpha, const void * Ap, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_cgeru (const enum CBLAS_ORDER order, const int M, const int N, const void * alpha, const void * x, const int incx, const void * y, const int incy, void * A, const int lda)

.. function:: void cblas_cgerc (const enum CBLAS_ORDER order, const int M, const int N, const void * alpha, const void * x, const int incx, const void * y, const int incy, void * A, const int lda)

.. function:: void cblas_cher (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const float alpha, const void * x, const int incx, void * A, const int lda)

.. function:: void cblas_chpr (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const float alpha, const void * x, const int incx, void * A)

.. function:: void cblas_cher2 (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const void * alpha, const void * x, const int incx, const void * y, const int incy, void * A, const int lda)

.. function:: void cblas_chpr2 (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const void * alpha, const void * x, const int incx, const void * y, const int incy, void * Ap)

.. function:: void cblas_zhemv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const void * alpha, const void * A, const int lda, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_zhbmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const int K, const void * alpha, const void * A, const int lda, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_zhpmv (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const void * alpha, const void * Ap, const void * x, const int incx, const void * beta, void * y, const int incy)

.. function:: void cblas_zgeru (const enum CBLAS_ORDER order, const int M, const int N, const void * alpha, const void * x, const int incx, const void * y, const int incy, void * A, const int lda)

.. function:: void cblas_zgerc (const enum CBLAS_ORDER order, const int M, const int N, const void * alpha, const void * x, const int incx, const void * y, const int incy, void * A, const int lda)

.. function:: void cblas_zher (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const double alpha, const void * x, const int incx, void * A, const int lda)

.. function:: void cblas_zhpr (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const double alpha, const void * x, const int incx, void * A)

.. function:: void cblas_zher2 (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const void * alpha, const void * x, const int incx, const void * y, const int incy, void * A, const int lda)

.. function:: void cblas_zhpr2 (const enum CBLAS_ORDER order, const enum CBLAS_UPLO Uplo, const int N, const void * alpha, const void * x, const int incx, const void * y, const int incy, void * Ap)

Level 3
=======

.. function:: void cblas_sgemm (const enum CBLAS_ORDER Order, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_TRANSPOSE TransB, const int M, const int N, const int K, const float alpha, const float * A, const int lda, const float * B, const int ldb, const float beta, float * C, const int ldc)

.. function:: void cblas_ssymm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const int M, const int N, const float alpha, const float * A, const int lda, const float * B, const int ldb, const float beta, float * C, const int ldc)

.. function:: void cblas_ssyrk (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const float alpha, const float * A, const int lda, const float beta, float * C, const int ldc)

.. function:: void cblas_ssyr2k (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const float alpha, const float * A, const int lda, const float * B, const int ldb, const float beta, float * C, const int ldc)

.. function:: void cblas_strmm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int M, const int N, const float alpha, const float * A, const int lda, float * B, const int ldb)

.. function:: void cblas_strsm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int M, const int N, const float alpha, const float * A, const int lda, float * B, const int ldb)

.. function:: void cblas_dgemm (const enum CBLAS_ORDER Order, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_TRANSPOSE TransB, const int M, const int N, const int K, const double alpha, const double * A, const int lda, const double * B, const int ldb, const double beta, double * C, const int ldc)

.. function:: void cblas_dsymm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const int M, const int N, const double alpha, const double * A, const int lda, const double * B, const int ldb, const double beta, double * C, const int ldc)

.. function:: void cblas_dsyrk (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const double alpha, const double * A, const int lda, const double beta, double * C, const int ldc)

.. function:: void cblas_dsyr2k (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const double alpha, const double * A, const int lda, const double * B, const int ldb, const double beta, double * C, const int ldc)

.. function:: void cblas_dtrmm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int M, const int N, const double alpha, const double * A, const int lda, double * B, const int ldb)

.. function:: void cblas_dtrsm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int M, const int N, const double alpha, const double * A, const int lda, double * B, const int ldb)

.. function:: void cblas_cgemm (const enum CBLAS_ORDER Order, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_TRANSPOSE TransB, const int M, const int N, const int K, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const void * beta, void * C, const int ldc)

.. function:: void cblas_csymm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const int M, const int N, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const void * beta, void * C, const int ldc)

.. function:: void cblas_csyrk (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const void * alpha, const void * A, const int lda, const void * beta, void * C, const int ldc)

.. function:: void cblas_csyr2k (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const void * beta, void * C, const int ldc)

.. function:: void cblas_ctrmm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int M, const int N, const void * alpha, const void * A, const int lda, void * B, const int ldb)

.. function:: void cblas_ctrsm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int M, const int N, const void * alpha, const void * A, const int lda, void * B, const int ldb)

.. function:: void cblas_zgemm (const enum CBLAS_ORDER Order, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_TRANSPOSE TransB, const int M, const int N, const int K, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const void * beta, void * C, const int ldc)

.. function:: void cblas_zsymm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const int M, const int N, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const void * beta, void * C, const int ldc)

.. function:: void cblas_zsyrk (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const void * alpha, const void * A, const int lda, const void * beta, void * C, const int ldc)

.. function:: void cblas_zsyr2k (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const void * beta, void * C, const int ldc)

.. function:: void cblas_ztrmm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int M, const int N, const void * alpha, const void * A, const int lda, void * B, const int ldb)

.. function:: void cblas_ztrsm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE TransA, const enum CBLAS_DIAG Diag, const int M, const int N, const void * alpha, const void * A, const int lda, void * B, const int ldb)

.. function:: void cblas_chemm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const int M, const int N, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const void * beta, void * C, const int ldc)

.. function:: void cblas_cherk (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const float alpha, const void * A, const int lda, const float beta, void * C, const int ldc)

.. function:: void cblas_cher2k (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const float beta, void * C, const int ldc)

.. function:: void cblas_zhemm (const enum CBLAS_ORDER Order, const enum CBLAS_SIDE Side, const enum CBLAS_UPLO Uplo, const int M, const int N, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const void * beta, void * C, const int ldc)

.. function:: void cblas_zherk (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const double alpha, const void * A, const int lda, const double beta, void * C, const int ldc)

.. function:: void cblas_zher2k (const enum CBLAS_ORDER Order, const enum CBLAS_UPLO Uplo, const enum CBLAS_TRANSPOSE Trans, const int N, const int K, const void * alpha, const void * A, const int lda, const void * B, const int ldb, const double beta, void * C, const int ldc)

.. function:: void cblas_xerbla (int p, const char * rout, const char * form, ...)

Examples
========

The following program computes the product of two matrices using the
Level-3 |blas| function SGEMM,

.. only:: not texinfo

   .. math::

      \left(
        \begin{array}{ccc}
          0.11 & 0.12 & 0.13\\
          0.21 & 0.22 & 0.23
        \end{array}
      \right)
      \left(
        \begin{array}{cc}
          1011 & 1012\\
          1021 & 1022\\
          1031 & 1032
        \end{array}
      \right)
      =
      \left(
        \begin{array}{cc}
          367.76 & 368.12\\
          674.06 & 674.72
        \end{array}
      \right)

.. only:: texinfo

   ::

      [ 0.11 0.12 0.13 ]  [ 1011 1012 ]     [ 367.76 368.12 ]
      [ 0.21 0.22 0.23 ]  [ 1021 1022 ]  =  [ 674.06 674.72 ]
                          [ 1031 1032 ]

The matrices are stored in row major order but could be stored in column
major order if the first argument of the call to :func:`cblas_sgemm` was
changed to :code:`CblasColMajor`.

.. include:: examples/cblas.c
   :code:

To compile the program use the following command line::

  $ gcc -Wall demo.c -lgslcblas

There is no need to link with the main library :code:`-lgsl` in this
case as the |cblas| library is an independent unit. Here is the output
from the program,

.. include:: examples/cblas.txt
   :code:
.. index:: logarithm and related functions

Information on the properties of the Logarithm function can be found in
Abramowitz & Stegun, Chapter 4.  The functions described in this section
are declared in the header file :file:`gsl_sf_log.h`.

.. function:: double gsl_sf_log (double x)
              int gsl_sf_log_e (double x, gsl_sf_result * result)

   These routines compute the logarithm of :data:`x`, :math:`\log(x)`, for
   :math:`x > 0`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_log_abs (double x)
              int gsl_sf_log_abs_e (double x, gsl_sf_result * result)

   These routines compute the logarithm of the magnitude of :data:`x`,
   :math:`\log(|x|)`, for :math:`x \ne 0`.
.. Exceptional Return Values: GSL_EDOM

.. function:: int gsl_sf_complex_log_e (double zr, double zi, gsl_sf_result * lnr, gsl_sf_result * theta)

   This routine computes the complex logarithm of :math:`z = z_r + i z_i`.
   The results are returned as :data:`lnr`, :data:`theta` such that
   :math:`\exp(lnr + i \theta) = z_r + i z_i`, where :math:`\theta` lies in
   the range :math:`[-\pi,\pi]`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_log_1plusx (double x)
              int gsl_sf_log_1plusx_e (double x, gsl_sf_result * result)

   These routines compute :math:`\log(1 + x)` for :math:`x > -1` using an
   algorithm that is accurate for small :data:`x`.
.. Domain: x > -1.0
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_log_1plusx_mx (double x)
              int gsl_sf_log_1plusx_mx_e (double x, gsl_sf_result * result)

   These routines compute :math:`\log(1 + x) - x` for :math:`x > -1` using an
   algorithm that is accurate for small :data:`x`.
.. Domain: x > -1.0 
.. Exceptional Return Values: GSL_EDOM
.. index::
   single: DWT, see wavelet transforms
   single: wavelet transforms
   single: transforms, wavelet

******************
Wavelet Transforms
******************

This chapter describes functions for performing Discrete Wavelet
Transforms (DWTs).  The library includes wavelets for real data in both
one and two dimensions.  The wavelet functions are declared in the header
files :file:`gsl_wavelet.h` and :file:`gsl_wavelet2d.h`.

.. index::
   single: DWT, mathematical definition

Definitions
===========

The continuous wavelet transform and its inverse are defined by
the relations,

.. math:: w(s, \tau) = \int_{-\infty}^\infty f(t) * \psi^*_{s,\tau}(t) dt

and,

.. math:: f(t) = \int_0^\infty ds \int_{-\infty}^\infty w(s, \tau) * \psi_{s,\tau}(t) d\tau

where the basis functions :math:`\psi_{s,\tau}`
are obtained by scaling
and translation from a single function, referred to as the {mother
wavelet*.

The discrete version of the wavelet transform acts on equally-spaced
samples, with fixed scaling and translation steps (:math:`s`,
:math:`\tau`).  The frequency and time axes are sampled *dyadically*
on scales of :math:`2^j` through a level parameter :math:`j`.

..  The wavelet :math:`\psi`
..  can be expressed in terms of a scaling function :math:`\varphi`,
..
..  @tex
..  \beforedisplay
..  $$
..  \psi(2^{j-1},t) = \sum_{k=0}^{2^j-1} g_j(k) * \bar{\varphi}(2^j t-k)
..  $$
..  \afterdisplay
..  @end tex
..  @ifinfo
..  @example
..  \psi(2^@{j-1@},t) = \sum_@{k=0@}^@{2^j-1@} g_j(k) * \bar@{\varphi@}(2^j t-k)
..  @end example
..  @end ifinfo
..  @noindent
..  and
..
..  @tex
..  \beforedisplay
..  $$
..  \varphi(2^{j-1},t) = \sum_{k=0}^{2^j-1} h_j(k) * \bar{\varphi}(2^j t-k)
..  $$
..  \afterdisplay
..  @end tex
..  @ifinfo
..  @example
..  \varphi(2^@{j-1@},t) = \sum_@{k=0@}^@{2^j-1@} h_j(k) * \bar@{\varphi@}(2^j t-k)
..  @end example
..  @end ifinfo
..  @noindent
..  The functions :math:`\psi` and :math:`\varphi` are related through the
..  coefficients
..  @c{$g_{n} = (-1)^n h_{L-1-n}$}
..  @math{g_@{n@} = (-1)^n h_@{L-1-n@}}
..  for @c{$n=0 \dots L-1$}
..  @math{n=0 ... L-1},
..  where :math:`L` is the total number of coefficients.  The two sets of
..  coefficients :math:`h_j` and :math:`g_i` define the scaling function and
.. the wavelet.  

The resulting family of functions :math:`\{\psi_{j,n}\}`
constitutes an orthonormal basis for square-integrable signals.  
The discrete wavelet transform is an :math:`O(N)` algorithm, and is also
referred to as the *fast wavelet transform*.

.. index:: DWT initialization

Initialization
==============

.. type:: gsl_wavelet

   This structure contains the filter coefficients
   defining the wavelet and any associated offset parameters.

.. function:: gsl_wavelet * gsl_wavelet_alloc (const gsl_wavelet_type * T, size_t k)

   This function allocates and initializes a wavelet object of type
   :data:`T`.  The parameter :data:`k` selects the specific member of the
   wavelet family.  A null pointer is returned if insufficient memory is
   available or if a unsupported member is selected.

The following wavelet types are implemented:

.. type:: gsl_wavelet_type

   .. index::
      single: Daubechies wavelets
      single: maximal phase, Daubechies wavelets

   .. var:: gsl_wavelet_daubechies
            gsl_wavelet_daubechies_centered

      This is the Daubechies wavelet family of maximum phase with :math:`k/2`
      vanishing moments.  The implemented wavelets are 
      :math:`k=4, 6, \dots, 20`, with :data:`k` even.

   .. index:: Haar wavelets

   .. var:: gsl_wavelet_haar
            gsl_wavelet_haar_centered

      This is the Haar wavelet.  The only valid choice of :math:`k` for the
      Haar wavelet is :math:`k=2`.

   .. index::
      single: biorthogonal wavelets
      single: B-spline wavelets

   .. var:: gsl_wavelet_bspline
            gsl_wavelet_bspline_centered

      This is the biorthogonal B-spline wavelet family of order :math:`(i,j)`.  
      The implemented values of :math:`k = 100*i + j` are 103, 105, 202, 204,
      206, 208, 301, 303, 305 307, 309.

The centered forms of the wavelets align the coefficients of the various
sub-bands on edges.  Thus the resulting visualization of the
coefficients of the wavelet transform in the phase plane is easier to
understand.

.. function:: const char * gsl_wavelet_name (const gsl_wavelet * w)

   This function returns a pointer to the name of the wavelet family for
   :data:`w`.

..  @deftypefun {void} gsl_wavelet_print (const gsl_wavelet * w)
..  This function prints the filter coefficients (@code{**h1}, @code{**g1}, @code{**h2}, @code{**g2}) of the wavelet object :data:`w`.
..  @end deftypefun

.. function:: void gsl_wavelet_free (gsl_wavelet * w)

   This function frees the wavelet object :data:`w`.

.. type:: gsl_wavelet_workspace

   This structure contains scratch space of the
   same size as the input data and is used to hold intermediate results
   during the transform.

.. function:: gsl_wavelet_workspace * gsl_wavelet_workspace_alloc (size_t n)

   This function allocates a workspace for the discrete wavelet transform.
   To perform a one-dimensional transform on :data:`n` elements, a workspace
   of size :data:`n` must be provided.  For two-dimensional transforms of
   :data:`n`-by-:data:`n` matrices it is sufficient to allocate a workspace of
   size :data:`n`, since the transform operates on individual rows and
   columns. A null pointer is returned if insufficient memory is available.

.. function:: void gsl_wavelet_workspace_free (gsl_wavelet_workspace * work)

   This function frees the allocated workspace :data:`work`.

Transform Functions
===================

This sections describes the actual functions performing the discrete
wavelet transform.  Note that the transforms use periodic boundary
conditions.  If the signal is not periodic in the sample length then
spurious coefficients will appear at the beginning and end of each level
of the transform.

.. index::
   single: DWT, one dimensional

Wavelet transforms in one dimension
-----------------------------------

.. function:: int gsl_wavelet_transform (const gsl_wavelet * w, double * data, size_t stride, size_t n, gsl_wavelet_direction dir, gsl_wavelet_workspace * work)
              int gsl_wavelet_transform_forward (const gsl_wavelet * w, double * data, size_t stride, size_t n, gsl_wavelet_workspace * work)
              int gsl_wavelet_transform_inverse (const gsl_wavelet * w, double * data, size_t stride, size_t n, gsl_wavelet_workspace * work)

   These functions compute in-place forward and inverse discrete wavelet
   transforms of length :data:`n` with stride :data:`stride` on the array
   :data:`data`. The length of the transform :data:`n` is restricted to powers
   of two.  For the :code:`transform` version of the function the argument
   :data:`dir` can be either :code:`forward` (:math:`+1`) or :code:`backward`
   (:math:`-1`).  A workspace :data:`work` of length :data:`n` must be provided.

   For the forward transform, the elements of the original array are 
   replaced by the discrete wavelet
   transform :math:`f_i \rightarrow w_{j,k}`
   in a packed triangular storage layout, 
   where :data:`j` is the index of the level 
   :math:`j = 0 \dots J-1`
   and
   :data:`k` is the index of the coefficient within each level,
   :math:`k = 0 \dots 2^j - 1`.
   The total number of levels is :math:`J = \log_2(n)`.  The output data
   has the following form,

   .. math:: (s_{-1,0}, d_{0,0}, d_{1,0}, d_{1,1}, d_{2,0},\cdots, d_{j,k},\cdots, d_{J-1,2^{J-1} - 1}) 

   where the first element is the smoothing coefficient :math:`s_{-1,0}`,
   followed by the detail coefficients :math:`d_{j,k}`
   for each level
   :math:`j`.  The backward transform inverts these coefficients to obtain 
   the original data.

   These functions return a status of :macro:`GSL_SUCCESS` upon successful
   completion.  :macro:`GSL_EINVAL` is returned if :data:`n` is not an integer
   power of 2 or if insufficient workspace is provided.

.. index::
   single: DWT, two dimensional

Wavelet transforms in two dimension
-----------------------------------

The library provides functions to perform two-dimensional discrete
wavelet transforms on square matrices.  The matrix dimensions must be an
integer power of two.  There are two possible orderings of the rows and
columns in the two-dimensional wavelet transform, referred to as the
"standard" and "non-standard" forms.

The "standard" transform performs a complete discrete wavelet
transform on the rows of the matrix, followed by a separate complete
discrete wavelet transform on the columns of the resulting
row-transformed matrix.  This procedure uses the same ordering as a
two-dimensional Fourier transform.

The "non-standard" transform is performed in interleaved passes on the
rows and columns of the matrix for each level of the transform.  The
first level of the transform is applied to the matrix rows, and then to
the matrix columns.  This procedure is then repeated across the rows and
columns of the data for the subsequent levels of the transform, until
the full discrete wavelet transform is complete.  The non-standard form
of the discrete wavelet transform is typically used in image analysis.

The functions described in this section are declared in the header file
:file:`gsl_wavelet2d.h`.

.. function:: int gsl_wavelet2d_transform (const gsl_wavelet * w, double * data, size_t tda, size_t size1, size_t size2, gsl_wavelet_direction dir, gsl_wavelet_workspace * work)
              int gsl_wavelet2d_transform_forward (const gsl_wavelet * w, double * data, size_t tda, size_t size1, size_t size2, gsl_wavelet_workspace * work)
              int gsl_wavelet2d_transform_inverse (const gsl_wavelet * w, double * data, size_t tda, size_t size1, size_t size2, gsl_wavelet_workspace * work)

   These functions compute two-dimensional in-place forward and inverse
   discrete wavelet transforms in standard form on the
   array :data:`data` stored in row-major form with dimensions :data:`size1`
   and :data:`size2` and physical row length :data:`tda`.  The dimensions must
   be equal (square matrix) and are restricted to powers of two.  For the
   :code:`transform` version of the function the argument :data:`dir` can be
   either :code:`forward` (:math:`+1`) or :code:`backward` (:math:`-1`).  A
   workspace :data:`work` of the appropriate size must be provided.  On exit,
   the appropriate elements of the array :data:`data` are replaced by their
   two-dimensional wavelet transform.

   The functions return a status of :macro:`GSL_SUCCESS` upon successful
   completion.  :macro:`GSL_EINVAL` is returned if :data:`size1` and
   :data:`size2` are not equal and integer powers of 2, or if insufficient
   workspace is provided.

.. function:: int gsl_wavelet2d_transform_matrix (const gsl_wavelet * w, gsl_matrix * m, gsl_wavelet_direction dir, gsl_wavelet_workspace * work)
              int gsl_wavelet2d_transform_matrix_forward (const gsl_wavelet * w, gsl_matrix * m, gsl_wavelet_workspace * work)
              int gsl_wavelet2d_transform_matrix_inverse (const gsl_wavelet * w, gsl_matrix * m, gsl_wavelet_workspace * work)

   These functions compute the two-dimensional in-place wavelet transform
   on a matrix :data:`m`.

.. function:: int gsl_wavelet2d_nstransform (const gsl_wavelet * w, double * data, size_t tda, size_t size1, size_t size2, gsl_wavelet_direction dir, gsl_wavelet_workspace * work)
              int gsl_wavelet2d_nstransform_forward (const gsl_wavelet * w, double * data, size_t tda, size_t size1, size_t size2, gsl_wavelet_workspace * work)
              int gsl_wavelet2d_nstransform_inverse (const gsl_wavelet * w, double * data, size_t tda, size_t size1, size_t size2, gsl_wavelet_workspace * work)

   These functions compute the two-dimensional wavelet transform in
   non-standard form.

.. function:: int gsl_wavelet2d_nstransform_matrix (const gsl_wavelet * w, gsl_matrix * m, gsl_wavelet_direction dir, gsl_wavelet_workspace * work)
              int gsl_wavelet2d_nstransform_matrix_forward (const gsl_wavelet * w, gsl_matrix * m, gsl_wavelet_workspace * work)
              int gsl_wavelet2d_nstransform_matrix_inverse (const gsl_wavelet * w, gsl_matrix * m, gsl_wavelet_workspace * work)

   These functions compute the non-standard form of the two-dimensional
   in-place wavelet transform on a matrix :data:`m`.

Examples
========

The following program demonstrates the use of the one-dimensional
wavelet transform functions.  It computes an approximation to an input
signal (of length 256) using the 20 largest components of the wavelet
transform, while setting the others to zero.

.. include:: examples/dwt.c
   :code:

The output can be used with the GNU plotutils :code:`graph` program::

  $ ./a.out ecg.dat > dwt.txt
  $ graph -T ps -x 0 256 32 -h 0.3 -a dwt.txt > dwt.ps

:numref:`fig_dwt` shows an original and compressed version of a sample ECG
recording from the MIT-BIH Arrhythmia Database, part of the PhysioNet
archive of public-domain of medical datasets.

.. _fig_dwt:

.. figure:: /images/dwt.png
   :scale: 60%

   Original (upper) and wavelet-compressed (lower) ECG signals, using the
   20 largest components of the Daubechies(4) discrete wavelet transform.

References and Further Reading
==============================

The mathematical background to wavelet transforms is covered in the
original lectures by Daubechies,

* Ingrid Daubechies.
  Ten Lectures on Wavelets.
  *CBMS-NSF Regional Conference Series in Applied Mathematics* (1992), 
  SIAM, ISBN 0898712742.

An easy to read introduction to the subject with an emphasis on the
application of the wavelet transform in various branches of science is,

* Paul S. Addison. *The Illustrated Wavelet Transform Handbook*.
  Institute of Physics Publishing (2002), ISBN 0750306920.

For extensive coverage of signal analysis by wavelets, wavelet packets
and local cosine bases see,

* S. G. Mallat. *A wavelet tour of signal processing* (Second
  edition). Academic Press (1999), ISBN 012466606X.

The concept of multiresolution analysis underlying the wavelet transform
is described in,

* S. G. Mallat.
  Multiresolution Approximations and Wavelet Orthonormal Bases of L^2(R).
  *Transactions of the American Mathematical Society*, 315(1), 1989, 69--87.

* S. G. Mallat.
  A Theory for Multiresolution Signal Decomposition---The Wavelet Representation.
  *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 11, 1989,
  674--693. 

The coefficients for the individual wavelet families implemented by the
library can be found in the following papers,

* I. Daubechies.
  Orthonormal Bases of Compactly Supported Wavelets.
  *Communications on Pure and Applied Mathematics*, 41 (1988) 909--996.

* A. Cohen, I. Daubechies, and J.-C. Feauveau.
  Biorthogonal Bases of Compactly Supported Wavelets.
  *Communications on Pure and Applied Mathematics*, 45 (1992)
  485--560.

The PhysioNet archive of physiological datasets can be found online at
http://www.physionet.org/ and is described in the following
paper,

* Goldberger et al.  
  PhysioBank, PhysioToolkit, and PhysioNet: Components
  of a New Research Resource for Complex Physiologic
  Signals. 
  *Circulation* 101(23):e215-e220 2000.
.. index::
   single: root finding
   single: zero finding
   single: finding roots
   single: finding zeros
   single: roots
   single: solving a nonlinear equation
   single: nonlinear equation, solutions of

****************************
One Dimensional Root-Finding
****************************

This chapter describes routines for finding roots of arbitrary
one-dimensional functions.  The library provides low level components
for a variety of iterative solvers and convergence tests.  These can be
combined by the user to achieve the desired solution, with full access
to the intermediate steps of the iteration.  Each class of methods uses
the same framework, so that you can switch between solvers at runtime
without needing to recompile your program.  Each instance of a solver
keeps track of its own state, allowing the solvers to be used in
multi-threaded programs.

The header file :file:`gsl_roots.h` contains prototypes for the root
finding functions and related declarations.

.. index::
   single: root finding, overview

Overview
========

One-dimensional root finding algorithms can be divided into two classes,
*root bracketing* and *root polishing*.  Algorithms which proceed
by bracketing a root are guaranteed to converge.  Bracketing algorithms
begin with a bounded region known to contain a root.  The size of this
bounded region is reduced, iteratively, until it encloses the root to a
desired tolerance.  This provides a rigorous error estimate for the
location of the root.

The technique of *root polishing* attempts to improve an initial
guess to the root.  These algorithms converge only if started "close
enough" to a root, and sacrifice a rigorous error bound for speed.  By
approximating the behavior of a function in the vicinity of a root they
attempt to find a higher order improvement of an initial guess.  When the
behavior of the function is compatible with the algorithm and a good
initial guess is available a polishing algorithm can provide rapid
convergence.

In GSL both types of algorithm are available in similar frameworks.  The
user provides a high-level driver for the algorithms, and the library
provides the individual functions necessary for each of the steps.
There are three main phases of the iteration.  The steps are,

* initialize solver state, :data:`s`, for algorithm :data:`T`

* update :data:`s` using the iteration :data:`T`

* test :data:`s` for convergence, and repeat iteration if necessary

The state for bracketing solvers is held in a :type:`gsl_root_fsolver`
struct.  The updating procedure uses only function evaluations (not
derivatives).  The state for root polishing solvers is held in a
:type:`gsl_root_fdfsolver` struct.  The updates require both the function
and its derivative (hence the name :code:`fdf`) to be supplied by the
user.

.. index::
   single: root finding, caveats

Caveats
=======

Note that root finding functions can only search for one root at a time.
When there are several roots in the search area, the first root to be
found will be returned; however it is difficult to predict which of the
roots this will be. *In most cases, no error will be reported if
you try to find a root in an area where there is more than one.*

Care must be taken when a function may have a multiple root (such as 
:math:`f(x) = (x-x_0)^2` or
:math:`f(x) = (x-x_0)^3`.
It is not possible to use root-bracketing algorithms on
even-multiplicity roots.  For these algorithms the initial interval must
contain a zero-crossing, where the function is negative at one end of
the interval and positive at the other end.  Roots with even-multiplicity
do not cross zero, but only touch it instantaneously.  Algorithms based
on root bracketing will still work for odd-multiplicity roots
(e.g. cubic, quintic, ...). 
Root polishing algorithms generally work with higher multiplicity roots,
but at a reduced rate of convergence.  In these cases the *Steffenson
algorithm* can be used to accelerate the convergence of multiple roots.

While it is not absolutely required that :math:`f` have a root within the
search region, numerical root finding functions should not be used
haphazardly to check for the *existence* of roots.  There are better
ways to do this.  Because it is easy to create situations where numerical
root finders can fail, it is a bad idea to throw a root finder at a
function you do not know much about.  In general it is best to examine
the function visually by plotting before searching for a root.

Initializing the Solver
=======================

.. type:: gsl_root_fsolver

   This is a workspace for finding roots using methods which do not require
   derivatives.

.. type:: gsl_root_fdfsolver

   This is a workspace for finding roots using methods which require
   derivatives.

.. function:: gsl_root_fsolver * gsl_root_fsolver_alloc (const gsl_root_fsolver_type * T)

   This function returns a pointer to a newly allocated instance of a
   solver of type :data:`T`.  For example, the following code creates an
   instance of a bisection solver::

      const gsl_root_fsolver_type * T = gsl_root_fsolver_bisection;
      gsl_root_fsolver * s = gsl_root_fsolver_alloc (T);

   If there is insufficient memory to create the solver then the function
   returns a null pointer and the error handler is invoked with an error
   code of :macro:`GSL_ENOMEM`.

.. function:: gsl_root_fdfsolver * gsl_root_fdfsolver_alloc (const gsl_root_fdfsolver_type * T)

   This function returns a pointer to a newly allocated instance of a
   derivative-based solver of type :data:`T`.  For example, the following
   code creates an instance of a Newton-Raphson solver::

      const gsl_root_fdfsolver_type * T = gsl_root_fdfsolver_newton;
      gsl_root_fdfsolver * s = gsl_root_fdfsolver_alloc (T);

   If there is insufficient memory to create the solver then the function
   returns a null pointer and the error handler is invoked with an error
   code of :macro:`GSL_ENOMEM`.

.. function:: int gsl_root_fsolver_set (gsl_root_fsolver * s, gsl_function * f, double x_lower, double x_upper)

   This function initializes, or reinitializes, an existing solver :data:`s`
   to use the function :data:`f` and the initial search interval
   [:data:`x_lower`, :data:`x_upper`].

.. function:: int gsl_root_fdfsolver_set (gsl_root_fdfsolver * s, gsl_function_fdf * fdf, double root)

   This function initializes, or reinitializes, an existing solver :data:`s`
   to use the function and derivative :data:`fdf` and the initial guess
   :data:`root`.

.. function:: void gsl_root_fsolver_free (gsl_root_fsolver * s)
              void gsl_root_fdfsolver_free (gsl_root_fdfsolver * s)

   These functions free all the memory associated with the solver :data:`s`.

.. function:: const char * gsl_root_fsolver_name (const gsl_root_fsolver * s)
              const char * gsl_root_fdfsolver_name (const gsl_root_fdfsolver * s)

   These functions return a pointer to the name of the solver.  For example::

      printf ("s is a '%s' solver\n", gsl_root_fsolver_name (s));

   would print something like :code:`s is a 'bisection' solver`.

.. index::
   single: root finding, providing a function to solve

.. _providing-function-to-solve:

Providing the function to solve
===============================

You must provide a continuous function of one variable for the root
finders to operate on, and, sometimes, its first derivative.  In order
to allow for general parameters the functions are defined by the
following data types:

.. type:: gsl_function 

   This data type defines a general function with parameters. 

   :code:`double (* function) (double x, void * params)`

      this function should return the value
      :math:`f(x,params)` for argument :data:`x` and parameters :data:`params`

   :code:`void * params`

      a pointer to the parameters of the function

Here is an example for the general quadratic function,

.. math:: f(x) = a x^2 + b x + c

with :math:`a = 3`, :math:`b = 2`, :math:`c = 1`.  The following code
defines a :type:`gsl_function` :code:`F` which you could pass to a root
finder as a function pointer::

  struct my_f_params { double a; double b; double c; };

  double
  my_f (double x, void * p)
    {
      struct my_f_params * params = (struct my_f_params *)p;
      double a = (params->a);
      double b = (params->b);
      double c = (params->c);

      return  (a * x + b) * x + c;
    }

  gsl_function F;
  struct my_f_params params = { 3.0, 2.0, 1.0 };

  F.function = &my_f;
  F.params = &params;

The function :math:`f(x)` can be evaluated using the macro
:code:`GSL_FN_EVAL(&F,x)` defined in :file:`gsl_math.h`.

.. type:: gsl_function_fdf

   This data type defines a general function with parameters and its first
   derivative.

   :code:`double (* f) (double x, void * params)`

      this function should return the value of
      :math:`f(x,params)` for argument :data:`x` and parameters :data:`params`

   :code:`double (* df) (double x, void * params)`

      this function should return the value of the derivative of :data:`f` with
      respect to :data:`x`,
      :math:`f'(x,params)`, for argument :data:`x` and parameters :data:`params`

   :code:`void (* fdf) (double x, void * params, double * f, double * df)`

      this function should set the values of the function :data:`f` to 
      :math:`f(x,params)`
      and its derivative :data:`df` to
      :math:`f'(x,params)`
      for argument :data:`x` and parameters :data:`params`.  This function
      provides an optimization of the separate functions for :math:`f(x)` and
      :math:`f'(x)`---it is always faster to compute the function and its
      derivative at the same time.

   :code:`void * params`

      a pointer to the parameters of the function

Here is an example where 
:math:`f(x) = \exp(2x)`::

  double
  my_f (double x, void * params)
  {
     return exp (2 * x);
  }

  double
  my_df (double x, void * params)
  {
     return 2 * exp (2 * x);
  }

  void
  my_fdf (double x, void * params, 
          double * f, double * df)
  {
     double t = exp (2 * x);

     *f = t;
     *df = 2 * t;   /* uses existing value */
  }

  gsl_function_fdf FDF;

  FDF.f = &my_f;
  FDF.df = &my_df;
  FDF.fdf = &my_fdf;
  FDF.params = 0;

The function :math:`f(x)` can be evaluated using the macro
:code:`GSL_FN_FDF_EVAL_F(&FDF,x)` and the derivative :math:`f'(x)` can
be evaluated using the macro :code:`GSL_FN_FDF_EVAL_DF(&FDF,x)`.  Both
the function :math:`y = f(x)` and its derivative :math:`dy = f'(x)` can
be evaluated at the same time using the macro
:code:`GSL_FN_FDF_EVAL_F_DF(&FDF,x,y,dy)`.  The macro stores
:math:`f(x)` in its :data:`y` argument and :math:`f'(x)` in its :data:`dy`
argument---both of these should be pointers to :code:`double`.

.. index::
   single: root finding, search bounds
   single: root finding, initial guess

Search Bounds and Guesses
=========================

You provide either search bounds or an initial guess; this section
explains how search bounds and guesses work and how function arguments
control them.

A guess is simply an :math:`x` value which is iterated until it is within
the desired precision of a root.  It takes the form of a :code:`double`.

Search bounds are the endpoints of an interval which is iterated until
the length of the interval is smaller than the requested precision.  The
interval is defined by two values, the lower limit and the upper limit.
Whether the endpoints are intended to be included in the interval or not
depends on the context in which the interval is used.

Iteration
=========

The following functions drive the iteration of each algorithm.  Each
function performs one iteration to update the state of any solver of the
corresponding type.  The same functions work for all solvers so that
different methods can be substituted at runtime without modifications to
the code.

.. function:: int gsl_root_fsolver_iterate (gsl_root_fsolver * s)
              int gsl_root_fdfsolver_iterate (gsl_root_fdfsolver * s)

   These functions perform a single iteration of the solver :data:`s`.  If the
   iteration encounters an unexpected problem then an error code will be
   returned,

   :code:`GSL_EBADFUNC`

      the iteration encountered a singular point where the function or its
      derivative evaluated to :code:`Inf` or :code:`NaN`.

   :code:`GSL_EZERODIV`

      the derivative of the function vanished at the iteration point,
      preventing the algorithm from continuing without a division by zero.

The solver maintains a current best estimate of the root at all
times.  The bracketing solvers also keep track of the current best
interval bounding the root.  This information can be accessed with the
following auxiliary functions,

.. function:: double gsl_root_fsolver_root (const gsl_root_fsolver * s)
              double gsl_root_fdfsolver_root (const gsl_root_fdfsolver * s)

   These functions return the current estimate of the root for the solver :data:`s`.

.. function:: double gsl_root_fsolver_x_lower (const gsl_root_fsolver * s)
              double gsl_root_fsolver_x_upper (const gsl_root_fsolver * s)

   These functions return the current bracketing interval for the solver :data:`s`.

.. index::
   single: root finding, stopping parameters

Search Stopping Parameters
==========================

A root finding procedure should stop when one of the following conditions is
true:

* A root has been found to within the user-specified precision.
* A user-specified maximum number of iterations has been reached.
* An error has occurred.

The handling of these conditions is under user control.  The functions
below allow the user to test the precision of the current result in
several standard ways.

.. function:: int gsl_root_test_interval (double x_lower, double x_upper, double epsabs, double epsrel)

   This function tests for the convergence of the interval [:data:`x_lower`,
   :data:`x_upper`] with absolute error :data:`epsabs` and relative error
   :data:`epsrel`.  The test returns :macro:`GSL_SUCCESS` if the following
   condition is achieved,

   .. only:: not texinfo

      .. math:: |a - b| < \hbox{\it epsabs} + \hbox{\it epsrel\/}\, \min(|a|,|b|)

   .. only:: texinfo

      ::

         |a - b| < epsabs + epsrel min(|a|,|b|) 

   when the interval :math:`x = [a,b]` does not include the origin.  If the
   interval includes the origin then :math:`\min(|a|,|b|)` is replaced by
   zero (which is the minimum value of :math:`|x|` over the interval).  This
   ensures that the relative error is accurately estimated for roots close
   to the origin.

   This condition on the interval also implies that any estimate of the
   root :math:`r` in the interval satisfies the same condition with respect
   to the true root :math:`r^*`,

   .. only:: not texinfo

      .. math:: |r - r^*| < \hbox{\it epsabs} + \hbox{\it epsrel\/}\, r^*

   .. only:: texinfo

      ::

         |r - r^*| < epsabs + epsrel r^*

   assuming that the true root :math:`r^*` is contained within the interval.

.. function:: int gsl_root_test_delta (double x1, double x0, double epsabs, double epsrel)

   This function tests for the convergence of the sequence :data:`x0`,
   :data:`x1` with absolute error :data:`epsabs` and relative error
   :data:`epsrel`.  The test returns :macro:`GSL_SUCCESS` if the following
   condition is achieved,

   .. only:: not texinfo

      .. math:: |x_1 - x_0| < \hbox{\it epsabs} + \hbox{\it epsrel\/}\, |x_1|

   .. only:: texinfo

      ::

         |x_1 - x_0| < epsabs + epsrel |x_1|

   and returns :macro:`GSL_CONTINUE` otherwise.

.. function:: int gsl_root_test_residual (double f, double epsabs)

   This function tests the residual value :data:`f` against the absolute
   error bound :data:`epsabs`.  The test returns :macro:`GSL_SUCCESS` if the
   following condition is achieved,

   .. only:: not texinfo

      .. math:: |f| < \hbox{\it epsabs}

   .. only:: texinfo

      ::

         |f| < epsabs

   and returns :macro:`GSL_CONTINUE` otherwise.  This criterion is suitable
   for situations where the precise location of the root, :math:`x`, is
   unimportant provided a value can be found where the residual,
   :math:`|f(x)|`, is small enough.

Root Bracketing Algorithms
==========================

The root bracketing algorithms described in this section require an
initial interval which is guaranteed to contain a root---if :math:`a`
and :math:`b` are the endpoints of the interval then :math:`f(a)` must
differ in sign from :math:`f(b)`.  This ensures that the function crosses
zero at least once in the interval.  If a valid initial interval is used
then these algorithm cannot fail, provided the function is well-behaved.

Note that a bracketing algorithm cannot find roots of even degree, since
these do not cross the :math:`x`-axis.

.. type:: gsl_root_fsolver_type

   .. index::
      single: bisection algorithm for finding roots
      single: root finding, bisection algorithm

   .. var:: gsl_root_fsolver_bisection

      The *bisection algorithm* is the simplest method of bracketing the
      roots of a function.   It is the slowest algorithm provided by
      the library, with linear convergence.

      On each iteration, the interval is bisected and the value of the
      function at the midpoint is calculated.  The sign of this value is used
      to determine which half of the interval does not contain a root.  That
      half is discarded to give a new, smaller interval containing the
      root.  This procedure can be continued indefinitely until the interval is
      sufficiently small.

      At any time the current estimate of the root is taken as the midpoint of
      the interval.

      .. eps file "roots-bisection.eps"
      .. @iftex
      .. @sp 1
      .. @center @image{roots-bisection,3.4in}

      .. @quotation
      .. Four iterations of bisection, where :math:`a_n` is :math:`n`-th position of
      .. the beginning of the interval and :math:`b_n` is the :math:`n`-th position
      .. of the end.  The midpoint of each interval is also indicated.
      .. @end quotation
      .. @end iftex

   .. index::
      single: false position algorithm for finding roots
      single: root finding, false position algorithm

   .. var:: gsl_root_fsolver_falsepos

      The *false position algorithm* is a method of finding roots based on
      linear interpolation.  Its convergence is linear, but it is usually
      faster than bisection.

      On each iteration a line is drawn between the endpoints :math:`(a,f(a))`
      and :math:`(b,f(b))` and the point where this line crosses the
      :math:`x`-axis taken as a "midpoint".  The value of the function at
      this point is calculated and its sign is used to determine which side of
      the interval does not contain a root.  That side is discarded to give a
      new, smaller interval containing the root.  This procedure can be
      continued indefinitely until the interval is sufficiently small.

      The best estimate of the root is taken from the linear interpolation of
      the interval on the current iteration.

      .. eps file "roots-false-position.eps"
      .. @iftex
      .. @image{roots-false-position,4in}
      .. @quotation
      .. Several iterations of false position, where :math:`a_n` is :math:`n`-th
      .. position of the beginning of the interval and :math:`b_n` is the
      .. :math:`n`-th position of the end.
      .. @end quotation
      .. @end iftex

   .. index::
      single: Brent's method for finding roots
      single: root finding, Brent's method

   .. var:: gsl_root_fsolver_brent

      The *Brent-Dekker method* (referred to here as *Brent's method*)
      combines an interpolation strategy with the bisection algorithm.  This
      produces a fast algorithm which is still robust.

      On each iteration Brent's method approximates the function using an
      interpolating curve.  On the first iteration this is a linear
      interpolation of the two endpoints.  For subsequent iterations the
      algorithm uses an inverse quadratic fit to the last three points, for
      higher accuracy.  The intercept of the interpolating curve with the
      :math:`x`-axis is taken as a guess for the root.  If it lies within the
      bounds of the current interval then the interpolating point is accepted,
      and used to generate a smaller interval.  If the interpolating point is
      not accepted then the algorithm falls back to an ordinary bisection
      step.

      The best estimate of the root is taken from the most recent
      interpolation or bisection.

Root Finding Algorithms using Derivatives
=========================================

The root polishing algorithms described in this section require an
initial guess for the location of the root.  There is no absolute
guarantee of convergence---the function must be suitable for this
technique and the initial guess must be sufficiently close to the root
for it to work.  When these conditions are satisfied then convergence is
quadratic.

These algorithms make use of both the function and its derivative. 

.. type:: gsl_root_fdfsolver_type

   .. index::
      single: Newton's method for finding roots
      single: root finding, Newton's method

   .. var:: gsl_root_fdfsolver_newton

      Newton's Method is the standard root-polishing algorithm.  The algorithm
      begins with an initial guess for the location of the root.  On each
      iteration, a line tangent to the function :math:`f` is drawn at that
      position.  The point where this line crosses the :math:`x`-axis becomes
      the new guess.  The iteration is defined by the following sequence,

      .. only:: not texinfo

         .. math:: x_{i+1} = x_i - {f(x_i) \over f'(x_i)}

      .. only:: texinfo

         ::

            x_{i+1} = x_i - f(x_i)/f'(x_i)

      Newton's method converges quadratically for single roots, and linearly
      for multiple roots.

      .. eps file "roots-newtons-method.eps"
      .. @iftex
      .. @sp 1
      .. @center @image{roots-newtons-method,3.4in}

      .. @quotation
      .. Several iterations of Newton's Method, where :math:`g_n` is the
      .. :math:`n`-th guess.
      .. @end quotation
      .. @end iftex

   .. index::
      single: secant method for finding roots
      single: root finding, secant method

   .. var:: gsl_root_fdfsolver_secant

      The *secant method* is a simplified version of Newton's method which does
      not require the computation of the derivative on every step.

      On its first iteration the algorithm begins with Newton's method, using
      the derivative to compute a first step,

      .. only:: not texinfo

         .. math:: x_1 = x_0 - {f(x_0) \over f'(x_0)}

      .. only:: texinfo

         ::

            x_1 = x_0 - f(x_0)/f'(x_0)

      Subsequent iterations avoid the evaluation of the derivative by
      replacing it with a numerical estimate, the slope of the line through
      the previous two points,

      .. only:: not texinfo

         .. math::

            x_{i+1} = x_i - {f(x_i) \over f'_{est}}
             ~\hbox{where}~
             f'_{est} =  {f(x_{i}) - f(x_{i-1}) \over x_i - x_{i-1}}

      .. only:: texinfo
      
         ::

            x_{i+1} = x_i f(x_i) / f'_{est} where
             f'_{est} = (f(x_i) - f(x_{i-1})/(x_i - x_{i-1})

      When the derivative does not change significantly in the vicinity of the
      root the secant method gives a useful saving.  Asymptotically the secant
      method is faster than Newton's method whenever the cost of evaluating
      the derivative is more than 0.44 times the cost of evaluating the
      function itself.  As with all methods of computing a numerical
      derivative the estimate can suffer from cancellation errors if the
      separation of the points becomes too small.

      On single roots, the method has a convergence of order :math:`(1 + \sqrt
      5)/2` (approximately :math:`1.62`).  It converges linearly for multiple
      roots.  

      .. eps file "roots-secant-method.eps"
      .. @iftex
      .. @tex
      .. \input epsf
      .. \medskip
      .. \centerline{\epsfxsize=5in\epsfbox{roots-secant-method.eps}}
      .. @end tex
      .. @quotation
      .. Several iterations of Secant Method, where :math:`g_n` is the :math:`n`-th
      .. guess.
      .. @end quotation
      .. @end iftex

   .. index::
      single: Steffenson's method for finding roots
      single: root finding, Steffenson's method

   .. var:: gsl_root_fdfsolver_steffenson

      The *Steffenson Method* [#f1]_
      provides the fastest
      convergence of all the routines.  It combines the basic Newton
      algorithm with an Aitken "delta-squared" acceleration.  If the
      Newton iterates are :math:`x_i` then the acceleration procedure
      generates a new sequence :math:`R_i`,

      .. only:: not texinfo

         .. math:: R_i = x_i - {(x_{i+1} - x_i)^2 \over (x_{i+2} - 2 x_{i+1} + x_i)}

      .. only:: texinfo

         ::

            R_i = x_i - (x_{i+1} - x_i)^2 / (x_{i+2} - 2 x_{i+1} + x_{i})

      which converges faster than the original sequence under reasonable
      conditions.  The new sequence requires three terms before it can produce
      its first value so the method returns accelerated values on the second
      and subsequent iterations.  On the first iteration it returns the
      ordinary Newton estimate.  The Newton iterate is also returned if the
      denominator of the acceleration term ever becomes zero.

      As with all acceleration procedures this method can become unstable if
      the function is not well-behaved. 

Examples
========

For any root finding algorithm we need to prepare the function to be
solved.  For this example we will use the general quadratic equation
described earlier.  We first need a header file (:file:`demo_fn.h`) to
define the function parameters,

.. include:: examples/demo_fn.h
   :code:

We place the function definitions in a separate file (:file:`demo_fn.c`),

.. include:: examples/demo_fn.c
   :code:

The first program uses the function solver :data:`gsl_root_fsolver_brent`
for Brent's method and the general quadratic defined above to solve the
following equation,

.. math:: x^2 - 5 = 0

with solution :math:`x = \sqrt 5 = 2.236068...`

.. include:: examples/roots.c
   :code:

Here are the results of the iterations::

  $ ./a.out 
  using brent method
   iter [    lower,     upper]      root        err  err(est)
      1 [1.0000000, 5.0000000] 1.0000000 -1.2360680 4.0000000
      2 [1.0000000, 3.0000000] 3.0000000 +0.7639320 2.0000000
      3 [2.0000000, 3.0000000] 2.0000000 -0.2360680 1.0000000
      4 [2.2000000, 3.0000000] 2.2000000 -0.0360680 0.8000000
      5 [2.2000000, 2.2366300] 2.2366300 +0.0005621 0.0366300
  Converged:                            
      6 [2.2360634, 2.2366300] 2.2360634 -0.0000046 0.0005666

If the program is modified to use the bisection solver instead of
Brent's method, by changing :data:`gsl_root_fsolver_brent` to
:data:`gsl_root_fsolver_bisection` the slower convergence of the
Bisection method can be observed::

  $ ./a.out 
  using bisection method
   iter [    lower,     upper]      root        err  err(est)
      1 [0.0000000, 2.5000000] 1.2500000 -0.9860680 2.5000000
      2 [1.2500000, 2.5000000] 1.8750000 -0.3610680 1.2500000
      3 [1.8750000, 2.5000000] 2.1875000 -0.0485680 0.6250000
      4 [2.1875000, 2.5000000] 2.3437500 +0.1076820 0.3125000
      5 [2.1875000, 2.3437500] 2.2656250 +0.0295570 0.1562500
      6 [2.1875000, 2.2656250] 2.2265625 -0.0095055 0.0781250
      7 [2.2265625, 2.2656250] 2.2460938 +0.0100258 0.0390625
      8 [2.2265625, 2.2460938] 2.2363281 +0.0002601 0.0195312
      9 [2.2265625, 2.2363281] 2.2314453 -0.0046227 0.0097656
     10 [2.2314453, 2.2363281] 2.2338867 -0.0021813 0.0048828
     11 [2.2338867, 2.2363281] 2.2351074 -0.0009606 0.0024414
  Converged:                            
     12 [2.2351074, 2.2363281] 2.2357178 -0.0003502 0.0012207

The next program solves the same function using a derivative solver
instead.

.. include:: examples/rootnewt.c
   :code:

Here are the results for Newton's method::

  $ ./a.out 
  using newton method
  iter        root        err   err(est)
      1  3.0000000 +0.7639320 -2.0000000
      2  2.3333333 +0.0972654 -0.6666667
      3  2.2380952 +0.0020273 -0.0952381
  Converged:      
      4  2.2360689 +0.0000009 -0.0020263

Note that the error can be estimated more accurately by taking the
difference between the current iterate and next iterate rather than the
previous iterate.  The other derivative solvers can be investigated by
changing :data:`gsl_root_fdfsolver_newton` to
:data:`gsl_root_fdfsolver_secant` or
:data:`gsl_root_fdfsolver_steffenson`.

References and Further Reading
==============================

For information on the Brent-Dekker algorithm see the following two
papers,

* R. P. Brent, "An algorithm with guaranteed convergence for finding a
  zero of a function", *Computer Journal*, 14 (1971) 422--425

* J. C. P. Bus and T. J. Dekker, "Two Efficient Algorithms with Guaranteed
  Convergence for Finding a Zero of a Function", *ACM Transactions of
  Mathematical Software*, Vol.: 1 No.: 4 (1975) 330--345

.. rubric:: Footnotes

.. [#f1] J.F. Steffensen (1873--1961). The spelling used in the name of the
         function is slightly incorrect, but has been preserved to avoid incompatibility.
**************************
GNU General Public License
**************************

.. literalinclude:: _static/gpl.txt
.. index::
   single: Jacobi elliptic functions
   single: elliptic functions (Jacobi)

The Jacobian Elliptic functions are defined in Abramowitz & Stegun,
Chapter 16.  The functions are declared in the header file
:file:`gsl_sf_elljac.h`.

.. function:: int gsl_sf_elljac_e (double u, double m, double * sn, double * cn, double * dn)

   This function computes the Jacobian elliptic functions :math:`sn(u|m)`,
   :math:`cn(u|m)`, :math:`dn(u|m)` by descending Landen
   transformations.
.. Exceptional Return Values: GSL_EDOM
.. index::
   single: sparse matrices
   single: matrices, sparse

***************
Sparse Matrices
***************

This chapter describes functions for the construction and
manipulation of sparse matrices, matrices which are populated
primarily with zeros and contain only a few non-zero elements.
Sparse matrices often appear in the solution of partial
differential equations. It is beneficial to use specialized
data structures and algorithms for storing and working with
sparse matrices, since dense matrix algorithms and structures
can be very slow and use huge amounts of memory when applied
to sparse matrices.

The header file :file:`gsl_spmatrix.h` contains the prototypes for the
sparse matrix functions and related declarations.

.. index::
   single: sparse matrices, overview

Overview
========

These routines provide support for constructing and manipulating
sparse matrices in GSL, using an API similar to :type:`gsl_matrix`.
The basic structure is called :type:`gsl_spmatrix`. There are
three supported storage formats for sparse matrices: the triplet,
compressed column storage (CCS) and compressed row storage (CRS)
formats. The triplet format stores triplets :math:`(i,j,x)` for each
non-zero element of the matrix. This notation means that the
:math:`(i,j)` element of the matrix :math:`A`
is :math:`A_{ij} = x`. Compressed column storage stores each column of
non-zero values in the sparse matrix in a continuous memory block, keeping
pointers to the beginning of each column in that memory block, and storing
the row indices of each non-zero element. Compressed row storage stores
each row of non-zero values in a continuous memory block, keeping pointers
to the beginning of each row in the block and storing the column indices
of each non-zero element. The triplet format is ideal
for adding elements to the sparse matrix structure while it is being
constructed, while the compressed storage formats are better suited for
matrix-matrix multiplication or linear solvers.

.. type:: gsl_spmatrix

   This structure is defined as::

      typedef struct
      {
        size_t size1;
        size_t size2;
        size_t *i;
        double *data;
        size_t *p;
        size_t nzmax;
        size_t nz;
        gsl_spmatrix_tree *tree_data;
        void *work;
        size_t sptype;
      } gsl_spmatrix;

   This defines a :data:`size1`-by-:data:`size2` sparse matrix. The number of non-zero
   elements currently in the matrix is given by :data:`nz`. For the triplet
   representation, :data:`i`, :data:`p`, and :data:`data` are arrays of size :data:`nz`
   which contain the row indices, column indices, and element value, respectively.
   So if :math:`data[k] = A(i,j)`, then :math:`i = i[k]` and :math:`j = p[k]`.

   For compressed column storage, :data:`i` and :data:`data` are arrays of size
   :data:`nz` containing the row indices and element values, identical to the triplet
   case. :data:`p` is an array of size :data:`size2` + 1 where :code:`p[j]` points
   to the index in :data:`data` of the start of column :data:`j`. Thus, if
   :math:`data[k] = A(i,j)`, then :math:`i = i[k]` and :math:`p[j] <= k < p[j+1]`.

   For compressed row storage, :data:`i` and :data:`data` are arrays of size
   :data:`nz` containing the column indices and element values, identical to the triplet
   case. :data:`p` is an array of size :data:`size1` + 1 where :code:`p[i]` points
   to the index in :data:`data` of the start of row :data:`i`. Thus, if
   :math:`data[k] = A(i,j)`, then :math:`j = i[k]` and :math:`p[i] <= k < p[i+1]`.

   The parameter :data:`tree_data` is a binary tree structure used in the triplet
   representation, specifically a balanced AVL tree. This speeds up element
   searches and duplicate detection during the matrix assembly process.
   The parameter :data:`work` is additional workspace needed for various operations like
   converting from triplet to compressed storage. :data:`sptype` indicates
   the type of storage format being used (triplet, CCS or CRS).

   The compressed storage format defined above makes it very simple
   to interface with sophisticated external linear solver libraries
   which accept compressed storage input. The user can simply
   pass the arrays :data:`i`, :data:`p`, and :data:`data` as the
   inputs to external libraries.

.. index::
   single: sparse matrices, allocation

Allocation
==========

The functions for allocating memory for a sparse matrix follow the style of
:func:`malloc` and :func:`free`. They also perform their own error checking. If
there is insufficient memory available to allocate a matrix then the functions
call the GSL error handler with an error code of :macro:`GSL_ENOMEM` in addition
to returning a null pointer.

.. function:: gsl_spmatrix * gsl_spmatrix_alloc (const size_t n1, const size_t n2)

   This function allocates a sparse matrix of size :data:`n1`-by-:data:`n2` and
   initializes it to all zeros. If the size of the matrix is not known at allocation
   time, both :data:`n1` and :data:`n2` may be set to 1, and they will automatically
   grow as elements are added to the matrix. This function sets the
   matrix to the triplet representation, which is the easiest for adding
   and accessing matrix elements. This function tries to make a reasonable guess
   for the number of non-zero elements (:data:`nzmax`) which will be added to the matrix by
   assuming a sparse density of :math:`10\%`. The function
   :func:`gsl_spmatrix_alloc_nzmax` can be used if this number is known more
   accurately. The workspace is of size :math:`O(nzmax)`.

.. function:: gsl_spmatrix * gsl_spmatrix_alloc_nzmax (const size_t n1, const size_t n2, const size_t nzmax, const size_t sptype)

   This function allocates a sparse matrix of size :data:`n1`-by-:data:`n2` and
   initializes it to all zeros. If the size of the matrix is not known at allocation
   time, both :data:`n1` and :data:`n2` may be set to 1, and they will automatically
   grow as elements are added to the matrix. The parameter :data:`nzmax` specifies
   the maximum number of non-zero elements which will be added to the matrix.
   It does not need to be precisely known in advance, since storage space will 
   automatically grow using :func:`gsl_spmatrix_realloc` if :data:`nzmax` is not
   large enough. Accurate knowledge of this parameter reduces the number of
   reallocation calls required. The parameter :data:`sptype` specifies the
   storage format of the sparse matrix. Possible values are

   .. macro:: GSL_SPMATRIX_TRIPLET

      This flag specifies triplet storage.

   .. macro:: GSL_SPMATRIX_CCS

      This flag specifies compressed column storage.

   .. macro:: GSL_SPMATRIX_CRS

      This flag specifies compressed row storage.

   The allocated :type:`gsl_spmatrix` structure is of size :math:`O(nzmax)`.

.. function:: int gsl_spmatrix_realloc (const size_t nzmax, gsl_spmatrix * m)

   This function reallocates the storage space for :data:`m` to accomodate
   :data:`nzmax` non-zero elements. It is typically called internally by
   :func:`gsl_spmatrix_set` if the user wants to add more elements to the
   sparse matrix than the previously specified :data:`nzmax`.

.. function:: void gsl_spmatrix_free (gsl_spmatrix * m)

   This function frees the memory associated with the sparse matrix :data:`m`.

.. index::
   single: sparse matrices, accessing elements

Accessing Matrix Elements
=========================

.. function:: double gsl_spmatrix_get (const gsl_spmatrix * m, const size_t i, const size_t j)

   This function returns element (:data:`i`, :data:`j`) of the matrix :data:`m`.
   The matrix may be in triplet or compressed format.

.. function:: int gsl_spmatrix_set (gsl_spmatrix * m, const size_t i, const size_t j, const double x)

   This function sets element (:data:`i`, :data:`j`) of the matrix :data:`m` to
   the value :data:`x`. The matrix must be in triplet representation.

.. function:: double * gsl_spmatrix_ptr (gsl_spmatrix * m, const size_t i, const size_t j)

   This function returns a pointer to the (:data:`i`, :data:`j`) element of the matrix :data:`m`.
   If the (:data:`i`, :data:`j`) element is not explicitly stored in the matrix,
   a null pointer is returned.

.. index::
   single: sparse matrices, initializing elements

Initializing Matrix Elements
============================

Since the sparse matrix format only stores the non-zero elements, it is automatically
initialized to zero upon allocation. The function :func:`gsl_spmatrix_set_zero` may
be used to re-initialize a matrix to zero after elements have been added to it.

.. function:: int gsl_spmatrix_set_zero (gsl_spmatrix * m)

   This function sets (or resets) all the elements of the matrix :data:`m` to zero.

.. index::
   single: sparse matrices, reading
   single: sparse matrices, writing

Reading and Writing Matrices
============================

.. function:: int gsl_spmatrix_fwrite (FILE * stream, const gsl_spmatrix * m)

   This function writes the elements of the matrix :data:`m` to the stream
   :data:`stream` in binary format.  The return value is 0 for success and
   :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since the
   data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_spmatrix_fread (FILE * stream, gsl_spmatrix * m)

   This function reads into the matrix :data:`m` from the open stream
   :data:`stream` in binary format.  The matrix :data:`m` must be preallocated
   with the correct storage format, dimensions and have a sufficiently large :data:`nzmax`
   in order to read in all matrix elements, otherwise :macro:`GSL_EBADLEN`
   is returned. The return value is 0 for success and
   :macro:`GSL_EFAILED` if there was a problem reading from the file.  The
   data is assumed to have been written in the native binary format on the
   same architecture.

.. function:: int gsl_spmatrix_fprintf (FILE * stream, const gsl_spmatrix * m, const char * format)

   This function writes the elements of the matrix :data:`m` line-by-line to
   the stream :data:`stream` using the format specifier :data:`format`, which
   should be one of the :code:`%g`, :code:`%e` or :code:`%f` formats for
   floating point numbers.  The function returns 0 for success and
   :macro:`GSL_EFAILED` if there was a problem writing to the file. The
   input matrix :data:`m` may be in any storage format, and the output file
   will be written in MatrixMarket format.

.. function:: gsl_spmatrix * gsl_spmatrix_fscanf (FILE * stream)

   This function reads sparse matrix data in the MatrixMarket format
   from the stream :data:`stream` and stores it in a newly allocated matrix
   which is returned in triplet format.  The function returns 0 for success and
   :macro:`GSL_EFAILED` if there was a problem reading from the file. The
   user should free the returned matrix when it is no longer needed.

.. index::
   single: sparse matrices, copying

Copying Matrices
================

.. function:: int gsl_spmatrix_memcpy (gsl_spmatrix * dest, const gsl_spmatrix * src)

   This function copies the elements of the sparse matrix :data:`src` into
   :data:`dest`. The two matrices must have the same dimensions and be in the
   same storage format.

.. index::
   single: sparse matrices, exchanging rows and columns

Exchanging Rows and Columns
===========================

.. function:: int gsl_spmatrix_transpose_memcpy (gsl_spmatrix * dest, const gsl_spmatrix * src)

   This function copies the transpose of the sparse matrix :data:`src` into
   :data:`dest`. The dimensions of :data:`dest` must match the transpose of the
   matrix :data:`src`. Also, both matrices must use the same sparse storage
   format.

.. function:: int gsl_spmatrix_transpose (gsl_spmatrix * m)

   This function replaces the matrix :data:`m` by its transpose,
   preserving the storage format of the input matrix. Currently,
   only triplet matrix inputs are supported.

.. function:: int gsl_spmatrix_transpose2 (gsl_spmatrix * m)

   This function replaces the matrix :data:`m` by its transpose, but
   changes the storage format for compressed matrix inputs. Since
   compressed column storage is the transpose of compressed row storage,
   this function simply converts a CCS matrix to CRS and vice versa.
   This is the most efficient way to transpose a compressed storage
   matrix, but the user should note that the storage format of their
   compressed matrix will change on output. For triplet matrices,
   the output matrix is also in triplet storage.

.. index::
   single: sparse matrices, operations

Matrix Operations
=================

.. function:: int gsl_spmatrix_add (gsl_spmatrix * c, const gsl_spmatrix * a, const gsl_spmatrix * b)

   This function computes the sum :math:`c = a + b`. The three matrices must
   have the same dimensions and be stored in a compressed format.

.. function:: int gsl_spmatrix_scale (gsl_spmatrix * m, const double x)

   This function scales all elements of the matrix :data:`m` by the constant
   factor :data:`x`. The result :math:`m(i,j) \leftarrow x m(i,j)` is stored in :data:`m`.

.. index::
   single: sparse matrices, properties

Matrix Properties
=================

.. function:: size_t gsl_spmatrix_nnz (const gsl_spmatrix * m)

   This function returns the number of non-zero elements in :data:`m`.

.. function:: int gsl_spmatrix_equal (const gsl_spmatrix * a, const gsl_spmatrix * b)

   This function returns 1 if the matrices :data:`a` and :data:`b` are equal (by comparison of
   element values) and 0 otherwise. The matrices :data:`a` and :data:`b` must be in the same
   sparse storage format for comparison.

.. index::
   single: sparse matrices, min/max elements

Finding Maximum and Minimum Elements
====================================

.. function:: int gsl_spmatrix_minmax (const gsl_spmatrix * m, double * min_out, double * max_out)

   This function returns the minimum and maximum elements of the matrix
   :data:`m`, storing them in :data:`min_out` and :data:`max_out`, and searching
   only the non-zero values.

.. index::
   single: sparse matrices, compression

Compressed Format
=================

GSL supports compressed column storage (CCS) and compressed row storage (CRS)
formats.

.. function:: gsl_spmatrix * gsl_spmatrix_ccs (const gsl_spmatrix * T)

   This function creates a sparse matrix in compressed column format
   from the input sparse matrix :data:`T` which must be in triplet format.
   A pointer to a newly allocated matrix is returned. The calling function
   should free the newly allocated matrix when it is no longer needed.

.. function:: gsl_spmatrix * gsl_spmatrix_crs (const gsl_spmatrix * T)

   This function creates a sparse matrix in compressed row format
   from the input sparse matrix :data:`T` which must be in triplet format.
   A pointer to a newly allocated matrix is returned. The calling function
   should free the newly allocated matrix when it is no longer needed.

.. index::
   single: sparse matrices, conversion

Conversion Between Sparse and Dense Matrices
============================================

The :type:`gsl_spmatrix` structure can be converted into the dense :type:`gsl_matrix`
format and vice versa with the following routines.

.. function:: int gsl_spmatrix_d2sp (gsl_spmatrix * S, const gsl_matrix * A)

   This function converts the dense matrix :data:`A` into sparse triplet format
   and stores the result in :data:`S`.

.. function:: int gsl_spmatrix_sp2d (gsl_matrix * A, const gsl_spmatrix * S)

   This function converts the sparse matrix :data:`S` into a dense matrix and
   stores the result in :data:`A`. :data:`S` must be in triplet format.

.. index::
   single: sparse matrices, examples

Examples
========

The following example program builds a 5-by-4 sparse matrix
and prints it in triplet, compressed column, and compressed
row format. The matrix which is constructed is

.. only:: not texinfo

   .. math::

      \left(
        \begin{array}{cccc}
          0 & 0 & 3.1 & 4.6 \\
          1 & 0 & 7.2 & 0 \\
          0 & 0 & 0 & 0 \\
          2.1 & 2.9 & 0 & 8.5 \\
          4.1 & 0 & 0 & 0
        \end{array}
      \right)

.. only:: texinfo

   ::

     [ 0    0  3.1  4.6 ]
     [ 1    0  7.2   0  ]
     [ 0    0   0    0  ]
     [ 2.1 2.9  0   8.5 ]
     [ 4.1  0   0    0  ]

The output of the program is::

  printing all matrix elements:
  A(0,0) = 0
  A(0,1) = 0
  A(0,2) = 3.1
  A(0,3) = 4.6
  A(1,0) = 1
  .
  .
  .
  A(4,0) = 4.1
  A(4,1) = 0
  A(4,2) = 0
  A(4,3) = 0
  matrix in triplet format (i,j,Aij):
  (0, 2, 3.1)
  (0, 3, 4.6)
  (1, 0, 1.0)
  (1, 2, 7.2)
  (3, 0, 2.1)
  (3, 1, 2.9)
  (3, 3, 8.5)
  (4, 0, 4.1)
  matrix in compressed column format:
  i = [ 1, 3, 4, 3, 0, 1, 0, 3, ]
  p = [ 0, 3, 4, 6, 8, ]
  d = [ 1, 2.1, 4.1, 2.9, 3.1, 7.2, 4.6, 8.5, ]
  matrix in compressed row format:
  i = [ 2, 3, 0, 2, 0, 1, 3, 0, ]
  p = [ 0, 2, 4, 4, 7, 8, ]
  d = [ 3.1, 4.6, 1, 7.2, 2.1, 2.9, 8.5, 4.1, ]

We see in the compressed column output, the data array stores
each column contiguously, the array :math:`i` stores
the row index of the corresponding data element, and the
array :math:`p` stores the index of the start of each column in the
data array. Similarly, for the compressed row output, the
data array stores each row contiguously, the array :math:`i`
stores the column index of the corresponding data element, and
the :math:`p` array stores the index of the start of each row
in the data array.

.. include:: examples/spmatrix.c
   :code:

.. index::
   single: sparse matrices, references

References and Further Reading
==============================

The algorithms used by these functions are described in the
following sources,

* Davis, T. A., Direct Methods for Sparse Linear Systems, SIAM, 2006.

* CSparse software library, https://www.cise.ufl.edu/research/sparse/CSparse
.. index::
   single: basis splines, B-splines
   single: splines, basis

.. _chap_basis-splines:

*************
Basis Splines
*************

This chapter describes functions for the computation of smoothing
basis splines (B-splines). A smoothing spline differs from an
interpolating spline in that the resulting curve is not required to
pass through each datapoint.  For information about
interpolating splines, see :ref:`sec_interpolation`.

The header file :file:`gsl_bspline.h` contains the prototypes for the
bspline functions and related declarations.

.. index::
   single: basis splines, overview

Overview
========

B-splines are commonly used as basis functions to fit smoothing
curves to large data sets. To do this, the abscissa axis is
broken up into some number of intervals, where the endpoints
of each interval are called *breakpoints*. These breakpoints
are then converted to *knots* by imposing various continuity
and smoothness conditions at each interface. Given a nondecreasing
knot vector

.. math:: t = \{t_0, t_1, \dots, t_{n+k-1}\}

the :math:`n` basis splines of order :math:`k` are defined by

.. only:: not texinfo

   .. math::

      B_{i,1}(x) &=
        \left\{
          \begin{array}{cc}
            1, & t_i \le x < t_{i+1} \\
            0, & else
          \end{array}
        \right. \\
      B_{i,k}(x) &= {(x - t_i) \over (t_{i+k-1} - t_i)} B_{i,k-1}(x) +
                    {(t_{i+k} - x) \over (t_{i+k} - t_{i+1})} B_{i+1,k-1}(x)

.. only:: texinfo

   ::

      B_(i,1)(x) = (1, t_i <= x < t_(i+1)
                   (0, else
      B_(i,k)(x) = [(x - t_i)/(t_(i+k-1) - t_i)] B_(i,k-1)(x)
                    + [(t_(i+k) - x)/(t_(i+k) - t_(i+1))] B_(i+1,k-1)(x)

for :math:`i = 0, \ldots, n-1`. The common case of cubic B-splines
is given by :math:`k = 4`. The above recurrence relation can be
evaluated in a numerically stable way by the de Boor algorithm.

If we define appropriate knots on an interval :math:`[a,b]` then
the B-spline basis functions form a complete set on that interval.
Therefore we can expand a smoothing function as

.. math:: f(x) = \sum_{i=0}^{n-1} c_i B_{i,k}(x)

given enough :math:`(x_j, f(x_j))` data pairs. The coefficients
:math:`c_i` can be readily obtained from a least-squares fit.

.. index::
   single: basis splines, initializing

Initializing the B-splines solver
=================================

.. type:: gsl_bspline_workspace

   The computation of B-spline functions requires a preallocated
   workspace.

.. function:: gsl_bspline_workspace * gsl_bspline_alloc (const size_t k, const size_t nbreak)

   This function allocates a workspace for computing B-splines of order
   :data:`k`. The number of breakpoints is given by :data:`nbreak`. This
   leads to :math:`n = nbreak + k - 2` basis functions. Cubic B-splines
   are specified by :math:`k = 4`. The size of the workspace is
   :math:`O(2k^2 + 5k + nbreak)`.

.. function:: void gsl_bspline_free (gsl_bspline_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. index::
   single: knots, basis splines

Constructing the knots vector
=============================

.. function:: int gsl_bspline_knots (const gsl_vector * breakpts, gsl_bspline_workspace * w)

   This function computes the knots associated with the given breakpoints
   and stores them internally in :code:`w->knots`.

.. function:: int gsl_bspline_knots_uniform (const double a, const double b, gsl_bspline_workspace * w)

   This function assumes uniformly spaced breakpoints on :math:`[a,b]`
   and constructs the corresponding knot vector using the previously
   specified :data:`nbreak` parameter. The knots are stored in
   :code:`w->knots`.

.. index::
   single: basis splines, evaluation

Evaluation of B-splines
=======================

.. function:: int gsl_bspline_eval (const double x, gsl_vector * B, gsl_bspline_workspace * w)

   This function evaluates all B-spline basis functions at the position
   :data:`x` and stores them in the vector :data:`B`, so that the :math:`i`-th element
   is :math:`B_i(x)`. The vector :data:`B` must be of length
   :math:`n = nbreak + k - 2`.  This value may also be obtained by calling
   :func:`gsl_bspline_ncoeffs`.
   Computing all the basis functions at once is more efficient than
   computing them individually, due to the nature of the defining
   recurrence relation.

.. function:: int gsl_bspline_eval_nonzero (const double x, gsl_vector * Bk, size_t * istart, size_t * iend, gsl_bspline_workspace * w)

   This function evaluates all potentially nonzero B-spline basis
   functions at the position :data:`x` and stores them in the vector :data:`Bk`, so
   that the :math:`i`-th element is :math:`B_{(istart+i)}(x)`.
   The last element of :data:`Bk` is :math:`B_{iend}(x)`.
   The vector :data:`Bk` must be
   of length :math:`k`.  By returning only the nonzero basis functions,
   this function
   allows quantities involving linear combinations of the :math:`B_i(x)`
   to be computed without unnecessary terms
   (such linear combinations occur, for example,
   when evaluating an interpolated function).

.. function:: size_t gsl_bspline_ncoeffs (gsl_bspline_workspace * w)

   This function returns the number of B-spline coefficients given by
   :math:`n = nbreak + k - 2`.

.. index::
   single: basis splines, derivatives

Evaluation of B-spline derivatives
==================================

.. function:: int gsl_bspline_deriv_eval (const double x, const size_t nderiv, gsl_matrix * dB, gsl_bspline_workspace * w)

   This function evaluates all B-spline basis function derivatives of orders
   :math:`0` through :data:`nderiv` (inclusive) at the position :data:`x`
   and stores them in the matrix :data:`dB`.  The :math:`(i,j)`-th element of :data:`dB`
   is :math:`d^jB_i(x)/dx^j`.  The matrix :data:`dB` must be
   of size :math:`n = nbreak + k - 2` by :math:`nderiv + 1`.
   The value :math:`n` may also be obtained
   by calling :func:`gsl_bspline_ncoeffs`.  Note that function evaluations
   are included as the zeroth order derivatives in :data:`dB`.
   Computing all the basis function derivatives at once is more efficient
   than computing them individually, due to the nature of the defining
   recurrence relation.

.. function:: int gsl_bspline_deriv_eval_nonzero (const double x, const size_t nderiv, gsl_matrix * dB, size_t * istart, size_t * iend, gsl_bspline_workspace * w)

   This function evaluates all potentially nonzero B-spline basis function
   derivatives of orders :math:`0` through :data:`nderiv` (inclusive) at
   the position :data:`x` and stores them in the matrix :data:`dB`.  The
   :math:`(i,j)`-th element of :data:`dB` is :math:`d^jB_{(istart+i)}(x)/dx^j`.
   The last row of :data:`dB` contains :math:`d^jB_{iend}(x)/dx^j`.
   The matrix :data:`dB` must be
   of size :math:`k` by at least :math:`nderiv + 1`.  Note that function
   evaluations are included as the zeroth order derivatives in :data:`dB`.
   By returning only the nonzero basis functions, this function allows
   quantities involving linear combinations of the :math:`B_i(x)` and
   their derivatives to be computed without unnecessary terms.

.. index::
   single: basis splines, Greville abscissae
   single: basis splines, Marsden-Schoenberg points

Working with the Greville abscissae
===================================

The Greville abscissae are defined to be the mean location of :math:`k-1`
consecutive knots in the knot vector for each basis spline function of order
:math:`k`.  With the first and last knots in the :type:`gsl_bspline_workspace`
knot vector excluded, there are :func:`gsl_bspline_ncoeffs` Greville abscissae
for any given B-spline basis.  These values are often used in B-spline
collocation applications and may also be called Marsden-Schoenberg points.

.. function:: double gsl_bspline_greville_abscissa (size_t i, gsl_bspline_workspace * w)

   Returns the location of the :math:`i`-th Greville abscissa for the given
   B-spline basis.  For the ill-defined case when :math:`k = 1`, the implementation
   chooses to return breakpoint interval midpoints.

.. See https://savannah.gnu.org/bugs/index.php?34361
.. @deftypefun int gsl_bspline_knots_greville (const gsl_vector * abscissae, gsl_bspline_workspace * w, double * abserr);
.. Given target Greville abscissae values in :data:`abscissae` and a workspace
.. :data:`w` where @code{abscissae->size == gsl_bspline_ncoeffs(w)}, this functions
.. computes and stores the knots required for the workspace to best approximate
.. the target abscissae.  The approximation is optimal in that the first and last
.. values in :data:`abscissae` are preserved exactly while the 2-norm of the error
.. in any other abscissae is minimized.  If not-@code{NULL}, the sum of the
.. absolute approximation errors over each abscissa is returned in :data:`abserr`.
..
.. The workspace order must satisfy :math:`k > 1` and :data:`abscissae` should be
.. monotonically increasing.  Beware that when @code{w->nbreak} is small relative
.. to @code{w->k} the best approximation may still be of poor quality for
.. non-uniformly spaced :data:`abscissae`.  This function has memory and runtime
.. overhead that scales like a QR-based linear least squares solution on a
.. @code{(abscissae->size - 2)} by @code{(w->nbreak - 2)} problem.
.. @end deftypefun

.. index::
   single: basis splines, examples

Examples
========

The following program computes a linear least squares fit to data using
cubic B-spline basis functions with uniform breakpoints. The data is
generated from the curve :math:`y(x) = \cos{(x)} \exp{(-x/10)}` on
the interval :math:`[0, 15]` with Gaussian noise added.

.. include:: examples/bspline.c
   :code:

The output is shown below::

  $ ./a.out > bspline.txt
  chisq/dof = 1.118217e+00, Rsq = 0.989771

The data and fitted model are shown in :numref:`fig_bspline`.

.. _fig_bspline:

.. figure:: /images/bspline.png
   :scale: 60%

   Data (black) and fitted model (red)

References and Further Reading
==============================

Further information on the algorithms described in this section can be
found in the following book,

* C. de Boor, *A Practical Guide to Splines* (1978), Springer-Verlag,
  ISBN 0-387-90356-9.

Further information of Greville abscissae and B-spline collocation
can be found in the following paper,

* Richard W. Johnson, Higher order B-spline collocation at the Greville
  abscissae.  *Applied Numerical Mathematics*. vol.: 52, 2005, 63--75.

A large collection of B-spline routines is available in the
PPPACK library available at http://www.netlib.org/pppack,
which is also part of SLATEC.
.. index::
   single: differential equations, initial value problems
   single: initial value problems, differential equations
   single: ordinary differential equations, initial value problem
   single: ODEs, initial value problems

*******************************
Ordinary Differential Equations
*******************************

This chapter describes functions for solving ordinary differential
equation (ODE) initial value problems.  The library provides a variety
of low-level methods, such as Runge-Kutta and Bulirsch-Stoer routines,
and higher-level components for adaptive step-size control. The
components can be combined by the user to achieve the desired
solution, with full access to any intermediate steps. A driver object
can be used as a high level wrapper for easy use of low level
functions.

These functions are declared in the header file :file:`gsl_odeiv2.h`.
This is a new interface in version 1.15 and uses the prefix
:code:`gsl_odeiv2` for all functions.  It is recommended over the
previous :code:`gsl_odeiv` implementation defined in :file:`gsl_odeiv.h`
The old interface has been retained under the original name for
backwards compatibility.

Defining the ODE System
=======================

The routines solve the general :math:`n`-dimensional first-order system,

.. only:: not texinfo

   .. math:: {dy_i(t) \over dt} = f_i (t, y_1(t), \dots y_n(t))

.. only:: texinfo

   ::

      dy_i(t)/dt = f_i(t, y_1(t), ..., y_n(t))

for :math:`i = 1, \dots, n`.  The stepping functions rely on the vector
of derivatives :math:`f_i` and the Jacobian matrix,

.. only:: not texinfo

   .. math:: J_{ij} = \partial f_i(t, y(t)) / \partial y_j

.. only:: texinfo

   ::

      J_{ij} = df_i(t,y(t)) / dy_j

A system of equations is defined using the :type:`gsl_odeiv2_system`
datatype.

.. type:: gsl_odeiv2_system

   This data type defines a general ODE system with arbitrary parameters.

   :code:`int (* function) (double t, const double y[], double dydt[], void * params)`

      This function should store the vector elements
      :math:`f_i(t,y,params)` in the array :data:`dydt`,
      for arguments (:data:`t`, :data:`y`) and parameters :data:`params`.

      The function should return :macro:`GSL_SUCCESS` if the calculation was
      completed successfully. Any other return value indicates an error. A
      special return value :macro:`GSL_EBADFUNC` causes :code:`gsl_odeiv2`
      routines to immediately stop and return. If :code:`function` 
      is modified (for example contents of :data:`params`), the user must call an
      appropriate reset function (:func:`gsl_odeiv2_driver_reset`,
      :func:`gsl_odeiv2_evolve_reset` or :func:`gsl_odeiv2_step_reset`)
      before continuing. Use return values
      distinct from standard GSL error codes to distinguish your function as
      the source of the error.

   .. index::
      single: Jacobian matrix, ODEs

   :code:`int (* jacobian) (double t, const double y[], double * dfdy, double dfdt[], void * params)`

      This function should store the vector of derivative elements

      .. only:: not texinfo

         .. math:: \partial f_i(t,y,params) / \partial t
      
      .. only:: texinfo
   
         ::
      
            df_i(t,y,params)/dt

      in the array :data:`dfdt` and the Jacobian matrix :math:`J_{ij}`
      in the array :data:`dfdy`, regarded as a row-ordered
      matrix :code:`J(i,j) = dfdy[i * dimension + j]` where :code:`dimension`
      is the dimension of the system. 

      Not all of the stepper algorithms of :code:`gsl_odeiv2` make use of the
      Jacobian matrix, so it may not be necessary to provide this function
      (the :code:`jacobian` element of the struct can be replaced by a null
      pointer for those algorithms).

      The function should return :macro:`GSL_SUCCESS` if the calculation was
      completed successfully. Any other return value indicates an error. A
      special return value :macro:`GSL_EBADFUNC` causes :code:`gsl_odeiv2`
      routines to immediately stop and return. If :code:`jacobian` 
      is modified (for example contents of :data:`params`), the user must call an
      appropriate reset function (:func:`gsl_odeiv2_driver_reset`,
      :func:`gsl_odeiv2_evolve_reset` or :func:`gsl_odeiv2_step_reset`)
      before continuing. Use return values
      distinct from standard GSL error codes to distinguish your function as
      the source of the error.

   :code:`size_t dimension`

      This is the dimension of the system of equations.

   :code:`void * params`

      This is a pointer to the arbitrary parameters of the system.

Stepping Functions
==================

The lowest level components are the *stepping functions* which
advance a solution from time :math:`t` to :math:`t+h` for a fixed
step-size :math:`h` and estimate the resulting local error.

.. type:: gsl_odeiv2_step

   This contains internal parameters for a stepping function.

.. function:: gsl_odeiv2_step * gsl_odeiv2_step_alloc (const gsl_odeiv2_step_type * T, size_t dim)

   This function returns a pointer to a newly allocated instance of a
   stepping function of type :data:`T` for a system of :data:`dim`
   dimensions. Please note that if you use a stepper method that
   requires access to a driver object, it is advisable to use a driver
   allocation method, which automatically allocates a stepper, too.

.. function:: int gsl_odeiv2_step_reset (gsl_odeiv2_step * s)

   This function resets the stepping function :data:`s`.  It should be used
   whenever the next use of :data:`s` will not be a continuation of a
   previous step.

.. function:: void gsl_odeiv2_step_free (gsl_odeiv2_step * s)

   This function frees all the memory associated with the stepping function
   :data:`s`.

.. function:: const char * gsl_odeiv2_step_name (const gsl_odeiv2_step * s)

   This function returns a pointer to the name of the stepping function.
   For example::

      printf ("step method is '%s'\n", gsl_odeiv2_step_name (s));

   would print something like :code:`step method is 'rkf45'`.

.. function:: unsigned int gsl_odeiv2_step_order (const gsl_odeiv2_step * s)

   This function returns the order of the stepping function on the previous
   step. The order can vary if the stepping function itself is adaptive.

.. function:: int gsl_odeiv2_step_set_driver (gsl_odeiv2_step * s, const gsl_odeiv2_driver * d)

   This function sets a pointer of the driver object :data:`d` for stepper
   :data:`s`, to allow the stepper to access control (and evolve) object
   through the driver object. This is a requirement for some steppers, to
   get the desired error level for internal iteration of
   stepper. Allocation of a driver object calls this function
   automatically.

.. function:: int gsl_odeiv2_step_apply (gsl_odeiv2_step * s, double t, double h, double y[], double yerr[], const double dydt_in[], double dydt_out[], const gsl_odeiv2_system * sys)

   This function applies the stepping function :data:`s` to the system of
   equations defined by :data:`sys`, using the step-size :data:`h` to advance
   the system from time :data:`t` and state :data:`y` to time :data:`t` + :data:`h`.
   The new state of the system is stored in :data:`y` on output, with an
   estimate of the absolute error in each component stored in :data:`yerr`.
   If the argument :data:`dydt_in` is not null it should point an array
   containing the derivatives for the system at time :data:`t` on input. This
   is optional as the derivatives will be computed internally if they are
   not provided, but allows the reuse of existing derivative information.
   On output the new derivatives of the system at time :data:`t` + :data:`h` will
   be stored in :data:`dydt_out` if it is not null.

   The stepping function returns :macro:`GSL_FAILURE` if it is unable to
   compute the requested step. Also, if the user-supplied functions
   defined in the system :data:`sys` return a status other than
   :macro:`GSL_SUCCESS` the step will be aborted. In that case, the
   elements of :data:`y` will be restored to their pre-step values and the
   error code from the user-supplied function will be returned. Failure
   may be due to a singularity in the system or too large step-size
   :data:`h`. In that case the step should be attempted again with a
   smaller step-size, e.g. :data:`h` / 2.

   If the driver object is not appropriately set via
   :func:`gsl_odeiv2_step_set_driver` for those steppers that need it, the
   stepping function returns :macro:`GSL_EFAULT`. If the user-supplied
   functions defined in the system :data:`sys` returns :macro:`GSL_EBADFUNC`,
   the function returns immediately with the same return code. In this
   case the user must call :func:`gsl_odeiv2_step_reset` before calling
   this function again.

The following algorithms are available,

.. type:: gsl_odeiv2_step_type

   .. index::
      single: RK2, Runge-Kutta method
      single: Runge-Kutta methods, ordinary differential equations

   .. var:: gsl_odeiv2_step_rk2

      Explicit embedded Runge-Kutta (2, 3) method.

   .. index::
      single: RK4, Runge-Kutta method

   .. var:: gsl_odeiv2_step_rk4

      Explicit 4th order (classical) Runge-Kutta. Error estimation is
      carried out by the step doubling method. For more efficient estimate
      of the error, use the embedded methods described below.

   .. index::
      single: Fehlberg method, differential equations
      single: RKF45, Runge-Kutta-Fehlberg method

   .. var:: gsl_odeiv2_step_rkf45

      Explicit embedded Runge-Kutta-Fehlberg (4, 5) method.  This method is
      a good general-purpose integrator.

   .. index::
      single: Runge-Kutta Cash-Karp method
      single: Cash-Karp, Runge-Kutta method

   .. var:: gsl_odeiv2_step_rkck 

      Explicit embedded Runge-Kutta Cash-Karp (4, 5) method.

   .. index::
      single: Runge-Kutta Prince-Dormand method
      single: Prince-Dormand, Runge-Kutta method

   .. var:: gsl_odeiv2_step_rk8pd  

      Explicit embedded Runge-Kutta Prince-Dormand (8, 9) method.

   .. index:: Implicit Euler method

   .. var:: gsl_odeiv2_step_rk1imp 

      Implicit Gaussian first order Runge-Kutta. Also known as implicit
      Euler or backward Euler method. Error estimation is carried out by the
      step doubling method. This algorithm requires the Jacobian and 
      access to the driver object via :func:`gsl_odeiv2_step_set_driver`.

   .. index:: Implicit Runge-Kutta method

   .. var:: gsl_odeiv2_step_rk2imp  

      Implicit Gaussian second order Runge-Kutta. Also known as implicit
      mid-point rule. Error estimation is carried out by the step doubling
      method. This stepper requires the Jacobian and access to the driver
      object via :func:`gsl_odeiv2_step_set_driver`.

   .. var:: gsl_odeiv2_step_rk4imp  

      Implicit Gaussian 4th order Runge-Kutta. Error estimation is carried
      out by the step doubling method. This algorithm requires the Jacobian
      and access to the driver object via :func:`gsl_odeiv2_step_set_driver`.

   .. index::
      single: Bulirsch-Stoer method
      single: Bader and Deuflhard, Bulirsch-Stoer method.
      single: Deuflhard and Bader, Bulirsch-Stoer method.

   .. var:: gsl_odeiv2_step_bsimp   

      Implicit Bulirsch-Stoer method of Bader and Deuflhard. The method is
      generally suitable for stiff problems. This stepper requires the
      Jacobian.

   .. index::
      single: Adams method
      single: multistep methods, ODEs
      single: predictor-corrector method, ODEs
      single: Nordsieck form

   .. var:: gsl_odeiv2_step_msadams  

      A variable-coefficient linear multistep Adams method in Nordsieck
      form. This stepper uses explicit Adams-Bashforth (predictor) and
      implicit Adams-Moulton (corrector) methods in :math:`P(EC)^m`
      functional iteration mode. Method order varies dynamically between 1
      and 12. This stepper requires the access to the driver object via
      :func:`gsl_odeiv2_step_set_driver`.

   .. index:: BDF method

   .. var:: gsl_odeiv2_step_msbdf

      A variable-coefficient linear multistep backward differentiation
      formula (BDF) method in Nordsieck form. This stepper uses the explicit
      BDF formula as predictor and implicit BDF formula as corrector. A
      modified Newton iteration method is used to solve the system of
      non-linear equations. Method order varies dynamically between 1 and
      5. The method is generally suitable for stiff problems. This stepper
      requires the Jacobian and the access to the driver object via
      :func:`gsl_odeiv2_step_set_driver`.

.. index::
   single: Adaptive step-size control, differential equations

Adaptive Step-size Control
==========================

The control function examines the proposed change to the solution
produced by a stepping function and attempts to determine the optimal
step-size for a user-specified level of error.

.. type:: gsl_odeiv2_control

   This is a workspace for controlling step size.

.. type:: gsl_odeiv2_control_type

   This specifies the control type.

.. function:: gsl_odeiv2_control * gsl_odeiv2_control_standard_new (double eps_abs, double eps_rel, double a_y, double a_dydt)

   The standard control object is a four parameter heuristic based on
   absolute and relative errors :data:`eps_abs` and :data:`eps_rel`, and
   scaling factors :data:`a_y` and :data:`a_dydt` for the system state
   :math:`y(t)` and derivatives :math:`y'(t)` respectively.

   The step-size adjustment procedure for this method begins by computing
   the desired error level :math:`D_i` for each component,

   .. only:: not texinfo

      .. math:: D_i = \epsilon_{abs} + \epsilon_{rel} * (a_{y} |y_i| + a_{dydt} h |y\prime_i|)

   .. only:: texinfo

      ::

         D_i = eps_abs + eps_rel * (a_y |y_i| + a_dydt h |y\prime_i|)

   and comparing it with the observed error :math:`E_i = |yerr_i|`.  If the
   observed error :data:`E` exceeds the desired error level :data:`D` by more
   than 10% for any component then the method reduces the step-size by an
   appropriate factor,

   .. math:: h_{new} = h_{old} * S * (E/D)^{-1/q}

   where :math:`q` is the consistency order of the method (e.g. :math:`q=4` for
   4(5) embedded RK), and :math:`S` is a safety factor of 0.9. The ratio
   :math:`E/D` is taken to be the maximum of the ratios
   :math:`E_i/D_i`. 

   If the observed error :math:`E` is less than 50% of the desired error
   level :data:`D` for the maximum ratio :math:`E_i/D_i` then the algorithm
   takes the opportunity to increase the step-size to bring the error in
   line with the desired level,

   .. math:: h_{new} = h_{old} * S * (E/D)^{-1/(q+1)}

   This encompasses all the standard error scaling methods. To avoid
   uncontrolled changes in the stepsize, the overall scaling factor is
   limited to the range :math:`1/5` to 5.

.. function:: gsl_odeiv2_control * gsl_odeiv2_control_y_new (double eps_abs, double eps_rel)

   This function creates a new control object which will keep the local
   error on each step within an absolute error of :data:`eps_abs` and
   relative error of :data:`eps_rel` with respect to the solution :math:`y_i(t)`.
   This is equivalent to the standard control object with :data:`a_y` = 1 and
   :data:`a_dydt` = 0.

.. function:: gsl_odeiv2_control * gsl_odeiv2_control_yp_new (double eps_abs, double eps_rel)

   This function creates a new control object which will keep the local
   error on each step within an absolute error of :data:`eps_abs` and
   relative error of :data:`eps_rel` with respect to the derivatives of the
   solution :math:`y'_i(t)`.  This is equivalent to the standard control
   object with :data:`a_y` = 0 and :data:`a_dydt` = 1.

.. function:: gsl_odeiv2_control * gsl_odeiv2_control_scaled_new (double eps_abs, double eps_rel, double a_y, double a_dydt, const double scale_abs[], size_t dim)

   This function creates a new control object which uses the same algorithm
   as :func:`gsl_odeiv2_control_standard_new` but with an absolute error
   which is scaled for each component by the array :data:`scale_abs`.
   The formula for :math:`D_i` for this control object is,

   .. only:: not texinfo

      .. math:: D_i = \epsilon_{abs} s_i + \epsilon_{rel} * (a_{y} |y_i| + a_{dydt} h |y\prime_i|)

   .. only:: texinfo

      ::

         D_i = eps_abs * s_i + eps_rel * (a_y |y_i| + a_dydt h |y\prime_i|)

   where :math:`s_i` is the :math:`i`-th component of the array :data:`scale_abs`.
   The same error control heuristic is used by the Matlab ODE suite. 

.. function:: gsl_odeiv2_control * gsl_odeiv2_control_alloc (const gsl_odeiv2_control_type * T)

   This function returns a pointer to a newly allocated instance of a
   control function of type :data:`T`.  This function is only needed for
   defining new types of control functions.  For most purposes the standard
   control functions described above should be sufficient. 

.. function:: int gsl_odeiv2_control_init (gsl_odeiv2_control * c, double eps_abs, double eps_rel, double a_y, double a_dydt)

   This function initializes the control function :data:`c` with the
   parameters :data:`eps_abs` (absolute error), :data:`eps_rel` (relative
   error), :data:`a_y` (scaling factor for y) and :data:`a_dydt` (scaling
   factor for derivatives).

.. function:: void gsl_odeiv2_control_free (gsl_odeiv2_control * c)

   This function frees all the memory associated with the control function
   :data:`c`.

.. function:: int gsl_odeiv2_control_hadjust (gsl_odeiv2_control * c, gsl_odeiv2_step * s, const double y[], const double yerr[], const double dydt[], double * h)

   This function adjusts the step-size :data:`h` using the control function
   :data:`c`, and the current values of :data:`y`, :data:`yerr` and :data:`dydt`.
   The stepping function :data:`step` is also needed to determine the order
   of the method.  If the error in the y-values :data:`yerr` is found to be
   too large then the step-size :data:`h` is reduced and the function returns
   :macro:`GSL_ODEIV_HADJ_DEC`.  If the error is sufficiently small then
   :data:`h` may be increased and :macro:`GSL_ODEIV_HADJ_INC` is returned.  The
   function returns :macro:`GSL_ODEIV_HADJ_NIL` if the step-size is
   unchanged.  The goal of the function is to estimate the largest
   step-size which satisfies the user-specified accuracy requirements for
   the current point.

.. function:: const char * gsl_odeiv2_control_name (const gsl_odeiv2_control * c)

   This function returns a pointer to the name of the control function.
   For example::

      printf ("control method is '%s'\n", gsl_odeiv2_control_name (c));

   would print something like :code:`control method is 'standard'`

.. function:: int gsl_odeiv2_control_errlevel (gsl_odeiv2_control * c, const double y, const double dydt, const double h, const size_t ind, double * errlev)

   This function calculates the desired error level of the :data:`ind`-th component
   to :data:`errlev`. It requires the value (:data:`y`) and value of the derivative
   (:data:`dydt`) of the component, and the current step size :data:`h`.

.. function:: int gsl_odeiv2_control_set_driver (gsl_odeiv2_control * c, const gsl_odeiv2_driver * d)

   This function sets a pointer of the driver object :data:`d` for control
   object :data:`c`.

Evolution
=========

The evolution function combines the results of a stepping function and
control function to reliably advance the solution forward one step
using an acceptable step-size.

.. type:: gsl_odeiv2_evolve

   This workspace contains parameters for controlling the evolution function

.. function:: gsl_odeiv2_evolve * gsl_odeiv2_evolve_alloc (size_t dim)

   This function returns a pointer to a newly allocated instance of an
   evolution function for a system of :data:`dim` dimensions.

.. function:: int gsl_odeiv2_evolve_apply (gsl_odeiv2_evolve * e, gsl_odeiv2_control * con, gsl_odeiv2_step * step, const gsl_odeiv2_system * sys, double * t, double t1, double * h, double y[])

   This function advances the system (:data:`e`, :data:`sys`) from time
   :data:`t` and position :data:`y` using the stepping function :data:`step`.
   The new time and position are stored in :data:`t` and :data:`y` on output.

   The initial step-size is taken as :data:`h`. The control function
   :data:`con` is applied to check whether the local error estimated by the
   stepping function :data:`step` using step-size :data:`h` exceeds the
   required error tolerance. If the error is too high, the step is
   retried by calling :data:`step` with a decreased step-size. This process
   is continued until an acceptable step-size is found. An estimate of
   the local error for the step can be obtained from the components of
   the array :code:`e->yerr[]`.

   If the user-supplied functions defined in the system :data:`sys` returns
   :macro:`GSL_EBADFUNC`, the function returns immediately with the same
   return code. In this case the user must call
   :func:`gsl_odeiv2_step_reset` and
   :func:`gsl_odeiv2_evolve_reset` before calling this function again.

   Otherwise, if the user-supplied functions defined in the system
   :data:`sys` or the stepping function :data:`step` return a status other
   than :macro:`GSL_SUCCESS`, the step is retried with a decreased
   step-size. If the step-size decreases below machine precision, a
   status of :macro:`GSL_FAILURE` is returned if the user functions
   returned :macro:`GSL_SUCCESS`. Otherwise the value returned by user
   function is returned. If no acceptable step can be made, :data:`t` and
   :data:`y` will be restored to their pre-step values and :data:`h` contains
   the final attempted step-size.

   If the step is successful the function returns a suggested step-size
   for the next step in :data:`h`. The maximum time :data:`t1` is guaranteed
   not to be exceeded by the time-step. On the final time-step the value
   of :data:`t` will be set to :data:`t1` exactly.

.. function:: int gsl_odeiv2_evolve_apply_fixed_step (gsl_odeiv2_evolve * e, gsl_odeiv2_control * con, gsl_odeiv2_step * step, const gsl_odeiv2_system * sys, double * t, const double h, double y[])

   This function advances the ODE-system (:data:`e`, :data:`sys`, :data:`con`)
   from time :data:`t` and position :data:`y` using the stepping function
   :data:`step` by a specified step size :data:`h`. If the local error
   estimated by the stepping function exceeds the desired error level,
   the step is not taken and the function returns
   :macro:`GSL_FAILURE`. Otherwise the value returned by user function is
   returned.

.. function:: int gsl_odeiv2_evolve_reset (gsl_odeiv2_evolve * e)

   This function resets the evolution function :data:`e`.  It should be used
   whenever the next use of :data:`e` will not be a continuation of a
   previous step.

.. function:: void gsl_odeiv2_evolve_free (gsl_odeiv2_evolve * e)

   This function frees all the memory associated with the evolution function
   :data:`e`.

.. function:: int gsl_odeiv2_evolve_set_driver (gsl_odeiv2_evolve * e, const gsl_odeiv2_driver * d)

   This function sets a pointer of the driver object :data:`d` for evolve
   object :data:`e`.

.. index::
   single: discontinuities, in ODE systems

If a system has discontinuous changes in the derivatives at known
points, it is advisable to evolve the system between each discontinuity
in sequence.  For example, if a step-change in an external driving
force occurs at times :math:`t_a, t_b` and :math:`t_c` then evolution
should be carried out over the ranges :math:`(t_0,t_a)`,
:math:`(t_a,t_b)`, :math:`(t_b,t_c)`, and :math:`(t_c,t_1)` separately
and not directly over the range :math:`(t_0,t_1)`.

Driver
======

The driver object is a high level wrapper that combines the evolution,
control and stepper objects for easy use.

.. function:: gsl_odeiv2_driver * gsl_odeiv2_driver_alloc_y_new (const gsl_odeiv2_system * sys, const gsl_odeiv2_step_type * T, const double hstart, const double epsabs, const double epsrel)
              gsl_odeiv2_driver * gsl_odeiv2_driver_alloc_yp_new (const gsl_odeiv2_system * sys, const gsl_odeiv2_step_type * T, const double hstart, const double epsabs, const double epsrel)
              gsl_odeiv2_driver * gsl_odeiv2_driver_alloc_standard_new (const gsl_odeiv2_system * sys, const gsl_odeiv2_step_type * T, const double hstart, const double epsabs, const double epsrel, const double a_y, const double a_dydt)
              gsl_odeiv2_driver * gsl_odeiv2_driver_alloc_scaled_new (const gsl_odeiv2_system * sys, const gsl_odeiv2_step_type * T, const double hstart, const double epsabs, const double epsrel, const double a_y, const double a_dydt, const double scale_abs[])

   These functions return a pointer to a newly allocated instance of a
   driver object. The functions automatically allocate and initialise the
   evolve, control and stepper objects for ODE system :data:`sys` using
   stepper type :data:`T`. The initial step size is given in
   :data:`hstart`. The rest of the arguments follow the syntax and
   semantics of the control functions with same name
   (:code:`gsl_odeiv2_control_*_new`).

.. function:: int gsl_odeiv2_driver_set_hmin (gsl_odeiv2_driver * d, const double hmin)

   The function sets a minimum for allowed step size :data:`hmin` for
   driver :data:`d`. Default value is 0.

.. function:: int gsl_odeiv2_driver_set_hmax (gsl_odeiv2_driver * d, const double hmax)

   The function sets a maximum for allowed step size :data:`hmax` for
   driver :data:`d`. Default value is :macro:`GSL_DBL_MAX`.

.. function:: int gsl_odeiv2_driver_set_nmax (gsl_odeiv2_driver * d, const unsigned long int nmax)

   The function sets a maximum for allowed number of steps :data:`nmax` for
   driver :data:`d`. Default value of 0 sets no limit for steps.

.. function:: int gsl_odeiv2_driver_apply (gsl_odeiv2_driver * d, double * t, const double t1, double y[])

   This function evolves the driver system :data:`d` from :data:`t` to
   :data:`t1`. Initially vector :data:`y` should contain the values of
   dependent variables at point :data:`t`. If the function is unable to
   complete the calculation, an error code from
   :func:`gsl_odeiv2_evolve_apply` is returned, and :data:`t` and :data:`y`
   contain the values from last successful step. 

   If maximum number of steps is reached, a value of :macro:`GSL_EMAXITER`
   is returned. If the step size drops below minimum value, the function
   returns with :macro:`GSL_ENOPROG`. If the user-supplied functions
   defined in the system :data:`sys` returns :macro:`GSL_EBADFUNC`, the
   function returns immediately with the same return code. In this case
   the user must call :func:`gsl_odeiv2_driver_reset` before calling this
   function again.

.. function:: int gsl_odeiv2_driver_apply_fixed_step (gsl_odeiv2_driver * d, double * t, const double h, const unsigned long int n, double y[])

   This function evolves the driver system :data:`d` from :data:`t` with
   :data:`n` steps of size :data:`h`. If the function is unable to complete
   the calculation, an error code from
   :func:`gsl_odeiv2_evolve_apply_fixed_step` is returned, and :data:`t` and
   :data:`y` contain the values from last successful step.

.. function:: int gsl_odeiv2_driver_reset (gsl_odeiv2_driver * d)

   This function resets the evolution and stepper objects.

.. function:: int gsl_odeiv2_driver_reset_hstart (gsl_odeiv2_driver * d, const double hstart)

   The routine resets the evolution and stepper objects and sets new
   initial step size to :data:`hstart`. This function can be used e.g. to
   change the direction of integration.

.. function:: int gsl_odeiv2_driver_free (gsl_odeiv2_driver * d)

   This function frees the driver object, and the related evolution,
   stepper and control objects.

Examples
========

.. index::
   single: Van der Pol oscillator, example

The following program solves the second-order nonlinear Van der Pol
oscillator equation,

.. math:: u''(t) + \mu u'(t) (u(t)^2 - 1) + u(t) = 0

This can be converted into a first order system suitable for use with
the routines described in this chapter by introducing a separate
variable for the velocity, :math:`v = u'(t)`,

.. only:: not texinfo

   .. math::

      u' &= v \\
      v' &= -u + \mu v (1-u^2)

.. only:: texinfo

   ::

      u' = v
      v' = -u + \mu v (1-u^2)

The program begins by defining functions for these derivatives and
their Jacobian. The main function uses driver level functions to solve
the problem. The program evolves the solution from :math:`(u, v) = (1, 0)`
at :math:`t = 0` to :math:`t = 100`.  The step-size :math:`h` is
automatically adjusted by the controller to maintain an absolute
accuracy of :math:`10^{-6}`
in the function values :math:`(u, v)`.
The loop in the example prints the solution at the points
:math:`t_i = 1, 2, \dots, 100`.

.. include:: examples/ode-initval.c
   :code:

The user can work with the lower level functions directly, as in
the following example. In this case an intermediate result is printed
after each successful step instead of equidistant time points. 

.. include:: examples/ode-initval-low-level.c
   :code:

For functions with multiple parameters, the appropriate information
can be passed in through the :data:`params` argument in
:type:`gsl_odeiv2_system` definition (:data:`mu` in this example) by using
a pointer to a struct.

.. figure:: /images/ode-vdp.png

   Numerical solution of the Van der Pol oscillator equation 
   using Prince-Dormand 8th order Runge-Kutta.

It is also possible to work with a non-adaptive integrator, using only
the stepping function itself,
:func:`gsl_odeiv2_driver_apply_fixed_step` or
:func:`gsl_odeiv2_evolve_apply_fixed_step`. The following program uses
the driver level function, with fourth-order
Runge-Kutta stepping function with a fixed stepsize of
0.001.

.. include:: examples/odefixed.c
   :code:

References and Further Reading
==============================

* Ascher, U.M., Petzold, L.R., *Computer Methods for Ordinary
  Differential and Differential-Algebraic Equations*, SIAM, 
  Philadelphia, 1998.

* Hairer, E., Norsett, S. P., Wanner, G., *Solving Ordinary Differential 
  Equations I: Nonstiff Problems*, Springer, Berlin, 1993.

* Hairer, E., Wanner, G., *Solving Ordinary Differential 
  Equations II: Stiff and Differential-Algebraic Problems*,
  Springer, Berlin, 1996.

Many of the basic Runge-Kutta formulas can be found in the Handbook of
Mathematical Functions,

* Abramowitz & Stegun (eds.), *Handbook of Mathematical Functions*,
  Section 25.5.

The implicit Bulirsch-Stoer algorithm :code:`bsimp` is described in the
following paper,

* G. Bader and P. Deuflhard, "A Semi-Implicit Mid-Point Rule for Stiff
  Systems of Ordinary Differential Equations.", Numer.: Math.: 41, 373--398,
  1983.

The Adams and BDF multistep methods :code:`msadams` and :code:`msbdf`
are based on the following articles,

* G. D. Byrne and A. C. Hindmarsh, "A Polyalgorithm for the
  Numerical Solution of Ordinary Differential Equations.",
  ACM Trans. Math. Software, 1, 71--96, 1975.

* P. N. Brown, G. D. Byrne and A. C. Hindmarsh, "VODE: A
  Variable-coefficient ODE Solver.", SIAM J. Sci. Stat. Comput. 10,
  1038--1051, 1989.

* A. C. Hindmarsh, P. N. Brown, K. E. Grant, S. L. Lee, R. Serban,
  D. E. Shumaker and C. S. Woodward, "SUNDIALS: Suite of
  Nonlinear and Differential/Algebraic Equation Solvers.", ACM
  Trans. Math. Software 31, 363--396, 2005.
.. index:: Airy functions
.. index:: Ai(x)
.. index:: Bi(x)

The Airy functions :math:`Ai(x)` and :math:`Bi(x)` are defined by the
integral representations,

.. only:: not texinfo

   .. math::

      Ai(x) & = {1\over\pi} \int_0^\infty \cos(t^3/3 + xt ) \,dt \\
      Bi(x) & = {1\over\pi} \int_0^\infty (e^{-t^3/3 + xt} + \sin(t^3/3 + xt)) \,dt

.. only:: texinfo

   | Ai(x) = (1/\pi) \int_0^\infty \cos((1/3) t^3 + xt) dt
   | Bi(x) = (1/\pi) \int_0^\infty (e^(-(1/3) t^3 + xt) + \sin((1/3) t^3 + xt)) dt

For further information see Abramowitz & Stegun, Section 10.4. The Airy
functions are defined in the header file :file:`gsl_sf_airy.h`.

Airy Functions
--------------

.. function:: double gsl_sf_airy_Ai (double x, gsl_mode_t mode)
              int gsl_sf_airy_Ai_e (double x, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the Airy function :math:`Ai(x)` with an accuracy
   specified by :data:`mode`.

.. function:: double gsl_sf_airy_Bi (double x, gsl_mode_t mode)
              int gsl_sf_airy_Bi_e (double x, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the Airy function :math:`Bi(x)` with an accuracy
   specified by :data:`mode`.

.. function:: double gsl_sf_airy_Ai_scaled (double x, gsl_mode_t mode)
              int gsl_sf_airy_Ai_scaled_e (double x, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute a scaled version of the Airy function
   :math:`S_A(x) Ai(x)`.  For :math:`x > 0` the scaling factor :math:`S_A(x)` is
   :math:`\exp(+(2/3) x^{3/2})`, 
   and is 1 for :math:`x < 0`.

.. function:: double gsl_sf_airy_Bi_scaled (double x, gsl_mode_t mode)
              int gsl_sf_airy_Bi_scaled_e (double x, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute a scaled version of the Airy function
   :math:`S_B(x) Bi(x)`.  For :math:`x > 0` the scaling factor :math:`S_B(x)` is
   :math:`exp(-(2/3) x^{3/2})`, and is 1 for :math:`x < 0`.


Derivatives of Airy Functions
-----------------------------

.. function:: double gsl_sf_airy_Ai_deriv (double x, gsl_mode_t mode)
              int gsl_sf_airy_Ai_deriv_e (double x, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the Airy function derivative :math:`Ai'(x)` with
   an accuracy specified by :data:`mode`.

.. function:: double gsl_sf_airy_Bi_deriv (double x, gsl_mode_t mode)
              int gsl_sf_airy_Bi_deriv_e (double x, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the Airy function derivative :math:`Bi'(x)` with
   an accuracy specified by :data:`mode`.

.. function:: double gsl_sf_airy_Ai_deriv_scaled (double x, gsl_mode_t mode)
              int gsl_sf_airy_Ai_deriv_scaled_e (double x, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the scaled Airy function derivative 
   :math:`S_A(x) Ai'(x)`.  
   For :math:`x > 0` the scaling factor :math:`S_A(x)` is
   :math:`\exp(+(2/3) x^{3/2})`, and is 1 for :math:`x < 0`.

.. function:: double gsl_sf_airy_Bi_deriv_scaled (double x, gsl_mode_t mode)
              int gsl_sf_airy_Bi_deriv_scaled_e (double x, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the scaled Airy function derivative 
   :math:`S_B(x) Bi'(x)`.
   For :math:`x > 0` the scaling factor :math:`S_B(x)` is
   :math:`exp(-(2/3) x^{3/2})`, and is 1 for :math:`x < 0`.

Zeros of Airy Functions
-----------------------

.. function:: double gsl_sf_airy_zero_Ai (unsigned int s)
              int gsl_sf_airy_zero_Ai_e (unsigned int s, gsl_sf_result * result)

   These routines compute the location of the :data:`s`-th zero of the Airy
   function :math:`Ai(x)`.

.. function:: double gsl_sf_airy_zero_Bi (unsigned int s)
              int gsl_sf_airy_zero_Bi_e (unsigned int s, gsl_sf_result * result)

   These routines compute the location of the :data:`s`-th zero of the Airy
   function :math:`Bi(x)`.

Zeros of Derivatives of Airy Functions
--------------------------------------

.. function:: double gsl_sf_airy_zero_Ai_deriv (unsigned int s)
              int gsl_sf_airy_zero_Ai_deriv_e (unsigned int s, gsl_sf_result * result)

   These routines compute the location of the :data:`s`-th zero of the Airy
   function derivative :math:`Ai'(x)`.

.. function:: double gsl_sf_airy_zero_Bi_deriv (unsigned int s)
              int gsl_sf_airy_zero_Bi_deriv_e (unsigned int s, gsl_sf_result * result)

   These routines compute the location of the :data:`s`-th zero of the Airy
   function derivative :math:`Bi'(x)`.
.. index::
   single: linear algebra, BLAS
   single: matrix, operations
   single: vector, operations
   single: BLAS
   single: CBLAS
   single: Basic Linear Algebra Subroutines (BLAS)

.. _chap_blas-support:

************
BLAS Support
************

The Basic Linear Algebra Subprograms (BLAS) define a set of fundamental
operations on vectors and matrices which can be used to create optimized
higher-level linear algebra functionality.

The library provides a low-level layer which corresponds directly to the
C-language BLAS standard, referred to here as "CBLAS", and a
higher-level interface for operations on GSL vectors and matrices.
Users who are interested in simple operations on GSL vector and matrix
objects should use the high-level layer described
in this chapter.  The functions are declared in the file
:file:`gsl_blas.h` and should satisfy the needs of most users.  

Note that GSL matrices are implemented using dense-storage so the
interface only includes the corresponding dense-storage BLAS
functions.  The full BLAS functionality for band-format and
packed-format matrices is available through the low-level CBLAS
interface.  Similarly, GSL vectors are restricted to positive strides,
whereas the low-level CBLAS interface supports negative
strides as specified in the BLAS standard [#f1]_.
 
The interface for the :code:`gsl_cblas` layer is specified in the file
:file:`gsl_cblas.h`.  This interface corresponds to the BLAS Technical
Forum's standard for the C interface to legacy BLAS
implementations. Users who have access to other conforming CBLAS
implementations can use these in place of the version provided by the
library.  Note that users who have only a Fortran BLAS library can
use a CBLAS conformant wrapper to convert it into a CBLAS
library.  A reference CBLAS wrapper for legacy Fortran
implementations exists as part of the CBLAS standard and can
be obtained from Netlib.  The complete set of CBLAS functions is
listed in an :ref:`appendix <chap_cblas>`.

There are three levels of BLAS operations,

=========== ===============================================================
**Level 1** Vector operations, e.g. :math:`y = \alpha x + y`
**Level 2** Matrix-vector operations, e.g. :math:`y = \alpha A x + \beta y`
**Level 3** Matrix-matrix operations, e.g. :math:`C = \alpha A B + C`
=========== ===============================================================

Each routine has a name which specifies the operation, the type of
matrices involved and their precisions.  Some of the most common
operations and their names are given below,

======== =====================================
**DOT**  scalar product, :math:`x^T y`
**AXPY** vector sum, :math:`\alpha x + y`
**MV**   matrix-vector product, :math:`A x`
**SV**   matrix-vector solve, :math:`inv(A) x`
**MM**   matrix-matrix product, :math:`A B`
**SM**   matrix-matrix solve, :math:`inv(A) B`
======== =====================================

The types of matrices are,

====== =================
**GE** general
**GB** general band
**SY** symmetric
**SB** symmetric band
**SP** symmetric packed
**HE** hermitian
**HB** hermitian band
**HP** hermitian packed
**TR** triangular 
**TB** triangular band
**TP** triangular packed
====== =================

Each operation is defined for four precisions,

===== ==============
**S** single real
**D** double real
**C** single complex
**Z** double complex
===== ==============

Thus, for example, the name SGEMM stands for "single-precision
general matrix-matrix multiply" and ZGEMM stands for
"double-precision complex matrix-matrix multiply".

Note that the vector and matrix arguments to BLAS functions must not
be aliased, as the results are undefined when the underlying arrays
overlap (:ref:`aliasing-of-arrays`).

GSL BLAS Interface
==================

GSL provides dense vector and matrix objects, based on the relevant
built-in types.  The library provides an interface to the BLAS
operations which apply to these objects.  The interface to this
functionality is given in the file :file:`gsl_blas.h`.

.. CblasNoTrans, CblasTrans, CblasConjTrans
.. CblasUpper, CblasLower
.. CblasNonUnit, CblasUnit
.. CblasLeft, CblasRight

Level 1
-------

.. index::
   single: DOT, Level-1 BLAS

.. function:: int gsl_blas_sdsdot (float alpha, const gsl_vector_float * x, const gsl_vector_float * y, float * result)

   This function computes the sum :math:`\alpha + x^T y` for the vectors
   :data:`x` and :data:`y`, returning the result in :data:`result`.

.. function:: int gsl_blas_sdot (const gsl_vector_float * x, const gsl_vector_float * y, float * result)
              int gsl_blas_dsdot (const gsl_vector_float * x, const gsl_vector_float * y, double * result)
              int gsl_blas_ddot (const gsl_vector * x, const gsl_vector * y, double * result)

   These functions compute the scalar product :math:`x^T y` for the vectors
   :data:`x` and :data:`y`, returning the result in :data:`result`.

.. function:: int gsl_blas_cdotu (const gsl_vector_complex_float * x, const gsl_vector_complex_float * y, gsl_complex_float * dotu)
              int gsl_blas_zdotu (const gsl_vector_complex * x, const gsl_vector_complex * y, gsl_complex * dotu)

   These functions compute the complex scalar product :math:`x^T y` for the
   vectors :data:`x` and :data:`y`, returning the result in :data:`dotu`

.. function:: int gsl_blas_cdotc (const gsl_vector_complex_float * x, const gsl_vector_complex_float * y, gsl_complex_float * dotc)
              int gsl_blas_zdotc (const gsl_vector_complex * x, const gsl_vector_complex * y, gsl_complex * dotc)

   These functions compute the complex conjugate scalar product :math:`x^H y`
   for the vectors :data:`x` and :data:`y`, returning the result in
   :data:`dotc`

.. index::
   single: NRM2, Level-1 BLAS

.. function:: float gsl_blas_snrm2 (const gsl_vector_float * x)
              double gsl_blas_dnrm2 (const gsl_vector * x)

   These functions compute the Euclidean norm 
   :math:`||x||_2 = \sqrt{\sum x_i^2}` of the vector :data:`x`.

.. function:: float gsl_blas_scnrm2 (const gsl_vector_complex_float * x)
              double gsl_blas_dznrm2 (const gsl_vector_complex * x)

   These functions compute the Euclidean norm of the complex vector :data:`x`,

   .. math:: ||x||_2 = \sqrt{\sum (\Re(x_i)^2 + \Im(x_i)^2)}.

.. index::
   single: ASUM, Level-1 BLAS

.. function:: float gsl_blas_sasum (const gsl_vector_float * x)
              double gsl_blas_dasum (const gsl_vector * x)

   These functions compute the absolute sum :math:`\sum |x_i|` of the
   elements of the vector :data:`x`.

.. function:: float gsl_blas_scasum (const gsl_vector_complex_float * x)
              double gsl_blas_dzasum (const gsl_vector_complex * x)

   These functions compute the sum of the magnitudes of the real and
   imaginary parts of the complex vector :data:`x`, 
   :math:`\sum \left( |\Re(x_i)| + |\Im(x_i)| \right)`.

.. index::
   single: AMAX, Level-1 BLAS

.. function:: CBLAS_INDEX_t gsl_blas_isamax (const gsl_vector_float * x)
              CBLAS_INDEX_t gsl_blas_idamax (const gsl_vector * x)
              CBLAS_INDEX_t gsl_blas_icamax (const gsl_vector_complex_float * x)
              CBLAS_INDEX_t gsl_blas_izamax (const gsl_vector_complex * x)

   These functions return the index of the largest element of the vector
   :data:`x`. The largest element is determined by its absolute magnitude for
   real vectors and by the sum of the magnitudes of the real and imaginary
   parts :math:`|\Re(x_i)| + |\Im(x_i)|` for complex vectors.  If the
   largest value occurs several times then the index of the first
   occurrence is returned.

.. index::
   single: SWAP, Level-1 BLAS

.. function:: int gsl_blas_sswap (gsl_vector_float * x, gsl_vector_float * y)
              int gsl_blas_dswap (gsl_vector * x, gsl_vector * y)
              int gsl_blas_cswap (gsl_vector_complex_float * x, gsl_vector_complex_float * y)
              int gsl_blas_zswap (gsl_vector_complex * x, gsl_vector_complex * y)

   These functions exchange the elements of the vectors :data:`x` and :data:`y`.

.. index::
   single: COPY, Level-1 BLAS

.. function:: int gsl_blas_scopy (const gsl_vector_float * x, gsl_vector_float * y)
              int gsl_blas_dcopy (const gsl_vector * x, gsl_vector * y)
              int gsl_blas_ccopy (const gsl_vector_complex_float * x, gsl_vector_complex_float * y)
              int gsl_blas_zcopy (const gsl_vector_complex * x, gsl_vector_complex * y)

   These functions copy the elements of the vector :data:`x` into the vector
   :data:`y`.

.. index::
   single: AXPY, Level-1 BLAS
   single: DAXPY, Level-1 BLAS
   single: SAXPY, Level-1 BLAS

.. function:: int gsl_blas_saxpy (float alpha, const gsl_vector_float * x, gsl_vector_float * y)
              int gsl_blas_daxpy (double alpha, const gsl_vector * x, gsl_vector * y)
              int gsl_blas_caxpy (const gsl_complex_float alpha, const gsl_vector_complex_float * x, gsl_vector_complex_float * y)
              int gsl_blas_zaxpy (const gsl_complex alpha, const gsl_vector_complex * x, gsl_vector_complex * y)

   These functions compute the sum :math:`y = \alpha x + y` for the vectors
   :data:`x` and :data:`y`.

.. index::
   single: SCAL, Level-1 BLAS

.. function:: void gsl_blas_sscal (float alpha, gsl_vector_float * x)
              void gsl_blas_dscal (double alpha, gsl_vector * x)
              void gsl_blas_cscal (const gsl_complex_float alpha, gsl_vector_complex_float * x)
              void gsl_blas_zscal (const gsl_complex alpha, gsl_vector_complex * x)
              void gsl_blas_csscal (float alpha, gsl_vector_complex_float * x)
              void gsl_blas_zdscal (double alpha, gsl_vector_complex * x)

   These functions rescale the vector :data:`x` by the multiplicative factor
   :data:`alpha`.

.. index::
   single: ROTG, Level-1 BLAS
   single: Givens Rotation, BLAS

.. function:: int gsl_blas_srotg (float a[], float b[], float c[], float s[])
              int gsl_blas_drotg (double a[], double b[], double c[], double s[])

   These functions compute a Givens rotation :math:`(c,s)` which zeroes the
   vector :math:`(a,b)`,

   .. only:: not texinfo

      .. math::

         \left(
         \begin{matrix}
            c & s \\
           -s & c
         \end{matrix}
         \right)
         \left(
         \begin{matrix}
           a \\
           b
         \end{matrix}
         \right)
         =
         \left(
         \begin{matrix}
           r' \\
           0
         \end{matrix}
         \right)

   .. only:: texinfo

      ::

         [  c  s ] [ a ] = [ r ]
         [ -s  c ] [ b ]   [ 0 ]

   The variables :data:`a` and :data:`b` are overwritten by the routine.

.. function:: int gsl_blas_srot (gsl_vector_float * x, gsl_vector_float * y, float c, float s)
              int gsl_blas_drot (gsl_vector * x, gsl_vector * y, const double c, const double s)

   These functions apply a Givens rotation :math:`(x', y') = (c x + s y, -s x + c y)`
   to the vectors :data:`x`, :data:`y`.

.. index::
   single: Modified Givens Rotation, BLAS
   single: Givens Rotation, Modified, BLAS

.. function:: int gsl_blas_srotmg (float d1[], float d2[], float b1[], float b2, float P[])
              int gsl_blas_drotmg (double d1[], double d2[], double b1[], double b2, double P[])

   These functions compute a modified Givens transformation.  The modified
   Givens transformation is defined in the original Level-1 BLAS
   specification, given in the references.

.. function:: int gsl_blas_srotm (gsl_vector_float * x, gsl_vector_float * y, const float P[])
              int gsl_blas_drotm (gsl_vector * x, gsl_vector * y, const double P[])

   These functions apply a modified Givens transformation.  

Level 2
-------

.. index::
   single: GEMV, Level-2 BLAS

.. function:: int gsl_blas_sgemv (CBLAS_TRANSPOSE_t TransA, float alpha, const gsl_matrix_float * A, const gsl_vector_float * x, float beta, gsl_vector_float * y)
              int gsl_blas_dgemv (CBLAS_TRANSPOSE_t TransA, double alpha, const gsl_matrix * A, const gsl_vector * x, double beta, gsl_vector * y)
              int gsl_blas_cgemv (CBLAS_TRANSPOSE_t TransA, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, const gsl_vector_complex_float * x, const gsl_complex_float beta, gsl_vector_complex_float * y)
              int gsl_blas_zgemv (CBLAS_TRANSPOSE_t TransA, const gsl_complex alpha, const gsl_matrix_complex * A, const gsl_vector_complex * x, const gsl_complex beta, gsl_vector_complex * y)

   These functions compute the matrix-vector product and sum :math:`y = \alpha op(A) x + \beta y`,
   where :math:`op(A) = A`, :math:`A^T`, :math:`A^H` for :data:`TransA` = :code:`CblasNoTrans`,
   :code:`CblasTrans`, :code:`CblasConjTrans`.

.. index::
   single: TRMV, Level-2 BLAS

.. function:: int gsl_blas_strmv (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_matrix_float * A, gsl_vector_float * x)
              int gsl_blas_dtrmv (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_matrix * A, gsl_vector * x)
              int gsl_blas_ctrmv (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_matrix_complex_float * A, gsl_vector_complex_float * x)
              int gsl_blas_ztrmv (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_matrix_complex * A, gsl_vector_complex * x)

   These functions compute the matrix-vector product 
   :math:`x = op(A) x` for the triangular matrix :data:`A`, where
   :math:`op(A) = A`, :math:`A^T`, :math:`A^H` for :data:`TransA` =
   :code:`CblasNoTrans`, :code:`CblasTrans`, :code:`CblasConjTrans`.  When
   :data:`Uplo` is :code:`CblasUpper` then the upper triangle of :data:`A` is
   used, and when :data:`Uplo` is :code:`CblasLower` then the lower triangle
   of :data:`A` is used.  If :data:`Diag` is :code:`CblasNonUnit` then the
   diagonal of the matrix is used, but if :data:`Diag` is :code:`CblasUnit`
   then the diagonal elements of the matrix :data:`A` are taken as unity and
   are not referenced.

.. index::
   single: TRSV, Level-2 BLAS

.. function:: int gsl_blas_strsv (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_matrix_float * A, gsl_vector_float * x)
              int gsl_blas_dtrsv (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_matrix * A, gsl_vector * x)
              int gsl_blas_ctrsv (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_matrix_complex_float * A, gsl_vector_complex_float * x)
              int gsl_blas_ztrsv (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_matrix_complex * A, gsl_vector_complex * x)

   These functions compute :math:`inv(op(A)) x` for :data:`x`, where
   :math:`op(A) = A`, :math:`A^T`, :math:`A^H` for :data:`TransA` =
   :code:`CblasNoTrans`, :code:`CblasTrans`, :code:`CblasConjTrans`.  When
   :data:`Uplo` is :code:`CblasUpper` then the upper triangle of :data:`A` is
   used, and when :data:`Uplo` is :code:`CblasLower` then the lower triangle
   of :data:`A` is used.  If :data:`Diag` is :code:`CblasNonUnit` then the
   diagonal of the matrix is used, but if :data:`Diag` is :code:`CblasUnit`
   then the diagonal elements of the matrix :data:`A` are taken as unity and
   are not referenced.

.. index::
   single: SYMV, Level-2 BLAS

.. function:: int gsl_blas_ssymv (CBLAS_UPLO_t Uplo, float alpha, const gsl_matrix_float * A, const gsl_vector_float * x, float beta, gsl_vector_float * y)
              int gsl_blas_dsymv (CBLAS_UPLO_t Uplo, double alpha, const gsl_matrix * A, const gsl_vector * x, double beta, gsl_vector * y)

   These functions compute the matrix-vector product and sum :math:`y = \alpha A x + \beta y`
   for the symmetric matrix :data:`A`.  Since the
   matrix :data:`A` is symmetric only its upper half or lower half need to be
   stored.  When :data:`Uplo` is :code:`CblasUpper` then the upper triangle
   and diagonal of :data:`A` are used, and when :data:`Uplo` is
   :code:`CblasLower` then the lower triangle and diagonal of :data:`A` are
   used.

.. index::
   single: HEMV, Level-2 BLAS

.. function:: int gsl_blas_chemv (CBLAS_UPLO_t Uplo, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, const gsl_vector_complex_float * x, const gsl_complex_float beta, gsl_vector_complex_float * y)
              int gsl_blas_zhemv (CBLAS_UPLO_t Uplo, const gsl_complex alpha, const gsl_matrix_complex * A, const gsl_vector_complex * x, const gsl_complex beta, gsl_vector_complex * y)

   These functions compute the matrix-vector product and sum :math:`y = \alpha A x + \beta y`
   for the hermitian matrix :data:`A`.  Since the
   matrix :data:`A` is hermitian only its upper half or lower half need to be
   stored.  When :data:`Uplo` is :code:`CblasUpper` then the upper triangle
   and diagonal of :data:`A` are used, and when :data:`Uplo` is
   :code:`CblasLower` then the lower triangle and diagonal of :data:`A` are
   used.  The imaginary elements of the diagonal are automatically assumed
   to be zero and are not referenced.

.. index::
   single: GER, Level-2 BLAS
   single: GERU, Level-2 BLAS

.. function:: int gsl_blas_sger (float alpha, const gsl_vector_float * x, const gsl_vector_float * y, gsl_matrix_float * A)
              int gsl_blas_dger (double alpha, const gsl_vector * x, const gsl_vector * y, gsl_matrix * A)
              int gsl_blas_cgeru (const gsl_complex_float alpha, const gsl_vector_complex_float * x, const gsl_vector_complex_float * y, gsl_matrix_complex_float * A)
              int gsl_blas_zgeru (const gsl_complex alpha, const gsl_vector_complex * x, const gsl_vector_complex * y, gsl_matrix_complex * A)

   These functions compute the rank-1 update :math:`A = \alpha x y^T + A` of
   the matrix :data:`A`.

.. index::
   single: GERC, Level-2 BLAS

.. function:: int gsl_blas_cgerc (const gsl_complex_float alpha, const gsl_vector_complex_float * x, const gsl_vector_complex_float * y, gsl_matrix_complex_float * A)
              int gsl_blas_zgerc (const gsl_complex alpha, const gsl_vector_complex * x, const gsl_vector_complex * y, gsl_matrix_complex * A)

   These functions compute the conjugate rank-1 update :math:`A = \alpha x y^H + A`
   of the matrix :data:`A`.

.. index::
   single: SYR, Level-2 BLAS

.. function:: int gsl_blas_ssyr (CBLAS_UPLO_t Uplo, float alpha, const gsl_vector_float * x, gsl_matrix_float * A)
              int gsl_blas_dsyr (CBLAS_UPLO_t Uplo, double alpha, const gsl_vector * x, gsl_matrix * A)

   These functions compute the symmetric rank-1 update :math:`A = \alpha x x^T + A`
   of the symmetric matrix :data:`A`.  Since the matrix :data:`A` is
   symmetric only its upper half or lower half need to be stored.  When
   :data:`Uplo` is :code:`CblasUpper` then the upper triangle and diagonal of
   :data:`A` are used, and when :data:`Uplo` is :code:`CblasLower` then the
   lower triangle and diagonal of :data:`A` are used.

.. index::
   single: HER, Level-2 BLAS

.. function:: int gsl_blas_cher (CBLAS_UPLO_t Uplo, float alpha, const gsl_vector_complex_float * x, gsl_matrix_complex_float * A)
              int gsl_blas_zher (CBLAS_UPLO_t Uplo, double alpha, const gsl_vector_complex * x, gsl_matrix_complex * A)

   These functions compute the hermitian rank-1 update :math:`A = \alpha x x^H + A`
   of the hermitian matrix :data:`A`.  Since the matrix :data:`A` is
   hermitian only its upper half or lower half need to be stored.  When
   :data:`Uplo` is :code:`CblasUpper` then the upper triangle and diagonal of
   :data:`A` are used, and when :data:`Uplo` is :code:`CblasLower` then the
   lower triangle and diagonal of :data:`A` are used.  The imaginary elements
   of the diagonal are automatically set to zero.

.. index::
   single: SYR2, Level-2 BLAS

.. function:: int gsl_blas_ssyr2 (CBLAS_UPLO_t Uplo, float alpha, const gsl_vector_float * x, const gsl_vector_float * y, gsl_matrix_float * A)
              int gsl_blas_dsyr2 (CBLAS_UPLO_t Uplo, double alpha, const gsl_vector * x, const gsl_vector * y, gsl_matrix * A)

   These functions compute the symmetric rank-2 update :math:`A = \alpha x y^T + \alpha y x^T + A`
   of the symmetric matrix :data:`A`.  Since the
   matrix :data:`A` is symmetric only its upper half or lower half need to be
   stored.  When :data:`Uplo` is :code:`CblasUpper` then the upper triangle
   and diagonal of :data:`A` are used, and when :data:`Uplo` is
   :code:`CblasLower` then the lower triangle and diagonal of :data:`A` are
   used.

.. index::
   single: HER2, Level-2 BLAS

.. function:: int gsl_blas_cher2 (CBLAS_UPLO_t Uplo, const gsl_complex_float alpha, const gsl_vector_complex_float * x, const gsl_vector_complex_float * y, gsl_matrix_complex_float * A)
              int gsl_blas_zher2 (CBLAS_UPLO_t Uplo, const gsl_complex alpha, const gsl_vector_complex * x, const gsl_vector_complex * y, gsl_matrix_complex * A)

   These functions compute the hermitian rank-2 update :math:`A = \alpha x y^H + \alpha^* y x^H + A`
   of the hermitian matrix :data:`A`.  Since the
   matrix :data:`A` is hermitian only its upper half or lower half need to be
   stored.  When :data:`Uplo` is :code:`CblasUpper` then the upper triangle
   and diagonal of :data:`A` are used, and when :data:`Uplo` is
   :code:`CblasLower` then the lower triangle and diagonal of :data:`A` are
   used.  The imaginary elements of the diagonal are automatically set to zero.

Level 3
-------

.. index::
   single: GEMM, Level-3 BLAS

.. function:: int gsl_blas_sgemm (CBLAS_TRANSPOSE_t TransA, CBLAS_TRANSPOSE_t TransB, float alpha, const gsl_matrix_float * A, const gsl_matrix_float * B, float beta, gsl_matrix_float * C)
              int gsl_blas_dgemm (CBLAS_TRANSPOSE_t TransA, CBLAS_TRANSPOSE_t TransB, double alpha, const gsl_matrix * A, const gsl_matrix * B, double beta, gsl_matrix * C)
              int gsl_blas_cgemm (CBLAS_TRANSPOSE_t TransA, CBLAS_TRANSPOSE_t TransB, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, const gsl_matrix_complex_float * B, const gsl_complex_float beta, gsl_matrix_complex_float * C)
              int gsl_blas_zgemm (CBLAS_TRANSPOSE_t TransA, CBLAS_TRANSPOSE_t TransB, const gsl_complex alpha, const gsl_matrix_complex * A, const gsl_matrix_complex * B, const gsl_complex beta, gsl_matrix_complex * C)

   These functions compute the matrix-matrix product and sum :math:`C = \alpha op(A) op(B) + \beta C`
   where :math:`op(A) = A`, :math:`A^T`,
   :math:`A^H` for :data:`TransA` = :code:`CblasNoTrans`, :code:`CblasTrans`,
   :code:`CblasConjTrans` and similarly for the parameter :data:`TransB`.

.. index::
   single: SYMM, Level-3 BLAS

.. function:: int gsl_blas_ssymm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, float alpha, const gsl_matrix_float * A, const gsl_matrix_float * B, float beta, gsl_matrix_float * C)
              int gsl_blas_dsymm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, double alpha, const gsl_matrix * A, const gsl_matrix * B, double beta, gsl_matrix * C)
              int gsl_blas_csymm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, const gsl_matrix_complex_float * B, const gsl_complex_float beta, gsl_matrix_complex_float * C)
              int gsl_blas_zsymm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, const gsl_complex alpha, const gsl_matrix_complex * A, const gsl_matrix_complex * B, const gsl_complex beta, gsl_matrix_complex * C)

   These functions compute the matrix-matrix product and sum :math:`C = \alpha A B + \beta C`
   for :data:`Side` is :code:`CblasLeft` and :math:`C = \alpha B A + \beta C`
   for :data:`Side` is :code:`CblasRight`, where the
   matrix :data:`A` is symmetric.  When :data:`Uplo` is :code:`CblasUpper` then
   the upper triangle and diagonal of :data:`A` are used, and when :data:`Uplo`
   is :code:`CblasLower` then the lower triangle and diagonal of :data:`A` are
   used.

.. index::
   single: HEMM, Level-3 BLAS

.. function:: int gsl_blas_chemm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, const gsl_matrix_complex_float * B, const gsl_complex_float beta, gsl_matrix_complex_float * C)
              int gsl_blas_zhemm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, const gsl_complex alpha, const gsl_matrix_complex * A, const gsl_matrix_complex * B, const gsl_complex beta, gsl_matrix_complex * C)

   These functions compute the matrix-matrix product and sum :math:`C = \alpha A B + \beta C`
   for :data:`Side` is :code:`CblasLeft` and :math:`C = \alpha B A + \beta C`
   for :data:`Side` is :code:`CblasRight`, where the
   matrix :data:`A` is hermitian.  When :data:`Uplo` is :code:`CblasUpper` then
   the upper triangle and diagonal of :data:`A` are used, and when :data:`Uplo`
   is :code:`CblasLower` then the lower triangle and diagonal of :data:`A` are
   used.  The imaginary elements of the diagonal are automatically set to
   zero.

.. index::
   single: TRMM, Level-3 BLAS

.. function:: int gsl_blas_strmm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, float alpha, const gsl_matrix_float * A, gsl_matrix_float * B)
              int gsl_blas_dtrmm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, double alpha, const gsl_matrix * A, gsl_matrix * B)
              int gsl_blas_ctrmm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, gsl_matrix_complex_float * B)
              int gsl_blas_ztrmm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_complex alpha, const gsl_matrix_complex * A, gsl_matrix_complex * B)

   These functions compute the matrix-matrix product :math:`B = \alpha op(A) B`
   for :data:`Side` is :code:`CblasLeft` and :math:`B = \alpha B op(A)` for
   :data:`Side` is :code:`CblasRight`.  The matrix :data:`A` is triangular and
   :math:`op(A) = A`, :math:`A^T`, :math:`A^H` for :data:`TransA` =
   :code:`CblasNoTrans`, :code:`CblasTrans`, :code:`CblasConjTrans`. When
   :data:`Uplo` is :code:`CblasUpper` then the upper triangle of :data:`A` is
   used, and when :data:`Uplo` is :code:`CblasLower` then the lower triangle
   of :data:`A` is used.  If :data:`Diag` is :code:`CblasNonUnit` then the
   diagonal of :data:`A` is used, but if :data:`Diag` is :code:`CblasUnit` then
   the diagonal elements of the matrix :data:`A` are taken as unity and are
   not referenced.

.. index::
   single: TRSM, Level-3 BLAS

.. function:: int gsl_blas_strsm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, float alpha, const gsl_matrix_float * A, gsl_matrix_float * B)
              int gsl_blas_dtrsm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, double alpha, const gsl_matrix * A, gsl_matrix * B)
              int gsl_blas_ctrsm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, gsl_matrix_complex_float * B)
              int gsl_blas_ztrsm (CBLAS_SIDE_t Side, CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t TransA, CBLAS_DIAG_t Diag, const gsl_complex alpha, const gsl_matrix_complex * A, gsl_matrix_complex * B)

   These functions compute the inverse-matrix matrix product 
   :math:`B = \alpha op(inv(A))B` for :data:`Side` is 
   :code:`CblasLeft` and :math:`B = \alpha B op(inv(A))` for
   :data:`Side` is :code:`CblasRight`.  The matrix :data:`A` is triangular and
   :math:`op(A) = A`, :math:`A^T`, :math:`A^H` for :data:`TransA` =
   :code:`CblasNoTrans`, :code:`CblasTrans`, :code:`CblasConjTrans`. When
   :data:`Uplo` is :code:`CblasUpper` then the upper triangle of :data:`A` is
   used, and when :data:`Uplo` is :code:`CblasLower` then the lower triangle
   of :data:`A` is used.  If :data:`Diag` is :code:`CblasNonUnit` then the
   diagonal of :data:`A` is used, but if :data:`Diag` is :code:`CblasUnit` then
   the diagonal elements of the matrix :data:`A` are taken as unity and are
   not referenced.

.. index::
   single: SYRK, Level-3 BLAS

.. function:: int gsl_blas_ssyrk (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, float alpha, const gsl_matrix_float * A, float beta, gsl_matrix_float * C)
              int gsl_blas_dsyrk (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, double alpha, const gsl_matrix * A, double beta, gsl_matrix * C)
              int gsl_blas_csyrk (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, const gsl_complex_float beta, gsl_matrix_complex_float * C)
              int gsl_blas_zsyrk (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, const gsl_complex alpha, const gsl_matrix_complex * A, const gsl_complex beta, gsl_matrix_complex * C)

   These functions compute a rank-k update of the symmetric matrix :data:`C`,
   :math:`C = \alpha A A^T + \beta C` when :data:`Trans` is
   :code:`CblasNoTrans` and :math:`C = \alpha A^T A + \beta C` when
   :data:`Trans` is :code:`CblasTrans`.  Since the matrix :data:`C` is symmetric
   only its upper half or lower half need to be stored.  When :data:`Uplo` is
   :code:`CblasUpper` then the upper triangle and diagonal of :data:`C` are
   used, and when :data:`Uplo` is :code:`CblasLower` then the lower triangle
   and diagonal of :data:`C` are used.

.. index::
   single: HERK, Level-3 BLAS

.. function:: int gsl_blas_cherk (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, float alpha, const gsl_matrix_complex_float * A, float beta, gsl_matrix_complex_float * C)
              int gsl_blas_zherk (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, double alpha, const gsl_matrix_complex * A, double beta, gsl_matrix_complex * C)

   These functions compute a rank-k update of the hermitian matrix :data:`C`,
   :math:`C = \alpha A A^H + \beta C` when :data:`Trans` is
   :code:`CblasNoTrans` and :math:`C = \alpha A^H A + \beta C` when
   :data:`Trans` is :code:`CblasConjTrans`.  Since the matrix :data:`C` is hermitian
   only its upper half or lower half need to be stored.  When :data:`Uplo` is
   :code:`CblasUpper` then the upper triangle and diagonal of :data:`C` are
   used, and when :data:`Uplo` is :code:`CblasLower` then the lower triangle
   and diagonal of :data:`C` are used.  The imaginary elements of the
   diagonal are automatically set to zero.

.. index::
   single: SYR2K, Level-3 BLAS

.. function:: int gsl_blas_ssyr2k (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, float alpha, const gsl_matrix_float * A, const gsl_matrix_float * B, float beta, gsl_matrix_float * C)
              int gsl_blas_dsyr2k (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, double alpha, const gsl_matrix * A, const gsl_matrix * B, double beta, gsl_matrix * C)
              int gsl_blas_csyr2k (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, const gsl_matrix_complex_float * B, const gsl_complex_float beta, gsl_matrix_complex_float * C)
              int gsl_blas_zsyr2k (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, const gsl_complex alpha, const gsl_matrix_complex * A, const gsl_matrix_complex * B, const gsl_complex beta, gsl_matrix_complex * C)

   These functions compute a rank-2k update of the symmetric matrix :data:`C`,
   :math:`C = \alpha A B^T + \alpha B A^T + \beta C` when :data:`Trans` is
   :code:`CblasNoTrans` and :math:`C = \alpha A^T B + \alpha B^T A + \beta C` when
   :data:`Trans` is :code:`CblasTrans`.  Since the matrix :data:`C` is symmetric
   only its upper half or lower half need to be stored.  When :data:`Uplo` is
   :code:`CblasUpper` then the upper triangle and diagonal of :data:`C` are
   used, and when :data:`Uplo` is :code:`CblasLower` then the lower triangle
   and diagonal of :data:`C` are used.

.. index::
   single: HER2K, Level-3 BLAS

.. function:: int gsl_blas_cher2k (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, const gsl_complex_float alpha, const gsl_matrix_complex_float * A, const gsl_matrix_complex_float * B, float beta, gsl_matrix_complex_float * C)
              int gsl_blas_zher2k (CBLAS_UPLO_t Uplo, CBLAS_TRANSPOSE_t Trans, const gsl_complex alpha, const gsl_matrix_complex * A, const gsl_matrix_complex * B, double beta, gsl_matrix_complex * C)

   These functions compute a rank-2k update of the hermitian matrix :data:`C`,
   :math:`C = \alpha A B^H + \alpha^* B A^H + \beta C` when :data:`Trans` is
   :code:`CblasNoTrans` and :math:`C = \alpha A^H B + \alpha^* B^H A + \beta C` when
   :data:`Trans` is :code:`CblasConjTrans`.  Since the matrix :data:`C` is hermitian
   only its upper half or lower half need to be stored.  When :data:`Uplo` is
   :code:`CblasUpper` then the upper triangle and diagonal of :data:`C` are
   used, and when :data:`Uplo` is :code:`CblasLower` then the lower triangle
   and diagonal of :data:`C` are used.  The imaginary elements of the
   diagonal are automatically set to zero.

Examples
========

The following program computes the product of two matrices using the
Level-3 BLAS function DGEMM,

.. only:: not texinfo

   .. math::

      \left(
      \begin{matrix}
        0.11&0.12&0.13 \\
        0.21&0.22&0.23
      \end{matrix}
      \right)
      \left(
      \begin{matrix}
        1011&1012 \\
        1021&1022 \\
        1031&1031
      \end{matrix}
      \right)
      =
      \left(
      \begin{matrix}
        367.76&368.12 \\
        674.06&674.72
      \end{matrix}
      \right)

.. only:: texinfo

   ::

      [ 0.11 0.12 0.13 ]  [ 1011 1012 ]     [ 367.76 368.12 ]
      [ 0.21 0.22 0.23 ]  [ 1021 1022 ]  =  [ 674.06 674.72 ]
                          [ 1031 1032 ]

The matrices are stored in row major order, according to the C convention 
for arrays.

.. include:: examples/blas.c
   :code:

Here is the output from the program,

.. include:: examples/blas.txt
   :code:

.. _sec_blas-references:

References and Further Reading
==============================

Information on the BLAS standards, including both the legacy and
updated interface standards, is available online from the BLAS
Homepage and BLAS Technical Forum web-site.

* BLAS Homepage, http://www.netlib.org/blas/

* BLAS Technical Forum, http://www.netlib.org/blas/blast-forum/

The following papers contain the specifications for Level 1, Level 2 and
Level 3 BLAS.

* C. Lawson, R. Hanson, D. Kincaid, F. Krogh, "Basic Linear Algebra
  Subprograms for Fortran Usage", ACM Transactions on Mathematical
  Software, Vol.: 5 (1979), Pages 308--325.

* J.J. Dongarra, J. DuCroz, S. Hammarling, R. Hanson, "An Extended Set of
  Fortran Basic Linear Algebra Subprograms", ACM Transactions on
  Mathematical Software, Vol.: 14, No.: 1 (1988), Pages 1--32.

* J.J. Dongarra, I. Duff, J. DuCroz, S. Hammarling, "A Set of
  Level 3 Basic Linear Algebra Subprograms", ACM Transactions on
  Mathematical Software, Vol.: 16 (1990), Pages 1--28.

Postscript versions of the latter two papers are available from
http://www.netlib.org/blas/. A CBLAS wrapper for Fortran BLAS
libraries is available from the same location.

.. rubric:: Footnotes

.. [#f1] In the low-level CBLAS interface, a negative stride accesses the vector elements
         in reverse order, i.e. the :math:`i`-th element is given by
         :math:`(N-i)*|incx|` for :math:`incx < 0`.
.. index::
   single: hypergeometric functions
   single: confluent hypergeometric functions

Hypergeometric functions are described in Abramowitz & Stegun, Chapters
13 and 15.  These functions are declared in the header file
:file:`gsl_sf_hyperg.h`.

.. function:: double gsl_sf_hyperg_0F1 (double c, double x)
              int gsl_sf_hyperg_0F1_e (double c, double x, gsl_sf_result * result)

   These routines compute the hypergeometric function
   
   .. only:: not texinfo
      
      .. math:: {}_0F_1(c,x)

   .. only:: texinfo

      .. math:: 0F1(c,x)

.. It is related to Bessel functions
.. 0F1[c,x] =
..   Gamma[c]    x^(1/2(1-c)) I_(c-1)(2 Sqrt[x])
..   Gamma[c] (-x)^(1/2(1-c)) J_(c-1)(2 Sqrt[-x])
.. exceptions: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_hyperg_1F1_int (int m, int n, double x)
              int gsl_sf_hyperg_1F1_int_e (int m, int n, double x, gsl_sf_result * result)

   These routines compute the confluent hypergeometric function

   .. only:: not texinfo

      .. math:: {}_1F_1(m,n,x) = M(m,n,x)

   .. only:: texinfo

      .. math:: 1F1(m,n,x) = M(m,n,x)

   for integer parameters :data:`m`, :data:`n`.
.. exceptions: 

.. function:: double gsl_sf_hyperg_1F1 (double a, double b, double x)
              int gsl_sf_hyperg_1F1_e (double a, double b, double x, gsl_sf_result * result)

   These routines compute the confluent hypergeometric function

   .. only:: not texinfo

      .. math:: {}_1F_1(a,b,x) = M(a,b,x)

   .. only:: texinfo

      .. math:: 1F1(a,b,x) = M(a,b,x)

   for general parameters :data:`a`, :data:`b`.
.. exceptions:

.. function:: double gsl_sf_hyperg_U_int (int m, int n, double x)
              int gsl_sf_hyperg_U_int_e (int m, int n, double x, gsl_sf_result * result)

   These routines compute the confluent hypergeometric function
   :math:`U(m,n,x)` for integer parameters :data:`m`, :data:`n`.
.. exceptions:

.. function:: int gsl_sf_hyperg_U_int_e10_e (int m, int n, double x, gsl_sf_result_e10 * result)

   This routine computes the confluent hypergeometric function
   :math:`U(m,n,x)` for integer parameters :data:`m`, :data:`n` using the
   :type:`gsl_sf_result_e10` type to return a result with extended range.

.. function:: double gsl_sf_hyperg_U (double a, double b, double x)
              int gsl_sf_hyperg_U_e (double a, double b, double x, gsl_sf_result * result)

   These routines compute the confluent hypergeometric function :math:`U(a,b,x)`.
.. exceptions:

.. function:: int gsl_sf_hyperg_U_e10_e (double a, double b, double x, gsl_sf_result_e10 * result)

   This routine computes the confluent hypergeometric function
   :math:`U(a,b,x)` using the :type:`gsl_sf_result_e10` type to return a
   result with extended range. 
.. exceptions:

.. function:: double gsl_sf_hyperg_2F1 (double a, double b, double c, double x)
              int gsl_sf_hyperg_2F1_e (double a, double b, double c, double x, gsl_sf_result * result)

   These routines compute the Gauss hypergeometric function

   .. only:: not texinfo

      .. math:: {}_2F_1(a,b,c,x) = F(a,b,c,x)

   .. only:: texinfo

      .. math:: 2F1(a,b,c,x) = F(a,b,c,x)
         
   for :math:`|x| < 1`. If the arguments :math:`(a,b,c,x)` are too close to a singularity then
   the function can return the error code :macro:`GSL_EMAXITER` when the
   series approximation converges too slowly.  This occurs in the region of
   :math:`x = 1`, :math:`c - a - b = m` for integer m.
.. exceptions:

.. function:: double gsl_sf_hyperg_2F1_conj (double aR, double aI, double c, double x)
              int gsl_sf_hyperg_2F1_conj_e (double aR, double aI, double c, double x, gsl_sf_result * result)

   These routines compute the Gauss hypergeometric function

   .. only:: not texinfo

      .. math:: {}_2F_1(a_R + i a_I, aR - i aI, c, x)

   .. only:: texinfo

      .. math:: 2F1(a_R + i a_I, aR - i aI, c, x)

   with complex parameters for :math:`|x| < 1`.

.. function:: double gsl_sf_hyperg_2F1_renorm (double a, double b, double c, double x)
              int gsl_sf_hyperg_2F1_renorm_e (double a, double b, double c, double x, gsl_sf_result * result)

   These routines compute the renormalized Gauss hypergeometric function

   .. only:: not texinfo

      .. math:: {}_2F_1(a,b,c,x) / \Gamma(c)

   .. only:: texinfo

      .. math:: 2F1(a,b,c,x) / \Gamma(c)

   for :math:`|x| < 1`.
.. exceptions:

.. function:: double gsl_sf_hyperg_2F1_conj_renorm (double aR, double aI, double c, double x)
              int gsl_sf_hyperg_2F1_conj_renorm_e (double aR, double aI, double c, double x, gsl_sf_result * result)

   These routines compute the renormalized Gauss hypergeometric function

   .. only:: not texinfo

      .. math:: {}_2F_1(a_R + i a_I, a_R - i a_I, c, x) / \Gamma(c)

   .. only:: texinfo

      .. math:: 2F1(a_R + i a_I, a_R - i a_I, c, x) / \Gamma(c)

   for :math:`|x| < 1`.
.. exceptions:

.. function:: double gsl_sf_hyperg_2F0 (double a, double b, double x)
              int gsl_sf_hyperg_2F0_e (double a, double b, double x, gsl_sf_result * result)

   These routines compute the hypergeometric function
   
   .. only:: not texinfo
      
      .. math:: {}_2F_0(a,b,x)

   .. only:: texinfo

      .. math:: 2F0(a,b,x)

   The series representation is a divergent hypergeometric series.
   However, for :math:`x < 0` we have 

   .. only:: not texinfo

      .. math:: {}_2F_0(a,b,x) = (-1/x)^a U(a,1+a-b,-1/x)

   .. only:: texinfo

      .. math:: 2F0(a,b,x) = (-1/x)^a U(a,1+a-b,-1/x)

.. exceptions: GSL_EDOM
.. index::
   single: Chebyshev series
   single: fitting, using Chebyshev polynomials
   single: interpolation, using Chebyshev polynomials

************************
Chebyshev Approximations
************************

This chapter describes routines for computing Chebyshev approximations
to univariate functions.  A Chebyshev approximation is a truncation of
the series :math:`f(x) = \sum c_n T_n(x)`, where the Chebyshev
polynomials :math:`T_n(x) = \cos(n \arccos x)` provide an orthogonal
basis of polynomials on the interval :math:`[-1,1]` with the weight
function :math:`1 / \sqrt{1-x^2}`.
The first few Chebyshev polynomials are,
:math:`T_0(x) = 1`, :math:`T_1(x) = x`, :math:`T_2(x) = 2 x^2 - 1`.
For further information see Abramowitz & Stegun, Chapter 22. 

The functions described in this chapter are declared in the header file
:file:`gsl_chebyshev.h`.

Definitions
===========

.. type:: gsl_cheb_series

   A Chebyshev series  is stored using the following structure::

      typedef struct
      {
        double * c;   /* coefficients  c[0] .. c[order] */
        int order;    /* order of expansion             */
        double a;     /* lower interval point           */
        double b;     /* upper interval point           */
        ...
      } gsl_cheb_series

The approximation is made over the range :math:`[a,b]` using
:data:`order` + 1 terms, including the coefficient :math:`c[0]`.  The series
is computed using the following convention,

.. only:: not texinfo

   .. math:: f(x) = {c_0 \over 2} + \sum_{n=1} c_n T_n(x)

.. only:: texinfo

   ::

      f(x) = (c_0 / 2) + \sum_{n=1} c_n T_n(x)

which is needed when accessing the coefficients directly.

Creation and Calculation of Chebyshev Series
============================================

.. function:: gsl_cheb_series * gsl_cheb_alloc (const size_t n)

   This function allocates space for a Chebyshev series of order :data:`n`
   and returns a pointer to a new :type:`gsl_cheb_series` struct.

.. function:: void gsl_cheb_free (gsl_cheb_series * cs)

   This function frees a previously allocated Chebyshev series :data:`cs`.

.. function:: int gsl_cheb_init (gsl_cheb_series * cs, const gsl_function * f, const double a, const double b)

   This function computes the Chebyshev approximation :data:`cs` for the
   function :data:`f` over the range :math:`(a,b)` to the previously specified
   order.  The computation of the Chebyshev approximation is an
   :math:`O(n^2)` process, and requires :math:`n` function evaluations.

Auxiliary Functions
===================
The following functions provide information about an existing
Chebyshev series.

.. function:: size_t gsl_cheb_order (const gsl_cheb_series * cs)

   This function returns the order of Chebyshev series :data:`cs`.

.. function:: size_t gsl_cheb_size (const gsl_cheb_series * cs)
              double * gsl_cheb_coeffs (const gsl_cheb_series * cs)

   These functions return the size of the Chebyshev coefficient array
   :code:`c[]` and a pointer to its location in memory for the Chebyshev
   series :data:`cs`.

Chebyshev Series Evaluation
===========================

.. function:: double gsl_cheb_eval (const gsl_cheb_series * cs, double x)

   This function evaluates the Chebyshev series :data:`cs` at a given point :data:`x`.

.. function:: int gsl_cheb_eval_err (const gsl_cheb_series * cs, const double x, double * result, double * abserr)

   This function computes the Chebyshev series :data:`cs` at a given point
   :data:`x`, estimating both the series :data:`result` and its absolute error
   :data:`abserr`.  The error estimate is made from the first neglected term
   in the series.

.. function:: double gsl_cheb_eval_n (const gsl_cheb_series * cs, size_t order, double x)

   This function evaluates the Chebyshev series :data:`cs` at a given point
   :data:`x`, to (at most) the given order :data:`order`.

.. function:: int gsl_cheb_eval_n_err (const gsl_cheb_series * cs, const size_t order, const double x, double * result, double * abserr)

   This function evaluates a Chebyshev series :data:`cs` at a given point
   :data:`x`, estimating both the series :data:`result` and its absolute error
   :data:`abserr`, to (at most) the given order :data:`order`.  The error
   estimate is made from the first neglected term in the series.

.. @deftypefun double gsl_cheb_eval_mode (const gsl_cheb_series * cs, double x, gsl_mode_t mode)
.. @end deftypefun

.. @deftypefun int gsl_cheb_eval_mode_err (const gsl_cheb_series * cs, const double x, gsl_mode_t mode, double * result, double * abserr)
.. Evaluate a Chebyshev series at a given point, using the default
.. order for double precision mode(s) and the single precision
.. order for other modes.
.. @end deftypefun

Derivatives and Integrals
=========================

The following functions allow a Chebyshev series to be differentiated or
integrated, producing a new Chebyshev series.  Note that the error
estimate produced by evaluating the derivative series will be
underestimated due to the contribution of higher order terms being
neglected.

.. function:: int gsl_cheb_calc_deriv (gsl_cheb_series * deriv, const gsl_cheb_series * cs)

   This function computes the derivative of the series :data:`cs`, storing
   the derivative coefficients in the previously allocated :data:`deriv`.
   The two series :data:`cs` and :data:`deriv` must have been allocated with
   the same order.

.. function:: int gsl_cheb_calc_integ (gsl_cheb_series * integ, const gsl_cheb_series * cs)

   This function computes the integral of the series :data:`cs`, storing the
   integral coefficients in the previously allocated :data:`integ`.  The two
   series :data:`cs` and :data:`integ` must have been allocated with the same
   order.  The lower limit of the integration is taken to be the left hand
   end of the range :data:`a`.

Examples
========

The following example program computes Chebyshev approximations to a
step function.  This is an extremely difficult approximation to make,
due to the discontinuity, and was chosen as an example where
approximation error is visible.  For smooth functions the Chebyshev
approximation converges extremely rapidly and errors would not be
visible.

.. include:: examples/cheb.c
   :code:

:numref:`fig_cheb` shows output from the program with the original function, 10-th order
approximation and 40-th order approximation, all sampled at intervals of
0.001 in :math:`x`.

.. _fig_cheb:

.. figure:: /images/cheb.png
   :scale: 60%

   Chebyshev approximations to a step function

References and Further Reading
==============================

The following paper describes the use of Chebyshev series,

* R. Broucke, "Ten Subroutines for the Manipulation of Chebyshev Series
  [C1] (Algorithm 446)". *Communications of the ACM* 16(4), 254--256
  (1973)
.. index:: complex numbers

***************
Complex Numbers
***************

The functions described in this chapter provide support for complex
numbers.  The algorithms take care to avoid unnecessary intermediate
underflows and overflows, allowing the functions to be evaluated over 
as much of the complex plane as possible. 

.. FIXME: this still needs to be
.. done for the csc,sec,cot,csch,sech,coth functions

For multiple-valued functions the branch cuts have been chosen to follow
the conventions of Abramowitz and Stegun.
The functions return principal values which are
the same as those in GNU Calc, which in turn are the same as those in
"Common Lisp, The Language (Second Edition)" [#f1]_
and the HP-28/48 series of calculators.

The complex types are defined in the header file :file:`gsl_complex.h`,
while the corresponding complex functions and arithmetic operations are
defined in :file:`gsl_complex_math.h`.

.. index::
   single: representations of complex numbers
   single: polar form of complex numbers
   single: gsl_complex

Representation of complex numbers
=================================

Complex numbers are represented using the type :code:`gsl_complex`. The
internal representation of this type may vary across platforms and
should not be accessed directly. The functions and macros described
below allow complex numbers to be manipulated in a portable way.

For reference, the default form of the :code:`gsl_complex` type is
given by the following struct::

    typedef struct
    {
      double dat[2];
    } gsl_complex;

The real and imaginary part are stored in contiguous elements of a two
element array. This eliminates any padding between the real and
imaginary parts, :code:`dat[0]` and :code:`dat[1]`, allowing the struct to
be mapped correctly onto packed complex arrays.

.. function:: gsl_complex gsl_complex_rect (double x, double y)

   This function uses the rectangular Cartesian components
   :math:`(x,y)` to return the complex number :math:`z = x + i y`.
   An inline version of this function is used when :macro:`HAVE_INLINE`
   is defined.

.. function:: gsl_complex gsl_complex_polar (double r, double theta)

   This function returns the complex number :math:`z = r \exp(i \theta) = r
   (\cos(\theta) + i \sin(\theta))` from the polar representation
   (:data:`r`, :data:`theta`).

.. macro::
   GSL_REAL (z)
   GSL_IMAG (z)

   These macros return the real and imaginary parts of the complex number
   :data:`z`.

.. macro:: GSL_SET_COMPLEX (zp, x, y)

   This macro uses the Cartesian components (:data:`x`, :data:`y`) to set the
   real and imaginary parts of the complex number pointed to by :data:`zp`.
   For example::

     GSL_SET_COMPLEX(&z, 3, 4)

   sets :math:`z` to be :math:`3 + 4i`.

.. macro::
   GSL_SET_REAL (zp,x)
   GSL_SET_IMAG (zp,y)

   These macros allow the real and imaginary parts of the complex number
   pointed to by :data:`zp` to be set independently.

Properties of complex numbers
=============================

.. index:: argument of complex number

.. function:: double gsl_complex_arg (gsl_complex z)

   This function returns the argument of the complex number :data:`z`,
   :math:`\arg(z)`, where :math:`-\pi < \arg(z) <= \pi`.

.. index:: magnitude of complex number

.. function:: double gsl_complex_abs (gsl_complex z)

   This function returns the magnitude of the complex number :data:`z`, :math:`|z|`.

.. function:: double gsl_complex_abs2 (gsl_complex z)

   This function returns the squared magnitude of the complex number
   :data:`z`, :math:`|z|^2`.

.. function:: double gsl_complex_logabs (gsl_complex z)

   This function returns the natural logarithm of the magnitude of the
   complex number :data:`z`, :math:`\log|z|`.  It allows an accurate
   evaluation of :math:`\log|z|` when :math:`|z|` is close to one. The direct
   evaluation of :code:`log(gsl_complex_abs(z))` would lead to a loss of
   precision in this case.

.. index:: complex arithmetic

Complex arithmetic operators
============================

.. function:: gsl_complex gsl_complex_add (gsl_complex a, gsl_complex b)

   This function returns the sum of the complex numbers :data:`a` and
   :data:`b`, :math:`z=a+b`.

.. function:: gsl_complex gsl_complex_sub (gsl_complex a, gsl_complex b)

   This function returns the difference of the complex numbers :data:`a` and
   :data:`b`, :math:`z=a-b`.

.. function:: gsl_complex gsl_complex_mul (gsl_complex a, gsl_complex b)

   This function returns the product of the complex numbers :data:`a` and
   :data:`b`, :math:`z=ab`.

.. function:: gsl_complex gsl_complex_div (gsl_complex a, gsl_complex b)

   This function returns the quotient of the complex numbers :data:`a` and
   :data:`b`, :math:`z=a/b`.

.. function:: gsl_complex gsl_complex_add_real (gsl_complex a, double x)

   This function returns the sum of the complex number :data:`a` and the
   real number :data:`x`, :math:`z=a+x`.

.. function:: gsl_complex gsl_complex_sub_real (gsl_complex a, double x)

   This function returns the difference of the complex number :data:`a` and the
   real number :data:`x`, :math:`z=a-x`.

.. function:: gsl_complex gsl_complex_mul_real (gsl_complex a, double x)

   This function returns the product of the complex number :data:`a` and the
   real number :data:`x`, :math:`z=ax`.

.. function:: gsl_complex gsl_complex_div_real (gsl_complex a, double x)

   This function returns the quotient of the complex number :data:`a` and the
   real number :data:`x`, :math:`z=a/x`.

.. function:: gsl_complex gsl_complex_add_imag (gsl_complex a, double y)

   This function returns the sum of the complex number :data:`a` and the
   imaginary number :math:`iy`, :math:`z=a+iy`.

.. function:: gsl_complex gsl_complex_sub_imag (gsl_complex a, double y)

   This function returns the difference of the complex number :data:`a` and the
   imaginary number :math:`iy`, :math:`z=a-iy`.

.. function:: gsl_complex gsl_complex_mul_imag (gsl_complex a, double y)

   This function returns the product of the complex number :data:`a` and the
   imaginary number :math:`iy`, :math:`z=a*(iy)`.

.. function:: gsl_complex gsl_complex_div_imag (gsl_complex a, double y)

   This function returns the quotient of the complex number :data:`a` and the
   imaginary number :math:`iy`, :math:`z=a/(iy)`.

.. index:: conjugate of complex number

.. function:: gsl_complex gsl_complex_conjugate (gsl_complex z)

   This function returns the complex conjugate of the complex number
   :data:`z`, :math:`z^* = x - i y`.

.. function:: gsl_complex gsl_complex_inverse (gsl_complex z)

   This function returns the inverse, or reciprocal, of the complex number
   :data:`z`, :math:`1/z = (x - i y)/(x^2 + y^2)`.

.. function:: gsl_complex gsl_complex_negative (gsl_complex z)

   This function returns the negative of the complex number
   :data:`z`, :math:`-z = (-x) + i(-y)`.


Elementary Complex Functions
============================

.. index:: square root of complex number

.. function:: gsl_complex gsl_complex_sqrt (gsl_complex z)

   This function returns the square root of the complex number :data:`z`,
   :math:`\sqrt z`. The branch cut is the negative real axis. The result
   always lies in the right half of the complex plane.

.. function:: gsl_complex gsl_complex_sqrt_real (double x)

   This function returns the complex square root of the real number
   :data:`x`, where :data:`x` may be negative.

.. index::
   single: power of complex number
   single: exponentiation of complex number

.. function:: gsl_complex gsl_complex_pow (gsl_complex z, gsl_complex a)

   The function returns the complex number :data:`z` raised to the complex
   power :data:`a`, :math:`z^a`. This is computed as :math:`\exp(\log(z)*a)`
   using complex logarithms and complex exponentials.

.. function:: gsl_complex gsl_complex_pow_real (gsl_complex z, double x)

   This function returns the complex number :data:`z` raised to the real
   power :data:`x`, :math:`z^x`.

.. function:: gsl_complex gsl_complex_exp (gsl_complex z)

   This function returns the complex exponential of the complex number
   :data:`z`, :math:`\exp(z)`.

.. index:: logarithm of complex number

.. function:: gsl_complex gsl_complex_log (gsl_complex z)

   This function returns the complex natural logarithm (base :math:`e`) of
   the complex number :data:`z`, :math:`\log(z)`.  The branch cut is the
   negative real axis. 

.. function:: gsl_complex gsl_complex_log10 (gsl_complex z)

   This function returns the complex base-10 logarithm of
   the complex number :data:`z`, :math:`\log_{10} (z)`.

.. function:: gsl_complex gsl_complex_log_b (gsl_complex z, gsl_complex b)

   This function returns the complex base-:data:`b` logarithm of the complex
   number :data:`z`, :math:`\log_b(z)`. This quantity is computed as the ratio
   :math:`\log(z)/\log(b)`.

.. index:: trigonometric functions of complex numbers

Complex Trigonometric Functions
===============================

.. index::
   single: sin, of complex number

.. function:: gsl_complex gsl_complex_sin (gsl_complex z)

   This function returns the complex sine of the complex number :data:`z`,
   :math:`\sin(z) = (\exp(iz) - \exp(-iz))/(2i)`.

.. index:: cosine of complex number

.. function:: gsl_complex gsl_complex_cos (gsl_complex z)

   This function returns the complex cosine of the complex number :data:`z`,
   :math:`\cos(z) = (\exp(iz) + \exp(-iz))/2`.

.. index:: tangent of complex number

.. function:: gsl_complex gsl_complex_tan (gsl_complex z)

   This function returns the complex tangent of the complex number :data:`z`,
   :math:`\tan(z) = \sin(z)/\cos(z)`.

.. function:: gsl_complex gsl_complex_sec (gsl_complex z)

   This function returns the complex secant of the complex number :data:`z`,
   :math:`\sec(z) = 1/\cos(z)`.

.. function:: gsl_complex gsl_complex_csc (gsl_complex z)

   This function returns the complex cosecant of the complex number :data:`z`,
   :math:`\csc(z) = 1/\sin(z)`.

.. function:: gsl_complex gsl_complex_cot (gsl_complex z)

   This function returns the complex cotangent of the complex number :data:`z`,
   :math:`\cot(z) = 1/\tan(z)`.

.. index:: inverse complex trigonometric functions

Inverse Complex Trigonometric Functions
=======================================

.. function:: gsl_complex gsl_complex_arcsin (gsl_complex z)

   This function returns the complex arcsine of the complex number :data:`z`,
   :math:`\arcsin(z)`. The branch cuts are on the real axis, less than :math:`-1`
   and greater than :math:`1`.

.. function:: gsl_complex gsl_complex_arcsin_real (double z)

   This function returns the complex arcsine of the real number :data:`z`,
   :math:`\arcsin(z)`. For :math:`z` between :math:`-1` and :math:`1`, the
   function returns a real value in the range :math:`[-\pi/2,\pi/2]`. For
   :math:`z` less than :math:`-1` the result has a real part of :math:`-\pi/2`
   and a positive imaginary part.  For :math:`z` greater than :math:`1` the
   result has a real part of :math:`\pi/2` and a negative imaginary part.

.. function:: gsl_complex gsl_complex_arccos (gsl_complex z)

   This function returns the complex arccosine of the complex number :data:`z`,
   :math:`\arccos(z)`. The branch cuts are on the real axis, less than :math:`-1`
   and greater than :math:`1`.

.. function:: gsl_complex gsl_complex_arccos_real (double z)

   This function returns the complex arccosine of the real number :data:`z`,
   :math:`\arccos(z)`. For :math:`z` between :math:`-1` and :math:`1`, the
   function returns a real value in the range :math:`[0,\pi]`. For :math:`z`
   less than :math:`-1` the result has a real part of :math:`\pi` and a
   negative imaginary part.  For :math:`z` greater than :math:`1` the result
   is purely imaginary and positive.

.. function:: gsl_complex gsl_complex_arctan (gsl_complex z)

   This function returns the complex arctangent of the complex number
   :data:`z`, :math:`\arctan(z)`. The branch cuts are on the imaginary axis,
   below :math:`-i` and above :math:`i`.

.. function:: gsl_complex gsl_complex_arcsec (gsl_complex z)

   This function returns the complex arcsecant of the complex number :data:`z`,
   :math:`\arcsec(z) = \arccos(1/z)`.

.. function:: gsl_complex gsl_complex_arcsec_real (double z)

   This function returns the complex arcsecant of the real number :data:`z`,
   :math:`\arcsec(z) = \arccos(1/z)`.

.. function:: gsl_complex gsl_complex_arccsc (gsl_complex z)

   This function returns the complex arccosecant of the complex number :data:`z`,
   :math:`\arccsc(z) = \arcsin(1/z)`.

.. function:: gsl_complex gsl_complex_arccsc_real (double z)

   This function returns the complex arccosecant of the real number :data:`z`,
   :math:`\arccsc(z) = \arcsin(1/z)`.

.. function:: gsl_complex gsl_complex_arccot (gsl_complex z)

   This function returns the complex arccotangent of the complex number :data:`z`,
   :math:`\arccot(z) = \arctan(1/z)`.

.. index::
   single: hyperbolic functions, complex numbers

Complex Hyperbolic Functions
============================

.. function:: gsl_complex gsl_complex_sinh (gsl_complex z)

   This function returns the complex hyperbolic sine of the complex number
   :data:`z`, :math:`\sinh(z) = (\exp(z) - \exp(-z))/2`.

.. function:: gsl_complex gsl_complex_cosh (gsl_complex z)

   This function returns the complex hyperbolic cosine of the complex number
   :data:`z`, :math:`\cosh(z) = (\exp(z) + \exp(-z))/2`.

.. function:: gsl_complex gsl_complex_tanh (gsl_complex z)

   This function returns the complex hyperbolic tangent of the complex number
   :data:`z`, :math:`\tanh(z) = \sinh(z)/\cosh(z)`.

.. function:: gsl_complex gsl_complex_sech (gsl_complex z)

   This function returns the complex hyperbolic secant of the complex
   number :data:`z`, :math:`\sech(z) = 1/\cosh(z)`.

.. function:: gsl_complex gsl_complex_csch (gsl_complex z)

   This function returns the complex hyperbolic cosecant of the complex
   number :data:`z`, :math:`\csch(z) = 1/\sinh(z)`.

.. function:: gsl_complex gsl_complex_coth (gsl_complex z)

   This function returns the complex hyperbolic cotangent of the complex
   number :data:`z`, :math:`\coth(z) = 1/\tanh(z)`.

.. index::
   single: inverse hyperbolic functions, complex numbers

Inverse Complex Hyperbolic Functions
====================================

.. function:: gsl_complex gsl_complex_arcsinh (gsl_complex z)

   This function returns the complex hyperbolic arcsine of the
   complex number :data:`z`, :math:`\arcsinh(z)`.  The branch cuts are on the
   imaginary axis, below :math:`-i` and above :math:`i`.

.. function:: gsl_complex gsl_complex_arccosh (gsl_complex z)

   This function returns the complex hyperbolic arccosine of the complex
   number :data:`z`, :math:`\arccosh(z)`.  The branch cut is on the real
   axis, less than :math:`1`.  Note that in this case we use the negative
   square root in formula 4.6.21 of Abramowitz & Stegun giving
   :math:`\arccosh(z)=\log(z-\sqrt{z^2-1})`.

.. function:: gsl_complex gsl_complex_arccosh_real (double z)

   This function returns the complex hyperbolic arccosine of
   the real number :data:`z`, :math:`\arccosh(z)`.

.. function:: gsl_complex gsl_complex_arctanh (gsl_complex z)

   This function returns the complex hyperbolic arctangent of the complex
   number :data:`z`, :math:`\arctanh(z)`.  The branch cuts are on the real
   axis, less than :math:`-1` and greater than :math:`1`.

.. function:: gsl_complex gsl_complex_arctanh_real (double z)

   This function returns the complex hyperbolic arctangent of the real
   number :data:`z`, :math:`\arctanh(z)`.

.. function:: gsl_complex gsl_complex_arcsech (gsl_complex z)

   This function returns the complex hyperbolic arcsecant of the complex
   number :data:`z`, :math:`\arcsech(z) = \arccosh(1/z)`.

.. function:: gsl_complex gsl_complex_arccsch (gsl_complex z)

   This function returns the complex hyperbolic arccosecant of the complex
   number :data:`z`, :math:`\arccsch(z) = \arcsinh(1/z)`.

.. function:: gsl_complex gsl_complex_arccoth (gsl_complex z)

   This function returns the complex hyperbolic arccotangent of the complex
   number :data:`z`, :math:`\arccoth(z) = \arctanh(1/z)`.

References and Further Reading
==============================

The implementations of the elementary and trigonometric functions are
based on the following papers,

* T. E. Hull, Thomas F. Fairgrieve, Ping Tak Peter Tang,
  "Implementing Complex Elementary Functions Using Exception
  Handling", ACM Transactions on Mathematical Software, Volume 20
  (1994), pp 215--244, Corrigenda, p553

* T. E. Hull, Thomas F. Fairgrieve, Ping Tak Peter Tang,
  "Implementing the complex arcsin and arccosine functions using exception
  handling", ACM Transactions on Mathematical Software, Volume 23
  (1997) pp 299--335

The general formulas and details of branch cuts can be found in the
following books,

* Abramowitz and Stegun, Handbook of Mathematical Functions,
  "Circular Functions in Terms of Real and Imaginary Parts", Formulas
  4.3.55--58,
  "Inverse Circular Functions in Terms of Real and Imaginary Parts",
  Formulas 4.4.37--39,
  "Hyperbolic Functions in Terms of Real and Imaginary Parts",
  Formulas 4.5.49--52,
  "Inverse Hyperbolic Functions---relation to Inverse Circular Functions",
  Formulas 4.6.14--19.

* Dave Gillespie, Calc Manual, Free Software Foundation, ISBN
  1-882114-18-3

.. rubric:: Footnotes

.. [#f1] Note that the first edition uses different definitions.
.. index::
   single: Monte Carlo integration
   single: stratified sampling in Monte Carlo integration
   single: multidimensional integration

***********************
Monte Carlo Integration
***********************

This chapter describes routines for multidimensional Monte Carlo
integration.  These include the traditional Monte Carlo method and
adaptive algorithms such as VEGAS and MISER which use
importance sampling and stratified sampling techniques. Each algorithm
computes an estimate of a multidimensional definite integral of the
form,

.. math:: I = \int_{x_l}^{x_u} dx \int_{y_l}^{y_u} dy ... f(x, y, ...)

over a hypercubic region :math:`((x_l,x_u)`, :math:`(y_l,y_u), ...)` using
a fixed number of function calls.  The routines also provide a
statistical estimate of the error on the result.  This error estimate
should be taken as a guide rather than as a strict error bound---random 
sampling of the region may not uncover all the important features
of the function, resulting in an underestimate of the error.

The functions are defined in separate header files for each routine,
:file:`gsl_monte_plain.h`, :file:`gsl_monte_miser.h` and
:file:`gsl_monte_vegas.h`.

Interface
=========

All of the Monte Carlo integration routines use the same general form of
interface.  There is an allocator to allocate memory for control
variables and workspace, a routine to initialize those control
variables, the integrator itself, and a function to free the space when
done.

Each integration function requires a random number generator to be
supplied, and returns an estimate of the integral and its standard
deviation.  The accuracy of the result is determined by the number of
function calls specified by the user.  If a known level of accuracy is
required this can be achieved by calling the integrator several times
and averaging the individual results until the desired accuracy is
obtained.  

Random sample points used within the Monte Carlo routines are always
chosen strictly within the integration region, so that endpoint
singularities are automatically avoided.

The function to be integrated has its own datatype, defined in the
header file :file:`gsl_monte.h`.

.. type:: gsl_monte_function 

   This data type defines a general function with parameters for Monte
   Carlo integration.

   ============================================================ ==========================================
   :code:`double (* f) (double * x, size_t dim, void * params)` this function should return the value
                                                                :math:`f(x,params)` for the argument
                                                                :data:`x` and parameters :data:`params`,
                                                                where :data:`x` is an array of size
                                                                :data:`dim` giving the coordinates of the
                                                                point where the function is to be
                                                                evaluated.

   :code:`size_t dim`                                           the number of dimensions for :data:`x`.
   :code:`void * params`                                        a pointer to the parameters of the
                                                                function.
   ============================================================ ==========================================

Here is an example for a quadratic function in two dimensions,

.. math:: f(x,y) = a x^2 + b x y + c y^2

with :math:`a = 3`, :math:`b = 2`, :math:`c = 1`.  The following code
defines a :type:`gsl_monte_function` :code:`F` which you could pass to an
integrator::

  struct my_f_params { double a; double b; double c; };

  double
  my_f (double x[], size_t dim, void * p) {
     struct my_f_params * fp = (struct my_f_params *)p;

     if (dim != 2)
        {
          fprintf (stderr, "error: dim != 2");
          abort ();
        }

     return  fp->a * x[0] * x[0] 
               + fp->b * x[0] * x[1] 
                 + fp->c * x[1] * x[1];
  }

  gsl_monte_function F;
  struct my_f_params params = { 3.0, 2.0, 1.0 };

  F.f = &my_f;
  F.dim = 2;
  F.params = &params;

The function :math:`f(x)` can be evaluated using the following macro::

  #define GSL_MONTE_FN_EVAL(F,x) 
      (*((F)->f))(x,(F)->dim,(F)->params)

.. index:: plain Monte Carlo

PLAIN Monte Carlo
=================

The plain Monte Carlo algorithm samples points randomly from the
integration region to estimate the integral and its error.  Using this
algorithm the estimate of the integral :math:`E(f; N)` for :math:`N`
randomly distributed points :math:`x_i` is given by,

.. only:: not texinfo

   .. math:: E(f; N) =  V \langle f \rangle = {V \over N} \sum_i^N f(x_i)

.. only:: texinfo

   ::

      E(f; N) = =  V <f> = (V / N) \sum_i^N f(x_i)

where :math:`V` is the volume of the integration region.  The error on
this estimate :math:`\sigma(E;N)` is calculated from the estimated
variance of the mean,

.. only:: not texinfo

   .. math:: \sigma^2 (E; N) = {V^2 \over N^2 } \sum_i^N (f(x_i) - \langle f \rangle)^2.

.. only:: texinfo

   ::

      \sigma^2 (E; N) = (V^2 / N^2) \sum_i^N (f(x_i) -  <f>)^2.

For large :math:`N` this variance decreases asymptotically as
:math:`\Var(f)/N`, where :math:`\Var(f)` is the true variance of the
function over the integration region.  The error estimate itself should
decrease as :math:`\sigma(f)/\sqrt{N}`.
The familiar law of errors
decreasing as :math:`1/\sqrt{N}`
applies---to reduce the error by a
factor of 10 requires a 100-fold increase in the number of sample
points.

The functions described in this section are declared in the header file
:file:`gsl_monte_plain.h`.

.. type:: gsl_monte_plain_state

   This is a workspace for plain Monte Carlo integration

.. function:: gsl_monte_plain_state * gsl_monte_plain_alloc (size_t dim)

   This function allocates and initializes a workspace for Monte Carlo
   integration in :data:`dim` dimensions.  

.. function:: int gsl_monte_plain_init (gsl_monte_plain_state* s)

   This function initializes a previously allocated integration state.
   This allows an existing workspace to be reused for different
   integrations.

.. function:: int gsl_monte_plain_integrate (gsl_monte_function * f, const double xl[], const double xu[], size_t dim, size_t calls, gsl_rng * r, gsl_monte_plain_state * s, double * result, double * abserr)

   This routines uses the plain Monte Carlo algorithm to integrate the
   function :data:`f` over the :data:`dim`-dimensional hypercubic region
   defined by the lower and upper limits in the arrays :data:`xl` and
   :data:`xu`, each of size :data:`dim`.  The integration uses a fixed number
   of function calls :data:`calls`, and obtains random sampling points using
   the random number generator :data:`r`. A previously allocated workspace
   :data:`s` must be supplied.  The result of the integration is returned in
   :data:`result`, with an estimated absolute error :data:`abserr`.

.. function:: void gsl_monte_plain_free (gsl_monte_plain_state * s)

   This function frees the memory associated with the integrator state
   :data:`s`.

.. index::
   single: MISER monte carlo integration
   single: recursive stratified sampling, MISER

MISER
=====

The MISER algorithm of Press and Farrar is based on recursive
stratified sampling.  This technique aims to reduce the overall
integration error by concentrating integration points in the regions of
highest variance.

The idea of stratified sampling begins with the observation that for two
disjoint regions :math:`a` and :math:`b` with Monte Carlo estimates of the
integral :math:`E_a(f)` and :math:`E_b(f)` and variances
:math:`\sigma_a^2(f)` and :math:`\sigma_b^2(f)`, the variance
:math:`\Var(f)` of the combined estimate 
:math:`E(f) = {1\over 2} (E_a(f) + E_b(f))`
is given by,

.. only:: not texinfo

   .. math:: \Var(f) = {\sigma_a^2(f) \over 4 N_a} + {\sigma_b^2(f) \over 4 N_b}.

.. only:: texinfo

   ::

      \Var(f) = (\sigma_a^2(f) / 4 N_a) + (\sigma_b^2(f) / 4 N_b).

It can be shown that this variance is minimized by distributing the
points such that,

.. only:: not texinfo

   .. math:: {N_a \over N_a+N_b} = {\sigma_a \over \sigma_a + \sigma_b}.

.. only:: texinfo

   ::

      N_a / (N_a + N_b) = \sigma_a / (\sigma_a + \sigma_b).

Hence the smallest error estimate is obtained by allocating sample
points in proportion to the standard deviation of the function in each
sub-region.

The MISER algorithm proceeds by bisecting the integration region
along one coordinate axis to give two sub-regions at each step.  The
direction is chosen by examining all :math:`d` possible bisections and
selecting the one which will minimize the combined variance of the two
sub-regions.  The variance in the sub-regions is estimated by sampling
with a fraction of the total number of points available to the current
step.  The same procedure is then repeated recursively for each of the
two half-spaces from the best bisection. The remaining sample points are
allocated to the sub-regions using the formula for :math:`N_a` and
:math:`N_b`.  This recursive allocation of integration points continues
down to a user-specified depth where each sub-region is integrated using
a plain Monte Carlo estimate.  These individual values and their error
estimates are then combined upwards to give an overall result and an
estimate of its error.

The functions described in this section are declared in the header file
:file:`gsl_monte_miser.h`.

.. type:: gsl_monte_miser_state

   This workspace is used for MISER Monte Carlo integration

.. function:: gsl_monte_miser_state * gsl_monte_miser_alloc (size_t dim)

   This function allocates and initializes a workspace for Monte Carlo
   integration in :data:`dim` dimensions.  The workspace is used to maintain
   the state of the integration.

.. function:: int gsl_monte_miser_init (gsl_monte_miser_state* s)

   This function initializes a previously allocated integration state.
   This allows an existing workspace to be reused for different
   integrations.

.. function:: int gsl_monte_miser_integrate (gsl_monte_function * f, const double xl[], const double xu[], size_t dim, size_t calls, gsl_rng * r, gsl_monte_miser_state * s, double * result, double * abserr)

   This routines uses the MISER Monte Carlo algorithm to integrate the
   function :data:`f` over the :data:`dim`-dimensional hypercubic region
   defined by the lower and upper limits in the arrays :data:`xl` and
   :data:`xu`, each of size :data:`dim`.  The integration uses a fixed number
   of function calls :data:`calls`, and obtains random sampling points using
   the random number generator :data:`r`. A previously allocated workspace
   :data:`s` must be supplied.  The result of the integration is returned in
   :data:`result`, with an estimated absolute error :data:`abserr`.

.. function:: void gsl_monte_miser_free (gsl_monte_miser_state * s)

   This function frees the memory associated with the integrator state
   :data:`s`.

The MISER algorithm has several configurable parameters which can
be changed using the following two functions [#f1]_.

.. function:: void gsl_monte_miser_params_get (const gsl_monte_miser_state * s, gsl_monte_miser_params * params) 

   This function copies the parameters of the integrator state into the
   user-supplied :data:`params` structure.

.. function:: void gsl_monte_miser_params_set (gsl_monte_miser_state * s, const gsl_monte_miser_params * params)

   This function sets the integrator parameters based on values provided
   in the :data:`params` structure.

Typically the values of the parameters are first read using
:func:`gsl_monte_miser_params_get`, the necessary changes are made to
the fields of the :data:`params` structure, and the values are copied
back into the integrator state using
:func:`gsl_monte_miser_params_set`.  The functions use the
:type:`gsl_monte_miser_params` structure which contains the following
fields:

.. type:: gsl_monte_miser_params

   .. var:: double estimate_frac

      This parameter specifies the fraction of the currently available number of
      function calls which are allocated to estimating the variance at each
      recursive step. The default value is 0.1.

   .. var:: size_t min_calls

      This parameter specifies the minimum number of function calls required
      for each estimate of the variance. If the number of function calls
      allocated to the estimate using :data:`estimate_frac` falls below
      :data:`min_calls` then :data:`min_calls` are used instead.  This ensures
      that each estimate maintains a reasonable level of accuracy.  The
      default value of :data:`min_calls` is :code:`16 * dim`.

   .. var:: size_t min_calls_per_bisection

      This parameter specifies the minimum number of function calls required
      to proceed with a bisection step.  When a recursive step has fewer calls
      available than :data:`min_calls_per_bisection` it performs a plain Monte
      Carlo estimate of the current sub-region and terminates its branch of
      the recursion.  The default value of this parameter is :code:`32 * min_calls`.

   .. var:: double alpha

      This parameter controls how the estimated variances for the two
      sub-regions of a bisection are combined when allocating points.  With
      recursive sampling the overall variance should scale better than
      :math:`1/N`, since the values from the sub-regions will be obtained using
      a procedure which explicitly minimizes their variance.  To accommodate
      this behavior the MISER algorithm allows the total variance to
      depend on a scaling parameter :math:`\alpha`,

      .. only:: not texinfo

         .. math:: \Var(f) = {\sigma_a \over N_a^\alpha} + {\sigma_b \over N_b^\alpha}.

      .. only:: texinfo

         ::

            \Var(f) = {\sigma_a \over N_a^\alpha} + {\sigma_b \over N_b^\alpha}.

      The authors of the original paper describing MISER recommend the
      value :math:`\alpha = 2` as a good choice, obtained from numerical
      experiments, and this is used as the default value in this
      implementation.

   .. var:: double dither

      This parameter introduces a random fractional variation of size
      :data:`dither` into each bisection, which can be used to break the
      symmetry of integrands which are concentrated near the exact center of
      the hypercubic integration region.  The default value of dither is zero,
      so no variation is introduced. If needed, a typical value of
      :data:`dither` is 0.1.

.. index::
   single: VEGAS Monte Carlo integration
   single: importance sampling, VEGAS

VEGAS
=====

The VEGAS algorithm of Lepage is based on importance sampling.  It
samples points from the probability distribution described by the
function :math:`|f|`, so that the points are concentrated in the regions
that make the largest contribution to the integral.

In general, if the Monte Carlo integral of :math:`f` is sampled with
points distributed according to a probability distribution described by
the function :math:`g`, we obtain an estimate :math:`E_g(f; N)`,

.. math:: E_g(f; N) = E(f/g; N)

with a corresponding variance,

.. math:: \Var_g(f; N) = \Var(f/g; N)

If the probability distribution is chosen as :math:`g = |f|/I(|f|)` then
it can be shown that the variance :math:`V_g(f; N)` vanishes, and the
error in the estimate will be zero.  In practice it is not possible to
sample from the exact distribution :math:`g` for an arbitrary function, so
importance sampling algorithms aim to produce efficient approximations
to the desired distribution.

The VEGAS algorithm approximates the exact distribution by making a
number of passes over the integration region while histogramming the
function :math:`f`. Each histogram is used to define a sampling
distribution for the next pass.  Asymptotically this procedure converges
to the desired distribution. In order
to avoid the number of histogram bins growing like :math:`K^d` the
probability distribution is approximated by a separable function:
:math:`g(x_1, x_2, \ldots) = g_1(x_1) g_2(x_2) \ldots`
so that the number of bins required is only :math:`Kd`.     
This is equivalent to locating the peaks of the function from the
projections of the integrand onto the coordinate axes.  The efficiency
of VEGAS depends on the validity of this assumption.  It is most
efficient when the peaks of the integrand are well-localized.  If an
integrand can be rewritten in a form which is approximately separable
this will increase the efficiency of integration with VEGAS.

VEGAS incorporates a number of additional features, and combines both
stratified sampling and importance sampling.  The integration region is
divided into a number of "boxes", with each box getting a fixed
number of points (the goal is 2).  Each box can then have a fractional
number of bins, but if the ratio of bins-per-box is less than two, Vegas switches to a
kind variance reduction (rather than importance sampling).

.. type:: gsl_monte_vegas_state

   This workspace is used for VEGAS Monte Carlo integration

.. function:: gsl_monte_vegas_state * gsl_monte_vegas_alloc (size_t dim)

   This function allocates and initializes a workspace for Monte Carlo
   integration in :data:`dim` dimensions.  The workspace is used to maintain
   the state of the integration.

.. function:: int gsl_monte_vegas_init (gsl_monte_vegas_state* s)

   This function initializes a previously allocated integration state.
   This allows an existing workspace to be reused for different
   integrations.

.. function:: int gsl_monte_vegas_integrate (gsl_monte_function * f, double xl[], double xu[], size_t dim, size_t calls, gsl_rng * r, gsl_monte_vegas_state * s, double * result, double * abserr)

   This routines uses the VEGAS Monte Carlo algorithm to integrate the
   function :data:`f` over the :data:`dim`-dimensional hypercubic region
   defined by the lower and upper limits in the arrays :data:`xl` and
   :data:`xu`, each of size :data:`dim`.  The integration uses a fixed number
   of function calls :data:`calls`, and obtains random sampling points using
   the random number generator :data:`r`. A previously allocated workspace
   :data:`s` must be supplied.  The result of the integration is returned in
   :data:`result`, with an estimated absolute error :data:`abserr`.  The result
   and its error estimate are based on a weighted average of independent
   samples. The chi-squared per degree of freedom for the weighted average
   is returned via the state struct component, :code:`s->chisq`, and must be
   consistent with 1 for the weighted average to be reliable.

.. function:: void gsl_monte_vegas_free (gsl_monte_vegas_state * s)

   This function frees the memory associated with the integrator state
   :data:`s`.

The VEGAS algorithm computes a number of independent estimates of the
integral internally, according to the :code:`iterations` parameter
described below, and returns their weighted average.  Random sampling of
the integrand can occasionally produce an estimate where the error is
zero, particularly if the function is constant in some regions. An
estimate with zero error causes the weighted average to break down and
must be handled separately. In the original Fortran implementations of
VEGAS the error estimate is made non-zero by substituting a small
value (typically :code:`1e-30`).  The implementation in GSL differs from
this and avoids the use of an arbitrary constant---it either assigns
the value a weight which is the average weight of the preceding
estimates or discards it according to the following procedure,

* current estimate has zero error, weighted average has finite error

  The current estimate is assigned a weight which is the average weight of
  the preceding estimates.

* current estimate has finite error, previous estimates had zero error

  The previous estimates are discarded and the weighted averaging
  procedure begins with the current estimate.

* current estimate has zero error, previous estimates had zero error

  The estimates are averaged using the arithmetic mean, but no error is computed.

The convergence of the algorithm can be tested using the overall
chi-squared value of the results, which is available from the
following function:

.. function:: double gsl_monte_vegas_chisq (const gsl_monte_vegas_state * s)

   This function returns the chi-squared per degree of freedom for the
   weighted estimate of the integral.  The returned value should be close
   to 1.  A value which differs significantly from 1 indicates that the
   values from different iterations are inconsistent.  In this case the
   weighted error will be under-estimated, and further iterations of the
   algorithm are needed to obtain reliable results.

.. function:: void gsl_monte_vegas_runval (const gsl_monte_vegas_state * s, double * result, double * sigma)

   This function returns the raw (unaveraged) values of the integral
   :data:`result` and its error :data:`sigma` from the most recent iteration
   of the algorithm.

The VEGAS algorithm is highly configurable. Several parameters
can be changed using the following two functions.

.. function:: void gsl_monte_vegas_params_get (const gsl_monte_vegas_state * s, gsl_monte_vegas_params * params) 

   This function copies the parameters of the integrator state into the
   user-supplied :data:`params` structure.

.. function:: void gsl_monte_vegas_params_set (gsl_monte_vegas_state * s, const gsl_monte_vegas_params * params)

   This function sets the integrator parameters based on values provided
   in the :data:`params` structure.

Typically the values of the parameters are first read using
:func:`gsl_monte_vegas_params_get`, the necessary changes are made to
the fields of the :data:`params` structure, and the values are copied
back into the integrator state using
:func:`gsl_monte_vegas_params_set`.  The functions use the
:type:`gsl_monte_vegas_params` structure which contains the following
fields:

.. type:: gsl_monte_vegas_params

   .. var:: double alpha

      The parameter :data:`alpha` controls the stiffness of the rebinning
      algorithm.  It is typically set between one and two. A value of zero
      prevents rebinning of the grid.  The default value is 1.5.

   .. var:: size_t iterations

      The number of iterations to perform for each call to the routine. The
      default value is 5 iterations.

   .. var:: int stage

      Setting this determines the *stage* of the calculation.  Normally,
      :code:`stage = 0` which begins with a new uniform grid and empty weighted
      average.  Calling VEGAS with :code:`stage = 1` retains the grid from the
      previous run but discards the weighted average, so that one can "tune"
      the grid using a relatively small number of points and then do a large
      run with :code:`stage = 1` on the optimized grid.  Setting :code:`stage = 2`
      keeps the grid and the weighted average from the previous run, but
      may increase (or decrease) the number of histogram bins in the grid
      depending on the number of calls available.  Choosing :code:`stage = 3`
      enters at the main loop, so that nothing is changed, and is equivalent
      to performing additional iterations in a previous call.

   .. var:: int mode

      The possible choices are :macro:`GSL_VEGAS_MODE_IMPORTANCE`,
      :macro:`GSL_VEGAS_MODE_STRATIFIED`, :macro:`GSL_VEGAS_MODE_IMPORTANCE_ONLY`.
      This determines whether VEGAS will use importance sampling or
      stratified sampling, or whether it can pick on its own.  In low
      dimensions VEGAS uses strict stratified sampling (more precisely,
      stratified sampling is chosen if there are fewer than 2 bins per box).

   .. var:: int verbose
            FILE * ostream

      These parameters set the level of information printed by VEGAS. All
      information is written to the stream :data:`ostream`.  The default setting
      of :data:`verbose` is :code:`-1`, which turns off all output.  A
      :data:`verbose` value of :code:`0` prints summary information about the
      weighted average and final result, while a value of :code:`1` also
      displays the grid coordinates.  A value of :code:`2` prints information
      from the rebinning procedure for each iteration.

The above fields and the :data:`chisq` value can also be accessed
directly in the :type:`gsl_monte_vegas_state` but such use is
deprecated.

Examples
========

The example program below uses the Monte Carlo routines to estimate the
value of the following 3-dimensional integral from the theory of random
walks,

.. only:: not texinfo

   .. math::

      I = \int_{-\pi}^{+\pi} {dk_x \over 2\pi} 
          \int_{-\pi}^{+\pi} {dk_y \over 2\pi} 
          \int_{-\pi}^{+\pi} {dk_z \over 2\pi} 
           { 1 \over (1 - \cos(k_x)\cos(k_y)\cos(k_z))}.

.. only:: texinfo

   ::

      I = \int_{-pi}^{+pi} {dk_x/(2 pi)} 
          \int_{-pi}^{+pi} {dk_y/(2 pi)} 
          \int_{-pi}^{+pi} {dk_z/(2 pi)} 
           1 / (1 - cos(k_x)cos(k_y)cos(k_z)).

The analytic value of this integral can be shown to be
:math:`I = \Gamma(1/4)^4/(4 \pi^3) = 1.393203929685676859...`.  The integral gives
the mean time spent at the origin by a random walk on a body-centered
cubic lattice in three dimensions.

For simplicity we will compute the integral over the region
:math:`(0,0,0)` to :math:`(\pi,\pi,\pi)` and multiply by 8 to obtain the
full result.  The integral is slowly varying in the middle of the region
but has integrable singularities at the corners :math:`(0,0,0)`,
:math:`(0,\pi,\pi)`, :math:`(\pi,0,\pi)` and :math:`(\pi,\pi,0)`.  The
Monte Carlo routines only select points which are strictly within the
integration region and so no special measures are needed to avoid these
singularities.

.. include:: examples/monte.c
   :code:

With 500,000 function calls the plain Monte Carlo algorithm achieves a
fractional error of 1%.  The estimated error :code:`sigma` is roughly
consistent with the actual error--the computed result differs from
the true result by about 1.4 standard deviations::

  plain ==================
  result =  1.412209
  sigma  =  0.013436
  exact  =  1.393204
  error  =  0.019005 = 1.4 sigma

The MISER algorithm reduces the error by a factor of four, and also
correctly estimates the error::

  miser ==================
  result =  1.391322
  sigma  =  0.003461
  exact  =  1.393204
  error  = -0.001882 = 0.54 sigma

In the case of the VEGAS algorithm the program uses an initial
warm-up run of 10,000 function calls to prepare, or "warm up", the grid.
This is followed by a main run with five iterations of 100,000 function
calls. The chi-squared per degree of freedom for the five iterations are
checked for consistency with 1, and the run is repeated if the results
have not converged. In this case the estimates are consistent on the
first pass::

  vegas warm-up ==================
  result =  1.392673
  sigma  =  0.003410
  exact  =  1.393204
  error  = -0.000531 = 0.16 sigma
  converging...
  result =  1.393281 sigma =  0.000362 chisq/dof = 1.5
  vegas final ==================
  result =  1.393281
  sigma  =  0.000362
  exact  =  1.393204
  error  =  0.000077 = 0.21 sigma

If the value of :code:`chisq` had differed significantly from 1 it would
indicate inconsistent results, with a correspondingly underestimated
error.  The final estimate from VEGAS (using a similar number of
function calls) is significantly more accurate than the other two
algorithms.

References and Further Reading
==============================

The MISER algorithm is described in the following article by Press
and Farrar,

* W.H. Press, G.R. Farrar, *Recursive Stratified Sampling for
  Multidimensional Monte Carlo Integration*,
  Computers in Physics, v4 (1990), pp190--195.

The VEGAS algorithm is described in the following papers,

* G.P. Lepage,
  *A New Algorithm for Adaptive Multidimensional Integration*,
  Journal of Computational Physics 27, 192--203, (1978)

* G.P. Lepage,
  *VEGAS: An Adaptive Multi-dimensional Integration Program*,
  Cornell preprint CLNS 80-447, March 1980

.. rubric:: Footnotes

.. [#f1] The previous method of accessing these fields directly through the
         :type:`gsl_monte_miser_state` struct is now deprecated.
.. index:: transport functions

The transport functions :math:`J(n,x)` are defined by the integral 
representations

.. math:: J(n,x) = \int_0^x t^n e^t /(e^t - 1)^2 dt

They are declared in the header file :file:`gsl_sf_transport.h`.

.. function:: double gsl_sf_transport_2 (double x)
              int gsl_sf_transport_2_e (double x, gsl_sf_result * result)

   These routines compute the transport function :math:`J(2,x)`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_transport_3 (double x)
              int gsl_sf_transport_3_e (double x, gsl_sf_result * result)

   These routines compute the transport function :math:`J(3,x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_transport_4 (double x)
              int gsl_sf_transport_4_e (double x, gsl_sf_result * result)

   These routines compute the transport function :math:`J(4,x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW

.. function:: double gsl_sf_transport_5 (double x)
              int gsl_sf_transport_5_e (double x, gsl_sf_result * result)

   These routines compute the transport function :math:`J(5,x)`.
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW
.. index::
   single: exponential integrals
   single: integrals, exponential

Information on the exponential integrals can be found in Abramowitz &
Stegun, Chapter 5.  These functions are declared in the header file
:file:`gsl_sf_expint.h`.

Exponential Integral
--------------------
.. index:: E1(x), E2(x), Ei(x)

.. function:: double gsl_sf_expint_E1 (double x)
              int gsl_sf_expint_E1_e (double x, gsl_sf_result * result)

   These routines compute the exponential integral :math:`E_1(x)`,

   .. math:: E_1(x) := \Re \int_1^\infty dt \exp(-xt)/t.

.. Domain: x != 0.0
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_expint_E2 (double x)
              int gsl_sf_expint_E2_e (double x, gsl_sf_result * result)

   These routines compute the second-order exponential integral :math:`E_2(x)`,

   .. math:: E_2(x) := \Re \int_1^\infty dt \exp(-xt)/t^2

.. Domain: x != 0.0
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_expint_En (int n, double x)
              int gsl_sf_expint_En_e (int n, double x, gsl_sf_result * result)

   These routines compute the exponential integral :math:`E_n(x)` of order :data:`n`, 

   .. math:: E_n(x) := \Re \int_1^\infty dt \exp(-xt)/t^n.

.. Domain: x != 0.0
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

Ei(x)
-----

.. function:: double gsl_sf_expint_Ei (double x)
              int gsl_sf_expint_Ei_e (double x, gsl_sf_result * result)

   These routines compute the exponential integral :math:`Ei(x)`,

   .. only:: not texinfo

      .. math:: \hbox{Ei}(x) = - PV \left( \int_{-x}^\infty dt \exp(-t)/t \right)

   .. only:: texinfo

      ::

         Ei(x) = - PV(\int_{-x}^\infty dt \exp(-t)/t)

   where :math:`PV` denotes the principal value of the integral.
.. Domain: x != 0.0
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

Hyperbolic Integrals
--------------------
.. index::
   single: hyperbolic integrals
   single: Shi(x)
   single: Chi(x)

.. function:: double gsl_sf_Shi (double x)
              int gsl_sf_Shi_e (double x, gsl_sf_result * result)

   These routines compute the integral
   
   .. only:: not texinfo
      
      .. math:: \hbox{Shi}(x) = \int_0^x dt \sinh(t)/t

   .. only:: texinfo

      ::

         Shi(x) = \int_0^x dt \sinh(t)/t

.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_Chi (double x)
              int gsl_sf_Chi_e (double x, gsl_sf_result * result)

   These routines compute the integral
   
   .. only:: not texinfo
      
      .. math:: \hbox{Chi}(x) := \Re \left[ \gamma_E + \log(x) + \int_0^x dt (\cosh(t)-1)/t \right]

   .. only:: texinfo

      ::

         Chi(x) := \Re[ \gamma_E + \log(x) + \int_0^x dt (\cosh(t)-1)/t ]

   where :math:`\gamma_E` is the Euler constant (available as the macro :macro:`M_EULER`).
.. Domain: x != 0.0
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

Ei_3(x)
-------

.. function:: double gsl_sf_expint_3 (double x)
              int gsl_sf_expint_3_e (double x, gsl_sf_result * result)

   These routines compute the third-order exponential integral
   
   .. only:: not texinfo
      
      .. math:: {\rm Ei}_3(x) = \int_0^x dt \exp(-t^3)

   .. only:: texinfo

      ::

         Ei_3(x) = \int_0^x dt \exp(-t^3)`
         
   for :math:`x \ge 0`.

.. Exceptional Return Values: GSL_EDOM

Trigonometric Integrals
-----------------------
.. index::
   single: trigonometric integrals
   single: Si(x)
   single: Ci(x)

.. function:: double gsl_sf_Si (const double x)
              int gsl_sf_Si_e (double x, gsl_sf_result * result)

   These routines compute the Sine integral
   
   .. only:: not texinfo
      
      .. math:: \hbox{Si}(x) = \int_0^x dt \sin(t)/t

   .. only:: texinfo

      ::

         Si(x) = \int_0^x dt \sin(t)/t

.. Exceptional Return Values: none
 
.. function:: double gsl_sf_Ci (const double x)
              int gsl_sf_Ci_e (double x, gsl_sf_result * result)

   These routines compute the Cosine integral
   
   .. only:: not texinfo
      
      .. math:: \hbox{Ci}(x) = -\int_x^\infty dt \cos(t)/t

   .. only:: texinfo

      ::

         Ci(x) = -\int_x^\infty dt \cos(t)/t}
         
   for :math:`x > 0`
.. Domain: x > 0.0
.. Exceptional Return Values: GSL_EDOM

Arctangent Integral
-------------------
.. index::
   single: arctangent integral

.. function:: double gsl_sf_atanint (double x)
              int gsl_sf_atanint_e (double x, gsl_sf_result * result)

   These routines compute the Arctangent integral, which is defined as
   
   .. only:: not texinfo
      
      .. math:: \hbox{AtanInt}(x) = \int_0^x dt \arctan(t)/t

   .. only:: texinfo

      ::

         AtanInt(x) = \int_0^x dt \arctan(t)/t

.. Domain: 
.. Exceptional Return Values: 
.. index:: elliptic integrals

The functions described in this section are declared in the header
file :file:`gsl_sf_ellint.h`.  Further information about the elliptic
integrals can be found in Abramowitz & Stegun, Chapter 17.

Definition of Legendre Forms
----------------------------
.. index:: Legendre forms of elliptic integrals

The Legendre forms of elliptic integrals :math:`F(\phi,k)`,
:math:`E(\phi,k)` and :math:`\Pi(\phi,k,n)` are defined by,

.. only:: not texinfo

   .. math::

      F(\phi,k)   &= \int_0^\phi dt {1 \over \sqrt{(1 - k^2 \sin^2(t))}} \\
      E(\phi,k)   &= \int_0^\phi dt   \sqrt{(1 - k^2 \sin^2(t))} \\
      \Pi(\phi,k,n) &= \int_0^\phi dt {1 \over (1 + n \sin^2(t)) \sqrt{1 - k^2 \sin^2(t)}}

.. only:: texinfo

   ::

      F(\phi,k) = \int_0^\phi dt 1/\sqrt((1 - k^2 \sin^2(t)))
      E(\phi,k) = \int_0^\phi dt   \sqrt((1 - k^2 \sin^2(t)))
      Pi(\phi,k,n) = \int_0^\phi dt 1/((1 + n \sin^2(t))\sqrt(1 - k^2 \sin^2(t)))

The complete Legendre forms are denoted by :math:`K(k) = F(\pi/2, k)` and
:math:`E(k) = E(\pi/2, k)`.  

The notation used here is based on Carlson, "Numerische
Mathematik" 33 (1979) 1 and differs slightly from that used by
Abramowitz & Stegun, where the functions are given in terms of the
parameter :math:`m = k^2` and :math:`n` is replaced by :math:`-n`.

Definition of Carlson Forms
---------------------------
.. index:: Carlson forms of Elliptic integrals

The Carlson symmetric forms of elliptical integrals :math:`RC(x,y)`,
:math:`RD(x,y,z)`, :math:`RF(x,y,z)` and :math:`RJ(x,y,z,p)` are defined
by,

.. only:: not texinfo

   .. math::

      RC(x,y)   &= 1/2 \int_0^\infty dt (t+x)^{-1/2} (t+y)^{-1} \\
      RD(x,y,z) &= 3/2 \int_0^\infty dt (t+x)^{-1/2} (t+y)^{-1/2} (t+z)^{-3/2} \\
      RF(x,y,z) &= 1/2 \int_0^\infty dt (t+x)^{-1/2} (t+y)^{-1/2} (t+z)^{-1/2} \\
      RJ(x,y,z,p) &= 3/2 \int_0^\infty dt (t+x)^{-1/2} (t+y)^{-1/2} (t+z)^{-1/2} (t+p)^{-1}

.. only:: texinfo

   ::

     RC(x,y) = 1/2 \int_0^\infty dt (t+x)^(-1/2) (t+y)^(-1)
     RD(x,y,z) = 3/2 \int_0^\infty dt (t+x)^(-1/2) (t+y)^(-1/2) (t+z)^(-3/2)
     RF(x,y,z) = 1/2 \int_0^\infty dt (t+x)^(-1/2) (t+y)^(-1/2) (t+z)^(-1/2)
     RJ(x,y,z,p) = 3/2 \int_0^\infty dt 
                      (t+x)^(-1/2) (t+y)^(-1/2) (t+z)^(-1/2) (t+p)^(-1)

Legendre Form of Complete Elliptic Integrals
--------------------------------------------

.. function:: double gsl_sf_ellint_Kcomp (double k, gsl_mode_t mode)
              int gsl_sf_ellint_Kcomp_e (double k, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the complete elliptic integral :math:`K(k)` to
   the accuracy specified by the mode variable :data:`mode`.  
   Note that Abramowitz & Stegun define this function in terms of the
   parameter :math:`m = k^2`.
.. Exceptional Return Values:  GSL_EDOM

.. function:: double gsl_sf_ellint_Ecomp (double k, gsl_mode_t mode)
              int gsl_sf_ellint_Ecomp_e (double k, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the complete elliptic integral :math:`E(k)` to the
   accuracy specified by the mode variable :data:`mode`.
   Note that Abramowitz & Stegun define this function in terms of the
   parameter :math:`m = k^2`.
.. Exceptional Return Values:  GSL_EDOM

.. function:: double gsl_sf_ellint_Pcomp (double k, double n, gsl_mode_t mode)
              int gsl_sf_ellint_Pcomp_e (double k, double n,  gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the complete elliptic integral :math:`\Pi(k,n)` to the
   accuracy specified by the mode variable :data:`mode`.
   Note that Abramowitz & Stegun define this function in terms of the
   parameters :math:`m = k^2` and :math:`\sin^2(\alpha) = k^2`, with the
   change of sign :math:`n \to -n`.
.. Exceptional Return Values:  GSL_EDOM

Legendre Form of Incomplete Elliptic Integrals
----------------------------------------------

.. function:: double gsl_sf_ellint_F (double phi, double k, gsl_mode_t mode)
              int gsl_sf_ellint_F_e (double phi, double k, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the incomplete elliptic integral :math:`F(\phi,k)`
   to the accuracy specified by the mode variable :data:`mode`.
   Note that Abramowitz & Stegun define this function in terms of the
   parameter :math:`m = k^2`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_ellint_E (double phi, double k, gsl_mode_t mode)
              int gsl_sf_ellint_E_e (double phi, double k, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the incomplete elliptic integral :math:`E(\phi,k)`
   to the accuracy specified by the mode variable :data:`mode`.
   Note that Abramowitz & Stegun define this function in terms of the
   parameter :math:`m = k^2`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_ellint_P (double phi, double k, double n, gsl_mode_t mode)
              int gsl_sf_ellint_P_e (double phi, double k, double n, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the incomplete elliptic integral :math:`\Pi(\phi,k,n)`
   to the accuracy specified by the mode variable :data:`mode`.
   Note that Abramowitz & Stegun define this function in terms of the
   parameters :math:`m = k^2` and :math:`\sin^2(\alpha) = k^2`, with the
   change of sign :math:`n \to -n`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_ellint_D (double phi, double k, gsl_mode_t mode)
              int gsl_sf_ellint_D_e (double phi, double k, gsl_mode_t mode, gsl_sf_result * result)

   These functions compute the incomplete elliptic integral
   :math:`D(\phi,k)` which is defined through the Carlson form :math:`RD(x,y,z)`
   by the following relation, 

   .. only:: not texinfo

      .. math:: D(\phi,k) = {1 \over 3} (\sin \phi)^3 RD (1-\sin^2(\phi), 1-k^2 \sin^2(\phi), 1)


   .. only:: texinfo

      ::

        D(\phi,k) = (1/3)(\sin(\phi))^3 RD (1-\sin^2(\phi), 1-k^2 \sin^2(\phi), 1).

.. Exceptional Return Values: GSL_EDOM

Carlson Forms
-------------

.. function:: double gsl_sf_ellint_RC (double x, double y, gsl_mode_t mode)
              int gsl_sf_ellint_RC_e (double x, double y, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the incomplete elliptic integral :math:`RC(x,y)`
   to the accuracy specified by the mode variable :data:`mode`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_ellint_RD (double x, double y, double z, gsl_mode_t mode)
              int gsl_sf_ellint_RD_e (double x, double y, double z, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the incomplete elliptic integral :math:`RD(x,y,z)`
   to the accuracy specified by the mode variable :data:`mode`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_ellint_RF (double x, double y, double z, gsl_mode_t mode)
              int gsl_sf_ellint_RF_e (double x, double y, double z, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the incomplete elliptic integral :math:`RF(x,y,z)`
   to the accuracy specified by the mode variable :data:`mode`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_ellint_RJ (double x, double y, double z, double p, gsl_mode_t mode)
              int gsl_sf_ellint_RJ_e (double x, double y, double z, double p, gsl_mode_t mode, gsl_sf_result * result)

   These routines compute the incomplete elliptic integral :math:`RJ(x,y,z,p)`
   to the accuracy specified by the mode variable :data:`mode`.
.. Exceptional Return Values: GSL_EDOM
.. index::
   single: linear algebra
   single: solution of linear systems, Ax=b
   single: matrix factorization
   single: factorization of matrices

**************
Linear Algebra
**************

.. include:: include.rst

This chapter describes functions for solving linear systems.  The
library provides linear algebra operations which operate directly on
the :type:`gsl_vector` and :type:`gsl_matrix` objects.  These routines
use the standard algorithms from Golub & Van Loan's *Matrix
Computations* with Level-1 and Level-2 BLAS calls for efficiency.

The functions described in this chapter are declared in the header file
:file:`gsl_linalg.h`.

.. index:: LU decomposition

LU Decomposition
================

A general :math:`N`-by-:math:`N` square matrix :math:`A` has an :math:`LU` decomposition into
upper and lower triangular matrices,

.. math:: P A = L U

where :math:`P` is a permutation matrix, :math:`L` is unit lower
triangular matrix and :math:`U` is upper triangular matrix. For square
matrices this decomposition can be used to convert the linear system
:math:`A x = b` into a pair of triangular systems (:math:`L y = P b`,
:math:`U x = y`), which can be solved by forward and back-substitution.
Note that the :math:`LU` decomposition is valid for singular matrices.

.. function:: int gsl_linalg_LU_decomp (gsl_matrix * A, gsl_permutation * p, int * signum)
              int gsl_linalg_complex_LU_decomp (gsl_matrix_complex * A, gsl_permutation * p, int * signum)

   These functions factorize the square matrix :data:`A` into the :math:`LU`
   decomposition :math:`PA = LU`.  On output the diagonal and upper
   triangular part of the input matrix :data:`A` contain the matrix
   :math:`U`. The lower triangular part of the input matrix (excluding the
   diagonal) contains :math:`L`.  The diagonal elements of :math:`L` are
   unity, and are not stored.

   The permutation matrix :math:`P` is encoded in the permutation
   :data:`p` on output. The :math:`j`-th column of the matrix :math:`P`
   is given by the :math:`k`-th column of the identity matrix, where
   :math:`k = p_j` the
   :math:`j`-th element of the permutation vector. The sign of the
   permutation is given by :data:`signum`. It has the value :math:`(-1)^n`,
   where :math:`n` is the number of interchanges in the permutation.

   The algorithm used in the decomposition is Gaussian Elimination with
   partial pivoting (Golub & Van Loan, *Matrix Computations*,
   Algorithm 3.4.1).

.. index:: linear systems, solution of

.. function:: int gsl_linalg_LU_solve (const gsl_matrix * LU, const gsl_permutation * p, const gsl_vector * b, gsl_vector * x)
              int gsl_linalg_complex_LU_solve (const gsl_matrix_complex * LU, const gsl_permutation * p, const gsl_vector_complex * b, gsl_vector_complex * x)

   These functions solve the square system :math:`A x = b` using the :math:`LU`
   decomposition of :math:`A` into (:data:`LU`, :data:`p`) given by
   :func:`gsl_linalg_LU_decomp` or :func:`gsl_linalg_complex_LU_decomp` as input.

.. function:: int gsl_linalg_LU_svx (const gsl_matrix * LU, const gsl_permutation * p, gsl_vector * x)
              int gsl_linalg_complex_LU_svx (const gsl_matrix_complex * LU, const gsl_permutation * p, gsl_vector_complex * x)

   These functions solve the square system :math:`A x = b` in-place using the
   precomputed :math:`LU` decomposition of :math:`A` into (:data:`LU`, :data:`p`). On input
   :data:`x` should contain the right-hand side :math:`b`, which is replaced
   by the solution on output.

.. index::
   single: refinement of solutions in linear systems
   single: iterative refinement of solutions in linear systems
   single: linear systems, refinement of solutions

.. function:: int gsl_linalg_LU_refine (const gsl_matrix * A, const gsl_matrix * LU, const gsl_permutation * p, const gsl_vector * b, gsl_vector * x, gsl_vector * work)
              int gsl_linalg_complex_LU_refine (const gsl_matrix_complex * A, const gsl_matrix_complex * LU, const gsl_permutation * p, const gsl_vector_complex * b, gsl_vector_complex * x, gsl_vector_complex * work)

   These functions apply an iterative improvement to :data:`x`, the solution
   of :math:`A x = b`, from the precomputed :math:`LU` decomposition of :math:`A` into
   (:data:`LU`, :data:`p`). Additional workspace of length :data:`N` is required in :data:`work`.

.. index::
   single: inverse of a matrix, by LU decomposition
   single: matrix inverse

.. function:: int gsl_linalg_LU_invert (const gsl_matrix * LU, const gsl_permutation * p, gsl_matrix * inverse)
              int gsl_linalg_complex_LU_invert (const gsl_matrix_complex * LU, const gsl_permutation * p, gsl_matrix_complex * inverse)

   These functions compute the inverse of a matrix :math:`A` from its
   :math:`LU` decomposition (:data:`LU`, :data:`p`), storing the result in the
   matrix :data:`inverse`. The inverse is computed by solving the system
   :math:`A x = b` for each column of the identity matrix.  It is preferable
   to avoid direct use of the inverse whenever possible, as the linear
   solver functions can obtain the same result more efficiently and
   reliably (consult any introductory textbook on numerical linear algebra
   for details).

.. index::
   single: determinant of a matrix, by LU decomposition
   single: matrix determinant

.. function:: double gsl_linalg_LU_det (gsl_matrix * LU, int signum)
              gsl_complex gsl_linalg_complex_LU_det (gsl_matrix_complex * LU, int signum)

   These functions compute the determinant of a matrix :math:`A` from its
   :math:`LU` decomposition, :data:`LU`. The determinant is computed as the
   product of the diagonal elements of :math:`U` and the sign of the row
   permutation :data:`signum`.

.. index:: logarithm of the determinant of a matrix

.. function:: double gsl_linalg_LU_lndet (gsl_matrix * LU)
              double gsl_linalg_complex_LU_lndet (gsl_matrix_complex * LU)

   These functions compute the logarithm of the absolute value of the
   determinant of a matrix :math:`A`, :math:`\ln|\det(A)|`, from its :math:`LU`
   decomposition, :data:`LU`.  This function may be useful if the direct
   computation of the determinant would overflow or underflow.

.. index:: sign of the determinant of a matrix

.. function:: int gsl_linalg_LU_sgndet (gsl_matrix * LU, int signum)
              gsl_complex gsl_linalg_complex_LU_sgndet (gsl_matrix_complex * LU, int signum)

   These functions compute the sign or phase factor of the determinant of a
   matrix :math:`A`, :math:`\det(A)/|\det(A)|`, from its :math:`LU` decomposition,
   :data:`LU`.

.. index:: QR decomposition

QR Decomposition
================

A general rectangular :math:`M`-by-:math:`N` matrix :math:`A` has a
:math:`QR` decomposition into the product of an orthogonal
:math:`M`-by-:math:`M` square matrix :math:`Q` (where :math:`Q^T Q = I`) and
an :math:`M`-by-:math:`N` right-triangular matrix :math:`R`,

.. math:: A = Q R

This decomposition can be used to convert the linear system :math:`A x = b`
into the triangular system :math:`R x = Q^T b`, which can be solved by
back-substitution. Another use of the :math:`QR` decomposition is to
compute an orthonormal basis for a set of vectors. The first :math:`N`
columns of :math:`Q` form an orthonormal basis for the range of :math:`A`,
:math:`ran(A)`, when :math:`A` has full column rank.

.. function:: int gsl_linalg_QR_decomp (gsl_matrix * A, gsl_vector * tau)

   This function factorizes the :math:`M`-by-:math:`N` matrix :data:`A` into
   the :math:`QR` decomposition :math:`A = Q R`.  On output the diagonal and
   upper triangular part of the input matrix contain the matrix
   :math:`R`. The vector :data:`tau` and the columns of the lower triangular
   part of the matrix :data:`A` contain the Householder coefficients and
   Householder vectors which encode the orthogonal matrix :data:`Q`.  The
   vector :data:`tau` must be of length :math:`k=\min(M,N)`. The matrix
   :math:`Q` is related to these components by, :math:`Q = Q_k ... Q_2 Q_1`
   where :math:`Q_i = I - \tau_i v_i v_i^T` and :math:`v_i` is the
   Householder vector :math:`v_i = (0,...,1,A(i+1,i),A(i+2,i),...,A(m,i))`.
   This is the same storage scheme as used by |lapack|.

   The algorithm used to perform the decomposition is Householder QR (Golub
   & Van Loan, "Matrix Computations", Algorithm 5.2.1).

.. function:: int gsl_linalg_QR_solve (const gsl_matrix * QR, const gsl_vector * tau, const gsl_vector * b, gsl_vector * x)

   This function solves the square system :math:`A x = b` using the :math:`QR`
   decomposition of :math:`A` held in (:data:`QR`, :data:`tau`) which must 
   have been computed previously with :func:`gsl_linalg_QR_decomp`. 
   The least-squares solution for 
   rectangular systems can be found using :func:`gsl_linalg_QR_lssolve`.

.. function:: int gsl_linalg_QR_svx (const gsl_matrix * QR, const gsl_vector * tau, gsl_vector * x)

   This function solves the square system :math:`A x = b` in-place using
   the :math:`QR` decomposition of :math:`A` held in (:data:`QR`, :data:`tau`)
   which must have been computed previously by
   :func:`gsl_linalg_QR_decomp`.  On input :data:`x` should contain the
   right-hand side :math:`b`, which is replaced by the solution on output.

.. function:: int gsl_linalg_QR_lssolve (const gsl_matrix * QR, const gsl_vector * tau, const gsl_vector * b, gsl_vector * x, gsl_vector * residual)

   This function finds the least squares solution to the overdetermined
   system :math:`A x = b` where the matrix :data:`A` has more rows than
   columns.  The least squares solution minimizes the Euclidean norm of the
   residual, :math:`||Ax - b||`.The routine requires as input 
   the :math:`QR` decomposition
   of :math:`A` into (:data:`QR`, :data:`tau`) given by
   :func:`gsl_linalg_QR_decomp`.  The solution is returned in :data:`x`.  The
   residual is computed as a by-product and stored in :data:`residual`.

.. function:: int gsl_linalg_QR_QTvec (const gsl_matrix * QR, const gsl_vector * tau, gsl_vector * v)

   This function applies the matrix :math:`Q^T` encoded in the decomposition
   (:data:`QR`, :data:`tau`) to the vector :data:`v`, storing the result :math:`Q^T v`
   in :data:`v`.  The matrix multiplication is carried out directly using
   the encoding of the Householder vectors without needing to form the full
   matrix :math:`Q^T`.

.. function:: int gsl_linalg_QR_Qvec (const gsl_matrix * QR, const gsl_vector * tau, gsl_vector * v)

   This function applies the matrix :math:`Q` encoded in the decomposition
   (:data:`QR`, :data:`tau`) to the vector :data:`v`, storing the result :math:`Q v`
   in :data:`v`.  The matrix multiplication is carried out directly using
   the encoding of the Householder vectors without needing to form the full
   matrix :math:`Q`.

.. function:: int gsl_linalg_QR_QTmat (const gsl_matrix * QR, const gsl_vector * tau, gsl_matrix * A)

   This function applies the matrix :math:`Q^T` encoded in the decomposition
   (:data:`QR`, :data:`tau`) to the matrix :data:`A`, storing the result :math:`Q^T A`
   in :data:`A`.  The matrix multiplication is carried out directly using
   the encoding of the Householder vectors without needing to form the full
   matrix :math:`Q^T`.

.. function:: int gsl_linalg_QR_Rsolve (const gsl_matrix * QR, const gsl_vector * b, gsl_vector * x)

   This function solves the triangular system :math:`R x = b` for
   :data:`x`. It may be useful if the product :math:`b' = Q^T b` has already
   been computed using :func:`gsl_linalg_QR_QTvec`.

.. function:: int gsl_linalg_QR_Rsvx (const gsl_matrix * QR, gsl_vector * x)

   This function solves the triangular system :math:`R x = b` for :data:`x`
   in-place. On input :data:`x` should contain the right-hand side :math:`b`
   and is replaced by the solution on output. This function may be useful if
   the product :math:`b' = Q^T b` has already been computed using
   :func:`gsl_linalg_QR_QTvec`.

.. function:: int gsl_linalg_QR_unpack (const gsl_matrix * QR, const gsl_vector * tau, gsl_matrix * Q, gsl_matrix * R)

   This function unpacks the encoded :math:`QR` decomposition
   (:data:`QR`, :data:`tau`) into the matrices :data:`Q` and :data:`R`, where
   :data:`Q` is :math:`M`-by-:math:`M` and :data:`R` is :math:`M`-by-:math:`N`. 

.. function:: int gsl_linalg_QR_QRsolve (gsl_matrix * Q, gsl_matrix * R, const gsl_vector * b, gsl_vector * x)

   This function solves the system :math:`R x = Q^T b` for :data:`x`. It can
   be used when the :math:`QR` decomposition of a matrix is available in
   unpacked form as (:data:`Q`, :data:`R`).

.. function:: int gsl_linalg_QR_update (gsl_matrix * Q, gsl_matrix * R, gsl_vector * w, const gsl_vector * v)

   This function performs a rank-1 update :math:`w v^T` of the :math:`QR`
   decomposition (:data:`Q`, :data:`R`). The update is given by :math:`Q'R' = Q (R + w v^T)`
   where the output matrices :math:`Q` and :math:`R` are also
   orthogonal and right triangular. Note that :data:`w` is destroyed by the
   update.

.. function:: int gsl_linalg_R_solve (const gsl_matrix * R, const gsl_vector * b, gsl_vector * x)

   This function solves the triangular system :math:`R x = b` for the
   :math:`N`-by-:math:`N` matrix :data:`R`.

.. function:: int gsl_linalg_R_svx (const gsl_matrix * R, gsl_vector * x)

   This function solves the triangular system :math:`R x = b` in-place. On
   input :data:`x` should contain the right-hand side :math:`b`, which is
   replaced by the solution on output.

.. index:: QR decomposition with column pivoting

QR Decomposition with Column Pivoting
=====================================

The :math:`QR` decomposition of an :math:`M`-by-:math:`N` matrix :math:`A`
can be extended to the rank deficient case by introducing a column permutation :math:`P`,

.. math:: A P = Q R

The first :math:`r` columns of :math:`Q` form an orthonormal basis
for the range of :math:`A` for a matrix with column rank :math:`r`.  This
decomposition can also be used to convert the linear system :math:`A x = b`
into the triangular system :math:`R y = Q^T b, x = P y`, which can be
solved by back-substitution and permutation.  We denote the :math:`QR`
decomposition with column pivoting by :math:`QRP^T` since :math:`A = Q R P^T`.
When :math:`A` is rank deficient with :math:`r = {\rm rank}(A)`, the matrix
:math:`R` can be partitioned as

.. only:: not texinfo

   .. math::

      R = \left(
      \begin{matrix}
        R_{11} & R_{12} \\
        0 & R_{22}
      \end{matrix}
      \right) \approx
      \left(
      \begin{matrix}
        R_{11} & R_{12} \\
        0 & 0
      \end{matrix}
      \right)

.. only:: texinfo

   ::

      R = [ R11 R12 ] =~ [ R11 R12 ]
          [  0  R22 ]    [  0   0  ]

where :math:`R_{11}` is :math:`r`-by-:math:`r` and nonsingular. In this case,
a *basic* least squares solution for the overdetermined system :math:`A x = b`
can be obtained as

.. only:: not texinfo

   .. math::

      x = P \left(
      \begin{matrix}
        R_{11}^{-1} c_1 \\
        0
      \end{matrix}
      \right)

.. only:: texinfo

   ::

      x = P [ R11^-1 c1 ]
            [     0     ]

where :math:`c_1` consists of the first :math:`r` elements of :math:`Q^T b`.
This basic solution is not guaranteed to be the minimum norm solution unless
:math:`R_{12} = 0` (see :ref:`Complete Orthogonal Decomposition <cod>`).

.. function:: int gsl_linalg_QRPT_decomp (gsl_matrix * A, gsl_vector * tau, gsl_permutation * p, int * signum, gsl_vector * norm)

   This function factorizes the :math:`M`-by-:math:`N` matrix :data:`A` into
   the :math:`QRP^T` decomposition :math:`A = Q R P^T`.  On output the
   diagonal and upper triangular part of the input matrix contain the
   matrix :math:`R`. The permutation matrix :math:`P` is stored in the
   permutation :data:`p`.  The sign of the permutation is given by
   :data:`signum`. It has the value :math:`(-1)^n`, where :math:`n` is the
   number of interchanges in the permutation. The vector :data:`tau` and the
   columns of the lower triangular part of the matrix :data:`A` contain the
   Householder coefficients and vectors which encode the orthogonal matrix
   :data:`Q`.  The vector :data:`tau` must be of length :math:`k=\min(M,N)`. The
   matrix :math:`Q` is related to these components by, :math:`Q = Q_k ... Q_2 Q_1`
   where :math:`Q_i = I - \tau_i v_i v_i^T` and :math:`v_i` is the
   Householder vector
   
   .. math:: v_i = (0,...,1,A(i+1,i),A(i+2,i),...,A(m,i))

   This is the same storage scheme
   as used by |lapack|.  The vector :data:`norm` is a workspace of length
   :data:`N` used for column pivoting.

   The algorithm used to perform the decomposition is Householder QR with
   column pivoting (Golub & Van Loan, "Matrix Computations", Algorithm
   5.4.1).

.. function:: int gsl_linalg_QRPT_decomp2 (const gsl_matrix * A, gsl_matrix * q, gsl_matrix * r, gsl_vector * tau, gsl_permutation * p, int * signum, gsl_vector * norm)

   This function factorizes the matrix :data:`A` into the decomposition
   :math:`A = Q R P^T` without modifying :data:`A` itself and storing the
   output in the separate matrices :data:`q` and :data:`r`.

.. function:: int gsl_linalg_QRPT_solve (const gsl_matrix * QR, const gsl_vector * tau, const gsl_permutation * p, const gsl_vector * b, gsl_vector * x)

   This function solves the square system :math:`A x = b` using the :math:`QRP^T`
   decomposition of :math:`A` held in (:data:`QR`, :data:`tau`, :data:`p`) which must 
   have been computed previously by :func:`gsl_linalg_QRPT_decomp`.

.. function:: int gsl_linalg_QRPT_svx (const gsl_matrix * QR, const gsl_vector * tau, const gsl_permutation * p, gsl_vector * x)

   This function solves the square system :math:`A x = b` in-place using the
   :math:`QRP^T` decomposition of :math:`A` held in
   (:data:`QR`, :data:`tau`, :data:`p`). On input :data:`x` should contain the
   right-hand side :math:`b`, which is replaced by the solution on output.

.. function:: int gsl_linalg_QRPT_lssolve (const gsl_matrix * QR, const gsl_vector * tau, const gsl_permutation * p, const gsl_vector * b, gsl_vector * x, gsl_vector * residual)

   This function finds the least squares solution to the overdetermined
   system :math:`A x = b` where the matrix :data:`A` has more rows than
   columns and is assumed to have full rank. The least squares solution minimizes
   the Euclidean norm of the residual, :math:`||b - A x||`. The routine requires as input 
   the :math:`QR` decomposition of :math:`A` into (:data:`QR`, :data:`tau`, :data:`p`) given by
   :func:`gsl_linalg_QRPT_decomp`.  The solution is returned in :data:`x`.  The
   residual is computed as a by-product and stored in :data:`residual`. For rank
   deficient matrices, :func:`gsl_linalg_QRPT_lssolve2` should be used instead.

.. function:: int gsl_linalg_QRPT_lssolve2 (const gsl_matrix * QR, const gsl_vector * tau, const gsl_permutation * p, const gsl_vector * b, const size_t rank, gsl_vector * x, gsl_vector * residual)

   This function finds the least squares solution to the overdetermined
   system :math:`A x = b` where the matrix :data:`A` has more rows than
   columns and has rank given by the input :data:`rank`. If the user does not
   know the rank of :math:`A`, the routine :func:`gsl_linalg_QRPT_rank` can be
   called to estimate it. The least squares solution is
   the so-called "basic" solution discussed above and may not be the minimum
   norm solution. The routine requires as input 
   the :math:`QR` decomposition of :math:`A` into (:data:`QR`, :data:`tau`, :data:`p`) given by
   :func:`gsl_linalg_QRPT_decomp`.  The solution is returned in :data:`x`.  The
   residual is computed as a by-product and stored in :data:`residual`.

.. function:: int gsl_linalg_QRPT_QRsolve (const gsl_matrix * Q, const gsl_matrix * R, const gsl_permutation * p, const gsl_vector * b, gsl_vector * x)

   This function solves the square system :math:`R P^T x = Q^T b` for
   :data:`x`. It can be used when the :math:`QR` decomposition of a matrix is
   available in unpacked form as (:data:`Q`, :data:`R`).

.. function:: int gsl_linalg_QRPT_update (gsl_matrix * Q, gsl_matrix * R, const gsl_permutation * p, gsl_vector * w, const gsl_vector * v)

   This function performs a rank-1 update :math:`w v^T` of the :math:`QRP^T`
   decomposition (:data:`Q`, :data:`R`, :data:`p`). The update is given by
   :math:`Q'R' = Q (R + w v^T P)` where the output matrices :math:`Q'` and
   :math:`R'` are also orthogonal and right triangular. Note that :data:`w` is
   destroyed by the update. The permutation :data:`p` is not changed.

.. function:: int gsl_linalg_QRPT_Rsolve (const gsl_matrix * QR, const gsl_permutation * p, const gsl_vector * b, gsl_vector * x)

   This function solves the triangular system :math:`R P^T x = b` for the
   :math:`N`-by-:math:`N` matrix :math:`R` contained in :data:`QR`.

.. function:: int gsl_linalg_QRPT_Rsvx (const gsl_matrix * QR, const gsl_permutation * p, gsl_vector * x)

   This function solves the triangular system :math:`R P^T x = b` in-place
   for the :math:`N`-by-:math:`N` matrix :math:`R` contained in :data:`QR`. On
   input :data:`x` should contain the right-hand side :math:`b`, which is
   replaced by the solution on output.

.. function:: size_t gsl_linalg_QRPT_rank (const gsl_matrix * QR, const double tol)

   This function estimates the rank of the triangular matrix :math:`R` contained in :data:`QR`.
   The algorithm simply counts the number of diagonal elements of :math:`R` whose absolute value
   is greater than the specified tolerance :data:`tol`. If the input :data:`tol` is negative,
   a default value of :math:`20 (M + N) eps(max(|diag(R)|))` is used.

.. function:: int gsl_linalg_QRPT_rcond (const gsl_matrix * QR, double * rcond, gsl_vector * work)

   This function estimates the reciprocal condition number (using the 1-norm) of the :math:`R` factor,
   stored in the upper triangle of :data:`QR`. The reciprocal condition number estimate, defined as
   :math:`1 / (||R||_1 \cdot ||R^{-1}||_1)`, is stored in :data:`rcond`.
   Additional workspace of size :math:`3 N` is required in :data:`work`.

.. index:: complete orthogonal decomposition

.. _cod:

Complete Orthogonal Decomposition
=================================

The complete orthogonal decomposition of a :math:`M`-by-:math:`N` matrix
:math:`A` is a generalization of the QR decomposition with column pivoting, given by

.. only:: not texinfo

   .. math::

      A P = Q
      \left(
      \begin{matrix}
        R_{11} & 0 \\
        0 & 0
      \end{matrix}
      \right) Z^T

.. only:: texinfo

   ::

      A P = Q [ R11 0 ] Z^T
              [  0  0 ]

where :math:`P` is a :math:`N`-by-:math:`N` permutation matrix,
:math:`Q` is :math:`M`-by-:math:`M` orthogonal, :math:`R_{11}` is
:math:`r`-by-:math:`r` upper triangular, with :math:`r = {\rm rank}(A)`,
and :math:`Z` is :math:`N`-by-:math:`N` orthogonal. If :math:`A`
has full rank, then :math:`R_{11} = R`, :math:`Z = I` and this reduces to the
QR decomposition with column pivoting.

For a rank deficient least squares problem, :math:`\min_x{|| b - Ax||^2}`, the solution vector
:math:`x` is not unique. However if we further require that :math:`||x||^2` is minimized,
then the complete orthogonal decomposition gives us the ability to compute
the unique minimum norm solution, which is given by

.. only:: not texinfo

   .. math::

      x = P Z
      \left(
      \begin{matrix}
        R_{11}^{-1} c_1 \\
        0
      \end{matrix}
      \right)

.. only:: texinfo

   ::

      x = P Z [ R11^-1 c1 ]
              [     0     ]

and the vector :math:`c_1` is the first :math:`r` elements of :math:`Q^T b`.

The COD also enables a straightforward solution of regularized least squares problems
in Tikhonov standard form, written as

.. math:: \min_x ||b - A x||^2 + \lambda^2 ||x||^2

where :math:`\lambda > 0` is a regularization parameter which represents a tradeoff between
minimizing the residual norm :math:`||b - A x||` and the solution norm :math:`||x||`. For this system,
the solution is given by

.. only:: not texinfo

   .. math::

      x = P Z
      \left(
      \begin{matrix}
        y_1 \\
        0
      \end{matrix}
      \right)

.. only:: texinfo

   ::

      x = P Z [ y1 ]
              [ 0  ]

where :math:`y_1` is a vector of length :math:`r` which is found by solving

.. only:: not texinfo

   .. math::

      \left(
      \begin{matrix}
        R_{11} \\
        \lambda I_r
      \end{matrix}
      \right) y_1 =
      \left(
      \begin{matrix}
        c_1 \\
        0
      \end{matrix}
      \right)

.. only:: texinfo

   ::

      [     R11     ] y_1 = [ c_1 ]
      [ \lambda I_r ]       [  0  ]

and :math:`c_1` is defined above. The equation above can be solved efficiently for different
values of :math:`\lambda` using QR factorizations of the left hand side matrix.

.. function:: int gsl_linalg_COD_decomp (gsl_matrix * A, gsl_vector * tau_Q, gsl_vector * tau_Z, gsl_permutation * p, size_t * rank, gsl_vector * work)
              int gsl_linalg_COD_decomp_e (gsl_matrix * A, gsl_vector * tau_Q, gsl_vector * tau_Z, gsl_permutation * p, double tol, size_t * rank, gsl_vector * work)

   These functions factor the :math:`M`-by-:math:`N` matrix :data:`A` into the decomposition :math:`A = Q R Z P^T`. The rank of :data:`A`
   is computed as the number of diagonal elements of :math:`R` greater than the tolerance :data:`tol` and output in :data:`rank`.
   If :data:`tol` is not specified, a default value is used (see :func:`gsl_linalg_QRPT_rank`). On output, the permutation
   matrix :math:`P` is stored in :data:`p`. The matrix :math:`R_{11}` is stored in the upper :data:`rank`-by-:data:`rank` block of :data:`A`.
   The matrices :math:`Q` and :math:`Z` are encoded in packed storage in :data:`A` on output. The vectors :data:`tau_Q` and :data:`tau_Z`
   contain the Householder scalars corresponding to the matrices :math:`Q` and :math:`Z` respectively and must be
   of length :math:`k = \min(M,N)`. The vector :data:`work` is additional workspace of length :math:`N`.

.. function:: int gsl_linalg_COD_lssolve (const gsl_matrix * QRZT, const gsl_vector * tau_Q, const gsl_vector * tau_Z, const gsl_permutation * p, const size_t rank, const gsl_vector * b, gsl_vector * x, gsl_vector * residual)

   This function finds the unique minimum norm least squares solution to the overdetermined
   system :math:`A x = b` where the matrix :data:`A` has more rows than
   columns.  The least squares solution minimizes the Euclidean norm of the
   residual, :math:`||b - A x||` as well as the norm of the solution :math:`||x||`.  The routine requires as input 
   the :math:`QRZT` decomposition of :math:`A` into (:data:`QRZT`, :data:`tau_Q`, :data:`tau_Z`, :data:`p`, :data:`rank`)
   given by :func:`gsl_linalg_COD_decomp`.  The solution is returned in :data:`x`.  The
   residual, :math:`b - Ax`, is computed as a by-product and stored in :data:`residual`.

.. function:: int gsl_linalg_COD_lssolve2 (const double lambda, const gsl_matrix * QRZT, const gsl_vector * tau_Q, const gsl_vector * tau_Z, const gsl_permutation * p, const size_t rank, const gsl_vector * b, gsl_vector * x, gsl_vector * residual, gsl_matrix * S, gsl_vector * work)

   This function finds the solution to the regularized least squares problem in Tikhonov
   standard form, :math:`\min_x ||b - Ax||^2 + \lambda^2 ||x||^2`. The routine requires as input 
   the :math:`QRZT` decomposition of :math:`A` into (:data:`QRZT`, :data:`tau_Q`, :data:`tau_Z`, :data:`p`, :data:`rank`)
   given by :func:`gsl_linalg_COD_decomp`. The parameter :math:`\lambda` is supplied in :data:`lambda`.  The solution
   is returned in :data:`x`. The residual, :math:`b - Ax`, is stored in :data:`residual` on output. :data:`S` is additional
   workspace of size :data:`rank`-by-:data:`rank`. :data:`work` is additional workspace of length :data:`rank`.

.. function:: int gsl_linalg_COD_unpack (const gsl_matrix * QRZT, const gsl_vector * tau_Q, const gsl_vector * tau_Z, const size_t rank, gsl_matrix * Q, gsl_matrix * R, gsl_matrix * Z)

   This function unpacks the encoded :math:`QRZT` decomposition
   (:data:`QRZT`, :data:`tau_Q`, :data:`tau_Z`, :data:`rank`) into the matrices
   :data:`Q`, :data:`R`, and :data:`Z`, where :data:`Q` is :math:`M`-by-:math:`M`,
   :data:`R` is :math:`M`-by-:math:`N`, and :data:`Z` is :math:`N`-by-:math:`N`.

.. function:: int gsl_linalg_COD_matZ (const gsl_matrix * QRZT, const gsl_vector * tau_Z, const size_t rank, gsl_matrix * A, gsl_vector * work)

   This function multiplies the input matrix :data:`A` on the right by :data:`Z`,
   :math:`A' = A Z` using the encoded :math:`QRZT` decomposition
   (:data:`QRZT`, :data:`tau_Z`, :data:`rank`). :data:`A` must have :math:`N` columns but may
   have any number of rows. Additional workspace of length :math:`M` is provided
   in :data:`work`.

.. index:: SVD, singular value decomposition

Singular Value Decomposition
============================

A general rectangular :math:`M`-by-:math:`N` matrix :math:`A` has a
singular value decomposition (SVD) into the product of an
:math:`M`-by-:math:`N` orthogonal matrix :math:`U`, an :math:`N`-by-:math:`N`
diagonal matrix of singular values :math:`S` and the transpose of an
:math:`N`-by-:math:`N` orthogonal square matrix :math:`V`,

.. math:: A = U S V^T

The singular values :math:`\sigma_i = S_{ii}`
are all non-negative and are
generally chosen to form a non-increasing sequence

.. only:: not texinfo

   .. math:: \sigma_1 \ge \sigma_2 \ge ... \ge \sigma_N \ge 0

.. only:: texinfo

   .. math:: \sigma_1 >= \sigma_2 >= ... >= \sigma_N >= 0

The singular value decomposition of a matrix has many practical uses.
The condition number of the matrix is given by the ratio of the largest
singular value to the smallest singular value. The presence of a zero
singular value indicates that the matrix is singular. The number of
non-zero singular values indicates the rank of the matrix.  In practice
singular value decomposition of a rank-deficient matrix will not produce
exact zeroes for singular values, due to finite numerical
precision.  Small singular values should be edited by choosing a suitable
tolerance.

For a rank-deficient matrix, the null space of :math:`A` is given by
the columns of :math:`V` corresponding to the zero singular values.
Similarly, the range of :math:`A` is given by columns of :math:`U`
corresponding to the non-zero singular values.

Note that the routines here compute the "thin" version of the SVD
with :math:`U` as :math:`M`-by-:math:`N` orthogonal matrix. This allows
in-place computation and is the most commonly-used form in practice.
Mathematically, the "full" SVD is defined with :math:`U` as an
:math:`M`-by-:math:`M` orthogonal matrix and :math:`S` as an
:math:`M`-by-:math:`N` diagonal matrix (with additional rows of zeros).

.. function:: int gsl_linalg_SV_decomp (gsl_matrix * A, gsl_matrix * V, gsl_vector * S, gsl_vector * work)

   This function factorizes the :math:`M`-by-:math:`N` matrix :data:`A` into
   the singular value decomposition :math:`A = U S V^T` for :math:`M \ge N`.
   On output the matrix :data:`A` is replaced by
   :math:`U`. The diagonal elements of the singular value matrix :math:`S`
   are stored in the vector :data:`S`. The singular values are non-negative
   and form a non-increasing sequence from :math:`S_1` to :math:`S_N`. The
   matrix :data:`V` contains the elements of :math:`V` in untransposed
   form. To form the product :math:`U S V^T` it is necessary to take the
   transpose of :data:`V`.  A workspace of length :data:`N` is required in
   :data:`work`.

   This routine uses the Golub-Reinsch SVD algorithm.  

.. function:: int gsl_linalg_SV_decomp_mod (gsl_matrix * A, gsl_matrix * X, gsl_matrix * V, gsl_vector * S, gsl_vector * work)

   This function computes the SVD using the modified Golub-Reinsch
   algorithm, which is faster for :math:`M \gg N`.
   It requires the vector :data:`work` of length :data:`N` and the
   :math:`N`-by-:math:`N` matrix :data:`X` as additional working space.

.. index:: Jacobi orthogonalization

.. function:: int gsl_linalg_SV_decomp_jacobi (gsl_matrix * A, gsl_matrix * V, gsl_vector * S)

   This function computes the SVD of the :math:`M`-by-:math:`N` matrix :data:`A`
   using one-sided Jacobi orthogonalization for :math:`M \ge N`.
   The Jacobi method can compute singular values to higher
   relative accuracy than Golub-Reinsch algorithms (see references for
   details).

.. function:: int gsl_linalg_SV_solve (const gsl_matrix * U, const gsl_matrix * V, const gsl_vector * S, const gsl_vector * b, gsl_vector * x)

   This function solves the system :math:`A x = b` using the singular value
   decomposition (:data:`U`, :data:`S`, :data:`V`) of :math:`A` which must 
   have been computed previously with :func:`gsl_linalg_SV_decomp`.

   Only non-zero singular values are used in computing the solution. The
   parts of the solution corresponding to singular values of zero are
   ignored.  Other singular values can be edited out by setting them to
   zero before calling this function. 

   In the over-determined case where :data:`A` has more rows than columns the
   system is solved in the least squares sense, returning the solution
   :data:`x` which minimizes :math:`||A x - b||_2`.

.. function:: int gsl_linalg_SV_leverage (const gsl_matrix * U, gsl_vector * h)

   This function computes the statistical leverage values :math:`h_i` of a matrix :math:`A`
   using its singular value decomposition (:data:`U`, :data:`S`, :data:`V`) previously computed
   with :func:`gsl_linalg_SV_decomp`. :math:`h_i` are the diagonal values of the matrix
   :math:`A (A^T A)^{-1} A^T` and depend only on the matrix :data:`U` which is the input to
   this function.

.. index::
   single: Cholesky decomposition
   single: square root of a matrix, Cholesky decomposition
   single: matrix square root, Cholesky decomposition

.. _sec_cholesky-decomposition:

Cholesky Decomposition
======================

A symmetric, positive definite square matrix :math:`A` has a Cholesky
decomposition into a product of a lower triangular matrix :math:`L` and
its transpose :math:`L^T`,

.. math:: A = L L^T

This is sometimes referred to as taking the square-root of a matrix. The
Cholesky decomposition can only be carried out when all the eigenvalues
of the matrix are positive.  This decomposition can be used to convert
the linear system :math:`A x = b` into a pair of triangular systems
(:math:`L y = b`, :math:`L^T x = y`), which can be solved by forward and
back-substitution.

If the matrix :math:`A` is near singular, it is sometimes possible to reduce
the condition number and recover a more accurate solution vector :math:`x`
by scaling as

.. only:: not texinfo

   .. math:: \left( S A S \right) \left( S^{-1} x \right) = S b

.. only:: texinfo

   .. math:: ( S A S ) ( S^(-1) x ) = S b

where :math:`S` is a diagonal matrix whose elements are given by
:math:`S_{ii} = 1/\sqrt{A_{ii}}`. This scaling is also known as
Jacobi preconditioning. There are routines below to solve
both the scaled and unscaled systems.

.. function:: int gsl_linalg_cholesky_decomp1 (gsl_matrix * A)
              int gsl_linalg_complex_cholesky_decomp (gsl_matrix_complex * A)

   These functions factorize the symmetric, positive-definite square matrix
   :data:`A` into the Cholesky decomposition :math:`A = L L^T` (or
   :math:`A = L L^{\dagger}`
   for the complex case). On input, the values from the diagonal and lower-triangular
   part of the matrix :data:`A` are used (the upper triangular part is ignored).  On output
   the diagonal and lower triangular part of the input matrix :data:`A` contain the matrix
   :math:`L`, while the upper triangular part is unmodified.  If the matrix is not
   positive-definite then the decomposition will fail, returning the
   error code :macro:`GSL_EDOM`.

   When testing whether a matrix is positive-definite, disable the error
   handler first to avoid triggering an error.

.. function:: int gsl_linalg_cholesky_decomp (gsl_matrix * A)

   This function is now deprecated and is provided only for backward compatibility.

.. function:: int gsl_linalg_cholesky_solve (const gsl_matrix * cholesky, const gsl_vector * b, gsl_vector * x)
              int gsl_linalg_complex_cholesky_solve (const gsl_matrix_complex * cholesky, const gsl_vector_complex * b, gsl_vector_complex * x)

   These functions solve the system :math:`A x = b` using the Cholesky
   decomposition of :math:`A` held in the matrix :data:`cholesky` which must
   have been previously computed by :func:`gsl_linalg_cholesky_decomp` or
   :func:`gsl_linalg_complex_cholesky_decomp`.

.. function:: int gsl_linalg_cholesky_svx (const gsl_matrix * cholesky, gsl_vector * x)
              int gsl_linalg_complex_cholesky_svx (const gsl_matrix_complex * cholesky, gsl_vector_complex * x)

   These functions solve the system :math:`A x = b` in-place using the
   Cholesky decomposition of :math:`A` held in the matrix :data:`cholesky`
   which must have been previously computed by
   :func:`gsl_linalg_cholesky_decomp` or
   :func:`gsl_linalg_complex_cholesky_decomp`. On input :data:`x` should
   contain the right-hand side :math:`b`, which is replaced by the
   solution on output.

.. function:: int gsl_linalg_cholesky_invert (gsl_matrix * cholesky)
              int gsl_linalg_complex_cholesky_invert (gsl_matrix_complex * cholesky)

   These functions compute the inverse of a matrix from its Cholesky
   decomposition :data:`cholesky`, which must have been previously computed
   by :func:`gsl_linalg_cholesky_decomp` or
   :func:`gsl_linalg_complex_cholesky_decomp`.  On output, the inverse is
   stored in-place in :data:`cholesky`.

.. function:: int gsl_linalg_cholesky_decomp2 (gsl_matrix * A, gsl_vector * S)

   This function calculates a diagonal scaling transformation :math:`S` for
   the symmetric, positive-definite square matrix :data:`A`, and then
   computes the Cholesky decomposition :math:`S A S = L L^T`.
   On input, the values from the diagonal and lower-triangular part of the matrix :data:`A` are
   used (the upper triangular part is ignored).  On output the diagonal and lower triangular part
   of the input matrix :data:`A` contain the matrix :math:`L`, while the upper triangular part
   of the input matrix is overwritten with :math:`L^T` (the diagonal terms being
   identical for both :math:`L` and :math:`L^T`).  If the matrix is not
   positive-definite then the decomposition will fail, returning the
   error code :macro:`GSL_EDOM`. The diagonal scale factors are stored in :data:`S`
   on output.

   When testing whether a matrix is positive-definite, disable the error
   handler first to avoid triggering an error.

.. function:: int gsl_linalg_cholesky_solve2 (const gsl_matrix * cholesky, const gsl_vector * S, const gsl_vector * b, gsl_vector * x)

   This function solves the system :math:`(S A S) (S^{-1} x) = S b` using the Cholesky
   decomposition of :math:`S A S` held in the matrix :data:`cholesky` which must
   have been previously computed by :func:`gsl_linalg_cholesky_decomp2`.

.. function:: int gsl_linalg_cholesky_svx2 (const gsl_matrix * cholesky, const gsl_vector * S, gsl_vector * x)

   This function solves the system :math:`(S A S) (S^{-1} x) = S b` in-place using the
   Cholesky decomposition of :math:`S A S` held in the matrix :data:`cholesky`
   which must have been previously computed by
   :func:`gsl_linalg_cholesky_decomp2`.  On input :data:`x` should
   contain the right-hand side :math:`b`, which is replaced by the
   solution on output.

.. function:: int gsl_linalg_cholesky_scale (const gsl_matrix * A, gsl_vector * S)

   This function calculates a diagonal scaling transformation of the
   symmetric, positive definite matrix :data:`A`, such that
   :math:`S A S` has a condition number within a factor of :math:`N`
   of the matrix of smallest possible condition number over all
   possible diagonal scalings. On output, :data:`S` contains the
   scale factors, given by :math:`S_i = 1/\sqrt{A_{ii}}`.
   For any :math:`A_{ii} \le 0`, the corresponding scale factor :math:`S_i`
   is set to :math:`1`.

.. function:: int gsl_linalg_cholesky_scale_apply (gsl_matrix * A, const gsl_vector * S)

   This function applies the scaling transformation :data:`S` to the matrix :data:`A`. On output,
   :data:`A` is replaced by :math:`S A S`.

.. function:: int gsl_linalg_cholesky_rcond (const gsl_matrix * cholesky, double * rcond, gsl_vector * work)

   This function estimates the reciprocal condition number (using the 1-norm) of the symmetric positive
   definite matrix :math:`A`, using its Cholesky decomposition provided in :data:`cholesky`.
   The reciprocal condition number estimate, defined as :math:`1 / (||A||_1 \cdot ||A^{-1}||_1)`, is stored
   in :data:`rcond`.  Additional workspace of size :math:`3 N` is required in :data:`work`.

.. index::
   single: Cholesky decomposition, pivoted
   single: Pivoted Cholesky Decomposition

Pivoted Cholesky Decomposition
==============================

A symmetric, positive definite square matrix :math:`A` has an alternate
Cholesky decomposition into a product of a lower unit triangular matrix :math:`L`,
a diagonal matrix :math:`D` and :math:`L^T`, given by :math:`L D L^T`. This is
equivalent to the Cholesky formulation discussed above, with
the standard Cholesky lower triangular factor given by :math:`L D^{1 \over 2}`.
For ill-conditioned matrices, it can help to use a pivoting strategy to
prevent the entries of :math:`D` and :math:`L` from growing too large, and also
ensure :math:`D_1 \ge D_2 \ge \cdots \ge D_n > 0`, where :math:`D_i` are
the diagonal entries of :math:`D`. The final decomposition is given by

.. math:: P A P^T = L D L^T

where :math:`P` is a permutation matrix.

.. function:: int gsl_linalg_pcholesky_decomp (gsl_matrix * A, gsl_permutation * p)

   This function factors the symmetric, positive-definite square matrix
   :data:`A` into the Pivoted Cholesky decomposition :math:`P A P^T = L D L^T`.
   On input, the values from the diagonal and lower-triangular part of the matrix :data:`A` are
   used to construct the factorization. On output the diagonal of the input matrix :data:`A` stores
   the diagonal elements of :math:`D`, and the lower triangular portion of :data:`A`
   contains the matrix :math:`L`. Since :math:`L` has ones on its diagonal these
   do not need to be explicitely stored. The upper triangular portion of :data:`A` is
   unmodified. The permutation matrix :math:`P` is stored in :data:`p` on output.

.. function:: int gsl_linalg_pcholesky_solve (const gsl_matrix * LDLT, const gsl_permutation * p, const gsl_vector * b, gsl_vector * x)

   This function solves the system :math:`A x = b` using the Pivoted Cholesky
   decomposition of :math:`A` held in the matrix :data:`LDLT` and permutation
   :data:`p` which must have been previously computed by :func:`gsl_linalg_pcholesky_decomp`.

.. function:: int gsl_linalg_pcholesky_svx (const gsl_matrix * LDLT, const gsl_permutation * p, gsl_vector * x)

   This function solves the system :math:`A x = b` in-place using the Pivoted Cholesky
   decomposition of :math:`A` held in the matrix :data:`LDLT` and permutation
   :data:`p` which must have been previously computed by :func:`gsl_linalg_pcholesky_decomp`.
   On input, :data:`x` contains the right hand side vector :math:`b` which is
   replaced by the solution vector on output.

.. function:: int gsl_linalg_pcholesky_decomp2 (gsl_matrix * A, gsl_permutation * p, gsl_vector * S)

   This function computes the pivoted Cholesky factorization of the matrix
   :math:`S A S`, where the input matrix :data:`A` is symmetric and positive
   definite, and the diagonal scaling matrix :data:`S` is computed to reduce the
   condition number of :data:`A` as much as possible. See
   :ref:`Cholesky Decomposition <sec_cholesky-decomposition>` for more information on the matrix :data:`S`.
   The Pivoted Cholesky decomposition satisfies :math:`P S A S P^T = L D L^T`.
   On input, the values from the diagonal and lower-triangular part of the matrix :data:`A` are
   used to construct the factorization.  On output the diagonal of the input matrix :data:`A` stores the diagonal
   elements of :math:`D`, and the lower triangular portion of :data:`A`
   contains the matrix :math:`L`. Since :math:`L` has ones on its diagonal these
   do not need to be explicitely stored. The upper triangular portion of :data:`A`
   is unmodified. The permutation matrix :math:`P` is stored in :data:`p` on output.
   The diagonal scaling transformation is stored in :data:`S` on output.

.. function:: int gsl_linalg_pcholesky_solve2 (const gsl_matrix * LDLT, const gsl_permutation * p, const gsl_vector * S, const gsl_vector * b, gsl_vector * x)

   This function solves the system :math:`(S A S) (S^{-1} x) = S b` using the Pivoted Cholesky
   decomposition of :math:`S A S` held in the matrix :data:`LDLT`, permutation
   :data:`p`, and vector :data:`S`, which must have been previously computed by
   :func:`gsl_linalg_pcholesky_decomp2`.

.. function:: int gsl_linalg_pcholesky_svx2 (const gsl_matrix * LDLT, const gsl_permutation * p, const gsl_vector * S, gsl_vector * x)

   This function solves the system :math:`(S A S) (S^{-1} x) = S b` in-place using the Pivoted Cholesky
   decomposition of :math:`S A S` held in the matrix :data:`LDLT`, permutation
   :data:`p` and vector :data:`S`, which must have been previously computed by
   :func:`gsl_linalg_pcholesky_decomp2`.
   On input, :data:`x` contains the right hand side vector :math:`b` which is
   replaced by the solution vector on output.

.. function:: int gsl_linalg_pcholesky_invert (const gsl_matrix * LDLT, const gsl_permutation * p, gsl_matrix * Ainv)

   This function computes the inverse of the matrix :math:`A`, using the Pivoted
   Cholesky decomposition stored in :data:`LDLT` and :data:`p`. On output, the
   matrix :data:`Ainv` contains :math:`A^{-1}`.

.. function:: int gsl_linalg_pcholesky_rcond (const gsl_matrix * LDLT, const gsl_permutation * p, double * rcond, gsl_vector * work)

   This function estimates the reciprocal condition number (using the 1-norm) of the symmetric positive
   definite matrix :math:`A`, using its pivoted Cholesky decomposition provided in :data:`LDLT`.
   The reciprocal condition number estimate, defined as :math:`1 / (||A||_1 \cdot ||A^{-1}||_1)`, is stored
   in :data:`rcond`.  Additional workspace of size :math:`3 N` is required in :data:`work`.

.. index::
   single: Cholesky decomposition, modified
   single: Modified Cholesky Decomposition

Modified Cholesky Decomposition
===============================

The modified Cholesky decomposition is suitable for solving systems
:math:`A x = b` where :math:`A` is a symmetric indefinite matrix. Such
matrices arise in nonlinear optimization algorithms. The standard
Cholesky decomposition requires a positive definite matrix and would
fail in this case. Instead of resorting to a method like QR or SVD,
which do not take into account the symmetry of the matrix, we can
instead introduce a small perturbation to the matrix :math:`A` to
make it positive definite, and then use a Cholesky decomposition on
the perturbed matrix. The resulting decomposition satisfies

.. math:: P (A + E) P^T = L D L^T

where :math:`P` is a permutation matrix, :math:`E` is a diagonal
perturbation matrix, :math:`L` is unit lower triangular, and
:math:`D` is diagonal. If :math:`A` is sufficiently positive
definite, then the perturbation matrix :math:`E` will be zero
and this method is equivalent to the pivoted Cholesky algorithm.
For indefinite matrices, the perturbation matrix :math:`E` is
computed to ensure that :math:`A + E` is positive definite and
well conditioned.

.. function:: int gsl_linalg_mcholesky_decomp (gsl_matrix * A, gsl_permutation * p, gsl_vector * E)

   This function factors the symmetric, indefinite square matrix
   :data:`A` into the Modified Cholesky decomposition :math:`P (A + E) P^T = L D L^T`.
   On input, the values from the diagonal and lower-triangular part of the matrix :data:`A` are
   used to construct the factorization. On output the diagonal of the input matrix :data:`A` stores the diagonal
   elements of :math:`D`, and the lower triangular portion of :data:`A`
   contains the matrix :math:`L`. Since :math:`L` has ones on its diagonal these
   do not need to be explicitely stored. The upper triangular portion of :data:`A`
   is unmodified. The permutation matrix :math:`P` is
   stored in :data:`p` on output. The diagonal perturbation matrix is stored in
   :data:`E` on output. The parameter :data:`E` may be set to NULL if it is not
   required.

.. function:: int gsl_linalg_mcholesky_solve (const gsl_matrix * LDLT, const gsl_permutation * p, const gsl_vector * b, gsl_vector * x)

   This function solves the perturbed system :math:`(A + E) x = b` using the Cholesky
   decomposition of :math:`A + E` held in the matrix :data:`LDLT` and permutation
   :data:`p` which must have been previously computed by :func:`gsl_linalg_mcholesky_decomp`.

.. function:: int gsl_linalg_mcholesky_svx (const gsl_matrix * LDLT, const gsl_permutation * p, gsl_vector * x)

   This function solves the perturbed system :math:`(A + E) x = b` in-place using the Cholesky
   decomposition of :math:`A + E` held in the matrix :data:`LDLT` and permutation
   :data:`p` which must have been previously computed by :func:`gsl_linalg_mcholesky_decomp`.
   On input, :data:`x` contains the right hand side vector :math:`b` which is
   replaced by the solution vector on output.

.. function:: int gsl_linalg_mcholesky_rcond (const gsl_matrix * LDLT, const gsl_permutation * p, double * rcond, gsl_vector * work)

   This function estimates the reciprocal condition number (using the 1-norm) of the perturbed matrix
   :math:`A + E`, using its pivoted Cholesky decomposition provided in :data:`LDLT`.
   The reciprocal condition number estimate, defined as :math:`1 / (||A + E||_1 \cdot ||(A + E)^{-1}||_1)`, is stored
   in :data:`rcond`.  Additional workspace of size :math:`3 N` is required in :data:`work`.

.. index:: tridiagonal decomposition

Tridiagonal Decomposition of Real Symmetric Matrices
====================================================

A symmetric matrix :math:`A` can be factorized by similarity
transformations into the form,

.. math:: A = Q T Q^T

where :math:`Q` is an orthogonal matrix and :math:`T` is a symmetric
tridiagonal matrix.

.. function:: int gsl_linalg_symmtd_decomp (gsl_matrix * A, gsl_vector * tau)

   This function factorizes the symmetric square matrix :data:`A` into the
   symmetric tridiagonal decomposition :math:`Q T Q^T`.  On output the
   diagonal and subdiagonal part of the input matrix :data:`A` contain the
   tridiagonal matrix :math:`T`.  The remaining lower triangular part of the
   input matrix contains the Householder vectors which, together with the
   Householder coefficients :data:`tau`, encode the orthogonal matrix
   :math:`Q`. This storage scheme is the same as used by |lapack|.  The
   upper triangular part of :data:`A` is not referenced.

.. function:: int gsl_linalg_symmtd_unpack (const gsl_matrix * A, const gsl_vector * tau, gsl_matrix * Q, gsl_vector * diag, gsl_vector * subdiag)

   This function unpacks the encoded symmetric tridiagonal decomposition
   (:data:`A`, :data:`tau`) obtained from :func:`gsl_linalg_symmtd_decomp` into
   the orthogonal matrix :data:`Q`, the vector of diagonal elements :data:`diag`
   and the vector of subdiagonal elements :data:`subdiag`.  

.. function:: int gsl_linalg_symmtd_unpack_T (const gsl_matrix * A, gsl_vector * diag, gsl_vector * subdiag)

   This function unpacks the diagonal and subdiagonal of the encoded
   symmetric tridiagonal decomposition (:data:`A`, :data:`tau`) obtained from
   :func:`gsl_linalg_symmtd_decomp` into the vectors :data:`diag` and :data:`subdiag`.

.. index:: tridiagonal decomposition

Tridiagonal Decomposition of Hermitian Matrices
===============================================

A hermitian matrix :math:`A` can be factorized by similarity
transformations into the form,

.. math:: A = U T U^T

where :math:`U` is a unitary matrix and :math:`T` is a real symmetric
tridiagonal matrix.

.. function:: int gsl_linalg_hermtd_decomp (gsl_matrix_complex * A, gsl_vector_complex * tau)

   This function factorizes the hermitian matrix :data:`A` into the symmetric
   tridiagonal decomposition :math:`U T U^T`.  On output the real parts of
   the diagonal and subdiagonal part of the input matrix :data:`A` contain
   the tridiagonal matrix :math:`T`.  The remaining lower triangular part of
   the input matrix contains the Householder vectors which, together with
   the Householder coefficients :data:`tau`, encode the unitary matrix
   :math:`U`. This storage scheme is the same as used by |lapack|.  The
   upper triangular part of :data:`A` and imaginary parts of the diagonal are
   not referenced.

.. function:: int gsl_linalg_hermtd_unpack (const gsl_matrix_complex * A, const gsl_vector_complex * tau, gsl_matrix_complex * U, gsl_vector * diag, gsl_vector * subdiag)

   This function unpacks the encoded tridiagonal decomposition (:data:`A`,
   :data:`tau`) obtained from :func:`gsl_linalg_hermtd_decomp` into the
   unitary matrix :data:`U`, the real vector of diagonal elements :data:`diag` and
   the real vector of subdiagonal elements :data:`subdiag`. 

.. function:: int gsl_linalg_hermtd_unpack_T (const gsl_matrix_complex * A, gsl_vector * diag, gsl_vector * subdiag)

   This function unpacks the diagonal and subdiagonal of the encoded
   tridiagonal decomposition (:data:`A`, :data:`tau`) obtained from the
   :func:`gsl_linalg_hermtd_decomp` into the real vectors
   :data:`diag` and :data:`subdiag`.

.. index:: Hessenberg decomposition

Hessenberg Decomposition of Real Matrices
=========================================

A general real matrix :math:`A` can be decomposed by orthogonal
similarity transformations into the form

.. math:: A = U H U^T

where :math:`U` is orthogonal and :math:`H` is an upper Hessenberg matrix,
meaning that it has zeros below the first subdiagonal. The
Hessenberg reduction is the first step in the Schur decomposition
for the nonsymmetric eigenvalue problem, but has applications in
other areas as well.

.. function:: int gsl_linalg_hessenberg_decomp (gsl_matrix * A, gsl_vector * tau)

   This function computes the Hessenberg decomposition of the matrix
   :data:`A` by applying the similarity transformation :math:`H = U^T A U`.
   On output, :math:`H` is stored in the upper portion of :data:`A`. The
   information required to construct the matrix :math:`U` is stored in
   the lower triangular portion of :data:`A`. :math:`U` is a product
   of :math:`N - 2` Householder matrices. The Householder vectors
   are stored in the lower portion of :data:`A` (below the subdiagonal)
   and the Householder coefficients are stored in the vector :data:`tau`.
   :data:`tau` must be of length :data:`N`.

.. function:: int gsl_linalg_hessenberg_unpack (gsl_matrix * H, gsl_vector * tau, gsl_matrix * U)

   This function constructs the orthogonal matrix :math:`U` from the
   information stored in the Hessenberg matrix :data:`H` along with the
   vector :data:`tau`. :data:`H` and :data:`tau` are outputs from
   :func:`gsl_linalg_hessenberg_decomp`.

.. function:: int gsl_linalg_hessenberg_unpack_accum (gsl_matrix * H, gsl_vector * tau, gsl_matrix * V)

   This function is similar to :func:`gsl_linalg_hessenberg_unpack`, except
   it accumulates the matrix :data:`U` into :data:`V`, so that :math:`V' = VU`.
   The matrix :data:`V` must be initialized prior to calling this function.
   Setting :data:`V` to the identity matrix provides the same result as
   :func:`gsl_linalg_hessenberg_unpack`. If :data:`H` is order :data:`N`, then
   :data:`V` must have :data:`N` columns but may have any number of rows.

.. function:: int gsl_linalg_hessenberg_set_zero (gsl_matrix * H)

   This function sets the lower triangular portion of :data:`H`, below
   the subdiagonal, to zero. It is useful for clearing out the
   Householder vectors after calling :func:`gsl_linalg_hessenberg_decomp`.

.. index:: Hessenberg triangular decomposition

Hessenberg-Triangular Decomposition of Real Matrices
====================================================

A general real matrix pair (:math:`A`, :math:`B`) can be decomposed by
orthogonal similarity transformations into the form

.. only:: not texinfo

   .. math::

      A &= U H V^T \\
      B &= U R V^T

.. only:: texinfo

   ::

      A = U H V^T
      B = U R V^T

where :math:`U` and :math:`V` are orthogonal, :math:`H` is an upper
Hessenberg matrix, and :math:`R` is upper triangular. The
Hessenberg-Triangular reduction is the first step in the generalized
Schur decomposition for the generalized eigenvalue problem.

.. function:: int gsl_linalg_hesstri_decomp (gsl_matrix * A, gsl_matrix * B, gsl_matrix * U, gsl_matrix * V, gsl_vector * work)

   This function computes the Hessenberg-Triangular decomposition of the
   matrix pair (:data:`A`, :data:`B`). On output, :math:`H` is stored in :data:`A`,
   and :math:`R` is stored in :data:`B`. If :data:`U` and :data:`V` are provided
   (they may be null), the similarity transformations are stored in them.
   Additional workspace of length :math:`N` is needed in :data:`work`.

.. index:: bidiagonalization of real matrices

Bidiagonalization
=================

A general matrix :math:`A` can be factorized by similarity
transformations into the form,

.. math:: A = U B V^T

where :math:`U` and :math:`V` are orthogonal matrices and :math:`B` is a
:math:`N`-by-:math:`N` bidiagonal matrix with non-zero entries only on the
diagonal and superdiagonal.  The size of :data:`U` is :math:`M`-by-:math:`N`
and the size of :data:`V` is :math:`N`-by-:math:`N`.

.. function:: int gsl_linalg_bidiag_decomp (gsl_matrix * A, gsl_vector * tau_U, gsl_vector * tau_V)

   This function factorizes the :math:`M`-by-:math:`N` matrix :data:`A` into
   bidiagonal form :math:`U B V^T`.  The diagonal and superdiagonal of the
   matrix :math:`B` are stored in the diagonal and superdiagonal of :data:`A`.
   The orthogonal matrices :math:`U` and :data:`V` are stored as compressed
   Householder vectors in the remaining elements of :data:`A`.  The
   Householder coefficients are stored in the vectors :data:`tau_U` and
   :data:`tau_V`.  The length of :data:`tau_U` must equal the number of
   elements in the diagonal of :data:`A` and the length of :data:`tau_V` should
   be one element shorter.

.. function:: int gsl_linalg_bidiag_unpack (const gsl_matrix * A, const gsl_vector * tau_U, gsl_matrix * U, const gsl_vector * tau_V, gsl_matrix * V, gsl_vector * diag, gsl_vector * superdiag)

   This function unpacks the bidiagonal decomposition of :data:`A` produced by
   :func:`gsl_linalg_bidiag_decomp`, (:data:`A`, :data:`tau_U`, :data:`tau_V`)
   into the separate orthogonal matrices :data:`U`, :data:`V` and the diagonal
   vector :data:`diag` and superdiagonal :data:`superdiag`.  Note that :data:`U`
   is stored as a compact :math:`M`-by-:math:`N` orthogonal matrix satisfying
   :math:`U^T U = I` for efficiency.

.. function:: int gsl_linalg_bidiag_unpack2 (gsl_matrix * A, gsl_vector * tau_U, gsl_vector * tau_V, gsl_matrix * V)

   This function unpacks the bidiagonal decomposition of :data:`A` produced by
   :func:`gsl_linalg_bidiag_decomp`, (:data:`A`, :data:`tau_U`, :data:`tau_V`)
   into the separate orthogonal matrices :data:`U`, :data:`V` and the diagonal
   vector :data:`diag` and superdiagonal :data:`superdiag`.  The matrix :data:`U`
   is stored in-place in :data:`A`.

.. function:: int gsl_linalg_bidiag_unpack_B (const gsl_matrix * A, gsl_vector * diag, gsl_vector * superdiag)

   This function unpacks the diagonal and superdiagonal of the bidiagonal
   decomposition of :data:`A` from :func:`gsl_linalg_bidiag_decomp`, into
   the diagonal vector :data:`diag` and superdiagonal vector :data:`superdiag`.

.. index:: Givens rotation

Givens Rotations
================

A Givens rotation is a rotation in the plane acting on two elements
of a given vector. It can be represented in matrix form as

.. only:: not texinfo

   .. math::

      G(i,j,\theta) =
      \left(
      \begin{matrix}
        1 & \ldots & 0 & \ldots & 0 & \ldots & 0 \\
        \vdots & \ddots & \vdots &  & \vdots & & \vdots \\
        0 & \ldots & \cos{\theta} & \ldots & -\sin{\theta} & \ldots & 0 \\
        \vdots &  & \vdots & \ddots & \vdots & & \vdots \\
        0 & \ldots & \sin{\theta} & \ldots & \cos{\theta} & \ldots & 0 \\
        \vdots &  & \vdots &  & \vdots & \ddots & \vdots \\
        0 & \ldots & 0 & \ldots & 0 & \ldots & 1
      \end{matrix}
      \right)

where the :math:`\cos{\theta}` and :math:`\sin{\theta}` appear at
the intersection of the :math:`i`-th and :math:`j`-th rows and columns.
When acting on a vector :math:`x`, :math:`G(i,j,\theta) x` performs
a rotation of the :math:`(i,j)` elements of :math:`x`. Givens
rotations are typically used to introduce zeros in
vectors, such as during the QR decomposition of a matrix. In this
case, it is typically desired to find :math:`c` and :math:`s` such that

.. only:: not texinfo

   .. math::

      \left(
      \begin{matrix}
        c & -s \\
        s & c
      \end{matrix}
      \right)
      \left(
      \begin{matrix}
        a \\
        b
      \end{matrix}
      \right) =
      \left(
      \begin{matrix}
        r \\
        0
      \end{matrix}
      \right)

.. only:: texinfo

   ::

     [ c -s ] [ a ] = [ r ]
     [ s  c ] [ b ]   [ 0 ]

with :math:`r = \sqrt{a^2 + b^2}`.

.. function:: void gsl_linalg_givens (const double a, const double b, double * c, double * s)

   This function computes :math:`c = \cos{\theta}` and :math:`s = \sin{\theta}`
   so that the Givens matrix :math:`G(\theta)` acting on the
   vector :math:`(a,b)` produces :math:`(r, 0)`, with :math:`r = \sqrt{a^2 + b^2}`.

.. function:: void gsl_linalg_givens_gv (gsl_vector * v, const size_t i, const size_t j, const double c, const double s)

   This function applies the Givens rotation defined by
   :math:`c = \cos{\theta}` and :math:`s = \sin{\theta}` to the :data:`i`
   and :data:`j` elements of :data:`v`. On output,
   :math:`(v(i),v(j)) \leftarrow G(\theta) (v(i),v(j))`.

.. index::
   single: Householder matrix
   single: Householder transformation
   single: transformation, Householder

Householder Transformations
===========================

A Householder transformation is a rank-1 modification of the identity
matrix which can be used to zero out selected elements of a vector.  A
Householder matrix :math:`P` takes the form,

.. math:: P = I - \tau v v^T

where :math:`v` is a vector (called the *Householder vector*) and
:math:`\tau = 2/(v^T v)`. The functions described in this section use the
rank-1 structure of the Householder matrix to create and apply
Householder transformations efficiently.

.. function:: double gsl_linalg_householder_transform (gsl_vector * w)
              gsl_complex gsl_linalg_complex_householder_transform (gsl_vector_complex * w)

   This function prepares a Householder transformation :math:`P = I - \tau v v^T`
   which can be used to zero all the elements of the input vector :data:`w`
   except the first. On output the Householder vector :data:`v` is stored in
   :data:`w` and the scalar :math:`\tau` is returned. The householder vector
   :data:`v` is normalized so that :code:`v[0] = 1`, however this 1 is not
   stored in the output vector. Instead, :code:`w[0]` is set to
   the first element of the transformed vector, so that if
   :math:`u = P w`, :code:`w[0] = u[0]` on output and the remainder
   of :math:`u` is zero.

.. function:: int gsl_linalg_householder_hm (double tau, const gsl_vector * v, gsl_matrix * A)
              int gsl_linalg_complex_householder_hm (gsl_complex tau, const gsl_vector_complex * v, gsl_matrix_complex * A)

   This function applies the Householder matrix :math:`P` defined by the
   scalar :data:`tau` and the vector :data:`v` to the left-hand side of the
   matrix :data:`A`. On output the result :math:`P A` is stored in :data:`A`.

.. function:: int gsl_linalg_householder_mh (double tau, const gsl_vector * v, gsl_matrix * A)
              int gsl_linalg_complex_householder_mh (gsl_complex tau, const gsl_vector_complex * v, gsl_matrix_complex * A)

   This function applies the Householder matrix :math:`P` defined by the
   scalar :data:`tau` and the vector :data:`v` to the right-hand side of the
   matrix :data:`A`. On output the result :math:`A P` is stored in :data:`A`.

.. function:: int gsl_linalg_householder_hv (double tau, const gsl_vector * v, gsl_vector * w)
              int gsl_linalg_complex_householder_hv (gsl_complex tau, const gsl_vector_complex * v, gsl_vector_complex * w)

   This function applies the Householder transformation :math:`P` defined by
   the scalar :data:`tau` and the vector :data:`v` to the vector :data:`w`.  On
   output the result :math:`P w` is stored in :data:`w`.

.. @deftypefun int gsl_linalg_householder_hm1 (double tau, gsl_matrix * A)
.. This function applies the Householder transform, defined by the scalar
.. :data:`tau` and the vector :data:`v`, to a matrix being build up from the
.. identity matrix, using the first column of :data:`A` as a householder vector.
.. @end deftypefun

.. index::
   single: solution of linear system by Householder transformations
   single: Householder linear solver

Householder solver for linear systems
=====================================

.. function:: int gsl_linalg_HH_solve (gsl_matrix * A, const gsl_vector * b, gsl_vector * x)

   This function solves the system :math:`A x = b` directly using
   Householder transformations. On output the solution is stored in :data:`x`
   and :data:`b` is not modified. The matrix :data:`A` is destroyed by the
   Householder transformations.

.. function:: int gsl_linalg_HH_svx (gsl_matrix * A, gsl_vector * x)

   This function solves the system :math:`A x = b` in-place using
   Householder transformations.  On input :data:`x` should contain the
   right-hand side :math:`b`, which is replaced by the solution on output.  The
   matrix :data:`A` is destroyed by the Householder transformations.

.. index:: tridiagonal systems

Tridiagonal Systems
===================

The functions described in this section efficiently solve symmetric,
non-symmetric and cyclic tridiagonal systems with minimal storage.
Note that the current implementations of these functions use a variant
of Cholesky decomposition, so the tridiagonal matrix must be positive
definite.  For non-positive definite matrices, the functions return
the error code :macro:`GSL_ESING`.

.. function:: int gsl_linalg_solve_tridiag (const gsl_vector * diag, const gsl_vector * e, const gsl_vector * f, const gsl_vector * b, gsl_vector * x)

   This function solves the general :math:`N`-by-:math:`N` system :math:`A x = b`
   where :data:`A` is tridiagonal (:math:`N \geq 2`).
   The super-diagonal and
   sub-diagonal vectors :data:`e` and :data:`f` must be one element shorter
   than the diagonal vector :data:`diag`.  The form of :data:`A` for the 4-by-4
   case is shown below,

   .. only:: not texinfo

      .. math::

         A =
         \left(
         \begin{matrix}
           d_0&e_0&  0& 0\\
           f_0&d_1&e_1& 0\\
           0  &f_1&d_2&e_2\\ 
           0  &0  &f_2&d_3
         \end{matrix}
         \right)

   .. only:: texinfo

      ::

         A = ( d_0 e_0  0   0  )
             ( f_0 d_1 e_1  0  )
             (  0  f_1 d_2 e_2 )
             (  0   0  f_2 d_3 )

.. function:: int gsl_linalg_solve_symm_tridiag (const gsl_vector * diag, const gsl_vector * e, const gsl_vector * b, gsl_vector * x)

   This function solves the general :math:`N`-by-:math:`N` system :math:`A x = b`
   where :data:`A` is symmetric tridiagonal (:math:`N \geq 2`).
   The off-diagonal vector
   :data:`e` must be one element shorter than the diagonal vector :data:`diag`.
   The form of :data:`A` for the 4-by-4 case is shown below,

   .. only:: not texinfo

      .. math::

         A =
         \left(
         \begin{matrix}
           d_0&e_0&  0& 0\\
           e_0&d_1&e_1& 0\\
           0  &e_1&d_2&e_2\\ 
           0  &0  &e_2&d_3
         \end{matrix}
         \right)

   .. only:: texinfo

      ::

         A = ( d_0 e_0  0   0  )
             ( e_0 d_1 e_1  0  )
             (  0  e_1 d_2 e_2 )
             (  0   0  e_2 d_3 )

.. function:: int gsl_linalg_solve_cyc_tridiag (const gsl_vector * diag, const gsl_vector * e, const gsl_vector * f, const gsl_vector * b, gsl_vector * x)

   This function solves the general :math:`N`-by-:math:`N` system :math:`A x = b`
   where :data:`A` is cyclic tridiagonal (:math:`N \geq 3`).
   The cyclic super-diagonal and
   sub-diagonal vectors :data:`e` and :data:`f` must have the same number of
   elements as the diagonal vector :data:`diag`.  The form of :data:`A` for the
   4-by-4 case is shown below,

   .. only:: not texinfo

      .. math::

         A =
         \left(
         \begin{matrix}
           d_0&e_0& 0 &f_3\\
           f_0&d_1&e_1& 0 \\
           0 &f_1&d_2&e_2\\ 
           e_3& 0 &f_2&d_3
         \end{matrix}
         \right)

   .. only:: texinfo

      ::

         A = ( d_0 e_0  0  f_3 )
             ( f_0 d_1 e_1  0  )
             (  0  f_1 d_2 e_2 )
             ( e_3  0  f_2 d_3 )

.. function:: int gsl_linalg_solve_symm_cyc_tridiag (const gsl_vector * diag, const gsl_vector * e, const gsl_vector * b, gsl_vector * x)

   This function solves the general :math:`N`-by-:math:`N` system :math:`A x = b`
   where :data:`A` is symmetric cyclic tridiagonal (:math:`N \geq 3`).
   The cyclic
   off-diagonal vector :data:`e` must have the same number of elements as the
   diagonal vector :data:`diag`.  The form of :data:`A` for the 4-by-4 case is
   shown below,

   .. only:: not texinfo

      .. math::

         A =
         \left(
         \begin{matrix}
           d_0&e_0& 0 &e_3\\
           e_0&d_1&e_1& 0 \\
           0 &e_1&d_2&e_2\\ 
           e_3& 0 &e_2&d_3
         \end{matrix}
         \right)

   .. only:: texinfo

      ::

         A = ( d_0 e_0  0  e_3 )
             ( e_0 d_1 e_1  0  )
             (  0  e_1 d_2 e_2 )
             ( e_3  0  e_2 d_3 )

.. index:: triangular systems

Triangular Systems
==================

.. function:: int gsl_linalg_tri_upper_invert (gsl_matrix * T)
              int gsl_linalg_tri_lower_invert (gsl_matrix * T)
              int gsl_linalg_tri_upper_unit_invert (gsl_matrix * T)
              int gsl_linalg_tri_lower_unit_invert (gsl_matrix * T)

   These functions calculate the in-place inverse of the triangular matrix :data:`T`. When
   the :code:`upper` prefix is specified, then the upper triangle of :data:`T` is used, and when
   the :code:`lower` prefix is specified, the lower triangle is used. If the :code:`unit`
   prefix is specified, then the diagonal elements of the matrix :data:`T` are taken as
   unity and are not referenced. Otherwise the diagonal elements are used in the inversion.

.. function:: int gsl_linalg_tri_upper_rcond (const gsl_matrix * T, double * rcond, gsl_vector * work)
              int gsl_linalg_tri_lower_rcond (const gsl_matrix * T, double * rcond, gsl_vector * work)

   These functions estimate the reciprocal condition number, in the 1-norm, of the upper or lower
   :math:`N`-by-:math:`N` triangular matrix :data:`T`. The reciprocal condition number
   is stored in :data:`rcond` on output, and is defined by :math:`1 / (||T||_1 \cdot ||T^{-1}||_1)`.
   Additional workspace of size :math:`3 N` is required in :data:`work`.

.. index:: balancing matrices

.. _balancing:

Balancing
=========

The process of balancing a matrix applies similarity transformations
to make the rows and columns have comparable norms. This is
useful, for example, to reduce roundoff errors in the solution
of eigenvalue problems. Balancing a matrix :math:`A` consists
of replacing :math:`A` with a similar matrix

.. math:: A' = D^{-1} A D

where :math:`D` is a diagonal matrix whose entries are powers
of the floating point radix.

.. function:: int gsl_linalg_balance_matrix (gsl_matrix * A, gsl_vector * D)

   This function replaces the matrix :data:`A` with its balanced counterpart
   and stores the diagonal elements of the similarity transformation
   into the vector :data:`D`.

Examples
========

The following program solves the linear system :math:`A x = b`. The
system to be solved is,

.. only:: not texinfo

   .. math::

      \left(
      \begin{matrix}
        0.18& 0.60& 0.57& 0.96\\
        0.41& 0.24& 0.99& 0.58\\
        0.14& 0.30& 0.97& 0.66\\
        0.51& 0.13& 0.19& 0.85
      \end{matrix}
      \right)
      \left(
      \begin{matrix}
        x_0\\
        x_1\\
        x_2\\
        x_3
      \end{matrix}
      \right)
      =
      \left(
      \begin{matrix}
        1.0\\
        2.0\\
        3.0\\
        4.0
      \end{matrix}
      \right)

.. only:: texinfo

   ::

      [ 0.18 0.60 0.57 0.96 ] [x0]   [1.0]
      [ 0.41 0.24 0.99 0.58 ] [x1] = [2.0]
      [ 0.14 0.30 0.97 0.66 ] [x2]   [3.0]
      [ 0.51 0.13 0.19 0.85 ] [x3]   [4.0]

and the solution is found using LU decomposition of the matrix :math:`A`.

.. include:: examples/linalglu.c
   :code:

Here is the output from the program,

.. include:: examples/linalglu.txt
   :code:

This can be verified by multiplying the solution :math:`x` by the
original matrix :math:`A` using |octave|,

::

  octave> A = [ 0.18, 0.60, 0.57, 0.96;
                0.41, 0.24, 0.99, 0.58; 
                0.14, 0.30, 0.97, 0.66; 
                0.51, 0.13, 0.19, 0.85 ];

  octave> x = [ -4.05205; -12.6056; 1.66091; 8.69377];

  octave> A * x
  ans =
    1.0000
    2.0000
    3.0000
    4.0000

This reproduces the original right-hand side vector, :math:`b`, in
accordance with the equation :math:`A x = b`.

References and Further Reading
==============================

Further information on the algorithms described in this section can be
found in the following book,

* G. H. Golub, C. F. Van Loan, "Matrix Computations" (3rd Ed, 1996),
  Johns Hopkins University Press, ISBN 0-8018-5414-8.

The |lapack| library is described in the following manual,

* *LAPACK Users' Guide* (Third Edition, 1999), Published by SIAM,
  ISBN 0-89871-447-8

The |lapack| source code can be found at http://www.netlib.org/lapack,
along with an online copy of the users guide.

The Modified Golub-Reinsch algorithm is described in the following paper,

* T.F. Chan, "An Improved Algorithm for Computing the Singular Value
  Decomposition", ACM Transactions on Mathematical Software, 8
  (1982), pp 72--83.

The Jacobi algorithm for singular value decomposition is described in
the following papers,

* J.C. Nash, "A one-sided transformation method for the singular value
  decomposition and algebraic eigenproblem", Computer Journal,
  Volume 18, Number 1 (1975), p 74--76

* J.C. Nash and S. Shlien "Simple algorithms for the partial singular
  value decomposition", Computer Journal, Volume 30 (1987), p
  268--275.

* J. Demmel, K. Veselic, "Jacobi's Method is more accurate than
  QR", Lapack Working Note 15 (LAWN-15), October 1989. Available
  from netlib, http://www.netlib.org/lapack/ in the :code:`lawns` or
  :code:`lawnspdf` directories.

The algorithm for estimating a matrix condition number is described in
the following paper,

* N. J. Higham, "FORTRAN codes for estimating the one-norm of
  a real or complex matrix, with applications to condition estimation",
  ACM Trans. Math. Soft., vol. 14, no. 4, pp. 381-396, December 1988.
.. index:: special functions

*****************
Special Functions
*****************

This chapter describes the GSL special function library.  The library
includes routines for calculating the values of Airy functions, Bessel
functions, Clausen functions, Coulomb wave functions, Coupling
coefficients, the Dawson function, Debye functions, Dilogarithms,
Elliptic integrals, Jacobi elliptic functions, Error functions,
Exponential integrals, Fermi-Dirac functions, Gamma functions,
Gegenbauer functions, Hermite polynomials and functions, Hypergeometric functions, Laguerre functions,
Legendre functions and Spherical Harmonics, the Psi (Digamma) Function,
Synchrotron functions, Transport functions, Trigonometric functions and
Zeta functions.  Each routine also computes an estimate of the numerical
error in the calculated value of the function.

The functions in this chapter are declared in individual header files,
such as :file:`gsl_sf_airy.h`, :file:`gsl_sf_bessel.h`, etc.  The complete
set of header files can be included using the file :file:`gsl_sf.h`.

Usage
=====

The special functions are available in two calling conventions, a
*natural form* which returns the numerical value of the function and
an *error-handling form* which returns an error code.  The two types
of function provide alternative ways of accessing the same underlying
code.

The *natural form* returns only the value of the function and can be
used directly in mathematical expressions.  For example, the following
function call will compute the value of the Bessel function
:math:`J_0(x)`::

    double y = gsl_sf_bessel_J0 (x);

There is no way to access an error code or to estimate the error using
this method.  To allow access to this information the alternative
error-handling form stores the value and error in a modifiable argument::

    gsl_sf_result result;
    int status = gsl_sf_bessel_J0_e (x, &result);

The error-handling functions have the suffix :code:`_e`. The returned
status value indicates error conditions such as overflow, underflow or
loss of precision.  If there are no errors the error-handling functions
return :code:`GSL_SUCCESS`.

The gsl_sf_result struct
========================

The error handling form of the special functions always calculate an
error estimate along with the value of the result.  Therefore,
structures are provided for amalgamating a value and error estimate.
These structures are declared in the header file :file:`gsl_sf_result.h`.

The following struct contains value and error fields.

.. type:: gsl_sf_result

   ::

     typedef struct
     {
       double val;
       double err;
     } gsl_sf_result;

   The field :data:`val` contains the value and the field :data:`err` contains
   an estimate of the absolute error in the value.

In some cases, an overflow or underflow can be detected and handled by a
function.  In this case, it may be possible to return a scaling exponent
as well as an error/value pair in order to save the result from
exceeding the dynamic range of the built-in types.  The
following struct contains value and error fields as well
as an exponent field such that the actual result is obtained as
:code:`result * 10^(e10)`.

.. type:: gsl_sf_result_e10

   ::

     typedef struct
     {
       double val;
       double err;
       int    e10;
     } gsl_sf_result_e10;

Modes
=====

The goal of the library is to achieve double precision accuracy wherever
possible.  However the cost of evaluating some special functions to
double precision can be significant, particularly where very high order
terms are required.  In these cases a :code:`mode` argument, of type
:type:`gsl_mode_t` allows the
accuracy of the function to be reduced in order to improve performance.
The following precision levels are available for the mode argument,

.. type:: gsl_mode_t

   .. macro:: GSL_PREC_DOUBLE

      Double-precision, a relative accuracy of approximately :math:`2 * 10^{-16}`.

   .. macro:: GSL_PREC_SINGLE

      Single-precision, a relative accuracy of approximately :math:`10^{-7}`.

   .. macro:: GSL_PREC_APPROX

      Approximate values, a relative accuracy of approximately :math:`5 * 10^{-4}`.

The approximate mode provides the fastest evaluation at the lowest
accuracy.

Airy Functions and Derivatives
==============================
.. include:: specfunc-airy.rst

Bessel Functions
================
.. include:: specfunc-bessel.rst

Clausen Functions
=================
.. include:: specfunc-clausen.rst

Coulomb Functions
=================
.. include:: specfunc-coulomb.rst

Coupling Coefficients
=====================
.. include:: specfunc-coupling.rst

Dawson Function
===============
.. include:: specfunc-dawson.rst

Debye Functions
===============
.. include:: specfunc-debye.rst

.. _dilog-function:

Dilogarithm
===========
.. include:: specfunc-dilog.rst

Elementary Operations
=====================
.. include:: specfunc-elementary.rst

Elliptic Integrals
==================
.. include:: specfunc-ellint.rst

Elliptic Functions (Jacobi)
===========================
.. include:: specfunc-elljac.rst

Error Functions
===============
.. include:: specfunc-erf.rst

Exponential Functions
=====================
.. include:: specfunc-exp.rst

Exponential Integrals
=====================
.. include:: specfunc-expint.rst

Fermi-Dirac Function
====================
.. include:: specfunc-fermi-dirac.rst

Gamma and Beta Functions
========================
.. include:: specfunc-gamma.rst

Gegenbauer Functions
====================
.. include:: specfunc-gegenbauer.rst

Hermite Polynomials and Functions
=================================
.. include:: specfunc-hermite.rst

Hypergeometric Functions
========================
.. include:: specfunc-hyperg.rst

.. _laguerre-functions:

Laguerre Functions
==================
.. include:: specfunc-laguerre.rst

Lambert W Functions
===================
.. include:: specfunc-lambert.rst

Legendre Functions and Spherical Harmonics
==========================================
.. include:: specfunc-legendre.rst

Logarithm and Related Functions
===============================
.. include:: specfunc-log.rst

Mathieu Functions
=================
.. include:: specfunc-mathieu.rst

Power Function
==============
.. include:: specfunc-pow-int.rst

Psi (Digamma) Function
======================
.. include:: specfunc-psi.rst

Synchrotron Functions
=====================
.. include:: specfunc-synchrotron.rst

Transport Functions
===================
.. include:: specfunc-transport.rst

Trigonometric Functions
=======================
.. include:: specfunc-trig.rst

Zeta Functions
==============
.. include:: specfunc-zeta.rst

Examples
========

The following example demonstrates the use of the error handling form of
the special functions, in this case to compute the Bessel function
:math:`J_0(5.0)`,

.. include:: examples/specfun_e.c
   :code:

Here are the results of running the program,

.. include:: examples/specfun_e.txt
   :code:

The next program computes the same quantity using the natural form of
the function. In this case the error term :data:`result.err` and return
status are not accessible.

.. include:: examples/specfun.c
   :code:

The results of the function are the same,

.. include:: examples/specfun.txt
   :code:

References and Further Reading
==============================

The library follows the conventions of the following book where possible,

* Handbook of Mathematical Functions, edited by Abramowitz & Stegun,
  Dover,  ISBN 0486612724.

The following papers contain information on the algorithms used 
to compute the special functions,

.. index:: MISCFUN

* Allan J. MacLeod, MISCFUN: A software package to compute uncommon
  special functions.  ACM Trans. Math. Soft., vol.: 22,
  1996, 288--301

* G.N. Watson, A Treatise on the Theory of Bessel Functions,
  2nd Edition (Cambridge University Press, 1944).

* G. Nemeth, Mathematical Approximations of Special Functions,
  Nova Science Publishers, ISBN 1-56072-052-2

* B.C. Carlson, Special Functions of Applied Mathematics (1977)

* N. M. Temme, Special Functions: An Introduction to the Classical
  Functions of Mathematical Physics (1996), ISBN 978-0471113133.

* W.J. Thompson, Atlas for Computing Mathematical Functions, John Wiley & Sons,
  New York (1997).

* Y.Y. Luke, Algorithms for the Computation of Mathematical Functions, Academic
  Press, New York (1977).

* S. A. Holmes and W. E. Featherstone, A unified approach to the Clenshaw
  summation and the recursive computation of very high degree and order
  normalised associated Legendre functions, Journal of Geodesy, 76,
  pg. 279-299, 2002.
.. index::
   single: coupling coefficients
   single: 3-j symbols
   single: 6-j symbols
   single: 9-j symbols
   single: Wigner coefficients
   single: Racah coefficients

The Wigner 3-j, 6-j and 9-j symbols give the coupling coefficients for
combined angular momentum vectors.  Since the arguments of the standard
coupling coefficient functions are integer or half-integer, the
arguments of the following functions are, by convention, integers equal
to twice the actual spin value.  For information on the 3-j coefficients
see Abramowitz & Stegun, Section 27.9.  The functions described in this
section are declared in the header file :file:`gsl_sf_coupling.h`.

3-j Symbols
-----------

.. function:: double gsl_sf_coupling_3j (int two_ja, int two_jb, int two_jc, int two_ma, int two_mb, int two_mc)
              int gsl_sf_coupling_3j_e (int two_ja, int two_jb, int two_jc, int two_ma, int two_mb, int two_mc, gsl_sf_result * result)

   These routines compute the Wigner 3-j coefficient, 

   .. only:: not texinfo

      .. math::

         \left(
         \begin{array}{ccc}
           ja & jb & jc \\
           ma & mb & mc
         \end{array}
         \right)

   .. only:: texinfo

      | ( ja jb jc )
      | ( ma mb mc )

   where the arguments are given in half-integer units, :math:`ja` =
   :data:`two_ja`/2, :math:`ma` = :data:`two_ma`/2, etc.
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW

6-j Symbols
-----------

.. function:: double gsl_sf_coupling_6j (int two_ja, int two_jb, int two_jc, int two_jd, int two_je, int two_jf)
              int gsl_sf_coupling_6j_e (int two_ja, int two_jb, int two_jc, int two_jd, int two_je, int two_jf, gsl_sf_result * result) 

   These routines compute the Wigner 6-j coefficient, 

   .. only:: not texinfo

      .. math::

         \left\{
         \begin{array}{ccc}
           ja & jb & jc \\
           jd & je & jf
         \end{array}
         \right\}

   .. only:: texinfo

      | { ja jb jc }
      | { jd je jf }

   where the arguments are given in half-integer units, :math:`ja` =
   :data:`two_ja`/2, :math:`ma` = :data:`two_ma`/2, etc.
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW

9-j Symbols
-----------

.. function:: double gsl_sf_coupling_9j (int two_ja, int two_jb, int two_jc, int two_jd, int two_je, int two_jf, int two_jg, int two_jh, int two_ji)
              int gsl_sf_coupling_9j_e (int two_ja, int two_jb, int two_jc, int two_jd, int two_je, int two_jf, int two_jg, int two_jh, int two_ji, gsl_sf_result * result) 

   These routines compute the Wigner 9-j coefficient, 

   .. only:: not texinfo

      .. math::

         \left\{
         \begin{array}{ccc}
           ja & jb & jc \\
           jd & je & jf \\
           jg & jh & ji
         \end{array}
         \right\}

   .. only:: texinfo
   
      | { ja jb jc }
      | { jd je jf }
      | { jg jh ji }

   where the arguments are given in half-integer units, :math:`ja` =
   :data:`two_ja`/2, :math:`ma` = :data:`two_ma`/2, etc.
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW
.. index::
   single: Legendre polynomials
   single: Legendre functions
   single: spherical harmonics
   single: conical functions
   single: hyperbolic space

The Legendre Functions and Legendre Polynomials are described in
Abramowitz & Stegun, Chapter 8.  These functions are declared in 
the header file :file:`gsl_sf_legendre.h`.

Legendre Polynomials
--------------------

.. function:: double gsl_sf_legendre_P1 (double x)
              double gsl_sf_legendre_P2 (double x)
              double gsl_sf_legendre_P3 (double x)
              int gsl_sf_legendre_P1_e (double x, gsl_sf_result * result)
              int gsl_sf_legendre_P2_e (double x, gsl_sf_result * result)
              int gsl_sf_legendre_P3_e (double x, gsl_sf_result * result)

   These functions evaluate the Legendre polynomials
   :math:`P_l(x)` using explicit representations for :math:`l = 1, 2, 3`.
.. Exceptional Return Values: none

.. function:: double gsl_sf_legendre_Pl (int l, double x)
              int gsl_sf_legendre_Pl_e (int l, double x, gsl_sf_result * result)

   These functions evaluate the Legendre polynomial :math:`P_l(x)`
   for a specific value of :data:`l`, :data:`x` subject to :math:`l \ge 0` and
   :math:`|x| \le 1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: int gsl_sf_legendre_Pl_array (int lmax, double x, double result_array[])
              int gsl_sf_legendre_Pl_deriv_array (int lmax, double x, double result_array[], double result_deriv_array[])

   These functions compute arrays of Legendre polynomials
   :math:`P_l(x)` and derivatives :math:`dP_l(x)/dx`
   for :math:`l = 0, \dots, lmax` and :math:`|x| \le 1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_legendre_Q0 (double x)
              int gsl_sf_legendre_Q0_e (double x, gsl_sf_result * result)

   These routines compute the Legendre function :math:`Q_0(x)` for
   :math:`x > -1` and :math:`x \ne 1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_legendre_Q1 (double x)
              int gsl_sf_legendre_Q1_e (double x, gsl_sf_result * result)

   These routines compute the Legendre function :math:`Q_1(x)` for
   :math:`x > -1` and :math:`x \ne 1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_legendre_Ql (int l, double x)
              int gsl_sf_legendre_Ql_e (int l, double x, gsl_sf_result * result)

   These routines compute the Legendre function :math:`Q_l(x)` for
   :math:`x > -1`, :math:`x \ne 1` and :math:`l \ge 0`.
.. Exceptional Return Values: GSL_EDOM

Associated Legendre Polynomials and Spherical Harmonics
-------------------------------------------------------

The following functions compute the associated Legendre polynomials
:math:`P_l^m(x)` which are solutions of the differential equation

.. only:: not texinfo

   .. math:: (1 - x^2) {d^2 \over dx^2} P_l^m(x) - 2x {d \over dx} P_l^m(x) +
             \left( l(l+1) - {m^2 \over 1 - x^2} \right) P_l^m(x) = 0

.. only:: texinfo

   ::

      (1 - x^2) d^2 P_l^m(x) / dx^2 P_l^m(x) - 2x d/dx P_l^m(x) +
      ( l(l+1) - m^2 / (1 - x^2) ) P_l^m(x) = 0

where the degree :math:`l` and order :math:`m` satisfy :math:`0 \le l` and
:math:`0 \le m \le l`.
The functions :math:`P_l^m(x)` grow combinatorially with
:math:`l` and can overflow for :math:`l` larger than about 150.
Alternatively, one may calculate normalized associated Legendre
polynomials. There are a number of different normalization conventions,
and these
functions can be stably computed up to degree and order 2700. The
following normalizations are provided:

* Schmidt semi-normalization

  Schmidt semi-normalized associated Legendre polynomials are often
  used in the magnetics community and are defined as

  .. only:: not texinfo

     .. math::

        S_l^0(x) &= P_l^0(x) \\
        S_l^m(x) &= (-1)^m \sqrt{2 {(l-m)! \over (l+m)!}} P_l^m(x), m > 0 

  .. only:: texinfo

     ::

        S_l^0(x) = P_l^0(x)
        S_l^m(x) = (-1)^m \sqrt((2(l-m)! / (l+m)!)) P_l^m(x), m > 0 

  The factor of :math:`(-1)^m` is called the Condon-Shortley phase
  factor and can be excluded if desired by setting the parameter
  :code:`csphase = 1` in the functions below.

* Spherical Harmonic Normalization

  The associated Legendre polynomials suitable for calculating spherical
  harmonics are defined as

  .. only:: not texinfo

     .. math:: Y_l^m(x) = (-1)^m \sqrt{{2l + 1 \over 4 \pi} {(l-m)! \over (l+m)!}} P_l^m(x)

  .. only:: texinfo

     ::

        Y_l^m(x) = (-1)^m \sqrt((2l + 1) * (l-m)! / (4 \pi) / (l+m)!) P_l^m(x)

  where again the phase factor :math:`(-1)^m` can be included or excluded
  if desired.

* Full Normalization

  The fully normalized associated Legendre polynomials are defined as

  .. only:: not texinfo

     .. math:: N_l^m(x) = (-1)^m \sqrt{(l + {1 \over 2}) {(l-m)! \over (l+m)!}} P_l^m(x)

  .. only:: texinfo
  
     ::
     
        N_l^m(x) = (-1)^m \sqrt((l + 1/2) (l-m)! / (l+m)!) P_l^m(x)

  and have the property

  .. math:: \int_{-1}^1 N_l^m(x)^2 dx = 1

The normalized associated Legendre routines below use a recurrence
relation which is stable up to a degree and order of about 2700.
Beyond this, the computed functions could suffer from underflow
leading to incorrect results. Routines are provided to compute
first and second derivatives
:math:`dP_l^m(x)/dx` and :math:`d^2 P_l^m(x)/dx^2` as well as their alternate
versions :math:`d P_l^m(\cos{\theta})/d\theta` and
:math:`d^2 P_l^m(\cos{\theta})/d\theta^2`. While there is a simple
scaling relationship between the two forms, the derivatives
involving :math:`\theta` are heavily used in spherical harmonic
expansions and so these routines are also provided.

In the functions below, a parameter of type :type:`gsl_sf_legendre_t`
specifies the type of normalization to use. The possible values are

.. type:: gsl_sf_legendre_t

   ================================== ===============================================================================
   Value                              Description
   ================================== ===============================================================================
   :code:`GSL_SF_LEGENDRE_NONE`       The unnormalized associated Legendre polynomials :math:`P_l^m(x)`
   :code:`GSL_SF_LEGENDRE_SCHMIDT`    The Schmidt semi-normalized associated Legendre polynomials :math:`S_l^m(x)`
   :code:`GSL_SF_LEGENDRE_SPHARM`     The spherical harmonic associated Legendre polynomials :math:`Y_l^m(x)`
   :code:`GSL_SF_LEGENDRE_FULL`       The fully normalized associated Legendre polynomials :math:`N_l^m(x)`
   ================================== ===============================================================================

.. function:: int gsl_sf_legendre_array (const gsl_sf_legendre_t norm, const size_t lmax, const double x, double result_array[])
              int gsl_sf_legendre_array_e (const gsl_sf_legendre_t norm, const size_t lmax, const double x, const double csphase, double result_array[])

   These functions calculate all normalized associated Legendre
   polynomials for :math:`0 \le l \le lmax` and
   :math:`0 \le m \le l` for :math:`|x| \le 1`.
   The :data:`norm` parameter specifies which normalization is used.
   The normalized :math:`P_l^m(x)` values are stored in :data:`result_array`, whose
   minimum size can be obtained from calling :func:`gsl_sf_legendre_array_n`.
   The array index of :math:`P_l^m(x)` is obtained from calling
   :code:`gsl_sf_legendre_array_index(l, m)`. To include or exclude
   the Condon-Shortley phase factor of :math:`(-1)^m`, set the parameter
   :data:`csphase` to either :math:`-1` or :math:`1` respectively in the
   :code:`_e` function. This factor is excluded by default.

.. function:: int gsl_sf_legendre_deriv_array (const gsl_sf_legendre_t norm, const size_t lmax, const double x, double result_array[], double result_deriv_array[])
              int gsl_sf_legendre_deriv_array_e (const gsl_sf_legendre_t norm, const size_t lmax, const double x, const double csphase, double result_array[], double result_deriv_array[])

   These functions calculate all normalized associated Legendre
   functions and their first derivatives up to degree :data:`lmax` for
   :math:`|x| < 1`.
   The parameter :data:`norm` specifies the normalization used. The
   normalized :math:`P_l^m(x)` values and their derivatives
   :math:`dP_l^m(x)/dx` are stored in :data:`result_array` and
   :data:`result_deriv_array` respectively.
   To include or exclude
   the Condon-Shortley phase factor of :math:`(-1)^m`, set the parameter
   :data:`csphase` to either :math:`-1` or :math:`1` respectively in the
   :code:`_e` function. This factor is excluded by default.

.. function:: int gsl_sf_legendre_deriv_alt_array (const gsl_sf_legendre_t norm, const size_t lmax, const double x, double result_array[], double result_deriv_array[])
              int gsl_sf_legendre_deriv_alt_array_e (const gsl_sf_legendre_t norm, const size_t lmax, const double x, const double csphase, double result_array[], double result_deriv_array[])

   These functions calculate all normalized associated Legendre
   functions and their (alternate) first derivatives up to degree :data:`lmax` for
   :math:`|x| < 1`.
   The normalized :math:`P_l^m(x)` values and their derivatives
   :math:`dP_l^m(\cos{\theta})/d\theta` are stored in :data:`result_array` and
   :data:`result_deriv_array` respectively.
   To include or exclude
   the Condon-Shortley phase factor of :math:`(-1)^m`, set the parameter
   :data:`csphase` to either :math:`-1` or :math:`1` respectively in the
   :code:`_e` function. This factor is excluded by default.

.. function:: int gsl_sf_legendre_deriv2_array (const gsl_sf_legendre_t norm, const size_t lmax, const double x, double result_array[], double result_deriv_array[], double result_deriv2_array[])
              int gsl_sf_legendre_deriv2_array_e (const gsl_sf_legendre_t norm, const size_t lmax, const double x, const double csphase, double result_array[], double result_deriv_array[], double result_deriv2_array[])

   These functions calculate all normalized associated Legendre
   functions and their first and second derivatives up to degree :data:`lmax` for
   :math:`|x| < 1`.
   The parameter :data:`norm` specifies the normalization used. The
   normalized :math:`P_l^m(x)`, their first derivatives
   :math:`dP_l^m(x)/dx`, and their second derivatives
   :math:`d^2 P_l^m(x)/dx^2` are stored in :data:`result_array`,
   :data:`result_deriv_array`, and :data:`result_deriv2_array` respectively.
   To include or exclude
   the Condon-Shortley phase factor of :math:`(-1)^m`, set the parameter
   :data:`csphase` to either :math:`-1` or :math:`1` respectively in the
   :code:`_e` function. This factor is excluded by default.

.. function:: int gsl_sf_legendre_deriv2_alt_array (const gsl_sf_legendre_t norm, const size_t lmax, const double x, double result_array[], double result_deriv_array[], double result_deriv2_array[])
              int gsl_sf_legendre_deriv2_alt_array_e (const gsl_sf_legendre_t norm, const size_t lmax, const double x, const double csphase, double result_array[], double result_deriv_array[], double result_deriv2_array[])

   These functions calculate all normalized associated Legendre
   functions and their (alternate) first and second derivatives up to degree
   :data:`lmax` for
   :math:`|x| < 1`.
   The parameter :data:`norm` specifies the normalization used. The
   normalized :math:`P_l^m(x)`, their first derivatives
   :math:`dP_l^m(\cos{\theta})/d\theta`, and their second derivatives
   :math:`d^2 P_l^m(\cos{\theta})/d\theta^2` are stored in :data:`result_array`,
   :data:`result_deriv_array`, and :data:`result_deriv2_array` respectively.
   To include or exclude
   the Condon-Shortley phase factor of :math:`(-1)^m`, set the parameter
   :data:`csphase` to either :math:`-1` or :math:`1` respectively in the
   :code:`_e` function. This factor is excluded by default.

.. function:: size_t gsl_sf_legendre_array_n (const size_t lmax)

   This function returns the minimum array size for maximum degree :data:`lmax`
   needed for the array versions of the associated Legendre functions.
   Size is calculated as the total number of :math:`P_l^m(x)` functions,
   plus extra space for precomputing multiplicative factors used in the
   recurrence relations.

.. function:: size_t gsl_sf_legendre_array_index (const size_t l, const size_t m)

   This function returns the index into :data:`result_array`,
   :data:`result_deriv_array`, or :data:`result_deriv2_array` corresponding
   to :math:`P_l^m(x)`, :math:`P_l^{'m}(x)`, or :math:`P_l^{''m}(x)`. The
   index is given by :math:`l(l+1)/2 + m`.

.. function:: double gsl_sf_legendre_Plm (int l, int m, double x)
              int gsl_sf_legendre_Plm_e (int l, int m, double x, gsl_sf_result * result)

   These routines compute the associated Legendre polynomial
   :math:`P_l^m(x)` for :math:`m \ge 0`,
   :math:`l \ge m`, and :math:`|x| \le 1`.
.. Exceptional Return Values: GSL_EDOM, GSL_EOVRFLW

.. function:: double gsl_sf_legendre_sphPlm (int l, int m, double x)
              int gsl_sf_legendre_sphPlm_e (int l, int m, double x, gsl_sf_result * result)

   These routines compute the normalized associated Legendre polynomial
   :math:`\sqrt{(2l+1)/(4\pi)} \sqrt{(l-m)!/(l+m)!} P_l^m(x)` suitable
   for use in spherical harmonics.  The parameters must satisfy :math:`m \ge 0`,
   :math:`l \ge m`, and :math:`|x| \le 1`.
   These routines avoid the overflows
   that occur for the standard normalization of :math:`P_l^m(x)`.
.. Exceptional Return Values: GSL_EDOM

.. function:: int gsl_sf_legendre_Plm_array (int lmax, int m, double x, double result_array[])
              int gsl_sf_legendre_Plm_deriv_array (int lmax, int m, double x, double result_array[], double result_deriv_array[])

   These functions are now deprecated and will be removed in a future
   release; see :func:`gsl_sf_legendre_array` and
   :func:`gsl_sf_legendre_deriv_array`.

.. function:: int gsl_sf_legendre_sphPlm_array (int lmax, int m, double x, double result_array[])
              int gsl_sf_legendre_sphPlm_deriv_array (int lmax, int m, double x, double result_array[], double result_deriv_array[])

   These functions are now deprecated and will be removed in a future
   release; see :func:`gsl_sf_legendre_array` and
   :func:`gsl_sf_legendre_deriv_array`.

.. function:: int gsl_sf_legendre_array_size (const int lmax, const int m)

   This function is now deprecated and will be removed in a future
   release.

Conical Functions
-----------------

The Conical Functions :math:`P^\mu_{-(1/2)+i\lambda}(x)`
and :math:`Q^\mu_{-(1/2)+i\lambda}`
are described in Abramowitz & Stegun, Section 8.12.

.. function:: double gsl_sf_conicalP_half (double lambda, double x)
              int gsl_sf_conicalP_half_e (double lambda, double x, gsl_sf_result * result)

   These routines compute the irregular Spherical Conical Function
   :math:`P^{1/2}_{-1/2 + i \lambda}(x)` for :math:`x > -1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_conicalP_mhalf (double lambda, double x)
              int gsl_sf_conicalP_mhalf_e (double lambda, double x, gsl_sf_result * result)

   These routines compute the regular Spherical Conical Function
   :math:`P^{-1/2}_{-1/2 + i \lambda}(x)` for :math:`x > -1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_conicalP_0 (double lambda, double x)
              int gsl_sf_conicalP_0_e (double lambda, double x, gsl_sf_result * result)

   These routines compute the conical function
   :math:`P^0_{-1/2 + i \lambda}(x)` for :math:`x > -1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_conicalP_1 (double lambda, double x)
              int gsl_sf_conicalP_1_e (double lambda, double x, gsl_sf_result * result)

   These routines compute the conical function 
   :math:`P^1_{-1/2 + i \lambda}(x)` for :math:`x > -1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_conicalP_sph_reg (int l, double lambda, double x)
              int gsl_sf_conicalP_sph_reg_e (int l, double lambda, double x, gsl_sf_result * result)

   These routines compute the Regular Spherical Conical Function
   :math:`P^{-1/2-l}_{-1/2 + i \lambda}(x)`
   for :math:`x > -1` and :math:`l \ge -1`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_conicalP_cyl_reg (int m, double lambda, double x)
              int gsl_sf_conicalP_cyl_reg_e (int m, double lambda, double x, gsl_sf_result * result)

   These routines compute the Regular Cylindrical Conical Function
   :math:`P^{-m}_{-1/2 + i \lambda}(x)`
   for :math:`x > -1` and :math:`m \ge -1`.
.. Exceptional Return Values: GSL_EDOM

Radial Functions for Hyperbolic Space
-------------------------------------

The following spherical functions are specializations of Legendre
functions which give the regular eigenfunctions of the Laplacian on a
3-dimensional hyperbolic space :math:`H^3`.  Of particular interest is
the flat limit, :math:`\lambda \to \infty`, :math:`\eta \to 0`,
:math:`\lambda\eta` fixed.
  
.. function:: double gsl_sf_legendre_H3d_0 (double lambda, double eta)
              int gsl_sf_legendre_H3d_0_e (double lambda, double eta, gsl_sf_result * result)

   These routines compute the zeroth radial eigenfunction of the Laplacian on the
   3-dimensional hyperbolic space,

   .. math:: L^{H3d}_0(\lambda,\eta) := {\sin(\lambda\eta) \over \lambda\sinh(\eta)}

   for :math:`\eta \ge 0`.
   In the flat limit this takes the form
   :math:`L^{H3d}_0(\lambda,\eta) = j_0(\lambda\eta)`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_legendre_H3d_1 (double lambda, double eta)
              int gsl_sf_legendre_H3d_1_e (double lambda, double eta, gsl_sf_result * result)

   These routines compute the first radial eigenfunction of the Laplacian on
   the 3-dimensional hyperbolic space,

   .. math:: L^{H3d}_1(\lambda,\eta) := {1\over\sqrt{\lambda^2 + 1}} {\left(\sin(\lambda \eta)\over \lambda \sinh(\eta)\right)} \left(\coth(\eta) - \lambda \cot(\lambda\eta)\right)

   for :math:`\eta \ge 0`
   In the flat limit this takes the form 
   :math:`L^{H3d}_1(\lambda,\eta) = j_1(\lambda\eta)`.
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_legendre_H3d (int l, double lambda, double eta)
              int gsl_sf_legendre_H3d_e (int l, double lambda, double eta, gsl_sf_result * result)

   These routines compute the :data:`l`-th radial eigenfunction of the
   Laplacian on the 3-dimensional hyperbolic space :math:`\eta \ge 0` and
   :math:`l \ge 0`.
   In the flat limit this takes the form
   :math:`L^{H3d}_l(\lambda,\eta) = j_l(\lambda\eta)`.
.. Exceptional Return Values: GSL_EDOM

.. function:: int gsl_sf_legendre_H3d_array (int lmax, double lambda, double eta, double result_array[])

   This function computes an array of radial eigenfunctions
   :math:`L^{H3d}_l( \lambda, \eta)`
   for :math:`0 \le l \le lmax`.
.. Exceptional Return Values:
.. index::
   single: minimization, multidimensional

*****************************
Multidimensional Minimization
*****************************

This chapter describes routines for finding minima of arbitrary
multidimensional functions.  The library provides low level components
for a variety of iterative minimizers and convergence tests.  These can
be combined by the user to achieve the desired solution, while providing
full access to the intermediate steps of the algorithms.  Each class of
methods uses the same framework, so that you can switch between
minimizers at runtime without needing to recompile your program.  Each
instance of a minimizer keeps track of its own state, allowing the
minimizers to be used in multi-threaded programs. The minimization
algorithms can be used to maximize a function by inverting its sign.

The header file :file:`gsl_multimin.h` contains prototypes for the
minimization functions and related declarations.  

Overview
========

The problem of multidimensional minimization requires finding a point
:math:`x` such that the scalar function,

.. math:: f(x_1, \dots, x_n)

takes a value which is lower than at any neighboring point. For smooth
functions the gradient :math:`g = \nabla f` vanishes at the minimum. In
general there are no bracketing methods available for the
minimization of :math:`n`-dimensional functions.  The algorithms
proceed from an initial guess using a search algorithm which attempts
to move in a downhill direction. 

Algorithms making use of the gradient of the function perform a
one-dimensional line minimisation along this direction until the lowest
point is found to a suitable tolerance.  The search direction is then
updated with local information from the function and its derivatives,
and the whole process repeated until the true :math:`n`-dimensional
minimum is found.

Algorithms which do not require the gradient of the function use
different strategies.  For example, the Nelder-Mead Simplex algorithm
maintains :math:`n+1` trial parameter vectors as the vertices of a
:math:`n`-dimensional simplex.  On each iteration it tries to improve
the worst vertex of the simplex by geometrical transformations.  The
iterations are continued until the overall size of the simplex has
decreased sufficiently.

Both types of algorithms use a standard framework. The user provides a
high-level driver for the algorithms, and the library provides the
individual functions necessary for each of the steps.  There are three
main phases of the iteration.  The steps are,

* initialize minimizer state, :data:`s`, for algorithm :data:`T`
* update :data:`s` using the iteration :data:`T`
* test :data:`s` for convergence, and repeat iteration if necessary

Each iteration step consists either of an improvement to the
line-minimisation in the current direction or an update to the search
direction itself.  The state for the minimizers is held in a
:type:`gsl_multimin_fdfminimizer` struct or a
:type:`gsl_multimin_fminimizer` struct.

.. index::
   single: Multimin, caveats

Caveats
=======

Note that the minimization algorithms can only search for one local
minimum at a time.  When there are several local minima in the search
area, the first minimum to be found will be returned; however it is
difficult to predict which of the minima this will be.  In most cases,
no error will be reported if you try to find a local minimum in an area
where there is more than one.

It is also important to note that the minimization algorithms find local
minima; there is no way to determine whether a minimum is a global
minimum of the function in question.

Initializing the Multidimensional Minimizer
===========================================

The following function initializes a multidimensional minimizer.  The
minimizer itself depends only on the dimension of the problem and the
algorithm and can be reused for different problems.

.. type:: gsl_multimin_fdfminimizer

   This is a workspace for minimizing functions using derivatives.

.. type:: gsl_multimin_fminimizer

   This is a workspace for minimizing functions without derivatives.

.. function:: gsl_multimin_fdfminimizer * gsl_multimin_fdfminimizer_alloc (const gsl_multimin_fdfminimizer_type * T, size_t n)
              gsl_multimin_fminimizer * gsl_multimin_fminimizer_alloc (const gsl_multimin_fminimizer_type * T, size_t n)

   This function returns a pointer to a newly allocated instance of a
   minimizer of type :data:`T` for an :data:`n`-dimension function.  If there
   is insufficient memory to create the minimizer then the function returns
   a null pointer and the error handler is invoked with an error code of
   :macro:`GSL_ENOMEM`.

.. function:: int gsl_multimin_fdfminimizer_set (gsl_multimin_fdfminimizer * s, gsl_multimin_function_fdf * fdf, const gsl_vector * x, double step_size, double tol)
              int gsl_multimin_fminimizer_set (gsl_multimin_fminimizer * s, gsl_multimin_function * f, const gsl_vector * x, const gsl_vector * step_size)

   The function :func:`gsl_multimin_fdfminimizer_set` initializes the minimizer :data:`s` to minimize the function
   :data:`fdf` starting from the initial point :data:`x`.  The size of the
   first trial step is given by :data:`step_size`.  The accuracy of the line
   minimization is specified by :data:`tol`.  The precise meaning of this
   parameter depends on the method used.  Typically the line minimization
   is considered successful if the gradient of the function :math:`g` is
   orthogonal to the current search direction :math:`p` to a relative
   accuracy of :data:`tol`, where :math:`p \cdot g < tol |p| |g|`.
   A :data:`tol` value of 0.1 is 
   suitable for most purposes, since line minimization only needs to
   be carried out approximately.    Note that setting :data:`tol` to zero will
   force the use of "exact" line-searches, which are extremely expensive.

   The function :func:`gsl_multimin_fminimizer_set` initializes the minimizer :data:`s` to minimize the function
   :data:`f`, starting from the initial point
   :data:`x`. The size of the initial trial steps is given in vector
   :data:`step_size`. The precise meaning of this parameter depends on the
   method used. 

.. function:: void gsl_multimin_fdfminimizer_free (gsl_multimin_fdfminimizer * s)
              void gsl_multimin_fminimizer_free (gsl_multimin_fminimizer * s)

   This function frees all the memory associated with the minimizer
   :data:`s`.

.. function:: const char * gsl_multimin_fdfminimizer_name (const gsl_multimin_fdfminimizer * s)
              const char * gsl_multimin_fminimizer_name (const gsl_multimin_fminimizer * s)

   This function returns a pointer to the name of the minimizer.  For example::

      printf ("s is a '%s' minimizer\n", gsl_multimin_fdfminimizer_name (s));

   would print something like :code:`s is a 'conjugate_pr' minimizer`.

Providing a function to minimize
================================

You must provide a parametric function of :math:`n` variables for the
minimizers to operate on.  You may also need to provide a routine which
calculates the gradient of the function and a third routine which
calculates both the function value and the gradient together.  In order
to allow for general parameters the functions are defined by the
following data types:

.. type:: gsl_multimin_function_fdf

   This data type defines a general function of :math:`n` variables with
   parameters and the corresponding gradient vector of derivatives,

   :code:`double (* f) (const gsl_vector * x, void * params)`

      this function should return the result
      :math:`f(x,params)` for argument :data:`x` and parameters :data:`params`.
      If the function cannot be computed, an error value of :macro:`GSL_NAN`
      should be returned.

   :code:`void (* df) (const gsl_vector * x, void * params, gsl_vector * g)`

      this function should store the :data:`n`-dimensional gradient

      .. only:: not texinfo

         .. math:: g_i = \partial f(x,\hbox{\it params}) / \partial x_i

      .. only:: texinfo

         ::

            g_i = d f(x,params) / d x_i
            
      in the vector :data:`g` for argument :data:`x` 
      and parameters :data:`params`, returning an appropriate error code if the
      function cannot be computed.

   :code:`void (* fdf) (const gsl_vector * x, void * params, double * f, gsl_vector * g)`

      This function should set the values of the :data:`f` and :data:`g` as above,
      for arguments :data:`x` and parameters :data:`params`.  This function
      provides an optimization of the separate functions for :math:`f(x)` and
      :math:`g(x)`---it is always faster to compute the function and its
      derivative at the same time.

   :code:`size_t n`

      the dimension of the system, i.e. the number of components of the
      vectors :data:`x`.

   :code:`void * params`

      a pointer to the parameters of the function.

.. type:: gsl_multimin_function

   This data type defines a general function of :math:`n` variables with
   parameters,

   :code:`double (* f) (const gsl_vector * x, void * params)`

      this function should return the result
      :math:`f(x,params)` for argument :data:`x` and parameters :data:`params`.
      If the function cannot be computed, an error value of :macro:`GSL_NAN`
      should be returned.

   :code:`size_t n`

      the dimension of the system, i.e. the number of components of the
      vectors :data:`x`.

   :code:`void * params`

      a pointer to the parameters of the function.

.. _multimin-paraboloid:

The following example function defines a simple two-dimensional
paraboloid with five parameters,

.. include:: examples/multiminfn.c
   :code:

The function can be initialized using the following code::

  gsl_multimin_function_fdf my_func;

  /* Paraboloid center at (1,2), scale factors (10, 20), 
     minimum value 30 */
  double p[5] = { 1.0, 2.0, 10.0, 20.0, 30.0 }; 

  my_func.n = 2;  /* number of function components */
  my_func.f = &my_f;
  my_func.df = &my_df;
  my_func.fdf = &my_fdf;
  my_func.params = (void *)p;

Iteration
=========

The following function drives the iteration of each algorithm.  The
function performs one iteration to update the state of the minimizer.
The same function works for all minimizers so that different methods can
be substituted at runtime without modifications to the code.

.. function:: int gsl_multimin_fdfminimizer_iterate (gsl_multimin_fdfminimizer * s)
              int gsl_multimin_fminimizer_iterate (gsl_multimin_fminimizer * s)

   These functions perform a single iteration of the minimizer :data:`s`.
   If the iteration encounters an unexpected problem then an error code
   will be returned.  The error code :macro:`GSL_ENOPROG` signifies that
   the minimizer is unable to improve on its current estimate, either due
   to numerical difficulty or because a genuine local minimum has been
   reached.

The minimizer maintains a current best estimate of the minimum at all
times.  This information can be accessed with the following auxiliary
functions,

.. function:: gsl_vector * gsl_multimin_fdfminimizer_x (const gsl_multimin_fdfminimizer * s)
              gsl_vector * gsl_multimin_fminimizer_x (const gsl_multimin_fminimizer * s)
              double gsl_multimin_fdfminimizer_minimum (const gsl_multimin_fdfminimizer * s)
              double gsl_multimin_fminimizer_minimum (const gsl_multimin_fminimizer * s)
              gsl_vector * gsl_multimin_fdfminimizer_gradient (const gsl_multimin_fdfminimizer * s)
              gsl_vector * gsl_multimin_fdfminimizer_dx (const gsl_multimin_fdfminimizer * s)
              double gsl_multimin_fminimizer_size (const gsl_multimin_fminimizer * s)

   These functions return the current best estimate of the location of the
   minimum, the value of the function at that point, its gradient, the last
   step increment of the estimate, and minimizer specific characteristic size for the minimizer :data:`s`.

.. function:: int gsl_multimin_fdfminimizer_restart (gsl_multimin_fdfminimizer * s)

   This function resets the minimizer :data:`s` to use the current point as a
   new starting point.

Stopping Criteria
=================

A minimization procedure should stop when one of the following
conditions is true:

* A minimum has been found to within the user-specified precision.
* A user-specified maximum number of iterations has been reached.
* An error has occurred.

The handling of these conditions is under user control.  The functions
below allow the user to test the precision of the current result.

.. function:: int gsl_multimin_test_gradient (const gsl_vector * g, double epsabs)

   This function tests the norm of the gradient :data:`g` against the
   absolute tolerance :data:`epsabs`. The gradient of a multidimensional
   function goes to zero at a minimum. The test returns :macro:`GSL_SUCCESS`
   if the following condition is achieved,

   .. only:: not texinfo

      .. math:: |g| < \hbox{\it epsabs}

   .. only:: texinfo

      ::

         |g| < epsabs

   and returns :macro:`GSL_CONTINUE` otherwise.  A suitable choice of
   :data:`epsabs` can be made from the desired accuracy in the function for
   small variations in :math:`x`.  The relationship between these quantities
   is given by :math:`\delta{f} = g\,\delta{x}`.

.. function:: int gsl_multimin_test_size (const double size, double epsabs)

   This function tests the minimizer specific characteristic
   size (if applicable to the used minimizer) against absolute tolerance :data:`epsabs`. 
   The test returns :macro:`GSL_SUCCESS` if the size is smaller than tolerance,
   otherwise :macro:`GSL_CONTINUE` is returned.

Algorithms with Derivatives
===========================

There are several minimization methods available. The best choice of
algorithm depends on the problem.  The algorithms described in this
section use the value of the function and its gradient at each
evaluation point.

.. type:: gsl_multimin_fdfminimizer_type

   This type specifies a minimization algorithm using gradients.

   .. index::
      single: Fletcher-Reeves conjugate gradient algorithm, minimization
      single: Conjugate gradient algorithm, minimization
      single: minimization, conjugate gradient algorithm

   .. var:: gsl_multimin_fdfminimizer_conjugate_fr

      This is the Fletcher-Reeves conjugate gradient algorithm. The conjugate
      gradient algorithm proceeds as a succession of line minimizations. The
      sequence of search directions is used to build up an approximation to the
      curvature of the function in the neighborhood of the minimum.  

      An initial search direction :data:`p` is chosen using the gradient, and line
      minimization is carried out in that direction.  The accuracy of the line
      minimization is specified by the parameter :data:`tol`.  The minimum
      along this line occurs when the function gradient :data:`g` and the search direction
      :data:`p` are orthogonal.  The line minimization terminates when
      :math:`p\cdot g < tol |p| |g|`. The
      search direction is updated  using the Fletcher-Reeves formula
      :math:`p' = g' - \beta g` where :math:`\beta=-|g'|^2/|g|^2`, and
      the line minimization is then repeated for the new search
      direction.

   .. index::
      single: Polak-Ribiere algorithm, minimization
      single: minimization, Polak-Ribiere algorithm

   .. var:: gsl_multimin_fdfminimizer_conjugate_pr

      This is the Polak-Ribiere conjugate gradient algorithm.  It is similar
      to the Fletcher-Reeves method, differing only in the choice of the
      coefficient :math:`\beta`. Both methods work well when the evaluation
      point is close enough to the minimum of the objective function that it
      is well approximated by a quadratic hypersurface.

   .. index::
      single: BFGS algorithm, minimization
      single: minimization, BFGS algorithm

   .. var:: gsl_multimin_fdfminimizer_vector_bfgs2
            gsl_multimin_fdfminimizer_vector_bfgs

      These methods use the vector Broyden-Fletcher-Goldfarb-Shanno (BFGS)
      algorithm.  This is a quasi-Newton method which builds up an approximation
      to the second derivatives of the function :math:`f` using the difference
      between successive gradient vectors.  By combining the first and second
      derivatives the algorithm is able to take Newton-type steps towards the
      function minimum, assuming quadratic behavior in that region.

      The :code:`bfgs2` version of this minimizer is the most efficient
      version available, and is a faithful implementation of the line
      minimization scheme described in Fletcher's *Practical Methods of
      Optimization*, Algorithms 2.6.2 and 2.6.4.  It supersedes the original
      :code:`bfgs` routine and requires substantially fewer function and
      gradient evaluations.  The user-supplied tolerance :data:`tol`
      corresponds to the parameter :math:`\sigma` used by Fletcher.  A value
      of 0.1 is recommended for typical use (larger values correspond to
      less accurate line searches).

   .. index::
      single: steepest descent algorithm, minimization
      single: minimization, steepest descent algorithm

   .. var:: gsl_multimin_fdfminimizer_steepest_descent

      The steepest descent algorithm follows the downhill gradient of the
      function at each step. When a downhill step is successful the step-size
      is increased by a factor of two.  If the downhill step leads to a higher
      function value then the algorithm backtracks and the step size is
      decreased using the parameter :data:`tol`.  A suitable value of :data:`tol`
      for most applications is 0.1.  The steepest descent method is
      inefficient and is included only for demonstration purposes.

Algorithms without Derivatives
==============================

The algorithms described in this section use only the value of the function
at each evaluation point.

.. type:: gsl_multimin_fminimizer_type

   This type specifies minimization algorithms which do not use gradients.

   .. index::
      single: Nelder-Mead simplex algorithm for minimization
      single: simplex algorithm, minimization
      single: minimization, simplex algorithm

   .. var:: gsl_multimin_fminimizer_nmsimplex2
            gsl_multimin_fminimizer_nmsimplex

      These methods use the Simplex algorithm of Nelder and Mead. 
      Starting from the initial vector :math:`x = p_0`, the algorithm
      constructs an additional :math:`n` vectors :math:`p_i`
      using the step size vector :math:`s = step\_size`
      as follows:

      .. only:: not texinfo

         .. math::

            p_0 & = (x_0, x_1, \cdots , x_n) \\
            p_1 & = (x_0 + s_0, x_1, \cdots , x_n) \\
            p_2 & = (x_0, x_1 + s_1, \cdots , x_n) \\
            \dots &= \dots \\
            p_n & = (x_0, x_1, \cdots , x_n + s_n)

      .. only:: texinfo

         ::

            p_0 = (x_0, x_1, ... , x_n) 
            p_1 = (x_0 + s_0, x_1, ... , x_n) 
            p_2 = (x_0, x_1 + s_1, ... , x_n) 
            ... = ...
            p_n = (x_0, x_1, ... , x_n + s_n)

      These vectors form the :math:`n+1` vertices of a simplex in :math:`n`
      dimensions.  On each iteration the algorithm uses simple geometrical
      transformations to update the vector corresponding to the highest
      function value.  The geometric transformations are reflection,
      reflection followed by expansion, contraction and multiple
      contraction.  Using these transformations the simplex moves through
      the space towards the minimum, where it contracts itself.

      After each iteration, the best vertex is returned.  Note, that due to
      the nature of the algorithm not every step improves the current
      best parameter vector.  Usually several iterations are required.

      The minimizer-specific characteristic size is calculated as the
      average distance from the geometrical center of the simplex to all its
      vertices.  This size can be used as a stopping criteria, as the
      simplex contracts itself near the minimum. The size is returned by the
      function :func:`gsl_multimin_fminimizer_size`.

      The :type:`gsl_multimin_fminimizer_nmsimplex2` version of this minimiser is
      a new :math:`O(N)` operations
      implementation of the earlier :math:`O(N^2)` operations
      :type:`gsl_multimin_fminimizer_nmsimplex`
      minimiser.  It uses the same underlying algorithm, but the simplex
      updates are computed more efficiently for high-dimensional problems.
      In addition, the size of simplex is calculated as the RMS
      distance of each vertex from the center rather than the mean distance,
      allowing a linear update of this quantity on each step.  The memory usage is
      :math:`O(N^2)` for both algorithms.

   .. var:: gsl_multimin_fminimizer_nmsimplex2rand

      This method is a variant of :type:`gsl_multimin_fminimizer_nmsimplex2` which initialises the
      simplex around the starting point :data:`x` using a randomly-oriented
      set of basis vectors instead of the fixed coordinate axes. The
      final dimensions of the simplex are scaled along the coordinate axes by the
      vector :data:`step_size`.  The randomisation uses a simple deterministic
      generator so that repeated calls to :func:`gsl_multimin_fminimizer_set` for
      a given solver object will vary the orientation in a well-defined way.

Examples
========

This example program finds the minimum of the :ref:`paraboloid function <multimin-paraboloid>`
defined earlier.  The location of the minimum is offset from the origin
in :math:`x` and :math:`y`, and the function value at the minimum is
non-zero. The main program is given below, it requires the example
function given earlier in this chapter.

.. include:: examples/multimin.c
   :code:

The initial step-size is chosen as 0.01, a conservative estimate in this
case, and the line minimization parameter is set at 0.0001.  The program
terminates when the norm of the gradient has been reduced below
0.001. The output of the program is shown below,

.. include:: examples/multimin.txt
   :code:

Note that the algorithm gradually increases the step size as it
successfully moves downhill, as can be seen by plotting the successive
points in :numref:`fig-multimin`.

.. _fig-multimin:

.. figure:: /images/multimin.png
   :scale: 60%

   Function contours with path taken by minimization algorithm

The conjugate gradient algorithm finds the minimum on its second
direction because the function is purely quadratic. Additional
iterations would be needed for a more complicated function.

Here is another example using the Nelder-Mead Simplex algorithm to
minimize the same example object function, as above.

.. include:: examples/nmsimplex.c
   :code:

The minimum search stops when the Simplex size drops to 0.01. The output is
shown below.

.. include:: examples/nmsimplex.txt
   :code:

The simplex size first increases, while the simplex moves towards the
minimum. After a while the size begins to decrease as the simplex
contracts around the minimum.

References and Further Reading
==============================

The conjugate gradient and BFGS methods are described in detail in the
following book,

* R. Fletcher,
  *Practical Methods of Optimization (Second Edition)* Wiley
  (1987), ISBN 0471915475.

A brief description of multidimensional minimization algorithms and
more recent references can be found in,

* C.W. Ueberhuber,
  *Numerical Computation (Volume 2)*, Chapter 14, Section 4.4
  "Minimization Methods", p.: 325--335, Springer (1997), ISBN
  3-540-62057-5.

The simplex algorithm is described in the following paper, 

* J.A. Nelder and R. Mead,
  *A simplex method for function minimization*, Computer Journal
  vol.: 7 (1965), 308--313.
.. index::
   single: statistics
   single: mean
   single: standard deviation
   single: variance
   single: estimated standard deviation
   single: estimated variance
   single: t-test
   single: range
   single: min
   single: max

**********
Statistics
**********

This chapter describes the statistical functions in the library.  The
basic statistical functions include routines to compute the mean,
variance and standard deviation.  More advanced functions allow you to
calculate absolute deviations, skewness, and kurtosis as well as the
median and arbitrary percentiles.  The algorithms use recurrence
relations to compute average quantities in a stable way, without large
intermediate values that might overflow. 

The functions are available in versions for datasets in the standard
floating-point and integer types.  The versions for double precision
floating-point data have the prefix :code:`gsl_stats` and are declared in
the header file :file:`gsl_statistics_double.h`.  The versions for integer
data have the prefix :code:`gsl_stats_int` and are declared in the header
file :file:`gsl_statistics_int.h`.   All the functions operate on C 
arrays with a :code:`stride` parameter specifying the spacing between 
elements.  

Mean, Standard Deviation and Variance
=====================================

.. function:: double gsl_stats_mean (const double data[], size_t stride, size_t n)

   This function returns the arithmetic mean of :data:`data`, a dataset of
   length :data:`n` with stride :data:`stride`.  The arithmetic mean, or
   *sample mean*, is denoted by :math:`\Hat\mu` and defined as,

   .. math:: \Hat\mu = {1 \over N} \sum x_i

   where :math:`x_i` are the elements of the dataset :data:`data`.  For
   samples drawn from a gaussian distribution the variance of
   :math:`\Hat\mu` is :math:`\sigma^2 / N`.

.. function:: double gsl_stats_variance (const double data[], size_t stride, size_t n)

   This function returns the estimated, or *sample*, variance of
   :data:`data`, a dataset of length :data:`n` with stride :data:`stride`.  The
   estimated variance is denoted by :math:`\Hat\sigma^2` and is defined by,

   .. only:: not texinfo

      .. math:: {\Hat\sigma}^2 = {1 \over (N-1)} \sum (x_i - {\Hat\mu})^2

   .. only:: texinfo

      ::

         \Hat\sigma^2 = (1/(N-1)) \sum (x_i - \Hat\mu)^2

   where :math:`x_i` are the elements of the dataset :data:`data`.  Note that
   the normalization factor of :math:`1/(N-1)` results from the derivation
   of :math:`\Hat\sigma^2` as an unbiased estimator of the population
   variance :math:`\sigma^2`.  For samples drawn from a Gaussian distribution
   the variance of :math:`\Hat\sigma^2` itself is :math:`2 \sigma^4 / N`.

   This function computes the mean via a call to :func:`gsl_stats_mean`.  If
   you have already computed the mean then you can pass it directly to
   :func:`gsl_stats_variance_m`.

.. function:: double gsl_stats_variance_m (const double data[], size_t stride, size_t n, double mean)

   This function returns the sample variance of :data:`data` relative to the
   given value of :data:`mean`.  The function is computed with :math:`\Hat\mu`
   replaced by the value of :data:`mean` that you supply,

   .. only:: not texinfo

      .. math:: {\Hat\sigma}^2 = {1 \over (N-1)} \sum (x_i - mean)^2

   .. only:: texinfo

      ::

         \Hat\sigma^2 = (1/(N-1)) \sum (x_i - mean)^2

.. function:: double gsl_stats_sd (const double data[], size_t stride, size_t n)
              double gsl_stats_sd_m (const double data[], size_t stride, size_t n, double mean)

   The standard deviation is defined as the square root of the variance.
   These functions return the square root of the corresponding variance
   functions above.

.. function:: double gsl_stats_tss (const double data[], size_t stride, size_t n)
              double gsl_stats_tss_m (const double data[], size_t stride, size_t n, double mean)

   These functions return the total sum of squares (TSS) of :data:`data` about
   the mean.  For :func:`gsl_stats_tss_m` the user-supplied value of
   :data:`mean` is used, and for :func:`gsl_stats_tss` it is computed using
   :func:`gsl_stats_mean`.

   .. only:: not texinfo

      .. math:: {\rm TSS} = \sum (x_i - mean)^2

   .. only:: texinfo

      ::

         TSS =  \sum (x_i - mean)^2

.. function:: double gsl_stats_variance_with_fixed_mean (const double data[], size_t stride, size_t n, double mean)

   This function computes an unbiased estimate of the variance of
   :data:`data` when the population mean :data:`mean` of the underlying
   distribution is known *a priori*.  In this case the estimator for
   the variance uses the factor :math:`1/N` and the sample mean
   :math:`\Hat\mu` is replaced by the known population mean :math:`\mu`,

   .. only:: not texinfo

      .. math:: {\Hat\sigma}^2 = {1 \over N} \sum (x_i - \mu)^2

   .. only:: texinfo

      ::

         \Hat\sigma^2 = (1/N) \sum (x_i - \mu)^2

.. function:: double gsl_stats_sd_with_fixed_mean (const double data[], size_t stride, size_t n, double mean)

   This function calculates the standard deviation of :data:`data` for a
   fixed population mean :data:`mean`.  The result is the square root of the
   corresponding variance function.

Absolute deviation
==================

.. function:: double gsl_stats_absdev (const double data[], size_t stride, size_t n)

   This function computes the absolute deviation from the mean of
   :data:`data`, a dataset of length :data:`n` with stride :data:`stride`.  The
   absolute deviation from the mean is defined as,

   .. only:: not texinfo

      .. math:: absdev  = {1 \over N} \sum |x_i - {\Hat\mu}|

   .. only:: texinfo

      ::

         absdev  = (1/N) \sum |x_i - \Hat\mu|

   where :math:`x_i` are the elements of the dataset :data:`data`.  The
   absolute deviation from the mean provides a more robust measure of the
   width of a distribution than the variance.  This function computes the
   mean of :data:`data` via a call to :func:`gsl_stats_mean`.

.. function:: double gsl_stats_absdev_m (const double data[], size_t stride, size_t n, double mean)

   This function computes the absolute deviation of the dataset :data:`data`
   relative to the given value of :data:`mean`,

   .. only:: not texinfo

      .. math:: absdev  = {1 \over N} \sum |x_i - mean|

   .. only:: texinfo

      ::

         absdev  = (1/N) \sum |x_i - mean|

   This function is useful if you have already computed the mean of
   :data:`data` (and want to avoid recomputing it), or wish to calculate the
   absolute deviation relative to another value (such as zero, or the
   median).

.. index:: skewness, kurtosis

Higher moments (skewness and kurtosis)
======================================

.. function:: double gsl_stats_skew (const double data[], size_t stride, size_t n)

   This function computes the skewness of :data:`data`, a dataset of length
   :data:`n` with stride :data:`stride`.  The skewness is defined as,

   .. only:: not texinfo

      .. math::

         skew = {1 \over N} \sum 
          {\left( x_i - {\Hat\mu} \over {\Hat\sigma} \right)}^3

   .. only:: texinfo

      ::

         skew = (1/N) \sum ((x_i - \Hat\mu)/\Hat\sigma)^3

   where :math:`x_i` are the elements of the dataset :data:`data`.  The skewness
   measures the asymmetry of the tails of a distribution.

   The function computes the mean and estimated standard deviation of
   :data:`data` via calls to :func:`gsl_stats_mean` and :func:`gsl_stats_sd`.

.. function:: double gsl_stats_skew_m_sd (const double data[], size_t stride, size_t n, double mean, double sd)

   This function computes the skewness of the dataset :data:`data` using the
   given values of the mean :data:`mean` and standard deviation :data:`sd`,

   .. only:: not texinfo

      .. math:: skew = {1 \over N} \sum {\left( x_i - mean \over sd \right)}^3

   .. only:: texinfo

      ::

         skew = (1/N) \sum ((x_i - mean)/sd)^3

   These functions are useful if you have already computed the mean and
   standard deviation of :data:`data` and want to avoid recomputing them.

.. function:: double gsl_stats_kurtosis (const double data[], size_t stride, size_t n)

   This function computes the kurtosis of :data:`data`, a dataset of length
   :data:`n` with stride :data:`stride`.  The kurtosis is defined as,

   .. only:: not texinfo

      .. math::

         kurtosis = \left( {1 \over N} \sum 
          {\left(x_i - {\Hat\mu} \over {\Hat\sigma} \right)}^4 
          \right) 
          - 3

   .. only:: texinfo

      ::

         kurtosis = ((1/N) \sum ((x_i - \Hat\mu)/\Hat\sigma)^4)  - 3

   The kurtosis measures how sharply peaked a distribution is, relative to
   its width.  The kurtosis is normalized to zero for a Gaussian
   distribution.

.. function:: double gsl_stats_kurtosis_m_sd (const double data[], size_t stride, size_t n, double mean, double sd)

   This function computes the kurtosis of the dataset :data:`data` using the
   given values of the mean :data:`mean` and standard deviation :data:`sd`,

   .. only:: not texinfo

      .. math::

         kurtosis = {1 \over N}
           \left( \sum {\left(x_i - mean \over sd \right)}^4 \right) 
           - 3

   .. only:: texinfo

      ::

         kurtosis = ((1/N) \sum ((x_i - mean)/sd)^4) - 3

   This function is useful if you have already computed the mean and
   standard deviation of :data:`data` and want to avoid recomputing them.

Autocorrelation
===============

.. function:: double gsl_stats_lag1_autocorrelation (const double data[], const size_t stride, const size_t n)

   This function computes the lag-1 autocorrelation of the dataset :data:`data`.

   .. only:: not texinfo

      .. math::

         a_1 = {\sum_{i = 2}^{n} (x_{i} - \Hat\mu) (x_{i-1} - \Hat\mu)
         \over
         \sum_{i = 1}^{n} (x_{i} - \Hat\mu) (x_{i} - \Hat\mu)}

   .. only:: texinfo

      ::

         a_1 = {\sum_{i = 2}^{n} (x_{i} - \Hat\mu) (x_{i-1} - \Hat\mu)
                \over
                \sum_{i = 1}^{n} (x_{i} - \Hat\mu) (x_{i} - \Hat\mu)}

.. function:: double gsl_stats_lag1_autocorrelation_m (const double data[], const size_t stride, const size_t n, const double mean)

   This function computes the lag-1 autocorrelation of the dataset
   :data:`data` using the given value of the mean :data:`mean`.

.. index::
   single: covariance, of two datasets

Covariance
==========

.. function:: double gsl_stats_covariance (const double data1[], const size_t stride1, const double data2[], const size_t stride2, const size_t n)

   This function computes the covariance of the datasets :data:`data1` and
   :data:`data2` which must both be of the same length :data:`n`.

   .. only:: not texinfo

      .. math:: covar = {1 \over (n - 1)} \sum_{i = 1}^{n} (x_{i} - \Hat x) (y_{i} - \Hat y)

   .. only:: texinfo

      ::

         covar = (1/(n - 1)) \sum_{i = 1}^{n} (x_i - \Hat x) (y_i - \Hat y)

.. function:: double gsl_stats_covariance_m (const double data1[], const size_t stride1, const double data2[], const size_t stride2, const size_t n, const double mean1, const double mean2)

   This function computes the covariance of the datasets :data:`data1` and
   :data:`data2` using the given values of the means, :data:`mean1` and
   :data:`mean2`.  This is useful if you have already computed the means of
   :data:`data1` and :data:`data2` and want to avoid recomputing them.

.. index::
   single: correlation, of two datasets

Correlation
===========

.. function:: double gsl_stats_correlation (const double data1[], const size_t stride1, const double data2[], const size_t stride2, const size_t n)

   This function efficiently computes the Pearson correlation coefficient
   between the datasets :data:`data1` and :data:`data2` which must both be of
   the same length :data:`n`.

   .. only:: not texinfo

      .. math::

         r = {cov(x, y) \over \Hat\sigma_x \Hat\sigma_y} =
         {{1 \over n-1} \sum (x_i - \Hat x) (y_i - \Hat y)
         \over
         \sqrt{{1 \over n-1} \sum (x_i - {\Hat x})^2}
         \sqrt{{1 \over n-1} \sum (y_i - {\Hat y})^2}
         }

   .. only:: texinfo

      ::

         r = cov(x, y) / (\Hat\sigma_x \Hat\sigma_y)
           = {1/(n-1) \sum (x_i - \Hat x) (y_i - \Hat y)
              \over
              \sqrt{1/(n-1) \sum (x_i - \Hat x)^2} \sqrt{1/(n-1) \sum (y_i - \Hat y)^2}
             }

.. function:: double gsl_stats_spearman (const double data1[], const size_t stride1, const double data2[], const size_t stride2, const size_t n, double work[])

   This function computes the Spearman rank correlation coefficient between
   the datasets :data:`data1` and :data:`data2` which must both be of the same
   length :data:`n`. Additional workspace of size 2 * :data:`n` is required in
   :data:`work`. The Spearman rank correlation between vectors :math:`x` and
   :math:`y` is equivalent to the Pearson correlation between the ranked
   vectors :math:`x_R` and :math:`y_R`, where ranks are defined to be the
   average of the positions of an element in the ascending order of the values.

Weighted Samples
================

The functions described in this section allow the computation of
statistics for weighted samples.  The functions accept an array of
samples, :math:`x_i`, with associated weights, :math:`w_i`.  Each sample
:math:`x_i` is considered as having been drawn from a Gaussian
distribution with variance :math:`\sigma_i^2`.  The sample weight
:math:`w_i` is defined as the reciprocal of this variance, :math:`w_i = 1/\sigma_i^2`.
Setting a weight to zero corresponds to removing a sample from a dataset.

.. function:: double gsl_stats_wmean (const double w[], size_t wstride, const double data[], size_t stride, size_t n)

   This function returns the weighted mean of the dataset :data:`data` with
   stride :data:`stride` and length :data:`n`, using the set of weights :data:`w`
   with stride :data:`wstride` and length :data:`n`.  The weighted mean is defined as,

   .. only:: not texinfo

      .. math:: {\Hat\mu} = {{\sum w_i x_i} \over {\sum w_i}}

   .. only:: texinfo

      ::

         \Hat\mu = (\sum w_i x_i) / (\sum w_i)

.. function:: double gsl_stats_wvariance (const double w[], size_t wstride, const double data[], size_t stride, size_t n)

   This function returns the estimated variance of the dataset :data:`data`
   with stride :data:`stride` and length :data:`n`, using the set of weights
   :data:`w` with stride :data:`wstride` and length :data:`n`.  The estimated
   variance of a weighted dataset is calculated as,

   .. only:: not texinfo

      .. math::

         \Hat\sigma^2 = {{\sum w_i} \over {(\sum w_i)^2 - \sum (w_i^2)}} 
                         \sum w_i (x_i - \Hat\mu)^2

   .. only:: texinfo

      ::

         \Hat\sigma^2 = ((\sum w_i)/((\sum w_i)^2 - \sum (w_i^2))) 
                         \sum w_i (x_i - \Hat\mu)^2

   Note that this expression reduces to an unweighted variance with the
   familiar :math:`1/(N-1)` factor when there are :math:`N` equal non-zero
   weights.

.. function:: double gsl_stats_wvariance_m (const double w[], size_t wstride, const double data[], size_t stride, size_t n, double wmean)

   This function returns the estimated variance of the weighted dataset
   :data:`data` using the given weighted mean :data:`wmean`.

.. function:: double gsl_stats_wsd (const double w[], size_t wstride, const double data[], size_t stride, size_t n)

   The standard deviation is defined as the square root of the variance.
   This function returns the square root of the corresponding variance
   function :func:`gsl_stats_wvariance` above.

.. function:: double gsl_stats_wsd_m (const double w[], size_t wstride, const double data[], size_t stride, size_t n, double wmean)

   This function returns the square root of the corresponding variance
   function :func:`gsl_stats_wvariance_m` above.

.. function:: double gsl_stats_wvariance_with_fixed_mean (const double w[], size_t wstride, const double data[], size_t stride, size_t n, const double mean)

   This function computes an unbiased estimate of the variance of the weighted
   dataset :data:`data` when the population mean :data:`mean` of the underlying
   distribution is known *a priori*.  In this case the estimator for
   the variance replaces the sample mean :math:`\Hat\mu` by the known
   population mean :math:`\mu`,

   .. only:: not texinfo

      .. math:: \Hat\sigma^2 = {{\sum w_i (x_i - \mu)^2} \over {\sum w_i}}

   .. only:: texinfo

      ::

         \Hat\sigma^2 = (\sum w_i (x_i - \mu)^2) / (\sum w_i)

.. function:: double gsl_stats_wsd_with_fixed_mean (const double w[], size_t wstride, const double data[], size_t stride, size_t n, const double mean)

   The standard deviation is defined as the square root of the variance.
   This function returns the square root of the corresponding variance
   function above.

.. function:: double gsl_stats_wtss (const double w[], const size_t wstride, const double data[], size_t stride, size_t n)
              double gsl_stats_wtss_m (const double w[], const size_t wstride, const double data[], size_t stride, size_t n, double wmean)

   These functions return the weighted total sum of squares (TSS) of
   :data:`data` about the weighted mean.  For :func:`gsl_stats_wtss_m` the
   user-supplied value of :data:`wmean` is used, and for :func:`gsl_stats_wtss`
   it is computed using :func:`gsl_stats_wmean`.

   .. only:: not texinfo

      .. math:: {\rm TSS} = \sum w_i (x_i - wmean)^2

   .. only:: texinfo

      ::

         TSS =  \sum w_i (x_i - wmean)^2

.. function:: double gsl_stats_wabsdev (const double w[], size_t wstride, const double data[], size_t stride, size_t n)

   This function computes the weighted absolute deviation from the weighted
   mean of :data:`data`.  The absolute deviation from the mean is defined as,

   .. only:: not texinfo

      .. math:: absdev = {{\sum w_i |x_i - \Hat\mu|} \over {\sum w_i}}

   .. only:: texinfo

      ::

         absdev = (\sum w_i |x_i - \Hat\mu|) / (\sum w_i)

.. function:: double gsl_stats_wabsdev_m (const double w[], size_t wstride, const double data[], size_t stride, size_t n, double wmean)

   This function computes the absolute deviation of the weighted dataset
   :data:`data` about the given weighted mean :data:`wmean`.

.. function:: double gsl_stats_wskew (const double w[], size_t wstride, const double data[], size_t stride, size_t n)

   This function computes the weighted skewness of the dataset :data:`data`.

   .. only:: not texinfo

      .. math:: skew = {{\sum w_i ((x_i - {\Hat x})/{\Hat \sigma})^3} \over {\sum w_i}}

   .. only:: texinfo

      ::

         skew = (\sum w_i ((x_i - \Hat x)/\Hat \sigma)^3) / (\sum w_i)

.. function:: double gsl_stats_wskew_m_sd (const double w[], size_t wstride, const double data[], size_t stride, size_t n, double wmean, double wsd)

   This function computes the weighted skewness of the dataset :data:`data`
   using the given values of the weighted mean and weighted standard
   deviation, :data:`wmean` and :data:`wsd`.

.. function:: double gsl_stats_wkurtosis (const double w[], size_t wstride, const double data[], size_t stride, size_t n)

   This function computes the weighted kurtosis of the dataset :data:`data`.

   .. only:: not texinfo

      .. math:: kurtosis = {{\sum w_i ((x_i - {\Hat x})/{\Hat \sigma})^4} \over {\sum w_i}} - 3

   .. only:: texinfo

      ::

         kurtosis = ((\sum w_i ((x_i - \Hat x)/\Hat \sigma)^4) / (\sum w_i)) - 3

.. function:: double gsl_stats_wkurtosis_m_sd (const double w[], size_t wstride, const double data[], size_t stride, size_t n, double wmean, double wsd)

   This function computes the weighted kurtosis of the dataset :data:`data`
   using the given values of the weighted mean and weighted standard
   deviation, :data:`wmean` and :data:`wsd`.

Maximum and Minimum values
==========================

The following functions find the maximum and minimum values of a
dataset (or their indices).  If the data contains :code:`NaN`-s then a
:code:`NaN` will be returned, since the maximum or minimum value is
undefined.  For functions which return an index, the location of the
first :code:`NaN` in the array is returned.

.. function:: double gsl_stats_max (const double data[], size_t stride, size_t n)

   This function returns the maximum value in :data:`data`, a dataset of
   length :data:`n` with stride :data:`stride`.  The maximum value is defined
   as the value of the element :math:`x_i` which satisfies :math:`x_i \ge x_j`
   for all :math:`j`.

   If you want instead to find the element with the largest absolute
   magnitude you will need to apply :func:`fabs` or :func:`abs` to your data
   before calling this function.

.. function:: double gsl_stats_min (const double data[], size_t stride, size_t n)

   This function returns the minimum value in :data:`data`, a dataset of
   length :data:`n` with stride :data:`stride`.  The minimum value is defined
   as the value of the element :math:`x_i` which satisfies :math:`x_i \le x_j`
   for all :math:`j`.

   If you want instead to find the element with the smallest absolute
   magnitude you will need to apply :func:`fabs` or :func:`abs` to your data
   before calling this function.

.. function:: void gsl_stats_minmax (double * min, double * max, const double data[], size_t stride, size_t n)

   This function finds both the minimum and maximum values :data:`min`,
   :data:`max` in :data:`data` in a single pass.

.. function:: size_t gsl_stats_max_index (const double data[], size_t stride, size_t n)

   This function returns the index of the maximum value in :data:`data`, a
   dataset of length :data:`n` with stride :data:`stride`.  The maximum value is
   defined as the value of the element :math:`x_i` which satisfies 
   :math:`x_i \ge x_j`
   for all :math:`j`.  When there are several equal maximum
   elements then the first one is chosen.

.. function:: size_t gsl_stats_min_index (const double data[], size_t stride, size_t n)

   This function returns the index of the minimum value in :data:`data`, a
   dataset of length :data:`n` with stride :data:`stride`.  The minimum value
   is defined as the value of the element :math:`x_i` which satisfies
   :math:`x_i \ge x_j`
   for all :math:`j`.  When there are several equal
   minimum elements then the first one is chosen.

.. function:: void gsl_stats_minmax_index (size_t * min_index, size_t * max_index, const double data[], size_t stride, size_t n)

   This function returns the indexes :data:`min_index`, :data:`max_index` of
   the minimum and maximum values in :data:`data` in a single pass.

Median and Percentiles
======================

The median and percentile functions described in this section operate on
sorted data in :math:`O(1)` time. There is also a routine for computing
the median of an unsorted input array in average :math:`O(n)` time using
the quickselect algorithm. For convenience we use *quantiles*, measured on a scale
of 0 to 1, instead of percentiles (which use a scale of 0 to 100).

.. function:: double gsl_stats_median_from_sorted_data (const double sorted_data[], const size_t stride, const size_t n)

   This function returns the median value of :data:`sorted_data`, a dataset
   of length :data:`n` with stride :data:`stride`.  The elements of the array
   must be in ascending numerical order.  There are no checks to see
   whether the data are sorted, so the function :func:`gsl_sort` should
   always be used first.

   When the dataset has an odd number of elements the median is the value
   of element :math:`(n-1)/2`.  When the dataset has an even number of
   elements the median is the mean of the two nearest middle values,
   elements :math:`(n-1)/2` and :math:`n/2`.  Since the algorithm for
   computing the median involves interpolation this function always returns
   a floating-point number, even for integer data types.

.. function:: double gsl_stats_median (double data[], const size_t stride, const size_t n)

   This function returns the median value of :data:`data`, a dataset
   of length :data:`n` with stride :data:`stride`. The median is found
   using the quickselect algorithm. The input array does not need to be
   sorted, but note that the algorithm rearranges the array and so the input
   is not preserved on output.

.. function:: double gsl_stats_quantile_from_sorted_data (const double sorted_data[], size_t stride, size_t n, double f)

   This function returns a quantile value of :data:`sorted_data`, a
   double-precision array of length :data:`n` with stride :data:`stride`.  The
   elements of the array must be in ascending numerical order.  The
   quantile is determined by the :data:`f`, a fraction between 0 and 1.  For
   example, to compute the value of the 75th percentile :data:`f` should have
   the value 0.75.

   There are no checks to see whether the data are sorted, so the function
   :func:`gsl_sort` should always be used first.

   The quantile is found by interpolation, using the formula

   .. only:: not texinfo

      .. math:: \hbox{quantile} = (1 - \delta) x_i + \delta x_{i+1}

   .. only:: texinfo

      ::

         quantile = (1 - \delta) x_i + \delta x_{i+1}

   where :math:`i` is :code:`floor((n - 1)f)` and :math:`\delta` is
   :math:`(n-1)f - i`.

   Thus the minimum value of the array (:code:`data[0*stride]`) is given by
   :data:`f` equal to zero, the maximum value (:code:`data[(n-1)*stride]`) is
   given by :data:`f` equal to one and the median value is given by :data:`f`
   equal to 0.5.  Since the algorithm for computing quantiles involves
   interpolation this function always returns a floating-point number, even
   for integer data types.

.. @node Statistical tests
.. @section Statistical tests

.. FIXME, do more work on the statistical tests

.. -@deftypefun double gsl_stats_ttest (const double data1[], double data2[], size_t n1, size_t n2)
.. -@deftypefunx Statistics double gsl_stats_int_ttest (const double data1[], double data2[], size_t n1, size_t n2)

.. The function :func:`gsl_stats_ttest` computes the t-test statistic for
.. the two arrays :data:`data1`[] and :data:`data2`[], of lengths :data:`n1` and
.. -:data:`n2` respectively.

.. The t-test statistic measures the difference between the means of two
.. datasets.

Order Statistics
================

The :math:`k`-th *order statistic* of a sample is equal to its :math:`k`-th smallest value.
The :math:`k`-th order statistic of a set of :math:`n` values :math:`x = \left\{ x_i \right\}, 1 \le i \le n` is
denoted :math:`x_{(k)}`. The median of the set :math:`x` is equal to :math:`x_{\left( \frac{n}{2} \right)}` if
:math:`n` is odd, or the average of :math:`x_{\left( \frac{n}{2} \right)}` and :math:`x_{\left( \frac{n}{2} + 1 \right)}`
if :math:`n` is even. The :math:`k`-th smallest element of a length :math:`n` vector can be found
in average :math:`O(n)` time using the quickselect algorithm.

.. function:: gsl_stats_select(double data[], const size_t stride, const size_t n, const size_t k)

   This function finds the :data:`k`-th smallest element of the input array :data:`data`
   of length :data:`n` and stride :data:`stride` using the quickselect method. The
   algorithm rearranges the elements of :data:`data` and so the input array is not preserved
   on output.

.. index::
   single: robust location estimators
   single: location estimation
   single: estimation, location

Robust Location Estimates
=========================

A *location estimate* refers to a typical or central value which best describes a given
dataset. The mean and median are both examples of location estimators. However, the
mean has a severe sensitivity to data outliers and can give erroneous values when
even a small number of outliers are present. The median on the other hand, has
a strong insensitivity to data outliers, but due to its non-smoothness it can
behave unexpectedly in certain situations. GSL offers the following alternative
location estimators, which are robust to the presence of outliers.

.. index::
   single: trimmed mean
   single: truncated mean
   single: mean, trimmed
   single: mean, truncated

Trimmed Mean
------------

The trimmed mean, or *truncated mean*, discards a certain number of smallest and largest
samples from the input vector before computing the mean of the remaining samples. The
amount of trimming is specified by a factor :math:`\alpha \in [0,0.5]`. Then the
number of samples discarded from both ends of the input vector is
:math:`\left\lfloor \alpha n \right\rfloor`, where :math:`n` is the length of the input.
So to discard 25% of the samples from each end, one would set :math:`\alpha = 0.25`.

.. function:: double gsl_stats_trmean_from_sorted_data (const double alpha, const double sorted_data[], const size_t stride, const size_t n)

   This function returns the trimmed mean of :data:`sorted_data`, a dataset
   of length :data:`n` with stride :data:`stride`. The elements of the array
   must be in ascending numerical order.  There are no checks to see
   whether the data are sorted, so the function :func:`gsl_sort` should
   always be used first. The trimming factor :math:`\alpha` is given in :data:`alpha`.
   If :math:`\alpha \ge 0.5`, then the median of the input is returned.

.. index::
   single: Gastwirth estimator

Gastwirth Estimator
-------------------

Gastwirth's location estimator is a weighted sum of three order statistics,

.. only:: not texinfo

   .. math:: gastwirth = 0.3 \times Q_{\frac{1}{3}} + 0.4 \times Q_{\frac{1}{2}} + 0.3 \times Q_{\frac{2}{3}}

.. only:: texinfo

   ::

      gastwirth = 0.3 * Q_{1/3} + 0.4 * Q_{1/2} + 0.3 * Q_{2/3}

where :math:`Q_{\frac{1}{3}}` is the one-third quantile, :math:`Q_{\frac{1}{2}}` is the one-half
quantile (i.e. median), and :math:`Q_{\frac{2}{3}}` is the two-thirds quantile.

.. function:: double gsl_stats_gastwirth_from_sorted_data (const double sorted_data[], const size_t stride, const size_t n)

   This function returns the Gastwirth location estimator of :data:`sorted_data`, a dataset
   of length :data:`n` with stride :data:`stride`.  The elements of the array
   must be in ascending numerical order.  There are no checks to see
   whether the data are sorted, so the function :func:`gsl_sort` should
   always be used first.

.. index::
   single: robust scale estimators
   single: scale estimation
   single: estimation, scale

Robust Scale Estimates
======================

A *robust scale estimate*, also known as a robust measure of scale, attempts to quantify
the statistical dispersion (variability, scatter, spread) in a set of data which may contain outliers.
In such datasets, the usual variance or standard deviation scale estimate can be rendered useless
by even a single outlier.

.. index::
   single: median absolute deviation

.. _sec_mad-statistic:

Median Absolute Deviation (MAD)
-------------------------------

The median absolute deviation (MAD) is defined as

.. only:: not texinfo

   .. math:: MAD = 1.4826 \times \textrm{median} \left\{ \left| x_i - \textrm{median} \left( x \right) \right| \right\}

.. only:: texinfo

   ::

      MAD = 1.4826 median { | x_i - median(x) | }

In words, first the median of all samples is computed. Then the median
is subtracted from all samples in the input to find the deviation of each sample
from the median. The median of all absolute deviations is then the MAD.
The factor :math:`1.4826` makes the MAD an unbiased estimator of the standard deviation for Gaussian data.
The median absolute deviation has an asymptotic efficiency of 37%.

.. function:: double gsl_stats_mad0 (const double data[], const size_t stride, const size_t n, double work[])
.. function:: double gsl_stats_mad (const double data[], const size_t stride, const size_t n, double work[])

   These functions return the median absolute deviation of :data:`data`, a dataset
   of length :data:`n` and stride :data:`stride`.
   The :code:`mad0` function calculates
   :math:`\textrm{median} \left\{ \left| x_i - \textrm{median} \left( x \right) \right| \right\}`
   (i.e. the :math:`MAD` statistic without the bias correction scale factor).
   These functions require additional workspace of size :code:`n` provided in :data:`work`.

.. index::
   single: Sn statistic

.. _sec_Sn-statistic:

:math:`S_n` Statistic
---------------------

The :math:`S_n` statistic developed by Croux and Rousseeuw is defined as

.. only:: not texinfo

   .. math:: S_n = 1.1926 \times c_n \times \textrm{median}_i \left\{ \textrm{median}_j \left( \left| x_i - x_j \right| \right) \right\}

.. only:: texinfo

   ::

      S_n = 1.1926 * c_n * median_i { median_j ( | x_i - x_j | ) }

For each sample :math:`x_i, 1 \le i \le n`, the median of the values :math:`\left| x_i - x_j \right|` is computed for all
:math:`x_j, 1 \le j \le n`. This yields :math:`n` values, whose median then gives the final :math:`S_n`.
The factor :math:`1.1926` makes :math:`S_n` an unbiased estimate of the standard deviation for Gaussian data.
The factor :math:`c_n` is a correction factor to correct bias in small sample sizes. :math:`S_n` has an asymptotic
efficiency of 58%.

.. function:: double gsl_stats_Sn0_from_sorted_data (const double sorted_data[], const size_t stride, const size_t n, double work[])
.. function:: double gsl_stats_Sn_from_sorted_data (const double sorted_data[], const size_t stride, const size_t n, double work[])

   These functions return the :math:`S_n` statistic of :data:`sorted_data`, a dataset
   of length :data:`n` with stride :data:`stride`.  The elements of the array
   must be in ascending numerical order.  There are no checks to see
   whether the data are sorted, so the function :func:`gsl_sort` should
   always be used first. The :code:`Sn0` function calculates
   :math:`\textrm{median}_i \left\{ \textrm{median}_j \left( \left| x_i - x_j \right| \right) \right\}`
   (i.e. the :math:`S_n` statistic without the bias correction scale factors).
   These functions require additional workspace of size
   :code:`n` provided in :data:`work`.

.. index::
   single: Qn statistic

.. _sec_Qn-statistic:

:math:`Q_n` Statistic
---------------------

The :math:`Q_n` statistic developed by Croux and Rousseeuw is defined as

.. only:: not texinfo

   .. math:: Q_n = 2.21914 \times d_n \times \left\{ \left| x_i - x_j \right|, i < j \right\}_{(k)}

.. only:: texinfo

   ::

      Q_n = 2.21914 * d_n * { | x_i - x_j |, i < j }_{(k)}

The factor :math:`2.21914` makes :math:`Q_n` an unbiased estimate of the standard deviation for Gaussian data.
The factor :math:`d_n` is a correction factor to correct bias in small sample sizes. The order statistic
is

.. only:: not texinfo

   .. math:: k = \left(
                   \begin{array}{c}
                     \left\lfloor \frac{n}{2} \right\rfloor + 1 \\
                     2
                   \end{array}
                 \right)

.. only:: texinfo

   ::

      k = ( floor(n/2) + 1 )
          (       2        )

:math:`Q_n` has an asymptotic efficiency of 82%.

.. function:: double gsl_stats_Qn0_from_sorted_data (const double sorted_data[], const size_t stride, const size_t n, double work[], int work_int[])
              double gsl_stats_Qn_from_sorted_data (const double sorted_data[], const size_t stride, const size_t n, double work[], int work_int[])

   These functions return the :math:`Q_n` statistic of :data:`sorted_data`, a dataset
   of length :data:`n` with stride :data:`stride`. The elements of the array
   must be in ascending numerical order.  There are no checks to see
   whether the data are sorted, so the function :func:`gsl_sort` should
   always be used first. The :code:`Qn0` function calculates
   :math:`\left\{ \left| x_i - x_j \right|, i < j \right\}_{(k)}`
   (i.e. :math:`Q_n` without the bias correction scale factors).
   These functions require additional workspace of size
   :code:`3n` provided in :data:`work` and integer workspace of size :code:`5n`
   provided in :data:`work_int`.

Examples
========

Here is a basic example of how to use the statistical functions:

.. include:: examples/stat.c
   :code:

The program should produce the following output,

.. include:: examples/stat.txt
   :code:

Here is an example using sorted data,

.. include:: examples/statsort.c
   :code:

This program should produce the following output,

.. include:: examples/statsort.txt
   :code:

References and Further Reading
==============================

The standard reference for almost any topic in statistics is the
multi-volume *Advanced Theory of Statistics* by Kendall and Stuart.

* Maurice Kendall, Alan Stuart, and J. Keith Ord.
  *The Advanced Theory of Statistics* (multiple volumes)
  reprinted as *Kendall's Advanced Theory of Statistics*.
  Wiley, ISBN 047023380X.

Many statistical concepts can be more easily understood by a Bayesian
approach.  The following book by Gelman, Carlin, Stern and Rubin gives a
comprehensive coverage of the subject.

* Andrew Gelman, John B. Carlin, Hal S. Stern, Donald B. Rubin.
  *Bayesian Data Analysis*.
  Chapman & Hall, ISBN 0412039915.

For physicists the Particle Data Group provides useful reviews of
Probability and Statistics in the "Mathematical Tools" section of its
Annual Review of Particle Physics. 

* *Review of Particle Properties*,
  R.M. Barnett et al., Physical Review D54, 1 (1996)

The Review of Particle Physics is available online at
the website http://pdg.lbl.gov/.

The following papers describe robust scale estimation,

* C. Croux and P. J. Rousseeuw, *Time-Efficient algorithms for two highly robust
  estimators of scale*, Comp. Stat., Physica, Heidelberg, 1992.
* P. J. Rousseeuw and C. Croux, *Explicit scale estimators with high breakdown point*,
  L1-Statistical Analysis and Related Methods, pp. 77-92, 1992.
.. index:: Fermi-Dirac function

The functions described in this section are declared in the header file
:file:`gsl_sf_fermi_dirac.h`.

Complete Fermi-Dirac Integrals
------------------------------
.. index::
   single: complete Fermi-Dirac integrals
   single: Fj(x), Fermi-Dirac integral

The complete Fermi-Dirac integral :math:`F_j(x)` is given by,

.. only:: not texinfo

   .. math:: F_j(x) := {1\over\Gamma(j+1)} \int_0^\infty dt {t^j  \over (\exp(t-x) + 1)}

.. only:: texinfo

   ::

      F_j(x) := (1/\Gamma(j+1)) \int_0^\infty dt (t^j / (\exp(t-x) + 1))

Note that the Fermi-Dirac integral is sometimes defined without the
normalisation factor in other texts.

.. function:: double gsl_sf_fermi_dirac_m1 (double x)
              int gsl_sf_fermi_dirac_m1_e (double x, gsl_sf_result * result)

   These routines compute the complete Fermi-Dirac integral with an index of :math:`-1`. 
   This integral is given by 
   :math:`F_{-1}(x) = e^x / (1 + e^x)`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_fermi_dirac_0 (double x)
              int gsl_sf_fermi_dirac_0_e (double x, gsl_sf_result * result)

   These routines compute the complete Fermi-Dirac integral with an index of :math:`0`. 
   This integral is given by :math:`F_0(x) = \ln(1 + e^x)`.
.. Exceptional Return Values: GSL_EUNDRFLW

.. function:: double gsl_sf_fermi_dirac_1 (double x)
              int gsl_sf_fermi_dirac_1_e (double x, gsl_sf_result * result)

   These routines compute the complete Fermi-Dirac integral with an index of :math:`1`,
   :math:`F_1(x) = \int_0^\infty dt (t /(\exp(t-x)+1))`.
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EOVRFLW

.. function:: double gsl_sf_fermi_dirac_2 (double x)
              int gsl_sf_fermi_dirac_2_e (double x, gsl_sf_result * result)

   These routines compute the complete Fermi-Dirac integral with an index
   of :math:`2`,
   :math:`F_2(x) = (1/2) \int_0^\infty dt (t^2 /(\exp(t-x)+1))`.
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EOVRFLW

.. function:: double gsl_sf_fermi_dirac_int (int j, double x)
              int gsl_sf_fermi_dirac_int_e (int j, double x, gsl_sf_result * result)

   These routines compute the complete Fermi-Dirac integral with an integer
   index of :math:`j`,
   :math:`F_j(x) = (1/\Gamma(j+1)) \int_0^\infty dt (t^j /(\exp(t-x)+1))`.
.. Complete integral F_j(x) for integer j
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EOVRFLW

.. function:: double gsl_sf_fermi_dirac_mhalf (double x)
              int gsl_sf_fermi_dirac_mhalf_e (double x, gsl_sf_result * result)

   These routines compute the complete Fermi-Dirac integral 
   :math:`F_{-1/2}(x)`.
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EOVRFLW

.. function:: double gsl_sf_fermi_dirac_half (double x)
              int gsl_sf_fermi_dirac_half_e (double x, gsl_sf_result * result)

   These routines compute the complete Fermi-Dirac integral 
   :math:`F_{1/2}(x)`.
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EOVRFLW

.. function:: double gsl_sf_fermi_dirac_3half (double x)
              int gsl_sf_fermi_dirac_3half_e (double x, gsl_sf_result * result)

   These routines compute the complete Fermi-Dirac integral 
   :math:`F_{3/2}(x)`.
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EOVRFLW

Incomplete Fermi-Dirac Integrals
--------------------------------
.. index::
   single: incomplete Fermi-Dirac integral
   single:  Fj(x,b), incomplete Fermi-Dirac integral

The incomplete Fermi-Dirac integral :math:`F_j(x,b)` is given by,

.. only:: not texinfo

   .. math:: F_j(x,b) := {1\over\Gamma(j+1)} \int_b^\infty dt {t^j  \over (\exp(t-x) + 1)}

.. only:: texinfo

   ::

      F_j(x,b) := (1/\Gamma(j+1)) \int_b^\infty dt (t^j / (\Exp(t-x) + 1))

.. function:: double gsl_sf_fermi_dirac_inc_0 (double x, double b)
              int gsl_sf_fermi_dirac_inc_0_e (double x, double b, gsl_sf_result * result)

   These routines compute the incomplete Fermi-Dirac integral with an index
   of zero,
   :math:`F_0(x,b) = \ln(1 + e^{b-x}) - (b-x)`
.. Exceptional Return Values: GSL_EUNDRFLW, GSL_EDOM
.. index:: synchrotron functions

The functions described in this section are declared in the header file
:file:`gsl_sf_synchrotron.h`.

.. function:: double gsl_sf_synchrotron_1 (double x)
              int gsl_sf_synchrotron_1_e (double x, gsl_sf_result * result)

   These routines compute the first synchrotron function 
   :math:`x \int_x^\infty dt K_{5/3}(t)`
   for :math:`x \ge 0`.
.. Domain: x >= 0.0
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW
 
.. function:: double gsl_sf_synchrotron_2 (double x)
              int gsl_sf_synchrotron_2_e (double x, gsl_sf_result * result)

   These routines compute the second synchrotron function 
   :math:`x K_{2/3}(x)` for :math:`x \ge 0`.
.. Domain: x >= 0.0
.. Exceptional Return Values: GSL_EDOM, GSL_EUNDRFLW
.. index:: permutations

************
Permutations
************

.. include:: include.rst

This chapter describes functions for creating and manipulating
permutations. A permutation :math:`p` is represented by an array of
:math:`n` integers in the range 0 to :math:`n-1`, where each value
:math:`p_i` occurs once and only once.  The application of a permutation
:math:`p` to a vector :math:`v` yields a new vector :math:`v'` where
:math:`v'_i = v_{p_i}`.
For example, the array :math:`(0,1,3,2)` represents a permutation
which exchanges the last two elements of a four element vector.
The corresponding identity permutation is :math:`(0,1,2,3)`.   

Note that the permutations produced by the linear algebra routines
correspond to the exchange of matrix columns, and so should be considered
as applying to row-vectors in the form :math:`v' = v P` rather than
column-vectors, when permuting the elements of a vector.

The functions described in this chapter are defined in the header file
:file:`gsl_permutation.h`.

The Permutation struct
======================

.. type:: gsl_permutation

   A permutation is defined by a structure containing two components, the size
   of the permutation and a pointer to the permutation array.  The elements
   of the permutation array are all of type :code:`size_t`.  The
   :type:`gsl_permutation` structure looks like this::

      typedef struct
      {
        size_t size;
        size_t * data;
      } gsl_permutation;

Permutation allocation
======================

.. function:: gsl_permutation * gsl_permutation_alloc (size_t n)

   This function allocates memory for a new permutation of size :data:`n`.
   The permutation is not initialized and its elements are undefined.  Use
   the function :func:`gsl_permutation_calloc` if you want to create a
   permutation which is initialized to the identity. A null pointer is
   returned if insufficient memory is available to create the permutation.

.. function:: gsl_permutation * gsl_permutation_calloc (size_t n)

   This function allocates memory for a new permutation of size :data:`n` and
   initializes it to the identity. A null pointer is returned if
   insufficient memory is available to create the permutation.

.. index:: identity permutation

.. function:: void gsl_permutation_init (gsl_permutation * p)

   This function initializes the permutation :data:`p` to the identity, i.e.
   :math:`(0, 1, 2, \dots, n - 1)`.

.. function:: void gsl_permutation_free (gsl_permutation * p)

   This function frees all the memory used by the permutation :data:`p`.

.. function:: int gsl_permutation_memcpy (gsl_permutation * dest, const gsl_permutation * src)

   This function copies the elements of the permutation :data:`src` into the
   permutation :data:`dest`.  The two permutations must have the same size.

Accessing permutation elements
==============================

The following functions can be used to access and manipulate
permutations.

.. function:: size_t gsl_permutation_get (const gsl_permutation * p, const size_t i)

   This function returns the value of the :data:`i`-th element of the
   permutation :data:`p`.  If :data:`i` lies outside the allowed range of 0 to
   :math:`n - 1` then the error handler is invoked and 0 is returned. |inlinefn|

.. index::
   single: exchanging permutation elements
   single: swapping permutation elements

.. function:: int gsl_permutation_swap (gsl_permutation * p, const size_t i, const size_t j)

   This function exchanges the :data:`i`-th and :data:`j`-th elements of the
   permutation :data:`p`.

Permutation properties
======================

.. function:: size_t gsl_permutation_size (const gsl_permutation * p)

   This function returns the size of the permutation :data:`p`.

.. function:: size_t * gsl_permutation_data (const gsl_permutation * p)

   This function returns a pointer to the array of elements in the
   permutation :data:`p`.

.. index::
   single: checking permutation for validity
   single: testing permutation for validity

.. function:: int gsl_permutation_valid (const gsl_permutation * p)

   This function checks that the permutation :data:`p` is valid.  The :code:`n`
   elements should contain each of the numbers 0 to :code:`n - 1` once and only
   once.

Permutation functions
=====================

.. index:: reversing a permutation

.. function:: void gsl_permutation_reverse (gsl_permutation * p)

   This function reverses the elements of the permutation :data:`p`.

.. index:: inverting a permutation

.. function:: int gsl_permutation_inverse (gsl_permutation * inv, const gsl_permutation * p)

   This function computes the inverse of the permutation :data:`p`, storing
   the result in :data:`inv`.

.. index:: iterating through permutations

.. function:: int gsl_permutation_next (gsl_permutation * p)

   This function advances the permutation :data:`p` to the next permutation
   in lexicographic order and returns :macro:`GSL_SUCCESS`.  If no further
   permutations are available it returns :macro:`GSL_FAILURE` and leaves
   :data:`p` unmodified.  Starting with the identity permutation and
   repeatedly applying this function will iterate through all possible
   permutations of a given order.

.. function:: int gsl_permutation_prev (gsl_permutation * p)

   This function steps backwards from the permutation :data:`p` to the
   previous permutation in lexicographic order, returning
   :macro:`GSL_SUCCESS`.  If no previous permutation is available it returns
   :macro:`GSL_FAILURE` and leaves :data:`p` unmodified.

Applying Permutations
=====================

.. function:: int gsl_permute (const size_t * p, double * data, size_t stride, size_t n)

   This function applies the permutation :data:`p` to the array :data:`data` of
   size :data:`n` with stride :data:`stride`.

.. function:: int gsl_permute_inverse (const size_t * p, double * data, size_t stride, size_t n)

   This function applies the inverse of the permutation :data:`p` to the
   array :data:`data` of size :data:`n` with stride :data:`stride`.

.. function:: int gsl_permute_vector (const gsl_permutation * p, gsl_vector * v)

   This function applies the permutation :data:`p` to the elements of the
   vector :data:`v`, considered as a row-vector acted on by a permutation
   matrix from the right, :math:`v' = v P`.  The :math:`j`-th column of the
   permutation matrix :math:`P` is given by the :math:`p_j`-th column of the
   identity matrix. The permutation :data:`p` and the vector :data:`v` must
   have the same length.

.. function:: int gsl_permute_vector_inverse (const gsl_permutation * p, gsl_vector * v)

   This function applies the inverse of the permutation :data:`p` to the
   elements of the vector :data:`v`, considered as a row-vector acted on by
   an inverse permutation matrix from the right, :math:`v' = v P^T`.  Note
   that for permutation matrices the inverse is the same as the transpose.
   The :math:`j`-th column of the permutation matrix :math:`P` is given by
   the :math:`:data:`p`_j`-th column of the identity matrix. The permutation :data:`p`
   and the vector :data:`v` must have the same length.

.. function:: int gsl_permute_matrix (const gsl_permutation * p, gsl_matrix * A)

   This function applies the permutation :data:`p` to the matrix :data:`A` from
   the right, :math:`A' = A P`.  The :math:`j`-th column of the
   permutation matrix :math:`P` is given by the :math:`p_j`-th column of the
   identity matrix. This effectively permutes the columns of :data:`A` according
   to the permutation :data:`p`, and so the number of columns of :data:`A` must
   equal the size of the permutation :data:`p`.

.. function:: int gsl_permutation_mul (gsl_permutation * p, const gsl_permutation * pa, const gsl_permutation * pb)

   This function combines the two permutations :data:`pa` and :data:`pb` into a
   single permutation :data:`p`, where :math:`p = pa * pb`
   The permutation :data:`p` is equivalent to applying :data:`pb` first and
   then :data:`pa`.

Reading and writing permutations
================================

The library provides functions for reading and writing permutations to a
file as binary data or formatted text.

.. function:: int gsl_permutation_fwrite (FILE * stream, const gsl_permutation * p)

   This function writes the elements of the permutation :data:`p` to the
   stream :data:`stream` in binary format.  The function returns
   :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since the
   data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_permutation_fread (FILE * stream, gsl_permutation * p)

   This function reads into the permutation :data:`p` from the open stream
   :data:`stream` in binary format.  The permutation :data:`p` must be
   preallocated with the correct length since the function uses the size of
   :data:`p` to determine how many bytes to read.  The function returns
   :macro:`GSL_EFAILED` if there was a problem reading from the file.  The
   data is assumed to have been written in the native binary format on the
   same architecture.

.. function:: int gsl_permutation_fprintf (FILE * stream, const gsl_permutation * p, const char * format)

   This function writes the elements of the permutation :data:`p`
   line-by-line to the stream :data:`stream` using the format specifier
   :data:`format`, which should be suitable for a type of :data:`size_t`. 
   In ISO C99 the type modifier :code:`z` represents :code:`size_t`, so
   :code:`"%zu\n"` is a suitable format [#f1]_.
   The function returns :macro:`GSL_EFAILED` if there was a problem writing
   to the file.

.. function:: int gsl_permutation_fscanf (FILE * stream, gsl_permutation * p)

   This function reads formatted data from the stream :data:`stream` into the
   permutation :data:`p`.  The permutation :data:`p` must be preallocated with
   the correct length since the function uses the size of :data:`p` to
   determine how many numbers to read.  The function returns
   :macro:`GSL_EFAILED` if there was a problem reading from the file.

Permutations in cyclic form
===========================

A permutation can be represented in both *linear* and *cyclic*
notations.  The functions described in this section convert between the
two forms.  The linear notation is an index mapping, and has already
been described above.  The cyclic notation expresses a permutation as a
series of circular rearrangements of groups of elements, or
*cycles*.

For example, under the cycle (1 2 3), 1 is replaced by 2, 2 is replaced
by 3 and 3 is replaced by 1 in a circular fashion. Cycles of different
sets of elements can be combined independently, for example (1 2 3) (4
5) combines the cycle (1 2 3) with the cycle (4 5), which is an exchange
of elements 4 and 5.  A cycle of length one represents an element which
is unchanged by the permutation and is referred to as a *singleton*.

It can be shown that every permutation can be decomposed into
combinations of cycles.  The decomposition is not unique, but can always
be rearranged into a standard *canonical form* by a reordering of
elements.  The library uses the canonical form defined in Knuth's
*Art of Computer Programming* (Vol 1, 3rd Ed, 1997) Section 1.3.3,
p.178.

The procedure for obtaining the canonical form given by Knuth is,

#. Write all singleton cycles explicitly
#. Within each cycle, put the smallest number first
#. Order the cycles in decreasing order of the first number in the cycle.

For example, the linear representation (2 4 3 0 1) is represented as (1
4) (0 2 3) in canonical form. The permutation corresponds to an
exchange of elements 1 and 4, and rotation of elements 0, 2 and 3.

The important property of the canonical form is that it can be
reconstructed from the contents of each cycle without the brackets. In
addition, by removing the brackets it can be considered as a linear
representation of a different permutation. In the example given above
the permutation (2 4 3 0 1) would become (1 4 0 2 3).  This mapping has
many applications in the theory of permutations.

.. function:: int gsl_permutation_linear_to_canonical (gsl_permutation * q, const gsl_permutation * p)

   This function computes the canonical form of the permutation :data:`p` and
   stores it in the output argument :data:`q`.

.. function:: int gsl_permutation_canonical_to_linear (gsl_permutation * p, const gsl_permutation * q)

   This function converts a permutation :data:`q` in canonical form back into
   linear form storing it in the output argument :data:`p`.

.. function:: size_t gsl_permutation_inversions (const gsl_permutation * p)

   This function counts the number of inversions in the permutation
   :data:`p`.  An inversion is any pair of elements that are not in order.
   For example, the permutation 2031 has three inversions, corresponding to
   the pairs (2,0) (2,1) and (3,1).  The identity permutation has no
   inversions.

.. function:: size_t gsl_permutation_linear_cycles (const gsl_permutation * p)

   This function counts the number of cycles in the permutation :data:`p`, given in linear form.

.. function:: size_t gsl_permutation_canonical_cycles (const gsl_permutation * q)

   This function counts the number of cycles in the permutation :data:`q`, given in canonical form.

Examples
========

The example program below creates a random permutation (by shuffling the
elements of the identity) and finds its inverse.

.. include:: examples/permshuffle.c
   :code:

Here is the output from the program::

   $ ./a.out 
   initial permutation: 0 1 2 3 4 5 6 7 8 9
    random permutation: 1 3 5 2 7 6 0 4 9 8
   inverse permutation: 6 0 3 1 7 2 5 4 9 8

The random permutation :code:`p[i]` and its inverse :code:`q[i]` are
related through the identity :code:`p[q[i]] = i`, which can be verified
from the output.

The next example program steps forwards through all possible third order
permutations, starting from the identity,

.. include:: examples/permseq.c
   :code:

Here is the output from the program::

   $ ./a.out 
    0 1 2
    0 2 1
    1 0 2
    1 2 0
    2 0 1
    2 1 0

The permutations are generated in lexicographic order.  To reverse the
sequence, begin with the final permutation (which is the reverse of the
identity) and replace :func:`gsl_permutation_next` with
:func:`gsl_permutation_prev`.

References and Further Reading
==============================

The subject of permutations is covered extensively in the following,

* Donald E. Knuth, The Art of Computer Programming: Sorting and
  Searching (Vol 3, 3rd Ed, 1997), Addison-Wesley, ISBN 0201896850.

For the definition of the *canonical form* see,

* Donald E. Knuth, The Art of Computer Programming: Fundamental
  Algorithms (Vol 1, 3rd Ed, 1997), Addison-Wesley, ISBN 0201896850.
  Section 1.3.3, An Unusual Correspondence, p.178--179.

.. rubric:: Footnotes

.. [#f1] In versions of the GNU C library prior to the ISO C99 standard, 
         the type modifier :code:`Z` was used instead.
.. index:: error handling

**************
Error Handling
**************

This chapter describes the way that GSL functions report and handle
errors.  By examining the status information returned by every function
you can determine whether it succeeded or failed, and if it failed you
can find out what the precise cause of failure was.  You can also define
your own error handling functions to modify the default behavior of the
library.

The functions described in this section are declared in the header file
:file:`gsl_errno.h`.

Error Reporting
===============

The library follows the thread-safe error reporting conventions of the
POSIX Threads library.  Functions return a non-zero error code to
indicate an error and :code:`0` to indicate success::

    int status = gsl_function (...)

    if (status) { /* an error occurred */
      .....       
      /* status value specifies the type of error */
    }

The routines report an error whenever they cannot perform the task
requested of them.  For example, a root-finding function would return a
non-zero error code if could not converge to the requested accuracy, or
exceeded a limit on the number of iterations.  Situations like this are
a normal occurrence when using any mathematical library and you should
check the return status of the functions that you call.

Whenever a routine reports an error the return value specifies the type
of error.  The return value is analogous to the value of the variable
:code:`errno` in the C library.  The caller can examine the return code
and decide what action to take, including ignoring the error if it is
not considered serious.

In addition to reporting errors by return codes the library also has an
error handler function :func:`gsl_error`.  This function is called by
other library functions when they report an error, just before they
return to the caller.  The default behavior of the error handler is to
print a message and abort the program::

    gsl: file.c:67: ERROR: invalid argument supplied by user
    Default GSL error handler invoked.
    Aborted

The purpose of the :func:`gsl_error` handler is to provide a function
where a breakpoint can be set that will catch library errors when
running under the debugger.  It is not intended for use in production
programs, which should handle any errors using the return codes.

.. index::
   single: error codes, reserved

Error Codes
===========

The error code numbers returned by library functions are defined in
the file :file:`gsl_errno.h`.  They all have the prefix :code:`GSL_` and
expand to non-zero constant integer values. Error codes above 1024 are
reserved for applications, and are not used by the library.  Many of
the error codes use the same base name as the corresponding error code
in the C library.  Here are some of the most common error codes,

.. index::
   single: error codes

.. var:: int GSL_EDOM

   Domain error; used by mathematical functions when an argument value does
   not fall into the domain over which the function is defined (like
   :data:`EDOM` in the C library)

.. var:: int GSL_ERANGE

   Range error; used by mathematical functions when the result value is not
   representable because of overflow or underflow (like :data:`ERANGE` in the C
   library)

.. var:: int GSL_ENOMEM

   No memory available.  The system cannot allocate more virtual memory
   because its capacity is full (like :data:`ENOMEM` in the C library).  This error
   is reported when a GSL routine encounters problems when trying to
   allocate memory with :func:`malloc`.

.. var:: int GSL_EINVAL

   Invalid argument.  This is used to indicate various kinds of problems
   with passing the wrong argument to a library function (like :data:`EINVAL` in the C
   library). 

The error codes can be converted into an error message using the
function :func:`gsl_strerror`.

.. function:: const char * gsl_strerror (const int gsl_errno)

   This function returns a pointer to a string describing the error code
   :data:`gsl_errno`. For example::

     printf ("error: %s\n", gsl_strerror (status));

   would print an error message like :code:`error: output range error` for a
   status value of :data:`GSL_ERANGE`.

.. index:: error handlers

Error Handlers
==============

The default behavior of the GSL error handler is to print a short
message and call :func:`abort`.  When this default is in use programs
will stop with a core-dump whenever a library routine reports an error.
This is intended as a fail-safe default for programs which do not check
the return status of library routines (we don't encourage you to write
programs this way).

If you turn off the default error handler it is your responsibility to
check the return values of routines and handle them yourself.  You can
also customize the error behavior by providing a new error handler. For
example, an alternative error handler could log all errors to a file,
ignore certain error conditions (such as underflows), or start the
debugger and attach it to the current process when an error occurs.

All GSL error handlers have the type :code:`gsl_error_handler_t`, which is
defined in :file:`gsl_errno.h`,

.. type:: gsl_error_handler_t

   This is the type of GSL error handler functions.  An error handler will
   be passed four arguments which specify the reason for the error (a
   string), the name of the source file in which it occurred (also a
   string), the line number in that file (an integer) and the error number
   (an integer).  The source file and line number are set at compile time
   using the :code:`__FILE__` and :code:`__LINE__` directives in the
   preprocessor.  An error handler function returns type :code:`void`.
   Error handler functions should be defined like this::

     void handler (const char * reason, 
                   const char * file, 
                   int line, 
                   int gsl_errno)

To request the use of your own error handler you need to call the
function :func:`gsl_set_error_handler` which is also declared in
:file:`gsl_errno.h`,

.. function:: gsl_error_handler_t * gsl_set_error_handler (gsl_error_handler_t * new_handler)

   This function sets a new error handler, :data:`new_handler`, for the GSL
   library routines.  The previous handler is returned (so that you can
   restore it later).  Note that the pointer to a user defined error
   handler function is stored in a static variable, so there can be only
   one error handler per program.  This function should be not be used in
   multi-threaded programs except to set up a program-wide error handler
   from a master thread.  The following example shows how to set and
   restore a new error handler::

     /* save original handler, install new handler */
     old_handler = gsl_set_error_handler (&my_handler); 

     /* code uses new handler */
     .....     

     /* restore original handler */
     gsl_set_error_handler (old_handler); 

   To use the default behavior (:func:`abort` on error) set the error
   handler to :code:`NULL`::

     old_handler = gsl_set_error_handler (NULL); 

.. function:: gsl_error_handler_t * gsl_set_error_handler_off ()

   This function turns off the error handler by defining an error handler
   which does nothing. This will cause the program to continue after any
   error, so the return values from any library routines must be checked.
   This is the recommended behavior for production programs.  The previous
   handler is returned (so that you can restore it later).

The error behavior can be changed for specific applications by
recompiling the library with a customized definition of the
:code:`GSL_ERROR` macro in the file :file:`gsl_errno.h`.

.. index:: error handling macros

Using GSL error reporting in your own functions
===============================================

If you are writing numerical functions in a program which also uses GSL
code you may find it convenient to adopt the same error reporting
conventions as in the library.

To report an error you need to call the function :func:`gsl_error` with a
string describing the error and then return an appropriate error code
from :file:`gsl_errno.h`, or a special value, such as :code:`NaN`.  For
convenience the file :file:`gsl_errno.h` defines two macros which carry
out these steps:

.. macro:: GSL_ERROR (reason, gsl_errno)

   This macro reports an error using the GSL conventions and returns a
   status value of :code:`gsl_errno`.  It expands to the following code fragment::

     gsl_error (reason, __FILE__, __LINE__, gsl_errno);
     return gsl_errno;

   The macro definition in :file:`gsl_errno.h` actually wraps the code
   in a :code:`do { ... } while (0)` block to prevent possible
   parsing problems.

Here is an example of how the macro could be used to report that a
routine did not achieve a requested tolerance.  To report the error the
routine needs to return the error code :code:`GSL_ETOL`::

    if (residual > tolerance) 
      {
        GSL_ERROR("residual exceeds tolerance", GSL_ETOL);
      }

.. macro:: GSL_ERROR_VAL (reason, gsl_errno, value)

   This macro is the same as :code:`GSL_ERROR` but returns a user-defined
   value of :data:`value` instead of an error code.  It can be used for
   mathematical functions that return a floating point value.

The following example shows how to return a :code:`NaN` at a mathematical
singularity using the :code:`GSL_ERROR_VAL` macro::

    if (x == 0) 
      {
        GSL_ERROR_VAL("argument lies on singularity", GSL_ERANGE, GSL_NAN);
      }


Examples
========

Here is an example of some code which checks the return value of a
function where an error might be reported::

    #include <stdio.h>
    #include <gsl/gsl_errno.h>
    #include <gsl/gsl_fft_complex.h>

    ...
      int status;
      size_t n = 37;

      gsl_set_error_handler_off();

      status = gsl_fft_complex_radix2_forward (data, stride, n);

      if (status) {
        if (status == GSL_EINVAL) {
           fprintf (stderr, "invalid argument, n=%d\n", n);
        } else {
           fprintf (stderr, "failed, gsl_errno=%d\n", status);
        }
        exit (-1);
      }
    ...

The function :func:`gsl_fft_complex_radix2_forward` only accepts integer lengths
which are a power of two.  If the variable :code:`n` is not a power of
two then the call to the library function will return :code:`GSL_EINVAL`,
indicating that the length argument is invalid.  The function call to
:func:`gsl_set_error_handler_off` stops the default error handler from
aborting the program.  The :code:`else` clause catches any other possible
errors.

.. index::
   single: FFT
   single: Fast Fourier Transforms, see FFT
   single: Fourier Transforms, see FFT
   single: Discrete Fourier Transforms, see FFT
   single: DFTs, see FFT

******************************
Fast Fourier Transforms (FFTs)
******************************

.. include:: include.rst

This chapter describes functions for performing Fast Fourier Transforms
(FFTs).  The library includes radix-2 routines (for lengths which are a
power of two) and mixed-radix routines (which work for any length).  For
efficiency there are separate versions of the routines for real data and
for complex data.  The mixed-radix routines are a reimplementation of the
|fftpack| library of Paul Swarztrauber.  Fortran code for |fftpack| is
available on Netlib (|fftpack| also includes some routines for sine and
cosine transforms but these are currently not available in GSL).  For
details and derivations of the underlying algorithms consult the
document "GSL FFT Algorithms" (see :ref:`References and Further Reading <fft-references>`)

.. index:: FFT mathematical definition

Mathematical Definitions
========================

Fast Fourier Transforms are efficient algorithms for
calculating the discrete Fourier transform (DFT),

.. math:: x_j = \sum_{k=0}^{n-1} z_k \exp(-2 \pi i j k / n) 

The DFT usually arises as an approximation to the continuous Fourier
transform when functions are sampled at discrete intervals in space or
time.  The naive evaluation of the discrete Fourier transform is a
matrix-vector multiplication :math:`W\vec{z}`.
A general matrix-vector multiplication takes
:math:`O(n^2)` operations for :math:`n` data-points.  Fast Fourier
transform algorithms use a divide-and-conquer strategy to factorize the
matrix :math:`W` into smaller sub-matrices, corresponding to the integer
factors of the length :math:`n`.  If :math:`n` can be factorized into a
product of integers :math:`f_1 f_2 \ldots f_m`
then the DFT can be computed in :math:`O(n \sum f_i)`
operations.  For a radix-2 FFT this gives an operation count of
:math:`O(n \log_2 n)`.

All the FFT functions offer three types of transform: forwards, inverse
and backwards, based on the same mathematical definitions.  The
definition of the *forward Fourier transform*,
:math:`x = \hbox{FFT}(z)`, is,

.. math:: x_j = \sum_{k=0}^{n-1} z_k \exp(-2 \pi i j k / n) 

and the definition of the *inverse Fourier transform*,
:math:`x = \hbox{IFFT}(z)`, is,

.. math:: z_j = {1 \over n} \sum_{k=0}^{n-1} x_k \exp(2 \pi i j k / n).

The factor of :math:`1/n` makes this a true inverse.  For example, a call
to :func:`gsl_fft_complex_forward` followed by a call to
:func:`gsl_fft_complex_inverse` should return the original data (within
numerical errors).

In general there are two possible choices for the sign of the
exponential in the transform/ inverse-transform pair. GSL follows the
same convention as |fftpack|, using a negative exponential for the forward
transform.  The advantage of this convention is that the inverse
transform recreates the original function with simple Fourier
synthesis.  Numerical Recipes uses the opposite convention, a positive
exponential in the forward transform.

The *backwards FFT* is simply our terminology for an unscaled
version of the inverse FFT,

.. math:: z^{backwards}_j = \sum_{k=0}^{n-1} x_k \exp(2 \pi i j k / n)

When the overall scale of the result is unimportant it is often
convenient to use the backwards FFT instead of the inverse to save
unnecessary divisions.

.. index::
   single: FFT, complex data

Overview of complex data FFTs
=============================

The inputs and outputs for the complex FFT routines are *packed arrays*
of floating point numbers.  In a packed array the real and
imaginary parts of each complex number are placed in alternate
neighboring elements.  For example, the following definition of a packed
array of length 6::

  double x[3*2];
  gsl_complex_packed_array data = x;

can be used to hold an array of three complex numbers, :code:`z[3]`, in
the following way::

  data[0] = Re(z[0])
  data[1] = Im(z[0])
  data[2] = Re(z[1])
  data[3] = Im(z[1])
  data[4] = Re(z[2])
  data[5] = Im(z[2])

The array indices for the data have the same ordering as those
in the definition of the DFT---i.e. there are no index transformations
or permutations of the data.

A *stride* parameter allows the user to perform transforms on the
elements :code:`z[stride*i]` instead of :code:`z[i]`.  A stride greater
than 1 can be used to take an in-place FFT of the column of a matrix. A
stride of 1 accesses the array without any additional spacing between
elements.  

To perform an FFT on a vector argument, such as :code:`gsl_vector_complex * v`,
use the following definitions (or their equivalents) when calling
the functions described in this chapter::

  gsl_complex_packed_array data = v->data;
  size_t stride = v->stride;
  size_t n = v->size;

For physical applications it is important to remember that the index
appearing in the DFT does not correspond directly to a physical
frequency.  If the time-step of the DFT is :math:`\Delta` then the
frequency-domain includes both positive and negative frequencies,
ranging from :math:`-1/(2\Delta)` through 0 to :math:`+1/(2\Delta)`.  The
positive frequencies are stored from the beginning of the array up to
the middle, and the negative frequencies are stored backwards from the
end of the array.

Here is a table which shows the layout of the array :data:`data`, and the
correspondence between the time-domain data :math:`z`, and the
frequency-domain data :math:`x`::

  index    z               x = FFT(z)

  0        z(t = 0)        x(f = 0)
  1        z(t = 1)        x(f = 1/(n Delta))
  2        z(t = 2)        x(f = 2/(n Delta))
  .        ........        ..................
  n/2      z(t = n/2)      x(f = +1/(2 Delta),
                                 -1/(2 Delta))
  .        ........        ..................
  n-3      z(t = n-3)      x(f = -3/(n Delta))
  n-2      z(t = n-2)      x(f = -2/(n Delta))
  n-1      z(t = n-1)      x(f = -1/(n Delta))

When :math:`n` is even the location :math:`n/2` contains the most positive
and negative frequencies (:math:`+1/(2 \Delta)`, :math:`-1/(2 \Delta)`)
which are equivalent.  If :math:`n` is odd then general structure of the
table above still applies, but :math:`n/2` does not appear.

.. index::
   single: FFT of complex data, radix-2 algorithm
   single: Radix-2 FFT, complex data

Radix-2 FFT routines for complex data
=====================================

The radix-2 algorithms described in this section are simple and compact,
although not necessarily the most efficient.  They use the Cooley-Tukey
algorithm to compute in-place complex FFTs for lengths which are a power
of 2---no additional storage is required.  The corresponding
self-sorting mixed-radix routines offer better performance at the
expense of requiring additional working space.

All the functions described in this section are declared in the header file :file:`gsl_fft_complex.h`.

.. function:: int gsl_fft_complex_radix2_forward (gsl_complex_packed_array data, size_t stride, size_t n)
              int gsl_fft_complex_radix2_transform (gsl_complex_packed_array data, size_t stride, size_t n, gsl_fft_direction sign)
              int gsl_fft_complex_radix2_backward (gsl_complex_packed_array data, size_t stride, size_t n)
              int gsl_fft_complex_radix2_inverse (gsl_complex_packed_array data, size_t stride, size_t n)

   These functions compute forward, backward and inverse FFTs of length
   :data:`n` with stride :data:`stride`, on the packed complex array :data:`data`
   using an in-place radix-2 decimation-in-time algorithm.  The length of
   the transform :data:`n` is restricted to powers of two.  For the
   :code:`transform` version of the function the :data:`sign` argument can be
   either :code:`forward` (:math:`-1`) or :code:`backward` (:math:`+1`).

   The functions return a value of :macro:`GSL_SUCCESS` if no errors were
   detected, or :macro:`GSL_EDOM` if the length of the data :data:`n` is not a
   power of two.

.. function:: int gsl_fft_complex_radix2_dif_forward (gsl_complex_packed_array data, size_t stride, size_t n)
              int gsl_fft_complex_radix2_dif_transform (gsl_complex_packed_array data, size_t stride, size_t n, gsl_fft_direction sign)
              int gsl_fft_complex_radix2_dif_backward (gsl_complex_packed_array data, size_t stride, size_t n)
              int gsl_fft_complex_radix2_dif_inverse (gsl_complex_packed_array data, size_t stride, size_t n)

   These are decimation-in-frequency versions of the radix-2 FFT functions.

Here is an example program which computes the FFT of a short pulse in a
sample of length 128.  To make the resulting Fourier transform real the
pulse is defined for equal positive and negative times (:math:`-10 \dots 10`),
where the negative times wrap around the end of the array.

.. include:: examples/fft.c
   :code:

Note that we have assumed that the program is using the default error
handler (which calls :func:`abort` for any errors).  If you are not using
a safe error handler you would need to check the return status of
:func:`gsl_fft_complex_radix2_forward`.

The transformed data is rescaled by :math:`1/\sqrt n` so that it fits on
the same plot as the input.  Only the real part is shown, by the choice
of the input data the imaginary part is zero.  Allowing for the
wrap-around of negative times at :math:`t=128`, and working in units of
:math:`k/n`, the DFT approximates the continuum Fourier transform, giving
a modulated sine function.

.. math:: \int_{-a}^{+a} e^{-2 \pi i k x} dx = {\sin(2\pi k a) \over\pi k}

The output of the example program is plotted in :numref:`fig_fft-complex-radix2`.

.. _fig_fft-complex-radix2:

.. figure:: /images/fft-complex-radix2.png
   :scale: 60%

   A pulse and its discrete Fourier transform, output from
   the example program.

.. index::
   single: FFT of complex data, mixed-radix algorithm
   single: Mixed-radix FFT, complex data

Mixed-radix FFT routines for complex data
=========================================

This section describes mixed-radix FFT algorithms for complex data.  The
mixed-radix functions work for FFTs of any length.  They are a
reimplementation of Paul Swarztrauber's Fortran |fftpack| library.
The theory is explained in the review article "Self-sorting
Mixed-radix FFTs" by Clive Temperton.  The routines here use the same
indexing scheme and basic algorithms as |fftpack|.

The mixed-radix algorithm is based on sub-transform modules---highly
optimized small length FFTs which are combined to create larger FFTs.
There are efficient modules for factors of 2, 3, 4, 5, 6 and 7.  The
modules for the composite factors of 4 and 6 are faster than combining
the modules for :math:`2*2` and :math:`2*3`.

For factors which are not implemented as modules there is a fall-back to
a general length-:math:`n` module which uses Singleton's method for
efficiently computing a DFT. This module is :math:`O(n^2)`, and slower
than a dedicated module would be but works for any length :math:`n`.  Of
course, lengths which use the general length-:math:`n` module will still
be factorized as much as possible.  For example, a length of 143 will be
factorized into :math:`11*13`.  Large prime factors are the worst case
scenario, e.g. as found in :math:`n=2*3*99991`, and should be avoided
because their :math:`O(n^2)` scaling will dominate the run-time (consult
the document "GSL FFT Algorithms" included in the GSL distribution
if you encounter this problem).

The mixed-radix initialization function :func:`gsl_fft_complex_wavetable_alloc`
returns the list of factors chosen by the library for a given length
:math:`n`.  It can be used to check how well the length has been
factorized, and estimate the run-time.  To a first approximation the
run-time scales as :math:`n \sum f_i`, where the :math:`f_i` are the
factors of :math:`n`.  For programs under user control you may wish to
issue a warning that the transform will be slow when the length is
poorly factorized.  If you frequently encounter data lengths which
cannot be factorized using the existing small-prime modules consult
"GSL FFT Algorithms" for details on adding support for other
factors.

.. First, the space for the trigonometric lookup tables and scratch area is
.. allocated by a call to one of the :code:`alloc` functions.  We
.. call the combination of factorization, scratch space and trigonometric
.. lookup arrays a *wavetable*.  It contains the sine and cosine
.. waveforms for the all the frequencies that will be used in the FFT.

.. The wavetable is initialized by a call to the corresponding :code:`init`
.. function.  It factorizes the data length, using the implemented
.. subtransforms as preferred factors wherever possible.  The trigonometric
.. lookup table for the chosen factorization is also computed.

.. An FFT is computed by a call to one of the :code:`forward`,
.. :code:`backward` or :code:`inverse` functions, with the data, length and
.. wavetable as arguments.

All the functions described in this section are declared in the header
file :file:`gsl_fft_complex.h`.

.. function:: gsl_fft_complex_wavetable * gsl_fft_complex_wavetable_alloc (size_t n)

   This function prepares a trigonometric lookup table for a complex FFT of
   length :data:`n`. The function returns a pointer to the newly allocated
   :type:`gsl_fft_complex_wavetable` if no errors were detected, and a null
   pointer in the case of error.  The length :data:`n` is factorized into a
   product of subtransforms, and the factors and their trigonometric
   coefficients are stored in the wavetable. The trigonometric coefficients
   are computed using direct calls to :code:`sin` and :code:`cos`, for
   accuracy.  Recursion relations could be used to compute the lookup table
   faster, but if an application performs many FFTs of the same length then
   this computation is a one-off overhead which does not affect the final
   throughput.

   The wavetable structure can be used repeatedly for any transform of the
   same length.  The table is not modified by calls to any of the other FFT
   functions.  The same wavetable can be used for both forward and backward
   (or inverse) transforms of a given length.

.. function:: void gsl_fft_complex_wavetable_free (gsl_fft_complex_wavetable * wavetable)

   This function frees the memory associated with the wavetable
   :data:`wavetable`.  The wavetable can be freed if no further FFTs of the
   same length will be needed.

These functions operate on a :type:`gsl_fft_complex_wavetable` structure
which contains internal parameters for the FFT.  It is not necessary to
set any of the components directly but it can sometimes be useful to
examine them.  For example, the chosen factorization of the FFT length
is given and can be used to provide an estimate of the run-time or
numerical error. The wavetable structure is declared in the header file
:file:`gsl_fft_complex.h`.

.. type:: gsl_fft_complex_wavetable

   This is a structure that holds the factorization and trigonometric
   lookup tables for the mixed radix fft algorithm.  It has the following
   components:

   ================================= ==============================================================================================
   :code:`size_t n`                  This is the number of complex data points
   :code:`size_t nf`                 This is the number of factors that the length :code:`n` was decomposed into.
   :code:`size_t factor[64]`         This is the array of factors.  Only the first :code:`nf` elements are used. 
   :code:`gsl_complex * trig`        This is a pointer to a preallocated trigonometric lookup table of :code:`n` complex elements.
   :code:`gsl_complex * twiddle[64]` This is an array of pointers into :code:`trig`, giving the twiddle factors for each pass.
   ================================= ==============================================================================================

.. (FIXME: factor[64] is a fixed length array and therefore probably in
.. violation of the GNU Coding Standards).

.. type:: gsl_fft_complex_workspace

   The mixed radix algorithms require additional working space to hold
   the intermediate steps of the transform.

.. function:: gsl_fft_complex_workspace * gsl_fft_complex_workspace_alloc (size_t n)

   This function allocates a workspace for a complex transform of length
   :data:`n`.

.. function:: void gsl_fft_complex_workspace_free (gsl_fft_complex_workspace * workspace)

   This function frees the memory associated with the workspace
   :data:`workspace`. The workspace can be freed if no further FFTs of the
   same length will be needed.

The following functions compute the transform,

.. function:: int gsl_fft_complex_forward (gsl_complex_packed_array data, size_t stride, size_t n, const gsl_fft_complex_wavetable * wavetable, gsl_fft_complex_workspace * work)
              int gsl_fft_complex_transform (gsl_complex_packed_array data, size_t stride, size_t n, const gsl_fft_complex_wavetable * wavetable, gsl_fft_complex_workspace * work, gsl_fft_direction sign)
              int gsl_fft_complex_backward (gsl_complex_packed_array data, size_t stride, size_t n, const gsl_fft_complex_wavetable * wavetable, gsl_fft_complex_workspace * work)
              int gsl_fft_complex_inverse (gsl_complex_packed_array data, size_t stride, size_t n, const gsl_fft_complex_wavetable * wavetable, gsl_fft_complex_workspace * work)

   These functions compute forward, backward and inverse FFTs of length
   :data:`n` with stride :data:`stride`, on the packed complex array
   :data:`data`, using a mixed radix decimation-in-frequency algorithm.
   There is no restriction on the length :data:`n`.  Efficient modules are
   provided for subtransforms of length 2, 3, 4, 5, 6 and 7.  Any remaining
   factors are computed with a slow, :math:`O(n^2)`, general-:math:`n`
   module. The caller must supply a :data:`wavetable` containing the
   trigonometric lookup tables and a workspace :data:`work`.  For the
   :code:`transform` version of the function the :data:`sign` argument can be
   either :code:`forward` (:math:`-1`) or :code:`backward` (:math:`+1`).

   The functions return a value of :code:`0` if no errors were detected. The
   following :data:`gsl_errno` conditions are defined for these functions:

   =================================== =========================================================================================================
   :macro:`GSL_EDOM`                   The length of the data :data:`n` is not a positive integer (i.e. :data:`n` is zero).
   :macro:`GSL_EINVAL`                 The length of the data :data:`n` and the length used to compute the given :data:`wavetable` do not match.
   =================================== =========================================================================================================

Here is an example program which computes the FFT of a short pulse in a
sample of length 630 (:math:`=2*3*3*5*7`) using the mixed-radix
algorithm.

.. include:: examples/fftmr.c
   :code:

Note that we have assumed that the program is using the default
:code:`gsl` error handler (which calls :func:`abort` for any errors).  If
you are not using a safe error handler you would need to check the
return status of all the :code:`gsl` routines.

.. index:: FFT of real data

Overview of real data FFTs
==========================

The functions for real data are similar to those for complex data.
However, there is an important difference between forward and inverse
transforms.  The Fourier transform of a real sequence is not real.  It is
a complex sequence with a special symmetry:

.. math:: z_k = z_{n-k}^*

A sequence with this symmetry is called *conjugate-complex* or
*half-complex*.  This different structure requires different
storage layouts for the forward transform (from real to half-complex)
and inverse transform (from half-complex back to real).  As a
consequence the routines are divided into two sets: functions in
:code:`gsl_fft_real` which operate on real sequences and functions in
:code:`gsl_fft_halfcomplex` which operate on half-complex sequences.

Functions in :code:`gsl_fft_real` compute the frequency coefficients of a
real sequence.  The half-complex coefficients :math:`c` of a real sequence
:math:`x` are given by Fourier analysis,

.. math:: c_k = \sum_{j=0}^{n-1} x_j \exp(-2 \pi i j k /n)

Functions in :code:`gsl_fft_halfcomplex` compute inverse or backwards
transforms.  They reconstruct real sequences by Fourier synthesis from
their half-complex frequency coefficients, :math:`c`,

.. math:: x_j = {1 \over n} \sum_{k=0}^{n-1} c_k \exp(2 \pi i j k /n)

The symmetry of the half-complex sequence implies that only half of the
complex numbers in the output need to be stored.  The remaining half can
be reconstructed using the half-complex symmetry condition. This works
for all lengths, even and odd---when the length is even the middle value
where :math:`k=n/2` is also real.  Thus only :data:`n` real numbers are
required to store the half-complex sequence, and the transform of a real
sequence can be stored in the same size array as the original data.

The precise storage arrangements depend on the algorithm, and are
different for radix-2 and mixed-radix routines.  The radix-2 function
operates in-place, which constrains the locations where each element can
be stored.  The restriction forces real and imaginary parts to be stored
far apart.  The mixed-radix algorithm does not have this restriction, and
it stores the real and imaginary parts of a given term in neighboring
locations (which is desirable for better locality of memory accesses).

.. index::
   single: FFT of real data, radix-2 algorithm
   single: Radix-2 FFT for real data

Radix-2 FFT routines for real data
==================================

This section describes radix-2 FFT algorithms for real data.  They use
the Cooley-Tukey algorithm to compute in-place FFTs for lengths which
are a power of 2. 

The radix-2 FFT functions for real data are declared in the header files
:file:`gsl_fft_real.h` 

.. function:: int gsl_fft_real_radix2_transform (double data[], size_t stride, size_t n)

   This function computes an in-place radix-2 FFT of length :data:`n` and
   stride :data:`stride` on the real array :data:`data`.  The output is a
   half-complex sequence, which is stored in-place.  The arrangement of the
   half-complex terms uses the following scheme: for :math:`k < n/2` the
   real part of the :math:`k`-th term is stored in location :math:`k`, and
   the corresponding imaginary part is stored in location :math:`n-k`.  Terms
   with :math:`k > n/2` can be reconstructed using the symmetry 
   :math:`z_k = z^*_{n-k}`.
   The terms for :math:`k=0` and :math:`k=n/2` are both purely
   real, and count as a special case.  Their real parts are stored in
   locations :math:`0` and :math:`n/2` respectively, while their imaginary
   parts which are zero are not stored.

   The following table shows the correspondence between the output
   :data:`data` and the equivalent results obtained by considering the input
   data as a complex sequence with zero imaginary part (assuming :data:`stride` = 1})::

      complex[0].real    =    data[0] 
      complex[0].imag    =    0 
      complex[1].real    =    data[1] 
      complex[1].imag    =    data[n-1]
      ...............         ................
      complex[k].real    =    data[k]
      complex[k].imag    =    data[n-k] 
      ...............         ................
      complex[n/2].real  =    data[n/2]
      complex[n/2].imag  =    0
      ...............         ................
      complex[k'].real   =    data[k]        k' = n - k
      complex[k'].imag   =   -data[n-k] 
      ...............         ................
      complex[n-1].real  =    data[1]
      complex[n-1].imag  =   -data[n-1]

   Note that the output data can be converted into the full complex
   sequence using the function :func:`gsl_fft_halfcomplex_radix2_unpack`
   described below.

The radix-2 FFT functions for halfcomplex data are declared in the
header file :file:`gsl_fft_halfcomplex.h`.

.. function:: int gsl_fft_halfcomplex_radix2_inverse (double data[], size_t stride, size_t n)
              int gsl_fft_halfcomplex_radix2_backward (double data[], size_t stride, size_t n)

   These functions compute the inverse or backwards in-place radix-2 FFT of
   length :data:`n` and stride :data:`stride` on the half-complex sequence
   :data:`data` stored according the output scheme used by
   :func:`gsl_fft_real_radix2`.  The result is a real array stored in natural
   order.

.. function:: int gsl_fft_halfcomplex_radix2_unpack (const double halfcomplex_coefficient[], gsl_complex_packed_array complex_coefficient, size_t stride, size_t n)

   This function converts :data:`halfcomplex_coefficient`, an array of
   half-complex coefficients as returned by :func:`gsl_fft_real_radix2_transform`, into an ordinary complex array, :data:`complex_coefficient`.  It fills in the
   complex array using the symmetry :math:`z_k = z_{n-k}^*`
   to reconstruct the redundant elements.  The algorithm for the conversion
   is::

      complex_coefficient[0].real = halfcomplex_coefficient[0];
      complex_coefficient[0].imag = 0.0;

      for (i = 1; i < n - i; i++)
        {
          double hc_real = halfcomplex_coefficient[i*stride];
          double hc_imag = halfcomplex_coefficient[(n-i)*stride];
          complex_coefficient[i*stride].real = hc_real;
          complex_coefficient[i*stride].imag = hc_imag;
          complex_coefficient[(n - i)*stride].real = hc_real;
          complex_coefficient[(n - i)*stride].imag = -hc_imag;
        }

      if (i == n - i)
        {
          complex_coefficient[i*stride].real = halfcomplex_coefficient[(n - 1)*stride];
          complex_coefficient[i*stride].imag = 0.0;
        }

.. index::
   single: FFT of real data, mixed-radix algorithm
   single: Mixed-radix FFT, real data

Mixed-radix FFT routines for real data
======================================

This section describes mixed-radix FFT algorithms for real data.  The
mixed-radix functions work for FFTs of any length.  They are a
reimplementation of the real-FFT routines in the Fortran |fftpack| library
by Paul Swarztrauber.  The theory behind the algorithm is explained in
the article "Fast Mixed-Radix Real Fourier Transforms" by Clive
Temperton.  The routines here use the same indexing scheme and basic
algorithms as |fftpack|.

The functions use the |fftpack| storage convention for half-complex
sequences.  In this convention the half-complex transform of a real
sequence is stored with frequencies in increasing order, starting at
zero, with the real and imaginary parts of each frequency in neighboring
locations.  When a value is known to be real the imaginary part is not
stored.  The imaginary part of the zero-frequency component is never
stored.  It is known to be zero (since the zero frequency component is
simply the sum of the input data (all real)).  For a sequence of even
length the imaginary part of the frequency :math:`n/2` is not stored
either, since the symmetry :math:`z_k = z_{n-k}^*`
implies that this is purely real too.

The storage scheme is best shown by some examples.  The table below
shows the output for an odd-length sequence, :math:`n=5`.  The two columns
give the correspondence between the 5 values in the half-complex
sequence returned by :func:`gsl_fft_real_transform`, :data:`halfcomplex[]` and the
values :data:`complex[]` that would be returned if the same real input
sequence were passed to :func:`gsl_fft_complex_backward` as a complex
sequence (with imaginary parts set to :code:`0`)::

  complex[0].real  =  halfcomplex[0] 
  complex[0].imag  =  0
  complex[1].real  =  halfcomplex[1] 
  complex[1].imag  =  halfcomplex[2]
  complex[2].real  =  halfcomplex[3]
  complex[2].imag  =  halfcomplex[4]
  complex[3].real  =  halfcomplex[3]
  complex[3].imag  = -halfcomplex[4]
  complex[4].real  =  halfcomplex[1]
  complex[4].imag  = -halfcomplex[2]

The upper elements of the :data:`complex` array, :code:`complex[3]` and
:code:`complex[4]` are filled in using the symmetry condition.  The
imaginary part of the zero-frequency term :code:`complex[0].imag` is
known to be zero by the symmetry.

The next table shows the output for an even-length sequence, :math:`n=6`.
In the even case there are two values which are purely real::

  complex[0].real  =  halfcomplex[0]
  complex[0].imag  =  0
  complex[1].real  =  halfcomplex[1] 
  complex[1].imag  =  halfcomplex[2] 
  complex[2].real  =  halfcomplex[3] 
  complex[2].imag  =  halfcomplex[4] 
  complex[3].real  =  halfcomplex[5] 
  complex[3].imag  =  0 
  complex[4].real  =  halfcomplex[3] 
  complex[4].imag  = -halfcomplex[4]
  complex[5].real  =  halfcomplex[1] 
  complex[5].imag  = -halfcomplex[2] 

The upper elements of the :data:`complex` array, :code:`complex[4]` and
:code:`complex[5]` are filled in using the symmetry condition.  Both
:code:`complex[0].imag` and :code:`complex[3].imag` are known to be zero.

All these functions are declared in the header files
:file:`gsl_fft_real.h` and :file:`gsl_fft_halfcomplex.h`.

.. type:: gsl_fft_real_wavetable
          gsl_fft_halfcomplex_wavetable

   These data structures contain lookup tables for an FFT of a fixed size.

.. function:: gsl_fft_real_wavetable * gsl_fft_real_wavetable_alloc (size_t n)
              gsl_fft_halfcomplex_wavetable * gsl_fft_halfcomplex_wavetable_alloc (size_t n)

   These functions prepare trigonometric lookup tables for an FFT of size
   :math:`n` real elements.  The functions return a pointer to the newly
   allocated struct if no errors were detected, and a null pointer in the
   case of error.  The length :data:`n` is factorized into a product of
   subtransforms, and the factors and their trigonometric coefficients are
   stored in the wavetable. The trigonometric coefficients are computed
   using direct calls to :code:`sin` and :code:`cos`, for accuracy.
   Recursion relations could be used to compute the lookup table faster,
   but if an application performs many FFTs of the same length then
   computing the wavetable is a one-off overhead which does not affect the
   final throughput.

   The wavetable structure can be used repeatedly for any transform of the
   same length.  The table is not modified by calls to any of the other FFT
   functions.  The appropriate type of wavetable must be used for forward
   real or inverse half-complex transforms.

.. function:: void gsl_fft_real_wavetable_free (gsl_fft_real_wavetable * wavetable)
              void gsl_fft_halfcomplex_wavetable_free (gsl_fft_halfcomplex_wavetable * wavetable)

   These functions free the memory associated with the wavetable
   :data:`wavetable`. The wavetable can be freed if no further FFTs of the
   same length will be needed.

The mixed radix algorithms require additional working space to hold
the intermediate steps of the transform,

.. type:: gsl_fft_real_workspace

   This workspace contains parameters needed to compute a real FFT.

.. function:: gsl_fft_real_workspace * gsl_fft_real_workspace_alloc (size_t n)

   This function allocates a workspace for a real transform of length
   :data:`n`.  The same workspace can be used for both forward real and inverse
   halfcomplex transforms.

.. function:: void gsl_fft_real_workspace_free (gsl_fft_real_workspace * workspace)

   This function frees the memory associated with the workspace
   :data:`workspace`. The workspace can be freed if no further FFTs of the
   same length will be needed.

The following functions compute the transforms of real and half-complex
data,

.. function:: int gsl_fft_real_transform (double data[], size_t stride, size_t n, const gsl_fft_real_wavetable * wavetable, gsl_fft_real_workspace * work)
              int gsl_fft_halfcomplex_transform (double data[], size_t stride, size_t n, const gsl_fft_halfcomplex_wavetable * wavetable, gsl_fft_real_workspace * work)

   These functions compute the FFT of :data:`data`, a real or half-complex
   array of length :data:`n`, using a mixed radix decimation-in-frequency
   algorithm.  For :func:`gsl_fft_real_transform` :data:`data` is an array of
   time-ordered real data.  For :func:`gsl_fft_halfcomplex_transform`
   :data:`data` contains Fourier coefficients in the half-complex ordering
   described above.  There is no restriction on the length :data:`n`.
   Efficient modules are provided for subtransforms of length 2, 3, 4 and
   5.  Any remaining factors are computed with a slow, :math:`O(n^2)`,
   general-n module.  The caller must supply a :data:`wavetable` containing
   trigonometric lookup tables and a workspace :data:`work`. 

.. function:: int gsl_fft_real_unpack (const double real_coefficient[], gsl_complex_packed_array complex_coefficient, size_t stride, size_t n)

   This function converts a single real array, :data:`real_coefficient` into
   an equivalent complex array, :data:`complex_coefficient`, (with imaginary
   part set to zero), suitable for :code:`gsl_fft_complex` routines.  The
   algorithm for the conversion is simply::

      for (i = 0; i < n; i++)
        {
          complex_coefficient[i*stride].real = real_coefficient[i*stride];
          complex_coefficient[i*stride].imag = 0.0;
        }

.. function:: int gsl_fft_halfcomplex_unpack (const double halfcomplex_coefficient[], gsl_complex_packed_array complex_coefficient, size_t stride, size_t n)

   This function converts :data:`halfcomplex_coefficient`, an array of
   half-complex coefficients as returned by :func:`gsl_fft_real_transform`, into an
   ordinary complex array, :data:`complex_coefficient`.  It fills in the
   complex array using the symmetry :math:`z_k = z_{n-k}^*`
   to reconstruct the redundant elements.  The algorithm for the conversion
   is::

      complex_coefficient[0].real = halfcomplex_coefficient[0];
      complex_coefficient[0].imag = 0.0;

      for (i = 1; i < n - i; i++)
        {
          double hc_real = halfcomplex_coefficient[(2 * i - 1)*stride];
          double hc_imag = halfcomplex_coefficient[(2 * i)*stride];
          complex_coefficient[i*stride].real = hc_real;
          complex_coefficient[i*stride].imag = hc_imag;
          complex_coefficient[(n - i)*stride].real = hc_real;
          complex_coefficient[(n - i)*stride].imag = -hc_imag;
        }

      if (i == n - i)
        {
          complex_coefficient[i*stride].real = halfcomplex_coefficient[(n - 1)*stride];
          complex_coefficient[i*stride].imag = 0.0;
        }

Here is an example program using :func:`gsl_fft_real_transform` and
:func:`gsl_fft_halfcomplex_inverse`.  It generates a real signal in the
shape of a square pulse.  The pulse is Fourier transformed to frequency
space, and all but the lowest ten frequency components are removed from
the array of Fourier coefficients returned by
:func:`gsl_fft_real_transform`.

The remaining Fourier coefficients are transformed back to the
time-domain, to give a filtered version of the square pulse.  Since
Fourier coefficients are stored using the half-complex symmetry both
positive and negative frequencies are removed and the final filtered
signal is also real.

.. include:: examples/fftreal.c
   :code:

The program output is shown in :numref:`fig_fft-real-mixedradix`.

.. _fig_fft-real-mixedradix:

.. figure:: /images/fft-real-mixedradix.png
   :scale: 100%

   Low-pass filtered version of a real pulse, output from the example program.

.. _fft-references:

References and Further Reading
==============================

A good starting point for learning more about the FFT is the following review
article,

* P. Duhamel and M. Vetterli.
  Fast Fourier transforms: A tutorial review and a state of the art.
  Signal Processing, 19:259--299, 1990.

To find out about the algorithms used in the GSL routines you may want
to consult the document "GSL FFT Algorithms" (it is included
in GSL, as :file:`doc/fftalgorithms.tex`).  This has general information
on FFTs and explicit derivations of the implementation for each
routine.  There are also references to the relevant literature.  For
convenience some of the more important references are reproduced below.

There are several introductory books on the FFT with example programs,
such as "The Fast Fourier Transform" by Brigham and "DFT/FFT
and Convolution Algorithms" by Burrus and Parks,

* E. Oran Brigham. "The Fast Fourier Transform".  Prentice Hall, 1974.

* C. S. Burrus and T. W. Parks.  "DFT/FFT and Convolution Algorithms",
  Wiley, 1984.

Both these introductory books cover the radix-2 FFT in some detail.
The mixed-radix algorithm at the heart of the |fftpack| routines is
reviewed in Clive Temperton's paper,

* Clive Temperton, Self-sorting mixed-radix fast Fourier transforms,
  Journal of Computational Physics, 52(1):1--23, 1983.

The derivation of FFTs for real-valued data is explained in the
following two articles,

* Henrik V. Sorenson, Douglas L. Jones, Michael T. Heideman, and C. Sidney
  Burrus.  Real-valued fast Fourier transform algorithms.
  "IEEE Transactions on Acoustics, Speech, and Signal Processing",
  ASSP-35(6):849--863, 1987.

* Clive Temperton.  Fast mixed-radix real Fourier transforms.
  "Journal of Computational Physics", 52:340--350, 1983.

In 1979 the IEEE published a compendium of carefully-reviewed Fortran
FFT programs in "Programs for Digital Signal Processing".  It is a
useful reference for implementations of many different FFT
algorithms,

* Digital Signal Processing Committee and IEEE Acoustics, Speech, and Signal
  Processing Committee, editors.
  Programs for Digital Signal Processing. IEEE Press, 1979.

For large-scale FFT work we recommend the use of the dedicated FFTW library
by Frigo and Johnson.  The FFTW library is self-optimizing---it
automatically tunes itself for each hardware platform in order to
achieve maximum performance.  It is available under the GNU GPL.

* FFTW Website, http://www.fftw.org/

The source code for |fftpack| is available from http://www.netlib.org/fftpack/
.. index:: IEEE floating point 

.. _chap_ieee:

******************************
IEEE floating-point arithmetic
******************************

This chapter describes functions for examining the representation of
floating point numbers and controlling the floating point environment of
your program.  The functions described in this chapter are declared in
the header file :file:`gsl_ieee_utils.h`.

.. index::
   single: IEEE format for floating point numbers
   single: bias, IEEE format
   single: exponent, IEEE format
   single: sign bit, IEEE format
   single: mantissa, IEEE format

Representation of floating point numbers
========================================

The IEEE Standard for Binary Floating-Point Arithmetic defines binary
formats for single and double precision numbers.  Each number is composed
of three parts: a *sign bit* (:math:`s`), an *exponent*
(:math:`E`) and a *fraction* (:math:`f`).  The numerical value of the
combination :math:`(s,E,f)` is given by the following formula,

.. only:: not texinfo

   .. math:: (-1)^s (1 \cdot fffff\dots) 2^E

.. only:: texinfo

   ::

      (-1)^s (1.fffff...) 2^E

.. index::
   single: normalized form, IEEE format
   single: denormalized form, IEEE format

The sign bit is either zero or one.  The exponent ranges from a minimum value
:math:`E_{min}`
to a maximum value
:math:`E_{max}`
depending on the precision.  The exponent is converted to an 
unsigned number
:math:`e`, known as the *biased exponent*, for storage by adding a
*bias* parameter,

.. only:: not texinfo

   .. math:: e = E + \hbox{\it bias}

.. only:: texinfo
   
   ::

      e = E + bias

The sequence :math:`fffff...` represents the digits of the binary
fraction :math:`f`.  The binary digits are stored in *normalized
form*, by adjusting the exponent to give a leading digit of :math:`1`. 
Since the leading digit is always 1 for normalized numbers it is
assumed implicitly and does not have to be stored.
Numbers smaller than 
:math:`2^{E_{min}}`
are be stored in *denormalized form* with a leading zero,

.. only:: not texinfo

   .. math:: (-1)^s (0 \cdot fffff\dots) 2^{E_{min}}

.. only:: texinfo

   ::

      (-1)^s (0.fffff...) 2^(E_min)

.. index::
   single: zero, IEEE format
   single: infinity, IEEE format

This allows gradual underflow down to 
:math:`2^{E_{min} - p}`
for :math:`p` bits of precision. 
A zero is encoded with the special exponent of 
:math:`2^{E_{min}-1}`
and infinities with the exponent of 
:math:`2^{E_{max}+1}`.

.. index::
   single: single precision, IEEE format

The format for single precision numbers uses 32 bits divided in the
following way::

  seeeeeeeefffffffffffffffffffffff
    
  s = sign bit, 1 bit
  e = exponent, 8 bits  (E_min=-126, E_max=127, bias=127)
  f = fraction, 23 bits

.. index::
   single: double precision, IEEE format

The format for double precision numbers uses 64 bits divided in the
following way::

  seeeeeeeeeeeffffffffffffffffffffffffffffffffffffffffffffffffffff

  s = sign bit, 1 bit
  e = exponent, 11 bits  (E_min=-1022, E_max=1023, bias=1023)
  f = fraction, 52 bits

It is often useful to be able to investigate the behavior of a
calculation at the bit-level and the library provides functions for
printing the IEEE representations in a human-readable form.

.. float vs double vs long double 
.. (how many digits are available for each)

.. function:: void gsl_ieee_fprintf_float (FILE * stream, const float * x)
              void gsl_ieee_fprintf_double (FILE * stream, const double * x)

   These functions output a formatted version of the IEEE floating-point
   number pointed to by :data:`x` to the stream :data:`stream`. A pointer is
   used to pass the number indirectly, to avoid any undesired promotion
   from :code:`float` to :code:`double`.  The output takes one of the
   following forms,

   :code:`NaN`

      the Not-a-Number symbol

   :code:`Inf, -Inf`

      positive or negative infinity

   :code:`1.fffff...*2^E, -1.fffff...*2^E`

      a normalized floating point number

   :code:`0.fffff...*2^E, -0.fffff...*2^E`

      a denormalized floating point number

   :code:`0, -0`

      positive or negative zero

   The output can be used directly in GNU Emacs Calc mode by preceding it
   with :code:`2#` to indicate binary.

.. @item [non-standard IEEE float], [non-standard IEEE double]
.. an unrecognized encoding

.. function:: void gsl_ieee_printf_float (const float * x)
              void gsl_ieee_printf_double (const double * x)

   These functions output a formatted version of the IEEE floating-point
   number pointed to by :data:`x` to the stream :code:`stdout`.

The following program demonstrates the use of the functions by printing
the single and double precision representations of the fraction
:math:`1/3`.  For comparison the representation of the value promoted from
single to double precision is also printed.

.. include:: examples/ieee.c
   :code:

The binary representation of :math:`1/3` is :math:`0.01010101...`.  The
output below shows that the IEEE format normalizes this fraction to give
a leading digit of 1::

   f= 1.01010101010101010101011*2^-2
  fd= 1.0101010101010101010101100000000000000000000000000000*2^-2
   d= 1.0101010101010101010101010101010101010101010101010101*2^-2

The output also shows that a single-precision number is promoted to
double-precision by adding zeros in the binary representation.

.. importance of using 1.234L in long double calculations

.. @example
.. int main (void)
.. @{
..   long double x = 1.0, y = 1.0;
  
..   x = x + 0.2;
..   y = y + 0.2L;

..   printf(" d %.20Lf\n",x);
..   printf("ld %.20Lf\n",y);

..   return 1;
.. @}

..  d 1.20000000000000001110
.. ld 1.20000000000000000004
.. @end example

.. index::
   single: IEEE exceptions
   single: precision, IEEE arithmetic
   single: rounding mode
   single: arithmetic exceptions
   single: exceptions, IEEE arithmetic
   single: division by zero, IEEE exceptions
   single: underflow, IEEE exceptions
   single: overflow, IEEE exceptions

Setting up your IEEE environment
================================

The IEEE standard defines several *modes* for controlling the
behavior of floating point operations.  These modes specify the important
properties of computer arithmetic: the direction used for rounding (e.g.
whether numbers should be rounded up, down or to the nearest number),
the rounding precision and how the program should handle arithmetic
exceptions, such as division by zero.

Many of these features can now be controlled via standard functions such
as :func:`fpsetround`, which should be used whenever they are available.
Unfortunately in the past there has been no universal API for
controlling their behavior---each system has had its own low-level way
of accessing them.  To help you write portable programs GSL allows you
to specify modes in a platform-independent way using the environment
variable :macro:`GSL_IEEE_MODE`.  The library then takes care of all the
necessary machine-specific initializations for you when you call the
function :func:`gsl_ieee_env_setup`.

.. macro:: GSL_IEEE_MODE

   Environment variable which specifies IEEE mode.

.. function:: void gsl_ieee_env_setup ()

   This function reads the environment variable :macro:`GSL_IEEE_MODE` and
   attempts to set up the corresponding specified IEEE modes.  The
   environment variable should be a list of keywords, separated by
   commas, like this::

      GSL_IEEE_MODE = "keyword, keyword, ..."

   where :data:`keyword` is one of the following mode-names::

     single-precision
     double-precision
     extended-precision
     round-to-nearest
     round-down
     round-up
     round-to-zero
     mask-all
     mask-invalid
     mask-denormalized
     mask-division-by-zero
     mask-overflow
     mask-underflow
     trap-inexact
     trap-common

   If :macro:`GSL_IEEE_MODE` is empty or undefined then the function returns
   immediately and no attempt is made to change the system's IEEE
   mode.  When the modes from :macro:`GSL_IEEE_MODE` are turned on the
   function prints a short message showing the new settings to remind you
   that the results of the program will be affected.

   If the requested modes are not supported by the platform being used then
   the function calls the error handler and returns an error code of
   :macro:`GSL_EUNSUP`.

   When options are specified using this method, the resulting mode is
   based on a default setting of the highest available precision (double
   precision or extended precision, depending on the platform) in
   round-to-nearest mode, with all exceptions enabled apart from the
   INEXACT exception.  The INEXACT exception is generated
   whenever rounding occurs, so it must generally be disabled in typical
   scientific calculations.  All other floating-point exceptions are
   enabled by default, including underflows and the use of denormalized
   numbers, for safety.  They can be disabled with the individual
   :code:`mask-` settings or together using :code:`mask-all`.

   The following adjusted combination of modes is convenient for many
   purposes::

      GSL_IEEE_MODE="double-precision,"\
                      "mask-underflow,"\
                        "mask-denormalized"

   This choice ignores any errors relating to small numbers (either
   denormalized, or underflowing to zero) but traps overflows, division by
   zero and invalid operations.

   Note that on the x86 series of processors this function sets both the
   original x87 mode and the newer MXCSR mode, which controls SSE
   floating-point operations.  The SSE floating-point units do not have a
   precision-control bit, and always work in double-precision.  The
   single-precision and extended-precision keywords have no effect in
   this case.

To demonstrate the effects of different rounding modes consider the
following program which computes :math:`e`, the base of natural
logarithms, by summing a rapidly-decreasing series,

.. only:: not texinfo

   .. math::

      e &= {1 \over 0!} + {1 \over 1!} + {1 \over 2!} + {1 \over 3!} + {1 \over 4!} + \dots \\
        &= 2.71828182846...

.. only:: texinfo

   ::

      e = 1 + 1/2! + 1/3! + 1/4! + ... 
        = 2.71828182846...

.. include:: examples/ieeeround.c
   :code:

Here are the results of running the program in :code:`round-to-nearest`
mode.  This is the IEEE default so it isn't really necessary to specify
it here::

  $ GSL_IEEE_MODE="round-to-nearest" ./a.out 
  i= 1 sum=1.000000000000000000 error=-1.71828
  i= 2 sum=2.000000000000000000 error=-0.718282
  ....
  i=18 sum=2.718281828459045535 error=4.44089e-16
  i=19 sum=2.718281828459045535 error=4.44089e-16

After nineteen terms the sum converges to within :math:`4 \times 10^{-16}`
of the correct value.  
If we now change the rounding mode to
:code:`round-down` the final result is less accurate::

  $ GSL_IEEE_MODE="round-down" ./a.out 
  i= 1 sum=1.000000000000000000 error=-1.71828
  ....
  i=19 sum=2.718281828459041094 error=-3.9968e-15

The result is about 
:math:`4 \times 10^{-15}`
below the correct value, an order of magnitude worse than the result
obtained in the :code:`round-to-nearest` mode.

If we change to rounding mode to :code:`round-up` then the final result
is higher than the correct value (when we add each term to the sum the
final result is always rounded up, which increases the sum by at least
one tick until the added term underflows to zero).  To avoid this
problem we would need to use a safer converge criterion, such as
:code:`while (fabs(sum - oldsum) > epsilon)`, with a suitably chosen
value of epsilon.

Finally we can see the effect of computing the sum using
single-precision rounding, in the default :code:`round-to-nearest`
mode.  In this case the program thinks it is still using double precision
numbers but the CPU rounds the result of each floating point operation
to single-precision accuracy.  This simulates the effect of writing the
program using single-precision :code:`float` variables instead of
:code:`double` variables.  The iteration stops after about half the number
of iterations and the final result is much less accurate::

  $ GSL_IEEE_MODE="single-precision" ./a.out 
  ....
  i=12 sum=2.718281984329223633 error=1.5587e-07

with an error of 
:math:`O(10^{-7})`,
which corresponds to single
precision accuracy (about 1 part in :math:`10^7`).  Continuing the
iterations further does not decrease the error because all the
subsequent results are rounded to the same value.

References and Further Reading
==============================

The reference for the IEEE standard is,

* ANSI/IEEE Std 754-1985, IEEE Standard for Binary Floating-Point Arithmetic.

A more pedagogical introduction to the standard can be found in the
following paper,

* David Goldberg: What Every Computer Scientist Should Know About
  Floating-Point Arithmetic. *ACM Computing Surveys*, Vol.: 23, No.: 1
  (March 1991), pages 5--48.

* Corrigendum: *ACM Computing Surveys*, Vol.: 23, No.: 3 (September
  1991), page 413. and see also the sections by B. A. Wichmann and Charles
  B. Dunham in Surveyor's Forum: "What Every Computer Scientist Should
  Know About Floating-Point Arithmetic". *ACM Computing Surveys*,
  Vol.: 24, No.: 3 (September 1992), page 319.

A detailed textbook on IEEE arithmetic and its practical use is
available from SIAM Press,

* Michael L. Overton, *Numerical Computing with IEEE Floating Point Arithmetic*,
  SIAM Press, ISBN 0898715717.
.. index::
   single: moving window statistics
   single: statistics, moving window
   single: online statistics

************************
Moving Window Statistics
************************

This chapter describes routines for computing *moving window
statistics* (also called rolling statistics and running statistics),
using a window around a sample which is used to calculate various
local statistical properties of an input data stream. The window is
then slid forward by one sample to process the next data point and so on.

The functions described in this chapter are declared in the header file
:file:`gsl_movstat.h`.

Introduction
============

This chapter is concerned with calculating various statistics from
subsets of a given dataset. The main idea is to compute statistics
in the vicinity of a given data sample by defining a *window* which
includes the sample itself as well as some specified number of samples
before and after the sample in question. For a sample :math:`x_i`, we
define a window :math:`W_i^{H,J}` as

.. only:: not texinfo

   .. math:: W_i^{H,J} = \left\{ x_{i-H}, \dots, x_i, \dots, x_{i+J} \right\}

.. only:: texinfo

   ::

      W_i^{H,J} = {x_{i-H},...,x_i,...,x_{i+J}}

The parameters :math:`H` and :math:`J` are non-negative integers specifying
the number of samples to include before and after the sample :math:`x_i`.
Statistics such as the mean and standard deviation of the window :math:`W_i^{H,J}`
may be computed, and then the window is shifted forward by one sample to
focus on :math:`x_{i+1}`. The total number of samples in the window is
:math:`K = H + J + 1`. To define a symmetric window centered on :math:`x_i`,
one would set :math:`H = J = \left\lfloor K / 2 \right\rfloor`.

Handling Endpoints
==================

When processing samples near the ends of the input signal, there will not
be enough samples to fill the window :math:`W_i^{H,J}` defined above.
Therefore the user must specify how to construct the windows near the end points.
This is done by passing an input argument of type :type:`gsl_movstat_end_t`:

.. type:: gsl_movstat_end_t

   This data type specifies how to construct windows near end points and can
   be selected from the following choices:

   .. macro:: GSL_MOVSTAT_END_PADZERO

      With this option, a full window of length :math:`K` will be constructed
      by inserting zeros into the window near the signal end points. Effectively,
      the input signal is modified to

      .. only:: not texinfo

         .. math:: \tilde{x} = \{ \underbrace{0, \dots, 0}_{H \textrm{ zeros}}, x_1, x_2, \dots, x_{n-1}, x_n, \underbrace{0, \dots, 0}_{J \textrm{ zeros} } \}

      .. only:: texinfo

         ::

            x~ = {0, ..., 0, x_1, x_2, ..., x_{n-1}, x_n, 0, ..., 0}

      to ensure a well-defined window for all :math:`x_i`.

   .. macro:: GSL_MOVSTAT_END_PADVALUE

      With this option, a full window of length :math:`K` will be constructed
      by padding the window with the first and last sample in the input signal.
      Effectively, the input signal is modified to

      .. only:: not texinfo

         .. math:: \tilde{x} = \{ \underbrace{x_1, \dots, x_1}_{H}, x_1, x_2, \dots, x_{n-1}, x_n, \underbrace{x_n, \dots, x_n}_{J} \}

      .. only:: texinfo

         ::

            x~ = {x_1, ..., x_1, x_1, x_2, ..., x_{n-1}, x_n, x_n, ..., x_n}

   .. macro:: GSL_MOVSTAT_END_TRUNCATE

      With this option, no padding is performed, and the windows are simply truncated
      as the end points are approached.

.. index::
   single: moving window, allocation

Allocation for Moving Window Statistics
=======================================

.. type:: gsl_movstat_workspace

   The moving window statistical routines use a common workspace.

.. function:: gsl_movstat_workspace * gsl_movstat_alloc(const size_t K)

   This function allocates a workspace for computing symmetric, centered moving statistics with a window
   length of :math:`K` samples. In this case, :math:`H = J = \left\lfloor K/2 \right\rfloor`. The size of the workspace
   is :math:`O(7K)`.

.. function:: gsl_movstat_workspace * gsl_movstat_alloc2(const size_t H, const size_t J)

   This function allocates a workspace for computing moving statistics using a window with :math:`H`
   samples prior to the current sample, and :math:`J` samples after the current sample. The
   total window size is :math:`K = H + J + 1`. The size of the workspace is :math:`O(7K)`.

.. function:: void * gsl_movstat_free(gsl_movstat_workspace * w)

   This function frees the memory associated with :data:`w`.

.. index::
   single: moving mean
   single: rolling mean

Moving Mean
===========

The moving window mean calculates the mean of the values of each window :math:`W_i^{H,J}`.

.. only:: not texinfo

   .. math:: \hat{\mu}_i = \frac{1}{\left| W_i^{H,J} \right|} \sum_{x_m \in W_i^{H,J}} x_m

.. only:: texinfo

   ::

      \hat{\mu}_i = 1/| W_i^{H,J} | \sum_{x_m \in W_i^{H,J}} x_m

Here, :math:`\left| W_i^{H,J} \right|` represents the number of elements in the window
:math:`W_i^{H,J}`. This will normally be :math:`K`, unless the :macro:`GSL_MOVSTAT_END_TRUNCATE`
option is selected, in which case it could be less than :math:`K` near the signal end points.

.. function:: int gsl_movstat_mean(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_movstat_workspace * w)

   This function computes the moving window mean of the input vector :data:`x`, storing
   the output in :data:`y`. The parameter :data:`endtype` specifies how windows near
   the ends of the input should be handled. It is allowed to have :data:`x` = :data:`y`
   for an in-place moving mean.

.. index::
   single: moving variance
   single: moving standard deviation
   single: rolling variance
   single: rolling standard deviation

Moving Variance and Standard Deviation
======================================

The moving window variance calculates the *sample variance* of the values of each window :math:`W_i^{H,J}`,
defined by

.. only:: not texinfo

   .. math:: \hat{\sigma}_i^2 = \frac{1}{\left( \left| W_i^{H,J} \right| - 1 \right)} \sum_{x_m \in W_i^{H,J}} \left( x_m - \hat{\mu}_i \right)^2

.. only:: texinfo

   ::

      \hat{\sigma}_i^2 = 1/(|W_i^{H,J}| - 1) \sum_{x_m \in W_i^{H,J}} ( x_m - \hat{\mu}_i )^2

where :math:`\hat{\mu}_i` is the mean of :math:`W_i^{H,J}` defined above. The standard deviation :math:`\hat{\sigma}_i`
is the square root of the variance.

.. function:: int gsl_movstat_variance(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_movstat_workspace * w)

   This function computes the moving window variance of the input vector :data:`x`, storing
   the output in :data:`y`. The parameter :data:`endtype` specifies how windows near
   the ends of the input should be handled. It is allowed to have :data:`x` = :data:`y`
   for an in-place moving variance.

.. function:: int gsl_movstat_sd(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_movstat_workspace * w)

   This function computes the moving window standard deviation of the input vector :data:`x`, storing
   the output in :data:`y`. The parameter :data:`endtype` specifies how windows near
   the ends of the input should be handled. It is allowed to have :data:`x` = :data:`y`
   for an in-place moving standard deviation.

.. index::
   single: moving minimum
   single: moving maximum
   single: rolling minimum
   single: rolling maximum

Moving Minimum and Maximum
==========================

The moving minimum/maximum calculates the minimum and maximum values of
each window :math:`W_i^{H,J}`.

.. only:: not texinfo

    .. math::

       y_i^{min} &= \min \left( W_i^{H,J} \right) \\
       y_i^{max} &= \max \left( W_i^{H,J} \right)

.. only:: texinfo

   ::

      y_i^{min} = \min W_i^{H,J}
      y_i^{max} = \max W_i^{H,J}

.. function:: int gsl_movstat_min(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_movstat_workspace * w)

   This function computes the moving minimum of the input vector :data:`x`, storing
   the result in :data:`y`. The parameter :data:`endtype` specifies how windows near
   the ends of the input should be handled.
   It is allowed to have :data:`x` = :data:`y` for an in-place moving minimum.

.. function:: int gsl_movstat_max(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_movstat_workspace * w)

   This function computes the moving maximum of the input vector :data:`x`, storing
   the result in :data:`y`. The parameter :data:`endtype` specifies how windows near
   the ends of the input should be handled.
   It is allowed to have :data:`x` = :data:`y` for an in-place moving maximum.

.. function:: int gsl_movstat_minmax(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * y_min, gsl_vector * y_max, gsl_movstat_workspace * w)

   This function computes the moving minimum and maximum of the input vector :data:`x`, storing
   the window minimums in :data:`y_min` and the window maximums in :data:`y_max`.
   The parameter :data:`endtype` specifies how windows near the ends of the input should be handled.

.. index::
   single: moving sum
   single: rolling sum

Moving Sum
==========

The moving window sum calculates the sum of the values of each window :math:`W_i^{H,J}`.

.. math:: y_i = \sum_{x_m \in W_i^{H,J}} x_m

.. function:: int gsl_movstat_sum(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_movstat_workspace * w)

   This function computes the moving window sum of the input vector :data:`x`, storing
   the output in :data:`y`. The parameter :data:`endtype` specifies how windows near
   the ends of the input should be handled. It is allowed to have :data:`x` = :data:`y`
   for an in-place moving sum.

.. index::
   single: moving median
   single: rolling median

Moving Median
=============

The moving median calculates the median of the window :math:`W_i^{H,J}` for
each sample :math:`x_i`:

.. only:: not texinfo

    .. math:: y_i = \textrm{median} \left( W_i^{H,J} \right)

.. only:: texinfo

   ::

      y_i = median(W_i^{H,J})

.. function:: int gsl_movstat_median(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * y, gsl_movstat_workspace * w)

   This function computes the moving median of the input vector :data:`x`, storing
   the output in :data:`y`. The parameter :data:`endtype` specifies how windows near
   the ends of the input should be handled. It is allowed for
   :data:`x` = :data:`y` for an in-place moving window median.

Robust Scale Estimation
=======================

A common problem in statistics is to quantify the dispersion (also known as the variability, scatter, and spread) of
a set of data. Often this is done by calculating the variance or standard deviation. However these statistics
are strongly influenced by outliers, and can often provide erroneous results when even a small number of outliers
are present.

Several useful statistics have emerged to provide robust estimates of scale which are not as susceptible to data outliers.
A few of these statistical scale estimators are described below.

.. index::
   single: moving median absolute deviation
   single: rolling median absolute deviation

Moving MAD
----------

The median absolute deviation (MAD) for the window :math:`W_i^{H,J}` is defined
to be the median of the absolute deviations from the window's median:

.. only:: not texinfo

    .. math:: MAD_i = 1.4826 \times \textrm{median} \left( \left| W_i^{H,J} - \textrm{median} \left( W_i^{H,J} \right) \right| \right)

.. only:: texinfo

   ::

      MAD_i = 1.4826 * median[ |W_i^{H,J} - median(W_i^{H,J})| ]

The factor of :math:`1.4826` makes the MAD an unbiased estimator of the standard deviation
for Gaussian data. The MAD has an efficiency of 37%.  See :ref:`here <sec_mad-statistic>` for more information.

.. function:: int gsl_movstat_mad0(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * xmedian, gsl_vector * xmad, gsl_movstat_workspace * w)
              int gsl_movstat_mad(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * xmedian, gsl_vector * xmad, gsl_movstat_workspace * w)

   These functions compute the moving MAD of the input vector :data:`x` and store the result
   in :data:`xmad`. The medians of each window :math:`W_i^{H,J}` are stored in :data:`xmedian`
   on output. The inputs :data:`x`, :data:`xmedian`, and :data:`xmad` must all be the same length.
   The parameter :data:`endtype` specifies how windows near the ends of the input should be handled.
   The function :code:`mad0` does not include the scale factor of :math:`1.4826`, while the
   function :code:`mad` does include this factor.

.. index::
   single: moving quantile range
   single: rolling quantile range

Moving QQR
----------

The q-quantile range (QQR) is the difference between the :math:`(1-q)` and :math:`q` quantiles
of a set of data,

.. math:: QQR = Q_{1-q} - Q_q

The case :math:`q = 0.25` corresponds to the well-known *interquartile range (IQR)*, which
is the difference between the 75th and 25th percentiles of a set of data. The QQR is
a *trimmed estimator*, the main idea being to discard the largest and smallest values in
a data window and compute a scale estimate from the remaining middle values. In the case
of the IQR, the largest and smallest 25% of the data are discarded and the scale is
estimated from the remaining (middle) 50%.

.. function:: int gsl_movstat_qqr(const gsl_movstat_end_t endtype, const gsl_vector * x, const double q, gsl_vector * xqqr, gsl_movstat_workspace * w)

   This function computes the moving QQR of the input vector :data:`x` and stores the q-quantile ranges
   of each window :math:`W_i^{H,J}` in :data:`xqqr`. The quantile parameter :data:`q` must be between
   :math:`0` and :math:`0.5`. The input :math:`q = 0.25` corresponds to the IQR.
   The inputs :data:`x` and :data:`xqqr` must be the same length.
   The parameter :data:`endtype` specifies how windows near the ends of the input should be handled.

Moving :math:`S_n`
------------------

The :math:`S_n` statistic proposed by Croux and Rousseeuw is based on pairwise differences between
all samples in the window. It has an efficiency of 58%, significantly higher than the MAD.
See :ref:`here <sec_Sn-statistic>` for more information.

.. function:: int gsl_movstat_Sn(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * xscale, gsl_movstat_workspace * w)

   This function computes the moving :math:`S_n` of the input vector :data:`x` and stores the output
   in :data:`xscale`. The inputs :data:`x` and :data:`xscale` must be the same length.
   The parameter :data:`endtype` specifies how windows near the ends of the input should be handled.
   It is allowed for :data:`x` = :data:`xscale` for an in-place moving window :math:`S_n`.

Moving :math:`Q_n`
------------------

The :math:`Q_n` statistic proposed by Croux and Rousseeuw is loosely based on the Hodges-Lehmann location
estimator. It has a relatively high efficiency of 82%. See :ref:`here <sec_Qn-statistic>` for more information.

.. function:: int gsl_movstat_Qn(const gsl_movstat_end_t endtype, const gsl_vector * x, gsl_vector * xscale, gsl_movstat_workspace * w)

   This function computes the moving :math:`Q_n` of the input vector :data:`x` and stores the output
   in :data:`xscale`. The inputs :data:`x` and :data:`xscale` must be the same length.
   The parameter :data:`endtype` specifies how windows near the ends of the input should be handled.
   It is allowed for :data:`x` = :data:`xscale` for an in-place moving window :math:`Q_n`.

.. index::
   single: moving window accumulators
   single: rolling window accumulators

User-defined Moving Statistics
==============================

GSL offers an interface for users to define their own moving window statistics
functions, without needing to implement the edge-handling and accumulator
machinery. This can be done by explicitly constructing the windows
:math:`W_i^{H,J}` for a given input signal (:func:`gsl_movstat_fill`), or by calculating a user-defined
function for each window automatically. In order to apply a user-defined
function to each window, users must define a variable of type
:type:`gsl_movstat_function` to pass into :func:`gsl_movstat_apply`.
This structure is defined as follows.

.. type:: gsl_movstat_function

   Structure specifying user-defined moving window statistical function::

     typedef struct
     {
       double (* function) (const size_t n, double x[], void * params);
       void * params;
     } gsl_movstat_function;

   This structure contains a pointer to the user-defined function as well
   as possible parameters to pass to the function.

   .. member:: double (* function) (const size_t n, double x[], void * params)

      This function returns the user-defined statistic of the array :data:`x`
      of length :data:`n`. User-specified parameters are passed in via :data:`params`.
      It is allowed to modify the array :data:`x`.

   .. member:: void * params

      User-specified parameters to be passed into the function.

.. function:: int gsl_movstat_apply(const gsl_movstat_end_t endtype, const gsl_movstat_function * F, const gsl_vector * x, gsl_vector * y, gsl_movstat_workspace * w)

   This function applies the user-defined moving window statistic specified in :data:`F`
   to the input vector :data:`x`, storing the output in :data:`y`.
   The parameter :data:`endtype` specifies how windows near the ends of the input should be handled.
   It is allowed for :data:`x` = :data:`y` for an in-place moving window calculation.

.. function:: size_t gsl_movstat_fill(const gsl_movstat_end_t endtype, const gsl_vector * x, const size_t idx, const size_t H, const size_t J, double * window)

   This function explicitly constructs the sliding window for the input vector :data:`x` which
   is centered on the sample :data:`idx`. On output, the array :data:`window` will contain
   :math:`W_{idx}^{H,J}`. The number of samples to the left and right
   of the sample :data:`idx` are specified by :data:`H` and :data:`J` respectively.
   The parameter :data:`endtype` specifies how windows near the ends of the input should be handled.
   The function returns the size of the window.

Accumulators
============

Many of the algorithms of this chapter are based on an accumulator design, which
process the input vector one sample at a time, updating calculations of the
desired statistic for the current window. Each accumulator is stored in the
following structure:

.. type:: gsl_movstat_accum

   Structure specifying accumulator for moving window statistics::

     typedef struct
     {
       size_t (* size) (const size_t n);
       int (* init) (const size_t n, void * vstate);
       int (* insert) (const double x, void * vstate);
       int (* delete) (void * vstate);
       int (* get) (void * params, double * result, const void * vstate);
     } gsl_movstat_accum;

   The structure contains function pointers responsible for performing
   different tasks for the accumulator.

   .. member:: size_t (* size) (const size_t n)

        This function returns the size of the workspace (in bytes) needed by the accumulator
        for a moving window of length :data:`n`.

   .. member:: int (* init) (const size_t n, void * vstate)

        This function initializes the workspace :data:`vstate` for a moving window of length :data:`n`.

   .. member:: int (* insert) (const double x, void * vstate)

        This function inserts a single sample :data:`x` into the accumulator, updating internal
        calculations of the desired statistic. If the accumulator is full (i.e. :math:`n` samples
        have already been inserted), then the oldest sample is deleted from the accumulator.

   .. member:: int (* delete) (void * vstate)

        This function deletes the oldest sample from the accumulator, updating internal
        calculations of the desired statistic.

   .. member:: int (* get) (void * params, double * result, const void * vstate)

        This function stores the desired statistic for the current window in
        :data:`result`. The input :data:`params` specifies optional parameters
        for calculating the statistic.

The following accumulators of type :type:`gsl_movstat_accum` are defined by GSL to perform moving window statistics
calculations.

.. var:: gsl_movstat_accum_min
         gsl_movstat_accum_max
         gsl_movstat_accum_minmax

   These accumulators calculate moving window minimum/maximums efficiently, using
   the algorithm of D. Lemire.

.. var:: gsl_movstat_accum_mean
         gsl_movstat_accum_sd
         gsl_movstat_accum_variance

   These accumulators calculate the moving window mean, standard deviation, and variance,
   using the algorithm of B. P. Welford.

.. var:: gsl_movstat_median

   This accumulator calculates the moving window median using the min/max heap algorithm
   of Härdle and Steiger.

.. var:: gsl_movstat_accum_Sn
         gsl_movstat_accum_Qn

   These accumulators calculate the moving window :math:`S_n` and :math:`Q_n` statistics
   developed by Croux and Rousseeuw.

.. var:: gsl_movstat_accum_sum

   This accumulator calculates the moving window sum.

.. var:: gsl_movstat_accum_qqr

   This accumulator calculates the moving window q-quantile range.

Examples
========

Example 1
---------

The following example program computes the moving mean, minimum and maximum of a noisy
sinusoid signal of length :math:`N = 500` with a symmetric moving window of size :math:`K = 11`.

.. _fig_movstat1:

.. figure:: /images/movstat1.png
   :scale: 60%

   Original signal time series (gray) with moving mean (green), moving minimum (blue),
   and moving maximum (orange).

The program is given below.

.. include:: examples/movstat1.c
   :code:

Example 2: Robust Scale
-----------------------

The following example program analyzes a time series of length :math:`N = 1000` composed
of Gaussian random variates with zero mean whose standard deviation changes in a piecewise constant fashion
as shown in the table below.

============ ==============
Sample Range :math:`\sigma`
============ ==============
1-200        1.0
201-450      5.0
451-600      1.0
601-850      3.0
851-1000     5.0
============ ==============

Additionally, about 1% of the samples are perturbed to represent outliers by adding
:math:`\pm 15` to the random Gaussian variate.
The program calculates the moving statistics MAD, IQR, :math:`S_n`, :math:`Q_n`, and
the standard deviation using a symmetric moving window of length :math:`K = 41`. The results are shown in
:numref:`fig_movstat2`.

.. _fig_movstat2:

.. figure:: /images/movstat2.png
   :scale: 60%

   Top: time series of piecewise constant variance. Bottom: scale estimates using a moving
   window; the true sigma value is in light blue, MAD in green, IQR in red, :math:`S_n` in yellow, and
   :math:`Q_n` in dark blue. The moving standard deviation is shown in gray.

The robust statistics follow the true standard deviation piecewise changes well, without being
influenced by the outliers. The moving standard deviation (gray curve) is heavily influenced by
the presence of the outliers. The program is given below.

.. include:: examples/movstat2.c
   :code:

Example 3: User-defined Moving Window
-------------------------------------

This example program illustrates how a user can define their own moving window function to apply
to an input vector. It constructs a random noisy time series of length :math:`N = 1000` with
some outliers added. Then it applies a moving window trimmed mean to the time series with
trim parameter :math:`\alpha = 0.1`. The length of the moving window is :math:`K = 11`, so
the smallest and largest sample of each window is discarded prior to computing the mean.
The results are shown in :numref:`fig_movstat3`.

.. _fig_movstat3:

.. figure:: /images/movstat3.png
   :scale: 60%

   Noisy time series data (black) with moving window trimmed mean (red)

The program is given below.

.. include:: examples/movstat3.c
   :code:

References and Further Reading
==============================

The following publications are relevant to the algorithms described
in this chapter,

* W.Hardle and W. Steiger, *Optimal Median Smoothing*, Appl. Statist., 44 (2), 1995.

* D. Lemire, *Streaming Maximum-Minimum Filter Using No More than Three Comparisons per Element*,
  Nordic Journal of Computing, 13 (4), 2006 (https://arxiv.org/abs/cs/0610046).

* B. P. Welford, *Note on a method for calculating corrected sums of squares and products*,
  Technometrics, 4 (3), 1962.
.. index:: combinations

************
Combinations
************

.. include:: include.rst

This chapter describes functions for creating and manipulating
combinations. A combination :math:`c` is represented by an array of
:math:`k` integers in the range 0 to :math:`n - 1`, where each value
:math:`c_i` occurs at most once.  The combination :math:`c` corresponds to
indices of :math:`k` elements chosen from an :math:`n` element vector.
Combinations are useful for iterating over all :math:`k`-element subsets
of a set.

The functions described in this chapter are defined in the header file
:file:`gsl_combination.h`.

The Combination struct
======================

.. type:: gsl_combination

   A combination is defined by a structure containing three components, the
   values of :math:`n` and :math:`k`, and a pointer to the combination array.
   The elements of the combination array are all of type :code:`size_t`, and
   are stored in increasing order.  The :type:`gsl_combination` structure
   looks like this::

      typedef struct
      {
        size_t n;
        size_t k;
        size_t *data;
      } gsl_combination;

Combination allocation
======================

.. function:: gsl_combination * gsl_combination_alloc (size_t n, size_t k)

   This function allocates memory for a new combination with parameters
   :data:`n`, :data:`k`.  The combination is not initialized and its elements
   are undefined.  Use the function :func:`gsl_combination_calloc` if you
   want to create a combination which is initialized to the
   lexicographically first combination. A null pointer is returned if
   insufficient memory is available to create the combination.

.. function:: gsl_combination * gsl_combination_calloc (size_t n, size_t k)

   This function allocates memory for a new combination with parameters
   :data:`n`, :data:`k` and initializes it to the lexicographically first
   combination. A null pointer is returned if insufficient memory is
   available to create the combination.

.. function:: void gsl_combination_init_first (gsl_combination * c)

   This function initializes the combination :data:`c` to the
   lexicographically first combination, i.e.  :math:`(0, 1, 2, \dots, k - 1)`.

.. function:: void gsl_combination_init_last (gsl_combination * c)

   This function initializes the combination :data:`c` to the
   lexicographically last combination, i.e.  :math:`(n - k, n - k + 1, \dots, n - 1)`.

.. function:: void gsl_combination_free (gsl_combination * c)

   This function frees all the memory used by the combination :data:`c`.

.. function:: int gsl_combination_memcpy (gsl_combination * dest, const gsl_combination * src)

   This function copies the elements of the combination :data:`src` into the
   combination :data:`dest`.  The two combinations must have the same size.

Accessing combination elements
==============================

The following function can be used to access the elements of a combination.

.. function:: size_t gsl_combination_get (const gsl_combination * c, const size_t i)

   This function returns the value of the :data:`i`-th element of the
   combination :data:`c`.  If :data:`i` lies outside the allowed range of 0 to
   :math:`k - 1` then the error handler is invoked and 0 is returned. |inlinefn|

Combination properties
======================

.. function:: size_t gsl_combination_n (const gsl_combination * c)

   This function returns the range (:math:`n`) of the combination c.

.. function:: size_t gsl_combination_k (const gsl_combination * c)

   This function returns the number of elements (:math:`k`) in the combination :data:`c`.

.. function:: size_t * gsl_combination_data (const gsl_combination * c)

   This function returns a pointer to the array of elements in the
   combination :data:`c`.

.. index::
   single: checking combination for validity
   single: testing combination for validity

.. function:: int gsl_combination_valid (gsl_combination * c)

   This function checks that the combination :data:`c` is valid.  The :data:`k`
   elements should lie in the range 0 to :math:`n - 1`, with each
   value occurring once at most and in increasing order.

Combination functions
=====================

.. index:: iterating through combinations

.. function:: int gsl_combination_next (gsl_combination * c)

   This function advances the combination :data:`c` to the next combination
   in lexicographic order and returns :macro:`GSL_SUCCESS`.  If no further
   combinations are available it returns :macro:`GSL_FAILURE` and leaves
   :data:`c` unmodified.  Starting with the first combination and
   repeatedly applying this function will iterate through all possible
   combinations of a given order.

.. function:: int gsl_combination_prev (gsl_combination * c)

   This function steps backwards from the combination :data:`c` to the
   previous combination in lexicographic order, returning
   :macro:`GSL_SUCCESS`.  If no previous combination is available it returns
   :macro:`GSL_FAILURE` and leaves :data:`c` unmodified.

Reading and writing combinations
================================

The library provides functions for reading and writing combinations to a
file as binary data or formatted text.

.. function:: int gsl_combination_fwrite (FILE * stream, const gsl_combination * c)

   This function writes the elements of the combination :data:`c` to the
   stream :data:`stream` in binary format.  The function returns
   :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since the
   data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_combination_fread (FILE * stream, gsl_combination * c)

   This function reads elements from the open stream :data:`stream` into the
   combination :data:`c` in binary format.  The combination :data:`c` must be
   preallocated with correct values of :math:`n` and :math:`k` since the
   function uses the size of :data:`c` to determine how many bytes to read.
   The function returns :macro:`GSL_EFAILED` if there was a problem reading
   from the file.  The data is assumed to have been written in the native
   binary format on the same architecture.

.. function:: int gsl_combination_fprintf (FILE * stream, const gsl_combination * c, const char * format)

   This function writes the elements of the combination :data:`c`
   line-by-line to the stream :data:`stream` using the format specifier
   :data:`format`, which should be suitable for a type of :code:`size_t`.
   In ISO C99 the type modifier :code:`z` represents :code:`size_t`, so
   :code:`"%zu\n"` is a suitable format [#f1]_.
   The function returns
   :macro:`GSL_EFAILED` if there was a problem writing to the file.

.. function:: int gsl_combination_fscanf (FILE * stream, gsl_combination * c)

   This function reads formatted data from the stream :data:`stream` into the
   combination :data:`c`.  The combination :data:`c` must be preallocated with
   correct values of :math:`n` and :math:`k` since the function uses the size of :data:`c` to
   determine how many numbers to read.  The function returns
   :macro:`GSL_EFAILED` if there was a problem reading from the file.

Examples
========

The example program below prints all subsets of the set
:math:`{0,1,2,3}` ordered by size.  Subsets of the same size are
ordered lexicographically.

.. include:: examples/combination.c
   :code:

Here is the output from the program,

.. include:: examples/combination.txt
   :code:

All 16 subsets are generated, and the subsets of each size are sorted
lexicographically.

References and Further Reading
==============================

Further information on combinations can be found in,

* Donald L. Kreher, Douglas R. Stinson, Combinatorial Algorithms:
  Generation, Enumeration and Search, 1998, CRC Press LLC, ISBN
  084933988X

.. rubric:: Footnotes

.. [#f1] In versions of the GNU C library prior to the ISO C99 standard, 
         the type modifier :code:`Z` was used instead.
.. index::
   single: simulated annealing
   single: combinatorial optimization
   single: optimization, combinatorial
   single: energy function
   single: cost function

*******************
Simulated Annealing
*******************

Stochastic search techniques are used when the structure of a space is
not well understood or is not smooth, so that techniques like Newton's
method (which requires calculating Jacobian derivative matrices) cannot
be used. In particular, these techniques are frequently used to solve
combinatorial optimization problems, such as the traveling salesman
problem.

The goal is to find a point in the space at which a real valued
*energy function* (or *cost function*) is minimized.  Simulated
annealing is a minimization technique which has given good results in
avoiding local minima; it is based on the idea of taking a random walk
through the space at successively lower temperatures, where the
probability of taking a step is given by a Boltzmann distribution.

The functions described in this chapter are declared in the header file
:file:`gsl_siman.h`.

Simulated Annealing algorithm
=============================

The simulated annealing algorithm takes random walks through the problem
space, looking for points with low energies; in these random walks, the
probability of taking a step is determined by the Boltzmann distribution,

.. math:: p = e^{-(E_{i+1} - E_i)/(kT)}

if 
:math:`E_{i+1} > E_i`, and
:math:`p = 1` when 
:math:`E_{i+1} \le E_i`.

In other words, a step will occur if the new energy is lower.  If
the new energy is higher, the transition can still occur, and its
likelihood is proportional to the temperature :math:`T` and inversely
proportional to the energy difference 
:math:`E_{i+1} - E_i`.

.. index::
   single: cooling schedule
   single: schedule, cooling

The temperature :math:`T` is initially set to a high value, and a random
walk is carried out at that temperature.  Then the temperature is
lowered very slightly according to a *cooling schedule*, for
example: :math:`T \rightarrow T/\mu_T`
where :math:`\mu_T` is slightly greater than 1. 

The slight probability of taking a step that gives higher energy is what
allows simulated annealing to frequently get out of local minima.

Simulated Annealing functions
=============================

.. function:: void gsl_siman_solve (const gsl_rng * r, void * x0_p, gsl_siman_Efunc_t Ef, gsl_siman_step_t take_step, gsl_siman_metric_t distance, gsl_siman_print_t print_position, gsl_siman_copy_t copyfunc, gsl_siman_copy_construct_t copy_constructor, gsl_siman_destroy_t destructor, size_t element_size, gsl_siman_params_t params)

   This function performs a simulated annealing search through a given
   space.  The space is specified by providing the functions :data:`Ef` and
   :data:`distance`.  The simulated annealing steps are generated using the
   random number generator :data:`r` and the function :data:`take_step`.

   The starting configuration of the system should be given by :data:`x0_p`.
   The routine offers two modes for updating configurations, a fixed-size
   mode and a variable-size mode.  In the fixed-size mode the configuration
   is stored as a single block of memory of size :data:`element_size`.
   Copies of this configuration are created, copied and destroyed
   internally using the standard library functions :func:`malloc`,
   :func:`memcpy` and :func:`free`.  The function pointers :data:`copyfunc`,
   :data:`copy_constructor` and :data:`destructor` should be null pointers in
   fixed-size mode.  In the variable-size mode the functions
   :data:`copyfunc`, :data:`copy_constructor` and :data:`destructor` are used to
   create, copy and destroy configurations internally.  The variable
   :data:`element_size` should be zero in the variable-size mode.

   The :data:`params` structure (described below) controls the run by
   providing the temperature schedule and other tunable parameters to the
   algorithm.

   On exit the best result achieved during the search is placed in
   :data:`x0_p`.  If the annealing process has been successful this
   should be a good approximation to the optimal point in the space.

   If the function pointer :data:`print_position` is not null, a debugging
   log will be printed to :code:`stdout` with the following columns::

      #-iter  #-evals  temperature  position  energy  best_energy

   and the output of the function :data:`print_position` itself.  If
   :data:`print_position` is null then no information is printed.

The simulated annealing routines require several user-specified
functions to define the configuration space and energy function.  The
prototypes for these functions are given below.

.. type:: gsl_siman_Efunc_t

   This function type should return the energy of a configuration :data:`xp`::

      double (*gsl_siman_Efunc_t) (void *xp)

.. type:: gsl_siman_step_t

   This function type should modify the configuration :data:`xp` using a random step
   taken from the generator :data:`r`, up to a maximum distance of
   :data:`step_size`::

      void (*gsl_siman_step_t) (const gsl_rng *r, void *xp, 
                                double step_size)

.. type:: gsl_siman_metric_t

   This function type should return the distance between two configurations
   :data:`xp` and :data:`yp`::

      double (*gsl_siman_metric_t) (void *xp, void *yp)

.. type:: gsl_siman_print_t

   This function type should print the contents of the configuration :data:`xp`::

      void (*gsl_siman_print_t) (void *xp)

.. type:: gsl_siman_copy_t

   This function type should copy the configuration :data:`source` into :data:`dest`::

      void (*gsl_siman_copy_t) (void *source, void *dest)

.. type:: gsl_siman_copy_construct_t

   This function type should create a new copy of the configuration :data:`xp`::

      void * (*gsl_siman_copy_construct_t) (void *xp)

.. type:: gsl_siman_destroy_t

   This function type should destroy the configuration :data:`xp`, freeing its
   memory::

      void (*gsl_siman_destroy_t) (void *xp)

.. type:: gsl_siman_params_t

   These are the parameters that control a run of :func:`gsl_siman_solve`.
   This structure contains all the information needed to control the
   search, beyond the energy function, the step function and the initial
   guess.

   ========================================= ============================================================
   :code:`int n_tries`                       The number of points to try for each step.
   :code:`int iters_fixed_T`                 The number of iterations at each temperature.
   :code:`double step_size`                  The maximum step size in the random walk.
   :code:`double k, t_initial, mu_t, t_min`  The parameters of the Boltzmann distribution and cooling
                                             schedule.
   ========================================= ============================================================

Examples
========

The simulated annealing package is clumsy, and it has to be because it
is written in C, for C callers, and tries to be polymorphic at the same
time.  But here we provide some examples which can be pasted into your
application with little change and should make things easier.

Trivial example
---------------

The first example, in one dimensional Cartesian space, sets up an energy
function which is a damped sine wave; this has many local minima, but
only one global minimum, somewhere between 1.0 and 1.5.  The initial
guess given is 15.5, which is several local minima away from the global
minimum.

.. include:: examples/siman.c
   :code:

:numref:`fig_siman-test` is generated by running
:code:`siman_test` in the following way::

  $ ./siman_test | awk '!/^#/ {print $1, $4}' 
   | graph -y 1.34 1.4 -W0 -X generation -Y position 
   | plot -Tps > siman-test.eps

:numref:`fig_siman-energy` is generated by running
:code:`siman_test` in the following way::

  $ ./siman_test | awk '!/^#/ {print $1, $5}' 
   | graph -y -0.88 -0.83 -W0 -X generation -Y energy 
   | plot -Tps > siman-energy.eps

.. _fig_siman-test:

.. figure:: /images/siman-test.png
   :scale: 60%

   Example of a simulated annealing run: at higher temperatures (early in
   the plot) you see that the solution can fluctuate, but at lower
   temperatures it converges.

.. _fig_siman-energy:

.. figure:: /images/siman-energy.png
   :scale: 60%

   Simulated annealing energy vs generation

.. index::
   single: TSP
   single: traveling salesman problem

Traveling Salesman Problem
--------------------------

The TSP (*Traveling Salesman Problem*) is the classic combinatorial
optimization problem.  I have provided a very simple version of it,
based on the coordinates of twelve cities in the southwestern United
States.  This should maybe be called the *Flying Salesman Problem*,
since I am using the great-circle distance between cities, rather than
the driving distance.  Also: I assume the earth is a sphere, so I don't
use geoid distances.

The :func:`gsl_siman_solve` routine finds a route which is 3490.62
Kilometers long; this is confirmed by an exhaustive search of all
possible routes with the same initial city.

The full code is given below.

.. include:: examples/siman_tsp.c
   :code:

Below are some plots generated in the following way::

  $ ./siman_tsp > tsp.output
  $ grep -v "^#" tsp.output  
   | awk '{print $1, $NF}'
   | graph -y 3300 6500 -W0 -X generation -Y distance 
      -L "TSP - 12 southwest cities"
   | plot -Tps > 12-cities.eps
  $ grep initial_city_coord tsp.output 
    | awk '{print $2, $3}' 
    | graph -X "longitude (- means west)" -Y "latitude" 
       -L "TSP - initial-order" -f 0.03 -S 1 0.1 
    | plot -Tps > initial-route.eps
  $ grep final_city_coord tsp.output 
    | awk '{print $2, $3}' 
    | graph -X "longitude (- means west)" -Y "latitude" 
       -L "TSP - final-order" -f 0.03 -S 1 0.1 
    | plot -Tps > final-route.eps

This is the output showing the initial order of the cities; longitude is
negative, since it is west and I want the plot to look like a map::

  # initial coordinates of cities (longitude and latitude)
  ###initial_city_coord: -105.95 35.68 Santa Fe
  ###initial_city_coord: -112.07 33.54 Phoenix
  ###initial_city_coord: -106.62 35.12 Albuquerque
  ###initial_city_coord: -103.2 34.41 Clovis
  ###initial_city_coord: -107.87 37.29 Durango
  ###initial_city_coord: -96.77 32.79 Dallas
  ###initial_city_coord: -105.92 35.77 Tesuque
  ###initial_city_coord: -107.84 35.15 Grants
  ###initial_city_coord: -106.28 35.89 Los Alamos
  ###initial_city_coord: -106.76 32.34 Las Cruces
  ###initial_city_coord: -108.58 37.35 Cortez
  ###initial_city_coord: -108.74 35.52 Gallup
  ###initial_city_coord: -105.95 35.68 Santa Fe

The optimal route turns out to be::

  # final coordinates of cities (longitude and latitude)
  ###final_city_coord: -105.95 35.68 Santa Fe
  ###final_city_coord: -103.2 34.41 Clovis
  ###final_city_coord: -96.77 32.79 Dallas
  ###final_city_coord: -106.76 32.34 Las Cruces
  ###final_city_coord: -112.07 33.54 Phoenix
  ###final_city_coord: -108.74 35.52 Gallup
  ###final_city_coord: -108.58 37.35 Cortez
  ###final_city_coord: -107.87 37.29 Durango
  ###final_city_coord: -107.84 35.15 Grants
  ###final_city_coord: -106.62 35.12 Albuquerque
  ###final_city_coord: -106.28 35.89 Los Alamos
  ###final_city_coord: -105.92 35.77 Tesuque
  ###final_city_coord: -105.95 35.68 Santa Fe

.. figure:: /images/siman-initial-route.png
   :scale: 60%

   Initial route for the 12 southwestern cities Flying Salesman Problem.

.. figure:: /images/siman-final-route.png
   :scale: 60%

   Final (optimal) route for the 12 southwestern cities Flying Salesman Problem.

Here's a plot of the cost function (energy) versus generation (point in
the calculation at which a new temperature is set) for this problem:

.. figure:: /images/siman-12-cities.png
   :scale: 60%

   Example of a simulated annealing run for the 12 southwestern cities
   Flying Salesman Problem.

References and Further Reading
==============================

Further information is available in the following book,

* *Modern Heuristic Techniques for Combinatorial Problems*, Colin R. Reeves
  (ed.), McGraw-Hill, 1995 (ISBN 0-07-709239-2).
.. index:: Mathieu functions

The routines described in this section compute the angular and radial
Mathieu functions, and their characteristic values.  Mathieu
functions are the solutions of the following two differential
equations:

.. only:: not texinfo

   .. math::

      {{d^2 y}\over{d v^2}}& + (a - 2q\cos 2v)y  = 0 \\
      {{d^2 f}\over{d u^2}}& - (a - 2q\cosh 2u)f  = 0

.. only:: texinfo

   ::

      d^2y/dv^2 + (a - 2q\cos 2v)y = 0
      d^2f/du^2 - (a - 2q\cosh 2u)f = 0

The angular Mathieu functions :math:`ce_r(x,q)`, :math:`se_r(x,q)` are
the even and odd periodic solutions of the first equation, which is known as Mathieu's equation. These exist
only for the discrete sequence of  characteristic values :math:`a = a_r(q)`
(even-periodic) and :math:`a = b_r(q)` (odd-periodic).

The radial Mathieu functions :math:`Mc^{(j)}_{r}(z,q)` and
:math:`Ms^{(j)}_{r}(z,q)`
are the solutions of the second equation,
which is referred to as Mathieu's modified equation.  The
radial Mathieu functions of the first, second, third and fourth kind
are denoted by the parameter :math:`j`, which takes the value 1, 2, 3
or 4.

.. The angular Mathieu functions can be divided into four types as
.. @tex
.. \beforedisplay
.. $$
.. \eqalign{
.. x & = \sum_{m=0}^\infty A_{2m+p} \cos(2m+p)\phi, \quad p = 0, 1, \cr
.. x & = \sum_{m=0}^\infty B_{2m+p} \sin(2m+p)\phi, \quad p = 0, 1.
.. }
.. $$
.. \afterdisplay
.. @end tex
.. @ifinfo

.. @example
.. x = \sum_(m=0)^\infty A_(2m+p) \cos(2m+p)\phi,   p = 0, 1,
.. x = \sum_(m=0)^\infty B_(2m+p) \sin(2m+p)\phi,   p = 0, 1.
.. @end example

.. @end ifinfo
.. @noindent
.. The nomenclature used for the angular Mathieu functions is :math:`ce_n`
.. for the first solution and :math:`se_n` for the second.

.. Similar solutions exist for the radial Mathieu functions by replacing
.. the trigonometric functions with their corresponding hyperbolic
.. functions as shown below.
.. @tex
.. \beforedisplay
.. $$
.. \eqalign{
.. x & = \sum_{m=0}^\infty A_{2m+p} \cosh(2m+p)u, \quad p = 0, 1, \cr
.. x & = \sum_{m=0}^\infty B_{2m+p} \sinh(2m+p)u, \quad p = 0, 1.
.. }
.. $$
.. \afterdisplay
.. @end tex
.. @ifinfo

.. @example
.. x = \sum_(m=0)^\infty A_(2m+p) \cosh(2m+p)u,   p = 0, 1,
.. x = \sum_(m=0)^\infty B_(2m+p) \sinh(2m+p)u,   p = 0, 1.
.. @end example

.. @end ifinfo
.. @noindent
.. The nomenclature used for the radial Mathieu functions is :math:`Mc_n`
.. for the first solution and :math:`Ms_n` for the second.  The hyperbolic
.. series do not always converge at an acceptable rate.  Therefore most
.. texts on the subject suggest using the following equivalent equations
.. that are expanded in series of Bessel and Hankel functions.
.. @tex
.. \beforedisplay
.. $$
.. \eqalign{
.. Mc_{2n}^{(j)}(x,q) & = \sum_{m=0}^\infty (-1)^{r+k}
..       A_{2m}^{2n}(q)\left[J_m(u_1)Z_m^{(j)}(u_2) +
..                           J_m(u_1)Z_m^{(j)}(u_2)\right]/A_2^{2n} \cr
.. Mc_{2n+1}^{(j)}(x,q) & = \sum_{m=0}^\infty (-1)^{r+k}
..       A_{2m+1}^{2n+1}(q)\left[J_m(u_1)Z_{m+1}^{(j)}(u_2) +
..                               J_{m+1}(u_1)Z_m^{(j)}(u_2)\right]/A_1^{2n+1} \cr
.. Ms_{2n}^{(j)}(x,q) & = \sum_{m=1}^\infty (-1)^{r+k}
..       B_{2m}^{2n}(q)\left[J_{m-1}(u_1)Z_{m+1}^{(j)}(u_2) +
..                           J_{m+1}(u_1)Z_{m-1}^{(j)}(u_2)\right]/B_2^{2n} \cr
.. Ms_{2n+1}^{(j)}(x,q) & = \sum_{m=0}^\infty (-1)^{r+k}
..       B_{2m+1}^{2n+1}(q)\left[J_m(u_1)Z_{m+1}^{(j)}(u_2) +
..                               J_{m+1}(u_1)Z_m^{(j)}(u_2)\right]/B_1^{2n+1}
.. }
.. $$
.. \afterdisplay
.. @end tex
.. @ifinfo

.. @example
.. Mc_(2n)^(j)(x,q) = \sum_(m=0)^\infty (-1)^(r+k) A_(2m)^(2n)(q)
..     [J_m(u_1)Z_m^(j)(u_2) + J_m(u_1)Z_m^(j)(u_2)]/A_2^(2n)
.. Mc_(2n+1)^(j)(x,q) = \sum_(m=0)^\infty (-1)^(r+k) A_(2m+1)^(2n+1)(q)
..     [J_m(u_1)Z_(m+1)^(j)(u_2) + J_(m+1)(u_1)Z_m^(j)(u_2)]/A_1^(2n+1)
.. Ms_(2n)^(j)(x,q) = \sum_(m=1)^\infty (-1)^(r+k) B_(2m)^(2n)(q)
..     [J_(m-1)(u_1)Z_(m+1)^(j)(u_2) + J_(m+1)(u_1)Z_(m-1)^(j)(u_2)]/B_2^(2n)
.. Ms_(2n+1)^(j)(x,q) = \sum_(m=0)^\infty (-1)^(r+k) B_(2m+1)^(2n+1)(q)
..     [J_m(u_1)Z_(m+1)^(j)(u_2) + J_(m+1)(u_1)Z_m^(j)(u_2)]/B_1^(2n+1)
.. @end example

.. @end ifinfo
.. @noindent
.. where @c{$u_1 = \sqrt{q} \exp(-x)$} 
.. @math{u_1 = \sqrt@{q@} \exp(-x)} and @c{$u_2 = \sqrt@{q@} \exp(x)$}
.. @math{u_2 = \sqrt@{q@} \exp(x)} and
.. @tex
.. \beforedisplay
.. $$
.. \eqalign{
.. Z_m^{(1)}(u) & = J_m(u) \cr
.. Z_m^{(2)}(u) & = Y_m(u) \cr
.. Z_m^{(3)}(u) & = H_m^{(1)}(u) \cr
.. Z_m^{(4)}(u) & = H_m^{(2)}(u)
.. }
.. $$
.. \afterdisplay
.. @end tex
.. @ifinfo

.. @example
.. Z_m^(1)(u) = J_m(u)
.. Z_m^(2)(u) = Y_m(u)
.. Z_m^(3)(u) = H_m^(1)(u)
.. Z_m^(4)(u) = H_m^(2)(u)
.. @end example

.. @end ifinfo
.. @noindent
.. where @math{J_m(u)}, @math{Y_m(u)}, @math{H_m^{(1)}(u)}, and
.. :math:`H_m^{(2)}(u)` are the regular and irregular Bessel functions and
.. the Hankel functions, respectively.

For more information on the Mathieu functions, see Abramowitz and
Stegun, Chapter 20.  These functions are defined in the header file
:file:`gsl_sf_mathieu.h`.

Mathieu Function Workspace
--------------------------

The Mathieu functions can be computed for a single order or
for multiple orders, using array-based routines.  The array-based
routines require a preallocated workspace.

.. type:: gsl_sf_mathieu_workspace

   Workspace required for array-based routines

.. function:: gsl_sf_mathieu_workspace * gsl_sf_mathieu_alloc (size_t n, double qmax)

   This function returns a workspace for the array versions of the
   Mathieu routines.  The arguments n and :data:`qmax` specify the
   maximum order and :math:`q`-value of Mathieu functions which can be
   computed with this workspace.  

.. This is required in order to properly
.. terminate the infinite eigenvalue matrix for high precision solutions.
.. The characteristic values for all orders :math:`0 \to n` are stored in
.. the work structure array element @kbd{work->char_value}.

.. function:: void gsl_sf_mathieu_free (gsl_sf_mathieu_workspace * work)

   This function frees the workspace :data:`work`.

Mathieu Function Characteristic Values
--------------------------------------
.. index:: Mathieu Function Characteristic Values

.. function:: int gsl_sf_mathieu_a (int n, double q)
              int gsl_sf_mathieu_a_e (int n, double q, gsl_sf_result * result)
              int gsl_sf_mathieu_b (int n, double q)
              int gsl_sf_mathieu_b_e (int n, double q, gsl_sf_result * result)

   These routines compute the characteristic values :math:`a_n(q)`,
   :math:`b_n(q)` of the Mathieu functions :math:`ce_n(q,x)` and
   :math:`se_n(q,x)`, respectively.

.. function:: int gsl_sf_mathieu_a_array (int order_min, int order_max, double q, gsl_sf_mathieu_workspace * work, double result_array[])
              int gsl_sf_mathieu_b_array (int order_min, int order_max, double q, gsl_sf_mathieu_workspace * work, double result_array[])

   These routines compute a series of Mathieu characteristic values
   :math:`a_n(q)`, :math:`b_n(q)` for :math:`n` from :data:`order_min` to
   :data:`order_max` inclusive, storing the results in the array :data:`result_array`.

Angular Mathieu Functions
-------------------------
.. index::
   single: Angular Mathieu Functions
   single: ce(q,x), Mathieu function
   single: se(q,x), Mathieu function

.. function:: int gsl_sf_mathieu_ce (int n, double q, double x)
              int gsl_sf_mathieu_ce_e (int n, double q, double x, gsl_sf_result * result)
              int gsl_sf_mathieu_se (int n, double q, double x)
              int gsl_sf_mathieu_se_e (int n, double q, double x, gsl_sf_result * result)

   These routines compute the angular Mathieu functions :math:`ce_n(q,x)`
   and :math:`se_n(q,x)`, respectively.

.. function:: int gsl_sf_mathieu_ce_array (int nmin, int nmax, double q, double x, gsl_sf_mathieu_workspace * work, double result_array[])
              int gsl_sf_mathieu_se_array (int nmin, int nmax, double q, double x, gsl_sf_mathieu_workspace * work, double result_array[])

   These routines compute a series of the angular Mathieu functions
   :math:`ce_n(q,x)` and :math:`se_n(q,x)` of order :math:`n` from
   :data:`nmin` to :data:`nmax` inclusive, storing the results in the array
   :data:`result_array`.

Radial Mathieu Functions
------------------------
.. index:: Radial Mathieu Functions

.. function:: int gsl_sf_mathieu_Mc (int j, int n, double q, double x)
              int gsl_sf_mathieu_Mc_e (int j, int n, double q, double x, gsl_sf_result * result)
              int gsl_sf_mathieu_Ms (int j, int n, double q, double x)
              int gsl_sf_mathieu_Ms_e (int j, int n, double q, double x, gsl_sf_result * result)

   These routines compute the radial :data:`j`-th kind Mathieu functions
   :math:`Mc_n^{(j)}(q,x)` and :math:`Ms_n^{(j)}(q,x)` of order :data:`n`.

   The allowed values of :data:`j` are 1 and 2.
   The functions for :math:`j = 3,4` can be computed as 
   :math:`M_n^{(3)} = M_n^{(1)} + iM_n^{(2)}` and
   :math:`M_n^{(4)} = M_n^{(1)} - iM_n^{(2)}`,
   where 
   :math:`M_n^{(j)} = Mc_n^{(j)}` or
   :math:`Ms_n^{(j)}`.

.. function:: int gsl_sf_mathieu_Mc_array (int j, int nmin, int nmax, double q, double x, gsl_sf_mathieu_workspace * work, double result_array[])
              int gsl_sf_mathieu_Ms_array (int j, int nmin, int nmax, double q, double x, gsl_sf_mathieu_workspace * work, double result_array[])

   These routines compute a series of the radial Mathieu functions of
   kind :data:`j`, with order from :data:`nmin` to :data:`nmax` inclusive, storing the
   results in the array :data:`result_array`.
.. index:: Gegenbauer functions

The Gegenbauer polynomials are defined in Abramowitz & Stegun, Chapter
22, where they are known as Ultraspherical polynomials.  The functions
described in this section are declared in the header file
:file:`gsl_sf_gegenbauer.h`.

.. function:: double gsl_sf_gegenpoly_1 (double lambda, double x)
              double gsl_sf_gegenpoly_2 (double lambda, double x)
              double gsl_sf_gegenpoly_3 (double lambda, double x)
              int gsl_sf_gegenpoly_1_e (double lambda, double x, gsl_sf_result * result)
              int gsl_sf_gegenpoly_2_e (double lambda, double x, gsl_sf_result * result)
              int gsl_sf_gegenpoly_3_e (double lambda, double x, gsl_sf_result * result)

   These functions evaluate the Gegenbauer polynomials
   :math:`C^{(\lambda)}_n(x)` using explicit
   representations for :math:`n = 1, 2, 3`.
.. Exceptional Return Values: none

.. function:: double gsl_sf_gegenpoly_n (int n, double lambda, double x)
              int gsl_sf_gegenpoly_n_e (int n, double lambda, double x, gsl_sf_result * result)

   These functions evaluate the Gegenbauer polynomial :math:`C^{(\lambda)}_n(x)`
   for a specific value of :data:`n`,
   :data:`lambda`, :data:`x` subject to :math:`\lambda > -1/2`, :math:`n \ge 0`.
.. Domain: lambda > -1/2, n >= 0
.. Exceptional Return Values: GSL_EDOM

.. function:: int gsl_sf_gegenpoly_array (int nmax, double lambda, double x, double result_array[])

   This function computes an array of Gegenbauer polynomials
   :math:`C^{(\lambda)}_n(x)`
   for :math:`n = 0, 1, 2, \dots, nmax`, subject
   to :math:`\lambda > -1/2`, :math:`nmax \ge 0`.
.. Conditions: n = 0, 1, 2, ... nmax
.. Domain: lambda > -1/2, nmax >= 0
.. Exceptional Return Values: GSL_EDOM
.. GSL documentation master file, created by
   sphinx-quickstart on Mon Feb 27 15:17:27 2017.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

GNU Scientific Library
++++++++++++++++++++++

.. toctree::
   :maxdepth: 2

   intro.rst
   usage.rst
   err.rst
   math.rst
   complex.rst
   poly.rst
   specfunc.rst
   vectors.rst
   permutation.rst
   combination.rst
   multiset.rst
   sort.rst
   blas.rst
   linalg.rst
   eigen.rst
   fft.rst
   integration.rst
   rng.rst
   qrng.rst
   randist.rst
   statistics.rst
   rstat.rst
   movstat.rst
   filter.rst
   histogram.rst
   ntuple.rst
   montecarlo.rst
   siman.rst
   ode-initval.rst
   interp.rst
   diff.rst
   cheb.rst
   sum.rst
   dwt.rst
   dht.rst
   roots.rst
   min.rst
   multiroots.rst
   multimin.rst
   lls.rst
   nls.rst
   bspline.rst
   spmatrix.rst
   spblas.rst
   splinalg.rst
   const.rst
   ieee754.rst

   debug.rst
   contrib.rst
   autoconf.rst
   cblas.rst
   gpl.rst
   fdl.rst


* :ref:`genindex`
.. index::
   single: solving nonlinear systems of equations
   single: nonlinear systems of equations, solution of
   single: systems of equations, nonlinear

*****************************
Multidimensional Root-Finding
*****************************

.. include:: include.rst

This chapter describes functions for multidimensional root-finding
(solving nonlinear systems with :math:`n` equations in :math:`n`
unknowns).  The library provides low level components for a variety of
iterative solvers and convergence tests.  These can be combined by the
user to achieve the desired solution, with full access to the
intermediate steps of the iteration.  Each class of methods uses the
same framework, so that you can switch between solvers at runtime
without needing to recompile your program.  Each instance of a solver
keeps track of its own state, allowing the solvers to be used in
multi-threaded programs.  The solvers are based on the original Fortran
library |minpack|.

The header file :file:`gsl_multiroots.h` contains prototypes for the
multidimensional root finding functions and related declarations.

.. index::
   single: multidimensional root finding, overview

Overview
========

The problem of multidimensional root finding requires the simultaneous
solution of :math:`n` equations, :math:`f_i`, in :math:`n` variables,
:math:`x_i`,

.. only:: not texinfo

   .. math:: f_i (x_1, \dots, x_n) = 0 \qquad\hbox{for}~i = 1 \dots n.

.. only:: texinfo

   ::

      f_i (x_1, ..., x_n) = 0    for i = 1 ... n.

In general there are no bracketing methods available for :math:`n`
dimensional systems, and no way of knowing whether any solutions
exist.  All algorithms proceed from an initial guess using a variant of
the Newton iteration,

.. only:: not texinfo

   .. math:: x \to x' = x - J^{-1} f(x)

.. only:: texinfo

   ::

      x -> x' = x - J^{-1} f(x)

where :math:`x`, :math:`f` are vector quantities and :math:`J` is the
Jacobian matrix :math:`J_{ij} = \partial f_i / \partial x_j`.
Additional strategies can be used to enlarge the region of
convergence.  These include requiring a decrease in the norm :math:`|f|` on
each step proposed by Newton's method, or taking steepest-descent steps in
the direction of the negative gradient of :math:`|f|`.

Several root-finding algorithms are available within a single framework.
The user provides a high-level driver for the algorithms, and the
library provides the individual functions necessary for each of the
steps.  There are three main phases of the iteration.  The steps are,

* initialize solver state, :data:`s`, for algorithm :data:`T`
* update :data:`s` using the iteration :data:`T`
* test :data:`s` for convergence, and repeat iteration if necessary

The evaluation of the Jacobian matrix can be problematic, either because
programming the derivatives is intractable or because computation of the
:math:`n^2` terms of the matrix becomes too expensive.  For these reasons
the algorithms provided by the library are divided into two classes according
to whether the derivatives are available or not.

.. index::
   single: Jacobian matrix, root finding

The state for solvers with an analytic Jacobian matrix is held in a
:type:`gsl_multiroot_fdfsolver` struct.  The updating procedure requires
both the function and its derivatives to be supplied by the user.

The state for solvers which do not use an analytic Jacobian matrix is
held in a :type:`gsl_multiroot_fsolver` struct.  The updating procedure
uses only function evaluations (not derivatives).  The algorithms
estimate the matrix :math:`J` or :math:`J^{-1}`
by approximate methods.

Initializing the Solver
=======================

The following functions initialize a multidimensional solver, either
with or without derivatives.  The solver itself depends only on the
dimension of the problem and the algorithm and can be reused for
different problems.

.. type:: gsl_multiroot_fsolver

   This is a workspace for multidimensional root-finding without derivatives.

.. type:: gsl_multiroot_fdfsolver

   This is a workspace for multidimensional root-finding with derivatives.

.. function:: gsl_multiroot_fsolver * gsl_multiroot_fsolver_alloc (const gsl_multiroot_fsolver_type * T, size_t n)

   This function returns a pointer to a newly allocated instance of a
   solver of type :data:`T` for a system of :data:`n` dimensions.
   For example, the following code creates an instance of a hybrid solver, 
   to solve a 3-dimensional system of equations::

      const gsl_multiroot_fsolver_type * T = gsl_multiroot_fsolver_hybrid;
      gsl_multiroot_fsolver * s = gsl_multiroot_fsolver_alloc (T, 3);

   If there is insufficient memory to create the solver then the function
   returns a null pointer and the error handler is invoked with an error
   code of :macro:`GSL_ENOMEM`.

.. function:: gsl_multiroot_fdfsolver * gsl_multiroot_fdfsolver_alloc (const gsl_multiroot_fdfsolver_type * T, size_t n)

   This function returns a pointer to a newly allocated instance of a
   derivative solver of type :data:`T` for a system of :data:`n` dimensions.
   For example, the following code creates an instance of a Newton-Raphson solver,
   for a 2-dimensional system of equations::

      const gsl_multiroot_fdfsolver_type * T = gsl_multiroot_fdfsolver_newton;
      gsl_multiroot_fdfsolver * s = gsl_multiroot_fdfsolver_alloc (T, 2);

   If there is insufficient memory to create the solver then the function
   returns a null pointer and the error handler is invoked with an error
   code of :macro:`GSL_ENOMEM`.

.. function:: int gsl_multiroot_fsolver_set (gsl_multiroot_fsolver * s, gsl_multiroot_function * f, const gsl_vector * x)
              int gsl_multiroot_fdfsolver_set (gsl_multiroot_fdfsolver * s, gsl_multiroot_function_fdf * fdf, const gsl_vector * x)

   These functions set, or reset, an existing solver :data:`s` to use the
   function :data:`f` or function and derivative :data:`fdf`, and the initial
   guess :data:`x`.  Note that the initial position is copied from :data:`x`, this
   argument is not modified by subsequent iterations.

.. function:: void gsl_multiroot_fsolver_free (gsl_multiroot_fsolver * s)
              void gsl_multiroot_fdfsolver_free (gsl_multiroot_fdfsolver * s)

   These functions free all the memory associated with the solver :data:`s`.

.. function:: const char * gsl_multiroot_fsolver_name (const gsl_multiroot_fsolver * s)
              const char * gsl_multiroot_fdfsolver_name (const gsl_multiroot_fdfsolver * s)

   These functions return a pointer to the name of the solver.  For example::

      printf ("s is a '%s' solver\n", gsl_multiroot_fdfsolver_name (s));

   would print something like :code:`s is a 'newton' solver`.

.. index::
   single: multidimensional root finding, providing a function to solve

Providing the function to solve
===============================

You must provide :math:`n` functions of :math:`n` variables for the root
finders to operate on.  In order to allow for general parameters the
functions are defined by the following data types:

.. type:: gsl_multiroot_function 

   This data type defines a general system of functions with parameters.

   :code:`int (* f) (const gsl_vector * x, void * params, gsl_vector * f)`

      this function should store the vector result
      :math:`f(x,params)` in :data:`f` for argument :data:`x` and parameters :data:`params`,
      returning an appropriate error code if the function cannot be computed.

   :code:`size_t n`

      the dimension of the system, i.e. the number of components of the
      vectors :data:`x` and :data:`f`.

   :code:`void * params`

      a pointer to the parameters of the function.

Here is an example using Powell's test function,

.. only:: not texinfo

   .. math::

      f_1(x) &= A x_0 x_1 - 1 \\
      f_2(x) &= \exp(-x_0) + \exp(-x_1) - (1 + 1/A)

.. only:: texinfo

   ::

      f_1(x) = A x_0 x_1 - 1,
      f_2(x) = exp(-x_0) + exp(-x_1) - (1 + 1/A)

with :math:`A = 10^4`.  The following code defines a
:type:`gsl_multiroot_function` system :code:`F` which you could pass to a
solver::

  struct powell_params { double A; };

  int
  powell (gsl_vector * x, void * p, gsl_vector * f) {
     struct powell_params * params 
       = (struct powell_params *)p;
     const double A = (params->A);
     const double x0 = gsl_vector_get(x,0);
     const double x1 = gsl_vector_get(x,1);

     gsl_vector_set (f, 0, A * x0 * x1 - 1);
     gsl_vector_set (f, 1, (exp(-x0) + exp(-x1) 
                            - (1.0 + 1.0/A)));
     return GSL_SUCCESS
  }

  gsl_multiroot_function F;
  struct powell_params params = { 10000.0 };

  F.f = &powell;
  F.n = 2;
  F.params = &params;

.. type:: gsl_multiroot_function_fdf

   This data type defines a general system of functions with parameters and
   the corresponding Jacobian matrix of derivatives,

   :code:`int (* f) (const gsl_vector * x, void * params, gsl_vector * f)`

      this function should store the vector result
      :math:`f(x,params)` in :data:`f` for argument :data:`x` and parameters :data:`params`,
      returning an appropriate error code if the function cannot be computed.

   :code:`int (* df) (const gsl_vector * x, void * params, gsl_matrix * J)`

      this function should store the :data:`n`-by-:data:`n` matrix result

      .. only:: not texinfo

         .. math:: J_{ij} = \partial f_i(x,\hbox{\it params}) / \partial x_j

      .. only:: texinfo

         ::

            J_ij = d f_i(x,params) / d x_j
            
      in :data:`J` for argument :data:`x` 
      and parameters :data:`params`, returning an appropriate error code if the
      function cannot be computed.

   :code:`int (* fdf) (const gsl_vector * x, void * params, gsl_vector * f, gsl_matrix * J)`

      This function should set the values of the :data:`f` and :data:`J` as above,
      for arguments :data:`x` and parameters :data:`params`.  This function
      provides an optimization of the separate functions for :math:`f(x)` and
      :math:`J(x)`---it is always faster to compute the function and its
      derivative at the same time.

   :code:`size_t n`

      the dimension of the system, i.e. the number of components of the
      vectors :data:`x` and :data:`f`.

   :code:`void * params`

      a pointer to the parameters of the function.

The example of Powell's test function defined above can be extended to
include analytic derivatives using the following code::

  int
  powell_df (gsl_vector * x, void * p, gsl_matrix * J) 
  {
     struct powell_params * params 
       = (struct powell_params *)p;
     const double A = (params->A);
     const double x0 = gsl_vector_get(x,0);
     const double x1 = gsl_vector_get(x,1);
     gsl_matrix_set (J, 0, 0, A * x1);
     gsl_matrix_set (J, 0, 1, A * x0);
     gsl_matrix_set (J, 1, 0, -exp(-x0));
     gsl_matrix_set (J, 1, 1, -exp(-x1));
     return GSL_SUCCESS
  }

  int
  powell_fdf (gsl_vector * x, void * p, 
              gsl_matrix * f, gsl_matrix * J) {
     struct powell_params * params 
       = (struct powell_params *)p;
     const double A = (params->A);
     const double x0 = gsl_vector_get(x,0);
     const double x1 = gsl_vector_get(x,1);

     const double u0 = exp(-x0);
     const double u1 = exp(-x1);

     gsl_vector_set (f, 0, A * x0 * x1 - 1);
     gsl_vector_set (f, 1, u0 + u1 - (1 + 1/A));

     gsl_matrix_set (J, 0, 0, A * x1);
     gsl_matrix_set (J, 0, 1, A * x0);
     gsl_matrix_set (J, 1, 0, -u0);
     gsl_matrix_set (J, 1, 1, -u1);
     return GSL_SUCCESS
  }

  gsl_multiroot_function_fdf FDF;

  FDF.f = &powell_f;
  FDF.df = &powell_df;
  FDF.fdf = &powell_fdf;
  FDF.n = 2;
  FDF.params = 0;

Note that the function :code:`powell_fdf` is able to reuse existing terms
from the function when calculating the Jacobian, thus saving time.

Iteration
=========

The following functions drive the iteration of each algorithm.  Each
function performs one iteration to update the state of any solver of the
corresponding type.  The same functions work for all solvers so that
different methods can be substituted at runtime without modifications to
the code.

.. function:: int gsl_multiroot_fsolver_iterate (gsl_multiroot_fsolver * s)
              int gsl_multiroot_fdfsolver_iterate (gsl_multiroot_fdfsolver * s)

   These functions perform a single iteration of the solver :data:`s`.  If the
   iteration encounters an unexpected problem then an error code will be
   returned,

   :macro:`GSL_EBADFUNC`

      the iteration encountered a singular point where the function or its
      derivative evaluated to :code:`Inf` or :code:`NaN`.

   :macro:`GSL_ENOPROG`

      the iteration is not making any progress, preventing the algorithm from
      continuing.

The solver maintains a current best estimate of the root :code:`s->x`
and its function value :code:`s->f` at all times.  This information can
be accessed with the following auxiliary functions,

.. function:: gsl_vector * gsl_multiroot_fsolver_root (const gsl_multiroot_fsolver * s)
              gsl_vector * gsl_multiroot_fdfsolver_root (const gsl_multiroot_fdfsolver * s)

   These functions return the current estimate of the root for the solver :data:`s`, given by :code:`s->x`.

.. function:: gsl_vector * gsl_multiroot_fsolver_f (const gsl_multiroot_fsolver * s)
              gsl_vector * gsl_multiroot_fdfsolver_f (const gsl_multiroot_fdfsolver * s)

   These functions return the function value :math:`f(x)` at the current
   estimate of the root for the solver :data:`s`, given by :code:`s->f`.

.. function:: gsl_vector * gsl_multiroot_fsolver_dx (const gsl_multiroot_fsolver * s)
              gsl_vector * gsl_multiroot_fdfsolver_dx (const gsl_multiroot_fdfsolver * s)

   These functions return the last step :math:`dx` taken by the solver
   :data:`s`, given by :code:`s->dx`.

.. index::
   single: root finding, stopping parameters

Search Stopping Parameters
==========================

A root finding procedure should stop when one of the following conditions is
true:

* A multidimensional root has been found to within the user-specified precision.
* A user-specified maximum number of iterations has been reached.
* An error has occurred.

The handling of these conditions is under user control.  The functions
below allow the user to test the precision of the current result in
several standard ways.

.. function:: int gsl_multiroot_test_delta (const gsl_vector * dx, const gsl_vector * x, double epsabs, double epsrel)

   This function tests for the convergence of the sequence by comparing the
   last step :data:`dx` with the absolute error :data:`epsabs` and relative
   error :data:`epsrel` to the current position :data:`x`.  The test returns
   :macro:`GSL_SUCCESS` if the following condition is achieved,

   .. only:: not texinfo

      .. math:: |dx_i| < \hbox{\it epsabs} + \hbox{\it epsrel\/}\, |x_i|

   .. only:: texinfo

      ::

         |dx_i| < epsabs + epsrel |x_i|

   for each component of :data:`x` and returns :macro:`GSL_CONTINUE` otherwise.

.. index::
   single: residual, in nonlinear systems of equations

.. function:: int gsl_multiroot_test_residual (const gsl_vector * f, double epsabs)

   This function tests the residual value :data:`f` against the absolute
   error bound :data:`epsabs`.  The test returns :macro:`GSL_SUCCESS` if the
   following condition is achieved,

   .. only:: not texinfo

      .. math:: \sum_i |f_i| < \hbox{\it epsabs}

   .. only:: texinfo

      ::

         \sum_i |f_i| < epsabs

   and returns :macro:`GSL_CONTINUE` otherwise.  This criterion is suitable
   for situations where the precise location of the root, :math:`x`, is
   unimportant provided a value can be found where the residual is small
   enough.

Algorithms using Derivatives
============================

The root finding algorithms described in this section make use of both
the function and its derivative.  They require an initial guess for the
location of the root, but there is no absolute guarantee of
convergence---the function must be suitable for this technique and the
initial guess must be sufficiently close to the root for it to work.
When the conditions are satisfied then convergence is quadratic.

.. type:: gsl_multiroot_fdfsolver_type

   The following are available algorithms for minimizing functions using
   derivatives.

   .. index:: HYBRID algorithms for nonlinear systems

   .. index::
      single: HYBRIDSJ algorithm
      single: MINPACK, minimization algorithms

   .. var:: gsl_multiroot_fdfsolver_hybridsj

      This is a modified version of Powell's Hybrid method as implemented in
      the HYBRJ algorithm in |minpack|.  Minpack was written by Jorge
      J. |More|, Burton S. Garbow and Kenneth E. Hillstrom.  The Hybrid
      algorithm retains the fast convergence of Newton's method but will also
      reduce the residual when Newton's method is unreliable. 

      The algorithm uses a generalized trust region to keep each step under
      control.  In order to be accepted a proposed new position :math:`x'` must
      satisfy the condition :math:`|D (x' - x)| < \delta`, where :math:`D` is a
      diagonal scaling matrix and :math:`\delta` is the size of the trust
      region.  The components of :math:`D` are computed internally, using the
      column norms of the Jacobian to estimate the sensitivity of the residual
      to each component of :math:`x`.  This improves the behavior of the
      algorithm for badly scaled functions.

      On each iteration the algorithm first determines the standard Newton
      step by solving the system :math:`J dx = - f`.  If this step falls inside
      the trust region it is used as a trial step in the next stage.  If not,
      the algorithm uses the linear combination of the Newton and gradient
      directions which is predicted to minimize the norm of the function while
      staying inside the trust region,

      .. math:: dx = - \alpha J^{-1} f(x) - \beta \nabla |f(x)|^2

      This combination of Newton and gradient directions is referred to as a
      *dogleg step*.

      The proposed step is now tested by evaluating the function at the
      resulting point, :math:`x'`.  If the step reduces the norm of the function
      sufficiently then it is accepted and size of the trust region is
      increased.  If the proposed step fails to improve the solution then the
      size of the trust region is decreased and another trial step is
      computed.

      The speed of the algorithm is increased by computing the changes to the
      Jacobian approximately, using a rank-1 update.  If two successive
      attempts fail to reduce the residual then the full Jacobian is
      recomputed.  The algorithm also monitors the progress of the solution
      and returns an error if several steps fail to make any improvement,

      :macro:`GSL_ENOPROG`

         the iteration is not making any progress, preventing the algorithm from
         continuing.

      :macro:`GSL_ENOPROGJ`

         re-evaluations of the Jacobian indicate that the iteration is not
         making any progress, preventing the algorithm from continuing.

   .. index:: HYBRIDJ algorithm

   .. var:: gsl_multiroot_fdfsolver_hybridj

      This algorithm is an unscaled version of HYBRIDSJ.  The steps are
      controlled by a spherical trust region :math:`|x' - x| < \delta`, instead
      of a generalized region.  This can be useful if the generalized region
      estimated by HYBRIDSJ is inappropriate.

   .. index:: Newton's method for systems of nonlinear equations

   .. var:: gsl_multiroot_fdfsolver_newton

      Newton's Method is the standard root-polishing algorithm.  The algorithm
      begins with an initial guess for the location of the solution.  On each
      iteration a linear approximation to the function :math:`F` is used to
      estimate the step which will zero all the components of the residual.
      The iteration is defined by the following sequence,

      .. only:: not texinfo

         .. math:: x \to x' = x - J^{-1} f(x)

      .. only:: texinfo

         ::

            x -> x' = x - J^{-1} f(x)

      where the Jacobian matrix :math:`J` is computed from the derivative
      functions provided by :data:`f`.  The step :math:`dx` is obtained by solving
      the linear system,

      .. math:: J dx = - f(x)

      using LU decomposition.  If the Jacobian matrix is singular, an error
      code of :macro:`GSL_EDOM` is returned.

   .. index::
      single: Modified Newton's method for nonlinear systems
      single: Newton algorithm, globally convergent

   .. var:: gsl_multiroot_fdfsolver_gnewton

      This is a modified version of Newton's method which attempts to improve
      global convergence by requiring every step to reduce the Euclidean norm
      of the residual, :math:`|f(x)|`.  If the Newton step leads to an increase
      in the norm then a reduced step of relative size,

      .. math:: t = (\sqrt{1 + 6 r} - 1) / (3 r)

      is proposed, with :math:`r` being the ratio of norms
      :math:`|f(x')|^2/|f(x)|^2`.  This procedure is repeated until a suitable step
      size is found. 

Algorithms without Derivatives
==============================

The algorithms described in this section do not require any derivative
information to be supplied by the user.  Any derivatives needed are
approximated by finite differences.  Note that if the
finite-differencing step size chosen by these routines is inappropriate,
an explicit user-supplied numerical derivative can always be used with
the algorithms described in the previous section.

.. type:: gsl_multiroot_fsolver_type

   The following are available algorithms for minimizing functions without
   derivatives.

   .. index::
      single: HYBRIDS algorithm, scaled without derivatives

   .. var:: gsl_multiroot_fsolver_hybrids

      This is a version of the Hybrid algorithm which replaces calls to the
      Jacobian function by its finite difference approximation.  The finite
      difference approximation is computed using :func:`gsl_multiroots_fdjac`
      with a relative step size of :macro:`GSL_SQRT_DBL_EPSILON`.  Note that
      this step size will not be suitable for all problems.

   .. index::
      single: HYBRID algorithm, unscaled without derivatives

   .. var:: gsl_multiroot_fsolver_hybrid

      This is a finite difference version of the Hybrid algorithm without
      internal scaling.

   .. index::
      single: Discrete Newton algorithm for multidimensional roots
      single: Newton algorithm, discrete

   .. var:: gsl_multiroot_fsolver_dnewton

      The *discrete Newton algorithm* is the simplest method of solving a
      multidimensional system.  It uses the Newton iteration

      .. only:: not texinfo

         .. math:: x \to x - J^{-1} f(x)

      .. only:: texinfo

         ::

            x -> x - J^{-1} f(x)

      where the Jacobian matrix :math:`J` is approximated by taking finite
      differences of the function :data:`f`.  The approximation scheme used by
      this implementation is,

      .. math:: J_{ij} = (f_i(x + \delta_j) - f_i(x)) /  \delta_j

      where :math:`\delta_j` is a step of size :math:`\sqrt\epsilon |x_j|` with
      :math:`\epsilon` being the machine precision 
      (:math:`\epsilon \approx 2.22 \times 10^{-16}`).
      The order of convergence of Newton's algorithm is quadratic, but the
      finite differences require :math:`n^2` function evaluations on each
      iteration.  The algorithm may become unstable if the finite differences
      are not a good approximation to the true derivatives.

   .. index::
      single: Broyden algorithm for multidimensional roots
      single: multidimensional root finding, Broyden algorithm

   .. var:: gsl_multiroot_fsolver_broyden

      The *Broyden algorithm* is a version of the discrete Newton
      algorithm which attempts to avoids the expensive update of the Jacobian
      matrix on each iteration.  The changes to the Jacobian are also
      approximated, using a rank-1 update,

      .. math:: J^{-1} \to J^{-1} - (J^{-1} df - dx) dx^T J^{-1} / dx^T J^{-1} df

      where the vectors :math:`dx` and :math:`df` are the changes in :math:`x`
      and :math:`f`.  On the first iteration the inverse Jacobian is estimated
      using finite differences, as in the discrete Newton algorithm.
 
      This approximation gives a fast update but is unreliable if the changes
      are not small, and the estimate of the inverse Jacobian becomes worse as
      time passes.  The algorithm has a tendency to become unstable unless it
      starts close to the root.  The Jacobian is refreshed if this instability
      is detected (consult the source for details).

      This algorithm is included only for demonstration purposes, and is not
      recommended for serious use.

Examples
========

The multidimensional solvers are used in a similar way to the
one-dimensional root finding algorithms.  This first example
demonstrates the HYBRIDS scaled-hybrid algorithm, which does not
require derivatives. The program solves the Rosenbrock system of equations,

.. only:: not texinfo

   .. math::

      f_1 (x, y) &= a (1 - x) \\
      f_2 (x, y) &= b (y - x^2)

.. only:: texinfo

   ::

      f_1 (x, y) = a (1 - x)
      f_2 (x, y) = b (y - x^2)

with :math:`a = 1, b = 10`. The solution of this system lies at
:math:`(x,y) = (1,1)` in a narrow valley.

The first stage of the program is to define the system of equations::

  #include <stdlib.h>
  #include <stdio.h>
  #include <gsl/gsl_vector.h>
  #include <gsl/gsl_multiroots.h>

  struct rparams
    {
      double a;
      double b;
    };

  int
  rosenbrock_f (const gsl_vector * x, void *params, 
                gsl_vector * f)
  {
    double a = ((struct rparams *) params)->a;
    double b = ((struct rparams *) params)->b;

    const double x0 = gsl_vector_get (x, 0);
    const double x1 = gsl_vector_get (x, 1);

    const double y0 = a * (1 - x0);
    const double y1 = b * (x1 - x0 * x0);

    gsl_vector_set (f, 0, y0);
    gsl_vector_set (f, 1, y1);

    return GSL_SUCCESS;
  }

The main program begins by creating the function object :code:`f`, with
the arguments :code:`(x,y)` and parameters :code:`(a,b)`. The solver
:code:`s` is initialized to use this function, with the :data:`gsl_multiroot_fsolver_hybrids`
method::

  int
  main (void)
  {
    const gsl_multiroot_fsolver_type *T;
    gsl_multiroot_fsolver *s;

    int status;
    size_t i, iter = 0;

    const size_t n = 2;
    struct rparams p = {1.0, 10.0};
    gsl_multiroot_function f = {&rosenbrock_f, n, &p};

    double x_init[2] = {-10.0, -5.0};
    gsl_vector *x = gsl_vector_alloc (n);

    gsl_vector_set (x, 0, x_init[0]);
    gsl_vector_set (x, 1, x_init[1]);

    T = gsl_multiroot_fsolver_hybrids;
    s = gsl_multiroot_fsolver_alloc (T, 2);
    gsl_multiroot_fsolver_set (s, &f, x);

    print_state (iter, s);

    do
      {
        iter++;
        status = gsl_multiroot_fsolver_iterate (s);

        print_state (iter, s);

        if (status)   /* check if solver is stuck */
          break;

        status = 
          gsl_multiroot_test_residual (s->f, 1e-7);
      }
    while (status == GSL_CONTINUE && iter < 1000);

    printf ("status = %s\n", gsl_strerror (status));

    gsl_multiroot_fsolver_free (s);
    gsl_vector_free (x);
    return 0;
  }

Note that it is important to check the return status of each solver
step, in case the algorithm becomes stuck.  If an error condition is
detected, indicating that the algorithm cannot proceed, then the error
can be reported to the user, a new starting point chosen or a different
algorithm used.

The intermediate state of the solution is displayed by the following
function.  The solver state contains the vector :code:`s->x` which is the
current position, and the vector :code:`s->f` with corresponding function
values::

  int
  print_state (size_t iter, gsl_multiroot_fsolver * s)
  {
    printf ("iter = %3u x = % .3f % .3f "
            "f(x) = % .3e % .3e\n",
            iter,
            gsl_vector_get (s->x, 0), 
            gsl_vector_get (s->x, 1),
            gsl_vector_get (s->f, 0), 
            gsl_vector_get (s->f, 1));
  }

Here are the results of running the program. The algorithm is started at
:math:`(-10,-5)` far from the solution.  Since the solution is hidden in
a narrow valley the earliest steps follow the gradient of the function
downhill, in an attempt to reduce the large value of the residual. Once
the root has been approximately located, on iteration 8, the Newton
behavior takes over and convergence is very rapid::

  iter =  0 x = -10.000  -5.000  f(x) = 1.100e+01 -1.050e+03
  iter =  1 x = -10.000  -5.000  f(x) = 1.100e+01 -1.050e+03
  iter =  2 x =  -3.976  24.827  f(x) = 4.976e+00  9.020e+01
  iter =  3 x =  -3.976  24.827  f(x) = 4.976e+00  9.020e+01
  iter =  4 x =  -3.976  24.827  f(x) = 4.976e+00  9.020e+01
  iter =  5 x =  -1.274  -5.680  f(x) = 2.274e+00 -7.302e+01
  iter =  6 x =  -1.274  -5.680  f(x) = 2.274e+00 -7.302e+01
  iter =  7 x =   0.249   0.298  f(x) = 7.511e-01  2.359e+00
  iter =  8 x =   0.249   0.298  f(x) = 7.511e-01  2.359e+00
  iter =  9 x =   1.000   0.878  f(x) = 1.268e-10 -1.218e+00
  iter = 10 x =   1.000   0.989  f(x) = 1.124e-11 -1.080e-01
  iter = 11 x =   1.000   1.000  f(x) = 0.000e+00  0.000e+00
  status = success

Note that the algorithm does not update the location on every
iteration. Some iterations are used to adjust the trust-region
parameter, after trying a step which was found to be divergent, or to
recompute the Jacobian, when poor convergence behavior is detected.

The next example program adds derivative information, in order to
accelerate the solution. There are two derivative functions
:code:`rosenbrock_df` and :code:`rosenbrock_fdf`. The latter computes both
the function and its derivative simultaneously. This allows the
optimization of any common terms.  For simplicity we substitute calls to
the separate :code:`f` and :code:`df` functions at this point in the code
below::

  int
  rosenbrock_df (const gsl_vector * x, void *params, 
                 gsl_matrix * J)
  {
    const double a = ((struct rparams *) params)->a;
    const double b = ((struct rparams *) params)->b;

    const double x0 = gsl_vector_get (x, 0);

    const double df00 = -a;
    const double df01 = 0;
    const double df10 = -2 * b  * x0;
    const double df11 = b;

    gsl_matrix_set (J, 0, 0, df00);
    gsl_matrix_set (J, 0, 1, df01);
    gsl_matrix_set (J, 1, 0, df10);
    gsl_matrix_set (J, 1, 1, df11);

    return GSL_SUCCESS;
  }

  int
  rosenbrock_fdf (const gsl_vector * x, void *params,
                  gsl_vector * f, gsl_matrix * J)
  {
    rosenbrock_f (x, params, f);
    rosenbrock_df (x, params, J);

    return GSL_SUCCESS;
  }

The main program now makes calls to the corresponding :code:`fdfsolver`
versions of the functions::

  int
  main (void)
  {
    const gsl_multiroot_fdfsolver_type *T;
    gsl_multiroot_fdfsolver *s;

    int status;
    size_t i, iter = 0;

    const size_t n = 2;
    struct rparams p = {1.0, 10.0};
    gsl_multiroot_function_fdf f = {&rosenbrock_f, 
                                    &rosenbrock_df, 
                                    &rosenbrock_fdf, 
                                    n, &p};

    double x_init[2] = {-10.0, -5.0};
    gsl_vector *x = gsl_vector_alloc (n);

    gsl_vector_set (x, 0, x_init[0]);
    gsl_vector_set (x, 1, x_init[1]);

    T = gsl_multiroot_fdfsolver_gnewton;
    s = gsl_multiroot_fdfsolver_alloc (T, n);
    gsl_multiroot_fdfsolver_set (s, &f, x);

    print_state (iter, s);

    do
      {
        iter++;

        status = gsl_multiroot_fdfsolver_iterate (s);

        print_state (iter, s);

        if (status)
          break;

        status = gsl_multiroot_test_residual (s->f, 1e-7);
      }
    while (status == GSL_CONTINUE && iter < 1000);

    printf ("status = %s\n", gsl_strerror (status));

    gsl_multiroot_fdfsolver_free (s);
    gsl_vector_free (x);
    return 0;
  }

The addition of derivative information to the :data:`gsl_multiroot_fsolver_hybrids` solver does
not make any significant difference to its behavior, since it able to
approximate the Jacobian numerically with sufficient accuracy.  To
illustrate the behavior of a different derivative solver we switch to
:data:`gsl_multiroot_fdfsolver_gnewton`. This is a traditional Newton solver with the constraint
that it scales back its step if the full step would lead "uphill". Here
is the output for the :data:`gsl_multiroot_fdfsolver_gnewton` algorithm::

  iter = 0 x = -10.000  -5.000 f(x) =  1.100e+01 -1.050e+03
  iter = 1 x =  -4.231 -65.317 f(x) =  5.231e+00 -8.321e+02
  iter = 2 x =   1.000 -26.358 f(x) = -8.882e-16 -2.736e+02
  iter = 3 x =   1.000   1.000 f(x) = -2.220e-16 -4.441e-15
  status = success

The convergence is much more rapid, but takes a wide excursion out to
the point :math:`(-4.23,-65.3)`. This could cause the algorithm to go
astray in a realistic application.  The hybrid algorithm follows the
downhill path to the solution more reliably.

References and Further Reading
==============================

The original version of the Hybrid method is described in the following
articles by Powell,

* M.J.D. Powell, "A Hybrid Method for Nonlinear Equations" (Chap 6, p
  87--114) and "A Fortran Subroutine for Solving systems of Nonlinear
  Algebraic Equations" (Chap 7, p 115--161), in *Numerical Methods for
  Nonlinear Algebraic Equations*, P. Rabinowitz, editor.  Gordon and
  Breach, 1970.

The following papers are also relevant to the algorithms described in
this section,

* J.J. |More|, M.Y. Cosnard, "Numerical Solution of Nonlinear Equations",
  *ACM Transactions on Mathematical Software*, Vol 5, No 1, (1979), p 64--85

* C.G. Broyden, "A Class of Methods for Solving Nonlinear
  Simultaneous Equations", *Mathematics of Computation*, Vol 19 (1965),
  p 577--593

* J.J. |More|, B.S. Garbow, K.E. Hillstrom, "Testing Unconstrained
  Optimization Software", ACM Transactions on Mathematical Software, Vol
  7, No 1 (1981), p 17--41
******************************
GNU Free Documentation License
******************************

.. literalinclude:: _static/fdl.txt
.. index::
   single: optimization, see minimization
   single: maximization, see minimization
   single: minimization, one-dimensional
   single: finding minima
   single: nonlinear functions, minimization

****************************
One Dimensional Minimization
****************************

This chapter describes routines for finding minima of arbitrary
one-dimensional functions.  The library provides low level components
for a variety of iterative minimizers and convergence tests.  These can be
combined by the user to achieve the desired solution, with full access
to the intermediate steps of the algorithms.  Each class of methods uses
the same framework, so that you can switch between minimizers at runtime
without needing to recompile your program.  Each instance of a minimizer
keeps track of its own state, allowing the minimizers to be used in
multi-threaded programs.

The header file :file:`gsl_min.h` contains prototypes for the
minimization functions and related declarations.  To use the minimization
algorithms to find the maximum of a function simply invert its sign.

.. index::
   single: minimization, overview

Overview
========

The minimization algorithms begin with a bounded region known to contain
a minimum.  The region is described by a lower bound :math:`a` and an
upper bound :math:`b`, with an estimate of the location of the minimum
:math:`x`, as shown in :numref:`fig_min-interval`.

.. _fig_min-interval:

.. figure:: /images/min-interval.png
   :scale: 60%

   Function with lower and upper bounds with an estimate of the minimum.

The value of the function at :math:`x` must be less than the value of the
function at the ends of the interval,

.. math:: f(a) > f(x) < f(b)

This condition guarantees that a minimum is contained somewhere within
the interval.  On each iteration a new point :math:`x'` is selected using
one of the available algorithms.  If the new point is a better estimate
of the minimum, i.e.: where :math:`f(x') < f(x)`, then the current
estimate of the minimum :math:`x` is updated.  The new point also allows
the size of the bounded interval to be reduced, by choosing the most
compact set of points which satisfies the constraint :math:`f(a) > f(x) < f(b)`.
The interval is reduced until it encloses the true minimum to a
desired tolerance.  This provides a best estimate of the location of the
minimum and a rigorous error estimate.

Several bracketing algorithms are available within a single framework.
The user provides a high-level driver for the algorithm, and the
library provides the individual functions necessary for each of the
steps.  There are three main phases of the iteration.  The steps are,

* initialize minimizer state, :data:`s`, for algorithm :data:`T`
* update :data:`s` using the iteration :data:`T`
* test :data:`s` for convergence, and repeat iteration if necessary

The state for the minimizers is held in a :type:`gsl_min_fminimizer`
struct.  The updating procedure uses only function evaluations (not
derivatives).

.. index::
   single: minimization, caveats

Caveats
=======

Note that minimization functions can only search for one minimum at a
time.  When there are several minima in the search area, the first
minimum to be found will be returned; however it is difficult to predict
which of the minima this will be. *In most cases, no error will be
reported if you try to find a minimum in an area where there is more
than one.*

With all minimization algorithms it can be difficult to determine the
location of the minimum to full numerical precision.  The behavior of the
function in the region of the minimum :math:`x^*` can be approximated by
a Taylor expansion,

.. only:: not texinfo

   .. math:: y = f(x^*) + {1 \over 2} f''(x^*) (x - x^*)^2

.. only:: texinfo

   ::

      y = f(x^*) + (1/2) f''(x^*) (x - x^*)^2

and the second term of this expansion can be lost when added to the
first term at finite precision.  This magnifies the error in locating
:math:`x^*`, making it proportional to :math:`\sqrt \epsilon` (where
:math:`\epsilon` is the relative accuracy of the floating point numbers).
For functions with higher order minima, such as :math:`x^4`, the
magnification of the error is correspondingly worse.  The best that can
be achieved is to converge to the limit of numerical accuracy in the
function values, rather than the location of the minimum itself.

Initializing the Minimizer
==========================

.. type:: gsl_min_fminimizer

   This is a workspace for minimizing functions.

.. function:: gsl_min_fminimizer * gsl_min_fminimizer_alloc (const gsl_min_fminimizer_type * T)

   This function returns a pointer to a newly allocated instance of a
   minimizer of type :data:`T`.  For example, the following code
   creates an instance of a golden section minimizer::

      const gsl_min_fminimizer_type * T = gsl_min_fminimizer_goldensection;
      gsl_min_fminimizer * s = gsl_min_fminimizer_alloc (T);

   If there is insufficient memory to create the minimizer then the function
   returns a null pointer and the error handler is invoked with an error
   code of :macro:`GSL_ENOMEM`.

.. function:: int gsl_min_fminimizer_set (gsl_min_fminimizer * s, gsl_function * f, double x_minimum, double x_lower, double x_upper)

   This function sets, or resets, an existing minimizer :data:`s` to use the
   function :data:`f` and the initial search interval [:data:`x_lower`,
   :data:`x_upper`], with a guess for the location of the minimum
   :data:`x_minimum`.

   If the interval given does not contain a minimum, then the function
   returns an error code of :macro:`GSL_EINVAL`.

.. function:: int gsl_min_fminimizer_set_with_values (gsl_min_fminimizer * s, gsl_function * f, double x_minimum, double f_minimum, double x_lower, double f_lower, double x_upper, double f_upper)

   This function is equivalent to :func:`gsl_min_fminimizer_set` but uses
   the values :data:`f_minimum`, :data:`f_lower` and :data:`f_upper` instead of
   computing :code:`f(x_minimum)`, :code:`f(x_lower)` and :code:`f(x_upper)`.

.. function:: void gsl_min_fminimizer_free (gsl_min_fminimizer * s)

   This function frees all the memory associated with the minimizer
   :data:`s`.

.. function:: const char * gsl_min_fminimizer_name (const gsl_min_fminimizer * s)

   This function returns a pointer to the name of the minimizer.  For example::

      printf ("s is a '%s' minimizer\n", gsl_min_fminimizer_name (s));

   would print something like :code:`s is a 'brent' minimizer`.

.. index::
   single: minimization, providing a function to minimize

Providing the function to minimize
==================================

You must provide a continuous function of one variable for the
minimizers to operate on.  In order to allow for general parameters the
functions are defined by a :type:`gsl_function` data type
(:ref:`providing-function-to-solve`).

Iteration
=========

The following functions drive the iteration of each algorithm.  Each
function performs one iteration to update the state of any minimizer of the
corresponding type.  The same functions work for all minimizers so that
different methods can be substituted at runtime without modifications to
the code.

.. function:: int gsl_min_fminimizer_iterate (gsl_min_fminimizer * s)

   This function performs a single iteration of the minimizer :data:`s`.  If the
   iteration encounters an unexpected problem then an error code will be
   returned,

   :macro:`GSL_EBADFUNC`

      the iteration encountered a singular point where the function evaluated
      to :code:`Inf` or :code:`NaN`.

   :macro:`GSL_FAILURE`

      the algorithm could not improve the current best approximation or
      bounding interval.

The minimizer maintains a current best estimate of the position of the
minimum at all times, and the current interval bounding the minimum.
This information can be accessed with the following auxiliary functions,

.. function:: double gsl_min_fminimizer_x_minimum (const gsl_min_fminimizer * s)

   This function returns the current estimate of the position of the
   minimum for the minimizer :data:`s`.

.. function:: double gsl_min_fminimizer_x_upper (const gsl_min_fminimizer * s)
              double gsl_min_fminimizer_x_lower (const gsl_min_fminimizer * s)

   These functions return the current upper and lower bound of the interval
   for the minimizer :data:`s`.

.. function:: double gsl_min_fminimizer_f_minimum (const gsl_min_fminimizer * s)
              double gsl_min_fminimizer_f_upper (const gsl_min_fminimizer * s)
              double gsl_min_fminimizer_f_lower (const gsl_min_fminimizer * s)

   These functions return the value of the function at the current estimate
   of the minimum and at the upper and lower bounds of the interval for the
   minimizer :data:`s`.

.. index::
   single: minimization, stopping parameters

Stopping Parameters
===================

A minimization procedure should stop when one of the following
conditions is true:

* A minimum has been found to within the user-specified precision.
* A user-specified maximum number of iterations has been reached.
* An error has occurred.

The handling of these conditions is under user control.  The function
below allows the user to test the precision of the current result.

.. function:: int gsl_min_test_interval (double x_lower, double x_upper,  double epsabs, double epsrel)

   This function tests for the convergence of the interval [:data:`x_lower`,
   :data:`x_upper`] with absolute error :data:`epsabs` and relative error
   :data:`epsrel`.  The test returns :macro:`GSL_SUCCESS` if the following
   condition is achieved,

   .. only:: not texinfo

      .. math:: |a - b| < \hbox{\it epsabs} + \hbox{\it epsrel\/}\, \min(|a|,|b|)

   .. only:: texinfo

      ::

         |a - b| < epsabs + epsrel min(|a|,|b|) 

   when the interval :math:`x = [a,b]` does not include the origin.  If the
   interval includes the origin then :math:`\min(|a|,|b|)` is replaced by
   zero (which is the minimum value of :math:`|x|` over the interval).  This
   ensures that the relative error is accurately estimated for minima close
   to the origin.

   This condition on the interval also implies that any estimate of the
   minimum :math:`x_m` in the interval satisfies the same condition with respect
   to the true minimum :math:`x_m^*`,

   .. only:: not texinfo

      .. math:: |x_m - x_m^*| < \hbox{\it epsabs} + \hbox{\it epsrel\/}\, x_m^*

   .. only:: texinfo

      ::

         |x_m - x_m^*| < epsabs + epsrel x_m^*

   assuming that the true minimum :math:`x_m^*` is contained within the interval.

Minimization Algorithms
=======================

The minimization algorithms described in this section require an initial
interval which is guaranteed to contain a minimum---if :math:`a` and
:math:`b` are the endpoints of the interval and :math:`x` is an estimate
of the minimum then :math:`f(a) > f(x) < f(b)`.  This ensures that the
function has at least one minimum somewhere in the interval.  If a valid
initial interval is used then these algorithm cannot fail, provided the
function is well-behaved.

.. type:: gsl_min_fminimizer_type

   .. index::
      single: golden section algorithm for finding minima
      single: minimum finding, golden section algorithm

   .. var:: gsl_min_fminimizer_goldensection

      The *golden section algorithm* is the simplest method of bracketing
      the minimum of a function.  It is the slowest algorithm provided by the
      library, with linear convergence.

      On each iteration, the algorithm first compares the subintervals from
      the endpoints to the current minimum.  The larger subinterval is divided
      in a golden section (using the famous ratio :math:`(3-\sqrt 5)/2 \approx 0.3819660`
      and the value of the function at this new point is
      calculated.  The new value is used with the constraint :math:`f(a') > f(x') < f(b')`
      to a select new interval containing the minimum, by
      discarding the least useful point.  This procedure can be continued
      indefinitely until the interval is sufficiently small.  Choosing the
      golden section as the bisection ratio can be shown to provide the
      fastest convergence for this type of algorithm.

   .. index::
      single: Brent's method for finding minima
      single: minimum finding, Brent's method

   .. var:: gsl_min_fminimizer_brent

      The *Brent minimization algorithm* combines a parabolic
      interpolation with the golden section algorithm.  This produces a fast
      algorithm which is still robust.

      The outline of the algorithm can be summarized as follows: on each
      iteration Brent's method approximates the function using an
      interpolating parabola through three existing points.  The minimum of the
      parabola is taken as a guess for the minimum.  If it lies within the
      bounds of the current interval then the interpolating point is accepted,
      and used to generate a smaller interval.  If the interpolating point is
      not accepted then the algorithm falls back to an ordinary golden section
      step.  The full details of Brent's method include some additional checks
      to improve convergence.

   .. index:: safeguarded step-length algorithm

   .. var:: gsl_min_fminimizer_quad_golden

      This is a variant of Brent's algorithm which uses the safeguarded
      step-length algorithm of Gill and Murray.

Examples
========

The following program uses the Brent algorithm to find the minimum of
the function :math:`f(x) = \cos(x) + 1`, which occurs at :math:`x = \pi`.
The starting interval is :math:`(0,6)`, with an initial guess for the
minimum of :math:`2`.

.. include:: examples/min.c
   :code:

Here are the results of the minimization procedure.

.. include:: examples/min.txt
   :code:

References and Further Reading
==============================

Further information on Brent's algorithm is available in the following
book,

* Richard Brent, *Algorithms for minimization without derivatives*,
  Prentice-Hall (1973), republished by Dover in paperback (2002), ISBN
  0-486-41998-3.
The following routines compute the gamma and beta functions in their
full and incomplete forms, as well as various kinds of factorials.
The functions described in this section are declared in the header
file :file:`gsl_sf_gamma.h`.

Gamma Functions
---------------
.. index:: gamma functions

The Gamma function is defined by the following integral,

.. math:: \Gamma(x) = \int_0^{\infty} dt t^{x-1} \exp(-t)

It is related to the factorial function by :math:`\Gamma(n) = (n-1)!`
for positive integer :math:`n`.  Further information on the Gamma function
can be found in Abramowitz & Stegun, Chapter 6.  

.. function:: double gsl_sf_gamma (double x)
              int gsl_sf_gamma_e (double x, gsl_sf_result * result)

   These routines compute the Gamma function :math:`\Gamma(x)`, subject to :math:`x`
   not being a negative integer or zero.  The function is computed using the real
   Lanczos method. The maximum value of :math:`x` such that :math:`\Gamma(x)` is not
   considered an overflow is given by the macro :macro:`GSL_SF_GAMMA_XMAX`
   and is 171.0.
.. exceptions: GSL_EDOM, GSL_EOVRFLW, GSL_EROUND

.. index:: logarithm of Gamma function

.. function:: double gsl_sf_lngamma (double x)
              int gsl_sf_lngamma_e (double x, gsl_sf_result * result)

   These routines compute the logarithm of the Gamma function,
   :math:`\log(\Gamma(x))`, subject to :math:`x` not being a negative
   integer or zero.  For :math:`x < 0` the real part of :math:`\log(\Gamma(x))` is
   returned, which is equivalent to :math:`\log(|\Gamma(x)|)`.  The function
   is computed using the real Lanczos method.
.. exceptions: GSL_EDOM, GSL_EROUND

.. function:: int gsl_sf_lngamma_sgn_e (double x, gsl_sf_result * result_lg, double * sgn)

   This routine computes the sign of the gamma function and the logarithm of
   its magnitude, subject to :math:`x` not being a negative integer or zero.  The
   function is computed using the real Lanczos method.  The value of the
   gamma function and its error can be reconstructed using the relation 
   :math:`\Gamma(x) = sgn * \exp(result\_lg)`, taking into account the two 
   components of :data:`result_lg`.
.. exceptions: GSL_EDOM, GSL_EROUND

.. index:: Regulated Gamma function

.. function:: double gsl_sf_gammastar (double x)
              int gsl_sf_gammastar_e (double x, gsl_sf_result * result)

   These routines compute the regulated Gamma Function :math:`\Gamma^*(x)`
   for :math:`x > 0`. The regulated gamma function is given by,

   .. only:: not texinfo

      .. math::

         \Gamma^*(x) &= \Gamma(x)/(\sqrt{2\pi} x^{(x-1/2)} \exp(-x))\cr
                     &= \left(1 + {1 \over 12x} + ...\right) \quad\hbox{for~} x\to \infty\cr

   .. only:: texinfo

      ::

         \Gamma^*(x) = \Gamma(x)/(\sqrt{2\pi} x^{(x-1/2)} \exp(-x))
                     = (1 + (1/12x) + ...)  for x \to \infty

   and is a useful suggestion of Temme.
.. exceptions: GSL_EDOM

.. index:: Reciprocal Gamma function

.. function:: double gsl_sf_gammainv (double x)
              int gsl_sf_gammainv_e (double x, gsl_sf_result * result)

   These routines compute the reciprocal of the gamma function,
   :math:`1/\Gamma(x)` using the real Lanczos method.
.. exceptions: GSL_EUNDRFLW, GSL_EROUND

.. index:: Complex Gamma function

.. function:: int gsl_sf_lngamma_complex_e (double zr, double zi, gsl_sf_result * lnr, gsl_sf_result * arg)

   This routine computes :math:`\log(\Gamma(z))` for complex :math:`z = z_r + i z_i`
   and :math:`z` not a negative integer or zero, using the complex Lanczos
   method.  The returned parameters are :math:`lnr = \log|\Gamma(z)|` and
   :math:`arg = \arg(\Gamma(z))` in :math:`(-\pi,\pi]`.  Note that the phase
   part (:data:`arg`) is not well-determined when :math:`|z|` is very large,
   due to inevitable roundoff in restricting to :math:`(-\pi,\pi]`.  This
   will result in a :macro:`GSL_ELOSS` error when it occurs.  The absolute
   value part (:data:`lnr`), however, never suffers from loss of precision.
.. exceptions: GSL_EDOM, GSL_ELOSS

Factorials
----------
.. index:: factorial

Although factorials can be computed from the Gamma function, using
the relation :math:`n! = \Gamma(n+1)` for non-negative integer :math:`n`,
it is usually more efficient to call the functions in this section,
particularly for small values of :math:`n`, whose factorial values are
maintained in hardcoded tables.

.. index:: factorial

.. function:: double gsl_sf_fact (unsigned int n)
              int gsl_sf_fact_e (unsigned int n, gsl_sf_result * result)

   These routines compute the factorial :math:`n!`.  The factorial is
   related to the Gamma function by :math:`n! = \Gamma(n+1)`.
   The maximum value of :math:`n` such that :math:`n!` is not
   considered an overflow is given by the macro :macro:`GSL_SF_FACT_NMAX`
   and is 170.
.. exceptions: GSL_EDOM, GSL_EOVRFLW

.. index:: double factorial

.. function:: double gsl_sf_doublefact (unsigned int n)
              int gsl_sf_doublefact_e (unsigned int n, gsl_sf_result * result)

   These routines compute the double factorial :math:`n!! = n(n-2)(n-4) \dots`. 
   The maximum value of :math:`n` such that :math:`n!!` is not
   considered an overflow is given by the macro :macro:`GSL_SF_DOUBLEFACT_NMAX`
   and is 297.
.. exceptions: GSL_EDOM, GSL_EOVRFLW

.. index:: logarithm of factorial

.. function:: double gsl_sf_lnfact (unsigned int n)
              int gsl_sf_lnfact_e (unsigned int n, gsl_sf_result * result)

   These routines compute the logarithm of the factorial of :data:`n`,
   :math:`\log(n!)`.  The algorithm is faster than computing
   :math:`\ln(\Gamma(n+1))` via :func:`gsl_sf_lngamma` for :math:`n < 170`,
   but defers for larger :data:`n`.
.. exceptions: none

.. index:: logarithm of double factorial

.. function:: double gsl_sf_lndoublefact (unsigned int n)
              int gsl_sf_lndoublefact_e (unsigned int n, gsl_sf_result * result)

   These routines compute the logarithm of the double factorial of :data:`n`,
   :math:`\log(n!!)`.
.. exceptions: none

.. index:: combinatorial factor C(m,n)

.. function:: double gsl_sf_choose (unsigned int n, unsigned int m)
              int gsl_sf_choose_e (unsigned int n, unsigned int m, gsl_sf_result * result)

   These routines compute the combinatorial factor :code:`n choose m`
   :math:`= n!/(m!(n-m)!)`
.. exceptions: GSL_EDOM, GSL_EOVRFLW

.. index:: logarithm of combinatorial factor C(m,n)

.. function:: double gsl_sf_lnchoose (unsigned int n, unsigned int m)
              int gsl_sf_lnchoose_e (unsigned int n, unsigned int m, gsl_sf_result * result)

   These routines compute the logarithm of :code:`n choose m`.  This is
   equivalent to the sum :math:`\log(n!) - \log(m!) - \log((n-m)!)`.
.. exceptions: GSL_EDOM 

.. index::
   single: Taylor coefficients, computation of

.. function:: double gsl_sf_taylorcoeff (int n, double x)
              int gsl_sf_taylorcoeff_e (int n, double x, gsl_sf_result * result)

   These routines compute the Taylor coefficient :math:`x^n / n!` for 
   :math:`x \ge 0`, :math:`n \ge 0`
.. exceptions: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. _pochhammer-symbol:

Pochhammer Symbol
-----------------

.. index::
   single: Pochhammer symbol
   single:  Apell symbol, see Pochhammer symbol

.. function:: double gsl_sf_poch (double a, double x)
              int gsl_sf_poch_e (double a, double x, gsl_sf_result * result)

   These routines compute the Pochhammer symbol :math:`(a)_x = \Gamma(a + x)/\Gamma(a)`.
   The Pochhammer symbol is also known as the Apell symbol and
   sometimes written as :math:`(a,x)`.  When :math:`a` and :math:`a + x` 
   are negative integers or zero, the limiting value of the ratio is returned. 
.. exceptions:  GSL_EDOM, GSL_EOVRFLW

.. index:: logarithm of Pochhammer symbol

.. function:: double gsl_sf_lnpoch (double a, double x)
              int gsl_sf_lnpoch_e (double a, double x, gsl_sf_result * result)

   These routines compute the logarithm of the Pochhammer symbol,
   :math:`\log((a)_x) = \log(\Gamma(a + x)/\Gamma(a))`.
.. exceptions:  GSL_EDOM

.. function:: int gsl_sf_lnpoch_sgn_e (double a, double x, gsl_sf_result * result, double * sgn)

   These routines compute the sign of the Pochhammer symbol and the
   logarithm of its magnitude.  The computed parameters are :math:`result = \log(|(a)_x|)`
   with a corresponding error term,  and :math:`sgn = \sgn((a)_x)` where :math:`(a)_x = \Gamma(a + x)/\Gamma(a)`.
.. exceptions:  GSL_EDOM

.. index:: relative Pochhammer symbol

.. function:: double gsl_sf_pochrel (double a, double x)
              int gsl_sf_pochrel_e (double a, double x, gsl_sf_result * result)

   These routines compute the relative Pochhammer symbol :math:`((a)_x - 1)/x`
   where :math:`(a)_x = \Gamma(a + x)/\Gamma(a)`.
.. exceptions:  GSL_EDOM

Incomplete Gamma Functions
--------------------------

.. index::
   single: non-normalized incomplete Gamma function
   single: unnormalized incomplete Gamma function

.. function:: double gsl_sf_gamma_inc (double a, double x)
              int gsl_sf_gamma_inc_e (double a, double x, gsl_sf_result * result)

   These functions compute the unnormalized incomplete Gamma Function
   :math:`\Gamma(a,x) = \int_x^\infty dt t^{(a-1)} \exp(-t)`
   for :math:`a` real and :math:`x \ge 0`.
.. exceptions: GSL_EDOM

.. index:: incomplete Gamma function

.. function:: double gsl_sf_gamma_inc_Q (double a, double x)
              int gsl_sf_gamma_inc_Q_e (double a, double x, gsl_sf_result * result)

   These routines compute the normalized incomplete Gamma Function
   :math:`Q(a,x) = 1/\Gamma(a) \int_x^\infty dt t^{(a-1)} \exp(-t)`
   for :math:`a > 0`, :math:`x \ge 0`.
.. exceptions: GSL_EDOM

.. index:: complementary incomplete Gamma function

.. function:: double gsl_sf_gamma_inc_P (double a, double x)
              int gsl_sf_gamma_inc_P_e (double a, double x, gsl_sf_result * result)

   These routines compute the complementary normalized incomplete Gamma Function
   :math:`P(a,x) = 1 - Q(a,x) = 1/\Gamma(a) \int_0^x dt t^{(a-1)} \exp(-t)`
   for :math:`a > 0`, :math:`x \ge 0`.

   Note that Abramowitz & Stegun call :math:`P(a,x)` the incomplete gamma
   function (section 6.5).
.. exceptions: GSL_EDOM

Beta Functions
--------------

.. index:: Beta function

.. function:: double gsl_sf_beta (double a, double b)
              int gsl_sf_beta_e (double a, double b, gsl_sf_result * result)

   These routines compute the Beta Function, :math:`B(a,b) = \Gamma(a)\Gamma(b)/\Gamma(a+b)`
   subject to :math:`a` and :math:`b` not being negative integers.
.. exceptions: GSL_EDOM, GSL_EOVRFLW, GSL_EUNDRFLW

.. index:: logarithm of Beta function

.. function:: double gsl_sf_lnbeta (double a, double b)
              int gsl_sf_lnbeta_e (double a, double b, gsl_sf_result * result)

   These routines compute the logarithm of the Beta Function, :math:`\log(B(a,b))`
   subject to :math:`a` and :math:`b` not being negative integers.
.. exceptions: GSL_EDOM

Incomplete Beta Function
------------------------

.. index::
   single: incomplete Beta function, normalized
   single: normalized incomplete Beta function
   single: Beta function, incomplete normalized 

.. function:: double gsl_sf_beta_inc (double a, double b, double x)
              int gsl_sf_beta_inc_e (double a, double b, double x, gsl_sf_result * result)

   These routines compute the normalized incomplete Beta function
   :math:`I_x(a,b) = B_x(a,b) / B(a,b)` where
   
   .. math:: B_x(a,b) = \int_0^x t^{a-1} (1-t)^{b-1} dt

   for :math:`0 \le x \le 1`.
   For :math:`a > 0`, :math:`b > 0` the value is computed using
   a continued fraction expansion.  For all other values it is computed using 
   the relation
   
   .. only:: not texinfo

      .. math:: I_x(a,b,x) = (1/a) x^a {}_2F_1(a,1-b,a+1,x)/B(a,b)

   .. only:: texinfo

      ::

         I_x(a,b,x) = (1/a) x^a 2F1(a,1-b,a+1,x) / B(a,b)
.. index:: trigonometric functions

The library includes its own trigonometric functions in order to provide
consistency across platforms and reliable error estimates.  These
functions are declared in the header file :file:`gsl_sf_trig.h`.

Circular Trigonometric Functions
--------------------------------

.. index::
   single: sine function, special functions

.. function:: double gsl_sf_sin (double x)
              int gsl_sf_sin_e (double x, gsl_sf_result * result)

   These routines compute the sine function :math:`\sin(x)`.
.. Exceptional Return Values:

.. index::
   single: cosine function, special functions

.. function:: double gsl_sf_cos (double x)
              int gsl_sf_cos_e (double x, gsl_sf_result * result)

   These routines compute the cosine function :math:`\cos(x)`.
.. Exceptional Return Values:

.. index::
   single: hypot function, special functions

.. function:: double gsl_sf_hypot (double x, double y)
              int gsl_sf_hypot_e (double x, double y, gsl_sf_result * result)

   These routines compute the hypotenuse function :math:`\sqrt{x^2 + y^2}`
   avoiding overflow and underflow.
.. Exceptional Return Values:

.. index::
   single: complex sinc function, special functions

.. function:: double gsl_sf_sinc (double x)
              int gsl_sf_sinc_e (double x, gsl_sf_result * result)

   These routines compute :math:`\sinc(x) = \sin(\pi x) / (\pi x)` for any
   value of :data:`x`.
.. Exceptional Return Values: none

Trigonometric Functions for Complex Arguments
---------------------------------------------

.. index::
   single: complex sine function, special functions

.. function:: int gsl_sf_complex_sin_e (double zr, double zi, gsl_sf_result * szr, gsl_sf_result * szi)

   This function computes the complex sine, :math:`\sin(z_r + i z_i)` storing
   the real and imaginary parts in :data:`szr`, :data:`szi`.
.. Exceptional Return Values: GSL_EOVRFLW

.. index::
   single: complex cosine function, special functions

.. function:: int gsl_sf_complex_cos_e (double zr, double zi, gsl_sf_result * czr, gsl_sf_result * czi)

   This function computes the complex cosine, :math:`\cos(z_r + i z_i)` storing
   the real and imaginary parts in :data:`czr`, :data:`czi`.
.. Exceptional Return Values: GSL_EOVRFLW

.. index::
   single: complex log sine function, special functions

.. function:: int gsl_sf_complex_logsin_e (double zr, double zi, gsl_sf_result * lszr, gsl_sf_result * lszi)

   This function computes the logarithm of the complex sine,
   :math:`\log(\sin(z_r + i z_i))` storing the real and imaginary parts in
   :data:`lszr`, :data:`lszi`.
.. Exceptional Return Values: GSL_EDOM, GSL_ELOSS

Hyperbolic Trigonometric Functions
----------------------------------

.. index:: logarithm of sinh function, special functions

.. function:: double gsl_sf_lnsinh (double x)
              int gsl_sf_lnsinh_e (double x, gsl_sf_result * result)

   These routines compute :math:`\log(\sinh(x))` for :math:`x > 0`.
.. Domain: x > 0 
.. Exceptional Return Values: GSL_EDOM

.. index::
   single: logarithm of cosh function, special functions

.. function:: double gsl_sf_lncosh (double x)
              int gsl_sf_lncosh_e (double x, gsl_sf_result * result)

   These routines compute :math:`\log(\cosh(x))` for any :data:`x`.
.. Exceptional Return Values: none

Conversion Functions
--------------------
.. index::
   single: polar to rectangular conversion
   single: rectangular to polar conversion

.. function:: int gsl_sf_polar_to_rect (double r, double theta, gsl_sf_result * x, gsl_sf_result * y)

   This function converts the polar coordinates (:data:`r`, :data:`theta`) to
   rectilinear coordinates (:data:`x`, :data:`y`), :math:`x = r\cos(\theta)`,
   :math:`y = r\sin(\theta)`.
.. Exceptional Return Values: GSL_ELOSS

.. function:: int gsl_sf_rect_to_polar (double x, double y, gsl_sf_result * r, gsl_sf_result * theta)

   This function converts the rectilinear coordinates (:data:`x`, :data:`y`) to
   polar coordinates (:data:`r`, :data:`theta`), such that :math:`x = r\cos(\theta)`,
   :math:`y = r\sin(\theta)`.  The argument :data:`theta`
   lies in the range :math:`[-\pi, \pi]`.
.. Exceptional Return Values: GSL_EDOM

Restriction Functions
---------------------
.. index::
   single: angular reduction
   single: reduction of angular variables

.. function:: double gsl_sf_angle_restrict_symm (double theta)
              int gsl_sf_angle_restrict_symm_e (double * theta)

   These routines force the angle :data:`theta` to lie in the range
   :math:`(-\pi,\pi]`.  

   Note that the mathematical value of :math:`\pi` is slightly greater
   than :macro:`M_PI`, so the machine numbers :macro:`M_PI` and :macro:`-M_PI`
   are included in the range.
.. Exceptional Return Values: GSL_ELOSS

.. function:: double gsl_sf_angle_restrict_pos (double theta)
              int gsl_sf_angle_restrict_pos_e (double * theta)

   These routines force the angle :data:`theta` to lie in the range :math:`[0, 2\pi)`.

   Note that the mathematical value of :math:`2\pi` is slightly greater
   than :code:`2*M_PI`, so the machine number :code:`2*M_PI` is included in
   the range.

.. Exceptional Return Values: GSL_ELOSS

Trigonometric Functions With Error Estimates
--------------------------------------------

.. function:: int gsl_sf_sin_err_e (double x, double dx, gsl_sf_result * result)

   This routine computes the sine of an angle :data:`x` with an associated 
   absolute error :data:`dx`,
   :math:`\sin(x \pm dx)`.  Note that this function is provided in the error-handling form only since
   its purpose is to compute the propagated error.

.. function:: int gsl_sf_cos_err_e (double x, double dx, gsl_sf_result * result)

   This routine computes the cosine of an angle :data:`x` with an associated
   absolute error :data:`dx`, 
   :math:`\cos(x \pm dx)`.  Note that this function is provided in the error-handling form only since
   its purpose is to compute the propagated error.
.. index::
   single: exponential function
   single: exp

The functions described in this section are declared in the header file
:file:`gsl_sf_exp.h`.

Exponential Function
--------------------

.. function:: double gsl_sf_exp (double x)
              int gsl_sf_exp_e (double x, gsl_sf_result * result)

   These routines provide an exponential function :math:`\exp(x)` using GSL
   semantics and error checking.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: int gsl_sf_exp_e10_e (double x, gsl_sf_result_e10 * result)

   This function computes the exponential :math:`\exp(x)` using the
   :type:`gsl_sf_result_e10` type to return a result with extended range.
   This function may be useful if the value of :math:`\exp(x)` would
   overflow the  numeric range of :code:`double`.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: double gsl_sf_exp_mult (double x, double y)
              int gsl_sf_exp_mult_e (double x, double y, gsl_sf_result * result)

   These routines exponentiate :data:`x` and multiply by the factor :data:`y`
   to return the product :math:`y \exp(x)`.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: int gsl_sf_exp_mult_e10_e (const double x, const double y, gsl_sf_result_e10 * result)

   This function computes the product :math:`y \exp(x)` using the
   :type:`gsl_sf_result_e10` type to return a result with extended numeric
   range.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

Relative Exponential Functions
------------------------------

.. function:: double gsl_sf_expm1 (double x)
              int gsl_sf_expm1_e (double x, gsl_sf_result * result)

   These routines compute the quantity :math:`\exp(x)-1` using an algorithm
   that is accurate for small :math:`x`.
.. Exceptional Return Values:  GSL_EOVRFLW

.. function:: double gsl_sf_exprel (double x)
              int gsl_sf_exprel_e (double x, gsl_sf_result * result)

   These routines compute the quantity :math:`(\exp(x)-1)/x` using an
   algorithm that is accurate for small :data:`x`.  For small :data:`x` the
   algorithm is based on the expansion
   :math:`(\exp(x)-1)/x = 1 + x/2 + x^2/(2*3) + x^3/(2*3*4) + \dots`.
.. Exceptional Return Values:  GSL_EOVRFLW

.. function:: double gsl_sf_exprel_2 (double x)
              int gsl_sf_exprel_2_e (double x, gsl_sf_result * result)

   These routines compute the quantity :math:`2(\exp(x)-1-x)/x^2` using an
   algorithm that is accurate for small :data:`x`.  For small :data:`x` the
   algorithm is based on the expansion
   :math:`2(\exp(x)-1-x)/x^2 = 1 + x/3 + x^2/(3*4) + x^3/(3*4*5) + \dots`.
.. Exceptional Return Values:  GSL_EOVRFLW

.. function:: double gsl_sf_exprel_n (int n, double x)
              int gsl_sf_exprel_n_e (int n, double x, gsl_sf_result * result)

   These routines compute the :math:`N`-relative exponential, which is the
   :data:`n`-th generalization of the functions :func:`gsl_sf_exprel` and
   :func:`gsl_sf_exprel_2`.  The :math:`N`-relative exponential is given by,

   .. only:: not texinfo

      .. math::

         \hbox{exprel}_N(x)
                     &= N!/x^N \left(\exp(x) - \sum_{k=0}^{N-1} x^k/k!\right)\cr
                     &= 1 + x/(N+1) + x^2/((N+1)(N+2)) + \dots\cr
                     &= {}_1F_1(1,1+N,x)\cr

   .. only:: texinfo

      ::

         exprel_N(x) = N!/x^N (\exp(x) - \sum_{k=0}^{N-1} x^k/k!)
                     = 1 + x/(N+1) + x^2/((N+1)(N+2)) + ...
                     = 1F1 (1,1+N,x)
.. Exceptional Return Values: 

Exponentiation With Error Estimate
----------------------------------

.. function:: int gsl_sf_exp_err_e (double x, double dx, gsl_sf_result * result)

   This function exponentiates :data:`x` with an associated absolute error
   :data:`dx`.
.. Exceptional Return Values: 

.. function:: int gsl_sf_exp_err_e10_e (double x, double dx, gsl_sf_result_e10 * result)

   This function exponentiates a quantity :data:`x` with an associated absolute 
   error :data:`dx` using the :type:`gsl_sf_result_e10` type to return a result with
   extended range.
.. Exceptional Return Values: 

.. function:: int gsl_sf_exp_mult_err_e (double x, double dx, double y, double dy, gsl_sf_result * result)

   This routine computes the product :math:`y \exp(x)` for the quantities
   :data:`x`, :data:`y` with associated absolute errors :data:`dx`, :data:`dy`.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: int gsl_sf_exp_mult_err_e10_e (double x, double dx, double y, double dy, gsl_sf_result_e10 * result)

   This routine computes the product :math:`y \exp(x)` for the quantities
   :data:`x`, :data:`y` with associated absolute errors :data:`dx`, :data:`dy` using the
   :type:`gsl_sf_result_e10` type to return a result with extended range.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW
.. index::
   single: Coulomb wave functions
   single: hydrogen atom

The prototypes of the Coulomb functions are declared in the header file
:file:`gsl_sf_coulomb.h`.  Both bound state and scattering solutions are
available.

Normalized Hydrogenic Bound States
----------------------------------

.. function:: double gsl_sf_hydrogenicR_1 (double Z, double r)
              int gsl_sf_hydrogenicR_1_e (double Z, double r, gsl_sf_result * result)

   These routines compute the lowest-order normalized hydrogenic bound
   state radial wavefunction
   :math:`R_1 := 2Z \sqrt{Z} \exp(-Z r)`.

.. function:: double gsl_sf_hydrogenicR (int n, int l, double Z, double r)
              int gsl_sf_hydrogenicR_e (int n, int l, double Z, double r, gsl_sf_result * result)

   These routines compute the :data:`n`-th normalized hydrogenic bound state
   radial wavefunction,

   .. only:: not texinfo

      .. math:: R_n := {2 Z^{3/2} \over n^2}  \left({2Z r \over n}\right)^l  \sqrt{(n-l-1)! \over (n+l)!} \exp(-Z r/n) L^{2l+1}_{n-l-1}(2Z r / n).

   .. only:: texinfo

      | R_n := 2 (Z^{3/2}/n^2) \sqrt{(n-l-1)!/(n+l)!} \exp(-Z r/n) (2Zr/n)^l
      |           L^{2l+1}_{n-l-1}(2Zr/n).  

   where :math:`L^a_b(x)` is the :ref:`generalized Laguerre polynomial <laguerre-functions>`.
   The normalization is chosen such that the wavefunction :math:`\psi` is
   given by :math:`\psi(n,l,r) = R_n Y_{lm}`.   

Coulomb Wave Functions
----------------------

The Coulomb wave functions :math:`F_L(\eta,x)`, :math:`G_L(\eta,x)` are
described in Abramowitz & Stegun, Chapter 14.  Because there can be a
large dynamic range of values for these functions, overflows are handled
gracefully.  If an overflow occurs, :code:`GSL_EOVRFLW` is signalled and
exponent(s) are returned through the modifiable parameters :data:`exp_F`,
:data:`exp_G`. The full solution can be reconstructed from the following
relations,

.. only:: not texinfo

   .. math::

      F_L(\eta,x) &= fc[k_L] * \exp(exp_F) \\
      G_L(\eta,x) &= gc[k_L] * \exp(exp_G)

   .. math::

      F_L'(\eta,x) &= fcp[k_L] * \exp(exp_F) \\
      G_L'(\eta,x) &= gcp[k_L] * \exp(exp_G)

.. only:: texinfo

   | F_L(\eta,x) = fc[k_L] * \exp(exp_F)
   | G_L(\eta,x) = gc[k_L] * \exp(exp_G)
   |
   | F_L'(\eta,x) = fcp[k_L] * \exp(exp_F)
   | G_L'(\eta,x) = gcp[k_L] * \exp(exp_G)

.. function:: int gsl_sf_coulomb_wave_FG_e (double eta, double x, double L_F, int k, gsl_sf_result * F, gsl_sf_result * Fp, gsl_sf_result * G, gsl_sf_result * Gp, double * exp_F, double * exp_G)

   This function computes the Coulomb wave functions :math:`F_L(\eta,x)`,
   :math:`G_{L-k}(\eta,x)` and their derivatives 
   :math:`F'_L(\eta,x)`, 
   :math:`G'_{L-k}(\eta,x)`
   with respect to :math:`x`.  The parameters are restricted to :math:`L, L-k > -1/2`,
   :math:`x > 0` and integer :math:`k`.  Note that :math:`L`
   itself is not restricted to being an integer. The results are stored in
   the parameters F, G for the function values and :data:`Fp`,
   :data:`Gp` for the derivative values.  If an overflow occurs,
   :code:`GSL_EOVRFLW` is returned and scaling exponents are stored in
   the modifiable parameters :data:`exp_F`, :data:`exp_G`.

.. function:: int gsl_sf_coulomb_wave_F_array (double L_min, int kmax, double eta, double x, double fc_array[], double * F_exponent)

   This function computes the Coulomb wave function :math:`F_L(\eta,x)` for
   :math:`L = Lmin \dots Lmin + kmax`, storing the results in :data:`fc_array`.
   In the case of overflow the exponent is stored in :data:`F_exponent`.

.. function:: int gsl_sf_coulomb_wave_FG_array (double L_min, int kmax, double eta, double x, double fc_array[], double gc_array[], double * F_exponent, double * G_exponent)

   This function computes the functions :math:`F_L(\eta,x)`,
   :math:`G_L(\eta,x)` for :math:`L = Lmin \dots Lmin + kmax` storing the
   results in :data:`fc_array` and :data:`gc_array`.  In the case of overflow the
   exponents are stored in :data:`F_exponent` and :data:`G_exponent`.

.. function:: int gsl_sf_coulomb_wave_FGp_array (double L_min, int kmax, double eta, double x, double fc_array[], double fcp_array[], double gc_array[], double gcp_array[], double * F_exponent, double * G_exponent)

   This function computes the functions :math:`F_L(\eta,x)`,
   :math:`G_L(\eta,x)` and their derivatives :math:`F'_L(\eta,x)`,
   :math:`G'_L(\eta,x)` for :math:`L = Lmin \dots Lmin + kmax` storing the
   results in :data:`fc_array`, :data:`gc_array`, :data:`fcp_array` and :data:`gcp_array`.
   In the case of overflow the exponents are stored in :data:`F_exponent` 
   and :data:`G_exponent`.

.. function:: int gsl_sf_coulomb_wave_sphF_array (double L_min, int kmax, double eta, double x, double fc_array[], double F_exponent[])

   This function computes the Coulomb wave function divided by the argument
   :math:`F_L(\eta, x)/x` for :math:`L = Lmin \dots Lmin + kmax`, storing the
   results in :data:`fc_array`.  In the case of overflow the exponent is
   stored in :data:`F_exponent`. This function reduces to spherical Bessel
   functions in the limit :math:`\eta \to 0`.

Coulomb Wave Function Normalization Constant
--------------------------------------------

The Coulomb wave function normalization constant is defined in
Abramowitz 14.1.7.

.. function:: int gsl_sf_coulomb_CL_e (double L, double eta, gsl_sf_result * result)

   This function computes the Coulomb wave function normalization constant
   :math:`C_L(\eta)` for :math:`L > -1`.

.. function:: int gsl_sf_coulomb_CL_array (double Lmin, int kmax, double eta, double cl[])

   This function computes the Coulomb wave function normalization constant
   :math:`C_L(\eta)` for :math:`L = Lmin \dots Lmin + kmax`, :math:`Lmin > -1`.
.. index::
   license of GSL
   GNU General Public License

************
Introduction
************

The GNU Scientific Library (GSL) is a collection of routines for
numerical computing.  The routines have been written from scratch in C,
and present a modern Applications Programming Interface
(API) for C programmers, allowing wrappers to be written for very
high level languages.  The source code is distributed under the GNU
General Public License.

Routines available in GSL
=========================

The library covers a wide range of topics in numerical computing.
Routines are available for the following areas,

===========================  ===========================  ===========================
Complex Numbers              Roots of Polynomials         Special Functions
Vectors and Matrices         Permutations                 Combinations
Sorting                      BLAS Support                 Linear Algebra
CBLAS Library                Fast Fourier Transforms      Eigensystems
Random Numbers               Quadrature                   Random Distributions
Quasi-Random Sequences       Histograms                   Statistics
Monte Carlo Integration      N-Tuples                     Differential Equations
Simulated Annealing          Numerical Differentiation    Interpolation
Series Acceleration          Chebyshev Approximations     Root-Finding
Discrete Hankel Transforms   Least-Squares Fitting        Minimization
IEEE Floating-Point          Physical Constants           Basis Splines
Wavelets                     Sparse BLAS Support          Sparse Linear Algebra
===========================  ===========================  ===========================

The use of these routines is described in this manual.  Each chapter
provides detailed definitions of the functions, followed by example
programs and references to the articles on which the algorithms are
based.

Where possible the routines have been based on reliable public-domain
packages such as FFTPACK and QUADPACK, which the developers of GSL
have reimplemented in C with modern coding conventions.

.. index::
   single: free software, explanation of

GSL is Free Software
====================

The subroutines in the GNU Scientific Library are "free software";
this means that everyone is free to use them, and to redistribute them
in other free programs.  The library is not in the public domain; it is
copyrighted and there are conditions on its distribution.  These
conditions are designed to permit everything that a good cooperating
citizen would want to do.  What is not allowed is to try to prevent
others from further sharing any version of the software that they might
get from you.

Specifically, we want to make sure that you have the right to share
copies of programs that you are given which use the GNU Scientific
Library, that you receive their source code or else can get it if you
want it, that you can change these programs or use pieces of them in new
free programs, and that you know you can do these things.

To make sure that everyone has such rights, we have to forbid you to
deprive anyone else of these rights.  For example, if you distribute
copies of any code which uses the GNU Scientific Library, you must give
the recipients all the rights that you have received.  You must make
sure that they, too, receive or can get the source code, both to the
library and the code which uses it.  And you must tell them their
rights.  This means that the library should not be redistributed in
proprietary programs.

Also, for our own protection, we must make certain that everyone finds
out that there is no warranty for the GNU Scientific Library.  If these
programs are modified by someone else and passed on, we want their
recipients to know that what they have is not what we distributed, so
that any problems introduced by others will not reflect on our
reputation.

The precise conditions for the distribution of software related to the
GNU Scientific Library are found in the
`GNU General Public License <https://www.gnu.org/software/gsl/manual/html_node/GNU-General-Public-License.html#GNU-General-Public-License>`_.
Further information about this
license is available from the GNU Project webpage `Frequently Asked
Questions about the GNU GPL <http://www.gnu.org/copyleft/gpl-faq.html>`_.

The Free Software Foundation also operates a license consulting
service for commercial users (contact details available from
http://www.fsf.org.

.. index::
   obtaining GSL
   downloading GSL
   mailing list for GSL announcements
   info-gsl mailing list

Obtaining GSL
=============

The source code for the library can be obtained in different ways, by
copying it from a friend, purchasing it on CDROM or downloading it
from the internet. A list of public ftp servers which carry the source
code can be found on the GNU website, http://www.gnu.org/software/gsl/.

The preferred platform for the library is a GNU system, which allows it
to take advantage of additional features in the GNU C compiler and GNU C
library.  However, the library is fully portable and should compile on
most systems with a C compiler. 

Announcements of new releases, updates and other relevant events are
made on the info-gsl@gnu.org mailing list.  To subscribe to this
low-volume list, send an email of the following form::

    To: info-gsl-request@gnu.org 
    Subject: subscribe

You will receive a response asking you to reply in order to confirm
your subscription.

.. index::
   warranty (none)

No Warranty
===========

The software described in this manual has no warranty, it is provided
"as is".  It is your responsibility to validate the behavior of the
routines and their accuracy using the source code provided, or to
purchase support and warranties from commercial redistributors.  Consult the
`GNU General Public License <https://www.gnu.org/software/gsl/manual/html_node/GNU-General-Public-License.html#GNU-General-Public-License>`_
for further details.

.. index::
   reporting bugs in GSL
   bugs, how to report
   bug-gsl mailing list
   mailing list, bug-gsl

Reporting Bugs
==============

A list of known bugs can be found in the :file:`BUGS` file included in
the GSL distribution or online in the GSL bug tracker. [#f1]_
Details of compilation problems can be found in the :file:`INSTALL` file.

If you find a bug which is not listed in these files, please report it to
bug-gsl@gnu.org.

All bug reports should include:

- The version number of GSL
- The hardware and operating system
- The compiler used, including version number and compilation options
- A description of the bug behavior
- A short program which exercises the bug

It is useful if you can check whether the same problem occurs when the
library is compiled without optimization.  Thank you.

Any errors or omissions in this manual can also be reported to the
same address.

.. index::
   mailing list archives
   single: website, developer information
   contacting the GSL developers

Further Information
===================

Additional information, including online copies of this manual, links to
related projects, and mailing list archives are available from the
website mentioned above.  

Any questions about the use and installation of the library can be asked
on the mailing list help-gsl@gnu.org.  To subscribe to this
list, send an email of the following form::

    To: help-gsl-request@gnu.org
    Subject: subscribe

This mailing list can be used to ask questions not covered by this
manual, and to contact the developers of the library.

If you would like to refer to the GNU Scientific Library in a journal
article, the recommended way is to cite this reference manual,
e.g.::

    M. Galassi et al, GNU Scientific Library Reference Manual (3rd Ed.), ISBN 0954612078.

If you want to give a url, use "http://www.gnu.org/software/gsl/".

.. index::
   single: conventions, used in manual
   single: examples, conventions used in
   single: shell prompt
   single: $, shell prompt

Conventions used in this manual
===============================

.. index::
   single: dollar sign $, shell prompt

This manual contains many examples which can be typed at the keyboard.
A command entered at the terminal is shown like this::

    $ command

The first character on the line is the terminal prompt, and should not
be typed.  The dollar sign $ is used as the standard prompt in
this manual, although some systems may use a different character.

The examples assume the use of the GNU operating system.  There may be
minor differences in the output on other systems.  The commands for
setting environment variables use the Bourne shell syntax of the
standard GNU shell (:code:`bash`).

.. rubric:: Footnotes

.. [#f1] http://savannah.gnu.org/bugs/?group=gsl
.. index::
   single: Laguerre functions
   single: confluent hypergeometric function

The generalized Laguerre polynomials, sometimes referred to as
associated Laguerre polynomials, are defined in terms of confluent
hypergeometric functions as

.. only:: not texinfo

   .. math:: L^a_n(x) = {(a+1)_n \over n!} {}_1F_1(-n,a+1,x)

.. only:: texinfo

   L^a_n(x) = ((a+1)_n / n!) 1F1(-n,a+1,x)
   
where :math:`(a)_n` is the :ref:`Pochhammer symbol <pochhammer-symbol>` (rising factorial).
They are related to the plain
Laguerre polynomials :math:`L_n(x)` by :math:`L^0_n(x) = L_n(x)` and 
:math:`L^k_n(x) = (-1)^k (d^k/dx^k) L_{(n+k)}(x)`
For more information see Abramowitz & Stegun, Chapter 22.

The functions described in this section are
declared in the header file :file:`gsl_sf_laguerre.h`.

.. function:: double gsl_sf_laguerre_1 (double a, double x)
              double gsl_sf_laguerre_2 (double a, double x)
              double gsl_sf_laguerre_3 (double a, double x)
              int gsl_sf_laguerre_1_e (double a, double x, gsl_sf_result * result)
              int gsl_sf_laguerre_2_e (double a, double x, gsl_sf_result * result)
              int gsl_sf_laguerre_3_e (double a, double x, gsl_sf_result * result)

   These routines evaluate the generalized Laguerre polynomials
   :math:`L^a_1(x)`, :math:`L^a_2(x)`, :math:`L^a_3(x)` using explicit
   representations.
.. Exceptional Return Values: none

.. function:: double gsl_sf_laguerre_n (const int n, const double a, const double x)
              int gsl_sf_laguerre_n_e (int n, double a, double x, gsl_sf_result * result)

   These routines evaluate the generalized Laguerre polynomials
   :math:`L^a_n(x)` for :math:`a > -1`,
   :math:`n \ge 0`.
.. Domain: a > -1.0, n >= 0
.. Evaluate generalized Laguerre polynomials.
.. Exceptional Return Values: GSL_EDOM
.. index:: Clausen functions

The Clausen function is defined by the following integral,

.. only:: not texinfo

   .. math:: Cl_2(x) = - \int_0^x dt \log{\left( 2 \sin{(t/2)} \right)}

.. only:: texinfo

   Cl_2(x) = - \int_0^x dt log( 2 \sin(t/2) )

It is related to the :ref:`dilogarithm <dilog-function>` by 
:math:`Cl_2(\theta) = \Im Li_2(\exp(i\theta))`.
The Clausen functions are declared in the header file
:file:`gsl_sf_clausen.h`.

.. function:: double gsl_sf_clausen (double x)
              int gsl_sf_clausen_e (double x, gsl_sf_result * result)

   These routines compute the Clausen integral :math:`Cl_2(x)`.
.. index:: elementary operations
.. index:: multiplication

The following functions allow for the propagation of errors when
combining quantities by multiplication.  The functions are declared in
the header file :file:`gsl_sf_elementary.h`.

.. function:: double gsl_sf_multiply (double x, double y)
              int gsl_sf_multiply_e (double x, double y, gsl_sf_result * result)

   This function multiplies :data:`x` and :data:`y` storing the product and its
   associated error in :data:`result`.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW

.. function:: int gsl_sf_multiply_err_e (double x, double dx, double y, double dy, gsl_sf_result * result)

   This function multiplies :data:`x` and :data:`y` with associated absolute
   errors :data:`dx` and :data:`dy`.  The product 
   :math:`xy \pm xy \sqrt{(dx/x)^2 +(dy/y)^2}`
   is stored in :data:`result`.
.. Exceptional Return Values: GSL_EOVRFLW, GSL_EUNDRFLW
.. index::
   single: elementary functions
   single: mathematical functions, elementary

**********************
Mathematical Functions
**********************

This chapter describes basic mathematical functions.  Some of these
functions are present in system libraries, but the alternative versions
given here can be used as a substitute when the system functions are not
available.

The functions and macros described in this chapter are defined in the
header file :file:`gsl_math.h`.

.. index::
   single: mathematical constants, defined as macros
   single: numerical constants, defined as macros
   single: constants, mathematical (defined as macros)
   single: macros for mathematical constants

Mathematical Constants
======================

The library ensures that the standard BSD mathematical constants
are defined. For reference, here is a list of the constants:

.. index::
   single: e, defined as a macro
   single: pi, defined as a macro
   single: Euler's constant, defined as a macro

===================== ===================================
:macro:`M_E`          The base of exponentials, :math:`e`
:macro:`M_LOG2E`      The base-2 logarithm of :math:`e`, :math:`\log_2 (e)`
:macro:`M_LOG10E`     The base-10 logarithm of :math:`e`, :math:`\log_{10} (e)`
:macro:`M_SQRT2`      The square root of two, :math:`\sqrt 2`
:macro:`M_SQRT1_2`    The square root of one-half, :math:`\sqrt{1/2}`
:macro:`M_SQRT3`      The square root of three, :math:`\sqrt 3`
:macro:`M_PI`         The constant pi, :math:`\pi`
:macro:`M_PI_2`       Pi divided by two, :math:`\pi/2`
:macro:`M_PI_4`       Pi divided by four, :math:`\pi/4`
:macro:`M_SQRTPI`     The square root of pi, :math:`\sqrt\pi`
:macro:`M_2_SQRTPI`   Two divided by the square root of pi, :math:`2/\sqrt\pi`
:macro:`M_1_PI`       The reciprocal of pi, :math:`1/\pi`
:macro:`M_2_PI`       Twice the reciprocal of pi, :math:`2/\pi`
:macro:`M_LN10`       The natural logarithm of ten, :math:`\ln(10)`
:macro:`M_LN2`        The natural logarithm of two, :math:`\ln(2)`
:macro:`M_LNPI`       The natural logarithm of pi, :math:`\ln(\pi)`
:macro:`M_EULER`      Euler's constant, :math:`\gamma`
===================== ===================================

.. index::
   single: infinity, defined as a macro
   single: IEEE infinity, defined as a macro

Infinities and Not-a-number
===========================

.. macro:: GSL_POSINF

   This macro contains the IEEE representation of positive infinity,
   :math:`+\infty`. It is computed from the expression :code:`+1.0/0.0`.

.. macro:: GSL_NEGINF

   This macro contains the IEEE representation of negative infinity,
   :math:`-\infty`. It is computed from the expression :code:`-1.0/0.0`.

.. index::
   single: NaN, defined as a macro
   single: Not-a-number, defined as a macro
   single: IEEE NaN, defined as a macro

.. macro:: GSL_NAN

   This macro contains the IEEE representation of the Not-a-Number symbol,
   :code:`NaN`. It is computed from the ratio :code:`0.0/0.0`.

.. function:: int gsl_isnan (const double x)

   This function returns 1 if :data:`x` is not-a-number.

.. function:: int gsl_isinf (const double x)

   This function returns :math:`+1` if :data:`x` is positive infinity,
   :math:`-1` if :data:`x` is negative infinity and 0
   otherwise. [#f1]_

.. function:: int gsl_finite (const double x)

   This function returns 1 if :data:`x` is a real number, and 0 if it is
   infinite or not-a-number.

Elementary Functions
====================

The following routines provide portable implementations of functions
found in the BSD math library.  When native versions are not available
the functions described here can be used instead.  The substitution can
be made automatically if you use :code:`autoconf` to compile your
application (see :ref:`portability-functions`).

.. index::
   single: log1p
   single: logarithm, computed accurately near 1

.. function:: double gsl_log1p (const double x)

   This function computes the value of :math:`\log(1+x)` in a way that is
   accurate for small :data:`x`. It provides an alternative to the BSD math
   function :code:`log1p(x)`.

.. index::
   single: expm1
   single: exponential, difference from 1 computed accurately

.. function:: double gsl_expm1 (const double x)

   This function computes the value of :math:`\exp(x)-1` in a way that is
   accurate for small :data:`x`. It provides an alternative to the BSD math
   function :code:`expm1(x)`.

.. index::
   single: hypot
   single: euclidean distance function, hypot
   single: length, computed accurately using hypot

.. function:: double gsl_hypot (const double x, const double y)

   This function computes the value of
   :math:`\sqrt{x^2 + y^2}` in a way that avoids overflow. It provides an
   alternative to the BSD math function :code:`hypot(x,y)`.

.. index::
   single: euclidean distance function, hypot3
   single: length, computed accurately using hypot3

.. function:: double gsl_hypot3 (const double x, const double y, const double z)

   This function computes the value of
   :math:`\sqrt{x^2 + y^2 + z^2}` in a way that avoids overflow.

.. index::
   single: acosh
   single: hyperbolic cosine, inverse
   single: inverse hyperbolic cosine

.. function:: double gsl_acosh (const double x)

   This function computes the value of :math:`\arccosh{(x)}`. It provides an
   alternative to the standard math function :code:`acosh(x)`.

.. index::
   single: asinh
   single: hyperbolic sine, inverse
   single: inverse hyperbolic sine

.. function:: double gsl_asinh (const double x)

   This function computes the value of :math:`\arcsinh{(x)}`. It provides an
   alternative to the standard math function :code:`asinh(x)`.

.. index::
   single: atanh
   single: hyperbolic tangent, inverse
   single: inverse hyperbolic tangent

.. function:: double gsl_atanh (const double x)

   This function computes the value of :math:`\arctanh{(x)}`. It provides an
   alternative to the standard math function :code:`atanh(x)`.

.. index:: ldexp

.. function:: double gsl_ldexp (double x, int e)

   This function computes the value of :math:`x * 2^e`. It provides an
   alternative to the standard math function :code:`ldexp(x,e)`.

.. index:: frexp

.. function:: double gsl_frexp (double x, int * e)

   This function splits the number :data:`x` into its normalized fraction
   :math:`f` and exponent :math:`e`, such that :math:`x = f * 2^e` and
   :math:`0.5 <= f < 1`. The function returns :math:`f` and stores the
   exponent in :math:`e`. If :math:`x` is zero, both :math:`f` and :math:`e`
   are set to zero. This function provides an alternative to the standard
   math function :code:`frexp(x, e)`.

Small integer powers
====================

A common complaint about the standard C library is its lack of a
function for calculating (small) integer powers.  GSL provides some simple
functions to fill this gap.  For reasons of efficiency, these functions
do not check for overflow or underflow conditions. 

.. function::
   double gsl_pow_int (double x, int n)
   double gsl_pow_uint (double x, unsigned int n)

   These routines computes the power :math:`x^n` for integer :data:`n`.  The
   power is computed efficiently---for example, :math:`x^8` is computed as
   :math:`((x^2)^2)^2`, requiring only 3 multiplications.  A version of this
   function which also computes the numerical error in the result is
   available as :func:`gsl_sf_pow_int_e`.

.. function::
   double gsl_pow_2 (const double x)
   double gsl_pow_3 (const double x)
   double gsl_pow_4 (const double x)
   double gsl_pow_5 (const double x)
   double gsl_pow_6 (const double x)
   double gsl_pow_7 (const double x)
   double gsl_pow_8 (const double x)
   double gsl_pow_9 (const double x)

   These functions can be used to compute small integer powers :math:`x^2`,
   :math:`x^3`, etc. efficiently. The functions will be inlined when 
   :macro:`HAVE_INLINE` is defined, so that use of these functions 
   should be as efficient as explicitly writing the corresponding 
   product expression::

     #include <gsl/gsl_math.h>
     double y = gsl_pow_4 (3.141)  /* compute 3.141**4 */

Testing the Sign of Numbers
===========================

.. macro:: GSL_SIGN (x)

   This macro returns the sign of :data:`x`. It is defined as :code:`((x) >= 0
   ? 1 : -1)`. Note that with this definition the sign of zero is positive
   (regardless of its IEEE sign bit).

Testing for Odd and Even Numbers
================================

.. macro:: GSL_IS_ODD (n)

   This macro evaluates to 1 if :data:`n` is odd and 0 if :data:`n` is
   even. The argument :data:`n` must be of integer type.

.. macro:: GSL_IS_EVEN (n)

   This macro is the opposite of :macro:`GSL_IS_ODD`. It evaluates to 1 if
   :data:`n` is even and 0 if :data:`n` is odd. The argument :data:`n` must be of
   integer type.

Maximum and Minimum functions
=============================

Note that the following macros perform multiple evaluations of their
arguments, so they should not be used with arguments that have side
effects (such as a call to a random number generator).

.. index:: maximum of two numbers

.. macro:: GSL_MAX (a, b)

   This macro returns the maximum of :data:`a` and :data:`b`. It is defined
   as :code:`((a) > (b) ? (a):(b))`.

.. index:: minimum of two numbers

.. macro:: GSL_MIN (a, b)

   This macro returns the minimum of :data:`a` and :data:`b`. It is defined as 
   :code:`((a) < (b) ? (a):(b))`.

.. function:: extern inline double GSL_MAX_DBL (double a, double b)

   This function returns the maximum of the double precision numbers
   :data:`a` and :data:`b` using an inline function. The use of a function
   allows for type checking of the arguments as an extra safety feature. On
   platforms where inline functions are not available the macro
   :macro:`GSL_MAX` will be automatically substituted.

.. function:: extern inline double GSL_MIN_DBL (double a, double b)

   This function returns the minimum of the double precision numbers
   :data:`a` and :data:`b` using an inline function. The use of a function
   allows for type checking of the arguments as an extra safety feature. On
   platforms where inline functions are not available the macro
   :macro:`GSL_MIN` will be automatically substituted.

.. function::
   extern inline int GSL_MAX_INT (int a, int b)
   extern inline int GSL_MIN_INT (int a, int b)

   These functions return the maximum or minimum of the integers :data:`a`
   and :data:`b` using an inline function.  On platforms where inline
   functions are not available the macros :macro:`GSL_MAX` or :macro:`GSL_MIN`
   will be automatically substituted.

.. function::
   extern inline long double GSL_MAX_LDBL (long double a, long double b)
   extern inline long double GSL_MIN_LDBL (long double a, long double b)

   These functions return the maximum or minimum of the long doubles :data:`a`
   and :data:`b` using an inline function.  On platforms where inline
   functions are not available the macros :macro:`GSL_MAX` or :macro:`GSL_MIN`
   will be automatically substituted.

Approximate Comparison of Floating Point Numbers
================================================

It is sometimes useful to be able to compare two floating point numbers
approximately, to allow for rounding and truncation errors.  The following
function implements the approximate floating-point comparison algorithm
proposed by D.E. Knuth in Section 4.2.2 of "Seminumerical
Algorithms" (3rd edition).

.. index::
   single: approximate comparison of floating point numbers
   single: safe comparison of floating point numbers
   single: floating point numbers, approximate comparison

.. function:: int gsl_fcmp (double x, double y, double epsilon)

   This function determines whether :data:`x` and :data:`y` are approximately
   equal to a relative accuracy :data:`epsilon`.

   The relative accuracy is measured using an interval of size :math:`2
   \delta`, where :math:`\delta = 2^k \epsilon` and :math:`k` is the
   maximum base-2 exponent of :math:`x` and :math:`y` as computed by the
   function :func:`frexp`.

   If :math:`x` and :math:`y` lie within this interval, they are considered
   approximately equal and the function returns 0. Otherwise if :math:`x <
   y`, the function returns :math:`-1`, or if :math:`x > y`, the function returns
   :math:`+1`.

   Note that :math:`x` and :math:`y` are compared to relative accuracy, so
   this function is not suitable for testing whether a value is
   approximately zero. 

   The implementation is based on the package :code:`fcmp` by T.C. Belding.

.. rubric:: Footnotes

.. [#f1] Note that the C99 standard only requires the
   system :func:`isinf` function to return a non-zero value, without the
   sign of the infinity.  The implementation in some earlier versions of
   GSL used the system :func:`isinf` function and may have this behavior
   on some platforms.  Therefore, it is advisable to test the sign of
   :data:`x` separately, if needed, rather than relying the sign of the
   return value from :func:`gsl_isinf()`.
.. index::
   single: running statistics
   single: online statistics

******************
Running Statistics
******************

This chapter describes routines for computing running statistics,
also known as online statistics, of data. These routines are
suitable for handling large datasets for which it may be
inconvenient or impractical to store in memory all at once.
The data can be processed in a single pass, one point at a time.
Each time a data point is added to the accumulator, internal
parameters are updated in order to compute the current mean, variance,
standard deviation, skewness, and kurtosis. These statistics are
exact, and are updated with numerically stable single-pass algorithms.
The median and arbitrary quantiles are also available, however these
calculations use algorithms which provide approximations, and grow
more accurate as more data is added to the accumulator.

The functions described in this chapter are declared in the header file
:file:`gsl_rstat.h`.

Initializing the Accumulator
============================

.. type:: gsl_rstat_workspace

   This workspace contains parameters used to calculate various statistics
   and are updated after each data point is added to the accumulator.

.. function:: gsl_rstat_workspace * gsl_rstat_alloc (void)

   This function allocates a workspace for computing running statistics.
   The size of the workspace is :math:`O(1)`.

.. function:: void gsl_rstat_free (gsl_rstat_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_rstat_reset (gsl_rstat_workspace * w)

   This function resets the workspace :data:`w` to its initial state,
   so it can begin working on a new set of data.

Adding Data to the Accumulator
==============================

.. function:: int gsl_rstat_add (const double x, gsl_rstat_workspace * w)

   This function adds the data point :data:`x` to the statistical
   accumulator, updating calculations of the mean, variance,
   standard deviation, skewness, kurtosis, and median.

.. function:: size_t gsl_rstat_n (const gsl_rstat_workspace * w)

   This function returns the number of data so far added to the accumulator.

Current Statistics
==================

.. function:: double gsl_rstat_min (const gsl_rstat_workspace * w)

   This function returns the minimum value added to the accumulator.

.. function:: double gsl_rstat_max (const gsl_rstat_workspace * w)

   This function returns the maximum value added to the accumulator.

.. function:: double gsl_rstat_mean (const gsl_rstat_workspace * w)

   This function returns the mean of all data added to the accumulator,
   defined as

   .. only:: not texinfo

      .. math:: {\Hat\mu} = {1 \over N} \sum x_i

   .. only:: texinfo

      ::

         \Hat\mu = (1/N) \sum x_i

.. function:: double gsl_rstat_variance (const gsl_rstat_workspace * w)

   This function returns the variance of all data added to the accumulator,
   defined as

   .. only:: not texinfo

      .. math:: {\Hat\sigma}^2 = {1 \over (N-1)} \sum (x_i - {\Hat\mu})^2

   .. only:: texinfo

      ::

         \Hat\sigma^2 = (1/(N-1)) \sum (x_i - \Hat\mu)^2

.. function:: double gsl_rstat_sd (const gsl_rstat_workspace * w)

   This function returns the standard deviation of all data added to the
   accumulator, defined as the square root of the variance given above.

.. function:: double gsl_rstat_sd_mean (const gsl_rstat_workspace * w)

   This function returns the standard deviation of the mean, defined as

   .. only:: not texinfo
   
      .. math:: \Hat\sigma_{\Hat\mu} = {\Hat\sigma \over \sqrt{N}}

   .. only:: texinfo

      ::

         sd_mean = \Hat\sigma / \sqrt{N}

.. function:: double gsl_rstat_rms (const gsl_rstat_workspace * w)

   This function returns the root mean square of all data added to the
   accumulator, defined as

   .. math:: rms = \sqrt{{1 \over N} \sum x_i^2}

.. function:: double gsl_rstat_skew (const gsl_rstat_workspace * w)

   This function returns the skewness of all data added to the accumulator,
   defined as

   .. only:: not texinfo

      .. math::

         skew = {1 \over N} \sum 
          {\left( x_i - {\Hat\mu} \over {\Hat\sigma} \right)}^3

   .. only:: texinfo

      ::

         skew = (1/N) \sum ((x_i - \Hat\mu)/\Hat\sigma)^3

.. function:: double gsl_rstat_kurtosis (const gsl_rstat_workspace * w)

   This function returns the kurtosis of all data added to the accumulator,
   defined as

   .. only:: not texinfo

      .. math::

         kurtosis = \left( {1 \over N} \sum 
          {\left(x_i - {\Hat\mu} \over {\Hat\sigma} \right)}^4 
          \right) 
          - 3

   .. only:: texinfo

      ::

         kurtosis = ((1/N) \sum ((x_i - \Hat\mu)/\Hat\sigma)^4)  - 3

.. function:: double gsl_rstat_median (gsl_rstat_workspace * w)

   This function returns an estimate of the median of the data added to
   the accumulator.

Quantiles
=========

The functions in this section estimate quantiles dynamically without
storing the entire dataset, using the algorithm of Jain and Chlamtec, 1985.
Only five points (markers) are stored which represent the minimum
and maximum of the data, as well as current estimates of the
:math:`p/2`-, :math:`p`-, and :math:`(1+p)/2`-quantiles. Each time
a new data point is added, the marker positions and heights are
updated.

.. type:: gsl_rstat_quantile_workspace

   This workspace contains parameters for estimating quantiles of the
   current dataset

.. function:: gsl_rstat_quantile_workspace * gsl_rstat_quantile_alloc (const double p)

   This function allocates a workspace for the dynamic estimation of
   :data:`p`-quantiles, where :data:`p` is between :math:`0` and :math:`1`.
   The median corresponds to :math:`p = 0.5`. The size of the workspace
   is :math:`O(1)`.

.. function:: void gsl_rstat_quantile_free (gsl_rstat_quantile_workspace * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: int gsl_rstat_quantile_reset (gsl_rstat_quantile_workspace * w)

   This function resets the workspace :data:`w` to its initial state,
   so it can begin working on a new set of data.

.. function:: int gsl_rstat_quantile_add (const double x, gsl_rstat_quantile_workspace * w)

   This function updates the estimate of the :math:`p`-quantile with
   the new data point :data:`x`.

.. function:: double gsl_rstat_quantile_get (gsl_rstat_quantile_workspace * w)

   This function returns the current estimate of the :math:`p`-quantile.

Examples
========

Here is a basic example of how to use the statistical functions:

.. include:: examples/rstat.c
   :code:

The program should produce the following output,

.. include:: examples/rstat.txt
   :code:

This next program estimates the lower quartile, median and upper
quartile from 10,000 samples of a random Rayleigh distribution,
using the :math:`P^2` algorithm of Jain and Chlamtec. For
comparison, the exact values are also computed from the sorted
dataset.

.. include:: examples/rquantile.c
   :code:

The program should produce the following output,

.. include:: examples/rquantile.txt
   :code:

References and Further Reading
==============================

The algorithm used to dynamically estimate :math:`p`-quantiles is described
in the paper,

* R. Jain and I. Chlamtac.
  *The P^2 algorithm for dynamic calculation of quantiles and histograms without storing observations*,
  Communications of the ACM, Volume 28 (October), Number 10, 1985,
  p. 1076-1085.
.. index::
   single: psi function
   single: digamma function
   single: polygamma functions

The polygamma functions of order :math:`n` are defined by

.. only:: not texinfo

   .. math:: \psi^{(n)}(x) = \left(d \over dx\right)^n \psi(x) = \left(d \over dx\right)^{n+1} \log(\Gamma(x))

.. only:: texinfo

   ::

      \psi^{(n)}(x) = (d/dx)^n \psi(x) = (d/dx)^{n+1} \log(\Gamma(x))

where :math:`\psi(x) = \Gamma'(x)/\Gamma(x)` is known as the digamma function.
These functions are declared in the header file :file:`gsl_sf_psi.h`.

Digamma Function
----------------

.. function:: double gsl_sf_psi_int (int n)
              int gsl_sf_psi_int_e (int n, gsl_sf_result * result)

   These routines compute the digamma function :math:`\psi(n)` for positive
   integer :data:`n`.  The digamma function is also called the Psi function.
.. Domain: n integer, n > 0
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_psi (double x)
              int gsl_sf_psi_e (double x, gsl_sf_result * result)

   These routines compute the digamma function :math:`\psi(x)` for general
   :data:`x`, :math:`x \ne 0`.
.. Domain: x != 0.0, -1.0, -2.0, ...
.. Exceptional Return Values: GSL_EDOM, GSL_ELOSS

.. function:: double gsl_sf_psi_1piy (double y)
              int gsl_sf_psi_1piy_e (double y, gsl_sf_result * result)

   These routines compute the real part of the digamma function on the line
   :math:`1 + i y`, :math:`\Re[\psi(1 + i y)]`.
.. exceptions: none
.. Exceptional Return Values: none

Trigamma Function
-----------------

.. function:: double gsl_sf_psi_1_int (int n)
              int gsl_sf_psi_1_int_e (int n, gsl_sf_result * result)

   These routines compute the Trigamma function :math:`\psi'(n)` for
   positive integer :math:`n`.
.. Domain: n integer, n > 0 
.. Exceptional Return Values: GSL_EDOM

.. function:: double gsl_sf_psi_1 (double x)
              int gsl_sf_psi_1_e (double x, gsl_sf_result * result)

   These routines compute the Trigamma function :math:`\psi'(x)` for
   general :data:`x`.
.. Domain: x != 0.0, -1.0, -2.0, ...
.. Exceptional Return Values: GSL_EDOM, GSL_ELOSS

Polygamma Function
------------------

.. function:: double gsl_sf_psi_n (int n, double x)
              int gsl_sf_psi_n_e (int n, double x, gsl_sf_result * result)

   These routines compute the polygamma function :math:`\psi^{(n)}(x)` for
   :math:`n \ge 0`, :math:`x > 0`.
.. Domain: n >= 0, x > 0.0
.. Exceptional Return Values: GSL_EDOM
.. index:: random number generators

************************
Random Number Generation
************************

.. include:: include.rst

The library provides a large collection of random number generators
which can be accessed through a uniform interface.  Environment
variables allow you to select different generators and seeds at runtime,
so that you can easily switch between generators without needing to
recompile your program.  Each instance of a generator keeps track of its
own state, allowing the generators to be used in multi-threaded
programs.  Additional functions are available for transforming uniform
random numbers into samples from continuous or discrete probability
distributions such as the Gaussian, log-normal or Poisson distributions.

These functions are declared in the header file :file:`gsl_rng.h`.

.. Need to explain the difference between SERIAL and PARALLEL random 
.. number generators here

General comments on random numbers
==================================

In 1988, Park and Miller wrote a paper entitled "Random number
generators: good ones are hard to find." [Commun.: ACM, 31, 1192--1201].
Fortunately, some excellent random number generators are available,
though poor ones are still in common use.  You may be happy with the
system-supplied random number generator on your computer, but you should
be aware that as computers get faster, requirements on random number
generators increase.  Nowadays, a simulation that calls a random number
generator millions of times can often finish before you can make it down
the hall to the coffee machine and back.

A very nice review of random number generators was written by Pierre
L'Ecuyer, as Chapter 4 of the book: Handbook on Simulation, Jerry Banks,
ed. (Wiley, 1997).  The chapter is available in postscript from
L'Ecuyer's ftp site (see references).  Knuth's volume on Seminumerical
Algorithms (originally published in 1968) devotes 170 pages to random
number generators, and has recently been updated in its 3rd edition
(1997).
It is brilliant, a classic.  If you don't own it, you should stop reading
right now, run to the nearest bookstore, and buy it.

A good random number generator will satisfy both theoretical and
statistical properties.  Theoretical properties are often hard to obtain
(they require real math!), but one prefers a random number generator
with a long period, low serial correlation, and a tendency **not** to
"fall mainly on the planes."  Statistical tests are performed with
numerical simulations.  Generally, a random number generator is used to
estimate some quantity for which the theory of probability provides an
exact answer.  Comparison to this exact answer provides a measure of
"randomness".

The Random Number Generator Interface
=====================================

It is important to remember that a random number generator is not a
"real" function like sine or cosine.  Unlike real functions, successive
calls to a random number generator yield different return values.  Of
course that is just what you want for a random number generator, but to
achieve this effect, the generator must keep track of some kind of
"state" variable.  Sometimes this state is just an integer (sometimes
just the value of the previously generated random number), but often it
is more complicated than that and may involve a whole array of numbers,
possibly with some indices thrown in.  To use the random number
generators, you do not need to know the details of what comprises the
state, and besides that varies from algorithm to algorithm.

.. type:: gsl_rng_type
          gsl_rng

   The random number generator library uses two special structs,
   :type:`gsl_rng_type` which holds static information about each type of
   generator and :type:`gsl_rng` which describes an instance of a generator
   created from a given :type:`gsl_rng_type`.

The functions described in this section are declared in the header file
:file:`gsl_rng.h`.

Random number generator initialization
======================================

.. function:: gsl_rng * gsl_rng_alloc (const gsl_rng_type * T)

   This function returns a pointer to a newly-created
   instance of a random number generator of type :data:`T`.
   For example, the following code creates an instance of the Tausworthe
   generator::

      gsl_rng * r = gsl_rng_alloc (gsl_rng_taus);

   If there is insufficient memory to create the generator then the
   function returns a null pointer and the error handler is invoked with an
   error code of :macro:`GSL_ENOMEM`.

   The generator is automatically initialized with the default seed,
   :data:`gsl_rng_default_seed`.  This is zero by default but can be changed
   either directly or by using the environment variable :macro:`GSL_RNG_SEED`.

   The details of the available generator types are
   described later in this chapter.

.. function:: void gsl_rng_set (const gsl_rng * r, unsigned long int s)

   This function initializes (or "seeds") the random number generator.  If
   the generator is seeded with the same value of :data:`s` on two different
   runs, the same stream of random numbers will be generated by successive
   calls to the routines below.  If different values of :math:`s \geq 1`
   are supplied, then the generated streams of random
   numbers should be completely different.  If the seed :data:`s` is zero
   then the standard seed from the original implementation is used
   instead.  For example, the original Fortran source code for the
   :code:`ranlux` generator used a seed of 314159265, and so choosing
   :data:`s` equal to zero reproduces this when using
   :data:`gsl_rng_ranlux`.

   When using multiple seeds with the same generator, choose seed values
   greater than zero to avoid collisions with the default setting.  

   Note that the most generators only accept 32-bit seeds, with higher
   values being reduced modulo :math:`2^{32}`.
   For generators with smaller ranges the maximum seed value will typically be lower.

.. function:: void gsl_rng_free (gsl_rng * r)

   This function frees all the memory associated with the generator
   :data:`r`.

Sampling from a random number generator
=======================================

The following functions return uniformly distributed random numbers,
either as integers or double precision floating point numbers.  |inlinefns|
To obtain non-uniform distributions, see :ref:`chap_random-number-distributions`.

.. function:: unsigned long int gsl_rng_get (const gsl_rng * r)

   This function returns a random integer from the generator :data:`r`.  The
   minimum and maximum values depend on the algorithm used, but all
   integers in the range [:data:`min`, :data:`max`] are equally likely.  The
   values of :data:`min` and :data:`max` can be determined using the auxiliary
   functions :func:`gsl_rng_max` and :func:`gsl_rng_min`.

.. function:: double gsl_rng_uniform (const gsl_rng * r)

   This function returns a double precision floating point number uniformly
   distributed in the range [0,1).  The range includes 0.0 but excludes 1.0.
   The value is typically obtained by dividing the result of
   :code:`gsl_rng_get(r)` by :code:`gsl_rng_max(r) + 1.0` in double
   precision.  Some generators compute this ratio internally so that they
   can provide floating point numbers with more than 32 bits of randomness
   (the maximum number of bits that can be portably represented in a single
   :code:`unsigned long int`).

.. function:: double gsl_rng_uniform_pos (const gsl_rng * r)

   This function returns a positive double precision floating point number
   uniformly distributed in the range (0,1), excluding both 0.0 and 1.0.
   The number is obtained by sampling the generator with the algorithm of
   :func:`gsl_rng_uniform` until a non-zero value is obtained.  You can use
   this function if you need to avoid a singularity at 0.0.

.. function:: unsigned long int gsl_rng_uniform_int (const gsl_rng * r, unsigned long int n)

   This function returns a random integer from 0 to :math:`n-1` inclusive
   by scaling down and/or discarding samples from the generator :data:`r`.
   All integers in the range :math:`[0,n-1]` are produced with equal
   probability.  For generators with a non-zero minimum value an offset
   is applied so that zero is returned with the correct probability.

   Note that this function is designed for sampling from ranges smaller
   than the range of the underlying generator.  The parameter :data:`n`
   must be less than or equal to the range of the generator :data:`r`.
   If :data:`n` is larger than the range of the generator then the function
   calls the error handler with an error code of :macro:`GSL_EINVAL` and
   returns zero.

   In particular, this function is not intended for generating the full range of
   unsigned integer values :math:`[0,2^{32}-1]`.
   Instead choose a generator with the maximal integer range and zero minimum
   value, such as :data:`gsl_rng_ranlxd1`, :data:`gsl_rng_mt19937` or
   :data:`gsl_rng_taus`, and sample it directly using
   :func:`gsl_rng_get`.  The range of each generator can be found using
   the auxiliary functions described in the next section.

Auxiliary random number generator functions
===========================================

The following functions provide information about an existing
generator.  You should use them in preference to hard-coding the generator
parameters into your own code.

.. function:: const char * gsl_rng_name (const gsl_rng * r)

   This function returns a pointer to the name of the generator.
   For example::

      printf ("r is a '%s' generator\n", gsl_rng_name (r));

   would print something like::
   
      r is a 'taus' generator

.. function:: unsigned long int gsl_rng_max (const gsl_rng * r)

   This function returns the largest value that :func:`gsl_rng_get`
   can return.

.. function:: unsigned long int gsl_rng_min (const gsl_rng * r)

   This function returns the smallest value that :func:`gsl_rng_get`
   can return.  Usually this value is zero.  There are some generators with
   algorithms that cannot return zero, and for these generators the minimum
   value is 1.

.. function:: void * gsl_rng_state (const gsl_rng * r)
              size_t gsl_rng_size (const gsl_rng * r)

   These functions return a pointer to the state of generator :data:`r` and
   its size.  You can use this information to access the state directly.  For
   example, the following code will write the state of a generator to a
   stream::

      void * state = gsl_rng_state (r);
      size_t n = gsl_rng_size (r);
      fwrite (state, n, 1, stream);

.. function:: const gsl_rng_type ** gsl_rng_types_setup (void)

   This function returns a pointer to an array of all the available
   generator types, terminated by a null pointer. The function should be
   called once at the start of the program, if needed.  The following code
   fragment shows how to iterate over the array of generator types to print
   the names of the available algorithms::

      const gsl_rng_type **t, **t0;

      t0 = gsl_rng_types_setup ();

      printf ("Available generators:\n");

      for (t = t0; *t != 0; t++)
        {
          printf ("%s\n", (*t)->name);
        }

Random number environment variables
===================================

The library allows you to choose a default generator and seed from the
environment variables :macro:`GSL_RNG_TYPE` and :macro:`GSL_RNG_SEED` and
the function :func:`gsl_rng_env_setup`.  This makes it easy try out
different generators and seeds without having to recompile your program.

.. macro:: GSL_RNG_TYPE

   This environment variable specifies the default random number generator.
   It should be the name of a generator, such as :code:`taus` or :code:`mt19937`.

.. macro:: GSL_RNG_SEED

   This environment variable specifies the default seed for the random
   number generator

.. var:: gsl_rng_default

   This global library variable specifies the default random number generator,
   and can be initialized from :macro:`GSL_RNG_TYPE` using :func:`gsl_rng_env_setup`.
   It is defined as follows::

      extern const gsl_rng_type *gsl_rng_default

.. var:: gsl_rng_default_seed

   This global library variable specifies the seed for the default random number generator,
   and can be initialized from :macro:`GSL_RNG_SEED` using :func:`gsl_rng_env_setup`.
   It is set to zero by default and is defined as follows::

      extern unsigned long int gsl_rng_default_seed

.. function:: const gsl_rng_type * gsl_rng_env_setup (void)

   This function reads the environment variables :macro:`GSL_RNG_TYPE` and
   :macro:`GSL_RNG_SEED` and uses their values to set the corresponding
   library variables :data:`gsl_rng_default` and
   :data:`gsl_rng_default_seed`.

   The value of :macro:`GSL_RNG_SEED` is converted to an :code:`unsigned long int`
   using the C library function :func:`strtoul`.

   If you don't specify a generator for :macro:`GSL_RNG_TYPE` then
   :data:`gsl_rng_mt19937` is used as the default.  The initial value of
   :data:`gsl_rng_default_seed` is zero.

Here is a short program which shows how to create a global
generator using the environment variables :macro:`GSL_RNG_TYPE` and
:macro:`GSL_RNG_SEED`,

.. include:: examples/rng.c
   :code:

Running the program without any environment variables uses the initial
defaults, an :code:`mt19937` generator with a seed of 0,

.. include:: examples/rng.txt
   :code:

By setting the two variables on the command line we can
change the default generator and the seed::

  $ GSL_RNG_TYPE="taus" GSL_RNG_SEED=123 ./a.out 
  GSL_RNG_TYPE=taus
  GSL_RNG_SEED=123
  generator type: taus
  seed = 123
  first value = 2720986350

Copying random number generator state
=====================================

The above methods do not expose the random number state which changes
from call to call.  It is often useful to be able to save and restore
the state.  To permit these practices, a few somewhat more advanced
functions are supplied.  These include:

.. function:: int gsl_rng_memcpy (gsl_rng * dest, const gsl_rng * src)

   This function copies the random number generator :data:`src` into the
   pre-existing generator :data:`dest`, making :data:`dest` into an exact copy
   of :data:`src`.  The two generators must be of the same type.

.. function:: gsl_rng * gsl_rng_clone (const gsl_rng * r)

   This function returns a pointer to a newly created generator which is an
   exact copy of the generator :data:`r`.

Reading and writing random number generator state
=================================================

The library provides functions for reading and writing the random
number state to a file as binary data.

.. function:: int gsl_rng_fwrite (FILE * stream, const gsl_rng * r)

   This function writes the random number state of the random number
   generator :data:`r` to the stream :data:`stream` in binary format.  The
   return value is 0 for success and :macro:`GSL_EFAILED` if there was a
   problem writing to the file.  Since the data is written in the native
   binary format it may not be portable between different architectures.

.. function:: int gsl_rng_fread (FILE * stream, gsl_rng * r)

   This function reads the random number state into the random number
   generator :data:`r` from the open stream :data:`stream` in binary format.
   The random number generator :data:`r` must be preinitialized with the
   correct random number generator type since type information is not
   saved.  The return value is 0 for success and :macro:`GSL_EFAILED` if
   there was a problem reading from the file.  The data is assumed to
   have been written in the native binary format on the same
   architecture.

Random number generator algorithms
==================================

The functions described above make no reference to the actual algorithm
used.  This is deliberate so that you can switch algorithms without
having to change any of your application source code.  The library
provides a large number of generators of different types, including
simulation quality generators, generators provided for compatibility
with other libraries and historical generators from the past.

The following generators are recommended for use in simulation.  They
have extremely long periods, low correlation and pass most statistical
tests.  For the most reliable source of uncorrelated numbers, the
second-generation RANLUX generators have the strongest proof of
randomness.

.. index:: MT19937 random number generator

.. var:: gsl_rng_mt19937

   The MT19937 generator of Makoto Matsumoto and Takuji Nishimura is a
   variant of the twisted generalized feedback shift-register algorithm,
   and is known as the "Mersenne Twister" generator.  It has a Mersenne
   prime period of :math:`2^{19937} - 1`
   (about :math:`10^{6000}`) and is
   equi-distributed in 623 dimensions.  It has passed the DIEHARD
   statistical tests.  It uses 624 words of state per generator and is
   comparable in speed to the other generators.  The original generator used
   a default seed of 4357 and choosing :data:`s` equal to zero in
   :func:`gsl_rng_set` reproduces this.  Later versions switched to 5489
   as the default seed, you can choose this explicitly via :func:`gsl_rng_set`
   instead if you require it.

   For more information see,

   * Makoto Matsumoto and Takuji Nishimura, "Mersenne Twister: A
     623-dimensionally equidistributed uniform pseudorandom number
     generator". ACM Transactions on Modeling and Computer
     Simulation, Vol.: 8, No.: 1 (Jan. 1998), Pages 3--30

   The generator :data:`gsl_rng_mt19937` uses the second revision of the
   seeding procedure published by the two authors above in 2002.  The
   original seeding procedures could cause spurious artifacts for some seed
   values. They are still available through the alternative generators
   :data:`gsl_rng_mt19937_1999` and :data:`gsl_rng_mt19937_1998`.

.. index:: RANLXS random number generator

.. var:: gsl_rng_ranlxs0
         gsl_rng_ranlxs1
         gsl_rng_ranlxs2

   The generator :code:`ranlxs0` is a second-generation version of the
   RANLUX algorithm of Luscher, which produces "luxury random
   numbers".  This generator provides single precision output (24 bits) at
   three luxury levels :code:`ranlxs0`, :code:`ranlxs1` and :code:`ranlxs2`,
   in increasing order of strength.  
   It uses double-precision floating point arithmetic internally and can be
   significantly faster than the integer version of :code:`ranlux`,
   particularly on 64-bit architectures.  The period of the generator is
   about :math:`10^{171}`.
   The algorithm has mathematically proven properties and
   can provide truly decorrelated numbers at a known level of randomness.
   The higher luxury levels provide increased decorrelation between samples
   as an additional safety margin.

   Note that the range of allowed seeds for this generator is :math:`[0,2^{31}-1]`.
   Higher seed values are wrapped modulo :math:`2^{31}`.

.. index:: RANLXD random number generator

.. var:: gsl_rng_ranlxd1
         gsl_rng_ranlxd2

   These generators produce double precision output (48 bits) from the
   RANLXS generator.  The library provides two luxury levels
   :code:`ranlxd1` and :code:`ranlxd2`, in increasing order of strength.

.. index:: RANLUX random number generator

.. var:: gsl_rng_ranlux
         gsl_rng_ranlux389

   The :code:`ranlux` generator is an implementation of the original
   algorithm developed by Luscher.  It uses a
   lagged-fibonacci-with-skipping algorithm to produce "luxury random
   numbers".  It is a 24-bit generator, originally designed for
   single-precision IEEE floating point numbers.  This implementation is
   based on integer arithmetic, while the second-generation versions
   RANLXS and RANLXD described above provide floating-point
   implementations which will be faster on many platforms.
   The period of the generator is about :math:`10^{171}`.
   The algorithm has mathematically proven properties and
   it can provide truly decorrelated numbers at a known level of
   randomness.  The default level of decorrelation recommended by Luscher
   is provided by :data:`gsl_rng_ranlux`, while :data:`gsl_rng_ranlux389`
   gives the highest level of randomness, with all 24 bits decorrelated.
   Both types of generator use 24 words of state per generator.

   For more information see,

   * M. Luscher, "A portable high-quality random number generator for
     lattice field theory calculations", Computer Physics
     Communications, 79 (1994) 100--110.

   * F. James, "RANLUX: A Fortran implementation of the high-quality
     pseudo-random number generator of Luscher", Computer Physics
     Communications, 79 (1994) 111--114

.. index::
   single: CMRG, combined multiple recursive random number generator

.. var:: gsl_rng_cmrg

   This is a combined multiple recursive generator by L'Ecuyer. 
   Its sequence is,

   .. math:: z_n = (x_n - y_n) \mod m_1

   where the two underlying generators :math:`x_n` and :math:`y_n` are,

   .. only:: not texinfo

      .. math::

         x_n & = (a_1 x_{n-1} + a_2 x_{n-2} + a_3 x_{n-3}) \mod m_1 \\
         y_n & = (b_1 y_{n-1} + b_2 y_{n-2} + b_3 y_{n-3}) \mod m_2

   .. only:: texinfo

      ::

         x_n = (a_1 x_{n-1} + a_2 x_{n-2} + a_3 x_{n-3}) mod m_1
         y_n = (b_1 y_{n-1} + b_2 y_{n-2} + b_3 y_{n-3}) mod m_2

   with coefficients 
   :math:`a_1 = 0`, 
   :math:`a_2 = 63308`, 
   :math:`a_3 = -183326`,
   :math:`b_1 = 86098`, 
   :math:`b_2 = 0`,
   :math:`b_3 = -539608`,
   and moduli 
   :math:`m_1 = 2^{31} - 1 = 2147483647`
   and 
   :math:`m_2 = 2145483479`.

   The period of this generator is  
   :math:`\hbox{lcm}(m_1^3-1, m_2^3-1)`,
   which is approximately
   :math:`2^{185}`
   (about :math:`10^{56}`).
   It uses 6 words of state per generator.  For more information see,

   * P. L'Ecuyer, "Combined Multiple Recursive Random Number
     Generators", Operations Research, 44, 5 (1996), 816--822.

.. index::
   single: MRG, multiple recursive random number generator

.. var:: gsl_rng_mrg

   This is a fifth-order multiple recursive generator by L'Ecuyer, Blouin
   and Coutre.  Its sequence is,

   .. math:: x_n = (a_1 x_{n-1} + a_5 x_{n-5}) \mod m

   with 
   :math:`a_1 = 107374182`,
   :math:`a_2 = a_3 = a_4 = 0`, 
   :math:`a_5 = 104480`
   and 
   :math:`m = 2^{31}-1`.

   The period of this generator is about 
   :math:`10^{46}`.
   It uses 5 words
   of state per generator.  More information can be found in the following
   paper,

   * P. L'Ecuyer, F. Blouin, and R. Coutre, "A search for good multiple
     recursive random number generators", ACM Transactions on Modeling and
     Computer Simulation 3, 87--98 (1993).

.. index:: Tausworthe random number generator

.. var:: gsl_rng_taus
         gsl_rng_taus2

   This is a maximally equidistributed combined Tausworthe generator by
   L'Ecuyer.  The sequence is,

   .. only:: not texinfo

      .. math:: x_n = (s^1_n \oplus s^2_n \oplus s^3_n) 

   .. only:: texinfo

      ::

         x_n = (s1_n ^^ s2_n ^^ s3_n) 

   where,

   .. only:: not texinfo

      .. math::

         s^1_{n+1} &= (((s^1_n \& 4294967294)\ll 12) \oplus (((s^1_n\ll 13) \oplus s^1_n)\gg 19)) \\
         s^2_{n+1} &= (((s^2_n \& 4294967288)\ll 4) \oplus (((s^2_n\ll 2) \oplus s^2_n)\gg 25)) \\
         s^3_{n+1} &= (((s^3_n \& 4294967280)\ll 17) \oplus (((s^3_n\ll 3) \oplus s^3_n)\gg 11))

   .. only:: texinfo

      ::

         s1_{n+1} = (((s1_n&4294967294)<<12)^^(((s1_n<<13)^^s1_n)>>19))
         s2_{n+1} = (((s2_n&4294967288)<< 4)^^(((s2_n<< 2)^^s2_n)>>25))
         s3_{n+1} = (((s3_n&4294967280)<<17)^^(((s3_n<< 3)^^s3_n)>>11))

   computed modulo 
   :math:`2^{32}`.
   In the formulas above 
   :math:`\oplus`
   denotes *exclusive-or*.  Note that the algorithm relies on the properties
   of 32-bit unsigned integers and has been implemented using a bitmask
   of :code:`0xFFFFFFFF` to make it work on 64 bit machines.

   The period of this generator is :math:`2^{88}`
   (about :math:`10^{26}`).
   It uses 3 words of state per generator.  For more
   information see,

   * P. L'Ecuyer, "Maximally Equidistributed Combined Tausworthe
     Generators", Mathematics of Computation, 65, 213 (1996), 203--213.

   The generator :data:`gsl_rng_taus2` uses the same algorithm as
   :data:`gsl_rng_taus` but with an improved seeding procedure described in
   the paper,

   * P. L'Ecuyer, "Tables of Maximally Equidistributed Combined LFSR
     Generators", Mathematics of Computation, 68, 225 (1999), 261--269

   The generator :data:`gsl_rng_taus2` should now be used in preference to
   :data:`gsl_rng_taus`.

.. index:: Four-tap Generalized Feedback Shift Register

.. var:: gsl_rng_gfsr4

   The :code:`gfsr4` generator is like a lagged-fibonacci generator, and 
   produces each number as an :code:`xor`'d sum of four previous values.

   .. only:: not texinfo

      .. math:: r_n = r_{n-A} \oplus r_{n-B} \oplus r_{n-C} \oplus r_{n-D}

   .. only:: texinfo

      ::

         r_n = r_{n-A} ^^ r_{n-B} ^^ r_{n-C} ^^ r_{n-D}

   Ziff (ref below) notes that "it is now widely known" that two-tap
   registers (such as R250, which is described below)
   have serious flaws, the most obvious one being the three-point
   correlation that comes from the definition of the generator.  Nice
   mathematical properties can be derived for GFSR's, and numerics bears
   out the claim that 4-tap GFSR's with appropriately chosen offsets are as
   random as can be measured, using the author's test.

   This implementation uses the values suggested the example on p392 of
   Ziff's article: :math:`A=471`, :math:`B=1586`, :math:`C=6988`, :math:`D=9689`.

   If the offsets are appropriately chosen (such as the one ones in this
   implementation), then the sequence is said to be maximal; that means
   that the period is :math:`2^D - 1`, where :math:`D` is the longest lag.
   (It is one less than :math:`2^D` because it is not permitted to have all
   zeros in the :code:`ra[]` array.)  For this implementation with
   :math:`D=9689` that works out to about :math:`10^{2917}`.

   Note that the implementation of this generator using a 32-bit
   integer amounts to 32 parallel implementations of one-bit
   generators.  One consequence of this is that the period of this
   32-bit generator is the same as for the one-bit generator.
   Moreover, this independence means that all 32-bit patterns are
   equally likely, and in particular that 0 is an allowed random
   value.  (We are grateful to Heiko Bauke for clarifying for us these
   properties of GFSR random number generators.)

   For more information see,

   * Robert M. Ziff, "Four-tap shift-register-sequence random-number 
     generators", Computers in Physics, 12(4), Jul/Aug
     1998, pp 385--392.

Unix random number generators
=============================

The standard Unix random number generators :code:`rand`, :code:`random`
and :code:`rand48` are provided as part of GSL. Although these
generators are widely available individually often they aren't all
available on the same platform.  This makes it difficult to write
portable code using them and so we have included the complete set of
Unix generators in GSL for convenience.  Note that these generators
don't produce high-quality randomness and aren't suitable for work
requiring accurate statistics.  However, if you won't be measuring
statistical quantities and just want to introduce some variation into
your program then these generators are quite acceptable.

.. index::
   single: rand, BSD random number generator
   single: Unix random number generators, rand
   single: Unix random number generators, rand48

.. index:: BSD random number generator

.. var:: gsl_rng_rand

   This is the BSD :code:`rand` generator.  Its sequence is

   .. math:: x_{n+1} = (a x_n + c) \mod m

   with 
   :math:`a = 1103515245`, 
   :math:`c = 12345` and 
   :math:`m = 2^{31}`.
   The seed specifies the initial value, 
   :math:`x_1`.  The period of this
   generator is 
   :math:`2^{31}`,
   and it uses 1 word of storage per generator.

.. var:: gsl_rng_random_bsd
         gsl_rng_random_libc5
         gsl_rng_random_glibc2

   These generators implement the :code:`random` family of functions, a
   set of linear feedback shift register generators originally used in BSD
   Unix.  There are several versions of :code:`random` in use today: the
   original BSD version (e.g. on SunOS4), a libc5 version (found on
   older GNU/Linux systems) and a glibc2 version.  Each version uses a
   different seeding procedure, and thus produces different sequences.

   The original BSD routines accepted a variable length buffer for the
   generator state, with longer buffers providing higher-quality
   randomness.  The :code:`random` function implemented algorithms for
   buffer lengths of 8, 32, 64, 128 and 256 bytes, and the algorithm with
   the largest length that would fit into the user-supplied buffer was
   used.  To support these algorithms additional generators are available
   with the following names::

      gsl_rng_random8_bsd
      gsl_rng_random32_bsd
      gsl_rng_random64_bsd
      gsl_rng_random128_bsd
      gsl_rng_random256_bsd

   where the numeric suffix indicates the buffer length.  The original BSD
   :code:`random` function used a 128-byte default buffer and so
   :data:`gsl_rng_random_bsd` has been made equivalent to
   :data:`gsl_rng_random128_bsd`.  Corresponding versions of the :code:`libc5`
   and :code:`glibc2` generators are also available, with the names
   :data:`gsl_rng_random8_libc5`, :data:`gsl_rng_random8_glibc2`, etc.

.. index:: rand48 random number generator

.. var:: gsl_rng_rand48

   This is the Unix :code:`rand48` generator.  Its sequence is

   .. math:: x_{n+1} = (a x_n + c) \mod m

   defined on 48-bit unsigned integers with 
   :math:`a = 25214903917`, 
   :math:`c = 11` and 
   :math:`m = 2^{48}`.
   The seed specifies the upper 32 bits of the initial value, :math:`x_1`,
   with the lower 16 bits set to :code:`0x330E`.  The function
   :func:`gsl_rng_get` returns the upper 32 bits from each term of the
   sequence.  This does not have a direct parallel in the original
   :code:`rand48` functions, but forcing the result to type :code:`long int`
   reproduces the output of :code:`mrand48`.  The function
   :func:`gsl_rng_uniform` uses the full 48 bits of internal state to return
   the double precision number :math:`x_n/m`, which is equivalent to the
   function :code:`drand48`.  Note that some versions of the GNU C Library
   contained a bug in :code:`mrand48` function which caused it to produce
   different results (only the lower 16-bits of the return value were set).

Other random number generators
==============================

The generators in this section are provided for compatibility with
existing libraries.  If you are converting an existing program to use GSL
then you can select these generators to check your new implementation
against the original one, using the same random number generator.  After
verifying that your new program reproduces the original results you can
then switch to a higher-quality generator.

Note that most of the generators in this section are based on single
linear congruence relations, which are the least sophisticated type of
generator.  In particular, linear congruences have poor properties when
used with a non-prime modulus, as several of these routines do (e.g.
with a power of two modulus, 
:math:`2^{31}` or
:math:`2^{32}`).
This leads to periodicity in the least significant bits of each number,
with only the higher bits having any randomness.  Thus if you want to
produce a random bitstream it is best to avoid using the least
significant bits.

.. index::
   single: RANF random number generator
   single: CRAY random number generator, RANF

.. var:: gsl_rng_ranf

   This is the CRAY random number generator :code:`RANF`.  Its sequence is

   .. math:: x_{n+1} = (a x_n) \mod m

   defined on 48-bit unsigned integers with :math:`a = 44485709377909` and
   :math:`m = 2^{48}`.
   The seed specifies the lower 32 bits of the initial value, 
   :math:`x_1`, with the lowest bit set to
   prevent the seed taking an even value.  The upper 16 bits of 
   :math:`x_1`
   are set to 0. A consequence of this procedure is that the pairs of seeds
   2 and 3, 4 and 5, etc.: produce the same sequences.

   The generator compatible with the CRAY MATHLIB routine RANF. It
   produces double precision floating point numbers which should be
   identical to those from the original RANF.

   There is a subtlety in the implementation of the seeding.  The initial
   state is reversed through one step, by multiplying by the modular
   inverse of :math:`a` mod :math:`m`.  This is done for compatibility with
   the original CRAY implementation.

   Note that you can only seed the generator with integers up to
   :math:`2^{32}`,
   while the original CRAY implementation uses
   non-portable wide integers which can cover all 
   :math:`2^{48}`
   states of the generator.

   The function :func:`gsl_rng_get` returns the upper 32 bits from each term
   of the sequence.  The function :func:`gsl_rng_uniform` uses the full 48
   bits to return the double precision number :math:`x_n/m`.

   The period of this generator is :math:`2^{46}`.

.. index:: RANMAR random number generator

.. var:: gsl_rng_ranmar

   This is the RANMAR lagged-fibonacci generator of Marsaglia, Zaman and
   Tsang.  It is a 24-bit generator, originally designed for
   single-precision IEEE floating point numbers.  It was included in the
   CERNLIB high-energy physics library.

.. index::
   single: shift-register random number generator
   single: R250 shift-register random number generator

.. var:: gsl_rng_r250

   This is the shift-register generator of Kirkpatrick and Stoll.  The
   sequence is based on the recurrence

   .. only:: not texinfo

      .. math:: x_n = x_{n-103} \oplus x_{n-250}

   .. only:: texinfo

      ::

         x_n = x_{n-103} ^^ x_{n-250}

   where 
   :math:`\oplus`
   denotes *exclusive-or*, defined on
   32-bit words.  The period of this generator is about :math:`2^{250}` and it
   uses 250 words of state per generator.

   For more information see,

   * S. Kirkpatrick and E. Stoll, "A very fast shift-register sequence random
     number generator", Journal of Computational Physics, 40, 517--526
     (1981)

.. index:: TT800 random number generator

.. var:: gsl_rng_tt800

   This is an earlier version of the twisted generalized feedback
   shift-register generator, and has been superseded by the development of
   MT19937.  However, it is still an acceptable generator in its own
   right.  It has a period of 
   :math:`2^{800}`
   and uses 33 words of storage per generator.

   For more information see,

   * Makoto Matsumoto and Yoshiharu Kurita, "Twisted GFSR Generators
     II", ACM Transactions on Modelling and Computer Simulation,
     Vol.: 4, No.: 3, 1994, pages 254--266.

.. The following generators are included only for historical reasons, so
.. that you can reproduce results from old programs which might have used
.. them.  These generators should not be used for real simulations since
.. they have poor statistical properties by modern standards.

.. index:: VAX random number generator

.. var:: gsl_rng_vax

   This is the VAX generator :code:`MTH$RANDOM`.  Its sequence is,

   .. math:: x_{n+1} = (a x_n + c) \mod m

   with 
   :math:`a = 69069`, :math:`c = 1` and 
   :math:`m = 2^{32}`.
   The seed specifies the initial value, 
   :math:`x_1`.  The
   period of this generator is 
   :math:`2^{32}`
   and it uses 1 word of storage per
   generator.

.. var:: gsl_rng_transputer

   This is the random number generator from the INMOS Transputer
   Development system.  Its sequence is,

   .. math:: x_{n+1} = (a x_n) \mod m

   with :math:`a = 1664525` and 
   :math:`m = 2^{32}`.
   The seed specifies the initial value, 
   :math:`x_1`.

.. index:: RANDU random number generator

.. var:: gsl_rng_randu

   This is the IBM :code:`RANDU` generator.  Its sequence is

   .. math:: x_{n+1} = (a x_n) \mod m

   with :math:`a = 65539` and 
   :math:`m = 2^{31}`. The
   seed specifies the initial value, 
   :math:`x_1`.  The period of this
   generator was only 
   :math:`2^{29}`.
   It has become a textbook example of a poor generator.

.. index:: RANMAR random number generator

.. var:: gsl_rng_minstd

   This is Park and Miller's "minimal standard" MINSTD generator, a
   simple linear congruence which takes care to avoid the major pitfalls of
   such algorithms.  Its sequence is,

   .. math:: x_{n+1} = (a x_n) \mod m

   with :math:`a = 16807` and 
   :math:`m = 2^{31} - 1 = 2147483647`.
   The seed specifies the initial value, 
   :math:`x_1`.  The period of this
   generator is about 
   :math:`2^{31}`.

   This generator was used in the IMSL Library (subroutine RNUN) and in
   MATLAB (the RAND function) in the past.  It is also sometimes known by
   the acronym "GGL" (I'm not sure what that stands for).

   For more information see,

   * Park and Miller, "Random Number Generators: Good ones are hard to find",
     Communications of the ACM, October 1988, Volume 31, No 10, pages
     1192--1201.

.. var:: gsl_rng_uni
         gsl_rng_uni32

   This is a reimplementation of the 16-bit SLATEC random number generator
   RUNIF. A generalization of the generator to 32 bits is provided by
   :data:`gsl_rng_uni32`.  The original source code is available from NETLIB.

.. var:: gsl_rng_slatec

   This is the SLATEC random number generator RAND. It is ancient.  The
   original source code is available from NETLIB.

.. var:: gsl_rng_zuf

   This is the ZUFALL lagged Fibonacci series generator of Peterson.  Its
   sequence is,

   .. only:: not texinfo

      .. math::

         t &= u_{n-273} + u_{n-607} \\
         u_n  &= t - \hbox{floor}(t)

   .. only:: texinfo

      ::

         t = u_{n-273} + u_{n-607}
         u_n  = t - floor(t)

   The original source code is available from NETLIB.  For more information
   see,

   * W. Petersen, "Lagged Fibonacci Random Number Generators for the NEC
     SX-3", International Journal of High Speed Computing (1994).

.. var:: gsl_rng_knuthran2

   This is a second-order multiple recursive generator described by Knuth
   in Seminumerical Algorithms, 3rd Ed., page 108.  Its sequence is,

   .. math:: x_n = (a_1 x_{n-1} + a_2 x_{n-2}) \mod m

   with 
   :math:`a_1 = 271828183`, 
   :math:`a_2 = 314159269`, 
   and 
   :math:`m = 2^{31}-1`.

.. var:: gsl_rng_knuthran2002
         gsl_rng_knuthran

   This is a second-order multiple recursive generator described by Knuth
   in Seminumerical Algorithms, 3rd Ed., Section 3.6.  Knuth
   provides its C code.  The updated routine :data:`gsl_rng_knuthran2002`
   is from the revised 9th printing and corrects some weaknesses in the
   earlier version, which is implemented as :data:`gsl_rng_knuthran`.

.. var:: gsl_rng_borosh13
         gsl_rng_fishman18
         gsl_rng_fishman20
         gsl_rng_lecuyer21
         gsl_rng_waterman14

   These multiplicative generators are taken from Knuth's
   Seminumerical Algorithms, 3rd Ed., pages 106--108. Their sequence
   is,

   .. math:: x_{n+1} = (a x_n) \mod m

   where the seed specifies the initial value,
   :math:`x_1`.
   The parameters :math:`a` and :math:`m` are as follows,
   Borosh-Niederreiter: 
   :math:`a = 1812433253`, :math:`m = 2^{32}`,
   Fishman18:
   :math:`a = 62089911`,
   :math:`m = 2^{31}-1`,
   Fishman20:
   :math:`a = 48271`,
   :math:`m = 2^{31}-1`,
   L'Ecuyer:
   :math:`a = 40692`,
   :math:`m = 2^{31}-249`,
   Waterman:
   :math:`a = 1566083941`,
   :math:`m = 2^{32}`.

.. var:: gsl_rng_fishman2x

   This is the L'Ecuyer--Fishman random number generator. It is taken from
   Knuth's Seminumerical Algorithms, 3rd Ed., page 108. Its sequence
   is,

   .. math:: z_{n+1} = (x_n - y_n) \mod m

   with :math:`m = 2^{31}-1`.
   :math:`x_n` and :math:`y_n` are given by the :code:`fishman20` 
   and :code:`lecuyer21` algorithms.
   The seed specifies the initial value, 
   :math:`x_1`.

.. var:: gsl_rng_coveyou

   This is the Coveyou random number generator. It is taken from Knuth's
   Seminumerical Algorithms, 3rd Ed., Section 3.2.2. Its sequence
   is,

   .. math:: x_{n+1} = (x_n (x_n + 1)) \mod m

   with :math:`m = 2^{32}`.
   The seed specifies the initial value, 
   :math:`x_1`.

Performance
===========

.. I made the original plot like this
.. ./benchmark > tmp; cat tmp | perl -n -e '($n,$s) = split(" ",$_); printf("%17s ",$n); print "-" x ($s/1e5), "\n";'

.. The large number of generators based on single linear congruences are
.. represented by the :code:`random` generator below.  These generators are
.. fast but have the lowest statistical quality.

The following table shows the relative performance of a selection the
available random number generators.  The fastest simulation quality
generators are :code:`taus`, :code:`gfsr4` and :code:`mt19937`.  The
generators which offer the best mathematically-proven quality are those
based on the RANLUX algorithm::

  1754 k ints/sec,    870 k doubles/sec, taus
  1613 k ints/sec,    855 k doubles/sec, gfsr4
  1370 k ints/sec,    769 k doubles/sec, mt19937
   565 k ints/sec,    571 k doubles/sec, ranlxs0
   400 k ints/sec,    405 k doubles/sec, ranlxs1
   490 k ints/sec,    389 k doubles/sec, mrg
   407 k ints/sec,    297 k doubles/sec, ranlux
   243 k ints/sec,    254 k doubles/sec, ranlxd1
   251 k ints/sec,    253 k doubles/sec, ranlxs2
   238 k ints/sec,    215 k doubles/sec, cmrg
   247 k ints/sec,    198 k doubles/sec, ranlux389
   141 k ints/sec,    140 k doubles/sec, ranlxd2

Examples
========

The following program demonstrates the use of a random number generator
to produce uniform random numbers in the range [0.0, 1.0),

.. include:: examples/rngunif.c
   :code:

Here is the output of the program,

.. include:: examples/rngunif.txt
   :code:

The numbers depend on the seed used by the generator.  The default seed
can be changed with the :macro:`GSL_RNG_SEED` environment variable to
produce a different stream of numbers.  The generator itself can be
changed using the environment variable :macro:`GSL_RNG_TYPE`.  Here is the
output of the program using a seed value of 123 and the
multiple-recursive generator :code:`mrg`::

  $ GSL_RNG_SEED=123 GSL_RNG_TYPE=mrg ./a.out 

.. include:: examples/rngunif2.txt
   :code:

References and Further Reading
==============================

The subject of random number generation and testing is reviewed
extensively in Knuth's *Seminumerical Algorithms*.

* Donald E. Knuth, The Art of Computer Programming: Seminumerical
  Algorithms (Vol 2, 3rd Ed, 1997), Addison-Wesley, ISBN 0201896842.

Further information is available in the review paper written by Pierre
L'Ecuyer,

* P. L'Ecuyer, "Random Number Generation", Chapter 4 of the
  Handbook on Simulation, Jerry Banks Ed., Wiley, 1998, 93--137.

* http://www.iro.umontreal.ca/~lecuyer/papers.html in the file :file:`handsim.ps`.

The source code for the DIEHARD random number generator tests is also
available online,

* DIEHARD source code, G. Marsaglia, http://stat.fsu.edu/pub/diehard/

A comprehensive set of random number generator tests is available from
NIST,

* NIST Special Publication 800-22, "A Statistical Test Suite for the
  Validation of Random Number Generators and Pseudo Random Number
  Generators for Cryptographic Applications".

* http://csrc.nist.gov/rng/

Acknowledgements
================

Thanks to Makoto Matsumoto, Takuji Nishimura and Yoshiharu Kurita for
making the source code to their generators (MT19937, MM&TN; TT800,
MM&YK) available under the GNU General Public License.  Thanks to Martin
Luscher for providing notes and source code for the RANLXS and
RANLXD generators.

.. lcg
.. [ LCG(n) := n * 69069 mod (2^32) ]
.. First 6: [69069, 475559465, 2801775573, 1790562961, 3104832285, 4238970681]
.. %2^31-1   69069, 475559465, 654291926, 1790562961, 957348638, 2091487034
.. mrg
.. [q([x1, x2, x3, x4, x5]) := [107374182 mod 2147483647 * x1 + 104480 mod 2147483647 * x5, x1, x2, x3, x4]]
..
.. cmrg
.. [q1([x1,x2,x3]) := [63308 mod 2147483647 * x2 -183326 mod 2147483647 * x3, x1, x2],
..  q2([x1,x2,x3]) := [86098 mod 2145483479 * x1 -539608 mod 2145483479 * x3, x1, x2] ]
..  initial for q1 is [69069, 475559465, 654291926]
..  initial for q2 is  [1790562961, 959348806, 2093487202]

.. tausworthe
..    [ b1(x) := rsh(xor(lsh(x, 13), x), 19),
..      q1(x) := xor(lsh(and(x, 4294967294), 12), b1(x)),
..      b2(x) := rsh(xor(lsh(x, 2), x), 25),
..      q2(x) := xor(lsh(and(x, 4294967288), 4), b2(x)),
..      b3(x) := rsh(xor(lsh(x, 3), x), 11),
..      q3(x) := xor(lsh(and(x, 4294967280), 17), b3(x)) ]
..      [s1, s2, s3] = [600098857, 1131373026, 1223067536] 
.. [2948905028, 441213979, 394017882]
.. Version 1: Konrad Griessinger (konradg(at)gmx.net), 12/2013

.. index::
   single: Hermite polynomials
   single: Hermite functions

.. :math:`He_n(x)`
.. @math{H_n(x)}
.. how can you get greek characters in the index in Texinfo?!?
.. @cindex @math{psi_n(x)}

The Hermite polynomials exist in two variants: the probabilists' version :math:`He_n(x)`
and the physicists'version :math:`H_n(x)`. The are defined by the derivatives

.. only:: not texinfo

   .. math::

      He_n(x) & = (-1)^n e^{x^2/2} \left({d \over dx}\right)^n e^{-x^2/2} \\
      H_n(x) & = (-1)^n e^{x^2} \left({d \over dx}\right)^n e^{-x^2}

.. only:: texinfo

   ::

      He_n(x) = (-1)^n e^{x^2/2} (d / dx)^n e^{-x^2/2} 
      H_n(x) = (-1)^n e^{x^2} (d / dx)^n e^{-x^2} 

They are connected via 

.. only:: not texinfo

   .. math::

      He_n(x) & = 2^{-n/2} H_n \left( {x \over \sqrt{2}} \right) \\
      H_n(x) & = 2^{n/2} He_n \left( \sqrt{2} x \right)

.. only:: texinfo

   ::

      He_n(x) = 2^{-n/2} H_n(x / \sqrt{2})
      H_n(x) = 2^{n/2} He_n(\sqrt{2} x)

and satisfy the ordinary differential equations

.. only:: not texinfo

   .. math::

      He_n^{\prime\prime}(x) - x He_n^{\prime}(x) + n He_n(x) & = 0 \\
      H_n^{\prime\prime}(x) - 2x H_n^{\prime}(x) + 2n H_n(x) & = 0

.. only:: texinfo

   ::

      He_n^{''}(x) - x He_n^{'}(x) + n He_n(x) = 0
      H_n^{''}(x) - 2x H_n^{'}(x) + 2n H_n(x) = 0

The closely related Hermite functions are defined by 

.. only:: not texinfo

   .. math:: \psi_n(x) = \left( n! \sqrt{\pi} \right)^{-1/2} e^{-x^2/2} He_n \left( {\sqrt{2} x} \right)

.. only:: texinfo

   ::

      psi_n = (n! sqrt(\pi))^{-1/2} e^{-x^2/2} He_n({sqrt(2) x})

and satisfy the Schrödinger equation for a quantum mechanical harmonic oscillator

.. only:: not texinfo

   .. math:: \psi_n^{\prime\prime}(x) + (2n + 1 - x^2) \psi_n(x) = 0

.. only:: texinfo

   ::

      psi_n^{''}(x) + (2n + 1 - x^2) psi_n(x) = 0

Maybe most importantly, the Hermite functions :math:`\psi_n` are eigenfunctions of the (continuous) Fourier transform.

For further information see Abramowitz & Stegun, Chapter 22 and Szego, Gabor (1939, 1958, 1967), Orthogonal Polynomials,
American Mathematical Society. The Hermite polynomials and functions are defined in the header file :file:`gsl_sf_hermite.h`.

Hermite Polynomials
-------------------

.. function:: double gsl_sf_hermite_prob (const int n, const double x)
              int gsl_sf_hermite_prob_e (const int n, const double x, gsl_sf_result * result)

   These routines evaluate the probabilists' Hermite polynomial :math:`He_n(x)` of order :data:`n` at position :data:`x`.

.. function:: int gsl_sf_hermite_prob_array (const int nmax, const double x, double * result_array)

   This routine evaluates all probabilists' Hermite polynomials :math:`He_n(x)` up to order :data:`nmax` at position :data:`x`.
   The results are stored in :data:`result_array`.

.. function:: double gsl_sf_hermite_prob_series (const int n, const double x, const double * a)
              int gsl_sf_hermite_prob_series_e (const int n, const double x, const double * a, gsl_sf_result * result)

   These routines evaluate the series :math:`\sum_{j=0}^n a_j He_j(x)` with :math:`He_j` being the
   :math:`j`-th probabilists' Hermite polynomial using the Clenshaw algorithm.

.. function:: double gsl_sf_hermite_phys (const int n, const double x)
              int gsl_sf_hermite_phys_e (const int n, const double x, gsl_sf_result * result)

   These routines evaluate the physicists' Hermite polynomial :math:`H_n(x)` of order :data:`n` at position :data:`x`.

.. function:: int gsl_sf_hermite_phys_array (const int nmax, const double x, double * result_array)

   This routine evaluates all physicists' Hermite polynomials :math:`H_n` up to order :data:`nmax` at position :data:`x`.
   The results are stored in :data:`result_array`.

.. function:: double gsl_sf_hermite_phys_series (const int n, const double x, const double * a)
              int gsl_sf_hermite_phys_series_e (const int n, const double x, const double * a, gsl_sf_result * result)

   These routines evaluate the series :math:`\sum_{j=0}^n a_j H_j(x)` with :math:`H_j` being
   the :math:`j`-th physicists' Hermite polynomial using the Clenshaw algorithm.

Hermite Functions
-----------------

.. function:: double gsl_sf_hermite_func (const int n, const double x)
              int gsl_sf_hermite_func_e (const int n, const double x, gsl_sf_result * result)

   These routines evaluate the Hermite function :math:`\psi_n(x)` of order :data:`n` at position :data:`x`.

.. function:: int gsl_sf_hermite_func_array (const int nmax, const double x, double * result_array)

   This routine evaluates all Hermite functions :math:`\psi_n(x)` up to order :data:`nmax` at position :data:`x`.
   The results are stored in :data:`result_array`.

.. function:: double gsl_sf_hermite_func_series (const int n, const double x, const double * a)
              int gsl_sf_hermite_func_series_e (const int n, const double x, const double * a, gsl_sf_result * result)

   These routines evaluate the series :math:`\sum_{j=0}^n a_j \psi_j(x)` with :math:`\psi_j` being
   the :math:`j`-th Hermite function using the Clenshaw algorithm.

Derivatives of Hermite Polynomials
----------------------------------
.. index::
   single: Hermite polynomials, derivatives

.. function:: double gsl_sf_hermite_prob_der (const int m, const  int n, const double x)
              int gsl_sf_hermite_prob_der_e (const int m, const  int n, const double x, gsl_sf_result * result)

   These routines evaluate the :data:`m`-th derivative of the probabilists' Hermite polynomial :math:`He_n(x)`
   of order :data:`n` at position :data:`x`.

.. function:: int gsl_sf_hermite_prob_array_der (const int m, const int nmax, const double x, double * result_array)

   This routine evaluates the :data:`m`-th derivative of all probabilists' Hermite polynomials :math:`He_n(x)` up to
   order :data:`nmax` at position :data:`x`. The results are stored in :data:`result_array`.

.. function:: int gsl_sf_hermite_prob_der_array (const int mmax, const int n, const double x, double * result_array)

   This routine evaluates all derivatives (starting from 0) up to the :data:`mmax`-th derivative of the probabilists' Hermite
   polynomial of order :data:`n` :math:`He_n(x)` at position :data:`x`. The results are stored in :data:`result_array`.

.. function:: double gsl_sf_hermite_phys_der (const int m, const int n, const double x)
              int gsl_sf_hermite_phys_der_e (const int m, const int n, const double x, gsl_sf_result * result)

   These routines evaluate the :data:`m`-th derivative of the physicists' Hermite polynomial :math:`H_n(x)` of order :data:`n` at position :data:`x`.

.. function::  int gsl_sf_hermite_phys_array_der (const int m, const int nmax, const double x, double * result_array)

   This routine evaluates the :data:`m`-th derivative of all physicists' Hermite polynomials :math:`H_n` up to order :data:`nmax` at position :data:`x`.
   The results are stored in :data:`result_array`.

.. function:: int gsl_sf_hermite_phys_der_array (const int mmax, const int n, const double x, double * result_array)

   This routine evaluates all derivatives (starting from 0) up to the :data:`mmax`-th derivative of the
   physicists' Hermite polynomial of order :data:`n` :math:`H_n` at position :data:`x`. The results are stored in :data:`result_array`.

Derivatives of Hermite Functions
--------------------------------
.. index::
   single: Hermite functions, derivatives

.. function:: double gsl_sf_hermite_func_der (const int m, const int n, const double x)
              int gsl_sf_hermite_func_der_e (const int m, const int n, const double x, gsl_sf_result * result)

   These routines evaluate the :data:`m`-th derivative of the Hermite function :math:`\psi_n(x)` of order :data:`n` at position :data:`x`.

Zeros of Hermite Polynomials and Hermite Functions
--------------------------------------------------
.. index::
   single: Hermite polynomials, zeros
   single: Hermite functions, zeros

These routines calculate the :math:`s`-th zero of the Hermite Polynomial/Function of order
:math:`n`. Since the zeros are symmetrical around zero, only positive zeros are calculated,
ordered from smallest to largest, starting from index 1. Only for odd polynomial orders a
zeroth zero exists, its value always being zero.

.. function:: double gsl_sf_hermite_prob_zero (const int n, const int s)
              int gsl_sf_hermite_prob_zero_e (const int n, const int s, gsl_sf_result * result)

   These routines evaluate the :data:`s`-th zero of the probabilists' Hermite polynomial :math:`He_n(x)` of order :data:`n`.

.. function:: double gsl_sf_hermite_phys_zero (const int n, const int s)
              int gsl_sf_hermite_phys_zero_e (const int n, const int s, gsl_sf_result * result)

   These routines evaluate the :data:`s`-th zero of the physicists' Hermite polynomial :math:`H_n(x)` of order :data:`n`.

.. function:: double gsl_sf_hermite_func_zero (const int n, const int s)
              int gsl_sf_hermite_func_zero_e (const int n, const int s, gsl_sf_result * result)

   These routines evaluate the :data:`s`-th zero of the Hermite function :math:`\psi_n(x)` of order :data:`n`.
.. index::
   single: sparse linear algebra
   single: linear algebra, sparse

*********************
Sparse Linear Algebra
*********************

This chapter describes functions for solving sparse linear systems
of equations. The library provides linear algebra routines which
operate directly on the :type:`gsl_spmatrix` and :type:`gsl_vector`
objects.

The functions described in this chapter are declared in the header file
:file:`gsl_splinalg.h`.

.. index::
   single: sparse linear algebra, overview

Overview
========

This chapter is primarily concerned with the solution of the
linear system

.. math:: A x = b

where :math:`A` is a general square :math:`n`-by-:math:`n` non-singular
sparse matrix, :math:`x` is an unknown :math:`n`-by-:math:`1` vector, and
:math:`b` is a given :math:`n`-by-1 right hand side vector. There exist
many methods for solving such sparse linear systems, which broadly
fall into either direct or iterative categories. Direct methods include
LU and QR decompositions, while iterative methods start with an
initial guess for the vector :math:`x` and update the guess through
iteration until convergence. GSL does not currently provide any
direct sparse solvers.

.. index::
   single: sparse matrices, iterative solvers
   single: sparse linear algebra, iterative solvers
   single: sparse, iterative solvers

Sparse Iterative Solvers
========================

Overview
--------

Many practical iterative methods of solving large :math:`n`-by-:math:`n`
sparse linear systems involve projecting an approximate solution for
:data:`x` onto a subspace of :math:`{\bf R}^n`. If we define a :math:`m`-dimensional
subspace :math:`{\cal K}` as the subspace of approximations to the solution
:data:`x`, then :math:`m` constraints must be imposed to determine
the next approximation. These :math:`m` constraints define another
:math:`m`-dimensional subspace denoted by :math:`{\cal L}`. The
subspace dimension :math:`m` is typically chosen to be much smaller than
:math:`n` in order to reduce the computational
effort needed to generate the next approximate solution vector.
The many iterative algorithms which exist differ mainly
in their choice of :math:`{\cal K}` and :math:`{\cal L}`.

Types of Sparse Iterative Solvers
---------------------------------

The sparse linear algebra library provides the following types
of iterative solvers:

.. type:: gsl_splinalg_itersolve_type

   .. index:: gmres

   .. var:: gsl_splinalg_itersolve_gmres

      This specifies the Generalized Minimum Residual Method (GMRES).
      This is a projection method using :math:`{\cal K} = {\cal K}_m`
      and :math:`{\cal L} = A {\cal K}_m` where :math:`{\cal K}_m` is
      the :math:`m`-th Krylov subspace

      .. only:: not texinfo

         .. math:: {\cal K}_m = span \left\{ r_0, A r_0, ..., A^{m-1} r_0 \right\}

      .. only:: texinfo

         ::

            K_m = span( r_0, A r_0, ..., A^(m-1) r_0)

      and :math:`r_0 = b - A x_0` is the residual vector of the initial guess
      :math:`x_0`. If :math:`m` is set equal to :math:`n`, then the Krylov
      subspace is :math:`{\bf R}^n` and GMRES will provide the exact solution
      :data:`x`.  However, the goal is for the method to arrive at a very good
      approximation to :data:`x` using a much smaller subspace :math:`{\cal K}_m`. By
      default, the GMRES method selects :math:`m = MIN(n,10)` but the user
      may specify a different value for :math:`m`. The GMRES storage
      requirements grow as :math:`O(n(m+1))` and the number of flops
      grow as :math:`O(4 m^2 n - 4 m^3 / 3)`.

      In the below function :func:`gsl_splinalg_itersolve_iterate`, one
      GMRES iteration is defined as projecting the approximate solution
      vector onto each Krylov subspace :math:`{\cal K}_1, ..., {\cal K}_m`,
      and so :math:`m` can be kept smaller by "restarting" the method
      and calling :func:`gsl_splinalg_itersolve_iterate` multiple times,
      providing the updated approximation :data:`x` to each new call. If
      the method is not adequately converging, the user may try increasing
      the parameter :math:`m`.

      GMRES is considered a robust general purpose iterative solver, however
      there are cases where the method stagnates if the matrix is not
      positive-definite and fails to reduce the residual until the very last
      projection onto the subspace :math:`{\cal K}_n = {\bf R}^n`. In these
      cases, preconditioning the linear system can help, but GSL does not
      currently provide any preconditioners.

Iterating the Sparse Linear System
----------------------------------

The following functions are provided to allocate storage for the
sparse linear solvers and iterate the system to a solution.

.. function:: gsl_splinalg_itersolve * gsl_splinalg_itersolve_alloc (const gsl_splinalg_itersolve_type * T, const size_t n, const size_t m)

   This function allocates a workspace for the iterative solution of
   :data:`n`-by-:data:`n` sparse matrix systems. The iterative solver type
   is specified by :data:`T`. The argument :data:`m` specifies the size
   of the solution candidate subspace :math:`{\cal K}_m`. The dimension
   :data:`m` may be set to 0 in which case a reasonable default value is used.

.. function:: void gsl_splinalg_itersolve_free (gsl_splinalg_itersolve * w)

   This function frees the memory associated with the workspace :data:`w`.

.. function:: const char * gsl_splinalg_itersolve_name (const gsl_splinalg_itersolve * w)

   This function returns a string pointer to the name of the solver.

.. function:: int gsl_splinalg_itersolve_iterate (const gsl_spmatrix * A, const gsl_vector * b, const double tol, gsl_vector * x, gsl_splinalg_itersolve * w)

   This function performs one iteration of the iterative method for
   the sparse linear system specfied by the matrix :data:`A`, right hand
   side vector :data:`b` and solution vector :data:`x`. On input, :data:`x`
   must be set to an initial guess for the solution. On output,
   :data:`x` is updated to give the current solution estimate. The
   parameter :data:`tol` specifies the relative tolerance between the residual
   norm and norm of :data:`b` in order to check for convergence.
   When the following condition is satisfied:

   .. only:: not texinfo

      .. math:: || A x - b || \le tol \times || b ||

   .. only:: texinfo

      ::

         || A x - b || <= tol * || b ||

   the method has converged, the function returns :macro:`GSL_SUCCESS` and
   the final solution is provided in :data:`x`. Otherwise, the function
   returns :macro:`GSL_CONTINUE` to signal that more iterations are
   required. Here, :math:`|| \cdot ||` represents the Euclidean norm.
   The input matrix :data:`A` may be in triplet or compressed format.

.. function:: double gsl_splinalg_itersolve_normr (const gsl_splinalg_itersolve * w)

   This function returns the current residual norm
   :math:`||r|| = ||A x - b||`, which is updated after each call to
   :func:`gsl_splinalg_itersolve_iterate`.

.. index::
   single: sparse linear algebra, examples

Examples
========

This example program demonstrates the sparse linear algebra routines on
the solution of a simple 1D Poisson equation on :math:`[0,1]`:

.. only:: not texinfo

   .. math:: {d^2 u(x) \over dx^2} = f(x) = -\pi^2 \sin{(\pi x)}

.. only:: texinfo

   ::

      u''(x) = f(x) = -\pi^2 \sin(\pi x)

with boundary conditions :math:`u(0) = u(1) = 0`. The analytic solution of
this simple problem is :math:`u(x) = \sin{\pi x}`. We will solve this
problem by finite differencing the left hand side to give

.. only:: not texinfo

   .. math:: {1 \over h^2} \left( u_{i+1} - 2 u_i + u_{i-1} \right) = f_i

.. only:: texinfo

   ::

      1/h^2 ( u_(i+1) - 2 u_i + u_(i-1) ) = f_i

Defining a grid of :math:`N` points, :math:`h = 1/(N-1)`. In the finite
difference equation above, :math:`u_0 = u_{N-1} = 0` are known from
the boundary conditions, so we will only put the equations for
:math:`i = 1, ..., N-2` into the matrix system. The resulting
:math:`(N-2) \times (N-2)` matrix equation is

.. only:: not texinfo

   .. math::

      {1 \over h^2}
      \left(
        \begin{array}{cccccc}
          -2 & 1 & 0 & 0 & \ldots & 0 \\
          1 & -2 & 1 & 0 & \ldots & 0 \\
          0 & 1 & -2 & 1 & \ldots & 0 \\
          \vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
          0 & \ldots & \ldots & 1 & -2 & 1 \\
          0 & \ldots & \ldots & \ldots & 1 & -2
        \end{array}
      \right)
      \left(
        \begin{array}{c}
          u_1 \\
          u_2 \\
          u_3 \\
          \vdots \\
          u_{N-3} \\
          u_{N-2}
        \end{array}
      \right) =
      \left(
        \begin{array}{c}
          f_1 \\
          f_2 \\
          f_3 \\
          \vdots \\
          f_{N-3} \\
          f_{N-2}
        \end{array}
      \right)

An example program which constructs and solves this system is given below.
The system is solved using the iterative GMRES solver. Here is
the output of the program::

  iter 0 residual = 4.297275996844e-11
  Converged

showing that the method converged in a single iteration.
The calculated solution is shown in :numref:`fig_splinalg-poisson`.

.. _fig_splinalg-poisson:

.. figure:: /images/sparse_poisson.png

   Solution of PDE

.. include:: examples/poisson.c
   :code:

.. index::
   single: sparse linear algebra, references

References and Further Reading
==============================

The implementation of the GMRES iterative solver closely follows
the publications

* H. F. Walker, Implementation of the GMRES method using
  Householder transformations, SIAM J. Sci. Stat. Comput.
  9(1), 1988.

* Y. Saad, Iterative methods for sparse linear systems, 2nd edition,
  SIAM, 2003.
.. index::
   single: histograms
   single: binning data

**********
Histograms
**********

This chapter describes functions for creating histograms.  Histograms
provide a convenient way of summarizing the distribution of a set of
data. A histogram consists of a set of *bins* which count the number
of events falling into a given range of a continuous variable :math:`x`.
In GSL the bins of a histogram contain floating-point numbers, so they
can be used to record both integer and non-integer distributions.  The
bins can use arbitrary sets of ranges (uniformly spaced bins are the
default).  Both one and two-dimensional histograms are supported.

Once a histogram has been created it can also be converted into a
probability distribution function.  The library provides efficient
routines for selecting random samples from probability distributions.
This can be useful for generating simulations based on real data.

The functions are declared in the header files :file:`gsl_histogram.h`
and :file:`gsl_histogram2d.h`.

The histogram struct
====================

A histogram is defined by the following struct,

.. type:: gsl_histogram

   ============================= ============================================================================
   size_t n                      This is the number of histogram bins
   double * range                The ranges of the bins are stored in an array of :code:`n+1` elements
                                 pointed to by range.
   double * bin                  The counts for each bin are stored in an array of :data:`n` elements
                                 pointed to by :data:`bin`.  The bins are floating-point numbers, so you can
                                 increment them by non-integer values if necessary.
   ============================= ============================================================================

   The range for :code:`bin[i]` is given by :code:`range[i]` to
   :code:`range[i+1]`.  For :math:`n` bins there are :code:`n+1` entries in the
   array :data:`range`.  Each bin is inclusive at the lower end and exclusive
   at the upper end.  Mathematically this means that the bins are defined by
   the following inequality,

   .. only:: not texinfo

      .. math:: \hbox{bin[i] corresponds to range[i]} \le x < \hbox{range[i+1]}

   .. only:: texinfo

      ::

         bin[i] corresponds to range[i] <= x < range[i+1]

   Here is a diagram of the correspondence between ranges and bins on the
   number-line for :math:`x`::

          [ bin[0] )[ bin[1] )[ bin[2] )[ bin[3] )[ bin[4] )
       ---|---------|---------|---------|---------|---------|---  x
        r[0]      r[1]      r[2]      r[3]      r[4]      r[5]

   In this picture the values of the :data:`range` array are denoted by
   :math:`r`.  On the left-hand side of each bin the square bracket
   :code:`[` denotes an inclusive lower bound 
   (:math:`r \le x`),
   and the round parentheses :code:`)` on the right-hand
   side denote an exclusive upper bound (:math:`x < r`).  Thus any samples
   which fall on the upper end of the histogram are excluded.  If you want
   to include this value for the last bin you will need to add an extra bin
   to your histogram.

   The :type:`gsl_histogram` struct and its associated functions are defined
   in the header file :file:`gsl_histogram.h`.

Histogram allocation
====================

The functions for allocating memory to a histogram follow the style of
:func:`malloc` and :func:`free`.  In addition they also perform their own
error checking.  If there is insufficient memory available to allocate a
histogram then the functions call the error handler (with an error
number of :macro:`GSL_ENOMEM`) in addition to returning a null pointer.
Thus if you use the library error handler to abort your program then it
isn't necessary to check every histogram :code:`alloc`.

.. function:: gsl_histogram * gsl_histogram_alloc (size_t n)

   This function allocates memory for a histogram with :data:`n` bins, and
   returns a pointer to a newly created :type:`gsl_histogram` struct.  If
   insufficient memory is available a null pointer is returned and the
   error handler is invoked with an error code of :macro:`GSL_ENOMEM`. The
   bins and ranges are not initialized, and should be prepared using one of
   the range-setting functions below in order to make the histogram ready
   for use.

.. @deftypefun {gsl_histogram *} gsl_histogram_calloc (size_t n)
.. This function allocates memory for a histogram with :data:`n` bins, and
.. returns a pointer to its newly initialized :type:`gsl_histogram` struct.
.. The bins are uniformly spaced with a total range of 
.. @c{$0 \le  x < n$}
.. @math{0 <=  x < n},
.. as shown in the table below.

.. @tex
.. \beforedisplay
.. $$
.. \matrix{
.. \hbox{bin[0]}&\hbox{corresponds to}& 0 \le x < 1\cr
.. \hbox{bin[1]}&\hbox{corresponds to}& 1 \le x < 2\cr
.. \dots&\dots&\dots\cr
.. \hbox{bin[n-1]}&\hbox{corresponds to}&n-1 \le x < n}
.. $$
.. \afterdisplay
.. @end tex
.. @ifinfo
.. @display
.. bin[0] corresponds to 0 <= x < 1
.. bin[1] corresponds to 1 <= x < 2
.. @dots{}
.. bin[n-1] corresponds to n-1 <= x < n
.. @end display
.. @end ifinfo
.. @noindent
.. The bins are initialized to zero so the histogram is ready for use.

.. If insufficient memory is available a null pointer is returned and the
.. error handler is invoked with an error code of :macro:`GSL_ENOMEM`.
.. @end deftypefun

.. @deftypefun {gsl_histogram *} gsl_histogram_calloc_uniform (size_t n, double xmin, double xmax)
.. This function allocates memory for a histogram with :data:`n` uniformly
.. spaced bins from :data:`xmin` to :data:`xmax`, and returns a pointer to the
.. newly initialized :type:`gsl_histogram` struct. 
.. If insufficient memory is available a null pointer is returned and the
.. error handler is invoked with an error code of :macro:`GSL_ENOMEM`.
.. @end deftypefun

.. @deftypefun {gsl_histogram *} gsl_histogram_calloc_range (size_t n, double * range)
.. This function allocates a histogram of size :data:`n` using the @math{n+1}
.. bin ranges specified by the array :data:`range`.
.. @end deftypefun

.. function:: int gsl_histogram_set_ranges (gsl_histogram * h, const double range[], size_t size)

   This function sets the ranges of the existing histogram :data:`h` using
   the array :data:`range` of size :data:`size`.  The values of the histogram
   bins are reset to zero.  The :data:`range` array should contain the
   desired bin limits.  The ranges can be arbitrary, subject to the
   restriction that they are monotonically increasing.

   The following example shows how to create a histogram with logarithmic
   bins with ranges [1,10), [10,100) and [100,1000)::

      gsl_histogram * h = gsl_histogram_alloc (3);

      /* bin[0] covers the range 1 <= x < 10 */
      /* bin[1] covers the range 10 <= x < 100 */
      /* bin[2] covers the range 100 <= x < 1000 */

      double range[4] = { 1.0, 10.0, 100.0, 1000.0 };

      gsl_histogram_set_ranges (h, range, 4);

   Note that the size of the :data:`range` array should be defined to be one
   element bigger than the number of bins.  The additional element is
   required for the upper value of the final bin.

.. function:: int gsl_histogram_set_ranges_uniform (gsl_histogram * h, double xmin, double xmax)

   This function sets the ranges of the existing histogram :data:`h` to cover
   the range :data:`xmin` to :data:`xmax` uniformly.  The values of the
   histogram bins are reset to zero.  The bin ranges are shown in the table
   below,

   .. only:: not texinfo

      .. math::

         \begin{array}{ccc}
           \hbox{bin[0]}&\hbox{corresponds to}& xmin \le  x < xmin + d \\
           \hbox{bin[1]} &\hbox{corresponds to}& xmin + d \le  x < xmin + 2 d \\
           \dots&\dots&\dots \\
           \hbox{bin[n-1]} & \hbox{corresponds to}& xmin + (n-1)d \le  x < xmax
         \end{array}

   .. only:: texinfo

      ::

         bin[0] corresponds to xmin <= x < xmin + d
         bin[1] corresponds to xmin + d <= x < xmin + 2 d
         ......
         bin[n-1] corresponds to xmin + (n-1)d <= x < xmax

   where :math:`d` is the bin spacing, :math:`d = (xmax-xmin)/n`.

.. function:: void gsl_histogram_free (gsl_histogram * h)

   This function frees the histogram :data:`h` and all of the memory
   associated with it.

Copying Histograms
==================

.. function:: int gsl_histogram_memcpy (gsl_histogram * dest, const gsl_histogram * src)

   This function copies the histogram :data:`src` into the pre-existing
   histogram :data:`dest`, making :data:`dest` into an exact copy of :data:`src`.
   The two histograms must be of the same size.

.. function:: gsl_histogram * gsl_histogram_clone (const gsl_histogram * src)

   This function returns a pointer to a newly created histogram which is an
   exact copy of the histogram :data:`src`.

Updating and accessing histogram elements
=========================================

There are two ways to access histogram bins, either by specifying an
:math:`x` coordinate or by using the bin-index directly.  The functions
for accessing the histogram through :math:`x` coordinates use a binary
search to identify the bin which covers the appropriate range.

.. function:: int gsl_histogram_increment (gsl_histogram * h, double x)

   This function updates the histogram :data:`h` by adding one (1.0) to the
   bin whose range contains the coordinate :data:`x`. 

   If :data:`x` lies in the valid range of the histogram then the function
   returns zero to indicate success.  If :data:`x` is less than the lower
   limit of the histogram then the function returns :macro:`GSL_EDOM`, and
   none of bins are modified.  Similarly, if the value of :data:`x` is greater
   than or equal to the upper limit of the histogram then the function
   returns :macro:`GSL_EDOM`, and none of the bins are modified.  The error
   handler is not called, however, since it is often necessary to compute
   histograms for a small range of a larger dataset, ignoring the values
   outside the range of interest.

.. function:: int gsl_histogram_accumulate (gsl_histogram * h, double x, double weight)

   This function is similar to :func:`gsl_histogram_increment` but increases
   the value of the appropriate bin in the histogram :data:`h` by the
   floating-point number :data:`weight`.

.. function:: double gsl_histogram_get (const gsl_histogram * h, size_t i)

   This function returns the contents of the :data:`i`-th bin of the histogram
   :data:`h`.  If :data:`i` lies outside the valid range of indices for the
   histogram then the error handler is called with an error code of
   :macro:`GSL_EDOM` and the function returns 0.

.. function:: int gsl_histogram_get_range (const gsl_histogram * h, size_t i, double * lower, double * upper)

   This function finds the upper and lower range limits of the :data:`i`-th
   bin of the histogram :data:`h`.  If the index :data:`i` is valid then the
   corresponding range limits are stored in :data:`lower` and :data:`upper`.
   The lower limit is inclusive (i.e. events with this coordinate are
   included in the bin) and the upper limit is exclusive (i.e. events with
   the coordinate of the upper limit are excluded and fall in the
   neighboring higher bin, if it exists).  The function returns 0 to
   indicate success.  If :data:`i` lies outside the valid range of indices for
   the histogram then the error handler is called and the function returns
   an error code of :macro:`GSL_EDOM`.

.. function:: double gsl_histogram_max (const gsl_histogram * h)
              double gsl_histogram_min (const gsl_histogram * h)
              size_t gsl_histogram_bins (const gsl_histogram * h)

   These functions return the maximum upper and minimum lower range limits
   and the number of bins of the histogram :data:`h`.  They provide a way of
   determining these values without accessing the :type:`gsl_histogram`
   struct directly.

.. function:: void gsl_histogram_reset (gsl_histogram * h)

   This function resets all the bins in the histogram :data:`h` to zero.

Searching histogram ranges
==========================

The following functions are used by the access and update routines to
locate the bin which corresponds to a given :math:`x` coordinate.

.. function:: int gsl_histogram_find (const gsl_histogram * h, double x, size_t * i)

   This function finds and sets the index :data:`i` to the bin number which
   covers the coordinate :data:`x` in the histogram :data:`h`.  The bin is
   located using a binary search. The search includes an optimization for
   histograms with uniform range, and will return the correct bin
   immediately in this case.  If :data:`x` is found in the range of the
   histogram then the function sets the index :data:`i` and returns
   :macro:`GSL_SUCCESS`.  If :data:`x` lies outside the valid range of the
   histogram then the function returns :macro:`GSL_EDOM` and the error
   handler is invoked.

.. index::
   single: histogram statistics
   single: statistics, from histogram
   single: maximum value, from histogram
   single: minimum value, from histogram

Histogram Statistics
====================

.. function:: double gsl_histogram_max_val (const gsl_histogram * h)

   This function returns the maximum value contained in the histogram bins.

.. function:: size_t gsl_histogram_max_bin (const gsl_histogram * h)

   This function returns the index of the bin containing the maximum
   value. In the case where several bins contain the same maximum value the
   smallest index is returned.

.. function:: double gsl_histogram_min_val (const gsl_histogram * h)

   This function returns the minimum value contained in the histogram bins.

.. function:: size_t gsl_histogram_min_bin (const gsl_histogram * h)

   This function returns the index of the bin containing the minimum
   value. In the case where several bins contain the same maximum value the
   smallest index is returned.

.. index::
   single: mean value, from histogram

.. function:: double gsl_histogram_mean (const gsl_histogram * h)

   This function returns the mean of the histogrammed variable, where the
   histogram is regarded as a probability distribution. Negative bin values
   are ignored for the purposes of this calculation.  The accuracy of the
   result is limited by the bin width.

.. index::
   single: standard deviation, from histogram
   single: variance, from histogram

.. function:: double gsl_histogram_sigma (const gsl_histogram * h)

   This function returns the standard deviation of the histogrammed
   variable, where the histogram is regarded as a probability
   distribution. Negative bin values are ignored for the purposes of this
   calculation. The accuracy of the result is limited by the bin width.

.. function:: double gsl_histogram_sum (const gsl_histogram * h)

   This function returns the sum of all bin values. Negative bin values
   are included in the sum.

Histogram Operations
====================

.. function:: int gsl_histogram_equal_bins_p (const gsl_histogram * h1, const gsl_histogram * h2)

   This function returns 1 if the all of the individual bin
   ranges of the two histograms are identical, and 0
   otherwise.

.. function:: int gsl_histogram_add (gsl_histogram * h1, const gsl_histogram * h2)

   This function adds the contents of the bins in histogram :data:`h2` to the
   corresponding bins of histogram :data:`h1`,  i.e. :math:`h'_1(i) = h_1(i) + h_2(i)`.
   The two histograms must have identical bin ranges.

.. function:: int gsl_histogram_sub (gsl_histogram * h1, const gsl_histogram * h2)

   This function subtracts the contents of the bins in histogram :data:`h2`
   from the corresponding bins of histogram :data:`h1`, i.e. :math:`h'_1(i) = h_1(i) - h_2(i)`.
   The two histograms must have identical bin ranges.

.. function:: int gsl_histogram_mul (gsl_histogram * h1, const gsl_histogram * h2)

   This function multiplies the contents of the bins of histogram :data:`h1`
   by the contents of the corresponding bins in histogram :data:`h2`,
   i.e. :math:`h'_1(i) = h_1(i) * h_2(i)`.  The two histograms must have
   identical bin ranges.

.. function:: int gsl_histogram_div (gsl_histogram * h1, const gsl_histogram * h2)

   This function divides the contents of the bins of histogram :data:`h1` by
   the contents of the corresponding bins in histogram :data:`h2`,
   i.e. :math:`h'_1(i) = h_1(i) / h_2(i)`.  The two histograms must have
   identical bin ranges.

.. function:: int gsl_histogram_scale (gsl_histogram * h, double scale)

   This function multiplies the contents of the bins of histogram :data:`h`
   by the constant :data:`scale`, i.e.
   
   .. only:: not texinfo
   
      .. math:: h'_1(i) = h_1(i) * \hbox{\it scale}

   .. only:: texinfo

      ::

         h'_1(i) = h_1(i) * scale

.. function:: int gsl_histogram_shift (gsl_histogram * h, double offset)

   This function shifts the contents of the bins of histogram :data:`h` by
   the constant :data:`offset`, i.e.
   
   .. only:: not texinfo
   
      .. math:: h'_1(i) = h_1(i) + \hbox{\it offset}

   .. only:: texinfo

      ::

         h'_1(i) = h_1(i) + offset

Reading and writing histograms
==============================

The library provides functions for reading and writing histograms to a file
as binary data or formatted text.

.. function:: int gsl_histogram_fwrite (FILE * stream, const gsl_histogram * h)

   This function writes the ranges and bins of the histogram :data:`h` to the
   stream :data:`stream` in binary format.  The return value is 0 for success
   and :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since
   the data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_histogram_fread (FILE * stream, gsl_histogram * h)

   This function reads into the histogram :data:`h` from the open stream
   :data:`stream` in binary format.  The histogram :data:`h` must be
   preallocated with the correct size since the function uses the number of
   bins in :data:`h` to determine how many bytes to read.  The return value is
   0 for success and :macro:`GSL_EFAILED` if there was a problem reading from
   the file.  The data is assumed to have been written in the native binary
   format on the same architecture.

.. function:: int gsl_histogram_fprintf (FILE * stream, const gsl_histogram * h, const char * range_format, const char * bin_format)

   This function writes the ranges and bins of the histogram :data:`h`
   line-by-line to the stream :data:`stream` using the format specifiers
   :data:`range_format` and :data:`bin_format`.  These should be one of the
   :code:`%g`, :code:`%e` or :code:`%f` formats for floating point
   numbers.  The function returns 0 for success and :macro:`GSL_EFAILED` if
   there was a problem writing to the file.  The histogram output is
   formatted in three columns, and the columns are separated by spaces,
   like this::

      range[0] range[1] bin[0]
      range[1] range[2] bin[1]
      range[2] range[3] bin[2]
      ....
      range[n-1] range[n] bin[n-1]

   The values of the ranges are formatted using :data:`range_format` and the
   value of the bins are formatted using :data:`bin_format`.  Each line
   contains the lower and upper limit of the range of the bins and the
   value of the bin itself.  Since the upper limit of one bin is the lower
   limit of the next there is duplication of these values between lines but
   this allows the histogram to be manipulated with line-oriented tools.

.. function:: int gsl_histogram_fscanf (FILE * stream, gsl_histogram * h)

   This function reads formatted data from the stream :data:`stream` into the
   histogram :data:`h`.  The data is assumed to be in the three-column format
   used by :func:`gsl_histogram_fprintf`.  The histogram :data:`h` must be
   preallocated with the correct length since the function uses the size of
   :data:`h` to determine how many numbers to read.  The function returns 0
   for success and :macro:`GSL_EFAILED` if there was a problem reading from
   the file.

.. index::
   single: resampling from histograms
   single: sampling from histograms
   single: probability distributions, from histograms

Resampling from histograms
==========================

A histogram made by counting events can be regarded as a measurement of
a probability distribution.  Allowing for statistical error, the height
of each bin represents the probability of an event where the value of
:math:`x` falls in the range of that bin.  The probability distribution
function has the one-dimensional form :math:`p(x)dx` where,

.. math:: p(x) = n_i / (N w_i)

In this equation :math:`n_i` is the number of events in the bin which
contains :math:`x`, :math:`w_i` is the width of the bin and :math:`N` is
the total number of events.  The distribution of events within each bin
is assumed to be uniform.

.. index::
   single: probability distribution, from histogram
   single: sampling from histograms
   single: random sampling from histograms
   single: histograms, random sampling from

The histogram probability distribution struct
=============================================

The probability distribution function for a histogram consists of a set
of *bins* which measure the probability of an event falling into a
given range of a continuous variable :math:`x`. A probability
distribution function is defined by the following struct, which actually
stores the cumulative probability distribution function.  This is the
natural quantity for generating samples via the inverse transform
method, because there is a one-to-one mapping between the cumulative
probability distribution and the range [0,1].  It can be shown that by
taking a uniform random number in this range and finding its
corresponding coordinate in the cumulative probability distribution we
obtain samples with the desired probability distribution.

.. type:: gsl_histogram_pdf

   ================================ =======================================================================
   :code:`size_t n`                 This is the number of bins used to approximate the probability
                                    distribution function. 
   :code:`double * range`           The ranges of the bins are stored in an array of :math:`n + 1`
                                    elements pointed to by :data:`range`.
   :code:`double * sum`             The cumulative probability for the bins is stored in an array of
                                    :data:`n` elements pointed to by :data:`sum`.
   ================================ =======================================================================

The following functions allow you to create a :type:`gsl_histogram_pdf`
struct which represents this probability distribution and generate
random samples from it.

.. function:: gsl_histogram_pdf * gsl_histogram_pdf_alloc (size_t n)

   This function allocates memory for a probability distribution with
   :data:`n` bins and returns a pointer to a newly initialized
   :type:`gsl_histogram_pdf` struct. If insufficient memory is available a
   null pointer is returned and the error handler is invoked with an error
   code of :macro:`GSL_ENOMEM`.

.. function:: int gsl_histogram_pdf_init (gsl_histogram_pdf * p, const gsl_histogram * h)

   This function initializes the probability distribution :data:`p` with
   the contents of the histogram :data:`h`. If any of the bins of :data:`h` are
   negative then the error handler is invoked with an error code of
   :macro:`GSL_EDOM` because a probability distribution cannot contain
   negative values.

.. function:: void gsl_histogram_pdf_free (gsl_histogram_pdf * p)

   This function frees the probability distribution function :data:`p` and
   all of the memory associated with it.

.. function:: double gsl_histogram_pdf_sample (const gsl_histogram_pdf * p, double r)

   This function uses :data:`r`, a uniform random number between zero and
   one, to compute a single random sample from the probability distribution
   :data:`p`.  The algorithm used to compute the sample :math:`s` is given by
   the following formula,

   .. only:: not texinfo

      .. math:: s = \hbox{range}[i] + \delta * (\hbox{range}[i+1] - \hbox{range}[i])

   .. only:: texinfo

      ::

         s = range[i] + delta * (range[i+1] - range[i])

   where :math:`i` is the index which satisfies 
   :math:`sum[i] \le  r < sum[i+1]`
   and :math:`delta` is 
   :math:`(r - sum[i])/(sum[i+1] - sum[i])`.

Example programs for histograms
===============================

The following program shows how to make a simple histogram of a column
of numerical data supplied on :code:`stdin`.  The program takes three
arguments, specifying the upper and lower bounds of the histogram and
the number of bins.  It then reads numbers from :code:`stdin`, one line at
a time, and adds them to the histogram.  When there is no more data to
read it prints out the accumulated histogram using
:func:`gsl_histogram_fprintf`.

.. include:: examples/histogram.c
   :code:

Here is an example of the program in use.  We generate 10000 random
samples from a Cauchy distribution with a width of 30 and histogram
them over the range -100 to 100, using 200 bins::

  $ gsl-randist 0 10000 cauchy 30 
     | gsl-histogram -- -100 100 200 > histogram.dat

:numref:`fig_histogram` shows the familiar shape of the
Cauchy distribution and the fluctuations caused by the finite sample
size.

.. _fig_histogram:

.. figure:: /images/histogram.png
   :scale: 60%

   Histogram output from example program

.. index::
   single: two dimensional histograms
   single: 2D histograms

Two dimensional histograms
==========================

A two dimensional histogram consists of a set of *bins* which count
the number of events falling in a given area of the :math:`(x,y)`
plane.  The simplest way to use a two dimensional histogram is to record
two-dimensional position information, :math:`n(x,y)`.  Another possibility
is to form a *joint distribution* by recording related
variables.  For example a detector might record both the position of an
event (:math:`x`) and the amount of energy it deposited :math:`E`.  These
could be histogrammed as the joint distribution :math:`n(x,E)`.

The 2D histogram struct
=======================

Two dimensional histograms are defined by the following struct,

.. type:: gsl_histogram2d

   =========================== ============================================================================
   :code:`size_t nx, ny`       This is the number of histogram bins in the x and y directions.
   :code:`double * xrange`     The ranges of the bins in the x-direction are stored in an array of
                               :code:`nx + 1` elements pointed to by :data:`xrange`.
   :code:`double * yrange`     The ranges of the bins in the y-direction are stored in an array of
                               :code:`ny + 1` elements pointed to by :data:`yrange`.
   :code:`double * bin`        The counts for each bin are stored in an array pointed to by :data:`bin`.
                               The bins are floating-point numbers, so you can increment them by
                               non-integer values if necessary.  The array :data:`bin` stores the two
                               dimensional array of bins in a single block of memory according to the
                               mapping :code:`bin(i,j)` = :code:`bin[i * ny + j]`.
   =========================== ============================================================================

The range for :code:`bin(i,j)` is given by :code:`xrange[i]` to
:code:`xrange[i+1]` in the x-direction and :code:`yrange[j]` to
:code:`yrange[j+1]` in the y-direction.  Each bin is inclusive at the lower
end and exclusive at the upper end.  Mathematically this means that the
bins are defined by the following inequality,

.. only:: not texinfo

   .. math::

      \begin{array}{cc}
        \hbox{bin(i,j) corresponds to} & \hbox{\it xrange}[i] \le x < \hbox{\it xrange}[i+1] \\
        \hbox{and} & \hbox{\it yrange}[j] \le y < \hbox{\it yrange}[j+1]
      \end{array}

.. only:: texinfo

   ::

      bin(i,j) corresponds to xrange[i] <= x < xrange[i+1]
                          and yrange[j] <= y < yrange[j+1]

Note that any samples which fall on the upper sides of the histogram are
excluded.  If you want to include these values for the side bins you will
need to add an extra row or column to your histogram.

The :type:`gsl_histogram2d` struct and its associated functions are
defined in the header file :file:`gsl_histogram2d.h`.

2D Histogram allocation
=======================

The functions for allocating memory to a 2D histogram follow the style
of :func:`malloc` and :func:`free`.  In addition they also perform their
own error checking.  If there is insufficient memory available to
allocate a histogram then the functions call the error handler (with
an error number of :macro:`GSL_ENOMEM`) in addition to returning a null
pointer.  Thus if you use the library error handler to abort your program
then it isn't necessary to check every 2D histogram :code:`alloc`.

.. function:: gsl_histogram2d * gsl_histogram2d_alloc (size_t nx, size_t ny)

   This function allocates memory for a two-dimensional histogram with
   :data:`nx` bins in the x direction and :data:`ny` bins in the y direction.
   The function returns a pointer to a newly created :type:`gsl_histogram2d`
   struct. If insufficient memory is available a null pointer is returned
   and the error handler is invoked with an error code of
   :macro:`GSL_ENOMEM`. The bins and ranges must be initialized with one of
   the functions below before the histogram is ready for use.

.. @deftypefun {gsl_histogram2d *} gsl_histogram2d_calloc (size_t nx, size_t ny)
.. This function allocates memory for a two-dimensional histogram with
.. :data:`nx` bins in the x direction and :data:`ny` bins in the y
.. direction.  The function returns a pointer to a newly initialized
.. :type:`gsl_histogram2d` struct.  The bins are uniformly spaced with a
.. total range of 
.. @c{$0 \le  x < nx$}
.. @math{0 <= x < nx} in the x-direction and 
.. @c{$0 \le  y < ny$} 
.. @math{0 <=  y < ny} in the y-direction, as shown in the table below.
.. 
.. The bins are initialized to zero so the histogram is ready for use.
.. 
.. If insufficient memory is available a null pointer is returned and the
.. error handler is invoked with an error code of :macro:`GSL_ENOMEM`.
.. @end deftypefun
.. 
.. @deftypefun {gsl_histogram2d *} gsl_histogram2d_calloc_uniform (size_t nx, size_t ny, double xmin, double xmax, double ymin, double ymax)
.. This function allocates a histogram of size :data:`nx`-by-:data:`ny` which
.. uniformly covers the ranges :data:`xmin` to :data:`xmax` and :data:`ymin` to
.. :data:`ymax` in the :math:`x` and :math:`y` directions respectively.
.. @end deftypefun
.. 
.. @deftypefun {gsl_histogram2d *} gsl_histogram2d_calloc_range (size_t nx, size_t ny, double * xrange, double * yrange)
.. This function allocates a histogram of size :data:`nx`-by-:data:`ny` using
.. the @math{nx+1} and @math{ny+1} bin ranges specified by the arrays
.. :data:`xrange` and :data:`yrange`.
.. @end deftypefun

.. function:: int gsl_histogram2d_set_ranges (gsl_histogram2d * h,  const double xrange[], size_t xsize, const double yrange[], size_t ysize)

   This function sets the ranges of the existing histogram :data:`h` using
   the arrays :data:`xrange` and :data:`yrange` of size :data:`xsize` and
   :data:`ysize` respectively.  The values of the histogram bins are reset to
   zero.

.. function:: int gsl_histogram2d_set_ranges_uniform (gsl_histogram2d * h, double xmin, double xmax, double ymin, double ymax)

   This function sets the ranges of the existing histogram :data:`h` to cover
   the ranges :data:`xmin` to :data:`xmax` and :data:`ymin` to :data:`ymax`
   uniformly.  The values of the histogram bins are reset to zero.

.. function:: void gsl_histogram2d_free (gsl_histogram2d * h)

   This function frees the 2D histogram :data:`h` and all of the memory
   associated with it.

Copying 2D Histograms
=====================

.. function:: int gsl_histogram2d_memcpy (gsl_histogram2d * dest, const gsl_histogram2d * src)

   This function copies the histogram :data:`src` into the pre-existing
   histogram :data:`dest`, making :data:`dest` into an exact copy of :data:`src`.
   The two histograms must be of the same size.

.. function:: gsl_histogram2d * gsl_histogram2d_clone (const gsl_histogram2d * src)

   This function returns a pointer to a newly created histogram which is an
   exact copy of the histogram :data:`src`.

Updating and accessing 2D histogram elements
============================================

You can access the bins of a two-dimensional histogram either by
specifying a pair of :math:`(x,y)` coordinates or by using the bin
indices :math:`(i,j)` directly.  The functions for accessing the histogram
through :math:`(x,y)` coordinates use binary searches in the x and y
directions to identify the bin which covers the appropriate range.

.. function:: int gsl_histogram2d_increment (gsl_histogram2d * h, double x, double y)

   This function updates the histogram :data:`h` by adding one (1.0) to the
   bin whose x and y ranges contain the coordinates (:data:`x`, :data:`y`).

   If the point :math:`(x,y)` lies inside the valid ranges of the
   histogram then the function returns zero to indicate success.  If
   :math:`(x,y)` lies outside the limits of the histogram then the
   function returns :macro:`GSL_EDOM`, and none of the bins are modified.  The
   error handler is not called, since it is often necessary to compute
   histograms for a small range of a larger dataset, ignoring any
   coordinates outside the range of interest.

.. function:: int gsl_histogram2d_accumulate (gsl_histogram2d * h, double x, double y, double weight)

   This function is similar to :func:`gsl_histogram2d_increment` but increases
   the value of the appropriate bin in the histogram :data:`h` by the
   floating-point number :data:`weight`.

.. function:: double gsl_histogram2d_get (const gsl_histogram2d * h, size_t i, size_t j)

   This function returns the contents of the (:data:`i`, :data:`j`)-th bin of the
   histogram :data:`h`.  If (:data:`i`, :data:`j`) lies outside the valid range of
   indices for the histogram then the error handler is called with an error
   code of :macro:`GSL_EDOM` and the function returns 0.

.. function:: int gsl_histogram2d_get_xrange (const gsl_histogram2d * h, size_t i, double * xlower, double * xupper)
              int gsl_histogram2d_get_yrange (const gsl_histogram2d * h, size_t j, double * ylower, double * yupper)

   These functions find the upper and lower range limits of the :data:`i`-th
   and :data:`j`-th bins in the x and y directions of the histogram :data:`h`.
   The range limits are stored in :data:`xlower` and :data:`xupper` or
   :data:`ylower` and :data:`yupper`.  The lower limits are inclusive
   (i.e. events with these coordinates are included in the bin) and the
   upper limits are exclusive (i.e. events with the value of the upper
   limit are not included and fall in the neighboring higher bin, if it
   exists).  The functions return 0 to indicate success.  If :data:`i` or
   :data:`j` lies outside the valid range of indices for the histogram then
   the error handler is called with an error code of :macro:`GSL_EDOM`.

.. function:: double gsl_histogram2d_xmax (const gsl_histogram2d * h)
              double gsl_histogram2d_xmin (const gsl_histogram2d * h)
              size_t gsl_histogram2d_nx (const gsl_histogram2d * h)
              double gsl_histogram2d_ymax (const gsl_histogram2d * h)
              double gsl_histogram2d_ymin (const gsl_histogram2d * h)
              size_t gsl_histogram2d_ny (const gsl_histogram2d * h)

   These functions return the maximum upper and minimum lower range limits
   and the number of bins for the x and y directions of the histogram
   :data:`h`.  They provide a way of determining these values without
   accessing the :type:`gsl_histogram2d` struct directly.

.. function:: void gsl_histogram2d_reset (gsl_histogram2d * h)

   This function resets all the bins of the histogram :data:`h` to zero.

Searching 2D histogram ranges
=============================

The following functions are used by the access and update routines to
locate the bin which corresponds to a given :math:`(x,y)` coordinate.

.. function:: int gsl_histogram2d_find (const gsl_histogram2d * h, double x, double y, size_t * i, size_t * j)

   This function finds and sets the indices :data:`i` and :data:`j` to
   the bin which covers the coordinates (:data:`x`, :data:`y`). The bin is
   located using a binary search.  The search includes an optimization for
   histograms with uniform ranges, and will return the correct bin immediately
   in this case. If :math:`(x,y)` is found then the function sets the
   indices (:data:`i`, :data:`j`) and returns :macro:`GSL_SUCCESS`.  If
   :math:`(x,y)` lies outside the valid range of the histogram then the
   function returns :macro:`GSL_EDOM` and the error handler is invoked.

2D Histogram Statistics
=======================

.. function:: double gsl_histogram2d_max_val (const gsl_histogram2d * h)

   This function returns the maximum value contained in the histogram bins.

.. function:: void gsl_histogram2d_max_bin (const gsl_histogram2d * h, size_t * i, size_t * j)

   This function finds the indices of the bin containing the maximum value
   in the histogram :data:`h` and stores the result in (:data:`i`, :data:`j`). In
   the case where several bins contain the same maximum value the first bin
   found is returned.

.. function:: double gsl_histogram2d_min_val (const gsl_histogram2d * h)

   This function returns the minimum value contained in the histogram bins.

.. function:: void gsl_histogram2d_min_bin (const gsl_histogram2d * h, size_t * i, size_t * j)

   This function finds the indices of the bin containing the minimum value
   in the histogram :data:`h` and stores the result in (:data:`i`, :data:`j`). In
   the case where several bins contain the same maximum value the first bin
   found is returned.

.. function:: double gsl_histogram2d_xmean (const gsl_histogram2d * h)

   This function returns the mean of the histogrammed x variable, where the
   histogram is regarded as a probability distribution. Negative bin values
   are ignored for the purposes of this calculation.

.. function:: double gsl_histogram2d_ymean (const gsl_histogram2d * h)

   This function returns the mean of the histogrammed y variable, where the
   histogram is regarded as a probability distribution. Negative bin values
   are ignored for the purposes of this calculation.

.. function:: double gsl_histogram2d_xsigma (const gsl_histogram2d * h)

   This function returns the standard deviation of the histogrammed
   x variable, where the histogram is regarded as a probability
   distribution. Negative bin values are ignored for the purposes of this
   calculation.

.. function:: double gsl_histogram2d_ysigma (const gsl_histogram2d * h)

   This function returns the standard deviation of the histogrammed
   y variable, where the histogram is regarded as a probability
   distribution. Negative bin values are ignored for the purposes of this
   calculation.

.. function:: double gsl_histogram2d_cov (const gsl_histogram2d * h)

   This function returns the covariance of the histogrammed x and y
   variables, where the histogram is regarded as a probability
   distribution. Negative bin values are ignored for the purposes of this
   calculation.

.. function:: double gsl_histogram2d_sum (const gsl_histogram2d * h)

   This function returns the sum of all bin values. Negative bin values
   are included in the sum.

2D Histogram Operations
=======================

.. function:: int gsl_histogram2d_equal_bins_p (const gsl_histogram2d * h1, const gsl_histogram2d * h2)

   This function returns 1 if all the individual bin ranges of the two
   histograms are identical, and 0 otherwise.

.. function:: int gsl_histogram2d_add (gsl_histogram2d * h1, const gsl_histogram2d * h2)

   This function adds the contents of the bins in histogram :data:`h2` to the
   corresponding bins of histogram :data:`h1`,
   i.e. :math:`h'_1(i,j) = h_1(i,j) + h_2(i,j)`.
   The two histograms must have identical bin ranges.

.. function:: int gsl_histogram2d_sub (gsl_histogram2d * h1, const gsl_histogram2d * h2)

   This function subtracts the contents of the bins in histogram :data:`h2` from the
   corresponding bins of histogram :data:`h1`,
   i.e. :math:`h'_1(i,j) = h_1(i,j) - h_2(i,j)`.
   The two histograms must have identical bin ranges.

.. function:: int gsl_histogram2d_mul (gsl_histogram2d * h1, const gsl_histogram2d * h2)

   This function multiplies the contents of the bins of histogram :data:`h1`
   by the contents of the corresponding bins in histogram :data:`h2`,
   i.e. :math:`h'_1(i,j) = h_1(i,j) * h_2(i,j)`.
   The two histograms must have identical bin ranges.

.. function:: int gsl_histogram2d_div (gsl_histogram2d * h1, const gsl_histogram2d * h2)

   This function divides the contents of the bins of histogram :data:`h1`
   by the contents of the corresponding bins in histogram :data:`h2`,
   i.e. :math:`h'_1(i,j) = h_1(i,j) / h_2(i,j)`.
   The two histograms must have identical bin ranges.

.. function:: int gsl_histogram2d_scale (gsl_histogram2d * h, double scale)

   This function multiplies the contents of the bins of histogram :data:`h`
   by the constant :data:`scale`, i.e.
   
   .. only:: not texinfo
   
      .. math:: h'_1(i,j) = h_1(i,j) * \hbox{\it scale}

   .. only:: texinfo

      ::

         h'_1(i,j) = h_1(i,j) scale

.. function:: int gsl_histogram2d_shift (gsl_histogram2d * h, double offset)

   This function shifts the contents of the bins of histogram :data:`h`
   by the constant :data:`offset`, i.e.
   
   .. only:: not texinfo
   
      .. math:: h'_1(i,j) = h_1(i,j) + \hbox{\it offset}

   .. only:: texinfo

      ::

         h'_1(i,j) = h_1(i,j) + offset

Reading and writing 2D histograms
=================================

The library provides functions for reading and writing two dimensional
histograms to a file as binary data or formatted text.

.. function:: int gsl_histogram2d_fwrite (FILE * stream, const gsl_histogram2d * h)

   This function writes the ranges and bins of the histogram :data:`h` to the
   stream :data:`stream` in binary format.  The return value is 0 for success
   and :macro:`GSL_EFAILED` if there was a problem writing to the file.  Since
   the data is written in the native binary format it may not be portable
   between different architectures.

.. function:: int gsl_histogram2d_fread (FILE * stream, gsl_histogram2d * h)

   This function reads into the histogram :data:`h` from the stream
   :data:`stream` in binary format.  The histogram :data:`h` must be
   preallocated with the correct size since the function uses the number of
   x and y bins in :data:`h` to determine how many bytes to read.  The return
   value is 0 for success and :macro:`GSL_EFAILED` if there was a problem
   reading from the file.  The data is assumed to have been written in the
   native binary format on the same architecture.

.. function:: int gsl_histogram2d_fprintf (FILE * stream, const gsl_histogram2d * h, const char * range_format, const char * bin_format)

   This function writes the ranges and bins of the histogram :data:`h`
   line-by-line to the stream :data:`stream` using the format specifiers
   :data:`range_format` and :data:`bin_format`.  These should be one of the
   :code:`%g`, :code:`%e` or :code:`%f` formats for floating point
   numbers.  The function returns 0 for success and :macro:`GSL_EFAILED` if
   there was a problem writing to the file.  The histogram output is
   formatted in five columns, and the columns are separated by spaces,
   like this::

      xrange[0] xrange[1] yrange[0] yrange[1] bin(0,0)
      xrange[0] xrange[1] yrange[1] yrange[2] bin(0,1)
      xrange[0] xrange[1] yrange[2] yrange[3] bin(0,2)
      ....
      xrange[0] xrange[1] yrange[ny-1] yrange[ny] bin(0,ny-1)

      xrange[1] xrange[2] yrange[0] yrange[1] bin(1,0)
      xrange[1] xrange[2] yrange[1] yrange[2] bin(1,1)
      xrange[1] xrange[2] yrange[1] yrange[2] bin(1,2)
      ....
      xrange[1] xrange[2] yrange[ny-1] yrange[ny] bin(1,ny-1)

      ....

      xrange[nx-1] xrange[nx] yrange[0] yrange[1] bin(nx-1,0)
      xrange[nx-1] xrange[nx] yrange[1] yrange[2] bin(nx-1,1)
      xrange[nx-1] xrange[nx] yrange[1] yrange[2] bin(nx-1,2)
      ....
      xrange[nx-1] xrange[nx] yrange[ny-1] yrange[ny] bin(nx-1,ny-1)

   Each line contains the lower and upper limits of the bin and the
   contents of the bin.  Since the upper limits of the each bin are the
   lower limits of the neighboring bins there is duplication of these
   values but this allows the histogram to be manipulated with
   line-oriented tools.

.. function:: int gsl_histogram2d_fscanf (FILE * stream, gsl_histogram2d * h)

   This function reads formatted data from the stream :data:`stream` into the
   histogram :data:`h`.  The data is assumed to be in the five-column format
   used by :func:`gsl_histogram2d_fprintf`.  The histogram :data:`h` must be
   preallocated with the correct lengths since the function uses the sizes
   of :data:`h` to determine how many numbers to read.  The function returns 0
   for success and :macro:`GSL_EFAILED` if there was a problem reading from
   the file.

Resampling from 2D histograms
=============================

As in the one-dimensional case, a two-dimensional histogram made by
counting events can be regarded as a measurement of a probability
distribution.  Allowing for statistical error, the height of each bin
represents the probability of an event where (:math:`x`,:math:`y`) falls in
the range of that bin.  For a two-dimensional histogram the probability
distribution takes the form :math:`p(x,y) dx dy` where,

.. math:: p(x,y) = n_{ij} / (N A_{ij})

In this equation :math:`n_{ij}`
is the number of events in the bin which
contains :math:`(x,y)`, :math:`A_{ij}`
is the area of the bin and :math:`N` is
the total number of events.  The distribution of events within each bin
is assumed to be uniform.

.. type:: gsl_histogram2d_pdf

   ============================= ===========================================================================
   :code:`size_t nx, ny`         This is the number of histogram bins used to approximate the probability
                                 distribution function in the x and y directions.
   :code:`double * xrange`       The ranges of the bins in the x-direction are stored in an array of
                                 :code:`nx + 1` elements pointed to by :data:`xrange`.
   :code:`double * yrange`       The ranges of the bins in the y-direction are stored in an array of
                                 :code:`ny + 1` pointed to by :data:`yrange`.
   :code:`double * sum`          The cumulative probability for the bins is stored in an array of
                                 :data:`nx` * :data:`ny` elements pointed to by :data:`sum`.
   ============================= ===========================================================================

The following functions allow you to create a :type:`gsl_histogram2d_pdf`
struct which represents a two dimensional probability distribution and
generate random samples from it.

.. function:: gsl_histogram2d_pdf * gsl_histogram2d_pdf_alloc (size_t nx, size_t ny)

   This function allocates memory for a two-dimensional probability
   distribution of size :data:`nx`-by-:data:`ny` and returns a pointer to a
   newly initialized :type:`gsl_histogram2d_pdf` struct. If insufficient
   memory is available a null pointer is returned and the error handler is
   invoked with an error code of :macro:`GSL_ENOMEM`.

.. function:: int gsl_histogram2d_pdf_init (gsl_histogram2d_pdf * p, const gsl_histogram2d * h)

   This function initializes the two-dimensional probability distribution
   calculated :data:`p` from the histogram :data:`h`.  If any of the bins of
   :data:`h` are negative then the error handler is invoked with an error
   code of :macro:`GSL_EDOM` because a probability distribution cannot
   contain negative values.

.. function:: void gsl_histogram2d_pdf_free (gsl_histogram2d_pdf * p)

   This function frees the two-dimensional probability distribution
   function :data:`p` and all of the memory associated with it.

.. function:: int gsl_histogram2d_pdf_sample (const gsl_histogram2d_pdf * p, double r1, double r2, double * x, double * y)

   This function uses two uniform random numbers between zero and one,
   :data:`r1` and :data:`r2`, to compute a single random sample from the
   two-dimensional probability distribution :data:`p`.

Example programs for 2D histograms
==================================

This program demonstrates two features of two-dimensional histograms.
First a 10-by-10 two-dimensional histogram is created with x and y running
from 0 to 1.  Then a few sample points are added to the histogram, at
(0.3,0.3) with a height of 1, at (0.8,0.1) with a height of 5 and at
(0.7,0.9) with a height of 0.5.  This histogram with three events is
used to generate a random sample of 1000 simulated events, which are
printed out.

.. include:: examples/histogram2d.c
   :code:

The following plot shows the distribution of the simulated events.  Using
a higher resolution grid we can see the original underlying histogram
and also the statistical fluctuations caused by the events being
uniformly distributed over the area of the original bins.

.. figure:: /images/histogram2d.png
   :scale: 60%

   Distribution of simulated events from example program
fileio, TODO: update to newest implementation
=============================================

The Fileio implementation helps to overcome the previous limitation of
the IO pickle format by using hdf5 files.

One of the main differences between pickle and hdf5 is how hdf5
structures the data. In pickle, it is necessary to retrieve the data in
the same order as the data has been saved. In hdf5 the data is
structured similarly as as a dictionary. It is necessary to assign a
label for every data element and therefore it can be accessed by
indexing the label into the structure (similarly as a python
dictionary).

Fileio facilitates the transition from pickle to hdf5 by proving a
unified interface to pickle and hdf5 files, and also provides a
conversion mechanism from pickle to hdf5.

The following example pretends to illustrate how to transition from the
current pickle IO format to hdf5:

Current usage with pickle
-------------------------

Load
~~~~

.. code:: python

        with open('./data/data_forces_M64xN64.pkl', 'rb') as ifile:
            [forces_init, w0, y, yTilde, YTilde, theta] = pickle.load(ifile)

Store
~~~~~

.. code:: python

        with open('./data/data_forces_M64xN64.pkl', "wb") as ifile:
            pickle.dump([forces_init, w0, y, yTilde, YTilde, theta], ifile)

Fileio using pickle format
--------------------------

Load
~~~~

.. code:: python

        from bioen import fileio as fio
        [forces_init, w0, y, yTilde, YTilde, theta] = fio.load('./data/data_forces_M64xN64.pkl')

Store
~~~~~

.. code:: python

        from bioen import fileio as fio
        fio.dump('./data/data_forces_M64xN64.pkl', [forces_init, w0, y, yTilde, YTilde, theta])

Fileio using hdf5 format (returns a dictionary) - (\*\*) and transform the data into a list or from list to dictionary.
-----------------------------------------------------------------------------------------------------------------------

Load
~~~~

.. code:: python

        from bioen import fileio as fio
        mydict = fio.load('data.h5')
        [forces_init, w0, y, yTilde, YTilde, theta] = fio.get_list_from_dict(mydict,"forces_init", "w0", "y", "yTilde", "YTilde", "theta")

or

.. code:: python

        from bioen import fileio as fio
        mydict = fio.load('data.h5')
        mylist = ["forces_init", "w0", "y", "yTilde", "YTilde", "theta"]
        [forces_init, w0, y, yTilde, YTilde, theta] = fio.get_list_from_dict(mydict, mylist)

Store
~~~~~

.. code:: python

        from bioen import fileio as fio
        mydict = fio.get_dict_from_list(forces_init=forces_init, w0=w0, y=y, yTilde=yTilde, YTilde=YTilde, theta=theta)
        fio.dump ('data.h5', mydict)

(\*\*) Optional; This can be useful to transition from the current
list-like format to a dictionary-like

Fileio converting a pickle file into a new hdf5 file
----------------------------------------------------

.. code:: python

        from bioen import fileio as fio
        mylist=["forces_init","w0","y","yTilde","YTilde","theta"]
        fio.convert_to_hdf5('data.pkl','data.h5',mylist)

Recommendations
===============

Three steps transition:

1) Transform the current pickle files into hdf5 files by using the
   conversion tool. This has to be a suppervised conversion because the
   tags/labels for the data must be specified.

   e.g.:

.. code:: python

        from bioen import fileio as fio

        ### Tags for the data
        mylist=["forces_init","w0","y","yTilde","YTilde","theta"]
        ### Convert pickle into a new h5 file
        fio.convert_to_hdf5('data.pkl','data.h5',mylist)

2) Replace the pickle calls for Fileio pickle calls

.. code:: python

        # Previous pickle
        #with open('./data/data_forces_M64xN64.pkl', 'rb') as ifile:
        #    [forces_init, w0, y, yTilde, YTilde, theta] = pickle.load(ifile)

        # Fileio pickle

        from bioen import fileio as fio
        [forces_init, w0, y, yTilde, YTilde, theta] = fio.load('./data/data_forces_M64xN64.pkl')

3) Replace the filename extension from '.pkl' to '.h5' and call the data
   type converter (dict-list/dict-list)

.. code:: python

        from bioen import fileio as fio
        mydict = fio.load('data.h5')
        [GInit, G, y, yTilde, YTilde, w0, theta] = fio.get_list_from_dict(new_mydict,"GInit", "G", "y", "yTilde", "YTilde", "w0", "theta")
:orphan:

API transition after redesing
+++++++++++++++++++++++++++++

The current version implements a major API change, therefore, the utilization of
previous scripts could be affected.


Introduction
============

The different definition of libraries and methods has been renamed in order to
create a unified context.

NOTATION:

    - library => minimizer
    - method => algorithm


Currently, bioen.optimize performs the optimization in combination with
external packages. There are working interfaces for **scipy**, **GSL** and
**LIBLBFGS** external packages/libraries. The user must decide, at compilation
time, to include one or more of them to extend the bioen.optimize functionality.

Depending on the installation options, we are able to use up to three
'**minimizers**':

    - scipy (mandatory)
    - GSL   (optional)
    - LBFGS (optional)


Each '**minimizer**' applies different '**algorithm**'s:
    - scipy
        - bfgs
        - lbfgs
        - cg
    - gsl
        - conjugate_fr
        - conjugate_pr
        - bfgs2
        - bfgs
        - steepest_descent
    - lbfsg
        - l-bfgs

For every combination of 'minimizer' and 'algorithm' there is a set of
arguments affecting the behaviour of the optimizizer. e.g.: 'tolerance',
'step_size', or 'max_iterations'

API Optimizer
=============

A new argument, containing the configuration of the optimizer, is needed
in the current version. This argument is an structure (a set) that contains the
definition of the minimizer, algorithm, algorithm specific parameters and
bioen.optimizer extended features.

Algorithm specific configuration
--------------------------------

Once the user has decided which minimizer to use, a basic structure containing a
default configuration can be obtained from the minimizer module:

    >>> config = bioen.optimize.minimize.Parameters('gsl')

This set can be printed but also shown in a more readable way:

    >>> bioen_optimzie.minimize.show_params(config)

    - minimizer        gsl
    - debug            True
    - verbose          True
    - params           {'step_size': 0.01, 'tol': 0.001, 'max_iterations': 5000}
    - algorithm        gsl_multimin_fdfminimizer_vector_bfgs2
    - use_c_functions  True
    - n_threads        -1
    - cache_ytilde_transposed  auto

The structure contains a specific field named 'params' with the specific
configuration for the algorithm.

It is possible to modify the values within this structure except for the
minimizer field. In order to modify the values, simply index the content from
the container as follows:

    >>> config['algorithm'] = 'conjugate_pr'
    >>> config['params']['step_size']=0.05
    >>> config['params']['max_iterations']=1000


Extended features
-----------------

Along with the algorithm specific configuration there are the following options:

    - debug; extra parameters are returned from the minimizer
    - verbose; extra information is printed on the execution.
    - use_c_functions; scipy exclusive parameter to select between python or C implementation
    - n_threads; explicit number or implicit -1 (through the environment variable OMP_NUM_THREADS)
    - cache_ytilde_transposed; True: performance improvement but higher memory consumption. [true,false,auto]



Usage
-----

To apply the optimization::

    import bioen.optimize as bop

    bop.forces.find_optimum (forces_init, w0, y, yTilde, YTilde, theta, config)

    bop.log_weights.find_optimum (GInit, G, y, yTilde, YTilde, theta, config)
Modules and submodules of the bioen Python package
==================================================

.. toctree::
   :maxdepth: 2


bioen
-----

.. automodule:: bioen
   :members:
   :undoc-members:


.. TODO: add other modules


bioen.version
-------------

.. automodule:: bioen.version
   :members:
   :undoc-members:


bioen.analyze
-------------

.. automodule:: bioen.analyze
   :members:
   :undoc-members:


bioen.analyze.procedure
-----------------------

.. automodule:: bioen.analyze.procedure
   :members:
   :undoc-members:


bioen.analyze.run_bioen
-----------------------

.. automodule:: bioen.analyze.run_bioen
   :members:
   :undoc-members:


bioen.analyze.utils
-------------------

.. automodule:: bioen.analyze.utils
   :members:
   :undoc-members:


bioen.analyze.observables
-------------------------

.. automodule:: bioen.analyze.observables
   :members:
   :undoc-members:


bioen.analyze.observables.observables
-------------------------------------

.. automodule:: bioen.analyze.observables.observables
   :members:
   :undoc-members:


bioen.analyze.observables.deer
------------------------------

.. automodule:: bioen.analyze.observables.deer
   :members:
   :undoc-members:


bioen.analyze.observables.deer.deer
-----------------------------------

.. automodule:: bioen.analyze.observables.deer.deer
   :members:
   :undoc-members:


bioen.analyze.observables.generic
---------------------------------

.. automodule:: bioen.analyze.observables.generic
   :members:
   :undoc-members:


bioen.analyze.observables.generic.generic
-----------------------------------------

.. automodule:: bioen.analyze.observables.generic.generic
   :members:
   :undoc-members:


bioen.analyze.observables.scattering
------------------------------------

.. automodule:: bioen.analyze.observables.scattering
   :members:
   :undoc-members:


bioen.analyze.observables.scattering.scattering
-----------------------------------------------

.. automodule:: bioen.analyze.observables.scattering.scattering
   :members:
   :undoc-members:


bioen.analyze.show_plot
-----------------------

.. automodule:: bioen.analyze.show_plot
   :members:
   :undoc-members:


bioen.analyze.show_plot.show_plot
---------------------------------

.. automodule:: bioen.analyze.show_plot.show_plot
   :members:
   :undoc-members:


bioen.optimize
-----------------------

.. automodule:: bioen.optimize
   :members:
   :undoc-members:


bioen.optimize.minimize
-----------------------

.. automodule:: bioen.optimize.minimize
   :members:
   :undoc-members:


bioen.optimize.log_weights
--------------------------

.. automodule:: bioen.optimize.log_weights
   :members:
   :undoc-members:


bioen.optimize.forces
---------------------

.. automodule:: bioen.optimize.forces
   :members:
   :undoc-members:


bioen.optimize.util
-------------------

.. automodule:: bioen.optimize.util
   :members:
   :undoc-members:


bioen.optimize.ext.c_bioen
--------------------------

.. automodule:: bioen.optimize.ext.c_bioen
   :members:
   :undoc-members:
.. hpcmd documentation master file, created by
   sphinx-quickstart on Tue Jul 17 13:05:42 2018.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.


Welcome to bioen's documentation!
=================================

.. toctree::
   :maxdepth: 2
   :caption: Contents:


Introduction
------------

TBD


Installation
------------

bioen is written in Python and is compatible with Python 2.7 (3.6 in
preparation). It is installed in the standard way using ``setup.py``.


Usage
-----

TBD

.. see redesign.rst for the optimize part

.. toctree::
   :maxdepth: 2

   fileio.rst


Source documentation
====================

The documentation linked below is generated automatically from the docstrings
present in the bioen source code.

.. toctree::
   :maxdepth: 2

   modules.rst


Copyright and License
=====================

Copyright 2018 Katrin Reichel, Jürgen Köfinger, Klaus Reuter, César Allande, Lukas S. Stelzl, Gerhard Hummer

License: GNU GPL version 3. See the files ``LICENSE.txt`` and ``COPYING`` for details.


Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`
