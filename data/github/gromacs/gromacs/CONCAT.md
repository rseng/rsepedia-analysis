# How to become a contributor and submit your own code

## Contributor License Agreements

We'd love to accept your patches! Before we can take them, we have to jump a
couple of legal hurdles.

Please fill out either the individual or corporate Contributor License Agreement
(CLA).

*   If you are an individual writing original source code and you're sure you
    own the intellectual property, then you'll need to sign an
    [individual CLA](https://developers.google.com/open-source/cla/individual).
*   If you work for a company that wants to allow you to contribute your work,
    then you'll need to sign a
    [corporate CLA](https://developers.google.com/open-source/cla/corporate).

Follow either of the two links above to access the appropriate CLA and
instructions for how to sign and return it. Once we receive it, we'll be able to
accept your pull requests.

## Are you a Googler?

If you are a Googler, please make an attempt to submit an internal change rather
than a GitHub Pull Request. If you are not able to submit an internal change a
PR is acceptable as an alternative.

## Contributing A Patch

1.  Submit an issue describing your proposed change to the
    [issue tracker](https://github.com/google/googletest/issues).
2.  Please don't mix more than one logical change per submittal, because it
    makes the history hard to follow. If you want to make a change that doesn't
    have a corresponding issue in the issue tracker, please create one.
3.  Also, coordinate with team members that are listed on the issue in question.
    This ensures that work isn't being duplicated and communicating your plan
    early also generally leads to better patches.
4.  If your proposed change is accepted, and you haven't already done so, sign a
    Contributor License Agreement (see details above).
5.  Fork the desired repo, develop and test your code changes.
6.  Ensure that your code adheres to the existing style in the sample to which
    you are contributing.
7.  Ensure that your code has an appropriate set of unit tests which all pass.
8.  Submit a pull request.

## The Google Test and Google Mock Communities

The Google Test community exists primarily through the
[discussion group](http://groups.google.com/group/googletestframework) and the
GitHub repository. Likewise, the Google Mock community exists primarily through
their own [discussion group](http://groups.google.com/group/googlemock). You are
definitely encouraged to contribute to the discussion and you can also help us
to keep the effectiveness of the group high by following and promoting the
guidelines listed here.

### Please Be Friendly

Showing courtesy and respect to others is a vital part of the Google culture,
and we strongly encourage everyone participating in Google Test development to
join us in accepting nothing less. Of course, being courteous is not the same as
failing to constructively disagree with each other, but it does mean that we
should be respectful of each other when enumerating the 42 technical reasons
that a particular proposal may not be the best choice. There's never a reason to
be antagonistic or dismissive toward anyone who is sincerely trying to
contribute to a discussion.

Sure, C++ testing is serious business and all that, but it's also a lot of fun.
Let's keep it that way. Let's strive to be one of the friendliest communities in
all of open source.

As always, discuss Google Test in the official GoogleTest discussion group. You
don't have to actually submit code in order to sign up. Your participation
itself is a valuable contribution.

## Style

To keep the source consistent, readable, diffable and easy to merge, we use a
fairly rigid coding style, as defined by the
[google-styleguide](https://github.com/google/styleguide) project. All patches
will be expected to conform to the style outlined
[here](https://google.github.io/styleguide/cppguide.html). Use
[.clang-format](https://github.com/google/googletest/blob/master/.clang-format)
to check your formatting.

## Requirements for Contributors

If you plan to contribute a patch, you need to build Google Test, Google Mock,
and their own tests from a git checkout, which has further requirements:

*   [Python](https://www.python.org/) v2.3 or newer (for running some of the
    tests and re-generating certain source files from templates)
*   [CMake](https://cmake.org/) v2.8.12 or newer

## Developing Google Test and Google Mock

This section discusses how to make your own changes to the Google Test project.

### Testing Google Test and Google Mock Themselves

To make sure your changes work as intended and don't break existing
functionality, you'll want to compile and run Google Test and GoogleMock's own
tests. For that you can use CMake:

    mkdir mybuild
    cd mybuild
    cmake -Dgtest_build_tests=ON -Dgmock_build_tests=ON ${GTEST_REPO_DIR}

To choose between building only Google Test or Google Mock, you may modify your
cmake command to be one of each

    cmake -Dgtest_build_tests=ON ${GTEST_DIR} # sets up Google Test tests
    cmake -Dgmock_build_tests=ON ${GMOCK_DIR} # sets up Google Mock tests

Make sure you have Python installed, as some of Google Test's tests are written
in Python. If the cmake command complains about not being able to find Python
(`Could NOT find PythonInterp (missing: PYTHON_EXECUTABLE)`), try telling it
explicitly where your Python executable can be found:

    cmake -DPYTHON_EXECUTABLE=path/to/python ...

Next, you can build Google Test and / or Google Mock and all desired tests. On
\*nix, this is usually done by

    make

To run the tests, do

    make test

All tests should pass.
# GoogleTest

### Announcements

#### Live at Head

GoogleTest now follows the
[Abseil Live at Head philosophy](https://abseil.io/about/philosophy#upgrade-support).
We recommend using the latest commit in the `master` branch in your projects.

#### Documentation Updates

Our documentation is now live on GitHub Pages at
https://google.github.io/googletest/. We recommend browsing the documentation on
GitHub Pages rather than directly in the repository.

#### Release 1.11.0

[Release 1.11.0](https://github.com/google/googletest/releases/tag/release-1.11.0)
is now available.

#### Coming Soon

*   We are planning to take a dependency on
    [Abseil](https://github.com/abseil/abseil-cpp).
*   More documentation improvements are planned.

## Welcome to **GoogleTest**, Google's C++ test framework!

This repository is a merger of the formerly separate GoogleTest and GoogleMock
projects. These were so closely related that it makes sense to maintain and
release them together.

### Getting Started

See the [GoogleTest User's Guide](https://google.github.io/googletest/) for
documentation. We recommend starting with the
[GoogleTest Primer](https://google.github.io/googletest/primer.html).

More information about building GoogleTest can be found at
[googletest/README.md](googletest/README.md).

## Features

*   An [xUnit](https://en.wikipedia.org/wiki/XUnit) test framework.
*   Test discovery.
*   A rich set of assertions.
*   User-defined assertions.
*   Death tests.
*   Fatal and non-fatal failures.
*   Value-parameterized tests.
*   Type-parameterized tests.
*   Various options for running the tests.
*   XML test report generation.

## Supported Platforms

GoogleTest requires a codebase and compiler compliant with the C++11 standard or
newer.

The GoogleTest code is officially supported on the following platforms.
Operating systems or tools not listed below are community-supported. For
community-supported platforms, patches that do not complicate the code may be
considered.

If you notice any problems on your platform, please file an issue on the
[GoogleTest GitHub Issue Tracker](https://github.com/google/googletest/issues).
Pull requests containing fixes are welcome!

### Operating Systems

*   Linux
*   macOS
*   Windows

### Compilers

*   gcc 5.0+
*   clang 5.0+
*   MSVC 2015+

**macOS users:** Xcode 9.3+ provides clang 5.0+.

### Build Systems

*   [Bazel](https://bazel.build/)
*   [CMake](https://cmake.org/)

**Note:** Bazel is the build system used by the team internally and in tests.
CMake is supported on a best-effort basis and by the community.

## Who Is Using GoogleTest?

In addition to many internal projects at Google, GoogleTest is also used by the
following notable projects:

*   The [Chromium projects](http://www.chromium.org/) (behind the Chrome browser
    and Chrome OS).
*   The [LLVM](http://llvm.org/) compiler.
*   [Protocol Buffers](https://github.com/google/protobuf), Google's data
    interchange format.
*   The [OpenCV](http://opencv.org/) computer vision library.

## Related Open Source Projects

[GTest Runner](https://github.com/nholthaus/gtest-runner) is a Qt5 based
automated test-runner and Graphical User Interface with powerful features for
Windows and Linux platforms.

[GoogleTest UI](https://github.com/ospector/gtest-gbar) is a test runner that
runs your test binary, allows you to track its progress via a progress bar, and
displays a list of test failures. Clicking on one shows failure text. GoogleTest
UI is written in C#.

[GTest TAP Listener](https://github.com/kinow/gtest-tap-listener) is an event
listener for GoogleTest that implements the
[TAP protocol](https://en.wikipedia.org/wiki/Test_Anything_Protocol) for test
result output. If your test runner understands TAP, you may find it useful.

[gtest-parallel](https://github.com/google/gtest-parallel) is a test runner that
runs tests from your binary in parallel to provide significant speed-up.

[GoogleTest Adapter](https://marketplace.visualstudio.com/items?itemName=DavidSchuldenfrei.gtest-adapter)
is a VS Code extension allowing to view GoogleTest in a tree view, and run/debug
your tests.

[C++ TestMate](https://github.com/matepek/vscode-catch2-test-adapter) is a VS
Code extension allowing to view GoogleTest in a tree view, and run/debug your
tests.

[Cornichon](https://pypi.org/project/cornichon/) is a small Gherkin DSL parser
that generates stub code for GoogleTest.

## Contributing Changes

Please read
[`CONTRIBUTING.md`](https://github.com/google/googletest/blob/master/CONTRIBUTING.md)
for details on how to contribute to this project.

Happy testing!
---
name: Bug report
about: Create a report to help us improve
title: ''
labels: 'bug'
assignees: ''
---

**Describe the bug**

Include a clear and concise description of what the problem is, including what
you expected to happen, and what actually happened.

**Steps to reproduce the bug**

It's important that we are able to reproduce the problem that you are
experiencing. Please provide all code and relevant steps to reproduce the
problem, including your `BUILD`/`CMakeLists.txt` file and build commands. Links
to a GitHub branch or [godbolt.org](https://godbolt.org/) that demonstrate the
problem are also helpful.

**Does the bug persist in the most recent commit?**

We recommend using the latest commit in the master branch in your projects.

**What operating system and version are you using?**

If you are using a Linux distribution please include the name and version of the
distribution as well.

**What compiler and version are you using?**

Please include the output of `gcc -v` or `clang -v`, or the equivalent for your
compiler.

**What build system are you using?**

Please include the output of `bazel --version` or `cmake --version`, or the
equivalent for your build system.

**Additional context**

Add any other context about the problem here.
---
name: Feature request
about: Propose a new feature
title: ''
labels: 'enhancement'
assignees: ''
---

**Does the feature exist in the most recent commit?**

We recommend using the latest commit from GitHub in your projects.

**Why do we need this feature?**

Ideally, explain why a combination of existing features cannot be used instead.

**Describe the proposal**

Include a detailed description of the feature, with usage examples.

**Is the feature specific to an operating system, compiler, or build system version?**

If it is, please specify which versions.

# Googletest Primer

## Introduction: Why googletest?

*googletest* helps you write better C++ tests.

googletest is a testing framework developed by the Testing Technology team with
Google's specific requirements and constraints in mind. Whether you work on
Linux, Windows, or a Mac, if you write C++ code, googletest can help you. And it
supports *any* kind of tests, not just unit tests.

So what makes a good test, and how does googletest fit in? We believe:

1.  Tests should be *independent* and *repeatable*. It's a pain to debug a test
    that succeeds or fails as a result of other tests. googletest isolates the
    tests by running each of them on a different object. When a test fails,
    googletest allows you to run it in isolation for quick debugging.
2.  Tests should be well *organized* and reflect the structure of the tested
    code. googletest groups related tests into test suites that can share data
    and subroutines. This common pattern is easy to recognize and makes tests
    easy to maintain. Such consistency is especially helpful when people switch
    projects and start to work on a new code base.
3.  Tests should be *portable* and *reusable*. Google has a lot of code that is
    platform-neutral; its tests should also be platform-neutral. googletest
    works on different OSes, with different compilers, with or without
    exceptions, so googletest tests can work with a variety of configurations.
4.  When tests fail, they should provide as much *information* about the problem
    as possible. googletest doesn't stop at the first test failure. Instead, it
    only stops the current test and continues with the next. You can also set up
    tests that report non-fatal failures after which the current test continues.
    Thus, you can detect and fix multiple bugs in a single run-edit-compile
    cycle.
5.  The testing framework should liberate test writers from housekeeping chores
    and let them focus on the test *content*. googletest automatically keeps
    track of all tests defined, and doesn't require the user to enumerate them
    in order to run them.
6.  Tests should be *fast*. With googletest, you can reuse shared resources
    across tests and pay for the set-up/tear-down only once, without making
    tests depend on each other.

Since googletest is based on the popular xUnit architecture, you'll feel right
at home if you've used JUnit or PyUnit before. If not, it will take you about 10
minutes to learn the basics and get started. So let's go!

## Beware of the nomenclature

{: .callout .note}
_Note:_ There might be some confusion arising from different definitions of the
terms _Test_, _Test Case_ and _Test Suite_, so beware of misunderstanding these.

Historically, googletest started to use the term _Test Case_ for grouping
related tests, whereas current publications, including International Software
Testing Qualifications Board ([ISTQB](http://www.istqb.org/)) materials and
various textbooks on software quality, use the term
_[Test Suite][istqb test suite]_ for this.

The related term _Test_, as it is used in googletest, corresponds to the term
_[Test Case][istqb test case]_ of ISTQB and others.

The term _Test_ is commonly of broad enough sense, including ISTQB's definition
of _Test Case_, so it's not much of a problem here. But the term _Test Case_ as
was used in Google Test is of contradictory sense and thus confusing.

googletest recently started replacing the term _Test Case_ with _Test Suite_.
The preferred API is *TestSuite*. The older TestCase API is being slowly
deprecated and refactored away.

So please be aware of the different definitions of the terms:


Meaning                                                                              | googletest Term         | [ISTQB](http://www.istqb.org/) Term
:----------------------------------------------------------------------------------- | :---------------------- | :----------------------------------
Exercise a particular program path with specific input values and verify the results | [TEST()](#simple-tests) | [Test Case][istqb test case]


[istqb test case]: http://glossary.istqb.org/en/search/test%20case
[istqb test suite]: http://glossary.istqb.org/en/search/test%20suite

## Basic Concepts

When using googletest, you start by writing *assertions*, which are statements
that check whether a condition is true. An assertion's result can be *success*,
*nonfatal failure*, or *fatal failure*. If a fatal failure occurs, it aborts the
current function; otherwise the program continues normally.

*Tests* use assertions to verify the tested code's behavior. If a test crashes
or has a failed assertion, then it *fails*; otherwise it *succeeds*.

A *test suite* contains one or many tests. You should group your tests into test
suites that reflect the structure of the tested code. When multiple tests in a
test suite need to share common objects and subroutines, you can put them into a
*test fixture* class.

A *test program* can contain multiple test suites.

We'll now explain how to write a test program, starting at the individual
assertion level and building up to tests and test suites.

## Assertions

googletest assertions are macros that resemble function calls. You test a class
or function by making assertions about its behavior. When an assertion fails,
googletest prints the assertion's source file and line number location, along
with a failure message. You may also supply a custom failure message which will
be appended to googletest's message.

The assertions come in pairs that test the same thing but have different effects
on the current function. `ASSERT_*` versions generate fatal failures when they
fail, and **abort the current function**. `EXPECT_*` versions generate nonfatal
failures, which don't abort the current function. Usually `EXPECT_*` are
preferred, as they allow more than one failure to be reported in a test.
However, you should use `ASSERT_*` if it doesn't make sense to continue when the
assertion in question fails.

Since a failed `ASSERT_*` returns from the current function immediately,
possibly skipping clean-up code that comes after it, it may cause a space leak.
Depending on the nature of the leak, it may or may not be worth fixing - so keep
this in mind if you get a heap checker error in addition to assertion errors.

To provide a custom failure message, simply stream it into the macro using the
`<<` operator or a sequence of such operators. See the following example, using
the [`ASSERT_EQ` and `EXPECT_EQ`](reference/assertions.md#EXPECT_EQ) macros to
verify value equality:

```c++
ASSERT_EQ(x.size(), y.size()) << "Vectors x and y are of unequal length";

for (int i = 0; i < x.size(); ++i) {
  EXPECT_EQ(x[i], y[i]) << "Vectors x and y differ at index " << i;
}
```

Anything that can be streamed to an `ostream` can be streamed to an assertion
macro--in particular, C strings and `string` objects. If a wide string
(`wchar_t*`, `TCHAR*` in `UNICODE` mode on Windows, or `std::wstring`) is
streamed to an assertion, it will be translated to UTF-8 when printed.

GoogleTest provides a collection of assertions for verifying the behavior of
your code in various ways. You can check Boolean conditions, compare values
based on relational operators, verify string values, floating-point values, and
much more. There are even assertions that enable you to verify more complex
states by providing custom predicates. For the complete list of assertions
provided by GoogleTest, see the [Assertions Reference](reference/assertions.md).

## Simple Tests

To create a test:

1.  Use the `TEST()` macro to define and name a test function. These are
    ordinary C++ functions that don't return a value.
2.  In this function, along with any valid C++ statements you want to include,
    use the various googletest assertions to check values.
3.  The test's result is determined by the assertions; if any assertion in the
    test fails (either fatally or non-fatally), or if the test crashes, the
    entire test fails. Otherwise, it succeeds.

```c++
TEST(TestSuiteName, TestName) {
  ... test body ...
}
```

`TEST()` arguments go from general to specific. The *first* argument is the name
of the test suite, and the *second* argument is the test's name within the test
suite. Both names must be valid C++ identifiers, and they should not contain
any underscores (`_`). A test's *full name* consists of its containing test suite and
its individual name. Tests from different test suites can have the same
individual name.

For example, let's take a simple integer function:

```c++
int Factorial(int n);  // Returns the factorial of n
```

A test suite for this function might look like:

```c++
// Tests factorial of 0.
TEST(FactorialTest, HandlesZeroInput) {
  EXPECT_EQ(Factorial(0), 1);
}

// Tests factorial of positive numbers.
TEST(FactorialTest, HandlesPositiveInput) {
  EXPECT_EQ(Factorial(1), 1);
  EXPECT_EQ(Factorial(2), 2);
  EXPECT_EQ(Factorial(3), 6);
  EXPECT_EQ(Factorial(8), 40320);
}
```

googletest groups the test results by test suites, so logically related tests
should be in the same test suite; in other words, the first argument to their
`TEST()` should be the same. In the above example, we have two tests,
`HandlesZeroInput` and `HandlesPositiveInput`, that belong to the same test
suite `FactorialTest`.

When naming your test suites and tests, you should follow the same convention as
for
[naming functions and classes](https://google.github.io/styleguide/cppguide.html#Function_Names).

**Availability**: Linux, Windows, Mac.

## Test Fixtures: Using the Same Data Configuration for Multiple Tests {#same-data-multiple-tests}

If you find yourself writing two or more tests that operate on similar data, you
can use a *test fixture*. This allows you to reuse the same configuration of
objects for several different tests.

To create a fixture:

1.  Derive a class from `::testing::Test` . Start its body with `protected:`, as
    we'll want to access fixture members from sub-classes.
2.  Inside the class, declare any objects you plan to use.
3.  If necessary, write a default constructor or `SetUp()` function to prepare
    the objects for each test. A common mistake is to spell `SetUp()` as
    **`Setup()`** with a small `u` - Use `override` in C++11 to make sure you
    spelled it correctly.
4.  If necessary, write a destructor or `TearDown()` function to release any
    resources you allocated in `SetUp()` . To learn when you should use the
    constructor/destructor and when you should use `SetUp()/TearDown()`, read
    the [FAQ](faq.md#CtorVsSetUp).
5.  If needed, define subroutines for your tests to share.

When using a fixture, use `TEST_F()` instead of `TEST()` as it allows you to
access objects and subroutines in the test fixture:

```c++
TEST_F(TestFixtureName, TestName) {
  ... test body ...
}
```

Like `TEST()`, the first argument is the test suite name, but for `TEST_F()`
this must be the name of the test fixture class. You've probably guessed: `_F`
is for fixture.

Unfortunately, the C++ macro system does not allow us to create a single macro
that can handle both types of tests. Using the wrong macro causes a compiler
error.

Also, you must first define a test fixture class before using it in a
`TEST_F()`, or you'll get the compiler error "`virtual outside class
declaration`".

For each test defined with `TEST_F()`, googletest will create a *fresh* test
fixture at runtime, immediately initialize it via `SetUp()`, run the test,
clean up by calling `TearDown()`, and then delete the test fixture. Note that
different tests in the same test suite have different test fixture objects, and
googletest always deletes a test fixture before it creates the next one.
googletest does **not** reuse the same test fixture for multiple tests. Any
changes one test makes to the fixture do not affect other tests.

As an example, let's write tests for a FIFO queue class named `Queue`, which has
the following interface:

```c++
template <typename E>  // E is the element type.
class Queue {
 public:
  Queue();
  void Enqueue(const E& element);
  E* Dequeue();  // Returns NULL if the queue is empty.
  size_t size() const;
  ...
};
```

First, define a fixture class. By convention, you should give it the name
`FooTest` where `Foo` is the class being tested.

```c++
class QueueTest : public ::testing::Test {
 protected:
  void SetUp() override {
     q1_.Enqueue(1);
     q2_.Enqueue(2);
     q2_.Enqueue(3);
  }

  // void TearDown() override {}

  Queue<int> q0_;
  Queue<int> q1_;
  Queue<int> q2_;
};
```

In this case, `TearDown()` is not needed since we don't have to clean up after
each test, other than what's already done by the destructor.

Now we'll write tests using `TEST_F()` and this fixture.

```c++
TEST_F(QueueTest, IsEmptyInitially) {
  EXPECT_EQ(q0_.size(), 0);
}

TEST_F(QueueTest, DequeueWorks) {
  int* n = q0_.Dequeue();
  EXPECT_EQ(n, nullptr);

  n = q1_.Dequeue();
  ASSERT_NE(n, nullptr);
  EXPECT_EQ(*n, 1);
  EXPECT_EQ(q1_.size(), 0);
  delete n;

  n = q2_.Dequeue();
  ASSERT_NE(n, nullptr);
  EXPECT_EQ(*n, 2);
  EXPECT_EQ(q2_.size(), 1);
  delete n;
}
```

The above uses both `ASSERT_*` and `EXPECT_*` assertions. The rule of thumb is
to use `EXPECT_*` when you want the test to continue to reveal more errors after
the assertion failure, and use `ASSERT_*` when continuing after failure doesn't
make sense. For example, the second assertion in the `Dequeue` test is
`ASSERT_NE(n, nullptr)`, as we need to dereference the pointer `n` later, which
would lead to a segfault when `n` is `NULL`.

When these tests run, the following happens:

1.  googletest constructs a `QueueTest` object (let's call it `t1`).
2.  `t1.SetUp()` initializes `t1`.
3.  The first test (`IsEmptyInitially`) runs on `t1`.
4.  `t1.TearDown()` cleans up after the test finishes.
5.  `t1` is destructed.
6.  The above steps are repeated on another `QueueTest` object, this time
    running the `DequeueWorks` test.

**Availability**: Linux, Windows, Mac.

## Invoking the Tests

`TEST()` and `TEST_F()` implicitly register their tests with googletest. So,
unlike with many other C++ testing frameworks, you don't have to re-list all
your defined tests in order to run them.

After defining your tests, you can run them with `RUN_ALL_TESTS()`, which
returns `0` if all the tests are successful, or `1` otherwise. Note that
`RUN_ALL_TESTS()` runs *all tests* in your link unit--they can be from
different test suites, or even different source files.

When invoked, the `RUN_ALL_TESTS()` macro:

*   Saves the state of all googletest flags.

*   Creates a test fixture object for the first test.

*   Initializes it via `SetUp()`.

*   Runs the test on the fixture object.

*   Cleans up the fixture via `TearDown()`.

*   Deletes the fixture.

*   Restores the state of all googletest flags.

*   Repeats the above steps for the next test, until all tests have run.

If a fatal failure happens the subsequent steps will be skipped.

{: .callout .important}
> IMPORTANT: You must **not** ignore the return value of `RUN_ALL_TESTS()`, or
> you will get a compiler error. The rationale for this design is that the
> automated testing service determines whether a test has passed based on its
> exit code, not on its stdout/stderr output; thus your `main()` function must
> return the value of `RUN_ALL_TESTS()`.
>
> Also, you should call `RUN_ALL_TESTS()` only **once**. Calling it more than
> once conflicts with some advanced googletest features (e.g., thread-safe
> [death tests](advanced.md#death-tests)) and thus is not supported.

**Availability**: Linux, Windows, Mac.

## Writing the main() Function

Most users should _not_ need to write their own `main` function and instead link
with `gtest_main` (as opposed to with `gtest`), which defines a suitable entry
point. See the end of this section for details. The remainder of this section
should only apply when you need to do something custom before the tests run that
cannot be expressed within the framework of fixtures and test suites.

If you write your own `main` function, it should return the value of
`RUN_ALL_TESTS()`.

You can start from this boilerplate:

```c++
#include "this/package/foo.h"

#include "gtest/gtest.h"

namespace my {
namespace project {
namespace {

// The fixture for testing class Foo.
class FooTest : public ::testing::Test {
 protected:
  // You can remove any or all of the following functions if their bodies would
  // be empty.

  FooTest() {
     // You can do set-up work for each test here.
  }

  ~FooTest() override {
     // You can do clean-up work that doesn't throw exceptions here.
  }

  // If the constructor and destructor are not enough for setting up
  // and cleaning up each test, you can define the following methods:

  void SetUp() override {
     // Code here will be called immediately after the constructor (right
     // before each test).
  }

  void TearDown() override {
     // Code here will be called immediately after each test (right
     // before the destructor).
  }

  // Class members declared here can be used by all tests in the test suite
  // for Foo.
};

// Tests that the Foo::Bar() method does Abc.
TEST_F(FooTest, MethodBarDoesAbc) {
  const std::string input_filepath = "this/package/testdata/myinputfile.dat";
  const std::string output_filepath = "this/package/testdata/myoutputfile.dat";
  Foo f;
  EXPECT_EQ(f.Bar(input_filepath, output_filepath), 0);
}

// Tests that Foo does Xyz.
TEST_F(FooTest, DoesXyz) {
  // Exercises the Xyz feature of Foo.
}

}  // namespace
}  // namespace project
}  // namespace my

int main(int argc, char **argv) {
  ::testing::InitGoogleTest(&argc, argv);
  return RUN_ALL_TESTS();
}
```

The `::testing::InitGoogleTest()` function parses the command line for
googletest flags, and removes all recognized flags. This allows the user to
control a test program's behavior via various flags, which we'll cover in
the [AdvancedGuide](advanced.md). You **must** call this function before calling
`RUN_ALL_TESTS()`, or the flags won't be properly initialized.

On Windows, `InitGoogleTest()` also works with wide strings, so it can be used
in programs compiled in `UNICODE` mode as well.

But maybe you think that writing all those `main` functions is too much work? We
agree with you completely, and that's why Google Test provides a basic
implementation of main(). If it fits your needs, then just link your test with
the `gtest_main` library and you are good to go.

{: .callout .note}
NOTE: `ParseGUnitFlags()` is deprecated in favor of `InitGoogleTest()`.

## Known Limitations

*   Google Test is designed to be thread-safe. The implementation is thread-safe
    on systems where the `pthreads` library is available. It is currently
    _unsafe_ to use Google Test assertions from two threads concurrently on
    other systems (e.g. Windows). In most tests this is not an issue as usually
    the assertions are done in the main thread. If you want to help, you can
    volunteer to implement the necessary synchronization primitives in
    `gtest-port.h` for your platform.
# Supported Platforms

GoogleTest requires a codebase and compiler compliant with the C++11 standard or
newer.

The GoogleTest code is officially supported on the following platforms.
Operating systems or tools not listed below are community-supported. For
community-supported platforms, patches that do not complicate the code may be
considered.

If you notice any problems on your platform, please file an issue on the
[GoogleTest GitHub Issue Tracker](https://github.com/google/googletest/issues).
Pull requests containing fixes are welcome!

### Operating systems

*   Linux
*   macOS
*   Windows

### Compilers

*   gcc 5.0+
*   clang 5.0+
*   MSVC 2015+

**macOS users:** Xcode 9.3+ provides clang 5.0+.

### Build systems

*   [Bazel](https://bazel.build/)
*   [CMake](https://cmake.org/)

Bazel is the build system used by the team internally and in tests. CMake is
supported on a best-effort basis and by the community.
# gMock for Dummies

## What Is gMock?

When you write a prototype or test, often it's not feasible or wise to rely on
real objects entirely. A **mock object** implements the same interface as a real
object (so it can be used as one), but lets you specify at run time how it will
be used and what it should do (which methods will be called? in which order? how
many times? with what arguments? what will they return? etc).

It is easy to confuse the term *fake objects* with mock objects. Fakes and mocks
actually mean very different things in the Test-Driven Development (TDD)
community:

*   **Fake** objects have working implementations, but usually take some
    shortcut (perhaps to make the operations less expensive), which makes them
    not suitable for production. An in-memory file system would be an example of
    a fake.
*   **Mocks** are objects pre-programmed with *expectations*, which form a
    specification of the calls they are expected to receive.

If all this seems too abstract for you, don't worry - the most important thing
to remember is that a mock allows you to check the *interaction* between itself
and code that uses it. The difference between fakes and mocks shall become much
clearer once you start to use mocks.

**gMock** is a library (sometimes we also call it a "framework" to make it sound
cool) for creating mock classes and using them. It does to C++ what
jMock/EasyMock does to Java (well, more or less).

When using gMock,

1.  first, you use some simple macros to describe the interface you want to
    mock, and they will expand to the implementation of your mock class;
2.  next, you create some mock objects and specify its expectations and behavior
    using an intuitive syntax;
3.  then you exercise code that uses the mock objects. gMock will catch any
    violation to the expectations as soon as it arises.

## Why gMock?

While mock objects help you remove unnecessary dependencies in tests and make
them fast and reliable, using mocks manually in C++ is *hard*:

*   Someone has to implement the mocks. The job is usually tedious and
    error-prone. No wonder people go great distance to avoid it.
*   The quality of those manually written mocks is a bit, uh, unpredictable. You
    may see some really polished ones, but you may also see some that were
    hacked up in a hurry and have all sorts of ad hoc restrictions.
*   The knowledge you gained from using one mock doesn't transfer to the next
    one.

In contrast, Java and Python programmers have some fine mock frameworks (jMock,
EasyMock, etc), which automate the creation of mocks. As a result, mocking is a
proven effective technique and widely adopted practice in those communities.
Having the right tool absolutely makes the difference.

gMock was built to help C++ programmers. It was inspired by jMock and EasyMock,
but designed with C++'s specifics in mind. It is your friend if any of the
following problems is bothering you:

*   You are stuck with a sub-optimal design and wish you had done more
    prototyping before it was too late, but prototyping in C++ is by no means
    "rapid".
*   Your tests are slow as they depend on too many libraries or use expensive
    resources (e.g. a database).
*   Your tests are brittle as some resources they use are unreliable (e.g. the
    network).
*   You want to test how your code handles a failure (e.g. a file checksum
    error), but it's not easy to cause one.
*   You need to make sure that your module interacts with other modules in the
    right way, but it's hard to observe the interaction; therefore you resort to
    observing the side effects at the end of the action, but it's awkward at
    best.
*   You want to "mock out" your dependencies, except that they don't have mock
    implementations yet; and, frankly, you aren't thrilled by some of those
    hand-written mocks.

We encourage you to use gMock as

*   a *design* tool, for it lets you experiment with your interface design early
    and often. More iterations lead to better designs!
*   a *testing* tool to cut your tests' outbound dependencies and probe the
    interaction between your module and its collaborators.

## Getting Started

gMock is bundled with googletest.

## A Case for Mock Turtles

Let's look at an example. Suppose you are developing a graphics program that
relies on a [LOGO](http://en.wikipedia.org/wiki/Logo_programming_language)-like
API for drawing. How would you test that it does the right thing? Well, you can
run it and compare the screen with a golden screen snapshot, but let's admit it:
tests like this are expensive to run and fragile (What if you just upgraded to a
shiny new graphics card that has better anti-aliasing? Suddenly you have to
update all your golden images.). It would be too painful if all your tests are
like this. Fortunately, you learned about
[Dependency Injection](http://en.wikipedia.org/wiki/Dependency_injection) and know the right thing
to do: instead of having your application talk to the system API directly, wrap
the API in an interface (say, `Turtle`) and code to that interface:

```cpp
class Turtle {
  ...
  virtual ~Turtle() {}
  virtual void PenUp() = 0;
  virtual void PenDown() = 0;
  virtual void Forward(int distance) = 0;
  virtual void Turn(int degrees) = 0;
  virtual void GoTo(int x, int y) = 0;
  virtual int GetX() const = 0;
  virtual int GetY() const = 0;
};
```

(Note that the destructor of `Turtle` **must** be virtual, as is the case for
**all** classes you intend to inherit from - otherwise the destructor of the
derived class will not be called when you delete an object through a base
pointer, and you'll get corrupted program states like memory leaks.)

You can control whether the turtle's movement will leave a trace using `PenUp()`
and `PenDown()`, and control its movement using `Forward()`, `Turn()`, and
`GoTo()`. Finally, `GetX()` and `GetY()` tell you the current position of the
turtle.

Your program will normally use a real implementation of this interface. In
tests, you can use a mock implementation instead. This allows you to easily
check what drawing primitives your program is calling, with what arguments, and
in which order. Tests written this way are much more robust (they won't break
because your new machine does anti-aliasing differently), easier to read and
maintain (the intent of a test is expressed in the code, not in some binary
images), and run *much, much faster*.

## Writing the Mock Class

If you are lucky, the mocks you need to use have already been implemented by
some nice people. If, however, you find yourself in the position to write a mock
class, relax - gMock turns this task into a fun game! (Well, almost.)

### How to Define It

Using the `Turtle` interface as example, here are the simple steps you need to
follow:

*   Derive a class `MockTurtle` from `Turtle`.
*   Take a *virtual* function of `Turtle` (while it's possible to
    [mock non-virtual methods using templates](gmock_cook_book.md#MockingNonVirtualMethods),
    it's much more involved).
*   In the `public:` section of the child class, write `MOCK_METHOD();`
*   Now comes the fun part: you take the function signature, cut-and-paste it
    into the macro, and add two commas - one between the return type and the
    name, another between the name and the argument list.
*   If you're mocking a const method, add a 4th parameter containing `(const)`
    (the parentheses are required).
*   Since you're overriding a virtual method, we suggest adding the `override`
    keyword. For const methods the 4th parameter becomes `(const, override)`,
    for non-const methods just `(override)`. This isn't mandatory.
*   Repeat until all virtual functions you want to mock are done. (It goes
    without saying that *all* pure virtual methods in your abstract class must
    be either mocked or overridden.)

After the process, you should have something like:

```cpp
#include "gmock/gmock.h"  // Brings in gMock.

class MockTurtle : public Turtle {
 public:
  ...
  MOCK_METHOD(void, PenUp, (), (override));
  MOCK_METHOD(void, PenDown, (), (override));
  MOCK_METHOD(void, Forward, (int distance), (override));
  MOCK_METHOD(void, Turn, (int degrees), (override));
  MOCK_METHOD(void, GoTo, (int x, int y), (override));
  MOCK_METHOD(int, GetX, (), (const, override));
  MOCK_METHOD(int, GetY, (), (const, override));
};
```

You don't need to define these mock methods somewhere else - the `MOCK_METHOD`
macro will generate the definitions for you. It's that simple!

### Where to Put It

When you define a mock class, you need to decide where to put its definition.
Some people put it in a `_test.cc`. This is fine when the interface being mocked
(say, `Foo`) is owned by the same person or team. Otherwise, when the owner of
`Foo` changes it, your test could break. (You can't really expect `Foo`'s
maintainer to fix every test that uses `Foo`, can you?)

So, the rule of thumb is: if you need to mock `Foo` and it's owned by others,
define the mock class in `Foo`'s package (better, in a `testing` sub-package
such that you can clearly separate production code and testing utilities), put
it in a `.h` and a `cc_library`. Then everyone can reference them from their
tests. If `Foo` ever changes, there is only one copy of `MockFoo` to change, and
only tests that depend on the changed methods need to be fixed.

Another way to do it: you can introduce a thin layer `FooAdaptor` on top of
`Foo` and code to this new interface. Since you own `FooAdaptor`, you can absorb
changes in `Foo` much more easily. While this is more work initially, carefully
choosing the adaptor interface can make your code easier to write and more
readable (a net win in the long run), as you can choose `FooAdaptor` to fit your
specific domain much better than `Foo` does.

## Using Mocks in Tests

Once you have a mock class, using it is easy. The typical work flow is:

1.  Import the gMock names from the `testing` namespace such that you can use
    them unqualified (You only have to do it once per file). Remember that
    namespaces are a good idea.
2.  Create some mock objects.
3.  Specify your expectations on them (How many times will a method be called?
    With what arguments? What should it do? etc.).
4.  Exercise some code that uses the mocks; optionally, check the result using
    googletest assertions. If a mock method is called more than expected or with
    wrong arguments, you'll get an error immediately.
5.  When a mock is destructed, gMock will automatically check whether all
    expectations on it have been satisfied.

Here's an example:

```cpp
#include "path/to/mock-turtle.h"
#include "gmock/gmock.h"
#include "gtest/gtest.h"

using ::testing::AtLeast;                         // #1

TEST(PainterTest, CanDrawSomething) {
  MockTurtle turtle;                              // #2
  EXPECT_CALL(turtle, PenDown())                  // #3
      .Times(AtLeast(1));

  Painter painter(&turtle);                       // #4

  EXPECT_TRUE(painter.DrawCircle(0, 0, 10));      // #5
}
```

As you might have guessed, this test checks that `PenDown()` is called at least
once. If the `painter` object didn't call this method, your test will fail with
a message like this:

```text
path/to/my_test.cc:119: Failure
Actual function call count doesn't match this expectation:
Actually: never called;
Expected: called at least once.
Stack trace:
...
```

**Tip 1:** If you run the test from an Emacs buffer, you can hit `<Enter>` on
the line number to jump right to the failed expectation.

**Tip 2:** If your mock objects are never deleted, the final verification won't
happen. Therefore it's a good idea to turn on the heap checker in your tests
when you allocate mocks on the heap. You get that automatically if you use the
`gtest_main` library already.

**Important note:** gMock requires expectations to be set **before** the mock
functions are called, otherwise the behavior is **undefined**. Do not alternate
between calls to `EXPECT_CALL()` and calls to the mock functions, and do not set
any expectations on a mock after passing the mock to an API.

This means `EXPECT_CALL()` should be read as expecting that a call will occur
*in the future*, not that a call has occurred. Why does gMock work like that?
Well, specifying the expectation beforehand allows gMock to report a violation
as soon as it rises, when the context (stack trace, etc) is still available.
This makes debugging much easier.

Admittedly, this test is contrived and doesn't do much. You can easily achieve
the same effect without using gMock. However, as we shall reveal soon, gMock
allows you to do *so much more* with the mocks.

## Setting Expectations

The key to using a mock object successfully is to set the *right expectations*
on it. If you set the expectations too strict, your test will fail as the result
of unrelated changes. If you set them too loose, bugs can slip through. You want
to do it just right such that your test can catch exactly the kind of bugs you
intend it to catch. gMock provides the necessary means for you to do it "just
right."

### General Syntax

In gMock we use the `EXPECT_CALL()` macro to set an expectation on a mock
method. The general syntax is:

```cpp
EXPECT_CALL(mock_object, method(matchers))
    .Times(cardinality)
    .WillOnce(action)
    .WillRepeatedly(action);
```

The macro has two arguments: first the mock object, and then the method and its
arguments. Note that the two are separated by a comma (`,`), not a period (`.`).
(Why using a comma? The answer is that it was necessary for technical reasons.)
If the method is not overloaded, the macro can also be called without matchers:

```cpp
EXPECT_CALL(mock_object, non-overloaded-method)
    .Times(cardinality)
    .WillOnce(action)
    .WillRepeatedly(action);
```

This syntax allows the test writer to specify "called with any arguments"
without explicitly specifying the number or types of arguments. To avoid
unintended ambiguity, this syntax may only be used for methods that are not
overloaded.

Either form of the macro can be followed by some optional *clauses* that provide
more information about the expectation. We'll discuss how each clause works in
the coming sections.

This syntax is designed to make an expectation read like English. For example,
you can probably guess that

```cpp
using ::testing::Return;
...
EXPECT_CALL(turtle, GetX())
    .Times(5)
    .WillOnce(Return(100))
    .WillOnce(Return(150))
    .WillRepeatedly(Return(200));
```

says that the `turtle` object's `GetX()` method will be called five times, it
will return 100 the first time, 150 the second time, and then 200 every time.
Some people like to call this style of syntax a Domain-Specific Language (DSL).

{: .callout .note}
**Note:** Why do we use a macro to do this? Well it serves two purposes: first
it makes expectations easily identifiable (either by `grep` or by a human
reader), and second it allows gMock to include the source file location of a
failed expectation in messages, making debugging easier.

### Matchers: What Arguments Do We Expect?

When a mock function takes arguments, we may specify what arguments we are
expecting, for example:

```cpp
// Expects the turtle to move forward by 100 units.
EXPECT_CALL(turtle, Forward(100));
```

Oftentimes you do not want to be too specific. Remember that talk about tests
being too rigid? Over specification leads to brittle tests and obscures the
intent of tests. Therefore we encourage you to specify only what's necessary—no
more, no less. If you aren't interested in the value of an argument, write `_`
as the argument, which means "anything goes":

```cpp
using ::testing::_;
...
// Expects that the turtle jumps to somewhere on the x=50 line.
EXPECT_CALL(turtle, GoTo(50, _));
```

`_` is an instance of what we call **matchers**. A matcher is like a predicate
and can test whether an argument is what we'd expect. You can use a matcher
inside `EXPECT_CALL()` wherever a function argument is expected. `_` is a
convenient way of saying "any value".

In the above examples, `100` and `50` are also matchers; implicitly, they are
the same as `Eq(100)` and `Eq(50)`, which specify that the argument must be
equal (using `operator==`) to the matcher argument. There are many
[built-in matchers](reference/matchers.md) for common types (as well as
[custom matchers](gmock_cook_book.md#NewMatchers)); for example:

```cpp
using ::testing::Ge;
...
// Expects the turtle moves forward by at least 100.
EXPECT_CALL(turtle, Forward(Ge(100)));
```

If you don't care about *any* arguments, rather than specify `_` for each of
them you may instead omit the parameter list:

```cpp
// Expects the turtle to move forward.
EXPECT_CALL(turtle, Forward);
// Expects the turtle to jump somewhere.
EXPECT_CALL(turtle, GoTo);
```

This works for all non-overloaded methods; if a method is overloaded, you need
to help gMock resolve which overload is expected by specifying the number of
arguments and possibly also the
[types of the arguments](gmock_cook_book.md#SelectOverload).

### Cardinalities: How Many Times Will It Be Called?

The first clause we can specify following an `EXPECT_CALL()` is `Times()`. We
call its argument a **cardinality** as it tells *how many times* the call should
occur. It allows us to repeat an expectation many times without actually writing
it as many times. More importantly, a cardinality can be "fuzzy", just like a
matcher can be. This allows a user to express the intent of a test exactly.

An interesting special case is when we say `Times(0)`. You may have guessed - it
means that the function shouldn't be called with the given arguments at all, and
gMock will report a googletest failure whenever the function is (wrongfully)
called.

We've seen `AtLeast(n)` as an example of fuzzy cardinalities earlier. For the
list of built-in cardinalities you can use, see
[here](gmock_cheat_sheet.md#CardinalityList).

The `Times()` clause can be omitted. **If you omit `Times()`, gMock will infer
the cardinality for you.** The rules are easy to remember:

*   If **neither** `WillOnce()` **nor** `WillRepeatedly()` is in the
    `EXPECT_CALL()`, the inferred cardinality is `Times(1)`.
*   If there are *n* `WillOnce()`'s but **no** `WillRepeatedly()`, where *n* >=
    1, the cardinality is `Times(n)`.
*   If there are *n* `WillOnce()`'s and **one** `WillRepeatedly()`, where *n* >=
    0, the cardinality is `Times(AtLeast(n))`.

**Quick quiz:** what do you think will happen if a function is expected to be
called twice but actually called four times?

### Actions: What Should It Do?

Remember that a mock object doesn't really have a working implementation? We as
users have to tell it what to do when a method is invoked. This is easy in
gMock.

First, if the return type of a mock function is a built-in type or a pointer,
the function has a **default action** (a `void` function will just return, a
`bool` function will return `false`, and other functions will return 0). In
addition, in C++ 11 and above, a mock function whose return type is
default-constructible (i.e. has a default constructor) has a default action of
returning a default-constructed value. If you don't say anything, this behavior
will be used.

Second, if a mock function doesn't have a default action, or the default action
doesn't suit you, you can specify the action to be taken each time the
expectation matches using a series of `WillOnce()` clauses followed by an
optional `WillRepeatedly()`. For example,

```cpp
using ::testing::Return;
...
EXPECT_CALL(turtle, GetX())
     .WillOnce(Return(100))
     .WillOnce(Return(200))
     .WillOnce(Return(300));
```

says that `turtle.GetX()` will be called *exactly three times* (gMock inferred
this from how many `WillOnce()` clauses we've written, since we didn't
explicitly write `Times()`), and will return 100, 200, and 300 respectively.

```cpp
using ::testing::Return;
...
EXPECT_CALL(turtle, GetY())
     .WillOnce(Return(100))
     .WillOnce(Return(200))
     .WillRepeatedly(Return(300));
```

says that `turtle.GetY()` will be called *at least twice* (gMock knows this as
we've written two `WillOnce()` clauses and a `WillRepeatedly()` while having no
explicit `Times()`), will return 100 and 200 respectively the first two times,
and 300 from the third time on.

Of course, if you explicitly write a `Times()`, gMock will not try to infer the
cardinality itself. What if the number you specified is larger than there are
`WillOnce()` clauses? Well, after all `WillOnce()`s are used up, gMock will do
the *default* action for the function every time (unless, of course, you have a
`WillRepeatedly()`.).

What can we do inside `WillOnce()` besides `Return()`? You can return a
reference using `ReturnRef(`*`variable`*`)`, or invoke a pre-defined function,
among [others](gmock_cook_book.md#using-actions).

**Important note:** The `EXPECT_CALL()` statement evaluates the action clause
only once, even though the action may be performed many times. Therefore you
must be careful about side effects. The following may not do what you want:

```cpp
using ::testing::Return;
...
int n = 100;
EXPECT_CALL(turtle, GetX())
    .Times(4)
    .WillRepeatedly(Return(n++));
```

Instead of returning 100, 101, 102, ..., consecutively, this mock function will
always return 100 as `n++` is only evaluated once. Similarly, `Return(new Foo)`
will create a new `Foo` object when the `EXPECT_CALL()` is executed, and will
return the same pointer every time. If you want the side effect to happen every
time, you need to define a custom action, which we'll teach in the
[cook book](gmock_cook_book.md).

Time for another quiz! What do you think the following means?

```cpp
using ::testing::Return;
...
EXPECT_CALL(turtle, GetY())
    .Times(4)
    .WillOnce(Return(100));
```

Obviously `turtle.GetY()` is expected to be called four times. But if you think
it will return 100 every time, think twice! Remember that one `WillOnce()`
clause will be consumed each time the function is invoked and the default action
will be taken afterwards. So the right answer is that `turtle.GetY()` will
return 100 the first time, but **return 0 from the second time on**, as
returning 0 is the default action for `int` functions.

### Using Multiple Expectations {#MultiExpectations}

So far we've only shown examples where you have a single expectation. More
realistically, you'll specify expectations on multiple mock methods which may be
from multiple mock objects.

By default, when a mock method is invoked, gMock will search the expectations in
the **reverse order** they are defined, and stop when an active expectation that
matches the arguments is found (you can think of it as "newer rules override
older ones."). If the matching expectation cannot take any more calls, you will
get an upper-bound-violated failure. Here's an example:

```cpp
using ::testing::_;
...
EXPECT_CALL(turtle, Forward(_));  // #1
EXPECT_CALL(turtle, Forward(10))  // #2
    .Times(2);
```

If `Forward(10)` is called three times in a row, the third time it will be an
error, as the last matching expectation (#2) has been saturated. If, however,
the third `Forward(10)` call is replaced by `Forward(20)`, then it would be OK,
as now #1 will be the matching expectation.

{: .callout .note}
**Note:** Why does gMock search for a match in the *reverse* order of the
expectations? The reason is that this allows a user to set up the default
expectations in a mock object's constructor or the test fixture's set-up phase
and then customize the mock by writing more specific expectations in the test
body. So, if you have two expectations on the same method, you want to put the
one with more specific matchers **after** the other, or the more specific rule
would be shadowed by the more general one that comes after it.

{: .callout .tip}
**Tip:** It is very common to start with a catch-all expectation for a method
and `Times(AnyNumber())` (omitting arguments, or with `_` for all arguments, if
overloaded). This makes any calls to the method expected. This is not necessary
for methods that are not mentioned at all (these are "uninteresting"), but is
useful for methods that have some expectations, but for which other calls are
ok. See
[Understanding Uninteresting vs Unexpected Calls](gmock_cook_book.md#uninteresting-vs-unexpected).

### Ordered vs Unordered Calls {#OrderedCalls}

By default, an expectation can match a call even though an earlier expectation
hasn't been satisfied. In other words, the calls don't have to occur in the
order the expectations are specified.

Sometimes, you may want all the expected calls to occur in a strict order. To
say this in gMock is easy:

```cpp
using ::testing::InSequence;
...
TEST(FooTest, DrawsLineSegment) {
  ...
  {
    InSequence seq;

    EXPECT_CALL(turtle, PenDown());
    EXPECT_CALL(turtle, Forward(100));
    EXPECT_CALL(turtle, PenUp());
  }
  Foo();
}
```

By creating an object of type `InSequence`, all expectations in its scope are
put into a *sequence* and have to occur *sequentially*. Since we are just
relying on the constructor and destructor of this object to do the actual work,
its name is really irrelevant.

In this example, we test that `Foo()` calls the three expected functions in the
order as written. If a call is made out-of-order, it will be an error.

(What if you care about the relative order of some of the calls, but not all of
them? Can you specify an arbitrary partial order? The answer is ... yes! The
details can be found [here](gmock_cook_book.md#OrderedCalls).)

### All Expectations Are Sticky (Unless Said Otherwise) {#StickyExpectations}

Now let's do a quick quiz to see how well you can use this mock stuff already.
How would you test that the turtle is asked to go to the origin *exactly twice*
(you want to ignore any other instructions it receives)?

After you've come up with your answer, take a look at ours and compare notes
(solve it yourself first - don't cheat!):

```cpp
using ::testing::_;
using ::testing::AnyNumber;
...
EXPECT_CALL(turtle, GoTo(_, _))  // #1
     .Times(AnyNumber());
EXPECT_CALL(turtle, GoTo(0, 0))  // #2
     .Times(2);
```

Suppose `turtle.GoTo(0, 0)` is called three times. In the third time, gMock will
see that the arguments match expectation #2 (remember that we always pick the
last matching expectation). Now, since we said that there should be only two
such calls, gMock will report an error immediately. This is basically what we've
told you in the [Using Multiple Expectations](#MultiExpectations) section above.

This example shows that **expectations in gMock are "sticky" by default**, in
the sense that they remain active even after we have reached their invocation
upper bounds. This is an important rule to remember, as it affects the meaning
of the spec, and is **different** to how it's done in many other mocking
frameworks (Why'd we do that? Because we think our rule makes the common cases
easier to express and understand.).

Simple? Let's see if you've really understood it: what does the following code
say?

```cpp
using ::testing::Return;
...
for (int i = n; i > 0; i--) {
  EXPECT_CALL(turtle, GetX())
      .WillOnce(Return(10*i));
}
```

If you think it says that `turtle.GetX()` will be called `n` times and will
return 10, 20, 30, ..., consecutively, think twice! The problem is that, as we
said, expectations are sticky. So, the second time `turtle.GetX()` is called,
the last (latest) `EXPECT_CALL()` statement will match, and will immediately
lead to an "upper bound violated" error - this piece of code is not very useful!

One correct way of saying that `turtle.GetX()` will return 10, 20, 30, ..., is
to explicitly say that the expectations are *not* sticky. In other words, they
should *retire* as soon as they are saturated:

```cpp
using ::testing::Return;
...
for (int i = n; i > 0; i--) {
  EXPECT_CALL(turtle, GetX())
      .WillOnce(Return(10*i))
      .RetiresOnSaturation();
}
```

And, there's a better way to do it: in this case, we expect the calls to occur
in a specific order, and we line up the actions to match the order. Since the
order is important here, we should make it explicit using a sequence:

```cpp
using ::testing::InSequence;
using ::testing::Return;
...
{
  InSequence s;

  for (int i = 1; i <= n; i++) {
    EXPECT_CALL(turtle, GetX())
        .WillOnce(Return(10*i))
        .RetiresOnSaturation();
  }
}
```

By the way, the other situation where an expectation may *not* be sticky is when
it's in a sequence - as soon as another expectation that comes after it in the
sequence has been used, it automatically retires (and will never be used to
match any call).

### Uninteresting Calls

A mock object may have many methods, and not all of them are that interesting.
For example, in some tests we may not care about how many times `GetX()` and
`GetY()` get called.

In gMock, if you are not interested in a method, just don't say anything about
it. If a call to this method occurs, you'll see a warning in the test output,
but it won't be a failure. This is called "naggy" behavior; to change, see
[The Nice, the Strict, and the Naggy](gmock_cook_book.md#NiceStrictNaggy).
# Quickstart: Building with CMake

This tutorial aims to get you up and running with GoogleTest using CMake. If
you're using GoogleTest for the first time or need a refresher, we recommend
this tutorial as a starting point. If your project uses Bazel, see the
[Quickstart for Bazel](quickstart-bazel.md) instead.

## Prerequisites

To complete this tutorial, you'll need:

*   A compatible operating system (e.g. Linux, macOS, Windows).
*   A compatible C++ compiler that supports at least C++11.
*   [CMake](https://cmake.org/) and a compatible build tool for building the
    project.
    *   Compatible build tools include
        [Make](https://www.gnu.org/software/make/),
        [Ninja](https://ninja-build.org/), and others - see
        [CMake Generators](https://cmake.org/cmake/help/latest/manual/cmake-generators.7.html)
        for more information.

See [Supported Platforms](platforms.md) for more information about platforms
compatible with GoogleTest.

If you don't already have CMake installed, see the
[CMake installation guide](https://cmake.org/install).

{: .callout .note}
Note: The terminal commands in this tutorial show a Unix shell prompt, but the
commands work on the Windows command line as well.

## Set up a project

CMake uses a file named `CMakeLists.txt` to configure the build system for a
project. You'll use this file to set up your project and declare a dependency on
GoogleTest.

First, create a directory for your project:

```
$ mkdir my_project && cd my_project
```

Next, you'll create the `CMakeLists.txt` file and declare a dependency on
GoogleTest. There are many ways to express dependencies in the CMake ecosystem;
in this quickstart, you'll use the
[`FetchContent` CMake module](https://cmake.org/cmake/help/latest/module/FetchContent.html).
To do this, in your project directory (`my_project`), create a file named
`CMakeLists.txt` with the following contents:

```cmake
cmake_minimum_required(VERSION 3.14)
project(my_project)

# GoogleTest requires at least C++11
set(CMAKE_CXX_STANDARD 11)

include(FetchContent)
FetchContent_Declare(
  googletest
  URL https://github.com/google/googletest/archive/609281088cfefc76f9d0ce82e1ff6c30cc3591e5.zip
)
# For Windows: Prevent overriding the parent project's compiler/linker settings
set(gtest_force_shared_crt ON CACHE BOOL "" FORCE)
FetchContent_MakeAvailable(googletest)
```

The above configuration declares a dependency on GoogleTest which is downloaded
from GitHub. In the above example, `609281088cfefc76f9d0ce82e1ff6c30cc3591e5` is
the Git commit hash of the GoogleTest version to use; we recommend updating the
hash often to point to the latest version.

For more information about how to create `CMakeLists.txt` files, see the
[CMake Tutorial](https://cmake.org/cmake/help/latest/guide/tutorial/index.html).

## Create and run a binary

With GoogleTest declared as a dependency, you can use GoogleTest code within
your own project.

As an example, create a file named `hello_test.cc` in your `my_project`
directory with the following contents:

```cpp
#include <gtest/gtest.h>

// Demonstrate some basic assertions.
TEST(HelloTest, BasicAssertions) {
  // Expect two strings not to be equal.
  EXPECT_STRNE("hello", "world");
  // Expect equality.
  EXPECT_EQ(7 * 6, 42);
}
```

GoogleTest provides [assertions](primer.md#assertions) that you use to test the
behavior of your code. The above sample includes the main GoogleTest header file
and demonstrates some basic assertions.

To build the code, add the following to the end of your `CMakeLists.txt` file:

```cmake
enable_testing()

add_executable(
  hello_test
  hello_test.cc
)
target_link_libraries(
  hello_test
  gtest_main
)

include(GoogleTest)
gtest_discover_tests(hello_test)
```

The above configuration enables testing in CMake, declares the C++ test binary
you want to build (`hello_test`), and links it to GoogleTest (`gtest_main`). The
last two lines enable CMake's test runner to discover the tests included in the
binary, using the
[`GoogleTest` CMake module](https://cmake.org/cmake/help/git-stage/module/GoogleTest.html).

Now you can build and run your test:

<pre>
<strong>my_project$ cmake -S . -B build</strong>
-- The C compiler identification is GNU 10.2.1
-- The CXX compiler identification is GNU 10.2.1
...
-- Build files have been written to: .../my_project/build

<strong>my_project$ cmake --build build</strong>
Scanning dependencies of target gtest
...
[100%] Built target gmock_main

<strong>my_project$ cd build && ctest</strong>
Test project .../my_project/build
    Start 1: HelloTest.BasicAssertions
1/1 Test #1: HelloTest.BasicAssertions ........   Passed    0.00 sec

100% tests passed, 0 tests failed out of 1

Total Test time (real) =   0.01 sec
</pre>

Congratulations! You've successfully built and run a test binary using
GoogleTest.

## Next steps

*   [Check out the Primer](primer.md) to start learning how to write simple
    tests.
*   [See the code samples](samples.md) for more examples showing how to use a
    variety of GoogleTest features.
# GoogleTest User's Guide

## Welcome to GoogleTest!

GoogleTest is Google's C++ testing and mocking framework. This user's guide has
the following contents:

*   [GoogleTest Primer](primer.md) - Teaches you how to write simple tests using
    GoogleTest. Read this first if you are new to GoogleTest.
*   [GoogleTest Advanced](advanced.md) - Read this when you've finished the
    Primer and want to utilize GoogleTest to its full potential.
*   [GoogleTest Samples](samples.md) - Describes some GoogleTest samples.
*   [GoogleTest FAQ](faq.md) - Have a question? Want some tips? Check here
    first.
*   [Mocking for Dummies](gmock_for_dummies.md) - Teaches you how to create mock
    objects and use them in tests.
*   [Mocking Cookbook](gmock_cook_book.md) - Includes tips and approaches to
    common mocking use cases.
*   [Mocking Cheat Sheet](gmock_cheat_sheet.md) - A handy reference for
    matchers, actions, invariants, and more.
*   [Mocking FAQ](gmock_faq.md) - Contains answers to some mocking-specific
    questions.
# Legacy gMock FAQ

### When I call a method on my mock object, the method for the real object is invoked instead. What's the problem?

In order for a method to be mocked, it must be *virtual*, unless you use the
[high-perf dependency injection technique](gmock_cook_book.md#MockingNonVirtualMethods).

### Can I mock a variadic function?

You cannot mock a variadic function (i.e. a function taking ellipsis (`...`)
arguments) directly in gMock.

The problem is that in general, there is *no way* for a mock object to know how
many arguments are passed to the variadic method, and what the arguments' types
are. Only the *author of the base class* knows the protocol, and we cannot look
into his or her head.

Therefore, to mock such a function, the *user* must teach the mock object how to
figure out the number of arguments and their types. One way to do it is to
provide overloaded versions of the function.

Ellipsis arguments are inherited from C and not really a C++ feature. They are
unsafe to use and don't work with arguments that have constructors or
destructors. Therefore we recommend to avoid them in C++ as much as possible.

### MSVC gives me warning C4301 or C4373 when I define a mock method with a const parameter. Why?

If you compile this using Microsoft Visual C++ 2005 SP1:

```cpp
class Foo {
  ...
  virtual void Bar(const int i) = 0;
};

class MockFoo : public Foo {
  ...
  MOCK_METHOD(void, Bar, (const int i), (override));
};
```

You may get the following warning:

```shell
warning C4301: 'MockFoo::Bar': overriding virtual function only differs from 'Foo::Bar' by const/volatile qualifier
```

This is a MSVC bug. The same code compiles fine with gcc, for example. If you
use Visual C++ 2008 SP1, you would get the warning:

```shell
warning C4373: 'MockFoo::Bar': virtual function overrides 'Foo::Bar', previous versions of the compiler did not override when parameters only differed by const/volatile qualifiers
```

In C++, if you *declare* a function with a `const` parameter, the `const`
modifier is ignored. Therefore, the `Foo` base class above is equivalent to:

```cpp
class Foo {
  ...
  virtual void Bar(int i) = 0;  // int or const int?  Makes no difference.
};
```

In fact, you can *declare* `Bar()` with an `int` parameter, and define it with a
`const int` parameter. The compiler will still match them up.

Since making a parameter `const` is meaningless in the method declaration, we
recommend to remove it in both `Foo` and `MockFoo`. That should workaround the
VC bug.

Note that we are talking about the *top-level* `const` modifier here. If the
function parameter is passed by pointer or reference, declaring the pointee or
referee as `const` is still meaningful. For example, the following two
declarations are *not* equivalent:

```cpp
void Bar(int* p);         // Neither p nor *p is const.
void Bar(const int* p);  // p is not const, but *p is.
```

### I can't figure out why gMock thinks my expectations are not satisfied. What should I do?

You might want to run your test with `--gmock_verbose=info`. This flag lets
gMock print a trace of every mock function call it receives. By studying the
trace, you'll gain insights on why the expectations you set are not met.

If you see the message "The mock function has no default action set, and its
return type has no default value set.", then try
[adding a default action](gmock_cheat_sheet.md#OnCall). Due to a known issue,
unexpected calls on mocks without default actions don't print out a detailed
comparison between the actual arguments and the expected arguments.

### My program crashed and `ScopedMockLog` spit out tons of messages. Is it a gMock bug?

gMock and `ScopedMockLog` are likely doing the right thing here.

When a test crashes, the failure signal handler will try to log a lot of
information (the stack trace, and the address map, for example). The messages
are compounded if you have many threads with depth stacks. When `ScopedMockLog`
intercepts these messages and finds that they don't match any expectations, it
prints an error for each of them.

You can learn to ignore the errors, or you can rewrite your expectations to make
your test more robust, for example, by adding something like:

```cpp
using ::testing::AnyNumber;
using ::testing::Not;
...
  // Ignores any log not done by us.
  EXPECT_CALL(log, Log(_, Not(EndsWith("/my_file.cc")), _))
      .Times(AnyNumber());
```

### How can I assert that a function is NEVER called?

```cpp
using ::testing::_;
...
  EXPECT_CALL(foo, Bar(_))
      .Times(0);
```

### I have a failed test where gMock tells me TWICE that a particular expectation is not satisfied. Isn't this redundant?

When gMock detects a failure, it prints relevant information (the mock function
arguments, the state of relevant expectations, and etc) to help the user debug.
If another failure is detected, gMock will do the same, including printing the
state of relevant expectations.

Sometimes an expectation's state didn't change between two failures, and you'll
see the same description of the state twice. They are however *not* redundant,
as they refer to *different points in time*. The fact they are the same *is*
interesting information.

### I get a heapcheck failure when using a mock object, but using a real object is fine. What can be wrong?

Does the class (hopefully a pure interface) you are mocking have a virtual
destructor?

Whenever you derive from a base class, make sure its destructor is virtual.
Otherwise Bad Things will happen. Consider the following code:

```cpp
class Base {
 public:
  // Not virtual, but should be.
  ~Base() { ... }
  ...
};

class Derived : public Base {
 public:
  ...
 private:
  std::string value_;
};

...
  Base* p = new Derived;
  ...
  delete p;  // Surprise! ~Base() will be called, but ~Derived() will not
                 // - value_ is leaked.
```

By changing `~Base()` to virtual, `~Derived()` will be correctly called when
`delete p` is executed, and the heap checker will be happy.

### The "newer expectations override older ones" rule makes writing expectations awkward. Why does gMock do that?

When people complain about this, often they are referring to code like:

```cpp
using ::testing::Return;
...
  // foo.Bar() should be called twice, return 1 the first time, and return
  // 2 the second time.  However, I have to write the expectations in the
  // reverse order.  This sucks big time!!!
  EXPECT_CALL(foo, Bar())
      .WillOnce(Return(2))
      .RetiresOnSaturation();
  EXPECT_CALL(foo, Bar())
      .WillOnce(Return(1))
      .RetiresOnSaturation();
```

The problem, is that they didn't pick the **best** way to express the test's
intent.

By default, expectations don't have to be matched in *any* particular order. If
you want them to match in a certain order, you need to be explicit. This is
gMock's (and jMock's) fundamental philosophy: it's easy to accidentally
over-specify your tests, and we want to make it harder to do so.

There are two better ways to write the test spec. You could either put the
expectations in sequence:

```cpp
using ::testing::Return;
...
  // foo.Bar() should be called twice, return 1 the first time, and return
  // 2 the second time.  Using a sequence, we can write the expectations
  // in their natural order.
  {
    InSequence s;
    EXPECT_CALL(foo, Bar())
        .WillOnce(Return(1))
        .RetiresOnSaturation();
    EXPECT_CALL(foo, Bar())
        .WillOnce(Return(2))
        .RetiresOnSaturation();
  }
```

or you can put the sequence of actions in the same expectation:

```cpp
using ::testing::Return;
...
  // foo.Bar() should be called twice, return 1 the first time, and return
  // 2 the second time.
  EXPECT_CALL(foo, Bar())
      .WillOnce(Return(1))
      .WillOnce(Return(2))
      .RetiresOnSaturation();
```

Back to the original questions: why does gMock search the expectations (and
`ON_CALL`s) from back to front? Because this allows a user to set up a mock's
behavior for the common case early (e.g. in the mock's constructor or the test
fixture's set-up phase) and customize it with more specific rules later. If
gMock searches from front to back, this very useful pattern won't be possible.

### gMock prints a warning when a function without EXPECT_CALL is called, even if I have set its behavior using ON_CALL. Would it be reasonable not to show the warning in this case?

When choosing between being neat and being safe, we lean toward the latter. So
the answer is that we think it's better to show the warning.

Often people write `ON_CALL`s in the mock object's constructor or `SetUp()`, as
the default behavior rarely changes from test to test. Then in the test body
they set the expectations, which are often different for each test. Having an
`ON_CALL` in the set-up part of a test doesn't mean that the calls are expected.
If there's no `EXPECT_CALL` and the method is called, it's possibly an error. If
we quietly let the call go through without notifying the user, bugs may creep in
unnoticed.

If, however, you are sure that the calls are OK, you can write

```cpp
using ::testing::_;
...
  EXPECT_CALL(foo, Bar(_))
      .WillRepeatedly(...);
```

instead of

```cpp
using ::testing::_;
...
  ON_CALL(foo, Bar(_))
      .WillByDefault(...);
```

This tells gMock that you do expect the calls and no warning should be printed.

Also, you can control the verbosity by specifying `--gmock_verbose=error`. Other
values are `info` and `warning`. If you find the output too noisy when
debugging, just choose a less verbose level.

### How can I delete the mock function's argument in an action?

If your mock function takes a pointer argument and you want to delete that
argument, you can use testing::DeleteArg<N>() to delete the N'th (zero-indexed)
argument:

```cpp
using ::testing::_;
  ...
  MOCK_METHOD(void, Bar, (X* x, const Y& y));
  ...
  EXPECT_CALL(mock_foo_, Bar(_, _))
      .WillOnce(testing::DeleteArg<0>()));
```

### How can I perform an arbitrary action on a mock function's argument?

If you find yourself needing to perform some action that's not supported by
gMock directly, remember that you can define your own actions using
[`MakeAction()`](#NewMonoActions) or
[`MakePolymorphicAction()`](#NewPolyActions), or you can write a stub function
and invoke it using [`Invoke()`](#FunctionsAsActions).

```cpp
using ::testing::_;
using ::testing::Invoke;
  ...
  MOCK_METHOD(void, Bar, (X* p));
  ...
  EXPECT_CALL(mock_foo_, Bar(_))
      .WillOnce(Invoke(MyAction(...)));
```

### My code calls a static/global function. Can I mock it?

You can, but you need to make some changes.

In general, if you find yourself needing to mock a static function, it's a sign
that your modules are too tightly coupled (and less flexible, less reusable,
less testable, etc). You are probably better off defining a small interface and
call the function through that interface, which then can be easily mocked. It's
a bit of work initially, but usually pays for itself quickly.

This Google Testing Blog
[post](https://testing.googleblog.com/2008/06/defeat-static-cling.html) says it
excellently. Check it out.

### My mock object needs to do complex stuff. It's a lot of pain to specify the actions. gMock sucks!

I know it's not a question, but you get an answer for free any way. :-)

With gMock, you can create mocks in C++ easily. And people might be tempted to
use them everywhere. Sometimes they work great, and sometimes you may find them,
well, a pain to use. So, what's wrong in the latter case?

When you write a test without using mocks, you exercise the code and assert that
it returns the correct value or that the system is in an expected state. This is
sometimes called "state-based testing".

Mocks are great for what some call "interaction-based" testing: instead of
checking the system state at the very end, mock objects verify that they are
invoked the right way and report an error as soon as it arises, giving you a
handle on the precise context in which the error was triggered. This is often
more effective and economical to do than state-based testing.

If you are doing state-based testing and using a test double just to simulate
the real object, you are probably better off using a fake. Using a mock in this
case causes pain, as it's not a strong point for mocks to perform complex
actions. If you experience this and think that mocks suck, you are just not
using the right tool for your problem. Or, you might be trying to solve the
wrong problem. :-)

### I got a warning "Uninteresting function call encountered - default action taken.." Should I panic?

By all means, NO! It's just an FYI. :-)

What it means is that you have a mock function, you haven't set any expectations
on it (by gMock's rule this means that you are not interested in calls to this
function and therefore it can be called any number of times), and it is called.
That's OK - you didn't say it's not OK to call the function!

What if you actually meant to disallow this function to be called, but forgot to
write `EXPECT_CALL(foo, Bar()).Times(0)`? While one can argue that it's the
user's fault, gMock tries to be nice and prints you a note.

So, when you see the message and believe that there shouldn't be any
uninteresting calls, you should investigate what's going on. To make your life
easier, gMock dumps the stack trace when an uninteresting call is encountered.
From that you can figure out which mock function it is, and how it is called.

### I want to define a custom action. Should I use Invoke() or implement the ActionInterface interface?

Either way is fine - you want to choose the one that's more convenient for your
circumstance.

Usually, if your action is for a particular function type, defining it using
`Invoke()` should be easier; if your action can be used in functions of
different types (e.g. if you are defining `Return(*value*)`),
`MakePolymorphicAction()` is easiest. Sometimes you want precise control on what
types of functions the action can be used in, and implementing `ActionInterface`
is the way to go here. See the implementation of `Return()` in
`testing/base/public/gmock-actions.h` for an example.

### I use SetArgPointee() in WillOnce(), but gcc complains about "conflicting return type specified". What does it mean?

You got this error as gMock has no idea what value it should return when the
mock method is called. `SetArgPointee()` says what the side effect is, but
doesn't say what the return value should be. You need `DoAll()` to chain a
`SetArgPointee()` with a `Return()` that provides a value appropriate to the API
being mocked.

See this [recipe](gmock_cook_book.md#mocking-side-effects) for more details and
an example.

### I have a huge mock class, and Microsoft Visual C++ runs out of memory when compiling it. What can I do?

We've noticed that when the `/clr` compiler flag is used, Visual C++ uses 5~6
times as much memory when compiling a mock class. We suggest to avoid `/clr`
when compiling native C++ mocks.
# gMock Cookbook

You can find recipes for using gMock here. If you haven't yet, please read
[the dummy guide](gmock_for_dummies.md) first to make sure you understand the
basics.

{: .callout .note}
**Note:** gMock lives in the `testing` name space. For readability, it is
recommended to write `using ::testing::Foo;` once in your file before using the
name `Foo` defined by gMock. We omit such `using` statements in this section for
brevity, but you should do it in your own code.

## Creating Mock Classes

Mock classes are defined as normal classes, using the `MOCK_METHOD` macro to
generate mocked methods. The macro gets 3 or 4 parameters:

```cpp
class MyMock {
 public:
  MOCK_METHOD(ReturnType, MethodName, (Args...));
  MOCK_METHOD(ReturnType, MethodName, (Args...), (Specs...));
};
```

The first 3 parameters are simply the method declaration, split into 3 parts.
The 4th parameter accepts a closed list of qualifiers, which affect the
generated method:

*   **`const`** - Makes the mocked method a `const` method. Required if
    overriding a `const` method.
*   **`override`** - Marks the method with `override`. Recommended if overriding
    a `virtual` method.
*   **`noexcept`** - Marks the method with `noexcept`. Required if overriding a
    `noexcept` method.
*   **`Calltype(...)`** - Sets the call type for the method (e.g. to
    `STDMETHODCALLTYPE`), useful in Windows.
*   **`ref(...)`** - Marks the method with the reference qualification
    specified. Required if overriding a method that has reference
    qualifications. Eg `ref(&)` or `ref(&&)`.

### Dealing with unprotected commas

Unprotected commas, i.e. commas which are not surrounded by parentheses, prevent
`MOCK_METHOD` from parsing its arguments correctly:

{: .bad}
```cpp
class MockFoo {
 public:
  MOCK_METHOD(std::pair<bool, int>, GetPair, ());  // Won't compile!
  MOCK_METHOD(bool, CheckMap, (std::map<int, double>, bool));  // Won't compile!
};
```

Solution 1 - wrap with parentheses:

{: .good}
```cpp
class MockFoo {
 public:
  MOCK_METHOD((std::pair<bool, int>), GetPair, ());
  MOCK_METHOD(bool, CheckMap, ((std::map<int, double>), bool));
};
```

Note that wrapping a return or argument type with parentheses is, in general,
invalid C++. `MOCK_METHOD` removes the parentheses.

Solution 2 - define an alias:

{: .good}
```cpp
class MockFoo {
 public:
  using BoolAndInt = std::pair<bool, int>;
  MOCK_METHOD(BoolAndInt, GetPair, ());
  using MapIntDouble = std::map<int, double>;
  MOCK_METHOD(bool, CheckMap, (MapIntDouble, bool));
};
```

### Mocking Private or Protected Methods

You must always put a mock method definition (`MOCK_METHOD`) in a `public:`
section of the mock class, regardless of the method being mocked being `public`,
`protected`, or `private` in the base class. This allows `ON_CALL` and
`EXPECT_CALL` to reference the mock function from outside of the mock class.
(Yes, C++ allows a subclass to change the access level of a virtual function in
the base class.) Example:

```cpp
class Foo {
 public:
  ...
  virtual bool Transform(Gadget* g) = 0;

 protected:
  virtual void Resume();

 private:
  virtual int GetTimeOut();
};

class MockFoo : public Foo {
 public:
  ...
  MOCK_METHOD(bool, Transform, (Gadget* g), (override));

  // The following must be in the public section, even though the
  // methods are protected or private in the base class.
  MOCK_METHOD(void, Resume, (), (override));
  MOCK_METHOD(int, GetTimeOut, (), (override));
};
```

### Mocking Overloaded Methods

You can mock overloaded functions as usual. No special attention is required:

```cpp
class Foo {
  ...

  // Must be virtual as we'll inherit from Foo.
  virtual ~Foo();

  // Overloaded on the types and/or numbers of arguments.
  virtual int Add(Element x);
  virtual int Add(int times, Element x);

  // Overloaded on the const-ness of this object.
  virtual Bar& GetBar();
  virtual const Bar& GetBar() const;
};

class MockFoo : public Foo {
  ...
  MOCK_METHOD(int, Add, (Element x), (override));
  MOCK_METHOD(int, Add, (int times, Element x), (override));

  MOCK_METHOD(Bar&, GetBar, (), (override));
  MOCK_METHOD(const Bar&, GetBar, (), (const, override));
};
```

{: .callout .note}
**Note:** if you don't mock all versions of the overloaded method, the compiler
will give you a warning about some methods in the base class being hidden. To
fix that, use `using` to bring them in scope:

```cpp
class MockFoo : public Foo {
  ...
  using Foo::Add;
  MOCK_METHOD(int, Add, (Element x), (override));
  // We don't want to mock int Add(int times, Element x);
  ...
};
```

### Mocking Class Templates

You can mock class templates just like any class.

```cpp
template <typename Elem>
class StackInterface {
  ...
  // Must be virtual as we'll inherit from StackInterface.
  virtual ~StackInterface();

  virtual int GetSize() const = 0;
  virtual void Push(const Elem& x) = 0;
};

template <typename Elem>
class MockStack : public StackInterface<Elem> {
  ...
  MOCK_METHOD(int, GetSize, (), (override));
  MOCK_METHOD(void, Push, (const Elem& x), (override));
};
```

### Mocking Non-virtual Methods {#MockingNonVirtualMethods}

gMock can mock non-virtual functions to be used in Hi-perf dependency injection.

In this case, instead of sharing a common base class with the real class, your
mock class will be *unrelated* to the real class, but contain methods with the
same signatures. The syntax for mocking non-virtual methods is the *same* as
mocking virtual methods (just don't add `override`):

```cpp
// A simple packet stream class.  None of its members is virtual.
class ConcretePacketStream {
 public:
  void AppendPacket(Packet* new_packet);
  const Packet* GetPacket(size_t packet_number) const;
  size_t NumberOfPackets() const;
  ...
};

// A mock packet stream class.  It inherits from no other, but defines
// GetPacket() and NumberOfPackets().
class MockPacketStream {
 public:
  MOCK_METHOD(const Packet*, GetPacket, (size_t packet_number), (const));
  MOCK_METHOD(size_t, NumberOfPackets, (), (const));
  ...
};
```

Note that the mock class doesn't define `AppendPacket()`, unlike the real class.
That's fine as long as the test doesn't need to call it.

Next, you need a way to say that you want to use `ConcretePacketStream` in
production code, and use `MockPacketStream` in tests. Since the functions are
not virtual and the two classes are unrelated, you must specify your choice at
*compile time* (as opposed to run time).

One way to do it is to templatize your code that needs to use a packet stream.
More specifically, you will give your code a template type argument for the type
of the packet stream. In production, you will instantiate your template with
`ConcretePacketStream` as the type argument. In tests, you will instantiate the
same template with `MockPacketStream`. For example, you may write:

```cpp
template <class PacketStream>
void CreateConnection(PacketStream* stream) { ... }

template <class PacketStream>
class PacketReader {
 public:
  void ReadPackets(PacketStream* stream, size_t packet_num);
};
```

Then you can use `CreateConnection<ConcretePacketStream>()` and
`PacketReader<ConcretePacketStream>` in production code, and use
`CreateConnection<MockPacketStream>()` and `PacketReader<MockPacketStream>` in
tests.

```cpp
  MockPacketStream mock_stream;
  EXPECT_CALL(mock_stream, ...)...;
  .. set more expectations on mock_stream ...
  PacketReader<MockPacketStream> reader(&mock_stream);
  ... exercise reader ...
```

### Mocking Free Functions

It is not possible to directly mock a free function (i.e. a C-style function or
a static method). If you need to, you can rewrite your code to use an interface
(abstract class).

Instead of calling a free function (say, `OpenFile`) directly, introduce an
interface for it and have a concrete subclass that calls the free function:

```cpp
class FileInterface {
 public:
  ...
  virtual bool Open(const char* path, const char* mode) = 0;
};

class File : public FileInterface {
 public:
  ...
  bool Open(const char* path, const char* mode) override {
     return OpenFile(path, mode);
  }
};
```

Your code should talk to `FileInterface` to open a file. Now it's easy to mock
out the function.

This may seem like a lot of hassle, but in practice you often have multiple
related functions that you can put in the same interface, so the per-function
syntactic overhead will be much lower.

If you are concerned about the performance overhead incurred by virtual
functions, and profiling confirms your concern, you can combine this with the
recipe for [mocking non-virtual methods](#MockingNonVirtualMethods).

### Old-Style `MOCK_METHODn` Macros

Before the generic `MOCK_METHOD` macro
[was introduced in 2018](https://github.com/google/googletest/commit/c5f08bf91944ce1b19bcf414fa1760e69d20afc2),
mocks where created using a family of macros collectively called `MOCK_METHODn`.
These macros are still supported, though migration to the new `MOCK_METHOD` is
recommended.

The macros in the `MOCK_METHODn` family differ from `MOCK_METHOD`:

*   The general structure is `MOCK_METHODn(MethodName, ReturnType(Args))`,
    instead of `MOCK_METHOD(ReturnType, MethodName, (Args))`.
*   The number `n` must equal the number of arguments.
*   When mocking a const method, one must use `MOCK_CONST_METHODn`.
*   When mocking a class template, the macro name must be suffixed with `_T`.
*   In order to specify the call type, the macro name must be suffixed with
    `_WITH_CALLTYPE`, and the call type is the first macro argument.

Old macros and their new equivalents:

<table>
  <tr><th colspan=2>Simple</th></tr>
  <tr>
    <td>Old</td>
    <td><code>MOCK_METHOD1(Foo, bool(int))</code></td>
  </tr>
  <tr>
    <td>New</td>
    <td><code>MOCK_METHOD(bool, Foo, (int))</code></td>
  </tr>

  <tr><th colspan=2>Const Method</th></tr>
  <tr>
    <td>Old</td>
    <td><code>MOCK_CONST_METHOD1(Foo, bool(int))</code></td>
  </tr>
  <tr>
    <td>New</td>
    <td><code>MOCK_METHOD(bool, Foo, (int), (const))</code></td>
  </tr>

  <tr><th colspan=2>Method in a Class Template</th></tr>
  <tr>
    <td>Old</td>
    <td><code>MOCK_METHOD1_T(Foo, bool(int))</code></td>
  </tr>
  <tr>
    <td>New</td>
    <td><code>MOCK_METHOD(bool, Foo, (int))</code></td>
  </tr>

  <tr><th colspan=2>Const Method in a Class Template</th></tr>
  <tr>
    <td>Old</td>
    <td><code>MOCK_CONST_METHOD1_T(Foo, bool(int))</code></td>
  </tr>
  <tr>
    <td>New</td>
    <td><code>MOCK_METHOD(bool, Foo, (int), (const))</code></td>
  </tr>

  <tr><th colspan=2>Method with Call Type</th></tr>
  <tr>
    <td>Old</td>
    <td><code>MOCK_METHOD1_WITH_CALLTYPE(STDMETHODCALLTYPE, Foo, bool(int))</code></td>
  </tr>
  <tr>
    <td>New</td>
    <td><code>MOCK_METHOD(bool, Foo, (int), (Calltype(STDMETHODCALLTYPE)))</code></td>
  </tr>

  <tr><th colspan=2>Const Method with Call Type</th></tr>
  <tr>
    <td>Old</td>
    <td><code>MOCK_CONST_METHOD1_WITH_CALLTYPE(STDMETHODCALLTYPE, Foo, bool(int))</code></td>
  </tr>
  <tr>
    <td>New</td>
    <td><code>MOCK_METHOD(bool, Foo, (int), (const, Calltype(STDMETHODCALLTYPE)))</code></td>
  </tr>

  <tr><th colspan=2>Method with Call Type in a Class Template</th></tr>
  <tr>
    <td>Old</td>
    <td><code>MOCK_METHOD1_T_WITH_CALLTYPE(STDMETHODCALLTYPE, Foo, bool(int))</code></td>
  </tr>
  <tr>
    <td>New</td>
    <td><code>MOCK_METHOD(bool, Foo, (int), (Calltype(STDMETHODCALLTYPE)))</code></td>
  </tr>

  <tr><th colspan=2>Const Method with Call Type in a Class Template</th></tr>
  <tr>
    <td>Old</td>
    <td><code>MOCK_CONST_METHOD1_T_WITH_CALLTYPE(STDMETHODCALLTYPE, Foo, bool(int))</code></td>
  </tr>
  <tr>
    <td>New</td>
    <td><code>MOCK_METHOD(bool, Foo, (int), (const, Calltype(STDMETHODCALLTYPE)))</code></td>
  </tr>
</table>

### The Nice, the Strict, and the Naggy {#NiceStrictNaggy}

If a mock method has no `EXPECT_CALL` spec but is called, we say that it's an
"uninteresting call", and the default action (which can be specified using
`ON_CALL()`) of the method will be taken. Currently, an uninteresting call will
also by default cause gMock to print a warning. (In the future, we might remove
this warning by default.)

However, sometimes you may want to ignore these uninteresting calls, and
sometimes you may want to treat them as errors. gMock lets you make the decision
on a per-mock-object basis.

Suppose your test uses a mock class `MockFoo`:

```cpp
TEST(...) {
  MockFoo mock_foo;
  EXPECT_CALL(mock_foo, DoThis());
  ... code that uses mock_foo ...
}
```

If a method of `mock_foo` other than `DoThis()` is called, you will get a
warning. However, if you rewrite your test to use `NiceMock<MockFoo>` instead,
you can suppress the warning:

```cpp
using ::testing::NiceMock;

TEST(...) {
  NiceMock<MockFoo> mock_foo;
  EXPECT_CALL(mock_foo, DoThis());
  ... code that uses mock_foo ...
}
```

`NiceMock<MockFoo>` is a subclass of `MockFoo`, so it can be used wherever
`MockFoo` is accepted.

It also works if `MockFoo`'s constructor takes some arguments, as
`NiceMock<MockFoo>` "inherits" `MockFoo`'s constructors:

```cpp
using ::testing::NiceMock;

TEST(...) {
  NiceMock<MockFoo> mock_foo(5, "hi");  // Calls MockFoo(5, "hi").
  EXPECT_CALL(mock_foo, DoThis());
  ... code that uses mock_foo ...
}
```

The usage of `StrictMock` is similar, except that it makes all uninteresting
calls failures:

```cpp
using ::testing::StrictMock;

TEST(...) {
  StrictMock<MockFoo> mock_foo;
  EXPECT_CALL(mock_foo, DoThis());
  ... code that uses mock_foo ...

  // The test will fail if a method of mock_foo other than DoThis()
  // is called.
}
```

{: .callout .note}
NOTE: `NiceMock` and `StrictMock` only affects *uninteresting* calls (calls of
*methods* with no expectations); they do not affect *unexpected* calls (calls of
methods with expectations, but they don't match). See
[Understanding Uninteresting vs Unexpected Calls](#uninteresting-vs-unexpected).

There are some caveats though (sadly they are side effects of C++'s
limitations):

1.  `NiceMock<MockFoo>` and `StrictMock<MockFoo>` only work for mock methods
    defined using the `MOCK_METHOD` macro **directly** in the `MockFoo` class.
    If a mock method is defined in a **base class** of `MockFoo`, the "nice" or
    "strict" modifier may not affect it, depending on the compiler. In
    particular, nesting `NiceMock` and `StrictMock` (e.g.
    `NiceMock<StrictMock<MockFoo> >`) is **not** supported.
2.  `NiceMock<MockFoo>` and `StrictMock<MockFoo>` may not work correctly if the
    destructor of `MockFoo` is not virtual. We would like to fix this, but it
    requires cleaning up existing tests.

Finally, you should be **very cautious** about when to use naggy or strict
mocks, as they tend to make tests more brittle and harder to maintain. When you
refactor your code without changing its externally visible behavior, ideally you
shouldn't need to update any tests. If your code interacts with a naggy mock,
however, you may start to get spammed with warnings as the result of your
change. Worse, if your code interacts with a strict mock, your tests may start
to fail and you'll be forced to fix them. Our general recommendation is to use
nice mocks (not yet the default) most of the time, use naggy mocks (the current
default) when developing or debugging tests, and use strict mocks only as the
last resort.

### Simplifying the Interface without Breaking Existing Code {#SimplerInterfaces}

Sometimes a method has a long list of arguments that is mostly uninteresting.
For example:

```cpp
class LogSink {
 public:
  ...
  virtual void send(LogSeverity severity, const char* full_filename,
                    const char* base_filename, int line,
                    const struct tm* tm_time,
                    const char* message, size_t message_len) = 0;
};
```

This method's argument list is lengthy and hard to work with (the `message`
argument is not even 0-terminated). If we mock it as is, using the mock will be
awkward. If, however, we try to simplify this interface, we'll need to fix all
clients depending on it, which is often infeasible.

The trick is to redispatch the method in the mock class:

```cpp
class ScopedMockLog : public LogSink {
 public:
  ...
  void send(LogSeverity severity, const char* full_filename,
                    const char* base_filename, int line, const tm* tm_time,
                    const char* message, size_t message_len) override {
    // We are only interested in the log severity, full file name, and
    // log message.
    Log(severity, full_filename, std::string(message, message_len));
  }

  // Implements the mock method:
  //
  //   void Log(LogSeverity severity,
  //            const string& file_path,
  //            const string& message);
  MOCK_METHOD(void, Log,
              (LogSeverity severity, const string& file_path,
               const string& message));
};
```

By defining a new mock method with a trimmed argument list, we make the mock
class more user-friendly.

This technique may also be applied to make overloaded methods more amenable to
mocking. For example, when overloads have been used to implement default
arguments:

```cpp
class MockTurtleFactory : public TurtleFactory {
 public:
  Turtle* MakeTurtle(int length, int weight) override { ... }
  Turtle* MakeTurtle(int length, int weight, int speed) override { ... }

  // the above methods delegate to this one:
  MOCK_METHOD(Turtle*, DoMakeTurtle, ());
};
```

This allows tests that don't care which overload was invoked to avoid specifying
argument matchers:

```cpp
ON_CALL(factory, DoMakeTurtle)
    .WillByDefault(Return(MakeMockTurtle()));
```

### Alternative to Mocking Concrete Classes

Often you may find yourself using classes that don't implement interfaces. In
order to test your code that uses such a class (let's call it `Concrete`), you
may be tempted to make the methods of `Concrete` virtual and then mock it.

Try not to do that.

Making a non-virtual function virtual is a big decision. It creates an extension
point where subclasses can tweak your class' behavior. This weakens your control
on the class because now it's harder to maintain the class invariants. You
should make a function virtual only when there is a valid reason for a subclass
to override it.

Mocking concrete classes directly is problematic as it creates a tight coupling
between the class and the tests - any small change in the class may invalidate
your tests and make test maintenance a pain.

To avoid such problems, many programmers have been practicing "coding to
interfaces": instead of talking to the `Concrete` class, your code would define
an interface and talk to it. Then you implement that interface as an adaptor on
top of `Concrete`. In tests, you can easily mock that interface to observe how
your code is doing.

This technique incurs some overhead:

*   You pay the cost of virtual function calls (usually not a problem).
*   There is more abstraction for the programmers to learn.

However, it can also bring significant benefits in addition to better
testability:

*   `Concrete`'s API may not fit your problem domain very well, as you may not
    be the only client it tries to serve. By designing your own interface, you
    have a chance to tailor it to your need - you may add higher-level
    functionalities, rename stuff, etc instead of just trimming the class. This
    allows you to write your code (user of the interface) in a more natural way,
    which means it will be more readable, more maintainable, and you'll be more
    productive.
*   If `Concrete`'s implementation ever has to change, you don't have to rewrite
    everywhere it is used. Instead, you can absorb the change in your
    implementation of the interface, and your other code and tests will be
    insulated from this change.

Some people worry that if everyone is practicing this technique, they will end
up writing lots of redundant code. This concern is totally understandable.
However, there are two reasons why it may not be the case:

*   Different projects may need to use `Concrete` in different ways, so the best
    interfaces for them will be different. Therefore, each of them will have its
    own domain-specific interface on top of `Concrete`, and they will not be the
    same code.
*   If enough projects want to use the same interface, they can always share it,
    just like they have been sharing `Concrete`. You can check in the interface
    and the adaptor somewhere near `Concrete` (perhaps in a `contrib`
    sub-directory) and let many projects use it.

You need to weigh the pros and cons carefully for your particular problem, but
I'd like to assure you that the Java community has been practicing this for a
long time and it's a proven effective technique applicable in a wide variety of
situations. :-)

### Delegating Calls to a Fake {#DelegatingToFake}

Some times you have a non-trivial fake implementation of an interface. For
example:

```cpp
class Foo {
 public:
  virtual ~Foo() {}
  virtual char DoThis(int n) = 0;
  virtual void DoThat(const char* s, int* p) = 0;
};

class FakeFoo : public Foo {
 public:
  char DoThis(int n) override {
    return (n > 0) ? '+' :
           (n < 0) ? '-' : '0';
  }

  void DoThat(const char* s, int* p) override {
    *p = strlen(s);
  }
};
```

Now you want to mock this interface such that you can set expectations on it.
However, you also want to use `FakeFoo` for the default behavior, as duplicating
it in the mock object is, well, a lot of work.

When you define the mock class using gMock, you can have it delegate its default
action to a fake class you already have, using this pattern:

```cpp
class MockFoo : public Foo {
 public:
  // Normal mock method definitions using gMock.
  MOCK_METHOD(char, DoThis, (int n), (override));
  MOCK_METHOD(void, DoThat, (const char* s, int* p), (override));

  // Delegates the default actions of the methods to a FakeFoo object.
  // This must be called *before* the custom ON_CALL() statements.
  void DelegateToFake() {
    ON_CALL(*this, DoThis).WillByDefault([this](int n) {
      return fake_.DoThis(n);
    });
    ON_CALL(*this, DoThat).WillByDefault([this](const char* s, int* p) {
      fake_.DoThat(s, p);
    });
  }

 private:
  FakeFoo fake_;  // Keeps an instance of the fake in the mock.
};
```

With that, you can use `MockFoo` in your tests as usual. Just remember that if
you don't explicitly set an action in an `ON_CALL()` or `EXPECT_CALL()`, the
fake will be called upon to do it.:

```cpp
using ::testing::_;

TEST(AbcTest, Xyz) {
  MockFoo foo;

  foo.DelegateToFake();  // Enables the fake for delegation.

  // Put your ON_CALL(foo, ...)s here, if any.

  // No action specified, meaning to use the default action.
  EXPECT_CALL(foo, DoThis(5));
  EXPECT_CALL(foo, DoThat(_, _));

  int n = 0;
  EXPECT_EQ('+', foo.DoThis(5));  // FakeFoo::DoThis() is invoked.
  foo.DoThat("Hi", &n);  // FakeFoo::DoThat() is invoked.
  EXPECT_EQ(2, n);
}
```

**Some tips:**

*   If you want, you can still override the default action by providing your own
    `ON_CALL()` or using `.WillOnce()` / `.WillRepeatedly()` in `EXPECT_CALL()`.
*   In `DelegateToFake()`, you only need to delegate the methods whose fake
    implementation you intend to use.

*   The general technique discussed here works for overloaded methods, but
    you'll need to tell the compiler which version you mean. To disambiguate a
    mock function (the one you specify inside the parentheses of `ON_CALL()`),
    use [this technique](#SelectOverload); to disambiguate a fake function (the
    one you place inside `Invoke()`), use a `static_cast` to specify the
    function's type. For instance, if class `Foo` has methods `char DoThis(int
    n)` and `bool DoThis(double x) const`, and you want to invoke the latter,
    you need to write `Invoke(&fake_, static_cast<bool (FakeFoo::*)(double)
    const>(&FakeFoo::DoThis))` instead of `Invoke(&fake_, &FakeFoo::DoThis)`
    (The strange-looking thing inside the angled brackets of `static_cast` is
    the type of a function pointer to the second `DoThis()` method.).

*   Having to mix a mock and a fake is often a sign of something gone wrong.
    Perhaps you haven't got used to the interaction-based way of testing yet. Or
    perhaps your interface is taking on too many roles and should be split up.
    Therefore, **don't abuse this**. We would only recommend to do it as an
    intermediate step when you are refactoring your code.

Regarding the tip on mixing a mock and a fake, here's an example on why it may
be a bad sign: Suppose you have a class `System` for low-level system
operations. In particular, it does file and I/O operations. And suppose you want
to test how your code uses `System` to do I/O, and you just want the file
operations to work normally. If you mock out the entire `System` class, you'll
have to provide a fake implementation for the file operation part, which
suggests that `System` is taking on too many roles.

Instead, you can define a `FileOps` interface and an `IOOps` interface and split
`System`'s functionalities into the two. Then you can mock `IOOps` without
mocking `FileOps`.

### Delegating Calls to a Real Object

When using testing doubles (mocks, fakes, stubs, and etc), sometimes their
behaviors will differ from those of the real objects. This difference could be
either intentional (as in simulating an error such that you can test the error
handling code) or unintentional. If your mocks have different behaviors than the
real objects by mistake, you could end up with code that passes the tests but
fails in production.

You can use the *delegating-to-real* technique to ensure that your mock has the
same behavior as the real object while retaining the ability to validate calls.
This technique is very similar to the [delegating-to-fake](#DelegatingToFake)
technique, the difference being that we use a real object instead of a fake.
Here's an example:

```cpp
using ::testing::AtLeast;

class MockFoo : public Foo {
 public:
  MockFoo() {
    // By default, all calls are delegated to the real object.
    ON_CALL(*this, DoThis).WillByDefault([this](int n) {
      return real_.DoThis(n);
    });
    ON_CALL(*this, DoThat).WillByDefault([this](const char* s, int* p) {
      real_.DoThat(s, p);
    });
    ...
  }
  MOCK_METHOD(char, DoThis, ...);
  MOCK_METHOD(void, DoThat, ...);
  ...
 private:
  Foo real_;
};

...
  MockFoo mock;
  EXPECT_CALL(mock, DoThis())
      .Times(3);
  EXPECT_CALL(mock, DoThat("Hi"))
      .Times(AtLeast(1));
  ... use mock in test ...
```

With this, gMock will verify that your code made the right calls (with the right
arguments, in the right order, called the right number of times, etc), and a
real object will answer the calls (so the behavior will be the same as in
production). This gives you the best of both worlds.

### Delegating Calls to a Parent Class

Ideally, you should code to interfaces, whose methods are all pure virtual. In
reality, sometimes you do need to mock a virtual method that is not pure (i.e,
it already has an implementation). For example:

```cpp
class Foo {
 public:
  virtual ~Foo();

  virtual void Pure(int n) = 0;
  virtual int Concrete(const char* str) { ... }
};

class MockFoo : public Foo {
 public:
  // Mocking a pure method.
  MOCK_METHOD(void, Pure, (int n), (override));
  // Mocking a concrete method.  Foo::Concrete() is shadowed.
  MOCK_METHOD(int, Concrete, (const char* str), (override));
};
```

Sometimes you may want to call `Foo::Concrete()` instead of
`MockFoo::Concrete()`. Perhaps you want to do it as part of a stub action, or
perhaps your test doesn't need to mock `Concrete()` at all (but it would be
oh-so painful to have to define a new mock class whenever you don't need to mock
one of its methods).

You can call `Foo::Concrete()` inside an action by:

```cpp
...
  EXPECT_CALL(foo, Concrete).WillOnce([&foo](const char* str) {
    return foo.Foo::Concrete(str);
  });
```

or tell the mock object that you don't want to mock `Concrete()`:

```cpp
...
  ON_CALL(foo, Concrete).WillByDefault([&foo](const char* str) {
    return foo.Foo::Concrete(str);
  });
```

(Why don't we just write `{ return foo.Concrete(str); }`? If you do that,
`MockFoo::Concrete()` will be called (and cause an infinite recursion) since
`Foo::Concrete()` is virtual. That's just how C++ works.)

## Using Matchers

### Matching Argument Values Exactly

You can specify exactly which arguments a mock method is expecting:

```cpp
using ::testing::Return;
...
  EXPECT_CALL(foo, DoThis(5))
      .WillOnce(Return('a'));
  EXPECT_CALL(foo, DoThat("Hello", bar));
```

### Using Simple Matchers

You can use matchers to match arguments that have a certain property:

```cpp
using ::testing::NotNull;
using ::testing::Return;
...
  EXPECT_CALL(foo, DoThis(Ge(5)))  // The argument must be >= 5.
      .WillOnce(Return('a'));
  EXPECT_CALL(foo, DoThat("Hello", NotNull()));
      // The second argument must not be NULL.
```

A frequently used matcher is `_`, which matches anything:

```cpp
  EXPECT_CALL(foo, DoThat(_, NotNull()));
```

### Combining Matchers {#CombiningMatchers}

You can build complex matchers from existing ones using `AllOf()`,
`AllOfArray()`, `AnyOf()`, `AnyOfArray()` and `Not()`:

```cpp
using ::testing::AllOf;
using ::testing::Gt;
using ::testing::HasSubstr;
using ::testing::Ne;
using ::testing::Not;
...
  // The argument must be > 5 and != 10.
  EXPECT_CALL(foo, DoThis(AllOf(Gt(5),
                                Ne(10))));

  // The first argument must not contain sub-string "blah".
  EXPECT_CALL(foo, DoThat(Not(HasSubstr("blah")),
                          NULL));
```

Matchers are function objects, and parametrized matchers can be composed just
like any other function. However because their types can be long and rarely
provide meaningful information, it can be easier to express them with C++14
generic lambdas to avoid specifying types. For example,

```cpp
using ::testing::Contains;
using ::testing::Property;

inline constexpr auto HasFoo = [](const auto& f) {
  return Property(&MyClass::foo, Contains(f));
};
...
  EXPECT_THAT(x, HasFoo("blah"));
```

### Casting Matchers {#SafeMatcherCast}

gMock matchers are statically typed, meaning that the compiler can catch your
mistake if you use a matcher of the wrong type (for example, if you use `Eq(5)`
to match a `string` argument). Good for you!

Sometimes, however, you know what you're doing and want the compiler to give you
some slack. One example is that you have a matcher for `long` and the argument
you want to match is `int`. While the two types aren't exactly the same, there
is nothing really wrong with using a `Matcher<long>` to match an `int` - after
all, we can first convert the `int` argument to a `long` losslessly before
giving it to the matcher.

To support this need, gMock gives you the `SafeMatcherCast<T>(m)` function. It
casts a matcher `m` to type `Matcher<T>`. To ensure safety, gMock checks that
(let `U` be the type `m` accepts :

1.  Type `T` can be *implicitly* cast to type `U`;
2.  When both `T` and `U` are built-in arithmetic types (`bool`, integers, and
    floating-point numbers), the conversion from `T` to `U` is not lossy (in
    other words, any value representable by `T` can also be represented by `U`);
    and
3.  When `U` is a reference, `T` must also be a reference (as the underlying
    matcher may be interested in the address of the `U` value).

The code won't compile if any of these conditions isn't met.

Here's one example:

```cpp
using ::testing::SafeMatcherCast;

// A base class and a child class.
class Base { ... };
class Derived : public Base { ... };

class MockFoo : public Foo {
 public:
  MOCK_METHOD(void, DoThis, (Derived* derived), (override));
};

...
  MockFoo foo;
  // m is a Matcher<Base*> we got from somewhere.
  EXPECT_CALL(foo, DoThis(SafeMatcherCast<Derived*>(m)));
```

If you find `SafeMatcherCast<T>(m)` too limiting, you can use a similar function
`MatcherCast<T>(m)`. The difference is that `MatcherCast` works as long as you
can `static_cast` type `T` to type `U`.

`MatcherCast` essentially lets you bypass C++'s type system (`static_cast` isn't
always safe as it could throw away information, for example), so be careful not
to misuse/abuse it.

### Selecting Between Overloaded Functions {#SelectOverload}

If you expect an overloaded function to be called, the compiler may need some
help on which overloaded version it is.

To disambiguate functions overloaded on the const-ness of this object, use the
`Const()` argument wrapper.

```cpp
using ::testing::ReturnRef;

class MockFoo : public Foo {
  ...
  MOCK_METHOD(Bar&, GetBar, (), (override));
  MOCK_METHOD(const Bar&, GetBar, (), (const, override));
};

...
  MockFoo foo;
  Bar bar1, bar2;
  EXPECT_CALL(foo, GetBar())         // The non-const GetBar().
      .WillOnce(ReturnRef(bar1));
  EXPECT_CALL(Const(foo), GetBar())  // The const GetBar().
      .WillOnce(ReturnRef(bar2));
```

(`Const()` is defined by gMock and returns a `const` reference to its argument.)

To disambiguate overloaded functions with the same number of arguments but
different argument types, you may need to specify the exact type of a matcher,
either by wrapping your matcher in `Matcher<type>()`, or using a matcher whose
type is fixed (`TypedEq<type>`, `An<type>()`, etc):

```cpp
using ::testing::An;
using ::testing::Matcher;
using ::testing::TypedEq;

class MockPrinter : public Printer {
 public:
  MOCK_METHOD(void, Print, (int n), (override));
  MOCK_METHOD(void, Print, (char c), (override));
};

TEST(PrinterTest, Print) {
  MockPrinter printer;

  EXPECT_CALL(printer, Print(An<int>()));            // void Print(int);
  EXPECT_CALL(printer, Print(Matcher<int>(Lt(5))));  // void Print(int);
  EXPECT_CALL(printer, Print(TypedEq<char>('a')));   // void Print(char);

  printer.Print(3);
  printer.Print(6);
  printer.Print('a');
}
```

### Performing Different Actions Based on the Arguments

When a mock method is called, the *last* matching expectation that's still
active will be selected (think "newer overrides older"). So, you can make a
method do different things depending on its argument values like this:

```cpp
using ::testing::_;
using ::testing::Lt;
using ::testing::Return;
...
  // The default case.
  EXPECT_CALL(foo, DoThis(_))
      .WillRepeatedly(Return('b'));
  // The more specific case.
  EXPECT_CALL(foo, DoThis(Lt(5)))
      .WillRepeatedly(Return('a'));
```

Now, if `foo.DoThis()` is called with a value less than 5, `'a'` will be
returned; otherwise `'b'` will be returned.

### Matching Multiple Arguments as a Whole

Sometimes it's not enough to match the arguments individually. For example, we
may want to say that the first argument must be less than the second argument.
The `With()` clause allows us to match all arguments of a mock function as a
whole. For example,

```cpp
using ::testing::_;
using ::testing::Ne;
using ::testing::Lt;
...
  EXPECT_CALL(foo, InRange(Ne(0), _))
      .With(Lt());
```

says that the first argument of `InRange()` must not be 0, and must be less than
the second argument.

The expression inside `With()` must be a matcher of type `Matcher<std::tuple<A1,
..., An>>`, where `A1`, ..., `An` are the types of the function arguments.

You can also write `AllArgs(m)` instead of `m` inside `.With()`. The two forms
are equivalent, but `.With(AllArgs(Lt()))` is more readable than `.With(Lt())`.

You can use `Args<k1, ..., kn>(m)` to match the `n` selected arguments (as a
tuple) against `m`. For example,

```cpp
using ::testing::_;
using ::testing::AllOf;
using ::testing::Args;
using ::testing::Lt;
...
  EXPECT_CALL(foo, Blah)
      .With(AllOf(Args<0, 1>(Lt()), Args<1, 2>(Lt())));
```

says that `Blah` will be called with arguments `x`, `y`, and `z` where `x < y <
z`. Note that in this example, it wasn't necessary specify the positional
matchers.

As a convenience and example, gMock provides some matchers for 2-tuples,
including the `Lt()` matcher above. See
[Multi-argument Matchers](reference/matchers.md#MultiArgMatchers) for the
complete list.

Note that if you want to pass the arguments to a predicate of your own (e.g.
`.With(Args<0, 1>(Truly(&MyPredicate)))`), that predicate MUST be written to
take a `std::tuple` as its argument; gMock will pass the `n` selected arguments
as *one* single tuple to the predicate.

### Using Matchers as Predicates

Have you noticed that a matcher is just a fancy predicate that also knows how to
describe itself? Many existing algorithms take predicates as arguments (e.g.
those defined in STL's `<algorithm>` header), and it would be a shame if gMock
matchers were not allowed to participate.

Luckily, you can use a matcher where a unary predicate functor is expected by
wrapping it inside the `Matches()` function. For example,

```cpp
#include <algorithm>
#include <vector>

using ::testing::Matches;
using ::testing::Ge;

vector<int> v;
...
// How many elements in v are >= 10?
const int count = count_if(v.begin(), v.end(), Matches(Ge(10)));
```

Since you can build complex matchers from simpler ones easily using gMock, this
gives you a way to conveniently construct composite predicates (doing the same
using STL's `<functional>` header is just painful). For example, here's a
predicate that's satisfied by any number that is >= 0, <= 100, and != 50:

```cpp
using testing::AllOf;
using testing::Ge;
using testing::Le;
using testing::Matches;
using testing::Ne;
...
Matches(AllOf(Ge(0), Le(100), Ne(50)))
```

### Using Matchers in googletest Assertions

See [`EXPECT_THAT`](reference/assertions.md#EXPECT_THAT) in the Assertions
Reference.

### Using Predicates as Matchers

gMock provides a set of built-in matchers for matching arguments with expected
values—see the [Matchers Reference](reference/matchers.md) for more information.
In case you find the built-in set lacking, you can use an arbitrary unary
predicate function or functor as a matcher - as long as the predicate accepts a
value of the type you want. You do this by wrapping the predicate inside the
`Truly()` function, for example:

```cpp
using ::testing::Truly;

int IsEven(int n) { return (n % 2) == 0 ? 1 : 0; }
...
  // Bar() must be called with an even number.
  EXPECT_CALL(foo, Bar(Truly(IsEven)));
```

Note that the predicate function / functor doesn't have to return `bool`. It
works as long as the return value can be used as the condition in in statement
`if (condition) ...`.

### Matching Arguments that Are Not Copyable

When you do an `EXPECT_CALL(mock_obj, Foo(bar))`, gMock saves away a copy of
`bar`. When `Foo()` is called later, gMock compares the argument to `Foo()` with
the saved copy of `bar`. This way, you don't need to worry about `bar` being
modified or destroyed after the `EXPECT_CALL()` is executed. The same is true
when you use matchers like `Eq(bar)`, `Le(bar)`, and so on.

But what if `bar` cannot be copied (i.e. has no copy constructor)? You could
define your own matcher function or callback and use it with `Truly()`, as the
previous couple of recipes have shown. Or, you may be able to get away from it
if you can guarantee that `bar` won't be changed after the `EXPECT_CALL()` is
executed. Just tell gMock that it should save a reference to `bar`, instead of a
copy of it. Here's how:

```cpp
using ::testing::Eq;
using ::testing::Lt;
...
  // Expects that Foo()'s argument == bar.
  EXPECT_CALL(mock_obj, Foo(Eq(std::ref(bar))));

  // Expects that Foo()'s argument < bar.
  EXPECT_CALL(mock_obj, Foo(Lt(std::ref(bar))));
```

Remember: if you do this, don't change `bar` after the `EXPECT_CALL()`, or the
result is undefined.

### Validating a Member of an Object

Often a mock function takes a reference to object as an argument. When matching
the argument, you may not want to compare the entire object against a fixed
object, as that may be over-specification. Instead, you may need to validate a
certain member variable or the result of a certain getter method of the object.
You can do this with `Field()` and `Property()`. More specifically,

```cpp
Field(&Foo::bar, m)
```

is a matcher that matches a `Foo` object whose `bar` member variable satisfies
matcher `m`.

```cpp
Property(&Foo::baz, m)
```

is a matcher that matches a `Foo` object whose `baz()` method returns a value
that satisfies matcher `m`.

For example:

| Expression                   | Description                              |
| :--------------------------- | :--------------------------------------- |
| `Field(&Foo::number, Ge(3))` | Matches `x` where `x.number >= 3`.       |
| `Property(&Foo::name,  StartsWith("John "))` | Matches `x` where `x.name()` starts with  `"John "`. |

Note that in `Property(&Foo::baz, ...)`, method `baz()` must take no argument
and be declared as `const`. Don't use `Property()` against member functions that
you do not own, because taking addresses of functions is fragile and generally
not part of the contract of the function.

`Field()` and `Property()` can also match plain pointers to objects. For
instance,

```cpp
using ::testing::Field;
using ::testing::Ge;
...
Field(&Foo::number, Ge(3))
```

matches a plain pointer `p` where `p->number >= 3`. If `p` is `NULL`, the match
will always fail regardless of the inner matcher.

What if you want to validate more than one members at the same time? Remember
that there are [`AllOf()` and `AllOfArray()`](#CombiningMatchers).

Finally `Field()` and `Property()` provide overloads that take the field or
property names as the first argument to include it in the error message. This
can be useful when creating combined matchers.

```cpp
using ::testing::AllOf;
using ::testing::Field;
using ::testing::Matcher;
using ::testing::SafeMatcherCast;

Matcher<Foo> IsFoo(const Foo& foo) {
  return AllOf(Field("some_field", &Foo::some_field, foo.some_field),
               Field("other_field", &Foo::other_field, foo.other_field),
               Field("last_field", &Foo::last_field, foo.last_field));
}
```

### Validating the Value Pointed to by a Pointer Argument

C++ functions often take pointers as arguments. You can use matchers like
`IsNull()`, `NotNull()`, and other comparison matchers to match a pointer, but
what if you want to make sure the value *pointed to* by the pointer, instead of
the pointer itself, has a certain property? Well, you can use the `Pointee(m)`
matcher.

`Pointee(m)` matches a pointer if and only if `m` matches the value the pointer
points to. For example:

```cpp
using ::testing::Ge;
using ::testing::Pointee;
...
  EXPECT_CALL(foo, Bar(Pointee(Ge(3))));
```

expects `foo.Bar()` to be called with a pointer that points to a value greater
than or equal to 3.

One nice thing about `Pointee()` is that it treats a `NULL` pointer as a match
failure, so you can write `Pointee(m)` instead of

```cpp
using ::testing::AllOf;
using ::testing::NotNull;
using ::testing::Pointee;
...
  AllOf(NotNull(), Pointee(m))
```

without worrying that a `NULL` pointer will crash your test.

Also, did we tell you that `Pointee()` works with both raw pointers **and**
smart pointers (`std::unique_ptr`, `std::shared_ptr`, etc)?

What if you have a pointer to pointer? You guessed it - you can use nested
`Pointee()` to probe deeper inside the value. For example,
`Pointee(Pointee(Lt(3)))` matches a pointer that points to a pointer that points
to a number less than 3 (what a mouthful...).

### Testing a Certain Property of an Object

Sometimes you want to specify that an object argument has a certain property,
but there is no existing matcher that does this. If you want good error
messages, you should [define a matcher](#NewMatchers). If you want to do it
quick and dirty, you could get away with writing an ordinary function.

Let's say you have a mock function that takes an object of type `Foo`, which has
an `int bar()` method and an `int baz()` method, and you want to constrain that
the argument's `bar()` value plus its `baz()` value is a given number. Here's
how you can define a matcher to do it:

```cpp
using ::testing::Matcher;

class BarPlusBazEqMatcher {
 public:
  explicit BarPlusBazEqMatcher(int expected_sum)
      : expected_sum_(expected_sum) {}

  bool MatchAndExplain(const Foo& foo,
                       std::ostream* /* listener */) const {
    return (foo.bar() + foo.baz()) == expected_sum_;
  }

  void DescribeTo(std::ostream& os) const {
    os << "bar() + baz() equals " << expected_sum_;
  }

  void DescribeNegationTo(std::ostream& os) const {
    os << "bar() + baz() does not equal " << expected_sum_;
  }
 private:
  const int expected_sum_;
};

Matcher<const Foo&> BarPlusBazEq(int expected_sum) {
  return BarPlusBazEqMatcher(expected_sum);
}

...
  EXPECT_CALL(..., DoThis(BarPlusBazEq(5)))...;
```

### Matching Containers

Sometimes an STL container (e.g. list, vector, map, ...) is passed to a mock
function and you may want to validate it. Since most STL containers support the
`==` operator, you can write `Eq(expected_container)` or simply
`expected_container` to match a container exactly.

Sometimes, though, you may want to be more flexible (for example, the first
element must be an exact match, but the second element can be any positive
number, and so on). Also, containers used in tests often have a small number of
elements, and having to define the expected container out-of-line is a bit of a
hassle.

You can use the `ElementsAre()` or `UnorderedElementsAre()` matcher in such
cases:

```cpp
using ::testing::_;
using ::testing::ElementsAre;
using ::testing::Gt;
...
  MOCK_METHOD(void, Foo, (const vector<int>& numbers), (override));
...
  EXPECT_CALL(mock, Foo(ElementsAre(1, Gt(0), _, 5)));
```

The above matcher says that the container must have 4 elements, which must be 1,
greater than 0, anything, and 5 respectively.

If you instead write:

```cpp
using ::testing::_;
using ::testing::Gt;
using ::testing::UnorderedElementsAre;
...
  MOCK_METHOD(void, Foo, (const vector<int>& numbers), (override));
...
  EXPECT_CALL(mock, Foo(UnorderedElementsAre(1, Gt(0), _, 5)));
```

It means that the container must have 4 elements, which (under some permutation)
must be 1, greater than 0, anything, and 5 respectively.

As an alternative you can place the arguments in a C-style array and use
`ElementsAreArray()` or `UnorderedElementsAreArray()` instead:

```cpp
using ::testing::ElementsAreArray;
...
  // ElementsAreArray accepts an array of element values.
  const int expected_vector1[] = {1, 5, 2, 4, ...};
  EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector1)));

  // Or, an array of element matchers.
  Matcher<int> expected_vector2[] = {1, Gt(2), _, 3, ...};
  EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector2)));
```

In case the array needs to be dynamically created (and therefore the array size
cannot be inferred by the compiler), you can give `ElementsAreArray()` an
additional argument to specify the array size:

```cpp
using ::testing::ElementsAreArray;
...
  int* const expected_vector3 = new int[count];
  ... fill expected_vector3 with values ...
  EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector3, count)));
```

Use `Pair` when comparing maps or other associative containers.

{% raw %}

```cpp
using testing::ElementsAre;
using testing::Pair;
...
  std::map<string, int> m = {{"a", 1}, {"b", 2}, {"c", 3}};
  EXPECT_THAT(m, ElementsAre(Pair("a", 1), Pair("b", 2), Pair("c", 3)));
```

{% endraw %}

**Tips:**

*   `ElementsAre*()` can be used to match *any* container that implements the
    STL iterator pattern (i.e. it has a `const_iterator` type and supports
    `begin()/end()`), not just the ones defined in STL. It will even work with
    container types yet to be written - as long as they follows the above
    pattern.
*   You can use nested `ElementsAre*()` to match nested (multi-dimensional)
    containers.
*   If the container is passed by pointer instead of by reference, just write
    `Pointee(ElementsAre*(...))`.
*   The order of elements *matters* for `ElementsAre*()`. If you are using it
    with containers whose element order are undefined (e.g. `hash_map`) you
    should use `WhenSorted` around `ElementsAre`.

### Sharing Matchers

Under the hood, a gMock matcher object consists of a pointer to a ref-counted
implementation object. Copying matchers is allowed and very efficient, as only
the pointer is copied. When the last matcher that references the implementation
object dies, the implementation object will be deleted.

Therefore, if you have some complex matcher that you want to use again and
again, there is no need to build it everytime. Just assign it to a matcher
variable and use that variable repeatedly! For example,

```cpp
using ::testing::AllOf;
using ::testing::Gt;
using ::testing::Le;
using ::testing::Matcher;
...
  Matcher<int> in_range = AllOf(Gt(5), Le(10));
  ... use in_range as a matcher in multiple EXPECT_CALLs ...
```

### Matchers must have no side-effects {#PureMatchers}

{: .callout .warning}
WARNING: gMock does not guarantee when or how many times a matcher will be
invoked. Therefore, all matchers must be *purely functional*: they cannot have
any side effects, and the match result must not depend on anything other than
the matcher's parameters and the value being matched.

This requirement must be satisfied no matter how a matcher is defined (e.g., if
it is one of the standard matchers, or a custom matcher). In particular, a
matcher can never call a mock function, as that will affect the state of the
mock object and gMock.

## Setting Expectations

### Knowing When to Expect {#UseOnCall}

**`ON_CALL`** is likely the *single most under-utilized construct* in gMock.

There are basically two constructs for defining the behavior of a mock object:
`ON_CALL` and `EXPECT_CALL`. The difference? `ON_CALL` defines what happens when
a mock method is called, but <em>doesn't imply any expectation on the method
being called</em>. `EXPECT_CALL` not only defines the behavior, but also sets an
expectation that <em>the method will be called with the given arguments, for the
given number of times</em> (and *in the given order* when you specify the order
too).

Since `EXPECT_CALL` does more, isn't it better than `ON_CALL`? Not really. Every
`EXPECT_CALL` adds a constraint on the behavior of the code under test. Having
more constraints than necessary is *baaad* - even worse than not having enough
constraints.

This may be counter-intuitive. How could tests that verify more be worse than
tests that verify less? Isn't verification the whole point of tests?

The answer lies in *what* a test should verify. **A good test verifies the
contract of the code.** If a test over-specifies, it doesn't leave enough
freedom to the implementation. As a result, changing the implementation without
breaking the contract (e.g. refactoring and optimization), which should be
perfectly fine to do, can break such tests. Then you have to spend time fixing
them, only to see them broken again the next time the implementation is changed.

Keep in mind that one doesn't have to verify more than one property in one test.
In fact, **it's a good style to verify only one thing in one test.** If you do
that, a bug will likely break only one or two tests instead of dozens (which
case would you rather debug?). If you are also in the habit of giving tests
descriptive names that tell what they verify, you can often easily guess what's
wrong just from the test log itself.

So use `ON_CALL` by default, and only use `EXPECT_CALL` when you actually intend
to verify that the call is made. For example, you may have a bunch of `ON_CALL`s
in your test fixture to set the common mock behavior shared by all tests in the
same group, and write (scarcely) different `EXPECT_CALL`s in different `TEST_F`s
to verify different aspects of the code's behavior. Compared with the style
where each `TEST` has many `EXPECT_CALL`s, this leads to tests that are more
resilient to implementational changes (and thus less likely to require
maintenance) and makes the intent of the tests more obvious (so they are easier
to maintain when you do need to maintain them).

If you are bothered by the "Uninteresting mock function call" message printed
when a mock method without an `EXPECT_CALL` is called, you may use a `NiceMock`
instead to suppress all such messages for the mock object, or suppress the
message for specific methods by adding `EXPECT_CALL(...).Times(AnyNumber())`. DO
NOT suppress it by blindly adding an `EXPECT_CALL(...)`, or you'll have a test
that's a pain to maintain.

### Ignoring Uninteresting Calls

If you are not interested in how a mock method is called, just don't say
anything about it. In this case, if the method is ever called, gMock will
perform its default action to allow the test program to continue. If you are not
happy with the default action taken by gMock, you can override it using
`DefaultValue<T>::Set()` (described [here](#DefaultValue)) or `ON_CALL()`.

Please note that once you expressed interest in a particular mock method (via
`EXPECT_CALL()`), all invocations to it must match some expectation. If this
function is called but the arguments don't match any `EXPECT_CALL()` statement,
it will be an error.

### Disallowing Unexpected Calls

If a mock method shouldn't be called at all, explicitly say so:

```cpp
using ::testing::_;
...
  EXPECT_CALL(foo, Bar(_))
      .Times(0);
```

If some calls to the method are allowed, but the rest are not, just list all the
expected calls:

```cpp
using ::testing::AnyNumber;
using ::testing::Gt;
...
  EXPECT_CALL(foo, Bar(5));
  EXPECT_CALL(foo, Bar(Gt(10)))
      .Times(AnyNumber());
```

A call to `foo.Bar()` that doesn't match any of the `EXPECT_CALL()` statements
will be an error.

### Understanding Uninteresting vs Unexpected Calls {#uninteresting-vs-unexpected}

*Uninteresting* calls and *unexpected* calls are different concepts in gMock.
*Very* different.

A call `x.Y(...)` is **uninteresting** if there's *not even a single*
`EXPECT_CALL(x, Y(...))` set. In other words, the test isn't interested in the
`x.Y()` method at all, as evident in that the test doesn't care to say anything
about it.

A call `x.Y(...)` is **unexpected** if there are *some* `EXPECT_CALL(x,
Y(...))`s set, but none of them matches the call. Put another way, the test is
interested in the `x.Y()` method (therefore it explicitly sets some
`EXPECT_CALL` to verify how it's called); however, the verification fails as the
test doesn't expect this particular call to happen.

**An unexpected call is always an error,** as the code under test doesn't behave
the way the test expects it to behave.

**By default, an uninteresting call is not an error,** as it violates no
constraint specified by the test. (gMock's philosophy is that saying nothing
means there is no constraint.) However, it leads to a warning, as it *might*
indicate a problem (e.g. the test author might have forgotten to specify a
constraint).

In gMock, `NiceMock` and `StrictMock` can be used to make a mock class "nice" or
"strict". How does this affect uninteresting calls and unexpected calls?

A **nice mock** suppresses uninteresting call *warnings*. It is less chatty than
the default mock, but otherwise is the same. If a test fails with a default
mock, it will also fail using a nice mock instead. And vice versa. Don't expect
making a mock nice to change the test's result.

A **strict mock** turns uninteresting call warnings into errors. So making a
mock strict may change the test's result.

Let's look at an example:

```cpp
TEST(...) {
  NiceMock<MockDomainRegistry> mock_registry;
  EXPECT_CALL(mock_registry, GetDomainOwner("google.com"))
          .WillRepeatedly(Return("Larry Page"));

  // Use mock_registry in code under test.
  ... &mock_registry ...
}
```

The sole `EXPECT_CALL` here says that all calls to `GetDomainOwner()` must have
`"google.com"` as the argument. If `GetDomainOwner("yahoo.com")` is called, it
will be an unexpected call, and thus an error. *Having a nice mock doesn't
change the severity of an unexpected call.*

So how do we tell gMock that `GetDomainOwner()` can be called with some other
arguments as well? The standard technique is to add a "catch all" `EXPECT_CALL`:

```cpp
  EXPECT_CALL(mock_registry, GetDomainOwner(_))
        .Times(AnyNumber());  // catches all other calls to this method.
  EXPECT_CALL(mock_registry, GetDomainOwner("google.com"))
        .WillRepeatedly(Return("Larry Page"));
```

Remember that `_` is the wildcard matcher that matches anything. With this, if
`GetDomainOwner("google.com")` is called, it will do what the second
`EXPECT_CALL` says; if it is called with a different argument, it will do what
the first `EXPECT_CALL` says.

Note that the order of the two `EXPECT_CALL`s is important, as a newer
`EXPECT_CALL` takes precedence over an older one.

For more on uninteresting calls, nice mocks, and strict mocks, read
["The Nice, the Strict, and the Naggy"](#NiceStrictNaggy).

### Ignoring Uninteresting Arguments {#ParameterlessExpectations}

If your test doesn't care about the parameters (it only cares about the number
or order of calls), you can often simply omit the parameter list:

```cpp
  // Expect foo.Bar( ... ) twice with any arguments.
  EXPECT_CALL(foo, Bar).Times(2);

  // Delegate to the given method whenever the factory is invoked.
  ON_CALL(foo_factory, MakeFoo)
      .WillByDefault(&BuildFooForTest);
```

This functionality is only available when a method is not overloaded; to prevent
unexpected behavior it is a compilation error to try to set an expectation on a
method where the specific overload is ambiguous. You can work around this by
supplying a [simpler mock interface](#SimplerInterfaces) than the mocked class
provides.

This pattern is also useful when the arguments are interesting, but match logic
is substantially complex. You can leave the argument list unspecified and use
SaveArg actions to [save the values for later verification](#SaveArgVerify). If
you do that, you can easily differentiate calling the method the wrong number of
times from calling it with the wrong arguments.

### Expecting Ordered Calls {#OrderedCalls}

Although an `EXPECT_CALL()` statement defined later takes precedence when gMock
tries to match a function call with an expectation, by default calls don't have
to happen in the order `EXPECT_CALL()` statements are written. For example, if
the arguments match the matchers in the second `EXPECT_CALL()`, but not those in
the first and third, then the second expectation will be used.

If you would rather have all calls occur in the order of the expectations, put
the `EXPECT_CALL()` statements in a block where you define a variable of type
`InSequence`:

```cpp
using ::testing::_;
using ::testing::InSequence;

  {
    InSequence s;

    EXPECT_CALL(foo, DoThis(5));
    EXPECT_CALL(bar, DoThat(_))
        .Times(2);
    EXPECT_CALL(foo, DoThis(6));
  }
```

In this example, we expect a call to `foo.DoThis(5)`, followed by two calls to
`bar.DoThat()` where the argument can be anything, which are in turn followed by
a call to `foo.DoThis(6)`. If a call occurred out-of-order, gMock will report an
error.

### Expecting Partially Ordered Calls {#PartialOrder}

Sometimes requiring everything to occur in a predetermined order can lead to
brittle tests. For example, we may care about `A` occurring before both `B` and
`C`, but aren't interested in the relative order of `B` and `C`. In this case,
the test should reflect our real intent, instead of being overly constraining.

gMock allows you to impose an arbitrary DAG (directed acyclic graph) on the
calls. One way to express the DAG is to use the
[`After` clause](reference/mocking.md#EXPECT_CALL.After) of `EXPECT_CALL`.

Another way is via the `InSequence()` clause (not the same as the `InSequence`
class), which we borrowed from jMock 2. It's less flexible than `After()`, but
more convenient when you have long chains of sequential calls, as it doesn't
require you to come up with different names for the expectations in the chains.
Here's how it works:

If we view `EXPECT_CALL()` statements as nodes in a graph, and add an edge from
node A to node B wherever A must occur before B, we can get a DAG. We use the
term "sequence" to mean a directed path in this DAG. Now, if we decompose the
DAG into sequences, we just need to know which sequences each `EXPECT_CALL()`
belongs to in order to be able to reconstruct the original DAG.

So, to specify the partial order on the expectations we need to do two things:
first to define some `Sequence` objects, and then for each `EXPECT_CALL()` say
which `Sequence` objects it is part of.

Expectations in the same sequence must occur in the order they are written. For
example,

```cpp
using ::testing::Sequence;
...
  Sequence s1, s2;

  EXPECT_CALL(foo, A())
      .InSequence(s1, s2);
  EXPECT_CALL(bar, B())
      .InSequence(s1);
  EXPECT_CALL(bar, C())
      .InSequence(s2);
  EXPECT_CALL(foo, D())
      .InSequence(s2);
```

specifies the following DAG (where `s1` is `A -> B`, and `s2` is `A -> C -> D`):

```text
       +---> B
       |
  A ---|
       |
        +---> C ---> D
```

This means that A must occur before B and C, and C must occur before D. There's
no restriction about the order other than these.

### Controlling When an Expectation Retires

When a mock method is called, gMock only considers expectations that are still
active. An expectation is active when created, and becomes inactive (aka
*retires*) when a call that has to occur later has occurred. For example, in

```cpp
using ::testing::_;
using ::testing::Sequence;
...
  Sequence s1, s2;

  EXPECT_CALL(log, Log(WARNING, _, "File too large."))      // #1
      .Times(AnyNumber())
      .InSequence(s1, s2);
  EXPECT_CALL(log, Log(WARNING, _, "Data set is empty."))   // #2
      .InSequence(s1);
  EXPECT_CALL(log, Log(WARNING, _, "User not found."))      // #3
      .InSequence(s2);
```

as soon as either #2 or #3 is matched, #1 will retire. If a warning `"File too
large."` is logged after this, it will be an error.

Note that an expectation doesn't retire automatically when it's saturated. For
example,

```cpp
using ::testing::_;
...
  EXPECT_CALL(log, Log(WARNING, _, _));                     // #1
  EXPECT_CALL(log, Log(WARNING, _, "File too large."));     // #2
```

says that there will be exactly one warning with the message `"File too
large."`. If the second warning contains this message too, #2 will match again
and result in an upper-bound-violated error.

If this is not what you want, you can ask an expectation to retire as soon as it
becomes saturated:

```cpp
using ::testing::_;
...
  EXPECT_CALL(log, Log(WARNING, _, _));                     // #1
  EXPECT_CALL(log, Log(WARNING, _, "File too large."))      // #2
      .RetiresOnSaturation();
```

Here #2 can be used only once, so if you have two warnings with the message
`"File too large."`, the first will match #2 and the second will match #1 -
there will be no error.

## Using Actions

### Returning References from Mock Methods

If a mock function's return type is a reference, you need to use `ReturnRef()`
instead of `Return()` to return a result:

```cpp
using ::testing::ReturnRef;

class MockFoo : public Foo {
 public:
  MOCK_METHOD(Bar&, GetBar, (), (override));
};
...
  MockFoo foo;
  Bar bar;
  EXPECT_CALL(foo, GetBar())
      .WillOnce(ReturnRef(bar));
...
```

### Returning Live Values from Mock Methods

The `Return(x)` action saves a copy of `x` when the action is created, and
always returns the same value whenever it's executed. Sometimes you may want to
instead return the *live* value of `x` (i.e. its value at the time when the
action is *executed*.). Use either `ReturnRef()` or `ReturnPointee()` for this
purpose.

If the mock function's return type is a reference, you can do it using
`ReturnRef(x)`, as shown in the previous recipe ("Returning References from Mock
Methods"). However, gMock doesn't let you use `ReturnRef()` in a mock function
whose return type is not a reference, as doing that usually indicates a user
error. So, what shall you do?

Though you may be tempted, DO NOT use `std::ref()`:

```cpp
using testing::Return;

class MockFoo : public Foo {
 public:
  MOCK_METHOD(int, GetValue, (), (override));
};
...
  int x = 0;
  MockFoo foo;
  EXPECT_CALL(foo, GetValue())
      .WillRepeatedly(Return(std::ref(x)));  // Wrong!
  x = 42;
  EXPECT_EQ(42, foo.GetValue());
```

Unfortunately, it doesn't work here. The above code will fail with error:

```text
Value of: foo.GetValue()
  Actual: 0
Expected: 42
```

The reason is that `Return(*value*)` converts `value` to the actual return type
of the mock function at the time when the action is *created*, not when it is
*executed*. (This behavior was chosen for the action to be safe when `value` is
a proxy object that references some temporary objects.) As a result,
`std::ref(x)` is converted to an `int` value (instead of a `const int&`) when
the expectation is set, and `Return(std::ref(x))` will always return 0.

`ReturnPointee(pointer)` was provided to solve this problem specifically. It
returns the value pointed to by `pointer` at the time the action is *executed*:

```cpp
using testing::ReturnPointee;
...
  int x = 0;
  MockFoo foo;
  EXPECT_CALL(foo, GetValue())
      .WillRepeatedly(ReturnPointee(&x));  // Note the & here.
  x = 42;
  EXPECT_EQ(42, foo.GetValue());  // This will succeed now.
```

### Combining Actions

Want to do more than one thing when a function is called? That's fine. `DoAll()`
allow you to do sequence of actions every time. Only the return value of the
last action in the sequence will be used.

```cpp
using ::testing::_;
using ::testing::DoAll;

class MockFoo : public Foo {
 public:
  MOCK_METHOD(bool, Bar, (int n), (override));
};
...
  EXPECT_CALL(foo, Bar(_))
      .WillOnce(DoAll(action_1,
                      action_2,
                      ...
                      action_n));
```

### Verifying Complex Arguments {#SaveArgVerify}

If you want to verify that a method is called with a particular argument but the
match criteria is complex, it can be difficult to distinguish between
cardinality failures (calling the method the wrong number of times) and argument
match failures. Similarly, if you are matching multiple parameters, it may not
be easy to distinguishing which argument failed to match. For example:

```cpp
  // Not ideal: this could fail because of a problem with arg1 or arg2, or maybe
  // just the method wasn't called.
  EXPECT_CALL(foo, SendValues(_, ElementsAre(1, 4, 4, 7), EqualsProto( ... )));
```

You can instead save the arguments and test them individually:

```cpp
  EXPECT_CALL(foo, SendValues)
      .WillOnce(DoAll(SaveArg<1>(&actual_array), SaveArg<2>(&actual_proto)));
  ... run the test
  EXPECT_THAT(actual_array, ElementsAre(1, 4, 4, 7));
  EXPECT_THAT(actual_proto, EqualsProto( ... ));
```

### Mocking Side Effects {#MockingSideEffects}

Sometimes a method exhibits its effect not via returning a value but via side
effects. For example, it may change some global state or modify an output
argument. To mock side effects, in general you can define your own action by
implementing `::testing::ActionInterface`.

If all you need to do is to change an output argument, the built-in
`SetArgPointee()` action is convenient:

```cpp
using ::testing::_;
using ::testing::SetArgPointee;

class MockMutator : public Mutator {
 public:
  MOCK_METHOD(void, Mutate, (bool mutate, int* value), (override));
  ...
}
...
  MockMutator mutator;
  EXPECT_CALL(mutator, Mutate(true, _))
      .WillOnce(SetArgPointee<1>(5));
```

In this example, when `mutator.Mutate()` is called, we will assign 5 to the
`int` variable pointed to by argument #1 (0-based).

`SetArgPointee()` conveniently makes an internal copy of the value you pass to
it, removing the need to keep the value in scope and alive. The implication
however is that the value must have a copy constructor and assignment operator.

If the mock method also needs to return a value as well, you can chain
`SetArgPointee()` with `Return()` using `DoAll()`, remembering to put the
`Return()` statement last:

```cpp
using ::testing::_;
using ::testing::Return;
using ::testing::SetArgPointee;

class MockMutator : public Mutator {
 public:
  ...
  MOCK_METHOD(bool, MutateInt, (int* value), (override));
}
...
  MockMutator mutator;
  EXPECT_CALL(mutator, MutateInt(_))
      .WillOnce(DoAll(SetArgPointee<0>(5),
                      Return(true)));
```

Note, however, that if you use the `ReturnOKWith()` method, it will override the
values provided by `SetArgPointee()` in the response parameters of your function
call.

If the output argument is an array, use the `SetArrayArgument<N>(first, last)`
action instead. It copies the elements in source range `[first, last)` to the
array pointed to by the `N`-th (0-based) argument:

```cpp
using ::testing::NotNull;
using ::testing::SetArrayArgument;

class MockArrayMutator : public ArrayMutator {
 public:
  MOCK_METHOD(void, Mutate, (int* values, int num_values), (override));
  ...
}
...
  MockArrayMutator mutator;
  int values[5] = {1, 2, 3, 4, 5};
  EXPECT_CALL(mutator, Mutate(NotNull(), 5))
      .WillOnce(SetArrayArgument<0>(values, values + 5));
```

This also works when the argument is an output iterator:

```cpp
using ::testing::_;
using ::testing::SetArrayArgument;

class MockRolodex : public Rolodex {
 public:
  MOCK_METHOD(void, GetNames, (std::back_insert_iterator<vector<string>>),
              (override));
  ...
}
...
  MockRolodex rolodex;
  vector<string> names;
  names.push_back("George");
  names.push_back("John");
  names.push_back("Thomas");
  EXPECT_CALL(rolodex, GetNames(_))
      .WillOnce(SetArrayArgument<0>(names.begin(), names.end()));
```

### Changing a Mock Object's Behavior Based on the State

If you expect a call to change the behavior of a mock object, you can use
`::testing::InSequence` to specify different behaviors before and after the
call:

```cpp
using ::testing::InSequence;
using ::testing::Return;

...
  {
     InSequence seq;
     EXPECT_CALL(my_mock, IsDirty())
         .WillRepeatedly(Return(true));
     EXPECT_CALL(my_mock, Flush());
     EXPECT_CALL(my_mock, IsDirty())
         .WillRepeatedly(Return(false));
  }
  my_mock.FlushIfDirty();
```

This makes `my_mock.IsDirty()` return `true` before `my_mock.Flush()` is called
and return `false` afterwards.

If the behavior change is more complex, you can store the effects in a variable
and make a mock method get its return value from that variable:

```cpp
using ::testing::_;
using ::testing::SaveArg;
using ::testing::Return;

ACTION_P(ReturnPointee, p) { return *p; }
...
  int previous_value = 0;
  EXPECT_CALL(my_mock, GetPrevValue)
      .WillRepeatedly(ReturnPointee(&previous_value));
  EXPECT_CALL(my_mock, UpdateValue)
      .WillRepeatedly(SaveArg<0>(&previous_value));
  my_mock.DoSomethingToUpdateValue();
```

Here `my_mock.GetPrevValue()` will always return the argument of the last
`UpdateValue()` call.

### Setting the Default Value for a Return Type {#DefaultValue}

If a mock method's return type is a built-in C++ type or pointer, by default it
will return 0 when invoked. Also, in C++ 11 and above, a mock method whose
return type has a default constructor will return a default-constructed value by
default. You only need to specify an action if this default value doesn't work
for you.

Sometimes, you may want to change this default value, or you may want to specify
a default value for types gMock doesn't know about. You can do this using the
`::testing::DefaultValue` class template:

```cpp
using ::testing::DefaultValue;

class MockFoo : public Foo {
 public:
  MOCK_METHOD(Bar, CalculateBar, (), (override));
};


...
  Bar default_bar;
  // Sets the default return value for type Bar.
  DefaultValue<Bar>::Set(default_bar);

  MockFoo foo;

  // We don't need to specify an action here, as the default
  // return value works for us.
  EXPECT_CALL(foo, CalculateBar());

  foo.CalculateBar();  // This should return default_bar.

  // Unsets the default return value.
  DefaultValue<Bar>::Clear();
```

Please note that changing the default value for a type can make your tests hard
to understand. We recommend you to use this feature judiciously. For example,
you may want to make sure the `Set()` and `Clear()` calls are right next to the
code that uses your mock.

### Setting the Default Actions for a Mock Method

You've learned how to change the default value of a given type. However, this
may be too coarse for your purpose: perhaps you have two mock methods with the
same return type and you want them to have different behaviors. The `ON_CALL()`
macro allows you to customize your mock's behavior at the method level:

```cpp
using ::testing::_;
using ::testing::AnyNumber;
using ::testing::Gt;
using ::testing::Return;
...
  ON_CALL(foo, Sign(_))
      .WillByDefault(Return(-1));
  ON_CALL(foo, Sign(0))
      .WillByDefault(Return(0));
  ON_CALL(foo, Sign(Gt(0)))
      .WillByDefault(Return(1));

  EXPECT_CALL(foo, Sign(_))
      .Times(AnyNumber());

  foo.Sign(5);   // This should return 1.
  foo.Sign(-9);  // This should return -1.
  foo.Sign(0);   // This should return 0.
```

As you may have guessed, when there are more than one `ON_CALL()` statements,
the newer ones in the order take precedence over the older ones. In other words,
the **last** one that matches the function arguments will be used. This matching
order allows you to set up the common behavior in a mock object's constructor or
the test fixture's set-up phase and specialize the mock's behavior later.

Note that both `ON_CALL` and `EXPECT_CALL` have the same "later statements take
precedence" rule, but they don't interact. That is, `EXPECT_CALL`s have their
own precedence order distinct from the `ON_CALL` precedence order.

### Using Functions/Methods/Functors/Lambdas as Actions {#FunctionsAsActions}

If the built-in actions don't suit you, you can use an existing callable
(function, `std::function`, method, functor, lambda) as an action.

```cpp
using ::testing::_; using ::testing::Invoke;

class MockFoo : public Foo {
 public:
  MOCK_METHOD(int, Sum, (int x, int y), (override));
  MOCK_METHOD(bool, ComplexJob, (int x), (override));
};

int CalculateSum(int x, int y) { return x + y; }
int Sum3(int x, int y, int z) { return x + y + z; }

class Helper {
 public:
  bool ComplexJob(int x);
};

...
  MockFoo foo;
  Helper helper;
  EXPECT_CALL(foo, Sum(_, _))
      .WillOnce(&CalculateSum)
      .WillRepeatedly(Invoke(NewPermanentCallback(Sum3, 1)));
  EXPECT_CALL(foo, ComplexJob(_))
      .WillOnce(Invoke(&helper, &Helper::ComplexJob))
      .WillOnce([] { return true; })
      .WillRepeatedly([](int x) { return x > 0; });

  foo.Sum(5, 6);         // Invokes CalculateSum(5, 6).
  foo.Sum(2, 3);         // Invokes Sum3(1, 2, 3).
  foo.ComplexJob(10);    // Invokes helper.ComplexJob(10).
  foo.ComplexJob(-1);    // Invokes the inline lambda.
```

The only requirement is that the type of the function, etc must be *compatible*
with the signature of the mock function, meaning that the latter's arguments (if
it takes any) can be implicitly converted to the corresponding arguments of the
former, and the former's return type can be implicitly converted to that of the
latter. So, you can invoke something whose type is *not* exactly the same as the
mock function, as long as it's safe to do so - nice, huh?

Note that:

*   The action takes ownership of the callback and will delete it when the
    action itself is destructed.
*   If the type of a callback is derived from a base callback type `C`, you need
    to implicitly cast it to `C` to resolve the overloading, e.g.

    ```cpp
    using ::testing::Invoke;
    ...
      ResultCallback<bool>* is_ok = ...;
      ... Invoke(is_ok) ...;  // This works.

      BlockingClosure* done = new BlockingClosure;
      ... Invoke(implicit_cast<Closure*>(done)) ...;  // The cast is necessary.
    ```

### Using Functions with Extra Info as Actions

The function or functor you call using `Invoke()` must have the same number of
arguments as the mock function you use it for. Sometimes you may have a function
that takes more arguments, and you are willing to pass in the extra arguments
yourself to fill the gap. You can do this in gMock using callbacks with
pre-bound arguments. Here's an example:

```cpp
using ::testing::Invoke;

class MockFoo : public Foo {
 public:
  MOCK_METHOD(char, DoThis, (int n), (override));
};

char SignOfSum(int x, int y) {
  const int sum = x + y;
  return (sum > 0) ? '+' : (sum < 0) ? '-' : '0';
}

TEST_F(FooTest, Test) {
  MockFoo foo;

  EXPECT_CALL(foo, DoThis(2))
      .WillOnce(Invoke(NewPermanentCallback(SignOfSum, 5)));
  EXPECT_EQ('+', foo.DoThis(2));  // Invokes SignOfSum(5, 2).
}
```

### Invoking a Function/Method/Functor/Lambda/Callback Without Arguments

`Invoke()` passes the mock function's arguments to the function, etc being
invoked such that the callee has the full context of the call to work with. If
the invoked function is not interested in some or all of the arguments, it can
simply ignore them.

Yet, a common pattern is that a test author wants to invoke a function without
the arguments of the mock function. She could do that using a wrapper function
that throws away the arguments before invoking an underlining nullary function.
Needless to say, this can be tedious and obscures the intent of the test.

There are two solutions to this problem. First, you can pass any callable of
zero args as an action. Alternatively, use `InvokeWithoutArgs()`, which is like
`Invoke()` except that it doesn't pass the mock function's arguments to the
callee. Here's an example of each:

```cpp
using ::testing::_;
using ::testing::InvokeWithoutArgs;

class MockFoo : public Foo {
 public:
  MOCK_METHOD(bool, ComplexJob, (int n), (override));
};

bool Job1() { ... }
bool Job2(int n, char c) { ... }

...
  MockFoo foo;
  EXPECT_CALL(foo, ComplexJob(_))
      .WillOnce([] { Job1(); });
      .WillOnce(InvokeWithoutArgs(NewPermanentCallback(Job2, 5, 'a')));

  foo.ComplexJob(10);  // Invokes Job1().
  foo.ComplexJob(20);  // Invokes Job2(5, 'a').
```

Note that:

*   The action takes ownership of the callback and will delete it when the
    action itself is destructed.
*   If the type of a callback is derived from a base callback type `C`, you need
    to implicitly cast it to `C` to resolve the overloading, e.g.

    ```cpp
    using ::testing::InvokeWithoutArgs;
    ...
      ResultCallback<bool>* is_ok = ...;
      ... InvokeWithoutArgs(is_ok) ...;  // This works.

      BlockingClosure* done = ...;
      ... InvokeWithoutArgs(implicit_cast<Closure*>(done)) ...;
      // The cast is necessary.
    ```

### Invoking an Argument of the Mock Function

Sometimes a mock function will receive a function pointer, a functor (in other
words, a "callable") as an argument, e.g.

```cpp
class MockFoo : public Foo {
 public:
  MOCK_METHOD(bool, DoThis, (int n, (ResultCallback1<bool, int>* callback)),
              (override));
};
```

and you may want to invoke this callable argument:

```cpp
using ::testing::_;
...
  MockFoo foo;
  EXPECT_CALL(foo, DoThis(_, _))
      .WillOnce(...);
      // Will execute callback->Run(5), where callback is the
      // second argument DoThis() receives.
```

{: .callout .note}
NOTE: The section below is legacy documentation from before C++ had lambdas:

Arghh, you need to refer to a mock function argument but C++ has no lambda
(yet), so you have to define your own action. :-( Or do you really?

Well, gMock has an action to solve *exactly* this problem:

```cpp
InvokeArgument<N>(arg_1, arg_2, ..., arg_m)
```

will invoke the `N`-th (0-based) argument the mock function receives, with
`arg_1`, `arg_2`, ..., and `arg_m`. No matter if the argument is a function
pointer, a functor, or a callback. gMock handles them all.

With that, you could write:

```cpp
using ::testing::_;
using ::testing::InvokeArgument;
...
  EXPECT_CALL(foo, DoThis(_, _))
      .WillOnce(InvokeArgument<1>(5));
      // Will execute callback->Run(5), where callback is the
      // second argument DoThis() receives.
```

What if the callable takes an argument by reference? No problem - just wrap it
inside `std::ref()`:

```cpp
  ...
  MOCK_METHOD(bool, Bar,
              ((ResultCallback2<bool, int, const Helper&>* callback)),
              (override));
  ...
  using ::testing::_;
  using ::testing::InvokeArgument;
  ...
  MockFoo foo;
  Helper helper;
  ...
  EXPECT_CALL(foo, Bar(_))
      .WillOnce(InvokeArgument<0>(5, std::ref(helper)));
      // std::ref(helper) guarantees that a reference to helper, not a copy of
      // it, will be passed to the callback.
```

What if the callable takes an argument by reference and we do **not** wrap the
argument in `std::ref()`? Then `InvokeArgument()` will *make a copy* of the
argument, and pass a *reference to the copy*, instead of a reference to the
original value, to the callable. This is especially handy when the argument is a
temporary value:

```cpp
  ...
  MOCK_METHOD(bool, DoThat, (bool (*f)(const double& x, const string& s)),
              (override));
  ...
  using ::testing::_;
  using ::testing::InvokeArgument;
  ...
  MockFoo foo;
  ...
  EXPECT_CALL(foo, DoThat(_))
      .WillOnce(InvokeArgument<0>(5.0, string("Hi")));
      // Will execute (*f)(5.0, string("Hi")), where f is the function pointer
      // DoThat() receives.  Note that the values 5.0 and string("Hi") are
      // temporary and dead once the EXPECT_CALL() statement finishes.  Yet
      // it's fine to perform this action later, since a copy of the values
      // are kept inside the InvokeArgument action.
```

### Ignoring an Action's Result

Sometimes you have an action that returns *something*, but you need an action
that returns `void` (perhaps you want to use it in a mock function that returns
`void`, or perhaps it needs to be used in `DoAll()` and it's not the last in the
list). `IgnoreResult()` lets you do that. For example:

```cpp
using ::testing::_;
using ::testing::DoAll;
using ::testing::IgnoreResult;
using ::testing::Return;

int Process(const MyData& data);
string DoSomething();

class MockFoo : public Foo {
 public:
  MOCK_METHOD(void, Abc, (const MyData& data), (override));
  MOCK_METHOD(bool, Xyz, (), (override));
};

  ...
  MockFoo foo;
  EXPECT_CALL(foo, Abc(_))
      // .WillOnce(Invoke(Process));
      // The above line won't compile as Process() returns int but Abc() needs
      // to return void.
      .WillOnce(IgnoreResult(Process));
  EXPECT_CALL(foo, Xyz())
      .WillOnce(DoAll(IgnoreResult(DoSomething),
                      // Ignores the string DoSomething() returns.
                      Return(true)));
```

Note that you **cannot** use `IgnoreResult()` on an action that already returns
`void`. Doing so will lead to ugly compiler errors.

### Selecting an Action's Arguments {#SelectingArgs}

Say you have a mock function `Foo()` that takes seven arguments, and you have a
custom action that you want to invoke when `Foo()` is called. Trouble is, the
custom action only wants three arguments:

```cpp
using ::testing::_;
using ::testing::Invoke;
...
  MOCK_METHOD(bool, Foo,
              (bool visible, const string& name, int x, int y,
               (const map<pair<int, int>>), double& weight, double min_weight,
               double max_wight));
...
bool IsVisibleInQuadrant1(bool visible, int x, int y) {
  return visible && x >= 0 && y >= 0;
}
...
  EXPECT_CALL(mock, Foo)
      .WillOnce(Invoke(IsVisibleInQuadrant1));  // Uh, won't compile. :-(
```

To please the compiler God, you need to define an "adaptor" that has the same
signature as `Foo()` and calls the custom action with the right arguments:

```cpp
using ::testing::_;
using ::testing::Invoke;
...
bool MyIsVisibleInQuadrant1(bool visible, const string& name, int x, int y,
                            const map<pair<int, int>, double>& weight,
                            double min_weight, double max_wight) {
  return IsVisibleInQuadrant1(visible, x, y);
}
...
  EXPECT_CALL(mock, Foo)
      .WillOnce(Invoke(MyIsVisibleInQuadrant1));  // Now it works.
```

But isn't this awkward?

gMock provides a generic *action adaptor*, so you can spend your time minding
more important business than writing your own adaptors. Here's the syntax:

```cpp
WithArgs<N1, N2, ..., Nk>(action)
```

creates an action that passes the arguments of the mock function at the given
indices (0-based) to the inner `action` and performs it. Using `WithArgs`, our
original example can be written as:

```cpp
using ::testing::_;
using ::testing::Invoke;
using ::testing::WithArgs;
...
  EXPECT_CALL(mock, Foo)
      .WillOnce(WithArgs<0, 2, 3>(Invoke(IsVisibleInQuadrant1)));  // No need to define your own adaptor.
```

For better readability, gMock also gives you:

*   `WithoutArgs(action)` when the inner `action` takes *no* argument, and
*   `WithArg<N>(action)` (no `s` after `Arg`) when the inner `action` takes
    *one* argument.

As you may have realized, `InvokeWithoutArgs(...)` is just syntactic sugar for
`WithoutArgs(Invoke(...))`.

Here are more tips:

*   The inner action used in `WithArgs` and friends does not have to be
    `Invoke()` -- it can be anything.
*   You can repeat an argument in the argument list if necessary, e.g.
    `WithArgs<2, 3, 3, 5>(...)`.
*   You can change the order of the arguments, e.g. `WithArgs<3, 2, 1>(...)`.
*   The types of the selected arguments do *not* have to match the signature of
    the inner action exactly. It works as long as they can be implicitly
    converted to the corresponding arguments of the inner action. For example,
    if the 4-th argument of the mock function is an `int` and `my_action` takes
    a `double`, `WithArg<4>(my_action)` will work.

### Ignoring Arguments in Action Functions

The [selecting-an-action's-arguments](#SelectingArgs) recipe showed us one way
to make a mock function and an action with incompatible argument lists fit
together. The downside is that wrapping the action in `WithArgs<...>()` can get
tedious for people writing the tests.

If you are defining a function (or method, functor, lambda, callback) to be used
with `Invoke*()`, and you are not interested in some of its arguments, an
alternative to `WithArgs` is to declare the uninteresting arguments as `Unused`.
This makes the definition less cluttered and less fragile in case the types of
the uninteresting arguments change. It could also increase the chance the action
function can be reused. For example, given

```cpp
 public:
  MOCK_METHOD(double, Foo, double(const string& label, double x, double y),
              (override));
  MOCK_METHOD(double, Bar, (int index, double x, double y), (override));
```

instead of

```cpp
using ::testing::_;
using ::testing::Invoke;

double DistanceToOriginWithLabel(const string& label, double x, double y) {
  return sqrt(x*x + y*y);
}
double DistanceToOriginWithIndex(int index, double x, double y) {
  return sqrt(x*x + y*y);
}
...
  EXPECT_CALL(mock, Foo("abc", _, _))
      .WillOnce(Invoke(DistanceToOriginWithLabel));
  EXPECT_CALL(mock, Bar(5, _, _))
      .WillOnce(Invoke(DistanceToOriginWithIndex));
```

you could write

```cpp
using ::testing::_;
using ::testing::Invoke;
using ::testing::Unused;

double DistanceToOrigin(Unused, double x, double y) {
  return sqrt(x*x + y*y);
}
...
  EXPECT_CALL(mock, Foo("abc", _, _))
      .WillOnce(Invoke(DistanceToOrigin));
  EXPECT_CALL(mock, Bar(5, _, _))
      .WillOnce(Invoke(DistanceToOrigin));
```

### Sharing Actions

Just like matchers, a gMock action object consists of a pointer to a ref-counted
implementation object. Therefore copying actions is also allowed and very
efficient. When the last action that references the implementation object dies,
the implementation object will be deleted.

If you have some complex action that you want to use again and again, you may
not have to build it from scratch everytime. If the action doesn't have an
internal state (i.e. if it always does the same thing no matter how many times
it has been called), you can assign it to an action variable and use that
variable repeatedly. For example:

```cpp
using ::testing::Action;
using ::testing::DoAll;
using ::testing::Return;
using ::testing::SetArgPointee;
...
  Action<bool(int*)> set_flag = DoAll(SetArgPointee<0>(5),
                                      Return(true));
  ... use set_flag in .WillOnce() and .WillRepeatedly() ...
```

However, if the action has its own state, you may be surprised if you share the
action object. Suppose you have an action factory `IncrementCounter(init)` which
creates an action that increments and returns a counter whose initial value is
`init`, using two actions created from the same expression and using a shared
action will exhibit different behaviors. Example:

```cpp
  EXPECT_CALL(foo, DoThis())
      .WillRepeatedly(IncrementCounter(0));
  EXPECT_CALL(foo, DoThat())
      .WillRepeatedly(IncrementCounter(0));
  foo.DoThis();  // Returns 1.
  foo.DoThis();  // Returns 2.
  foo.DoThat();  // Returns 1 - Blah() uses a different
                 // counter than Bar()'s.
```

versus

```cpp
using ::testing::Action;
...
  Action<int()> increment = IncrementCounter(0);
  EXPECT_CALL(foo, DoThis())
      .WillRepeatedly(increment);
  EXPECT_CALL(foo, DoThat())
      .WillRepeatedly(increment);
  foo.DoThis();  // Returns 1.
  foo.DoThis();  // Returns 2.
  foo.DoThat();  // Returns 3 - the counter is shared.
```

### Testing Asynchronous Behavior

One oft-encountered problem with gMock is that it can be hard to test
asynchronous behavior. Suppose you had a `EventQueue` class that you wanted to
test, and you created a separate `EventDispatcher` interface so that you could
easily mock it out. However, the implementation of the class fired all the
events on a background thread, which made test timings difficult. You could just
insert `sleep()` statements and hope for the best, but that makes your test
behavior nondeterministic. A better way is to use gMock actions and
`Notification` objects to force your asynchronous test to behave synchronously.

```cpp
class MockEventDispatcher : public EventDispatcher {
  MOCK_METHOD(bool, DispatchEvent, (int32), (override));
};

TEST(EventQueueTest, EnqueueEventTest) {
  MockEventDispatcher mock_event_dispatcher;
  EventQueue event_queue(&mock_event_dispatcher);

  const int32 kEventId = 321;
  absl::Notification done;
  EXPECT_CALL(mock_event_dispatcher, DispatchEvent(kEventId))
      .WillOnce([&done] { done.Notify(); });

  event_queue.EnqueueEvent(kEventId);
  done.WaitForNotification();
}
```

In the example above, we set our normal gMock expectations, but then add an
additional action to notify the `Notification` object. Now we can just call
`Notification::WaitForNotification()` in the main thread to wait for the
asynchronous call to finish. After that, our test suite is complete and we can
safely exit.

{: .callout .note}
Note: this example has a downside: namely, if the expectation is not satisfied,
our test will run forever. It will eventually time-out and fail, but it will
take longer and be slightly harder to debug. To alleviate this problem, you can
use `WaitForNotificationWithTimeout(ms)` instead of `WaitForNotification()`.

## Misc Recipes on Using gMock

### Mocking Methods That Use Move-Only Types

C++11 introduced *move-only types*. A move-only-typed value can be moved from
one object to another, but cannot be copied. `std::unique_ptr<T>` is probably
the most commonly used move-only type.

Mocking a method that takes and/or returns move-only types presents some
challenges, but nothing insurmountable. This recipe shows you how you can do it.
Note that the support for move-only method arguments was only introduced to
gMock in April 2017; in older code, you may find more complex
[workarounds](#LegacyMoveOnly) for lack of this feature.

Let’s say we are working on a fictional project that lets one post and share
snippets called “buzzes”. Your code uses these types:

```cpp
enum class AccessLevel { kInternal, kPublic };

class Buzz {
 public:
  explicit Buzz(AccessLevel access) { ... }
  ...
};

class Buzzer {
 public:
  virtual ~Buzzer() {}
  virtual std::unique_ptr<Buzz> MakeBuzz(StringPiece text) = 0;
  virtual bool ShareBuzz(std::unique_ptr<Buzz> buzz, int64_t timestamp) = 0;
  ...
};
```

A `Buzz` object represents a snippet being posted. A class that implements the
`Buzzer` interface is capable of creating and sharing `Buzz`es. Methods in
`Buzzer` may return a `unique_ptr<Buzz>` or take a `unique_ptr<Buzz>`. Now we
need to mock `Buzzer` in our tests.

To mock a method that accepts or returns move-only types, you just use the
familiar `MOCK_METHOD` syntax as usual:

```cpp
class MockBuzzer : public Buzzer {
 public:
  MOCK_METHOD(std::unique_ptr<Buzz>, MakeBuzz, (StringPiece text), (override));
  MOCK_METHOD(bool, ShareBuzz, (std::unique_ptr<Buzz> buzz, int64_t timestamp),
              (override));
};
```

Now that we have the mock class defined, we can use it in tests. In the
following code examples, we assume that we have defined a `MockBuzzer` object
named `mock_buzzer_`:

```cpp
  MockBuzzer mock_buzzer_;
```

First let’s see how we can set expectations on the `MakeBuzz()` method, which
returns a `unique_ptr<Buzz>`.

As usual, if you set an expectation without an action (i.e. the `.WillOnce()` or
`.WillRepeatedly()` clause), when that expectation fires, the default action for
that method will be taken. Since `unique_ptr<>` has a default constructor that
returns a null `unique_ptr`, that’s what you’ll get if you don’t specify an
action:

```cpp
  // Use the default action.
  EXPECT_CALL(mock_buzzer_, MakeBuzz("hello"));

  // Triggers the previous EXPECT_CALL.
  EXPECT_EQ(nullptr, mock_buzzer_.MakeBuzz("hello"));
```

If you are not happy with the default action, you can tweak it as usual; see
[Setting Default Actions](#OnCall).

If you just need to return a pre-defined move-only value, you can use the
`Return(ByMove(...))` action:

```cpp
  // When this fires, the unique_ptr<> specified by ByMove(...) will
  // be returned.
  EXPECT_CALL(mock_buzzer_, MakeBuzz("world"))
      .WillOnce(Return(ByMove(MakeUnique<Buzz>(AccessLevel::kInternal))));

  EXPECT_NE(nullptr, mock_buzzer_.MakeBuzz("world"));
```

Note that `ByMove()` is essential here - if you drop it, the code won’t compile.

Quiz time! What do you think will happen if a `Return(ByMove(...))` action is
performed more than once (e.g. you write `...
.WillRepeatedly(Return(ByMove(...)));`)? Come think of it, after the first time
the action runs, the source value will be consumed (since it’s a move-only
value), so the next time around, there’s no value to move from -- you’ll get a
run-time error that `Return(ByMove(...))` can only be run once.

If you need your mock method to do more than just moving a pre-defined value,
remember that you can always use a lambda or a callable object, which can do
pretty much anything you want:

```cpp
  EXPECT_CALL(mock_buzzer_, MakeBuzz("x"))
      .WillRepeatedly([](StringPiece text) {
        return MakeUnique<Buzz>(AccessLevel::kInternal);
      });

  EXPECT_NE(nullptr, mock_buzzer_.MakeBuzz("x"));
  EXPECT_NE(nullptr, mock_buzzer_.MakeBuzz("x"));
```

Every time this `EXPECT_CALL` fires, a new `unique_ptr<Buzz>` will be created
and returned. You cannot do this with `Return(ByMove(...))`.

That covers returning move-only values; but how do we work with methods
accepting move-only arguments? The answer is that they work normally, although
some actions will not compile when any of method's arguments are move-only. You
can always use `Return`, or a [lambda or functor](#FunctionsAsActions):

```cpp
  using ::testing::Unused;

  EXPECT_CALL(mock_buzzer_, ShareBuzz(NotNull(), _)).WillOnce(Return(true));
  EXPECT_TRUE(mock_buzzer_.ShareBuzz(MakeUnique<Buzz>(AccessLevel::kInternal)),
              0);

  EXPECT_CALL(mock_buzzer_, ShareBuzz(_, _)).WillOnce(
      [](std::unique_ptr<Buzz> buzz, Unused) { return buzz != nullptr; });
  EXPECT_FALSE(mock_buzzer_.ShareBuzz(nullptr, 0));
```

Many built-in actions (`WithArgs`, `WithoutArgs`,`DeleteArg`, `SaveArg`, ...)
could in principle support move-only arguments, but the support for this is not
implemented yet. If this is blocking you, please file a bug.

A few actions (e.g. `DoAll`) copy their arguments internally, so they can never
work with non-copyable objects; you'll have to use functors instead.

#### Legacy workarounds for move-only types {#LegacyMoveOnly}

Support for move-only function arguments was only introduced to gMock in April
of 2017. In older code, you may encounter the following workaround for the lack
of this feature (it is no longer necessary - we're including it just for
reference):

```cpp
class MockBuzzer : public Buzzer {
 public:
  MOCK_METHOD(bool, DoShareBuzz, (Buzz* buzz, Time timestamp));
  bool ShareBuzz(std::unique_ptr<Buzz> buzz, Time timestamp) override {
    return DoShareBuzz(buzz.get(), timestamp);
  }
};
```

The trick is to delegate the `ShareBuzz()` method to a mock method (let’s call
it `DoShareBuzz()`) that does not take move-only parameters. Then, instead of
setting expectations on `ShareBuzz()`, you set them on the `DoShareBuzz()` mock
method:

```cpp
  MockBuzzer mock_buzzer_;
  EXPECT_CALL(mock_buzzer_, DoShareBuzz(NotNull(), _));

  // When one calls ShareBuzz() on the MockBuzzer like this, the call is
  // forwarded to DoShareBuzz(), which is mocked.  Therefore this statement
  // will trigger the above EXPECT_CALL.
  mock_buzzer_.ShareBuzz(MakeUnique<Buzz>(AccessLevel::kInternal), 0);
```

### Making the Compilation Faster

Believe it or not, the *vast majority* of the time spent on compiling a mock
class is in generating its constructor and destructor, as they perform
non-trivial tasks (e.g. verification of the expectations). What's more, mock
methods with different signatures have different types and thus their
constructors/destructors need to be generated by the compiler separately. As a
result, if you mock many different types of methods, compiling your mock class
can get really slow.

If you are experiencing slow compilation, you can move the definition of your
mock class' constructor and destructor out of the class body and into a `.cc`
file. This way, even if you `#include` your mock class in N files, the compiler
only needs to generate its constructor and destructor once, resulting in a much
faster compilation.

Let's illustrate the idea using an example. Here's the definition of a mock
class before applying this recipe:

```cpp
// File mock_foo.h.
...
class MockFoo : public Foo {
 public:
  // Since we don't declare the constructor or the destructor,
  // the compiler will generate them in every translation unit
  // where this mock class is used.

  MOCK_METHOD(int, DoThis, (), (override));
  MOCK_METHOD(bool, DoThat, (const char* str), (override));
  ... more mock methods ...
};
```

After the change, it would look like:

```cpp
// File mock_foo.h.
...
class MockFoo : public Foo {
 public:
  // The constructor and destructor are declared, but not defined, here.
  MockFoo();
  virtual ~MockFoo();

  MOCK_METHOD(int, DoThis, (), (override));
  MOCK_METHOD(bool, DoThat, (const char* str), (override));
  ... more mock methods ...
};
```

and

```cpp
// File mock_foo.cc.
#include "path/to/mock_foo.h"

// The definitions may appear trivial, but the functions actually do a
// lot of things through the constructors/destructors of the member
// variables used to implement the mock methods.
MockFoo::MockFoo() {}
MockFoo::~MockFoo() {}
```

### Forcing a Verification

When it's being destroyed, your friendly mock object will automatically verify
that all expectations on it have been satisfied, and will generate googletest
failures if not. This is convenient as it leaves you with one less thing to
worry about. That is, unless you are not sure if your mock object will be
destroyed.

How could it be that your mock object won't eventually be destroyed? Well, it
might be created on the heap and owned by the code you are testing. Suppose
there's a bug in that code and it doesn't delete the mock object properly - you
could end up with a passing test when there's actually a bug.

Using a heap checker is a good idea and can alleviate the concern, but its
implementation is not 100% reliable. So, sometimes you do want to *force* gMock
to verify a mock object before it is (hopefully) destructed. You can do this
with `Mock::VerifyAndClearExpectations(&mock_object)`:

```cpp
TEST(MyServerTest, ProcessesRequest) {
  using ::testing::Mock;

  MockFoo* const foo = new MockFoo;
  EXPECT_CALL(*foo, ...)...;
  // ... other expectations ...

  // server now owns foo.
  MyServer server(foo);
  server.ProcessRequest(...);

  // In case that server's destructor will forget to delete foo,
  // this will verify the expectations anyway.
  Mock::VerifyAndClearExpectations(foo);
}  // server is destroyed when it goes out of scope here.
```

{: .callout .tip}
**Tip:** The `Mock::VerifyAndClearExpectations()` function returns a `bool` to
indicate whether the verification was successful (`true` for yes), so you can
wrap that function call inside a `ASSERT_TRUE()` if there is no point going
further when the verification has failed.

Do not set new expectations after verifying and clearing a mock after its use.
Setting expectations after code that exercises the mock has undefined behavior.
See [Using Mocks in Tests](gmock_for_dummies.md#using-mocks-in-tests) for more
information.

### Using Checkpoints {#UsingCheckPoints}

Sometimes you might want to test a mock object's behavior in phases whose sizes
are each manageable, or you might want to set more detailed expectations about
which API calls invoke which mock functions.

A technique you can use is to put the expectations in a sequence and insert
calls to a dummy "checkpoint" function at specific places. Then you can verify
that the mock function calls do happen at the right time. For example, if you
are exercising the code:

```cpp
  Foo(1);
  Foo(2);
  Foo(3);
```

and want to verify that `Foo(1)` and `Foo(3)` both invoke `mock.Bar("a")`, but
`Foo(2)` doesn't invoke anything, you can write:

```cpp
using ::testing::MockFunction;

TEST(FooTest, InvokesBarCorrectly) {
  MyMock mock;
  // Class MockFunction<F> has exactly one mock method.  It is named
  // Call() and has type F.
  MockFunction<void(string check_point_name)> check;
  {
    InSequence s;

    EXPECT_CALL(mock, Bar("a"));
    EXPECT_CALL(check, Call("1"));
    EXPECT_CALL(check, Call("2"));
    EXPECT_CALL(mock, Bar("a"));
  }
  Foo(1);
  check.Call("1");
  Foo(2);
  check.Call("2");
  Foo(3);
}
```

The expectation spec says that the first `Bar("a")` call must happen before
checkpoint "1", the second `Bar("a")` call must happen after checkpoint "2", and
nothing should happen between the two checkpoints. The explicit checkpoints make
it clear which `Bar("a")` is called by which call to `Foo()`.

### Mocking Destructors

Sometimes you want to make sure a mock object is destructed at the right time,
e.g. after `bar->A()` is called but before `bar->B()` is called. We already know
that you can specify constraints on the [order](#OrderedCalls) of mock function
calls, so all we need to do is to mock the destructor of the mock function.

This sounds simple, except for one problem: a destructor is a special function
with special syntax and special semantics, and the `MOCK_METHOD` macro doesn't
work for it:

```cpp
MOCK_METHOD(void, ~MockFoo, ());  // Won't compile!
```

The good news is that you can use a simple pattern to achieve the same effect.
First, add a mock function `Die()` to your mock class and call it in the
destructor, like this:

```cpp
class MockFoo : public Foo {
  ...
  // Add the following two lines to the mock class.
  MOCK_METHOD(void, Die, ());
  ~MockFoo() override { Die(); }
};
```

(If the name `Die()` clashes with an existing symbol, choose another name.) Now,
we have translated the problem of testing when a `MockFoo` object dies to
testing when its `Die()` method is called:

```cpp
  MockFoo* foo = new MockFoo;
  MockBar* bar = new MockBar;
  ...
  {
    InSequence s;

    // Expects *foo to die after bar->A() and before bar->B().
    EXPECT_CALL(*bar, A());
    EXPECT_CALL(*foo, Die());
    EXPECT_CALL(*bar, B());
  }
```

And that's that.

### Using gMock and Threads {#UsingThreads}

In a **unit** test, it's best if you could isolate and test a piece of code in a
single-threaded context. That avoids race conditions and dead locks, and makes
debugging your test much easier.

Yet most programs are multi-threaded, and sometimes to test something we need to
pound on it from more than one thread. gMock works for this purpose too.

Remember the steps for using a mock:

1.  Create a mock object `foo`.
2.  Set its default actions and expectations using `ON_CALL()` and
    `EXPECT_CALL()`.
3.  The code under test calls methods of `foo`.
4.  Optionally, verify and reset the mock.
5.  Destroy the mock yourself, or let the code under test destroy it. The
    destructor will automatically verify it.

If you follow the following simple rules, your mocks and threads can live
happily together:

*   Execute your *test code* (as opposed to the code being tested) in *one*
    thread. This makes your test easy to follow.
*   Obviously, you can do step #1 without locking.
*   When doing step #2 and #5, make sure no other thread is accessing `foo`.
    Obvious too, huh?
*   #3 and #4 can be done either in one thread or in multiple threads - anyway
    you want. gMock takes care of the locking, so you don't have to do any -
    unless required by your test logic.

If you violate the rules (for example, if you set expectations on a mock while
another thread is calling its methods), you get undefined behavior. That's not
fun, so don't do it.

gMock guarantees that the action for a mock function is done in the same thread
that called the mock function. For example, in

```cpp
  EXPECT_CALL(mock, Foo(1))
      .WillOnce(action1);
  EXPECT_CALL(mock, Foo(2))
      .WillOnce(action2);
```

if `Foo(1)` is called in thread 1 and `Foo(2)` is called in thread 2, gMock will
execute `action1` in thread 1 and `action2` in thread 2.

gMock does *not* impose a sequence on actions performed in different threads
(doing so may create deadlocks as the actions may need to cooperate). This means
that the execution of `action1` and `action2` in the above example *may*
interleave. If this is a problem, you should add proper synchronization logic to
`action1` and `action2` to make the test thread-safe.

Also, remember that `DefaultValue<T>` is a global resource that potentially
affects *all* living mock objects in your program. Naturally, you won't want to
mess with it from multiple threads or when there still are mocks in action.

### Controlling How Much Information gMock Prints

When gMock sees something that has the potential of being an error (e.g. a mock
function with no expectation is called, a.k.a. an uninteresting call, which is
allowed but perhaps you forgot to explicitly ban the call), it prints some
warning messages, including the arguments of the function, the return value, and
the stack trace. Hopefully this will remind you to take a look and see if there
is indeed a problem.

Sometimes you are confident that your tests are correct and may not appreciate
such friendly messages. Some other times, you are debugging your tests or
learning about the behavior of the code you are testing, and wish you could
observe every mock call that happens (including argument values, the return
value, and the stack trace). Clearly, one size doesn't fit all.

You can control how much gMock tells you using the `--gmock_verbose=LEVEL`
command-line flag, where `LEVEL` is a string with three possible values:

*   `info`: gMock will print all informational messages, warnings, and errors
    (most verbose). At this setting, gMock will also log any calls to the
    `ON_CALL/EXPECT_CALL` macros. It will include a stack trace in
    "uninteresting call" warnings.
*   `warning`: gMock will print both warnings and errors (less verbose); it will
    omit the stack traces in "uninteresting call" warnings. This is the default.
*   `error`: gMock will print errors only (least verbose).

Alternatively, you can adjust the value of that flag from within your tests like
so:

```cpp
  ::testing::FLAGS_gmock_verbose = "error";
```

If you find gMock printing too many stack frames with its informational or
warning messages, remember that you can control their amount with the
`--gtest_stack_trace_depth=max_depth` flag.

Now, judiciously use the right flag to enable gMock serve you better!

### Gaining Super Vision into Mock Calls

You have a test using gMock. It fails: gMock tells you some expectations aren't
satisfied. However, you aren't sure why: Is there a typo somewhere in the
matchers? Did you mess up the order of the `EXPECT_CALL`s? Or is the code under
test doing something wrong? How can you find out the cause?

Won't it be nice if you have X-ray vision and can actually see the trace of all
`EXPECT_CALL`s and mock method calls as they are made? For each call, would you
like to see its actual argument values and which `EXPECT_CALL` gMock thinks it
matches? If you still need some help to figure out who made these calls, how
about being able to see the complete stack trace at each mock call?

You can unlock this power by running your test with the `--gmock_verbose=info`
flag. For example, given the test program:

```cpp
#include "gmock/gmock.h"

using testing::_;
using testing::HasSubstr;
using testing::Return;

class MockFoo {
 public:
  MOCK_METHOD(void, F, (const string& x, const string& y));
};

TEST(Foo, Bar) {
  MockFoo mock;
  EXPECT_CALL(mock, F(_, _)).WillRepeatedly(Return());
  EXPECT_CALL(mock, F("a", "b"));
  EXPECT_CALL(mock, F("c", HasSubstr("d")));

  mock.F("a", "good");
  mock.F("a", "b");
}
```

if you run it with `--gmock_verbose=info`, you will see this output:

```shell
[ RUN       ] Foo.Bar

foo_test.cc:14: EXPECT_CALL(mock, F(_, _)) invoked
Stack trace: ...

foo_test.cc:15: EXPECT_CALL(mock, F("a", "b")) invoked
Stack trace: ...

foo_test.cc:16: EXPECT_CALL(mock, F("c", HasSubstr("d"))) invoked
Stack trace: ...

foo_test.cc:14: Mock function call matches EXPECT_CALL(mock, F(_, _))...
    Function call: F(@0x7fff7c8dad40"a",@0x7fff7c8dad10"good")
Stack trace: ...

foo_test.cc:15: Mock function call matches EXPECT_CALL(mock, F("a", "b"))...
    Function call: F(@0x7fff7c8dada0"a",@0x7fff7c8dad70"b")
Stack trace: ...

foo_test.cc:16: Failure
Actual function call count doesn't match EXPECT_CALL(mock, F("c", HasSubstr("d")))...
         Expected: to be called once
           Actual: never called - unsatisfied and active
[  FAILED  ] Foo.Bar
```

Suppose the bug is that the `"c"` in the third `EXPECT_CALL` is a typo and
should actually be `"a"`. With the above message, you should see that the actual
`F("a", "good")` call is matched by the first `EXPECT_CALL`, not the third as
you thought. From that it should be obvious that the third `EXPECT_CALL` is
written wrong. Case solved.

If you are interested in the mock call trace but not the stack traces, you can
combine `--gmock_verbose=info` with `--gtest_stack_trace_depth=0` on the test
command line.

### Running Tests in Emacs

If you build and run your tests in Emacs using the `M-x google-compile` command
(as many googletest users do), the source file locations of gMock and googletest
errors will be highlighted. Just press `<Enter>` on one of them and you'll be
taken to the offending line. Or, you can just type `C-x`` to jump to the next
error.

To make it even easier, you can add the following lines to your `~/.emacs` file:

```text
(global-set-key "\M-m"  'google-compile)  ; m is for make
(global-set-key [M-down] 'next-error)
(global-set-key [M-up]  '(lambda () (interactive) (next-error -1)))
```

Then you can type `M-m` to start a build (if you want to run the test as well,
just make sure `foo_test.run` or `runtests` is in the build command you supply
after typing `M-m`), or `M-up`/`M-down` to move back and forth between errors.

## Extending gMock

### Writing New Matchers Quickly {#NewMatchers}

{: .callout .warning}
WARNING: gMock does not guarantee when or how many times a matcher will be
invoked. Therefore, all matchers must be functionally pure. See
[this section](#PureMatchers) for more details.

The `MATCHER*` family of macros can be used to define custom matchers easily.
The syntax:

```cpp
MATCHER(name, description_string_expression) { statements; }
```

will define a matcher with the given name that executes the statements, which
must return a `bool` to indicate if the match succeeds. Inside the statements,
you can refer to the value being matched by `arg`, and refer to its type by
`arg_type`.

The *description string* is a `string`-typed expression that documents what the
matcher does, and is used to generate the failure message when the match fails.
It can (and should) reference the special `bool` variable `negation`, and should
evaluate to the description of the matcher when `negation` is `false`, or that
of the matcher's negation when `negation` is `true`.

For convenience, we allow the description string to be empty (`""`), in which
case gMock will use the sequence of words in the matcher name as the
description.

For example:

```cpp
MATCHER(IsDivisibleBy7, "") { return (arg % 7) == 0; }
```

allows you to write

```cpp
  // Expects mock_foo.Bar(n) to be called where n is divisible by 7.
  EXPECT_CALL(mock_foo, Bar(IsDivisibleBy7()));
```

or,

```cpp
  using ::testing::Not;
  ...
  // Verifies that a value is divisible by 7 and the other is not.
  EXPECT_THAT(some_expression, IsDivisibleBy7());
  EXPECT_THAT(some_other_expression, Not(IsDivisibleBy7()));
```

If the above assertions fail, they will print something like:

```shell
  Value of: some_expression
  Expected: is divisible by 7
    Actual: 27
  ...
  Value of: some_other_expression
  Expected: not (is divisible by 7)
    Actual: 21
```

where the descriptions `"is divisible by 7"` and `"not (is divisible by 7)"` are
automatically calculated from the matcher name `IsDivisibleBy7`.

As you may have noticed, the auto-generated descriptions (especially those for
the negation) may not be so great. You can always override them with a `string`
expression of your own:

```cpp
MATCHER(IsDivisibleBy7,
        absl::StrCat(negation ? "isn't" : "is", " divisible by 7")) {
  return (arg % 7) == 0;
}
```

Optionally, you can stream additional information to a hidden argument named
`result_listener` to explain the match result. For example, a better definition
of `IsDivisibleBy7` is:

```cpp
MATCHER(IsDivisibleBy7, "") {
  if ((arg % 7) == 0)
    return true;

  *result_listener << "the remainder is " << (arg % 7);
  return false;
}
```

With this definition, the above assertion will give a better message:

```shell
  Value of: some_expression
  Expected: is divisible by 7
    Actual: 27 (the remainder is 6)
```

You should let `MatchAndExplain()` print *any additional information* that can
help a user understand the match result. Note that it should explain why the
match succeeds in case of a success (unless it's obvious) - this is useful when
the matcher is used inside `Not()`. There is no need to print the argument value
itself, as gMock already prints it for you.

{: .callout .note}
NOTE: The type of the value being matched (`arg_type`) is determined by the
context in which you use the matcher and is supplied to you by the compiler, so
you don't need to worry about declaring it (nor can you). This allows the
matcher to be polymorphic. For example, `IsDivisibleBy7()` can be used to match
any type where the value of `(arg % 7) == 0` can be implicitly converted to a
`bool`. In the `Bar(IsDivisibleBy7())` example above, if method `Bar()` takes an
`int`, `arg_type` will be `int`; if it takes an `unsigned long`, `arg_type` will
be `unsigned long`; and so on.

### Writing New Parameterized Matchers Quickly

Sometimes you'll want to define a matcher that has parameters. For that you can
use the macro:

```cpp
MATCHER_P(name, param_name, description_string) { statements; }
```

where the description string can be either `""` or a `string` expression that
references `negation` and `param_name`.

For example:

```cpp
MATCHER_P(HasAbsoluteValue, value, "") { return abs(arg) == value; }
```

will allow you to write:

```cpp
  EXPECT_THAT(Blah("a"), HasAbsoluteValue(n));
```

which may lead to this message (assuming `n` is 10):

```shell
  Value of: Blah("a")
  Expected: has absolute value 10
    Actual: -9
```

Note that both the matcher description and its parameter are printed, making the
message human-friendly.

In the matcher definition body, you can write `foo_type` to reference the type
of a parameter named `foo`. For example, in the body of
`MATCHER_P(HasAbsoluteValue, value)` above, you can write `value_type` to refer
to the type of `value`.

gMock also provides `MATCHER_P2`, `MATCHER_P3`, ..., up to `MATCHER_P10` to
support multi-parameter matchers:

```cpp
MATCHER_Pk(name, param_1, ..., param_k, description_string) { statements; }
```

Please note that the custom description string is for a particular *instance* of
the matcher, where the parameters have been bound to actual values. Therefore
usually you'll want the parameter values to be part of the description. gMock
lets you do that by referencing the matcher parameters in the description string
expression.

For example,

```cpp
using ::testing::PrintToString;
MATCHER_P2(InClosedRange, low, hi,
           absl::StrFormat("%s in range [%s, %s]", negation ? "isn't" : "is",
                           PrintToString(low), PrintToString(hi))) {
  return low <= arg && arg <= hi;
}
...
EXPECT_THAT(3, InClosedRange(4, 6));
```

would generate a failure that contains the message:

```shell
  Expected: is in range [4, 6]
```

If you specify `""` as the description, the failure message will contain the
sequence of words in the matcher name followed by the parameter values printed
as a tuple. For example,

```cpp
  MATCHER_P2(InClosedRange, low, hi, "") { ... }
  ...
  EXPECT_THAT(3, InClosedRange(4, 6));
```

would generate a failure that contains the text:

```shell
  Expected: in closed range (4, 6)
```

For the purpose of typing, you can view

```cpp
MATCHER_Pk(Foo, p1, ..., pk, description_string) { ... }
```

as shorthand for

```cpp
template <typename p1_type, ..., typename pk_type>
FooMatcherPk<p1_type, ..., pk_type>
Foo(p1_type p1, ..., pk_type pk) { ... }
```

When you write `Foo(v1, ..., vk)`, the compiler infers the types of the
parameters `v1`, ..., and `vk` for you. If you are not happy with the result of
the type inference, you can specify the types by explicitly instantiating the
template, as in `Foo<long, bool>(5, false)`. As said earlier, you don't get to
(or need to) specify `arg_type` as that's determined by the context in which the
matcher is used.

You can assign the result of expression `Foo(p1, ..., pk)` to a variable of type
`FooMatcherPk<p1_type, ..., pk_type>`. This can be useful when composing
matchers. Matchers that don't have a parameter or have only one parameter have
special types: you can assign `Foo()` to a `FooMatcher`-typed variable, and
assign `Foo(p)` to a `FooMatcherP<p_type>`-typed variable.

While you can instantiate a matcher template with reference types, passing the
parameters by pointer usually makes your code more readable. If, however, you
still want to pass a parameter by reference, be aware that in the failure
message generated by the matcher you will see the value of the referenced object
but not its address.

You can overload matchers with different numbers of parameters:

```cpp
MATCHER_P(Blah, a, description_string_1) { ... }
MATCHER_P2(Blah, a, b, description_string_2) { ... }
```

While it's tempting to always use the `MATCHER*` macros when defining a new
matcher, you should also consider implementing the matcher interface directly
instead (see the recipes that follow), especially if you need to use the matcher
a lot. While these approaches require more work, they give you more control on
the types of the value being matched and the matcher parameters, which in
general leads to better compiler error messages that pay off in the long run.
They also allow overloading matchers based on parameter types (as opposed to
just based on the number of parameters).

### Writing New Monomorphic Matchers

A matcher of argument type `T` implements the matcher interface for `T` and does
two things: it tests whether a value of type `T` matches the matcher, and can
describe what kind of values it matches. The latter ability is used for
generating readable error messages when expectations are violated.

A matcher of `T` must declare a typedef like:

```cpp
using is_gtest_matcher = void;
```

and supports the following operations:

```cpp
// Match a value and optionally explain into an ostream.
bool matched = matcher.MatchAndExplain(value, maybe_os);
// where `value` is of type `T` and
// `maybe_os` is of type `std::ostream*`, where it can be null if the caller
// is not interested in there textual explanation.

matcher.DescribeTo(os);
matcher.DescribeNegationTo(os);
// where `os` is of type `std::ostream*`.
```

If you need a custom matcher but `Truly()` is not a good option (for example,
you may not be happy with the way `Truly(predicate)` describes itself, or you
may want your matcher to be polymorphic as `Eq(value)` is), you can define a
matcher to do whatever you want in two steps: first implement the matcher
interface, and then define a factory function to create a matcher instance. The
second step is not strictly needed but it makes the syntax of using the matcher
nicer.

For example, you can define a matcher to test whether an `int` is divisible by 7
and then use it like this:

```cpp
using ::testing::Matcher;

class DivisibleBy7Matcher {
 public:
  using is_gtest_matcher = void;

  bool MatchAndExplain(int n, std::ostream*) const {
    return (n % 7) == 0;
  }

  void DescribeTo(std::ostream* os) const {
    *os << "is divisible by 7";
  }

  void DescribeNegationTo(std::ostream* os) const {
    *os << "is not divisible by 7";
  }
};

Matcher<int> DivisibleBy7() {
  return DivisibleBy7Matcher();
}

...
  EXPECT_CALL(foo, Bar(DivisibleBy7()));
```

You may improve the matcher message by streaming additional information to the
`os` argument in `MatchAndExplain()`:

```cpp
class DivisibleBy7Matcher {
 public:
  bool MatchAndExplain(int n, std::ostream* os) const {
    const int remainder = n % 7;
    if (remainder != 0 && os != nullptr) {
      *os << "the remainder is " << remainder;
    }
    return remainder == 0;
  }
  ...
};
```

Then, `EXPECT_THAT(x, DivisibleBy7());` may generate a message like this:

```shell
Value of: x
Expected: is divisible by 7
  Actual: 23 (the remainder is 2)
```

{: .callout .tip}
Tip: for convenience, `MatchAndExplain()` can take a `MatchResultListener*`
instead of `std::ostream*`.

### Writing New Polymorphic Matchers

Expanding what we learned above to *polymorphic* matchers is now just as simple
as adding templates in the right place.

```cpp

class NotNullMatcher {
 public:
  using is_gtest_matcher = void;

  // To implement a polymorphic matcher, we just need to make MatchAndExplain a
  // template on its first argument.

  // In this example, we want to use NotNull() with any pointer, so
  // MatchAndExplain() accepts a pointer of any type as its first argument.
  // In general, you can define MatchAndExplain() as an ordinary method or
  // a method template, or even overload it.
  template <typename T>
  bool MatchAndExplain(T* p, std::ostream*) const {
    return p != nullptr;
  }

  // Describes the property of a value matching this matcher.
  void DescribeTo(std::ostream* os) const { *os << "is not NULL"; }

  // Describes the property of a value NOT matching this matcher.
  void DescribeNegationTo(std::ostream* os) const { *os << "is NULL"; }
};

NotNullMatcher NotNull() {
  return NotNullMatcher();
}

...

  EXPECT_CALL(foo, Bar(NotNull()));  // The argument must be a non-NULL pointer.
```

### Legacy Matcher Implementation

Defining matchers used to be somewhat more complicated, in which it required
several supporting classes and virtual functions. To implement a matcher for
type `T` using the legacy API you have to derive from `MatcherInterface<T>` and
call `MakeMatcher` to construct the object.

The interface looks like this:

```cpp
class MatchResultListener {
 public:
  ...
  // Streams x to the underlying ostream; does nothing if the ostream
  // is NULL.
  template <typename T>
  MatchResultListener& operator<<(const T& x);

  // Returns the underlying ostream.
  std::ostream* stream();
};

template <typename T>
class MatcherInterface {
 public:
  virtual ~MatcherInterface();

  // Returns true if and only if the matcher matches x; also explains the match
  // result to 'listener'.
  virtual bool MatchAndExplain(T x, MatchResultListener* listener) const = 0;

  // Describes this matcher to an ostream.
  virtual void DescribeTo(std::ostream* os) const = 0;

  // Describes the negation of this matcher to an ostream.
  virtual void DescribeNegationTo(std::ostream* os) const;
};
```

Fortunately, most of the time you can define a polymorphic matcher easily with
the help of `MakePolymorphicMatcher()`. Here's how you can define `NotNull()` as
an example:

```cpp
using ::testing::MakePolymorphicMatcher;
using ::testing::MatchResultListener;
using ::testing::PolymorphicMatcher;

class NotNullMatcher {
 public:
  // To implement a polymorphic matcher, first define a COPYABLE class
  // that has three members MatchAndExplain(), DescribeTo(), and
  // DescribeNegationTo(), like the following.

  // In this example, we want to use NotNull() with any pointer, so
  // MatchAndExplain() accepts a pointer of any type as its first argument.
  // In general, you can define MatchAndExplain() as an ordinary method or
  // a method template, or even overload it.
  template <typename T>
  bool MatchAndExplain(T* p,
                       MatchResultListener* /* listener */) const {
    return p != NULL;
  }

  // Describes the property of a value matching this matcher.
  void DescribeTo(std::ostream* os) const { *os << "is not NULL"; }

  // Describes the property of a value NOT matching this matcher.
  void DescribeNegationTo(std::ostream* os) const { *os << "is NULL"; }
};

// To construct a polymorphic matcher, pass an instance of the class
// to MakePolymorphicMatcher().  Note the return type.
PolymorphicMatcher<NotNullMatcher> NotNull() {
  return MakePolymorphicMatcher(NotNullMatcher());
}

...

  EXPECT_CALL(foo, Bar(NotNull()));  // The argument must be a non-NULL pointer.
```

{: .callout .note}
**Note:** Your polymorphic matcher class does **not** need to inherit from
`MatcherInterface` or any other class, and its methods do **not** need to be
virtual.

Like in a monomorphic matcher, you may explain the match result by streaming
additional information to the `listener` argument in `MatchAndExplain()`.

### Writing New Cardinalities

A cardinality is used in `Times()` to tell gMock how many times you expect a
call to occur. It doesn't have to be exact. For example, you can say
`AtLeast(5)` or `Between(2, 4)`.

If the [built-in set](gmock_cheat_sheet.md#CardinalityList) of cardinalities
doesn't suit you, you are free to define your own by implementing the following
interface (in namespace `testing`):

```cpp
class CardinalityInterface {
 public:
  virtual ~CardinalityInterface();

  // Returns true if and only if call_count calls will satisfy this cardinality.
  virtual bool IsSatisfiedByCallCount(int call_count) const = 0;

  // Returns true if and only if call_count calls will saturate this
  // cardinality.
  virtual bool IsSaturatedByCallCount(int call_count) const = 0;

  // Describes self to an ostream.
  virtual void DescribeTo(std::ostream* os) const = 0;
};
```

For example, to specify that a call must occur even number of times, you can
write

```cpp
using ::testing::Cardinality;
using ::testing::CardinalityInterface;
using ::testing::MakeCardinality;

class EvenNumberCardinality : public CardinalityInterface {
 public:
  bool IsSatisfiedByCallCount(int call_count) const override {
    return (call_count % 2) == 0;
  }

  bool IsSaturatedByCallCount(int call_count) const override {
    return false;
  }

  void DescribeTo(std::ostream* os) const {
    *os << "called even number of times";
  }
};

Cardinality EvenNumber() {
  return MakeCardinality(new EvenNumberCardinality);
}

...
  EXPECT_CALL(foo, Bar(3))
      .Times(EvenNumber());
```

### Writing New Actions Quickly {#QuickNewActions}

If the built-in actions don't work for you, you can easily define your own one.
Just define a functor class with a (possibly templated) call operator, matching
the signature of your action.

```cpp
struct Increment {
  template <typename T>
  T operator()(T* arg) {
    return ++(*arg);
  }
}
```

The same approach works with stateful functors (or any callable, really):

```
struct MultiplyBy {
  template <typename T>
  T operator()(T arg) { return arg * multiplier; }

  int multiplier;
}

// Then use:
// EXPECT_CALL(...).WillOnce(MultiplyBy{7});
```

#### Legacy macro-based Actions

Before C++11, the functor-based actions were not supported; the old way of
writing actions was through a set of `ACTION*` macros. We suggest to avoid them
in new code; they hide a lot of logic behind the macro, potentially leading to
harder-to-understand compiler errors. Nevertheless, we cover them here for
completeness.

By writing

```cpp
ACTION(name) { statements; }
```

in a namespace scope (i.e. not inside a class or function), you will define an
action with the given name that executes the statements. The value returned by
`statements` will be used as the return value of the action. Inside the
statements, you can refer to the K-th (0-based) argument of the mock function as
`argK`. For example:

```cpp
ACTION(IncrementArg1) { return ++(*arg1); }
```

allows you to write

```cpp
... WillOnce(IncrementArg1());
```

Note that you don't need to specify the types of the mock function arguments.
Rest assured that your code is type-safe though: you'll get a compiler error if
`*arg1` doesn't support the `++` operator, or if the type of `++(*arg1)` isn't
compatible with the mock function's return type.

Another example:

```cpp
ACTION(Foo) {
  (*arg2)(5);
  Blah();
  *arg1 = 0;
  return arg0;
}
```

defines an action `Foo()` that invokes argument #2 (a function pointer) with 5,
calls function `Blah()`, sets the value pointed to by argument #1 to 0, and
returns argument #0.

For more convenience and flexibility, you can also use the following pre-defined
symbols in the body of `ACTION`:

`argK_type`     | The type of the K-th (0-based) argument of the mock function
:-------------- | :-----------------------------------------------------------
`args`          | All arguments of the mock function as a tuple
`args_type`     | The type of all arguments of the mock function as a tuple
`return_type`   | The return type of the mock function
`function_type` | The type of the mock function

For example, when using an `ACTION` as a stub action for mock function:

```cpp
int DoSomething(bool flag, int* ptr);
```

we have:

Pre-defined Symbol | Is Bound To
------------------ | ---------------------------------
`arg0`             | the value of `flag`
`arg0_type`        | the type `bool`
`arg1`             | the value of `ptr`
`arg1_type`        | the type `int*`
`args`             | the tuple `(flag, ptr)`
`args_type`        | the type `std::tuple<bool, int*>`
`return_type`      | the type `int`
`function_type`    | the type `int(bool, int*)`

#### Legacy macro-based parameterized Actions

Sometimes you'll want to parameterize an action you define. For that we have
another macro

```cpp
ACTION_P(name, param) { statements; }
```

For example,

```cpp
ACTION_P(Add, n) { return arg0 + n; }
```

will allow you to write

```cpp
// Returns argument #0 + 5.
... WillOnce(Add(5));
```

For convenience, we use the term *arguments* for the values used to invoke the
mock function, and the term *parameters* for the values used to instantiate an
action.

Note that you don't need to provide the type of the parameter either. Suppose
the parameter is named `param`, you can also use the gMock-defined symbol
`param_type` to refer to the type of the parameter as inferred by the compiler.
For example, in the body of `ACTION_P(Add, n)` above, you can write `n_type` for
the type of `n`.

gMock also provides `ACTION_P2`, `ACTION_P3`, and etc to support multi-parameter
actions. For example,

```cpp
ACTION_P2(ReturnDistanceTo, x, y) {
  double dx = arg0 - x;
  double dy = arg1 - y;
  return sqrt(dx*dx + dy*dy);
}
```

lets you write

```cpp
... WillOnce(ReturnDistanceTo(5.0, 26.5));
```

You can view `ACTION` as a degenerated parameterized action where the number of
parameters is 0.

You can also easily define actions overloaded on the number of parameters:

```cpp
ACTION_P(Plus, a) { ... }
ACTION_P2(Plus, a, b) { ... }
```

### Restricting the Type of an Argument or Parameter in an ACTION

For maximum brevity and reusability, the `ACTION*` macros don't ask you to
provide the types of the mock function arguments and the action parameters.
Instead, we let the compiler infer the types for us.

Sometimes, however, we may want to be more explicit about the types. There are
several tricks to do that. For example:

```cpp
ACTION(Foo) {
  // Makes sure arg0 can be converted to int.
  int n = arg0;
  ... use n instead of arg0 here ...
}

ACTION_P(Bar, param) {
  // Makes sure the type of arg1 is const char*.
  ::testing::StaticAssertTypeEq<const char*, arg1_type>();

  // Makes sure param can be converted to bool.
  bool flag = param;
}
```

where `StaticAssertTypeEq` is a compile-time assertion in googletest that
verifies two types are the same.

### Writing New Action Templates Quickly

Sometimes you want to give an action explicit template parameters that cannot be
inferred from its value parameters. `ACTION_TEMPLATE()` supports that and can be
viewed as an extension to `ACTION()` and `ACTION_P*()`.

The syntax:

```cpp
ACTION_TEMPLATE(ActionName,
                HAS_m_TEMPLATE_PARAMS(kind1, name1, ..., kind_m, name_m),
                AND_n_VALUE_PARAMS(p1, ..., p_n)) { statements; }
```

defines an action template that takes *m* explicit template parameters and *n*
value parameters, where *m* is in [1, 10] and *n* is in [0, 10]. `name_i` is the
name of the *i*-th template parameter, and `kind_i` specifies whether it's a
`typename`, an integral constant, or a template. `p_i` is the name of the *i*-th
value parameter.

Example:

```cpp
// DuplicateArg<k, T>(output) converts the k-th argument of the mock
// function to type T and copies it to *output.
ACTION_TEMPLATE(DuplicateArg,
                // Note the comma between int and k:
                HAS_2_TEMPLATE_PARAMS(int, k, typename, T),
                AND_1_VALUE_PARAMS(output)) {
  *output = T(std::get<k>(args));
}
```

To create an instance of an action template, write:

```cpp
ActionName<t1, ..., t_m>(v1, ..., v_n)
```

where the `t`s are the template arguments and the `v`s are the value arguments.
The value argument types are inferred by the compiler. For example:

```cpp
using ::testing::_;
...
  int n;
  EXPECT_CALL(mock, Foo).WillOnce(DuplicateArg<1, unsigned char>(&n));
```

If you want to explicitly specify the value argument types, you can provide
additional template arguments:

```cpp
ActionName<t1, ..., t_m, u1, ..., u_k>(v1, ..., v_n)
```

where `u_i` is the desired type of `v_i`.

`ACTION_TEMPLATE` and `ACTION`/`ACTION_P*` can be overloaded on the number of
value parameters, but not on the number of template parameters. Without the
restriction, the meaning of the following is unclear:

```cpp
  OverloadedAction<int, bool>(x);
```

Are we using a single-template-parameter action where `bool` refers to the type
of `x`, or a two-template-parameter action where the compiler is asked to infer
the type of `x`?

### Using the ACTION Object's Type

If you are writing a function that returns an `ACTION` object, you'll need to
know its type. The type depends on the macro used to define the action and the
parameter types. The rule is relatively simple:


| Given Definition              | Expression          | Has Type              |
| ----------------------------- | ------------------- | --------------------- |
| `ACTION(Foo)`                 | `Foo()`             | `FooAction`           |
| `ACTION_TEMPLATE(Foo, HAS_m_TEMPLATE_PARAMS(...), AND_0_VALUE_PARAMS())` | `Foo<t1, ..., t_m>()` | `FooAction<t1, ..., t_m>` |
| `ACTION_P(Bar, param)`        | `Bar(int_value)`    | `BarActionP<int>`     |
| `ACTION_TEMPLATE(Bar, HAS_m_TEMPLATE_PARAMS(...), AND_1_VALUE_PARAMS(p1))` | `Bar<t1, ..., t_m>(int_value)` | `BarActionP<t1, ..., t_m, int>` |
| `ACTION_P2(Baz, p1, p2)`      | `Baz(bool_value, int_value)` | `BazActionP2<bool, int>` |
| `ACTION_TEMPLATE(Baz, HAS_m_TEMPLATE_PARAMS(...), AND_2_VALUE_PARAMS(p1, p2))` | `Baz<t1, ..., t_m>(bool_value, int_value)` | `BazActionP2<t1, ..., t_m, bool, int>` |
| ...                           | ...                 | ...                   |


Note that we have to pick different suffixes (`Action`, `ActionP`, `ActionP2`,
and etc) for actions with different numbers of value parameters, or the action
definitions cannot be overloaded on the number of them.

### Writing New Monomorphic Actions {#NewMonoActions}

While the `ACTION*` macros are very convenient, sometimes they are
inappropriate. For example, despite the tricks shown in the previous recipes,
they don't let you directly specify the types of the mock function arguments and
the action parameters, which in general leads to unoptimized compiler error
messages that can baffle unfamiliar users. They also don't allow overloading
actions based on parameter types without jumping through some hoops.

An alternative to the `ACTION*` macros is to implement
`::testing::ActionInterface<F>`, where `F` is the type of the mock function in
which the action will be used. For example:

```cpp
template <typename F>
class ActionInterface {
 public:
  virtual ~ActionInterface();

  // Performs the action.  Result is the return type of function type
  // F, and ArgumentTuple is the tuple of arguments of F.
  //

  // For example, if F is int(bool, const string&), then Result would
  // be int, and ArgumentTuple would be std::tuple<bool, const string&>.
  virtual Result Perform(const ArgumentTuple& args) = 0;
};
```

```cpp
using ::testing::_;
using ::testing::Action;
using ::testing::ActionInterface;
using ::testing::MakeAction;

typedef int IncrementMethod(int*);

class IncrementArgumentAction : public ActionInterface<IncrementMethod> {
 public:
  int Perform(const std::tuple<int*>& args) override {
    int* p = std::get<0>(args);  // Grabs the first argument.
    return *p++;
  }
};

Action<IncrementMethod> IncrementArgument() {
  return MakeAction(new IncrementArgumentAction);
}

...
  EXPECT_CALL(foo, Baz(_))
      .WillOnce(IncrementArgument());

  int n = 5;
  foo.Baz(&n);  // Should return 5 and change n to 6.
```

### Writing New Polymorphic Actions {#NewPolyActions}

The previous recipe showed you how to define your own action. This is all good,
except that you need to know the type of the function in which the action will
be used. Sometimes that can be a problem. For example, if you want to use the
action in functions with *different* types (e.g. like `Return()` and
`SetArgPointee()`).

If an action can be used in several types of mock functions, we say it's
*polymorphic*. The `MakePolymorphicAction()` function template makes it easy to
define such an action:

```cpp
namespace testing {
template <typename Impl>
PolymorphicAction<Impl> MakePolymorphicAction(const Impl& impl);
}  // namespace testing
```

As an example, let's define an action that returns the second argument in the
mock function's argument list. The first step is to define an implementation
class:

```cpp
class ReturnSecondArgumentAction {
 public:
  template <typename Result, typename ArgumentTuple>
  Result Perform(const ArgumentTuple& args) const {
    // To get the i-th (0-based) argument, use std::get(args).
    return std::get<1>(args);
  }
};
```

This implementation class does *not* need to inherit from any particular class.
What matters is that it must have a `Perform()` method template. This method
template takes the mock function's arguments as a tuple in a **single**
argument, and returns the result of the action. It can be either `const` or not,
but must be invokable with exactly one template argument, which is the result
type. In other words, you must be able to call `Perform<R>(args)` where `R` is
the mock function's return type and `args` is its arguments in a tuple.

Next, we use `MakePolymorphicAction()` to turn an instance of the implementation
class into the polymorphic action we need. It will be convenient to have a
wrapper for this:

```cpp
using ::testing::MakePolymorphicAction;
using ::testing::PolymorphicAction;

PolymorphicAction<ReturnSecondArgumentAction> ReturnSecondArgument() {
  return MakePolymorphicAction(ReturnSecondArgumentAction());
}
```

Now, you can use this polymorphic action the same way you use the built-in ones:

```cpp
using ::testing::_;

class MockFoo : public Foo {
 public:
  MOCK_METHOD(int, DoThis, (bool flag, int n), (override));
  MOCK_METHOD(string, DoThat, (int x, const char* str1, const char* str2),
              (override));
};

  ...
  MockFoo foo;
  EXPECT_CALL(foo, DoThis).WillOnce(ReturnSecondArgument());
  EXPECT_CALL(foo, DoThat).WillOnce(ReturnSecondArgument());
  ...
  foo.DoThis(true, 5);  // Will return 5.
  foo.DoThat(1, "Hi", "Bye");  // Will return "Hi".
```

### Teaching gMock How to Print Your Values

When an uninteresting or unexpected call occurs, gMock prints the argument
values and the stack trace to help you debug. Assertion macros like
`EXPECT_THAT` and `EXPECT_EQ` also print the values in question when the
assertion fails. gMock and googletest do this using googletest's user-extensible
value printer.

This printer knows how to print built-in C++ types, native arrays, STL
containers, and any type that supports the `<<` operator. For other types, it
prints the raw bytes in the value and hopes that you the user can figure it out.
[The GoogleTest advanced guide](advanced.md#teaching-googletest-how-to-print-your-values)
explains how to extend the printer to do a better job at printing your
particular type than to dump the bytes.

## Useful Mocks Created Using gMock

<!--#include file="includes/g3_testing_LOGs.md"-->
<!--#include file="includes/g3_mock_callbacks.md"-->

### Mock std::function {#MockFunction}

`std::function` is a general function type introduced in C++11. It is a
preferred way of passing callbacks to new interfaces. Functions are copiable,
and are not usually passed around by pointer, which makes them tricky to mock.
But fear not - `MockFunction` can help you with that.

`MockFunction<R(T1, ..., Tn)>` has a mock method `Call()` with the signature:

```cpp
  R Call(T1, ..., Tn);
```

It also has a `AsStdFunction()` method, which creates a `std::function` proxy
forwarding to Call:

```cpp
  std::function<R(T1, ..., Tn)> AsStdFunction();
```

To use `MockFunction`, first create `MockFunction` object and set up
expectations on its `Call` method. Then pass proxy obtained from
`AsStdFunction()` to the code you are testing. For example:

```cpp
TEST(FooTest, RunsCallbackWithBarArgument) {
  // 1. Create a mock object.
  MockFunction<int(string)> mock_function;

  // 2. Set expectations on Call() method.
  EXPECT_CALL(mock_function, Call("bar")).WillOnce(Return(1));

  // 3. Exercise code that uses std::function.
  Foo(mock_function.AsStdFunction());
  // Foo's signature can be either of:
  // void Foo(const std::function<int(string)>& fun);
  // void Foo(std::function<int(string)> fun);

  // 4. All expectations will be verified when mock_function
  //     goes out of scope and is destroyed.
}
```

Remember that function objects created with `AsStdFunction()` are just
forwarders. If you create multiple of them, they will share the same set of
expectations.

Although `std::function` supports unlimited number of arguments, `MockFunction`
implementation is limited to ten. If you ever hit that limit... well, your
callback has bigger problems than being mockable. :-)
## Using GoogleTest from various build systems

GoogleTest comes with pkg-config files that can be used to determine all
necessary flags for compiling and linking to GoogleTest (and GoogleMock).
Pkg-config is a standardised plain-text format containing

*   the includedir (-I) path
*   necessary macro (-D) definitions
*   further required flags (-pthread)
*   the library (-L) path
*   the library (-l) to link to

All current build systems support pkg-config in one way or another. For all
examples here we assume you want to compile the sample
`samples/sample3_unittest.cc`.

### CMake

Using `pkg-config` in CMake is fairly easy:

```cmake
cmake_minimum_required(VERSION 3.0)

cmake_policy(SET CMP0048 NEW)
project(my_gtest_pkgconfig VERSION 0.0.1 LANGUAGES CXX)

find_package(PkgConfig)
pkg_search_module(GTEST REQUIRED gtest_main)

add_executable(testapp samples/sample3_unittest.cc)
target_link_libraries(testapp ${GTEST_LDFLAGS})
target_compile_options(testapp PUBLIC ${GTEST_CFLAGS})

include(CTest)
add_test(first_and_only_test testapp)
```

It is generally recommended that you use `target_compile_options` + `_CFLAGS`
over `target_include_directories` + `_INCLUDE_DIRS` as the former includes not
just -I flags (GoogleTest might require a macro indicating to internal headers
that all libraries have been compiled with threading enabled. In addition,
GoogleTest might also require `-pthread` in the compiling step, and as such
splitting the pkg-config `Cflags` variable into include dirs and macros for
`target_compile_definitions()` might still miss this). The same recommendation
goes for using `_LDFLAGS` over the more commonplace `_LIBRARIES`, which happens
to discard `-L` flags and `-pthread`.

### Help! pkg-config can't find GoogleTest!

Let's say you have a `CMakeLists.txt` along the lines of the one in this
tutorial and you try to run `cmake`. It is very possible that you get a failure
along the lines of:

```
-- Checking for one of the modules 'gtest_main'
CMake Error at /usr/share/cmake/Modules/FindPkgConfig.cmake:640 (message):
  None of the required 'gtest_main' found
```

These failures are common if you installed GoogleTest yourself and have not
sourced it from a distro or other package manager. If so, you need to tell
pkg-config where it can find the `.pc` files containing the information. Say you
installed GoogleTest to `/usr/local`, then it might be that the `.pc` files are
installed under `/usr/local/lib64/pkgconfig`. If you set

```
export PKG_CONFIG_PATH=/usr/local/lib64/pkgconfig
```

pkg-config will also try to look in `PKG_CONFIG_PATH` to find `gtest_main.pc`.

### Using pkg-config in a cross-compilation setting

Pkg-config can be used in a cross-compilation setting too. To do this, let's
assume the final prefix of the cross-compiled installation will be `/usr`, and
your sysroot is `/home/MYUSER/sysroot`. Configure and install GTest using

```
mkdir build && cmake -DCMAKE_INSTALL_PREFIX=/usr ..
```

Install into the sysroot using `DESTDIR`:

```
make -j install DESTDIR=/home/MYUSER/sysroot
```

Before we continue, it is recommended to **always** define the following two
variables for pkg-config in a cross-compilation setting:

```
export PKG_CONFIG_ALLOW_SYSTEM_CFLAGS=yes
export PKG_CONFIG_ALLOW_SYSTEM_LIBS=yes
```

otherwise `pkg-config` will filter `-I` and `-L` flags against standard prefixes
such as `/usr` (see https://bugs.freedesktop.org/show_bug.cgi?id=28264#c3 for
reasons why this stripping needs to occur usually).

If you look at the generated pkg-config file, it will look something like

```
libdir=/usr/lib64
includedir=/usr/include

Name: gtest
Description: GoogleTest (without main() function)
Version: 1.11.0
URL: https://github.com/google/googletest
Libs: -L${libdir} -lgtest -lpthread
Cflags: -I${includedir} -DGTEST_HAS_PTHREAD=1 -lpthread
```

Notice that the sysroot is not included in `libdir` and `includedir`! If you try
to run `pkg-config` with the correct
`PKG_CONFIG_LIBDIR=/home/MYUSER/sysroot/usr/lib64/pkgconfig` against this `.pc`
file, you will get

```
$ pkg-config --cflags gtest
-DGTEST_HAS_PTHREAD=1 -lpthread -I/usr/include
$ pkg-config --libs gtest
-L/usr/lib64 -lgtest -lpthread
```

which is obviously wrong and points to the `CBUILD` and not `CHOST` root. In
order to use this in a cross-compilation setting, we need to tell pkg-config to
inject the actual sysroot into `-I` and `-L` variables. Let us now tell
pkg-config about the actual sysroot

```
export PKG_CONFIG_DIR=
export PKG_CONFIG_SYSROOT_DIR=/home/MYUSER/sysroot
export PKG_CONFIG_LIBDIR=${PKG_CONFIG_SYSROOT_DIR}/usr/lib64/pkgconfig
```

and running `pkg-config` again we get

```
$ pkg-config --cflags gtest
-DGTEST_HAS_PTHREAD=1 -lpthread -I/home/MYUSER/sysroot/usr/include
$ pkg-config --libs gtest
-L/home/MYUSER/sysroot/usr/lib64 -lgtest -lpthread
```

which contains the correct sysroot now. For a more comprehensive guide to also
including `${CHOST}` in build system calls, see the excellent tutorial by Diego
Elio Pettenò: <https://autotools.io/pkgconfig/cross-compiling.html>
# Googletest Samples

If you're like us, you'd like to look at
[googletest samples.](https://github.com/google/googletest/tree/master/googletest/samples)
The sample directory has a number of well-commented samples showing how to use a
variety of googletest features.

*   Sample #1 shows the basic steps of using googletest to test C++ functions.
*   Sample #2 shows a more complex unit test for a class with multiple member
    functions.
*   Sample #3 uses a test fixture.
*   Sample #4 teaches you how to use googletest and `googletest.h` together to
    get the best of both libraries.
*   Sample #5 puts shared testing logic in a base test fixture, and reuses it in
    derived fixtures.
*   Sample #6 demonstrates type-parameterized tests.
*   Sample #7 teaches the basics of value-parameterized tests.
*   Sample #8 shows using `Combine()` in value-parameterized tests.
*   Sample #9 shows use of the listener API to modify Google Test's console
    output and the use of its reflection API to inspect test results.
*   Sample #10 shows use of the listener API to implement a primitive memory
    leak checker.
# Advanced googletest Topics

## Introduction

Now that you have read the [googletest Primer](primer.md) and learned how to
write tests using googletest, it's time to learn some new tricks. This document
will show you more assertions as well as how to construct complex failure
messages, propagate fatal failures, reuse and speed up your test fixtures, and
use various flags with your tests.

## More Assertions

This section covers some less frequently used, but still significant,
assertions.

### Explicit Success and Failure

See [Explicit Success and Failure](reference/assertions.md#success-failure) in
the Assertions Reference.

### Exception Assertions

See [Exception Assertions](reference/assertions.md#exceptions) in the Assertions
Reference.

### Predicate Assertions for Better Error Messages

Even though googletest has a rich set of assertions, they can never be complete,
as it's impossible (nor a good idea) to anticipate all scenarios a user might
run into. Therefore, sometimes a user has to use `EXPECT_TRUE()` to check a
complex expression, for lack of a better macro. This has the problem of not
showing you the values of the parts of the expression, making it hard to
understand what went wrong. As a workaround, some users choose to construct the
failure message by themselves, streaming it into `EXPECT_TRUE()`. However, this
is awkward especially when the expression has side-effects or is expensive to
evaluate.

googletest gives you three different options to solve this problem:

#### Using an Existing Boolean Function

If you already have a function or functor that returns `bool` (or a type that
can be implicitly converted to `bool`), you can use it in a *predicate
assertion* to get the function arguments printed for free. See
[`EXPECT_PRED*`](reference/assertions.md#EXPECT_PRED) in the Assertions
Reference for details.

#### Using a Function That Returns an AssertionResult

While `EXPECT_PRED*()` and friends are handy for a quick job, the syntax is not
satisfactory: you have to use different macros for different arities, and it
feels more like Lisp than C++. The `::testing::AssertionResult` class solves
this problem.

An `AssertionResult` object represents the result of an assertion (whether it's
a success or a failure, and an associated message). You can create an
`AssertionResult` using one of these factory functions:

```c++
namespace testing {

// Returns an AssertionResult object to indicate that an assertion has
// succeeded.
AssertionResult AssertionSuccess();

// Returns an AssertionResult object to indicate that an assertion has
// failed.
AssertionResult AssertionFailure();

}
```

You can then use the `<<` operator to stream messages to the `AssertionResult`
object.

To provide more readable messages in Boolean assertions (e.g. `EXPECT_TRUE()`),
write a predicate function that returns `AssertionResult` instead of `bool`. For
example, if you define `IsEven()` as:

```c++
testing::AssertionResult IsEven(int n) {
  if ((n % 2) == 0)
    return testing::AssertionSuccess();
  else
    return testing::AssertionFailure() << n << " is odd";
}
```

instead of:

```c++
bool IsEven(int n) {
  return (n % 2) == 0;
}
```

the failed assertion `EXPECT_TRUE(IsEven(Fib(4)))` will print:

```none
Value of: IsEven(Fib(4))
  Actual: false (3 is odd)
Expected: true
```

instead of a more opaque

```none
Value of: IsEven(Fib(4))
  Actual: false
Expected: true
```

If you want informative messages in `EXPECT_FALSE` and `ASSERT_FALSE` as well
(one third of Boolean assertions in the Google code base are negative ones), and
are fine with making the predicate slower in the success case, you can supply a
success message:

```c++
testing::AssertionResult IsEven(int n) {
  if ((n % 2) == 0)
    return testing::AssertionSuccess() << n << " is even";
  else
    return testing::AssertionFailure() << n << " is odd";
}
```

Then the statement `EXPECT_FALSE(IsEven(Fib(6)))` will print

```none
  Value of: IsEven(Fib(6))
     Actual: true (8 is even)
  Expected: false
```

#### Using a Predicate-Formatter

If you find the default message generated by
[`EXPECT_PRED*`](reference/assertions.md#EXPECT_PRED) and
[`EXPECT_TRUE`](reference/assertions.md#EXPECT_TRUE) unsatisfactory, or some
arguments to your predicate do not support streaming to `ostream`, you can
instead use *predicate-formatter assertions* to *fully* customize how the
message is formatted. See
[`EXPECT_PRED_FORMAT*`](reference/assertions.md#EXPECT_PRED_FORMAT) in the
Assertions Reference for details.

### Floating-Point Comparison

See [Floating-Point Comparison](reference/assertions.md#floating-point) in the
Assertions Reference.

#### Floating-Point Predicate-Format Functions

Some floating-point operations are useful, but not that often used. In order to
avoid an explosion of new macros, we provide them as predicate-format functions
that can be used in the predicate assertion macro
[`EXPECT_PRED_FORMAT2`](reference/assertions.md#EXPECT_PRED_FORMAT), for
example:

```c++
EXPECT_PRED_FORMAT2(testing::FloatLE, val1, val2);
EXPECT_PRED_FORMAT2(testing::DoubleLE, val1, val2);
```

The above code verifies that `val1` is less than, or approximately equal to,
`val2`.

### Asserting Using gMock Matchers

See [`EXPECT_THAT`](reference/assertions.md#EXPECT_THAT) in the Assertions
Reference.

### More String Assertions

(Please read the [previous](#asserting-using-gmock-matchers) section first if
you haven't.)

You can use the gMock [string matchers](reference/matchers.md#string-matchers)
with [`EXPECT_THAT`](reference/assertions.md#EXPECT_THAT) to do more string
comparison tricks (sub-string, prefix, suffix, regular expression, and etc). For
example,

```c++
using ::testing::HasSubstr;
using ::testing::MatchesRegex;
...
  ASSERT_THAT(foo_string, HasSubstr("needle"));
  EXPECT_THAT(bar_string, MatchesRegex("\\w*\\d+"));
```

### Windows HRESULT assertions

See [Windows HRESULT Assertions](reference/assertions.md#HRESULT) in the
Assertions Reference.

### Type Assertions

You can call the function

```c++
::testing::StaticAssertTypeEq<T1, T2>();
```

to assert that types `T1` and `T2` are the same. The function does nothing if
the assertion is satisfied. If the types are different, the function call will
fail to compile, the compiler error message will say that
`T1 and T2 are not the same type` and most likely (depending on the compiler)
show you the actual values of `T1` and `T2`. This is mainly useful inside
template code.

**Caveat**: When used inside a member function of a class template or a function
template, `StaticAssertTypeEq<T1, T2>()` is effective only if the function is
instantiated. For example, given:

```c++
template <typename T> class Foo {
 public:
  void Bar() { testing::StaticAssertTypeEq<int, T>(); }
};
```

the code:

```c++
void Test1() { Foo<bool> foo; }
```

will not generate a compiler error, as `Foo<bool>::Bar()` is never actually
instantiated. Instead, you need:

```c++
void Test2() { Foo<bool> foo; foo.Bar(); }
```

to cause a compiler error.

### Assertion Placement

You can use assertions in any C++ function. In particular, it doesn't have to be
a method of the test fixture class. The one constraint is that assertions that
generate a fatal failure (`FAIL*` and `ASSERT_*`) can only be used in
void-returning functions. This is a consequence of Google's not using
exceptions. By placing it in a non-void function you'll get a confusing compile
error like `"error: void value not ignored as it ought to be"` or `"cannot
initialize return object of type 'bool' with an rvalue of type 'void'"` or
`"error: no viable conversion from 'void' to 'string'"`.

If you need to use fatal assertions in a function that returns non-void, one
option is to make the function return the value in an out parameter instead. For
example, you can rewrite `T2 Foo(T1 x)` to `void Foo(T1 x, T2* result)`. You
need to make sure that `*result` contains some sensible value even when the
function returns prematurely. As the function now returns `void`, you can use
any assertion inside of it.

If changing the function's type is not an option, you should just use assertions
that generate non-fatal failures, such as `ADD_FAILURE*` and `EXPECT_*`.

{: .callout .note}
NOTE: Constructors and destructors are not considered void-returning functions,
according to the C++ language specification, and so you may not use fatal
assertions in them; you'll get a compilation error if you try. Instead, either
call `abort` and crash the entire test executable, or put the fatal assertion in
a `SetUp`/`TearDown` function; see
[constructor/destructor vs. `SetUp`/`TearDown`](faq.md#CtorVsSetUp)

{: .callout .warning}
WARNING: A fatal assertion in a helper function (private void-returning method)
called from a constructor or destructor does not terminate the current test, as
your intuition might suggest: it merely returns from the constructor or
destructor early, possibly leaving your object in a partially-constructed or
partially-destructed state! You almost certainly want to `abort` or use
`SetUp`/`TearDown` instead.

## Skipping test execution

Related to the assertions `SUCCEED()` and `FAIL()`, you can prevent further test
execution at runtime with the `GTEST_SKIP()` macro. This is useful when you need
to check for preconditions of the system under test during runtime and skip
tests in a meaningful way.

`GTEST_SKIP()` can be used in individual test cases or in the `SetUp()` methods
of classes derived from either `::testing::Environment` or `::testing::Test`.
For example:

```c++
TEST(SkipTest, DoesSkip) {
  GTEST_SKIP() << "Skipping single test";
  EXPECT_EQ(0, 1);  // Won't fail; it won't be executed
}

class SkipFixture : public ::testing::Test {
 protected:
  void SetUp() override {
    GTEST_SKIP() << "Skipping all tests for this fixture";
  }
};

// Tests for SkipFixture won't be executed.
TEST_F(SkipFixture, SkipsOneTest) {
  EXPECT_EQ(5, 7);  // Won't fail
}
```

As with assertion macros, you can stream a custom message into `GTEST_SKIP()`.

## Teaching googletest How to Print Your Values

When a test assertion such as `EXPECT_EQ` fails, googletest prints the argument
values to help you debug. It does this using a user-extensible value printer.

This printer knows how to print built-in C++ types, native arrays, STL
containers, and any type that supports the `<<` operator. For other types, it
prints the raw bytes in the value and hopes that you the user can figure it out.

As mentioned earlier, the printer is *extensible*. That means you can teach it
to do a better job at printing your particular type than to dump the bytes. To
do that, define `<<` for your type:

```c++
#include <ostream>

namespace foo {

class Bar {  // We want googletest to be able to print instances of this.
...
  // Create a free inline friend function.
  friend std::ostream& operator<<(std::ostream& os, const Bar& bar) {
    return os << bar.DebugString();  // whatever needed to print bar to os
  }
};

// If you can't declare the function in the class it's important that the
// << operator is defined in the SAME namespace that defines Bar.  C++'s look-up
// rules rely on that.
std::ostream& operator<<(std::ostream& os, const Bar& bar) {
  return os << bar.DebugString();  // whatever needed to print bar to os
}

}  // namespace foo
```

Sometimes, this might not be an option: your team may consider it bad style to
have a `<<` operator for `Bar`, or `Bar` may already have a `<<` operator that
doesn't do what you want (and you cannot change it). If so, you can instead
define a `PrintTo()` function like this:

```c++
#include <ostream>

namespace foo {

class Bar {
  ...
  friend void PrintTo(const Bar& bar, std::ostream* os) {
    *os << bar.DebugString();  // whatever needed to print bar to os
  }
};

// If you can't declare the function in the class it's important that PrintTo()
// is defined in the SAME namespace that defines Bar.  C++'s look-up rules rely
// on that.
void PrintTo(const Bar& bar, std::ostream* os) {
  *os << bar.DebugString();  // whatever needed to print bar to os
}

}  // namespace foo
```

If you have defined both `<<` and `PrintTo()`, the latter will be used when
googletest is concerned. This allows you to customize how the value appears in
googletest's output without affecting code that relies on the behavior of its
`<<` operator.

If you want to print a value `x` using googletest's value printer yourself, just
call `::testing::PrintToString(x)`, which returns an `std::string`:

```c++
vector<pair<Bar, int> > bar_ints = GetBarIntVector();

EXPECT_TRUE(IsCorrectBarIntVector(bar_ints))
    << "bar_ints = " << testing::PrintToString(bar_ints);
```

## Death Tests

In many applications, there are assertions that can cause application failure if
a condition is not met. These sanity checks, which ensure that the program is in
a known good state, are there to fail at the earliest possible time after some
program state is corrupted. If the assertion checks the wrong condition, then
the program may proceed in an erroneous state, which could lead to memory
corruption, security holes, or worse. Hence it is vitally important to test that
such assertion statements work as expected.

Since these precondition checks cause the processes to die, we call such tests
_death tests_. More generally, any test that checks that a program terminates
(except by throwing an exception) in an expected fashion is also a death test.

Note that if a piece of code throws an exception, we don't consider it "death"
for the purpose of death tests, as the caller of the code could catch the
exception and avoid the crash. If you want to verify exceptions thrown by your
code, see [Exception Assertions](#ExceptionAssertions).

If you want to test `EXPECT_*()/ASSERT_*()` failures in your test code, see
["Catching" Failures](#catching-failures).

### How to Write a Death Test

GoogleTest provides assertion macros to support death tests. See
[Death Assertions](reference/assertions.md#death) in the Assertions Reference
for details.

To write a death test, simply use one of the macros inside your test function.
For example,

```c++
TEST(MyDeathTest, Foo) {
  // This death test uses a compound statement.
  ASSERT_DEATH({
    int n = 5;
    Foo(&n);
  }, "Error on line .* of Foo()");
}

TEST(MyDeathTest, NormalExit) {
  EXPECT_EXIT(NormalExit(), testing::ExitedWithCode(0), "Success");
}

TEST(MyDeathTest, KillProcess) {
  EXPECT_EXIT(KillProcess(), testing::KilledBySignal(SIGKILL),
              "Sending myself unblockable signal");
}
```

verifies that:

*   calling `Foo(5)` causes the process to die with the given error message,
*   calling `NormalExit()` causes the process to print `"Success"` to stderr and
    exit with exit code 0, and
*   calling `KillProcess()` kills the process with signal `SIGKILL`.

The test function body may contain other assertions and statements as well, if
necessary.

Note that a death test only cares about three things:

1.  does `statement` abort or exit the process?
2.  (in the case of `ASSERT_EXIT` and `EXPECT_EXIT`) does the exit status
    satisfy `predicate`? Or (in the case of `ASSERT_DEATH` and `EXPECT_DEATH`)
    is the exit status non-zero? And
3.  does the stderr output match `matcher`?

In particular, if `statement` generates an `ASSERT_*` or `EXPECT_*` failure, it
will **not** cause the death test to fail, as googletest assertions don't abort
the process.

### Death Test Naming

{: .callout .important}
IMPORTANT: We strongly recommend you to follow the convention of naming your
**test suite** (not test) `*DeathTest` when it contains a death test, as
demonstrated in the above example. The
[Death Tests And Threads](#death-tests-and-threads) section below explains why.

If a test fixture class is shared by normal tests and death tests, you can use
`using` or `typedef` to introduce an alias for the fixture class and avoid
duplicating its code:

```c++
class FooTest : public testing::Test { ... };

using FooDeathTest = FooTest;

TEST_F(FooTest, DoesThis) {
  // normal test
}

TEST_F(FooDeathTest, DoesThat) {
  // death test
}
```

### Regular Expression Syntax

On POSIX systems (e.g. Linux, Cygwin, and Mac), googletest uses the
[POSIX extended regular expression](http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html#tag_09_04)
syntax. To learn about this syntax, you may want to read this
[Wikipedia entry](http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions).

On Windows, googletest uses its own simple regular expression implementation. It
lacks many features. For example, we don't support union (`"x|y"`), grouping
(`"(xy)"`), brackets (`"[xy]"`), and repetition count (`"x{5,7}"`), among
others. Below is what we do support (`A` denotes a literal character, period
(`.`), or a single `\\ ` escape sequence; `x` and `y` denote regular
expressions.):

Expression | Meaning
---------- | --------------------------------------------------------------
`c`        | matches any literal character `c`
`\\d`      | matches any decimal digit
`\\D`      | matches any character that's not a decimal digit
`\\f`      | matches `\f`
`\\n`      | matches `\n`
`\\r`      | matches `\r`
`\\s`      | matches any ASCII whitespace, including `\n`
`\\S`      | matches any character that's not a whitespace
`\\t`      | matches `\t`
`\\v`      | matches `\v`
`\\w`      | matches any letter, `_`, or decimal digit
`\\W`      | matches any character that `\\w` doesn't match
`\\c`      | matches any literal character `c`, which must be a punctuation
`.`        | matches any single character except `\n`
`A?`       | matches 0 or 1 occurrences of `A`
`A*`       | matches 0 or many occurrences of `A`
`A+`       | matches 1 or many occurrences of `A`
`^`        | matches the beginning of a string (not that of each line)
`$`        | matches the end of a string (not that of each line)
`xy`       | matches `x` followed by `y`

To help you determine which capability is available on your system, googletest
defines macros to govern which regular expression it is using. The macros are:
`GTEST_USES_SIMPLE_RE=1` or `GTEST_USES_POSIX_RE=1`. If you want your death
tests to work in all cases, you can either `#if` on these macros or use the more
limited syntax only.

### How It Works

See [Death Assertions](reference/assertions.md#death) in the Assertions
Reference.

### Death Tests And Threads

The reason for the two death test styles has to do with thread safety. Due to
well-known problems with forking in the presence of threads, death tests should
be run in a single-threaded context. Sometimes, however, it isn't feasible to
arrange that kind of environment. For example, statically-initialized modules
may start threads before main is ever reached. Once threads have been created,
it may be difficult or impossible to clean them up.

googletest has three features intended to raise awareness of threading issues.

1.  A warning is emitted if multiple threads are running when a death test is
    encountered.
2.  Test suites with a name ending in "DeathTest" are run before all other
    tests.
3.  It uses `clone()` instead of `fork()` to spawn the child process on Linux
    (`clone()` is not available on Cygwin and Mac), as `fork()` is more likely
    to cause the child to hang when the parent process has multiple threads.

It's perfectly fine to create threads inside a death test statement; they are
executed in a separate process and cannot affect the parent.

### Death Test Styles

The "threadsafe" death test style was introduced in order to help mitigate the
risks of testing in a possibly multithreaded environment. It trades increased
test execution time (potentially dramatically so) for improved thread safety.

The automated testing framework does not set the style flag. You can choose a
particular style of death tests by setting the flag programmatically:

```c++
testing::FLAGS_gtest_death_test_style="threadsafe"
```

You can do this in `main()` to set the style for all death tests in the binary,
or in individual tests. Recall that flags are saved before running each test and
restored afterwards, so you need not do that yourself. For example:

```c++
int main(int argc, char** argv) {
  testing::InitGoogleTest(&argc, argv);
  testing::FLAGS_gtest_death_test_style = "fast";
  return RUN_ALL_TESTS();
}

TEST(MyDeathTest, TestOne) {
  testing::FLAGS_gtest_death_test_style = "threadsafe";
  // This test is run in the "threadsafe" style:
  ASSERT_DEATH(ThisShouldDie(), "");
}

TEST(MyDeathTest, TestTwo) {
  // This test is run in the "fast" style:
  ASSERT_DEATH(ThisShouldDie(), "");
}
```

### Caveats

The `statement` argument of `ASSERT_EXIT()` can be any valid C++ statement. If
it leaves the current function via a `return` statement or by throwing an
exception, the death test is considered to have failed. Some googletest macros
may return from the current function (e.g. `ASSERT_TRUE()`), so be sure to avoid
them in `statement`.

Since `statement` runs in the child process, any in-memory side effect (e.g.
modifying a variable, releasing memory, etc) it causes will *not* be observable
in the parent process. In particular, if you release memory in a death test,
your program will fail the heap check as the parent process will never see the
memory reclaimed. To solve this problem, you can

1.  try not to free memory in a death test;
2.  free the memory again in the parent process; or
3.  do not use the heap checker in your program.

Due to an implementation detail, you cannot place multiple death test assertions
on the same line; otherwise, compilation will fail with an unobvious error
message.

Despite the improved thread safety afforded by the "threadsafe" style of death
test, thread problems such as deadlock are still possible in the presence of
handlers registered with `pthread_atfork(3)`.


## Using Assertions in Sub-routines

{: .callout .note}
Note: If you want to put a series of test assertions in a subroutine to check
for a complex condition, consider using
[a custom GMock matcher](gmock_cook_book.md#NewMatchers)
instead. This lets you provide a more readable error message in case of failure
and avoid all of the issues described below.

### Adding Traces to Assertions

If a test sub-routine is called from several places, when an assertion inside it
fails, it can be hard to tell which invocation of the sub-routine the failure is
from. You can alleviate this problem using extra logging or custom failure
messages, but that usually clutters up your tests. A better solution is to use
the `SCOPED_TRACE` macro or the `ScopedTrace` utility:

```c++
SCOPED_TRACE(message);
```
```c++
ScopedTrace trace("file_path", line_number, message);
```

where `message` can be anything streamable to `std::ostream`. `SCOPED_TRACE`
macro will cause the current file name, line number, and the given message to be
added in every failure message. `ScopedTrace` accepts explicit file name and
line number in arguments, which is useful for writing test helpers. The effect
will be undone when the control leaves the current lexical scope.

For example,

```c++
10: void Sub1(int n) {
11:   EXPECT_EQ(Bar(n), 1);
12:   EXPECT_EQ(Bar(n + 1), 2);
13: }
14:
15: TEST(FooTest, Bar) {
16:   {
17:     SCOPED_TRACE("A");  // This trace point will be included in
18:                         // every failure in this scope.
19:     Sub1(1);
20:   }
21:   // Now it won't.
22:   Sub1(9);
23: }
```

could result in messages like these:

```none
path/to/foo_test.cc:11: Failure
Value of: Bar(n)
Expected: 1
  Actual: 2
Google Test trace:
path/to/foo_test.cc:17: A

path/to/foo_test.cc:12: Failure
Value of: Bar(n + 1)
Expected: 2
  Actual: 3
```

Without the trace, it would've been difficult to know which invocation of
`Sub1()` the two failures come from respectively. (You could add an extra
message to each assertion in `Sub1()` to indicate the value of `n`, but that's
tedious.)

Some tips on using `SCOPED_TRACE`:

1.  With a suitable message, it's often enough to use `SCOPED_TRACE` at the
    beginning of a sub-routine, instead of at each call site.
2.  When calling sub-routines inside a loop, make the loop iterator part of the
    message in `SCOPED_TRACE` such that you can know which iteration the failure
    is from.
3.  Sometimes the line number of the trace point is enough for identifying the
    particular invocation of a sub-routine. In this case, you don't have to
    choose a unique message for `SCOPED_TRACE`. You can simply use `""`.
4.  You can use `SCOPED_TRACE` in an inner scope when there is one in the outer
    scope. In this case, all active trace points will be included in the failure
    messages, in reverse order they are encountered.
5.  The trace dump is clickable in Emacs - hit `return` on a line number and
    you'll be taken to that line in the source file!

### Propagating Fatal Failures

A common pitfall when using `ASSERT_*` and `FAIL*` is not understanding that
when they fail they only abort the _current function_, not the entire test. For
example, the following test will segfault:

```c++
void Subroutine() {
  // Generates a fatal failure and aborts the current function.
  ASSERT_EQ(1, 2);

  // The following won't be executed.
  ...
}

TEST(FooTest, Bar) {
  Subroutine();  // The intended behavior is for the fatal failure
                 // in Subroutine() to abort the entire test.

  // The actual behavior: the function goes on after Subroutine() returns.
  int* p = nullptr;
  *p = 3;  // Segfault!
}
```

To alleviate this, googletest provides three different solutions. You could use
either exceptions, the `(ASSERT|EXPECT)_NO_FATAL_FAILURE` assertions or the
`HasFatalFailure()` function. They are described in the following two
subsections.

#### Asserting on Subroutines with an exception

The following code can turn ASSERT-failure into an exception:

```c++
class ThrowListener : public testing::EmptyTestEventListener {
  void OnTestPartResult(const testing::TestPartResult& result) override {
    if (result.type() == testing::TestPartResult::kFatalFailure) {
      throw testing::AssertionException(result);
    }
  }
};
int main(int argc, char** argv) {
  ...
  testing::UnitTest::GetInstance()->listeners().Append(new ThrowListener);
  return RUN_ALL_TESTS();
}
```

This listener should be added after other listeners if you have any, otherwise
they won't see failed `OnTestPartResult`.

#### Asserting on Subroutines

As shown above, if your test calls a subroutine that has an `ASSERT_*` failure
in it, the test will continue after the subroutine returns. This may not be what
you want.

Often people want fatal failures to propagate like exceptions. For that
googletest offers the following macros:

Fatal assertion                       | Nonfatal assertion                    | Verifies
------------------------------------- | ------------------------------------- | --------
`ASSERT_NO_FATAL_FAILURE(statement);` | `EXPECT_NO_FATAL_FAILURE(statement);` | `statement` doesn't generate any new fatal failures in the current thread.

Only failures in the thread that executes the assertion are checked to determine
the result of this type of assertions. If `statement` creates new threads,
failures in these threads are ignored.

Examples:

```c++
ASSERT_NO_FATAL_FAILURE(Foo());

int i;
EXPECT_NO_FATAL_FAILURE({
  i = Bar();
});
```

Assertions from multiple threads are currently not supported on Windows.

#### Checking for Failures in the Current Test

`HasFatalFailure()` in the `::testing::Test` class returns `true` if an
assertion in the current test has suffered a fatal failure. This allows
functions to catch fatal failures in a sub-routine and return early.

```c++
class Test {
 public:
  ...
  static bool HasFatalFailure();
};
```

The typical usage, which basically simulates the behavior of a thrown exception,
is:

```c++
TEST(FooTest, Bar) {
  Subroutine();
  // Aborts if Subroutine() had a fatal failure.
  if (HasFatalFailure()) return;

  // The following won't be executed.
  ...
}
```

If `HasFatalFailure()` is used outside of `TEST()` , `TEST_F()` , or a test
fixture, you must add the `::testing::Test::` prefix, as in:

```c++
if (testing::Test::HasFatalFailure()) return;
```

Similarly, `HasNonfatalFailure()` returns `true` if the current test has at
least one non-fatal failure, and `HasFailure()` returns `true` if the current
test has at least one failure of either kind.

## Logging Additional Information

In your test code, you can call `RecordProperty("key", value)` to log additional
information, where `value` can be either a string or an `int`. The *last* value
recorded for a key will be emitted to the
[XML output](#generating-an-xml-report) if you specify one. For example, the
test

```c++
TEST_F(WidgetUsageTest, MinAndMaxWidgets) {
  RecordProperty("MaximumWidgets", ComputeMaxUsage());
  RecordProperty("MinimumWidgets", ComputeMinUsage());
}
```

will output XML like this:

```xml
  ...
    <testcase name="MinAndMaxWidgets" status="run" time="0.006" classname="WidgetUsageTest" MaximumWidgets="12" MinimumWidgets="9" />
  ...
```

{: .callout .note}
> NOTE:
>
> *   `RecordProperty()` is a static member of the `Test` class. Therefore it
>     needs to be prefixed with `::testing::Test::` if used outside of the
>     `TEST` body and the test fixture class.
> *   *`key`* must be a valid XML attribute name, and cannot conflict with the
>     ones already used by googletest (`name`, `status`, `time`, `classname`,
>     `type_param`, and `value_param`).
> *   Calling `RecordProperty()` outside of the lifespan of a test is allowed.
>     If it's called outside of a test but between a test suite's
>     `SetUpTestSuite()` and `TearDownTestSuite()` methods, it will be
>     attributed to the XML element for the test suite. If it's called outside
>     of all test suites (e.g. in a test environment), it will be attributed to
>     the top-level XML element.

## Sharing Resources Between Tests in the Same Test Suite

googletest creates a new test fixture object for each test in order to make
tests independent and easier to debug. However, sometimes tests use resources
that are expensive to set up, making the one-copy-per-test model prohibitively
expensive.

If the tests don't change the resource, there's no harm in their sharing a
single resource copy. So, in addition to per-test set-up/tear-down, googletest
also supports per-test-suite set-up/tear-down. To use it:

1.  In your test fixture class (say `FooTest` ), declare as `static` some member
    variables to hold the shared resources.
2.  Outside your test fixture class (typically just below it), define those
    member variables, optionally giving them initial values.
3.  In the same test fixture class, define a `static void SetUpTestSuite()`
    function (remember not to spell it as **`SetupTestSuite`** with a small
    `u`!) to set up the shared resources and a `static void TearDownTestSuite()`
    function to tear them down.

That's it! googletest automatically calls `SetUpTestSuite()` before running the
*first test* in the `FooTest` test suite (i.e. before creating the first
`FooTest` object), and calls `TearDownTestSuite()` after running the *last test*
in it (i.e. after deleting the last `FooTest` object). In between, the tests can
use the shared resources.

Remember that the test order is undefined, so your code can't depend on a test
preceding or following another. Also, the tests must either not modify the state
of any shared resource, or, if they do modify the state, they must restore the
state to its original value before passing control to the next test.

Here's an example of per-test-suite set-up and tear-down:

```c++
class FooTest : public testing::Test {
 protected:
  // Per-test-suite set-up.
  // Called before the first test in this test suite.
  // Can be omitted if not needed.
  static void SetUpTestSuite() {
    shared_resource_ = new ...;
  }

  // Per-test-suite tear-down.
  // Called after the last test in this test suite.
  // Can be omitted if not needed.
  static void TearDownTestSuite() {
    delete shared_resource_;
    shared_resource_ = nullptr;
  }

  // You can define per-test set-up logic as usual.
  void SetUp() override { ... }

  // You can define per-test tear-down logic as usual.
  void TearDown() override { ... }

  // Some expensive resource shared by all tests.
  static T* shared_resource_;
};

T* FooTest::shared_resource_ = nullptr;

TEST_F(FooTest, Test1) {
  ... you can refer to shared_resource_ here ...
}

TEST_F(FooTest, Test2) {
  ... you can refer to shared_resource_ here ...
}
```

{: .callout .note}
NOTE: Though the above code declares `SetUpTestSuite()` protected, it may
sometimes be necessary to declare it public, such as when using it with
`TEST_P`.

## Global Set-Up and Tear-Down

Just as you can do set-up and tear-down at the test level and the test suite
level, you can also do it at the test program level. Here's how.

First, you subclass the `::testing::Environment` class to define a test
environment, which knows how to set-up and tear-down:

```c++
class Environment : public ::testing::Environment {
 public:
  ~Environment() override {}

  // Override this to define how to set up the environment.
  void SetUp() override {}

  // Override this to define how to tear down the environment.
  void TearDown() override {}
};
```

Then, you register an instance of your environment class with googletest by
calling the `::testing::AddGlobalTestEnvironment()` function:

```c++
Environment* AddGlobalTestEnvironment(Environment* env);
```

Now, when `RUN_ALL_TESTS()` is called, it first calls the `SetUp()` method of
each environment object, then runs the tests if none of the environments
reported fatal failures and `GTEST_SKIP()` was not called. `RUN_ALL_TESTS()`
always calls `TearDown()` with each environment object, regardless of whether or
not the tests were run.

It's OK to register multiple environment objects. In this suite, their `SetUp()`
will be called in the order they are registered, and their `TearDown()` will be
called in the reverse order.

Note that googletest takes ownership of the registered environment objects.
Therefore **do not delete them** by yourself.

You should call `AddGlobalTestEnvironment()` before `RUN_ALL_TESTS()` is called,
probably in `main()`. If you use `gtest_main`, you need to call this before
`main()` starts for it to take effect. One way to do this is to define a global
variable like this:

```c++
testing::Environment* const foo_env =
    testing::AddGlobalTestEnvironment(new FooEnvironment);
```

However, we strongly recommend you to write your own `main()` and call
`AddGlobalTestEnvironment()` there, as relying on initialization of global
variables makes the code harder to read and may cause problems when you register
multiple environments from different translation units and the environments have
dependencies among them (remember that the compiler doesn't guarantee the order
in which global variables from different translation units are initialized).

## Value-Parameterized Tests

*Value-parameterized tests* allow you to test your code with different
parameters without writing multiple copies of the same test. This is useful in a
number of situations, for example:

*   You have a piece of code whose behavior is affected by one or more
    command-line flags. You want to make sure your code performs correctly for
    various values of those flags.
*   You want to test different implementations of an OO interface.
*   You want to test your code over various inputs (a.k.a. data-driven testing).
    This feature is easy to abuse, so please exercise your good sense when doing
    it!

### How to Write Value-Parameterized Tests

To write value-parameterized tests, first you should define a fixture class. It
must be derived from both `testing::Test` and `testing::WithParamInterface<T>`
(the latter is a pure interface), where `T` is the type of your parameter
values. For convenience, you can just derive the fixture class from
`testing::TestWithParam<T>`, which itself is derived from both `testing::Test`
and `testing::WithParamInterface<T>`. `T` can be any copyable type. If it's a
raw pointer, you are responsible for managing the lifespan of the pointed
values.

{: .callout .note}
NOTE: If your test fixture defines `SetUpTestSuite()` or `TearDownTestSuite()`
they must be declared **public** rather than **protected** in order to use
`TEST_P`.

```c++
class FooTest :
    public testing::TestWithParam<const char*> {
  // You can implement all the usual fixture class members here.
  // To access the test parameter, call GetParam() from class
  // TestWithParam<T>.
};

// Or, when you want to add parameters to a pre-existing fixture class:
class BaseTest : public testing::Test {
  ...
};
class BarTest : public BaseTest,
                public testing::WithParamInterface<const char*> {
  ...
};
```

Then, use the `TEST_P` macro to define as many test patterns using this fixture
as you want. The `_P` suffix is for "parameterized" or "pattern", whichever you
prefer to think.

```c++
TEST_P(FooTest, DoesBlah) {
  // Inside a test, access the test parameter with the GetParam() method
  // of the TestWithParam<T> class:
  EXPECT_TRUE(foo.Blah(GetParam()));
  ...
}

TEST_P(FooTest, HasBlahBlah) {
  ...
}
```

Finally, you can use the `INSTANTIATE_TEST_SUITE_P` macro to instantiate the
test suite with any set of parameters you want. GoogleTest defines a number of
functions for generating test parameters—see details at
[`INSTANTIATE_TEST_SUITE_P`](reference/testing.md#INSTANTIATE_TEST_SUITE_P) in
the Testing Reference.

For example, the following statement will instantiate tests from the `FooTest`
test suite each with parameter values `"meeny"`, `"miny"`, and `"moe"` using the
[`Values`](reference/testing.md#param-generators) parameter generator:

```c++
INSTANTIATE_TEST_SUITE_P(MeenyMinyMoe,
                         FooTest,
                         testing::Values("meeny", "miny", "moe"));
```

{: .callout .note}
NOTE: The code above must be placed at global or namespace scope, not at
function scope.

The first argument to `INSTANTIATE_TEST_SUITE_P` is a unique name for the
instantiation of the test suite. The next argument is the name of the test
pattern, and the last is the
[parameter generator](reference/testing.md#param-generators).

You can instantiate a test pattern more than once, so to distinguish different
instances of the pattern, the instantiation name is added as a prefix to the
actual test suite name. Remember to pick unique prefixes for different
instantiations. The tests from the instantiation above will have these names:

*   `MeenyMinyMoe/FooTest.DoesBlah/0` for `"meeny"`
*   `MeenyMinyMoe/FooTest.DoesBlah/1` for `"miny"`
*   `MeenyMinyMoe/FooTest.DoesBlah/2` for `"moe"`
*   `MeenyMinyMoe/FooTest.HasBlahBlah/0` for `"meeny"`
*   `MeenyMinyMoe/FooTest.HasBlahBlah/1` for `"miny"`
*   `MeenyMinyMoe/FooTest.HasBlahBlah/2` for `"moe"`

You can use these names in [`--gtest_filter`](#running-a-subset-of-the-tests).

The following statement will instantiate all tests from `FooTest` again, each
with parameter values `"cat"` and `"dog"` using the
[`ValuesIn`](reference/testing.md#param-generators) parameter generator:

```c++
const char* pets[] = {"cat", "dog"};
INSTANTIATE_TEST_SUITE_P(Pets, FooTest, testing::ValuesIn(pets));
```

The tests from the instantiation above will have these names:

*   `Pets/FooTest.DoesBlah/0` for `"cat"`
*   `Pets/FooTest.DoesBlah/1` for `"dog"`
*   `Pets/FooTest.HasBlahBlah/0` for `"cat"`
*   `Pets/FooTest.HasBlahBlah/1` for `"dog"`

Please note that `INSTANTIATE_TEST_SUITE_P` will instantiate *all* tests in the
given test suite, whether their definitions come before or *after* the
`INSTANTIATE_TEST_SUITE_P` statement.

Additionally, by default, every `TEST_P` without a corresponding
`INSTANTIATE_TEST_SUITE_P` causes a failing test in test suite
`GoogleTestVerification`. If you have a test suite where that omission is not an
error, for example it is in a library that may be linked in for other reasons or
where the list of test cases is dynamic and may be empty, then this check can be
suppressed by tagging the test suite:

```c++
GTEST_ALLOW_UNINSTANTIATED_PARAMETERIZED_TEST(FooTest);
```

You can see [sample7_unittest.cc] and [sample8_unittest.cc] for more examples.

[sample7_unittest.cc]: https://github.com/google/googletest/blob/master/googletest/samples/sample7_unittest.cc "Parameterized Test example"
[sample8_unittest.cc]: https://github.com/google/googletest/blob/master/googletest/samples/sample8_unittest.cc "Parameterized Test example with multiple parameters"

### Creating Value-Parameterized Abstract Tests

In the above, we define and instantiate `FooTest` in the *same* source file.
Sometimes you may want to define value-parameterized tests in a library and let
other people instantiate them later. This pattern is known as *abstract tests*.
As an example of its application, when you are designing an interface you can
write a standard suite of abstract tests (perhaps using a factory function as
the test parameter) that all implementations of the interface are expected to
pass. When someone implements the interface, they can instantiate your suite to
get all the interface-conformance tests for free.

To define abstract tests, you should organize your code like this:

1.  Put the definition of the parameterized test fixture class (e.g. `FooTest`)
    in a header file, say `foo_param_test.h`. Think of this as *declaring* your
    abstract tests.
2.  Put the `TEST_P` definitions in `foo_param_test.cc`, which includes
    `foo_param_test.h`. Think of this as *implementing* your abstract tests.

Once they are defined, you can instantiate them by including `foo_param_test.h`,
invoking `INSTANTIATE_TEST_SUITE_P()`, and depending on the library target that
contains `foo_param_test.cc`. You can instantiate the same abstract test suite
multiple times, possibly in different source files.

### Specifying Names for Value-Parameterized Test Parameters

The optional last argument to `INSTANTIATE_TEST_SUITE_P()` allows the user to
specify a function or functor that generates custom test name suffixes based on
the test parameters. The function should accept one argument of type
`testing::TestParamInfo<class ParamType>`, and return `std::string`.

`testing::PrintToStringParamName` is a builtin test suffix generator that
returns the value of `testing::PrintToString(GetParam())`. It does not work for
`std::string` or C strings.

{: .callout .note}
NOTE: test names must be non-empty, unique, and may only contain ASCII
alphanumeric characters. In particular, they
[should not contain underscores](faq.md#why-should-test-suite-names-and-test-names-not-contain-underscore)

```c++
class MyTestSuite : public testing::TestWithParam<int> {};

TEST_P(MyTestSuite, MyTest)
{
  std::cout << "Example Test Param: " << GetParam() << std::endl;
}

INSTANTIATE_TEST_SUITE_P(MyGroup, MyTestSuite, testing::Range(0, 10),
                         testing::PrintToStringParamName());
```

Providing a custom functor allows for more control over test parameter name
generation, especially for types where the automatic conversion does not
generate helpful parameter names (e.g. strings as demonstrated above). The
following example illustrates this for multiple parameters, an enumeration type
and a string, and also demonstrates how to combine generators. It uses a lambda
for conciseness:

```c++
enum class MyType { MY_FOO = 0, MY_BAR = 1 };

class MyTestSuite : public testing::TestWithParam<std::tuple<MyType, std::string>> {
};

INSTANTIATE_TEST_SUITE_P(
    MyGroup, MyTestSuite,
    testing::Combine(
        testing::Values(MyType::MY_FOO, MyType::MY_BAR),
        testing::Values("A", "B")),
    [](const testing::TestParamInfo<MyTestSuite::ParamType>& info) {
      std::string name = absl::StrCat(
          std::get<0>(info.param) == MyType::MY_FOO ? "Foo" : "Bar",
          std::get<1>(info.param));
      absl::c_replace_if(name, [](char c) { return !std::isalnum(c); }, '_');
      return name;
    });
```

## Typed Tests

Suppose you have multiple implementations of the same interface and want to make
sure that all of them satisfy some common requirements. Or, you may have defined
several types that are supposed to conform to the same "concept" and you want to
verify it. In both cases, you want the same test logic repeated for different
types.

While you can write one `TEST` or `TEST_F` for each type you want to test (and
you may even factor the test logic into a function template that you invoke from
the `TEST`), it's tedious and doesn't scale: if you want `m` tests over `n`
types, you'll end up writing `m*n` `TEST`s.

*Typed tests* allow you to repeat the same test logic over a list of types. You
only need to write the test logic once, although you must know the type list
when writing typed tests. Here's how you do it:

First, define a fixture class template. It should be parameterized by a type.
Remember to derive it from `::testing::Test`:

```c++
template <typename T>
class FooTest : public testing::Test {
 public:
  ...
  using List = std::list<T>;
  static T shared_;
  T value_;
};
```

Next, associate a list of types with the test suite, which will be repeated for
each type in the list:

```c++
using MyTypes = ::testing::Types<char, int, unsigned int>;
TYPED_TEST_SUITE(FooTest, MyTypes);
```

The type alias (`using` or `typedef`) is necessary for the `TYPED_TEST_SUITE`
macro to parse correctly. Otherwise the compiler will think that each comma in
the type list introduces a new macro argument.

Then, use `TYPED_TEST()` instead of `TEST_F()` to define a typed test for this
test suite. You can repeat this as many times as you want:

```c++
TYPED_TEST(FooTest, DoesBlah) {
  // Inside a test, refer to the special name TypeParam to get the type
  // parameter.  Since we are inside a derived class template, C++ requires
  // us to visit the members of FooTest via 'this'.
  TypeParam n = this->value_;

  // To visit static members of the fixture, add the 'TestFixture::'
  // prefix.
  n += TestFixture::shared_;

  // To refer to typedefs in the fixture, add the 'typename TestFixture::'
  // prefix.  The 'typename' is required to satisfy the compiler.
  typename TestFixture::List values;

  values.push_back(n);
  ...
}

TYPED_TEST(FooTest, HasPropertyA) { ... }
```

You can see [sample6_unittest.cc] for a complete example.

[sample6_unittest.cc]: https://github.com/google/googletest/blob/master/googletest/samples/sample6_unittest.cc "Typed Test example"

## Type-Parameterized Tests

*Type-parameterized tests* are like typed tests, except that they don't require
you to know the list of types ahead of time. Instead, you can define the test
logic first and instantiate it with different type lists later. You can even
instantiate it more than once in the same program.

If you are designing an interface or concept, you can define a suite of
type-parameterized tests to verify properties that any valid implementation of
the interface/concept should have. Then, the author of each implementation can
just instantiate the test suite with their type to verify that it conforms to
the requirements, without having to write similar tests repeatedly. Here's an
example:

First, define a fixture class template, as we did with typed tests:

```c++
template <typename T>
class FooTest : public testing::Test {
  ...
};
```

Next, declare that you will define a type-parameterized test suite:

```c++
TYPED_TEST_SUITE_P(FooTest);
```

Then, use `TYPED_TEST_P()` to define a type-parameterized test. You can repeat
this as many times as you want:

```c++
TYPED_TEST_P(FooTest, DoesBlah) {
  // Inside a test, refer to TypeParam to get the type parameter.
  TypeParam n = 0;
  ...
}

TYPED_TEST_P(FooTest, HasPropertyA) { ... }
```

Now the tricky part: you need to register all test patterns using the
`REGISTER_TYPED_TEST_SUITE_P` macro before you can instantiate them. The first
argument of the macro is the test suite name; the rest are the names of the
tests in this test suite:

```c++
REGISTER_TYPED_TEST_SUITE_P(FooTest,
                            DoesBlah, HasPropertyA);
```

Finally, you are free to instantiate the pattern with the types you want. If you
put the above code in a header file, you can `#include` it in multiple C++
source files and instantiate it multiple times.

```c++
using MyTypes = ::testing::Types<char, int, unsigned int>;
INSTANTIATE_TYPED_TEST_SUITE_P(My, FooTest, MyTypes);
```

To distinguish different instances of the pattern, the first argument to the
`INSTANTIATE_TYPED_TEST_SUITE_P` macro is a prefix that will be added to the
actual test suite name. Remember to pick unique prefixes for different
instances.

In the special case where the type list contains only one type, you can write
that type directly without `::testing::Types<...>`, like this:

```c++
INSTANTIATE_TYPED_TEST_SUITE_P(My, FooTest, int);
```

You can see [sample6_unittest.cc] for a complete example.

## Testing Private Code

If you change your software's internal implementation, your tests should not
break as long as the change is not observable by users. Therefore, **per the
black-box testing principle, most of the time you should test your code through
its public interfaces.**

**If you still find yourself needing to test internal implementation code,
consider if there's a better design.** The desire to test internal
implementation is often a sign that the class is doing too much. Consider
extracting an implementation class, and testing it. Then use that implementation
class in the original class.

If you absolutely have to test non-public interface code though, you can. There
are two cases to consider:

*   Static functions ( *not* the same as static member functions!) or unnamed
    namespaces, and
*   Private or protected class members

To test them, we use the following special techniques:

*   Both static functions and definitions/declarations in an unnamed namespace
    are only visible within the same translation unit. To test them, you can
    `#include` the entire `.cc` file being tested in your `*_test.cc` file.
    (#including `.cc` files is not a good way to reuse code - you should not do
    this in production code!)

    However, a better approach is to move the private code into the
    `foo::internal` namespace, where `foo` is the namespace your project
    normally uses, and put the private declarations in a `*-internal.h` file.
    Your production `.cc` files and your tests are allowed to include this
    internal header, but your clients are not. This way, you can fully test your
    internal implementation without leaking it to your clients.

*   Private class members are only accessible from within the class or by
    friends. To access a class' private members, you can declare your test
    fixture as a friend to the class and define accessors in your fixture. Tests
    using the fixture can then access the private members of your production
    class via the accessors in the fixture. Note that even though your fixture
    is a friend to your production class, your tests are not automatically
    friends to it, as they are technically defined in sub-classes of the
    fixture.

    Another way to test private members is to refactor them into an
    implementation class, which is then declared in a `*-internal.h` file. Your
    clients aren't allowed to include this header but your tests can. Such is
    called the
    [Pimpl](https://www.gamedev.net/articles/programming/general-and-gameplay-programming/the-c-pimpl-r1794/)
    (Private Implementation) idiom.

    Or, you can declare an individual test as a friend of your class by adding
    this line in the class body:

    ```c++
        FRIEND_TEST(TestSuiteName, TestName);
    ```

    For example,

    ```c++
    // foo.h
    class Foo {
      ...
     private:
      FRIEND_TEST(FooTest, BarReturnsZeroOnNull);

      int Bar(void* x);
    };

    // foo_test.cc
    ...
    TEST(FooTest, BarReturnsZeroOnNull) {
      Foo foo;
      EXPECT_EQ(foo.Bar(NULL), 0);  // Uses Foo's private member Bar().
    }
    ```

    Pay special attention when your class is defined in a namespace. If you want
    your test fixtures and tests to be friends of your class, then they must be
    defined in the exact same namespace (no anonymous or inline namespaces).

    For example, if the code to be tested looks like:

    ```c++
    namespace my_namespace {

    class Foo {
      friend class FooTest;
      FRIEND_TEST(FooTest, Bar);
      FRIEND_TEST(FooTest, Baz);
      ... definition of the class Foo ...
    };

    }  // namespace my_namespace
    ```

    Your test code should be something like:

    ```c++
    namespace my_namespace {

    class FooTest : public testing::Test {
     protected:
      ...
    };

    TEST_F(FooTest, Bar) { ... }
    TEST_F(FooTest, Baz) { ... }

    }  // namespace my_namespace
    ```

## "Catching" Failures

If you are building a testing utility on top of googletest, you'll want to test
your utility. What framework would you use to test it? googletest, of course.

The challenge is to verify that your testing utility reports failures correctly.
In frameworks that report a failure by throwing an exception, you could catch
the exception and assert on it. But googletest doesn't use exceptions, so how do
we test that a piece of code generates an expected failure?

`"gtest/gtest-spi.h"` contains some constructs to do this. After #including this header,
you can use

```c++
  EXPECT_FATAL_FAILURE(statement, substring);
```

to assert that `statement` generates a fatal (e.g. `ASSERT_*`) failure in the
current thread whose message contains the given `substring`, or use

```c++
  EXPECT_NONFATAL_FAILURE(statement, substring);
```

if you are expecting a non-fatal (e.g. `EXPECT_*`) failure.

Only failures in the current thread are checked to determine the result of this
type of expectations. If `statement` creates new threads, failures in these
threads are also ignored. If you want to catch failures in other threads as
well, use one of the following macros instead:

```c++
  EXPECT_FATAL_FAILURE_ON_ALL_THREADS(statement, substring);
  EXPECT_NONFATAL_FAILURE_ON_ALL_THREADS(statement, substring);
```

{: .callout .note}
NOTE: Assertions from multiple threads are currently not supported on Windows.

For technical reasons, there are some caveats:

1.  You cannot stream a failure message to either macro.

2.  `statement` in `EXPECT_FATAL_FAILURE{_ON_ALL_THREADS}()` cannot reference
    local non-static variables or non-static members of `this` object.

3.  `statement` in `EXPECT_FATAL_FAILURE{_ON_ALL_THREADS}()` cannot return a
    value.

## Registering tests programmatically

The `TEST` macros handle the vast majority of all use cases, but there are few
where runtime registration logic is required. For those cases, the framework
provides the `::testing::RegisterTest` that allows callers to register arbitrary
tests dynamically.

This is an advanced API only to be used when the `TEST` macros are insufficient.
The macros should be preferred when possible, as they avoid most of the
complexity of calling this function.

It provides the following signature:

```c++
template <typename Factory>
TestInfo* RegisterTest(const char* test_suite_name, const char* test_name,
                       const char* type_param, const char* value_param,
                       const char* file, int line, Factory factory);
```

The `factory` argument is a factory callable (move-constructible) object or
function pointer that creates a new instance of the Test object. It handles
ownership to the caller. The signature of the callable is `Fixture*()`, where
`Fixture` is the test fixture class for the test. All tests registered with the
same `test_suite_name` must return the same fixture type. This is checked at
runtime.

The framework will infer the fixture class from the factory and will call the
`SetUpTestSuite` and `TearDownTestSuite` for it.

Must be called before `RUN_ALL_TESTS()` is invoked, otherwise behavior is
undefined.

Use case example:

```c++
class MyFixture : public testing::Test {
 public:
  // All of these optional, just like in regular macro usage.
  static void SetUpTestSuite() { ... }
  static void TearDownTestSuite() { ... }
  void SetUp() override { ... }
  void TearDown() override { ... }
};

class MyTest : public MyFixture {
 public:
  explicit MyTest(int data) : data_(data) {}
  void TestBody() override { ... }

 private:
  int data_;
};

void RegisterMyTests(const std::vector<int>& values) {
  for (int v : values) {
    testing::RegisterTest(
        "MyFixture", ("Test" + std::to_string(v)).c_str(), nullptr,
        std::to_string(v).c_str(),
        __FILE__, __LINE__,
        // Important to use the fixture type as the return type here.
        [=]() -> MyFixture* { return new MyTest(v); });
  }
}
...
int main(int argc, char** argv) {
  std::vector<int> values_to_test = LoadValuesFromConfig();
  RegisterMyTests(values_to_test);
  ...
  return RUN_ALL_TESTS();
}
```
## Getting the Current Test's Name

Sometimes a function may need to know the name of the currently running test.
For example, you may be using the `SetUp()` method of your test fixture to set
the golden file name based on which test is running. The
[`TestInfo`](reference/testing.md#TestInfo) class has this information.

To obtain a `TestInfo` object for the currently running test, call
`current_test_info()` on the [`UnitTest`](reference/testing.md#UnitTest)
singleton object:

```c++
  // Gets information about the currently running test.
  // Do NOT delete the returned object - it's managed by the UnitTest class.
  const testing::TestInfo* const test_info =
      testing::UnitTest::GetInstance()->current_test_info();

  printf("We are in test %s of test suite %s.\n",
         test_info->name(),
         test_info->test_suite_name());
```

`current_test_info()` returns a null pointer if no test is running. In
particular, you cannot find the test suite name in `SetUpTestSuite()`,
`TearDownTestSuite()` (where you know the test suite name implicitly), or
functions called from them.

## Extending googletest by Handling Test Events

googletest provides an **event listener API** to let you receive notifications
about the progress of a test program and test failures. The events you can
listen to include the start and end of the test program, a test suite, or a test
method, among others. You may use this API to augment or replace the standard
console output, replace the XML output, or provide a completely different form
of output, such as a GUI or a database. You can also use test events as
checkpoints to implement a resource leak checker, for example.

### Defining Event Listeners

To define a event listener, you subclass either
[`testing::TestEventListener`](reference/testing.md#TestEventListener) or
[`testing::EmptyTestEventListener`](reference/testing.md#EmptyTestEventListener)
The former is an (abstract) interface, where *each pure virtual method can be
overridden to handle a test event* (For example, when a test starts, the
`OnTestStart()` method will be called.). The latter provides an empty
implementation of all methods in the interface, such that a subclass only needs
to override the methods it cares about.

When an event is fired, its context is passed to the handler function as an
argument. The following argument types are used:

*   UnitTest reflects the state of the entire test program,
*   TestSuite has information about a test suite, which can contain one or more
    tests,
*   TestInfo contains the state of a test, and
*   TestPartResult represents the result of a test assertion.

An event handler function can examine the argument it receives to find out
interesting information about the event and the test program's state.

Here's an example:

```c++
  class MinimalistPrinter : public testing::EmptyTestEventListener {
    // Called before a test starts.
    void OnTestStart(const testing::TestInfo& test_info) override {
      printf("*** Test %s.%s starting.\n",
             test_info.test_suite_name(), test_info.name());
    }

    // Called after a failed assertion or a SUCCESS().
    void OnTestPartResult(const testing::TestPartResult& test_part_result) override {
      printf("%s in %s:%d\n%s\n",
             test_part_result.failed() ? "*** Failure" : "Success",
             test_part_result.file_name(),
             test_part_result.line_number(),
             test_part_result.summary());
    }

    // Called after a test ends.
    void OnTestEnd(const testing::TestInfo& test_info) override {
      printf("*** Test %s.%s ending.\n",
             test_info.test_suite_name(), test_info.name());
    }
  };
```

### Using Event Listeners

To use the event listener you have defined, add an instance of it to the
googletest event listener list (represented by class
[`TestEventListeners`](reference/testing.md#TestEventListeners) - note the "s"
at the end of the name) in your `main()` function, before calling
`RUN_ALL_TESTS()`:

```c++
int main(int argc, char** argv) {
  testing::InitGoogleTest(&argc, argv);
  // Gets hold of the event listener list.
  testing::TestEventListeners& listeners =
      testing::UnitTest::GetInstance()->listeners();
  // Adds a listener to the end.  googletest takes the ownership.
  listeners.Append(new MinimalistPrinter);
  return RUN_ALL_TESTS();
}
```

There's only one problem: the default test result printer is still in effect, so
its output will mingle with the output from your minimalist printer. To suppress
the default printer, just release it from the event listener list and delete it.
You can do so by adding one line:

```c++
  ...
  delete listeners.Release(listeners.default_result_printer());
  listeners.Append(new MinimalistPrinter);
  return RUN_ALL_TESTS();
```

Now, sit back and enjoy a completely different output from your tests. For more
details, see [sample9_unittest.cc].

[sample9_unittest.cc]: https://github.com/google/googletest/blob/master/googletest/samples/sample9_unittest.cc "Event listener example"

You may append more than one listener to the list. When an `On*Start()` or
`OnTestPartResult()` event is fired, the listeners will receive it in the order
they appear in the list (since new listeners are added to the end of the list,
the default text printer and the default XML generator will receive the event
first). An `On*End()` event will be received by the listeners in the *reverse*
order. This allows output by listeners added later to be framed by output from
listeners added earlier.

### Generating Failures in Listeners

You may use failure-raising macros (`EXPECT_*()`, `ASSERT_*()`, `FAIL()`, etc)
when processing an event. There are some restrictions:

1.  You cannot generate any failure in `OnTestPartResult()` (otherwise it will
    cause `OnTestPartResult()` to be called recursively).
2.  A listener that handles `OnTestPartResult()` is not allowed to generate any
    failure.

When you add listeners to the listener list, you should put listeners that
handle `OnTestPartResult()` *before* listeners that can generate failures. This
ensures that failures generated by the latter are attributed to the right test
by the former.

See [sample10_unittest.cc] for an example of a failure-raising listener.

[sample10_unittest.cc]: https://github.com/google/googletest/blob/master/googletest/samples/sample10_unittest.cc "Failure-raising listener example"

## Running Test Programs: Advanced Options

googletest test programs are ordinary executables. Once built, you can run them
directly and affect their behavior via the following environment variables
and/or command line flags. For the flags to work, your programs must call
`::testing::InitGoogleTest()` before calling `RUN_ALL_TESTS()`.

To see a list of supported flags and their usage, please run your test program
with the `--help` flag. You can also use `-h`, `-?`, or `/?` for short.

If an option is specified both by an environment variable and by a flag, the
latter takes precedence.

### Selecting Tests

#### Listing Test Names

Sometimes it is necessary to list the available tests in a program before
running them so that a filter may be applied if needed. Including the flag
`--gtest_list_tests` overrides all other flags and lists tests in the following
format:

```none
TestSuite1.
  TestName1
  TestName2
TestSuite2.
  TestName
```

None of the tests listed are actually run if the flag is provided. There is no
corresponding environment variable for this flag.

#### Running a Subset of the Tests

By default, a googletest program runs all tests the user has defined. Sometimes,
you want to run only a subset of the tests (e.g. for debugging or quickly
verifying a change). If you set the `GTEST_FILTER` environment variable or the
`--gtest_filter` flag to a filter string, googletest will only run the tests
whose full names (in the form of `TestSuiteName.TestName`) match the filter.

The format of a filter is a '`:`'-separated list of wildcard patterns (called
the *positive patterns*) optionally followed by a '`-`' and another
'`:`'-separated pattern list (called the *negative patterns*). A test matches
the filter if and only if it matches any of the positive patterns but does not
match any of the negative patterns.

A pattern may contain `'*'` (matches any string) or `'?'` (matches any single
character). For convenience, the filter `'*-NegativePatterns'` can be also
written as `'-NegativePatterns'`.

For example:

*   `./foo_test` Has no flag, and thus runs all its tests.
*   `./foo_test --gtest_filter=*` Also runs everything, due to the single
    match-everything `*` value.
*   `./foo_test --gtest_filter=FooTest.*` Runs everything in test suite
    `FooTest` .
*   `./foo_test --gtest_filter=*Null*:*Constructor*` Runs any test whose full
    name contains either `"Null"` or `"Constructor"` .
*   `./foo_test --gtest_filter=-*DeathTest.*` Runs all non-death tests.
*   `./foo_test --gtest_filter=FooTest.*-FooTest.Bar` Runs everything in test
    suite `FooTest` except `FooTest.Bar`.
*   `./foo_test --gtest_filter=FooTest.*:BarTest.*-FooTest.Bar:BarTest.Foo` Runs
    everything in test suite `FooTest` except `FooTest.Bar` and everything in
    test suite `BarTest` except `BarTest.Foo`.

#### Stop test execution upon first failure

By default, a googletest program runs all tests the user has defined. In some
cases (e.g. iterative test development & execution) it may be desirable stop
test execution upon first failure (trading improved latency for completeness).
If `GTEST_FAIL_FAST` environment variable or `--gtest_fail_fast` flag is set,
the test runner will stop execution as soon as the first test failure is
found.

#### Temporarily Disabling Tests

If you have a broken test that you cannot fix right away, you can add the
`DISABLED_` prefix to its name. This will exclude it from execution. This is
better than commenting out the code or using `#if 0`, as disabled tests are
still compiled (and thus won't rot).

If you need to disable all tests in a test suite, you can either add `DISABLED_`
to the front of the name of each test, or alternatively add it to the front of
the test suite name.

For example, the following tests won't be run by googletest, even though they
will still be compiled:

```c++
// Tests that Foo does Abc.
TEST(FooTest, DISABLED_DoesAbc) { ... }

class DISABLED_BarTest : public testing::Test { ... };

// Tests that Bar does Xyz.
TEST_F(DISABLED_BarTest, DoesXyz) { ... }
```

{: .callout .note}
NOTE: This feature should only be used for temporary pain-relief. You still have
to fix the disabled tests at a later date. As a reminder, googletest will print
a banner warning you if a test program contains any disabled tests.

{: .callout .tip}
TIP: You can easily count the number of disabled tests you have using
`grep`. This number can be used as a metric for
improving your test quality.

#### Temporarily Enabling Disabled Tests

To include disabled tests in test execution, just invoke the test program with
the `--gtest_also_run_disabled_tests` flag or set the
`GTEST_ALSO_RUN_DISABLED_TESTS` environment variable to a value other than `0`.
You can combine this with the `--gtest_filter` flag to further select which
disabled tests to run.

### Repeating the Tests

Once in a while you'll run into a test whose result is hit-or-miss. Perhaps it
will fail only 1% of the time, making it rather hard to reproduce the bug under
a debugger. This can be a major source of frustration.

The `--gtest_repeat` flag allows you to repeat all (or selected) test methods in
a program many times. Hopefully, a flaky test will eventually fail and give you
a chance to debug. Here's how to use it:

```none
$ foo_test --gtest_repeat=1000
Repeat foo_test 1000 times and don't stop at failures.

$ foo_test --gtest_repeat=-1
A negative count means repeating forever.

$ foo_test --gtest_repeat=1000 --gtest_break_on_failure
Repeat foo_test 1000 times, stopping at the first failure.  This
is especially useful when running under a debugger: when the test
fails, it will drop into the debugger and you can then inspect
variables and stacks.

$ foo_test --gtest_repeat=1000 --gtest_filter=FooBar.*
Repeat the tests whose name matches the filter 1000 times.
```

If your test program contains
[global set-up/tear-down](#global-set-up-and-tear-down) code, it will be
repeated in each iteration as well, as the flakiness may be in it. You can also
specify the repeat count by setting the `GTEST_REPEAT` environment variable.

### Shuffling the Tests

You can specify the `--gtest_shuffle` flag (or set the `GTEST_SHUFFLE`
environment variable to `1`) to run the tests in a program in a random order.
This helps to reveal bad dependencies between tests.

By default, googletest uses a random seed calculated from the current time.
Therefore you'll get a different order every time. The console output includes
the random seed value, such that you can reproduce an order-related test failure
later. To specify the random seed explicitly, use the `--gtest_random_seed=SEED`
flag (or set the `GTEST_RANDOM_SEED` environment variable), where `SEED` is an
integer in the range [0, 99999]. The seed value 0 is special: it tells
googletest to do the default behavior of calculating the seed from the current
time.

If you combine this with `--gtest_repeat=N`, googletest will pick a different
random seed and re-shuffle the tests in each iteration.

### Controlling Test Output

#### Colored Terminal Output

googletest can use colors in its terminal output to make it easier to spot the
important information:

<pre>...
<font color="green">[----------]</font> 1 test from FooTest
<font color="green">[ RUN      ]</font> FooTest.DoesAbc
<font color="green">[       OK ]</font> FooTest.DoesAbc
<font color="green">[----------]</font> 2 tests from BarTest
<font color="green">[ RUN      ]</font> BarTest.HasXyzProperty
<font color="green">[       OK ]</font> BarTest.HasXyzProperty
<font color="green">[ RUN      ]</font> BarTest.ReturnsTrueOnSuccess
... some error messages ...
<font color="red">[   FAILED ]</font> BarTest.ReturnsTrueOnSuccess
...
<font color="green">[==========]</font> 30 tests from 14 test suites ran.
<font color="green">[   PASSED ]</font> 28 tests.
<font color="red">[   FAILED ]</font> 2 tests, listed below:
<font color="red">[   FAILED ]</font> BarTest.ReturnsTrueOnSuccess
<font color="red">[   FAILED ]</font> AnotherTest.DoesXyz

 2 FAILED TESTS
</pre>

You can set the `GTEST_COLOR` environment variable or the `--gtest_color`
command line flag to `yes`, `no`, or `auto` (the default) to enable colors,
disable colors, or let googletest decide. When the value is `auto`, googletest
will use colors if and only if the output goes to a terminal and (on non-Windows
platforms) the `TERM` environment variable is set to `xterm` or `xterm-color`.

#### Suppressing test passes

By default, googletest prints 1 line of output for each test, indicating if it
passed or failed. To show only test failures, run the test program with
`--gtest_brief=1`, or set the GTEST_BRIEF environment variable to `1`.

#### Suppressing the Elapsed Time

By default, googletest prints the time it takes to run each test. To disable
that, run the test program with the `--gtest_print_time=0` command line flag, or
set the GTEST_PRINT_TIME environment variable to `0`.

#### Suppressing UTF-8 Text Output

In case of assertion failures, googletest prints expected and actual values of
type `string` both as hex-encoded strings as well as in readable UTF-8 text if
they contain valid non-ASCII UTF-8 characters. If you want to suppress the UTF-8
text because, for example, you don't have an UTF-8 compatible output medium, run
the test program with `--gtest_print_utf8=0` or set the `GTEST_PRINT_UTF8`
environment variable to `0`.



#### Generating an XML Report

googletest can emit a detailed XML report to a file in addition to its normal
textual output. The report contains the duration of each test, and thus can help
you identify slow tests.

To generate the XML report, set the `GTEST_OUTPUT` environment variable or the
`--gtest_output` flag to the string `"xml:path_to_output_file"`, which will
create the file at the given location. You can also just use the string `"xml"`,
in which case the output can be found in the `test_detail.xml` file in the
current directory.

If you specify a directory (for example, `"xml:output/directory/"` on Linux or
`"xml:output\directory\"` on Windows), googletest will create the XML file in
that directory, named after the test executable (e.g. `foo_test.xml` for test
program `foo_test` or `foo_test.exe`). If the file already exists (perhaps left
over from a previous run), googletest will pick a different name (e.g.
`foo_test_1.xml`) to avoid overwriting it.

The report is based on the `junitreport` Ant task. Since that format was
originally intended for Java, a little interpretation is required to make it
apply to googletest tests, as shown here:

```xml
<testsuites name="AllTests" ...>
  <testsuite name="test_case_name" ...>
    <testcase    name="test_name" ...>
      <failure message="..."/>
      <failure message="..."/>
      <failure message="..."/>
    </testcase>
  </testsuite>
</testsuites>
```

*   The root `<testsuites>` element corresponds to the entire test program.
*   `<testsuite>` elements correspond to googletest test suites.
*   `<testcase>` elements correspond to googletest test functions.

For instance, the following program

```c++
TEST(MathTest, Addition) { ... }
TEST(MathTest, Subtraction) { ... }
TEST(LogicTest, NonContradiction) { ... }
```

could generate this report:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<testsuites tests="3" failures="1" errors="0" time="0.035" timestamp="2011-10-31T18:52:42" name="AllTests">
  <testsuite name="MathTest" tests="2" failures="1" errors="0" time="0.015">
    <testcase name="Addition" status="run" time="0.007" classname="">
      <failure message="Value of: add(1, 1)&#x0A;  Actual: 3&#x0A;Expected: 2" type="">...</failure>
      <failure message="Value of: add(1, -1)&#x0A;  Actual: 1&#x0A;Expected: 0" type="">...</failure>
    </testcase>
    <testcase name="Subtraction" status="run" time="0.005" classname="">
    </testcase>
  </testsuite>
  <testsuite name="LogicTest" tests="1" failures="0" errors="0" time="0.005">
    <testcase name="NonContradiction" status="run" time="0.005" classname="">
    </testcase>
  </testsuite>
</testsuites>
```

Things to note:

*   The `tests` attribute of a `<testsuites>` or `<testsuite>` element tells how
    many test functions the googletest program or test suite contains, while the
    `failures` attribute tells how many of them failed.

*   The `time` attribute expresses the duration of the test, test suite, or
    entire test program in seconds.

*   The `timestamp` attribute records the local date and time of the test
    execution.

*   Each `<failure>` element corresponds to a single failed googletest
    assertion.

#### Generating a JSON Report

googletest can also emit a JSON report as an alternative format to XML. To
generate the JSON report, set the `GTEST_OUTPUT` environment variable or the
`--gtest_output` flag to the string `"json:path_to_output_file"`, which will
create the file at the given location. You can also just use the string
`"json"`, in which case the output can be found in the `test_detail.json` file
in the current directory.

The report format conforms to the following JSON Schema:

```json
{
  "$schema": "http://json-schema.org/schema#",
  "type": "object",
  "definitions": {
    "TestCase": {
      "type": "object",
      "properties": {
        "name": { "type": "string" },
        "tests": { "type": "integer" },
        "failures": { "type": "integer" },
        "disabled": { "type": "integer" },
        "time": { "type": "string" },
        "testsuite": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/TestInfo"
          }
        }
      }
    },
    "TestInfo": {
      "type": "object",
      "properties": {
        "name": { "type": "string" },
        "status": {
          "type": "string",
          "enum": ["RUN", "NOTRUN"]
        },
        "time": { "type": "string" },
        "classname": { "type": "string" },
        "failures": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/Failure"
          }
        }
      }
    },
    "Failure": {
      "type": "object",
      "properties": {
        "failures": { "type": "string" },
        "type": { "type": "string" }
      }
    }
  },
  "properties": {
    "tests": { "type": "integer" },
    "failures": { "type": "integer" },
    "disabled": { "type": "integer" },
    "errors": { "type": "integer" },
    "timestamp": {
      "type": "string",
      "format": "date-time"
    },
    "time": { "type": "string" },
    "name": { "type": "string" },
    "testsuites": {
      "type": "array",
      "items": {
        "$ref": "#/definitions/TestCase"
      }
    }
  }
}
```

The report uses the format that conforms to the following Proto3 using the
[JSON encoding](https://developers.google.com/protocol-buffers/docs/proto3#json):

```proto
syntax = "proto3";

package googletest;

import "google/protobuf/timestamp.proto";
import "google/protobuf/duration.proto";

message UnitTest {
  int32 tests = 1;
  int32 failures = 2;
  int32 disabled = 3;
  int32 errors = 4;
  google.protobuf.Timestamp timestamp = 5;
  google.protobuf.Duration time = 6;
  string name = 7;
  repeated TestCase testsuites = 8;
}

message TestCase {
  string name = 1;
  int32 tests = 2;
  int32 failures = 3;
  int32 disabled = 4;
  int32 errors = 5;
  google.protobuf.Duration time = 6;
  repeated TestInfo testsuite = 7;
}

message TestInfo {
  string name = 1;
  enum Status {
    RUN = 0;
    NOTRUN = 1;
  }
  Status status = 2;
  google.protobuf.Duration time = 3;
  string classname = 4;
  message Failure {
    string failures = 1;
    string type = 2;
  }
  repeated Failure failures = 5;
}
```

For instance, the following program

```c++
TEST(MathTest, Addition) { ... }
TEST(MathTest, Subtraction) { ... }
TEST(LogicTest, NonContradiction) { ... }
```

could generate this report:

```json
{
  "tests": 3,
  "failures": 1,
  "errors": 0,
  "time": "0.035s",
  "timestamp": "2011-10-31T18:52:42Z",
  "name": "AllTests",
  "testsuites": [
    {
      "name": "MathTest",
      "tests": 2,
      "failures": 1,
      "errors": 0,
      "time": "0.015s",
      "testsuite": [
        {
          "name": "Addition",
          "status": "RUN",
          "time": "0.007s",
          "classname": "",
          "failures": [
            {
              "message": "Value of: add(1, 1)\n  Actual: 3\nExpected: 2",
              "type": ""
            },
            {
              "message": "Value of: add(1, -1)\n  Actual: 1\nExpected: 0",
              "type": ""
            }
          ]
        },
        {
          "name": "Subtraction",
          "status": "RUN",
          "time": "0.005s",
          "classname": ""
        }
      ]
    },
    {
      "name": "LogicTest",
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "time": "0.005s",
      "testsuite": [
        {
          "name": "NonContradiction",
          "status": "RUN",
          "time": "0.005s",
          "classname": ""
        }
      ]
    }
  ]
}
```

{: .callout .important}
IMPORTANT: The exact format of the JSON document is subject to change.

### Controlling How Failures Are Reported

#### Detecting Test Premature Exit

Google Test implements the _premature-exit-file_ protocol for test runners
to catch any kind of unexpected exits of test programs. Upon start,
Google Test creates the file which will be automatically deleted after
all work has been finished. Then, the test runner can check if this file
exists. In case the file remains undeleted, the inspected test has exited
prematurely.

This feature is enabled only if the `TEST_PREMATURE_EXIT_FILE` environment
variable has been set.

#### Turning Assertion Failures into Break-Points

When running test programs under a debugger, it's very convenient if the
debugger can catch an assertion failure and automatically drop into interactive
mode. googletest's *break-on-failure* mode supports this behavior.

To enable it, set the `GTEST_BREAK_ON_FAILURE` environment variable to a value
other than `0`. Alternatively, you can use the `--gtest_break_on_failure`
command line flag.

#### Disabling Catching Test-Thrown Exceptions

googletest can be used either with or without exceptions enabled. If a test
throws a C++ exception or (on Windows) a structured exception (SEH), by default
googletest catches it, reports it as a test failure, and continues with the next
test method. This maximizes the coverage of a test run. Also, on Windows an
uncaught exception will cause a pop-up window, so catching the exceptions allows
you to run the tests automatically.

When debugging the test failures, however, you may instead want the exceptions
to be handled by the debugger, such that you can examine the call stack when an
exception is thrown. To achieve that, set the `GTEST_CATCH_EXCEPTIONS`
environment variable to `0`, or use the `--gtest_catch_exceptions=0` flag when
running the tests.

### Sanitizer Integration

The
[Undefined Behavior Sanitizer](https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html),
[Address Sanitizer](https://github.com/google/sanitizers/wiki/AddressSanitizer),
and
[Thread Sanitizer](https://github.com/google/sanitizers/wiki/ThreadSanitizerCppManual)
all provide weak functions that you can override to trigger explicit failures
when they detect sanitizer errors, such as creating a reference from `nullptr`.
To override these functions, place definitions for them in a source file that
you compile as part of your main binary:

```
extern "C" {
void __ubsan_on_report() {
  FAIL() << "Encountered an undefined behavior sanitizer error";
}
void __asan_on_error() {
  FAIL() << "Encountered an address sanitizer error";
}
void __tsan_on_report() {
  FAIL() << "Encountered a thread sanitizer error";
}
}  // extern "C"
```

After compiling your project with one of the sanitizers enabled, if a particular
test triggers a sanitizer error, googletest will report that it failed.
# Community-Created Documentation

The following is a list, in no particular order, of links to documentation
created by the Googletest community.

*   [Googlemock Insights](https://github.com/ElectricRCAircraftGuy/eRCaGuy_dotfiles/blob/master/googletest/insights.md),
    by [ElectricRCAircraftGuy](https://github.com/ElectricRCAircraftGuy)
# Googletest FAQ

## Why should test suite names and test names not contain underscore?

{: .callout .note}
Note: Googletest reserves underscore (`_`) for special purpose keywords, such as
[the `DISABLED_` prefix](advanced.md#temporarily-disabling-tests), in addition
to the following rationale.

Underscore (`_`) is special, as C++ reserves the following to be used by the
compiler and the standard library:

1.  any identifier that starts with an `_` followed by an upper-case letter, and
2.  any identifier that contains two consecutive underscores (i.e. `__`)
    *anywhere* in its name.

User code is *prohibited* from using such identifiers.

Now let's look at what this means for `TEST` and `TEST_F`.

Currently `TEST(TestSuiteName, TestName)` generates a class named
`TestSuiteName_TestName_Test`. What happens if `TestSuiteName` or `TestName`
contains `_`?

1.  If `TestSuiteName` starts with an `_` followed by an upper-case letter (say,
    `_Foo`), we end up with `_Foo_TestName_Test`, which is reserved and thus
    invalid.
2.  If `TestSuiteName` ends with an `_` (say, `Foo_`), we get
    `Foo__TestName_Test`, which is invalid.
3.  If `TestName` starts with an `_` (say, `_Bar`), we get
    `TestSuiteName__Bar_Test`, which is invalid.
4.  If `TestName` ends with an `_` (say, `Bar_`), we get
    `TestSuiteName_Bar__Test`, which is invalid.

So clearly `TestSuiteName` and `TestName` cannot start or end with `_`
(Actually, `TestSuiteName` can start with `_` -- as long as the `_` isn't
followed by an upper-case letter. But that's getting complicated. So for
simplicity we just say that it cannot start with `_`.).

It may seem fine for `TestSuiteName` and `TestName` to contain `_` in the
middle. However, consider this:

```c++
TEST(Time, Flies_Like_An_Arrow) { ... }
TEST(Time_Flies, Like_An_Arrow) { ... }
```

Now, the two `TEST`s will both generate the same class
(`Time_Flies_Like_An_Arrow_Test`). That's not good.

So for simplicity, we just ask the users to avoid `_` in `TestSuiteName` and
`TestName`. The rule is more constraining than necessary, but it's simple and
easy to remember. It also gives googletest some wiggle room in case its
implementation needs to change in the future.

If you violate the rule, there may not be immediate consequences, but your test
may (just may) break with a new compiler (or a new version of the compiler you
are using) or with a new version of googletest. Therefore it's best to follow
the rule.

## Why does googletest support `EXPECT_EQ(NULL, ptr)` and `ASSERT_EQ(NULL, ptr)` but not `EXPECT_NE(NULL, ptr)` and `ASSERT_NE(NULL, ptr)`?

First of all, you can use `nullptr` with each of these macros, e.g.
`EXPECT_EQ(ptr, nullptr)`, `EXPECT_NE(ptr, nullptr)`, `ASSERT_EQ(ptr, nullptr)`,
`ASSERT_NE(ptr, nullptr)`. This is the preferred syntax in the style guide
because `nullptr` does not have the type problems that `NULL` does.

Due to some peculiarity of C++, it requires some non-trivial template meta
programming tricks to support using `NULL` as an argument of the `EXPECT_XX()`
and `ASSERT_XX()` macros. Therefore we only do it where it's most needed
(otherwise we make the implementation of googletest harder to maintain and more
error-prone than necessary).

Historically, the `EXPECT_EQ()` macro took the *expected* value as its first
argument and the *actual* value as the second, though this argument order is now
discouraged. It was reasonable that someone wanted
to write `EXPECT_EQ(NULL, some_expression)`, and this indeed was requested
several times. Therefore we implemented it.

The need for `EXPECT_NE(NULL, ptr)` wasn't nearly as strong. When the assertion
fails, you already know that `ptr` must be `NULL`, so it doesn't add any
information to print `ptr` in this case. That means `EXPECT_TRUE(ptr != NULL)`
works just as well.

If we were to support `EXPECT_NE(NULL, ptr)`, for consistency we'd have to
support `EXPECT_NE(ptr, NULL)` as well. This means using the template meta
programming tricks twice in the implementation, making it even harder to
understand and maintain. We believe the benefit doesn't justify the cost.

Finally, with the growth of the gMock matcher library, we are encouraging people
to use the unified `EXPECT_THAT(value, matcher)` syntax more often in tests. One
significant advantage of the matcher approach is that matchers can be easily
combined to form new matchers, while the `EXPECT_NE`, etc, macros cannot be
easily combined. Therefore we want to invest more in the matchers than in the
`EXPECT_XX()` macros.

## I need to test that different implementations of an interface satisfy some common requirements. Should I use typed tests or value-parameterized tests?

For testing various implementations of the same interface, either typed tests or
value-parameterized tests can get it done. It's really up to you the user to
decide which is more convenient for you, depending on your particular case. Some
rough guidelines:

*   Typed tests can be easier to write if instances of the different
    implementations can be created the same way, modulo the type. For example,
    if all these implementations have a public default constructor (such that
    you can write `new TypeParam`), or if their factory functions have the same
    form (e.g. `CreateInstance<TypeParam>()`).
*   Value-parameterized tests can be easier to write if you need different code
    patterns to create different implementations' instances, e.g. `new Foo` vs
    `new Bar(5)`. To accommodate for the differences, you can write factory
    function wrappers and pass these function pointers to the tests as their
    parameters.
*   When a typed test fails, the default output includes the name of the type,
    which can help you quickly identify which implementation is wrong.
    Value-parameterized tests only show the number of the failed iteration by
    default. You will need to define a function that returns the iteration name
    and pass it as the third parameter to INSTANTIATE_TEST_SUITE_P to have more
    useful output.
*   When using typed tests, you need to make sure you are testing against the
    interface type, not the concrete types (in other words, you want to make
    sure `implicit_cast<MyInterface*>(my_concrete_impl)` works, not just that
    `my_concrete_impl` works). It's less likely to make mistakes in this area
    when using value-parameterized tests.

I hope I didn't confuse you more. :-) If you don't mind, I'd suggest you to give
both approaches a try. Practice is a much better way to grasp the subtle
differences between the two tools. Once you have some concrete experience, you
can much more easily decide which one to use the next time.

## I got some run-time errors about invalid proto descriptors when using `ProtocolMessageEquals`. Help!

{: .callout .note}
**Note:** `ProtocolMessageEquals` and `ProtocolMessageEquiv` are *deprecated*
now. Please use `EqualsProto`, etc instead.

`ProtocolMessageEquals` and `ProtocolMessageEquiv` were redefined recently and
are now less tolerant of invalid protocol buffer definitions. In particular, if
you have a `foo.proto` that doesn't fully qualify the type of a protocol message
it references (e.g. `message<Bar>` where it should be `message<blah.Bar>`), you
will now get run-time errors like:

```
... descriptor.cc:...] Invalid proto descriptor for file "path/to/foo.proto":
... descriptor.cc:...]  blah.MyMessage.my_field: ".Bar" is not defined.
```

If you see this, your `.proto` file is broken and needs to be fixed by making
the types fully qualified. The new definition of `ProtocolMessageEquals` and
`ProtocolMessageEquiv` just happen to reveal your bug.

## My death test modifies some state, but the change seems lost after the death test finishes. Why?

Death tests (`EXPECT_DEATH`, etc) are executed in a sub-process s.t. the
expected crash won't kill the test program (i.e. the parent process). As a
result, any in-memory side effects they incur are observable in their respective
sub-processes, but not in the parent process. You can think of them as running
in a parallel universe, more or less.

In particular, if you use mocking and the death test statement invokes some mock
methods, the parent process will think the calls have never occurred. Therefore,
you may want to move your `EXPECT_CALL` statements inside the `EXPECT_DEATH`
macro.

## EXPECT_EQ(htonl(blah), blah_blah) generates weird compiler errors in opt mode. Is this a googletest bug?

Actually, the bug is in `htonl()`.

According to `'man htonl'`, `htonl()` is a *function*, which means it's valid to
use `htonl` as a function pointer. However, in opt mode `htonl()` is defined as
a *macro*, which breaks this usage.

Worse, the macro definition of `htonl()` uses a `gcc` extension and is *not*
standard C++. That hacky implementation has some ad hoc limitations. In
particular, it prevents you from writing `Foo<sizeof(htonl(x))>()`, where `Foo`
is a template that has an integral argument.

The implementation of `EXPECT_EQ(a, b)` uses `sizeof(... a ...)` inside a
template argument, and thus doesn't compile in opt mode when `a` contains a call
to `htonl()`. It is difficult to make `EXPECT_EQ` bypass the `htonl()` bug, as
the solution must work with different compilers on various platforms.

## The compiler complains about "undefined references" to some static const member variables, but I did define them in the class body. What's wrong?

If your class has a static data member:

```c++
// foo.h
class Foo {
  ...
  static const int kBar = 100;
};
```

You also need to define it *outside* of the class body in `foo.cc`:

```c++
const int Foo::kBar;  // No initializer here.
```

Otherwise your code is **invalid C++**, and may break in unexpected ways. In
particular, using it in googletest comparison assertions (`EXPECT_EQ`, etc) will
generate an "undefined reference" linker error. The fact that "it used to work"
doesn't mean it's valid. It just means that you were lucky. :-)

If the declaration of the static data member is `constexpr` then it is
implicitly an `inline` definition, and a separate definition in `foo.cc` is not
needed:

```c++
// foo.h
class Foo {
  ...
  static constexpr int kBar = 100;  // Defines kBar, no need to do it in foo.cc.
};
```

## Can I derive a test fixture from another?

Yes.

Each test fixture has a corresponding and same named test suite. This means only
one test suite can use a particular fixture. Sometimes, however, multiple test
cases may want to use the same or slightly different fixtures. For example, you
may want to make sure that all of a GUI library's test suites don't leak
important system resources like fonts and brushes.

In googletest, you share a fixture among test suites by putting the shared logic
in a base test fixture, then deriving from that base a separate fixture for each
test suite that wants to use this common logic. You then use `TEST_F()` to write
tests using each derived fixture.

Typically, your code looks like this:

```c++
// Defines a base test fixture.
class BaseTest : public ::testing::Test {
 protected:
  ...
};

// Derives a fixture FooTest from BaseTest.
class FooTest : public BaseTest {
 protected:
  void SetUp() override {
    BaseTest::SetUp();  // Sets up the base fixture first.
    ... additional set-up work ...
  }

  void TearDown() override {
    ... clean-up work for FooTest ...
    BaseTest::TearDown();  // Remember to tear down the base fixture
                           // after cleaning up FooTest!
  }

  ... functions and variables for FooTest ...
};

// Tests that use the fixture FooTest.
TEST_F(FooTest, Bar) { ... }
TEST_F(FooTest, Baz) { ... }

... additional fixtures derived from BaseTest ...
```

If necessary, you can continue to derive test fixtures from a derived fixture.
googletest has no limit on how deep the hierarchy can be.

For a complete example using derived test fixtures, see
[sample5_unittest.cc](https://github.com/google/googletest/blob/master/googletest/samples/sample5_unittest.cc).

## My compiler complains "void value not ignored as it ought to be." What does this mean?

You're probably using an `ASSERT_*()` in a function that doesn't return `void`.
`ASSERT_*()` can only be used in `void` functions, due to exceptions being
disabled by our build system. Please see more details
[here](advanced.md#assertion-placement).

## My death test hangs (or seg-faults). How do I fix it?

In googletest, death tests are run in a child process and the way they work is
delicate. To write death tests you really need to understand how they work—see
the details at [Death Assertions](reference/assertions.md#death) in the
Assertions Reference.

In particular, death tests don't like having multiple threads in the parent
process. So the first thing you can try is to eliminate creating threads outside
of `EXPECT_DEATH()`. For example, you may want to use mocks or fake objects
instead of real ones in your tests.

Sometimes this is impossible as some library you must use may be creating
threads before `main()` is even reached. In this case, you can try to minimize
the chance of conflicts by either moving as many activities as possible inside
`EXPECT_DEATH()` (in the extreme case, you want to move everything inside), or
leaving as few things as possible in it. Also, you can try to set the death test
style to `"threadsafe"`, which is safer but slower, and see if it helps.

If you go with thread-safe death tests, remember that they rerun the test
program from the beginning in the child process. Therefore make sure your
program can run side-by-side with itself and is deterministic.

In the end, this boils down to good concurrent programming. You have to make
sure that there are no race conditions or deadlocks in your program. No silver
bullet - sorry!

## Should I use the constructor/destructor of the test fixture or SetUp()/TearDown()? {#CtorVsSetUp}

The first thing to remember is that googletest does **not** reuse the same test
fixture object across multiple tests. For each `TEST_F`, googletest will create
a **fresh** test fixture object, immediately call `SetUp()`, run the test body,
call `TearDown()`, and then delete the test fixture object.

When you need to write per-test set-up and tear-down logic, you have the choice
between using the test fixture constructor/destructor or `SetUp()/TearDown()`.
The former is usually preferred, as it has the following benefits:

*   By initializing a member variable in the constructor, we have the option to
    make it `const`, which helps prevent accidental changes to its value and
    makes the tests more obviously correct.
*   In case we need to subclass the test fixture class, the subclass'
    constructor is guaranteed to call the base class' constructor *first*, and
    the subclass' destructor is guaranteed to call the base class' destructor
    *afterward*. With `SetUp()/TearDown()`, a subclass may make the mistake of
    forgetting to call the base class' `SetUp()/TearDown()` or call them at the
    wrong time.

You may still want to use `SetUp()/TearDown()` in the following cases:

*   C++ does not allow virtual function calls in constructors and destructors.
    You can call a method declared as virtual, but it will not use dynamic
    dispatch, it will use the definition from the class the constructor of which
    is currently executing. This is because calling a virtual method before the
    derived class constructor has a chance to run is very dangerous - the
    virtual method might operate on uninitialized data. Therefore, if you need
    to call a method that will be overridden in a derived class, you have to use
    `SetUp()/TearDown()`.
*   In the body of a constructor (or destructor), it's not possible to use the
    `ASSERT_xx` macros. Therefore, if the set-up operation could cause a fatal
    test failure that should prevent the test from running, it's necessary to
    use `abort` and abort the whole test
    executable, or to use `SetUp()` instead of a constructor.
*   If the tear-down operation could throw an exception, you must use
    `TearDown()` as opposed to the destructor, as throwing in a destructor leads
    to undefined behavior and usually will kill your program right away. Note
    that many standard libraries (like STL) may throw when exceptions are
    enabled in the compiler. Therefore you should prefer `TearDown()` if you
    want to write portable tests that work with or without exceptions.
*   The googletest team is considering making the assertion macros throw on
    platforms where exceptions are enabled (e.g. Windows, Mac OS, and Linux
    client-side), which will eliminate the need for the user to propagate
    failures from a subroutine to its caller. Therefore, you shouldn't use
    googletest assertions in a destructor if your code could run on such a
    platform.

## The compiler complains "no matching function to call" when I use ASSERT_PRED*. How do I fix it?

See details for [`EXPECT_PRED*`](reference/assertions.md#EXPECT_PRED) in the
Assertions Reference.

## My compiler complains about "ignoring return value" when I call RUN_ALL_TESTS(). Why?

Some people had been ignoring the return value of `RUN_ALL_TESTS()`. That is,
instead of

```c++
  return RUN_ALL_TESTS();
```

they write

```c++
  RUN_ALL_TESTS();
```

This is **wrong and dangerous**. The testing services needs to see the return
value of `RUN_ALL_TESTS()` in order to determine if a test has passed. If your
`main()` function ignores it, your test will be considered successful even if it
has a googletest assertion failure. Very bad.

We have decided to fix this (thanks to Michael Chastain for the idea). Now, your
code will no longer be able to ignore `RUN_ALL_TESTS()` when compiled with
`gcc`. If you do so, you'll get a compiler error.

If you see the compiler complaining about you ignoring the return value of
`RUN_ALL_TESTS()`, the fix is simple: just make sure its value is used as the
return value of `main()`.

But how could we introduce a change that breaks existing tests? Well, in this
case, the code was already broken in the first place, so we didn't break it. :-)

## My compiler complains that a constructor (or destructor) cannot return a value. What's going on?

Due to a peculiarity of C++, in order to support the syntax for streaming
messages to an `ASSERT_*`, e.g.

```c++
  ASSERT_EQ(1, Foo()) << "blah blah" << foo;
```

we had to give up using `ASSERT*` and `FAIL*` (but not `EXPECT*` and
`ADD_FAILURE*`) in constructors and destructors. The workaround is to move the
content of your constructor/destructor to a private void member function, or
switch to `EXPECT_*()` if that works. This
[section](advanced.md#assertion-placement) in the user's guide explains it.

## My SetUp() function is not called. Why?

C++ is case-sensitive. Did you spell it as `Setup()`?

Similarly, sometimes people spell `SetUpTestSuite()` as `SetupTestSuite()` and
wonder why it's never called.


## I have several test suites which share the same test fixture logic, do I have to define a new test fixture class for each of them? This seems pretty tedious.

You don't have to. Instead of

```c++
class FooTest : public BaseTest {};

TEST_F(FooTest, Abc) { ... }
TEST_F(FooTest, Def) { ... }

class BarTest : public BaseTest {};

TEST_F(BarTest, Abc) { ... }
TEST_F(BarTest, Def) { ... }
```

you can simply `typedef` the test fixtures:

```c++
typedef BaseTest FooTest;

TEST_F(FooTest, Abc) { ... }
TEST_F(FooTest, Def) { ... }

typedef BaseTest BarTest;

TEST_F(BarTest, Abc) { ... }
TEST_F(BarTest, Def) { ... }
```

## googletest output is buried in a whole bunch of LOG messages. What do I do?

The googletest output is meant to be a concise and human-friendly report. If
your test generates textual output itself, it will mix with the googletest
output, making it hard to read. However, there is an easy solution to this
problem.

Since `LOG` messages go to stderr, we decided to let googletest output go to
stdout. This way, you can easily separate the two using redirection. For
example:

```shell
$ ./my_test > gtest_output.txt
```

## Why should I prefer test fixtures over global variables?

There are several good reasons:

1.  It's likely your test needs to change the states of its global variables.
    This makes it difficult to keep side effects from escaping one test and
    contaminating others, making debugging difficult. By using fixtures, each
    test has a fresh set of variables that's different (but with the same
    names). Thus, tests are kept independent of each other.
2.  Global variables pollute the global namespace.
3.  Test fixtures can be reused via subclassing, which cannot be done easily
    with global variables. This is useful if many test suites have something in
    common.

## What can the statement argument in ASSERT_DEATH() be?

`ASSERT_DEATH(statement, matcher)` (or any death assertion macro) can be used
wherever *`statement`* is valid. So basically *`statement`* can be any C++
statement that makes sense in the current context. In particular, it can
reference global and/or local variables, and can be:

*   a simple function call (often the case),
*   a complex expression, or
*   a compound statement.

Some examples are shown here:

```c++
// A death test can be a simple function call.
TEST(MyDeathTest, FunctionCall) {
  ASSERT_DEATH(Xyz(5), "Xyz failed");
}

// Or a complex expression that references variables and functions.
TEST(MyDeathTest, ComplexExpression) {
  const bool c = Condition();
  ASSERT_DEATH((c ? Func1(0) : object2.Method("test")),
               "(Func1|Method) failed");
}

// Death assertions can be used anywhere in a function.  In
// particular, they can be inside a loop.
TEST(MyDeathTest, InsideLoop) {
  // Verifies that Foo(0), Foo(1), ..., and Foo(4) all die.
  for (int i = 0; i < 5; i++) {
    EXPECT_DEATH_M(Foo(i), "Foo has \\d+ errors",
                   ::testing::Message() << "where i is " << i);
  }
}

// A death assertion can contain a compound statement.
TEST(MyDeathTest, CompoundStatement) {
  // Verifies that at lease one of Bar(0), Bar(1), ..., and
  // Bar(4) dies.
  ASSERT_DEATH({
    for (int i = 0; i < 5; i++) {
      Bar(i);
    }
  },
  "Bar has \\d+ errors");
}
```

## I have a fixture class `FooTest`, but `TEST_F(FooTest, Bar)` gives me error ``"no matching function for call to `FooTest::FooTest()'"``. Why?

Googletest needs to be able to create objects of your test fixture class, so it
must have a default constructor. Normally the compiler will define one for you.
However, there are cases where you have to define your own:

*   If you explicitly declare a non-default constructor for class `FooTest`
    (`DISALLOW_EVIL_CONSTRUCTORS()` does this), then you need to define a
    default constructor, even if it would be empty.
*   If `FooTest` has a const non-static data member, then you have to define the
    default constructor *and* initialize the const member in the initializer
    list of the constructor. (Early versions of `gcc` doesn't force you to
    initialize the const member. It's a bug that has been fixed in `gcc 4`.)

## Why does ASSERT_DEATH complain about previous threads that were already joined?

With the Linux pthread library, there is no turning back once you cross the line
from a single thread to multiple threads. The first time you create a thread, a
manager thread is created in addition, so you get 3, not 2, threads. Later when
the thread you create joins the main thread, the thread count decrements by 1,
but the manager thread will never be killed, so you still have 2 threads, which
means you cannot safely run a death test.

The new NPTL thread library doesn't suffer from this problem, as it doesn't
create a manager thread. However, if you don't control which machine your test
runs on, you shouldn't depend on this.

## Why does googletest require the entire test suite, instead of individual tests, to be named *DeathTest when it uses ASSERT_DEATH?

googletest does not interleave tests from different test suites. That is, it
runs all tests in one test suite first, and then runs all tests in the next test
suite, and so on. googletest does this because it needs to set up a test suite
before the first test in it is run, and tear it down afterwards. Splitting up
the test case would require multiple set-up and tear-down processes, which is
inefficient and makes the semantics unclean.

If we were to determine the order of tests based on test name instead of test
case name, then we would have a problem with the following situation:

```c++
TEST_F(FooTest, AbcDeathTest) { ... }
TEST_F(FooTest, Uvw) { ... }

TEST_F(BarTest, DefDeathTest) { ... }
TEST_F(BarTest, Xyz) { ... }
```

Since `FooTest.AbcDeathTest` needs to run before `BarTest.Xyz`, and we don't
interleave tests from different test suites, we need to run all tests in the
`FooTest` case before running any test in the `BarTest` case. This contradicts
with the requirement to run `BarTest.DefDeathTest` before `FooTest.Uvw`.

## But I don't like calling my entire test suite \*DeathTest when it contains both death tests and non-death tests. What do I do?

You don't have to, but if you like, you may split up the test suite into
`FooTest` and `FooDeathTest`, where the names make it clear that they are
related:

```c++
class FooTest : public ::testing::Test { ... };

TEST_F(FooTest, Abc) { ... }
TEST_F(FooTest, Def) { ... }

using FooDeathTest = FooTest;

TEST_F(FooDeathTest, Uvw) { ... EXPECT_DEATH(...) ... }
TEST_F(FooDeathTest, Xyz) { ... ASSERT_DEATH(...) ... }
```

## googletest prints the LOG messages in a death test's child process only when the test fails. How can I see the LOG messages when the death test succeeds?

Printing the LOG messages generated by the statement inside `EXPECT_DEATH()`
makes it harder to search for real problems in the parent's log. Therefore,
googletest only prints them when the death test has failed.

If you really need to see such LOG messages, a workaround is to temporarily
break the death test (e.g. by changing the regex pattern it is expected to
match). Admittedly, this is a hack. We'll consider a more permanent solution
after the fork-and-exec-style death tests are implemented.

## The compiler complains about `no match for 'operator<<'` when I use an assertion. What gives?

If you use a user-defined type `FooType` in an assertion, you must make sure
there is an `std::ostream& operator<<(std::ostream&, const FooType&)` function
defined such that we can print a value of `FooType`.

In addition, if `FooType` is declared in a name space, the `<<` operator also
needs to be defined in the *same* name space. See
[Tip of the Week #49](http://abseil.io/tips/49) for details.

## How do I suppress the memory leak messages on Windows?

Since the statically initialized googletest singleton requires allocations on
the heap, the Visual C++ memory leak detector will report memory leaks at the
end of the program run. The easiest way to avoid this is to use the
`_CrtMemCheckpoint` and `_CrtMemDumpAllObjectsSince` calls to not report any
statically initialized heap objects. See MSDN for more details and additional
heap check/debug routines.

## How can my code detect if it is running in a test?

If you write code that sniffs whether it's running in a test and does different
things accordingly, you are leaking test-only logic into production code and
there is no easy way to ensure that the test-only code paths aren't run by
mistake in production. Such cleverness also leads to
[Heisenbugs](https://en.wikipedia.org/wiki/Heisenbug). Therefore we strongly
advise against the practice, and googletest doesn't provide a way to do it.

In general, the recommended way to cause the code to behave differently under
test is [Dependency Injection](http://en.wikipedia.org/wiki/Dependency_injection). You can inject
different functionality from the test and from the production code. Since your
production code doesn't link in the for-test logic at all (the
[`testonly`](http://docs.bazel.build/versions/master/be/common-definitions.html#common.testonly) attribute for BUILD targets helps to ensure
that), there is no danger in accidentally running it.

However, if you *really*, *really*, *really* have no choice, and if you follow
the rule of ending your test program names with `_test`, you can use the
*horrible* hack of sniffing your executable name (`argv[0]` in `main()`) to know
whether the code is under test.

## How do I temporarily disable a test?

If you have a broken test that you cannot fix right away, you can add the
`DISABLED_` prefix to its name. This will exclude it from execution. This is
better than commenting out the code or using `#if 0`, as disabled tests are
still compiled (and thus won't rot).

To include disabled tests in test execution, just invoke the test program with
the `--gtest_also_run_disabled_tests` flag.

## Is it OK if I have two separate `TEST(Foo, Bar)` test methods defined in different namespaces?

Yes.

The rule is **all test methods in the same test suite must use the same fixture
class.** This means that the following is **allowed** because both tests use the
same fixture class (`::testing::Test`).

```c++
namespace foo {
TEST(CoolTest, DoSomething) {
  SUCCEED();
}
}  // namespace foo

namespace bar {
TEST(CoolTest, DoSomething) {
  SUCCEED();
}
}  // namespace bar
```

However, the following code is **not allowed** and will produce a runtime error
from googletest because the test methods are using different test fixture
classes with the same test suite name.

```c++
namespace foo {
class CoolTest : public ::testing::Test {};  // Fixture foo::CoolTest
TEST_F(CoolTest, DoSomething) {
  SUCCEED();
}
}  // namespace foo

namespace bar {
class CoolTest : public ::testing::Test {};  // Fixture: bar::CoolTest
TEST_F(CoolTest, DoSomething) {
  SUCCEED();
}
}  // namespace bar
```
# Quickstart: Building with Bazel

This tutorial aims to get you up and running with GoogleTest using the Bazel
build system. If you're using GoogleTest for the first time or need a refresher,
we recommend this tutorial as a starting point.

## Prerequisites

To complete this tutorial, you'll need:

*   A compatible operating system (e.g. Linux, macOS, Windows).
*   A compatible C++ compiler that supports at least C++11.
*   [Bazel](https://bazel.build/), the preferred build system used by the
    GoogleTest team.

See [Supported Platforms](platforms.md) for more information about platforms
compatible with GoogleTest.

If you don't already have Bazel installed, see the
[Bazel installation guide](https://docs.bazel.build/versions/master/install.html).

{: .callout .note}
Note: The terminal commands in this tutorial show a Unix shell prompt, but the
commands work on the Windows command line as well.

## Set up a Bazel workspace

A
[Bazel workspace](https://docs.bazel.build/versions/master/build-ref.html#workspace)
is a directory on your filesystem that you use to manage source files for the
software you want to build. Each workspace directory has a text file named
`WORKSPACE` which may be empty, or may contain references to external
dependencies required to build the outputs.

First, create a directory for your workspace:

```
$ mkdir my_workspace && cd my_workspace
```

Next, you’ll create the `WORKSPACE` file to specify dependencies. A common and
recommended way to depend on GoogleTest is to use a
[Bazel external dependency](https://docs.bazel.build/versions/master/external.html)
via the
[`http_archive` rule](https://docs.bazel.build/versions/master/repo/http.html#http_archive).
To do this, in the root directory of your workspace (`my_workspace/`), create a
file named `WORKSPACE` with the following contents:

```
load("@bazel_tools//tools/build_defs/repo:http.bzl", "http_archive")

http_archive(
  name = "com_google_googletest",
  urls = ["https://github.com/google/googletest/archive/609281088cfefc76f9d0ce82e1ff6c30cc3591e5.zip"],
  strip_prefix = "googletest-609281088cfefc76f9d0ce82e1ff6c30cc3591e5",
)
```

The above configuration declares a dependency on GoogleTest which is downloaded
as a ZIP archive from GitHub. In the above example,
`609281088cfefc76f9d0ce82e1ff6c30cc3591e5` is the Git commit hash of the
GoogleTest version to use; we recommend updating the hash often to point to the
latest version.

Bazel also needs a dependency on the
[`rules_cc` repository](https://github.com/bazelbuild/rules_cc) to build C++
code, so add the following to the `WORKSPACE` file:

```
http_archive(
  name = "rules_cc",
  urls = ["https://github.com/bazelbuild/rules_cc/archive/40548a2974f1aea06215272d9c2b47a14a24e556.zip"],
  strip_prefix = "rules_cc-40548a2974f1aea06215272d9c2b47a14a24e556",
)
```

Now you're ready to build C++ code that uses GoogleTest.

## Create and run a binary

With your Bazel workspace set up, you can now use GoogleTest code within your
own project.

As an example, create a file named `hello_test.cc` in your `my_workspace`
directory with the following contents:

```cpp
#include <gtest/gtest.h>

// Demonstrate some basic assertions.
TEST(HelloTest, BasicAssertions) {
  // Expect two strings not to be equal.
  EXPECT_STRNE("hello", "world");
  // Expect equality.
  EXPECT_EQ(7 * 6, 42);
}
```

GoogleTest provides [assertions](primer.md#assertions) that you use to test the
behavior of your code. The above sample includes the main GoogleTest header file
and demonstrates some basic assertions.

To build the code, create a file named `BUILD` in the same directory with the
following contents:

```
load("@rules_cc//cc:defs.bzl", "cc_test")

cc_test(
  name = "hello_test",
  size = "small",
  srcs = ["hello_test.cc"],
  deps = ["@com_google_googletest//:gtest_main"],
)
```

This `cc_test` rule declares the C++ test binary you want to build, and links to
GoogleTest (`//:gtest_main`) using the prefix you specified in the `WORKSPACE`
file (`@com_google_googletest`). For more information about Bazel `BUILD` files,
see the
[Bazel C++ Tutorial](https://docs.bazel.build/versions/master/tutorial/cpp.html).

Now you can build and run your test:

<pre>
<strong>my_workspace$ bazel test --test_output=all //:hello_test</strong>
INFO: Analyzed target //:hello_test (26 packages loaded, 362 targets configured).
INFO: Found 1 test target...
INFO: From Testing //:hello_test:
==================== Test output for //:hello_test:
Running main() from gmock_main.cc
[==========] Running 1 test from 1 test suite.
[----------] Global test environment set-up.
[----------] 1 test from HelloTest
[ RUN      ] HelloTest.BasicAssertions
[       OK ] HelloTest.BasicAssertions (0 ms)
[----------] 1 test from HelloTest (0 ms total)

[----------] Global test environment tear-down
[==========] 1 test from 1 test suite ran. (0 ms total)
[  PASSED  ] 1 test.
================================================================================
Target //:hello_test up-to-date:
  bazel-bin/hello_test
INFO: Elapsed time: 4.190s, Critical Path: 3.05s
INFO: 27 processes: 8 internal, 19 linux-sandbox.
INFO: Build completed successfully, 27 total actions
//:hello_test                                                     PASSED in 0.1s

INFO: Build completed successfully, 27 total actions
</pre>

Congratulations! You've successfully built and run a test binary using
GoogleTest.

## Next steps

*   [Check out the Primer](primer.md) to start learning how to write simple
    tests.
*   [See the code samples](samples.md) for more examples showing how to use a
    variety of GoogleTest features.
# gMock Cheat Sheet

## Defining a Mock Class

### Mocking a Normal Class {#MockClass}

Given

```cpp
class Foo {
  ...
  virtual ~Foo();
  virtual int GetSize() const = 0;
  virtual string Describe(const char* name) = 0;
  virtual string Describe(int type) = 0;
  virtual bool Process(Bar elem, int count) = 0;
};
```

(note that `~Foo()` **must** be virtual) we can define its mock as

```cpp
#include "gmock/gmock.h"

class MockFoo : public Foo {
  ...
  MOCK_METHOD(int, GetSize, (), (const, override));
  MOCK_METHOD(string, Describe, (const char* name), (override));
  MOCK_METHOD(string, Describe, (int type), (override));
  MOCK_METHOD(bool, Process, (Bar elem, int count), (override));
};
```

To create a "nice" mock, which ignores all uninteresting calls, a "naggy" mock,
which warns on all uninteresting calls, or a "strict" mock, which treats them as
failures:

```cpp
using ::testing::NiceMock;
using ::testing::NaggyMock;
using ::testing::StrictMock;

NiceMock<MockFoo> nice_foo;      // The type is a subclass of MockFoo.
NaggyMock<MockFoo> naggy_foo;    // The type is a subclass of MockFoo.
StrictMock<MockFoo> strict_foo;  // The type is a subclass of MockFoo.
```

{: .callout .note}
**Note:** A mock object is currently naggy by default. We may make it nice by
default in the future.

### Mocking a Class Template {#MockTemplate}

Class templates can be mocked just like any class.

To mock

```cpp
template <typename Elem>
class StackInterface {
  ...
  virtual ~StackInterface();
  virtual int GetSize() const = 0;
  virtual void Push(const Elem& x) = 0;
};
```

(note that all member functions that are mocked, including `~StackInterface()`
**must** be virtual).

```cpp
template <typename Elem>
class MockStack : public StackInterface<Elem> {
  ...
  MOCK_METHOD(int, GetSize, (), (const, override));
  MOCK_METHOD(void, Push, (const Elem& x), (override));
};
```

### Specifying Calling Conventions for Mock Functions

If your mock function doesn't use the default calling convention, you can
specify it by adding `Calltype(convention)` to `MOCK_METHOD`'s 4th parameter.
For example,

```cpp
  MOCK_METHOD(bool, Foo, (int n), (Calltype(STDMETHODCALLTYPE)));
  MOCK_METHOD(int, Bar, (double x, double y),
              (const, Calltype(STDMETHODCALLTYPE)));
```

where `STDMETHODCALLTYPE` is defined by `<objbase.h>` on Windows.

## Using Mocks in Tests {#UsingMocks}

The typical work flow is:

1.  Import the gMock names you need to use. All gMock symbols are in the
    `testing` namespace unless they are macros or otherwise noted.
2.  Create the mock objects.
3.  Optionally, set the default actions of the mock objects.
4.  Set your expectations on the mock objects (How will they be called? What
    will they do?).
5.  Exercise code that uses the mock objects; if necessary, check the result
    using googletest assertions.
6.  When a mock object is destructed, gMock automatically verifies that all
    expectations on it have been satisfied.

Here's an example:

```cpp
using ::testing::Return;                          // #1

TEST(BarTest, DoesThis) {
  MockFoo foo;                                    // #2

  ON_CALL(foo, GetSize())                         // #3
      .WillByDefault(Return(1));
  // ... other default actions ...

  EXPECT_CALL(foo, Describe(5))                   // #4
      .Times(3)
      .WillRepeatedly(Return("Category 5"));
  // ... other expectations ...

  EXPECT_EQ(MyProductionFunction(&foo), "good");  // #5
}                                                 // #6
```

## Setting Default Actions {#OnCall}

gMock has a **built-in default action** for any function that returns `void`,
`bool`, a numeric value, or a pointer. In C++11, it will additionally returns
the default-constructed value, if one exists for the given type.

To customize the default action for functions with return type `T`, use
[`DefaultValue<T>`](reference/mocking.md#DefaultValue). For example:

```cpp
  // Sets the default action for return type std::unique_ptr<Buzz> to
  // creating a new Buzz every time.
  DefaultValue<std::unique_ptr<Buzz>>::SetFactory(
      [] { return MakeUnique<Buzz>(AccessLevel::kInternal); });

  // When this fires, the default action of MakeBuzz() will run, which
  // will return a new Buzz object.
  EXPECT_CALL(mock_buzzer_, MakeBuzz("hello")).Times(AnyNumber());

  auto buzz1 = mock_buzzer_.MakeBuzz("hello");
  auto buzz2 = mock_buzzer_.MakeBuzz("hello");
  EXPECT_NE(buzz1, nullptr);
  EXPECT_NE(buzz2, nullptr);
  EXPECT_NE(buzz1, buzz2);

  // Resets the default action for return type std::unique_ptr<Buzz>,
  // to avoid interfere with other tests.
  DefaultValue<std::unique_ptr<Buzz>>::Clear();
```

To customize the default action for a particular method of a specific mock
object, use [`ON_CALL`](reference/mocking.md#ON_CALL). `ON_CALL` has a similar
syntax to `EXPECT_CALL`, but it is used for setting default behaviors when you
do not require that the mock method is called. See
[Knowing When to Expect](gmock_cook_book.md#UseOnCall) for a more detailed
discussion.

## Setting Expectations {#ExpectCall}

See [`EXPECT_CALL`](reference/mocking.md#EXPECT_CALL) in the Mocking Reference.

## Matchers {#MatcherList}

See the [Matchers Reference](reference/matchers.md).

## Actions {#ActionList}

See the [Actions Reference](reference/actions.md).

## Cardinalities {#CardinalityList}

See the [`Times` clause](reference/mocking.md#EXPECT_CALL.Times) of
`EXPECT_CALL` in the Mocking Reference.

## Expectation Order

By default, expectations can be matched in *any* order. If some or all
expectations must be matched in a given order, you can use the
[`After` clause](reference/mocking.md#EXPECT_CALL.After) or
[`InSequence` clause](reference/mocking.md#EXPECT_CALL.InSequence) of
`EXPECT_CALL`, or use an [`InSequence` object](reference/mocking.md#InSequence).

## Verifying and Resetting a Mock

gMock will verify the expectations on a mock object when it is destructed, or
you can do it earlier:

```cpp
using ::testing::Mock;
...
// Verifies and removes the expectations on mock_obj;
// returns true if and only if successful.
Mock::VerifyAndClearExpectations(&mock_obj);
...
// Verifies and removes the expectations on mock_obj;
// also removes the default actions set by ON_CALL();
// returns true if and only if successful.
Mock::VerifyAndClear(&mock_obj);
```

Do not set new expectations after verifying and clearing a mock after its use.
Setting expectations after code that exercises the mock has undefined behavior.
See [Using Mocks in Tests](gmock_for_dummies.md#using-mocks-in-tests) for more
information.

You can also tell gMock that a mock object can be leaked and doesn't need to be
verified:

```cpp
Mock::AllowLeak(&mock_obj);
```

## Mock Classes

gMock defines a convenient mock class template

```cpp
class MockFunction<R(A1, ..., An)> {
 public:
  MOCK_METHOD(R, Call, (A1, ..., An));
};
```

See this [recipe](gmock_cook_book.md#UsingCheckPoints) for one application of
it.

## Flags

| Flag                           | Description                               |
| :----------------------------- | :---------------------------------------- |
| `--gmock_catch_leaked_mocks=0` | Don't report leaked mock objects as failures. |
| `--gmock_verbose=LEVEL` | Sets the default verbosity level (`info`, `warning`, or `error`) of Google Mock messages. |
# Testing Reference

<!--* toc_depth: 3 *-->

This page lists the facilities provided by GoogleTest for writing test programs.
To use them, include the header `gtest/gtest.h`.

## Macros

GoogleTest defines the following macros for writing tests.

### TEST {#TEST}

<pre>
TEST(<em>TestSuiteName</em>, <em>TestName</em>) {
  ... <em>statements</em> ...
}
</pre>

Defines an individual test named *`TestName`* in the test suite
*`TestSuiteName`*, consisting of the given statements.

Both arguments *`TestSuiteName`* and *`TestName`* must be valid C++ identifiers
and must not contain underscores (`_`). Tests in different test suites can have
the same individual name.

The statements within the test body can be any code under test.
[Assertions](assertions.md) used within the test body determine the outcome of
the test.

### TEST_F {#TEST_F}

<pre>
TEST_F(<em>TestFixtureName</em>, <em>TestName</em>) {
  ... <em>statements</em> ...
}
</pre>

Defines an individual test named *`TestName`* that uses the test fixture class
*`TestFixtureName`*. The test suite name is *`TestFixtureName`*.

Both arguments *`TestFixtureName`* and *`TestName`* must be valid C++
identifiers and must not contain underscores (`_`). *`TestFixtureName`* must be
the name of a test fixture class—see
[Test Fixtures](../primer.md#same-data-multiple-tests).

The statements within the test body can be any code under test.
[Assertions](assertions.md) used within the test body determine the outcome of
the test.

### TEST_P {#TEST_P}

<pre>
TEST_P(<em>TestFixtureName</em>, <em>TestName</em>) {
  ... <em>statements</em> ...
}
</pre>

Defines an individual value-parameterized test named *`TestName`* that uses the
test fixture class *`TestFixtureName`*. The test suite name is
*`TestFixtureName`*.

Both arguments *`TestFixtureName`* and *`TestName`* must be valid C++
identifiers and must not contain underscores (`_`). *`TestFixtureName`* must be
the name of a value-parameterized test fixture class—see
[Value-Parameterized Tests](../advanced.md#value-parameterized-tests).

The statements within the test body can be any code under test. Within the test
body, the test parameter can be accessed with the `GetParam()` function (see
[`WithParamInterface`](#WithParamInterface)). For example:

```cpp
TEST_P(MyTestSuite, DoesSomething) {
  ...
  EXPECT_TRUE(DoSomething(GetParam()));
  ...
}
```

[Assertions](assertions.md) used within the test body determine the outcome of
the test.

See also [`INSTANTIATE_TEST_SUITE_P`](#INSTANTIATE_TEST_SUITE_P).

### INSTANTIATE_TEST_SUITE_P {#INSTANTIATE_TEST_SUITE_P}

`INSTANTIATE_TEST_SUITE_P(`*`InstantiationName`*`,`*`TestSuiteName`*`,`*`param_generator`*`)`
\
`INSTANTIATE_TEST_SUITE_P(`*`InstantiationName`*`,`*`TestSuiteName`*`,`*`param_generator`*`,`*`name_generator`*`)`

Instantiates the value-parameterized test suite *`TestSuiteName`* (defined with
[`TEST_P`](#TEST_P)).

The argument *`InstantiationName`* is a unique name for the instantiation of the
test suite, to distinguish between multiple instantiations. In test output, the
instantiation name is added as a prefix to the test suite name
*`TestSuiteName`*.

The argument *`param_generator`* is one of the following GoogleTest-provided
functions that generate the test parameters, all defined in the `::testing`
namespace:

<span id="param-generators"></span>

| Parameter Generator | Behavior                                             |
| ------------------- | ---------------------------------------------------- |
| `Range(begin, end [, step])` | Yields values `{begin, begin+step, begin+step+step, ...}`. The values do not include `end`. `step` defaults to 1. |
| `Values(v1, v2, ..., vN)`    | Yields values `{v1, v2, ..., vN}`.          |
| `ValuesIn(container)` or `ValuesIn(begin,end)` | Yields values from a C-style array, an STL-style container, or an iterator range `[begin, end)`. |
| `Bool()`                     | Yields sequence `{false, true}`.            |
| `Combine(g1, g2, ..., gN)`   | Yields as `std::tuple` *n*-tuples all combinations (Cartesian product) of the values generated by the given *n* generators `g1`, `g2`, ..., `gN`. |

The optional last argument *`name_generator`* is a function or functor that
generates custom test name suffixes based on the test parameters. The function
must accept an argument of type
[`TestParamInfo<class ParamType>`](#TestParamInfo) and return a `std::string`.
The test name suffix can only contain alphanumeric characters and underscores.
GoogleTest provides [`PrintToStringParamName`](#PrintToStringParamName), or a
custom function can be used for more control:

```cpp
INSTANTIATE_TEST_SUITE_P(
    MyInstantiation, MyTestSuite,
    ::testing::Values(...),
    [](const ::testing::TestParamInfo<MyTestSuite::ParamType>& info) {
      // Can use info.param here to generate the test suffix
      std::string name = ...
      return name;
    });
```

For more information, see
[Value-Parameterized Tests](../advanced.md#value-parameterized-tests).

See also
[`GTEST_ALLOW_UNINSTANTIATED_PARAMETERIZED_TEST`](#GTEST_ALLOW_UNINSTANTIATED_PARAMETERIZED_TEST).

### TYPED_TEST_SUITE {#TYPED_TEST_SUITE}

`TYPED_TEST_SUITE(`*`TestFixtureName`*`,`*`Types`*`)`

Defines a typed test suite based on the test fixture *`TestFixtureName`*. The
test suite name is *`TestFixtureName`*.

The argument *`TestFixtureName`* is a fixture class template, parameterized by a
type, for example:

```cpp
template <typename T>
class MyFixture : public ::testing::Test {
 public:
  ...
  using List = std::list<T>;
  static T shared_;
  T value_;
};
```

The argument *`Types`* is a [`Types`](#Types) object representing the list of
types to run the tests on, for example:

```cpp
using MyTypes = ::testing::Types<char, int, unsigned int>;
TYPED_TEST_SUITE(MyFixture, MyTypes);
```

The type alias (`using` or `typedef`) is necessary for the `TYPED_TEST_SUITE`
macro to parse correctly.

See also [`TYPED_TEST`](#TYPED_TEST) and
[Typed Tests](../advanced.md#typed-tests) for more information.

### TYPED_TEST {#TYPED_TEST}

<pre>
TYPED_TEST(<em>TestSuiteName</em>, <em>TestName</em>) {
  ... <em>statements</em> ...
}
</pre>

Defines an individual typed test named *`TestName`* in the typed test suite
*`TestSuiteName`*. The test suite must be defined with
[`TYPED_TEST_SUITE`](#TYPED_TEST_SUITE).

Within the test body, the special name `TypeParam` refers to the type parameter,
and `TestFixture` refers to the fixture class. See the following example:

```cpp
TYPED_TEST(MyFixture, Example) {
  // Inside a test, refer to the special name TypeParam to get the type
  // parameter.  Since we are inside a derived class template, C++ requires
  // us to visit the members of MyFixture via 'this'.
  TypeParam n = this->value_;

  // To visit static members of the fixture, add the 'TestFixture::'
  // prefix.
  n += TestFixture::shared_;

  // To refer to typedefs in the fixture, add the 'typename TestFixture::'
  // prefix. The 'typename' is required to satisfy the compiler.
  typename TestFixture::List values;

  values.push_back(n);
  ...
}
```

For more information, see [Typed Tests](../advanced.md#typed-tests).

### TYPED_TEST_SUITE_P {#TYPED_TEST_SUITE_P}

`TYPED_TEST_SUITE_P(`*`TestFixtureName`*`)`

Defines a type-parameterized test suite based on the test fixture
*`TestFixtureName`*. The test suite name is *`TestFixtureName`*.

The argument *`TestFixtureName`* is a fixture class template, parameterized by a
type. See [`TYPED_TEST_SUITE`](#TYPED_TEST_SUITE) for an example.

See also [`TYPED_TEST_P`](#TYPED_TEST_P) and
[Type-Parameterized Tests](../advanced.md#type-parameterized-tests) for more
information.

### TYPED_TEST_P {#TYPED_TEST_P}

<pre>
TYPED_TEST_P(<em>TestSuiteName</em>, <em>TestName</em>) {
  ... <em>statements</em> ...
}
</pre>

Defines an individual type-parameterized test named *`TestName`* in the
type-parameterized test suite *`TestSuiteName`*. The test suite must be defined
with [`TYPED_TEST_SUITE_P`](#TYPED_TEST_SUITE_P).

Within the test body, the special name `TypeParam` refers to the type parameter,
and `TestFixture` refers to the fixture class. See [`TYPED_TEST`](#TYPED_TEST)
for an example.

See also [`REGISTER_TYPED_TEST_SUITE_P`](#REGISTER_TYPED_TEST_SUITE_P) and
[Type-Parameterized Tests](../advanced.md#type-parameterized-tests) for more
information.

### REGISTER_TYPED_TEST_SUITE_P {#REGISTER_TYPED_TEST_SUITE_P}

`REGISTER_TYPED_TEST_SUITE_P(`*`TestSuiteName`*`,`*`TestNames...`*`)`

Registers the type-parameterized tests *`TestNames...`* of the test suite
*`TestSuiteName`*. The test suite and tests must be defined with
[`TYPED_TEST_SUITE_P`](#TYPED_TEST_SUITE_P) and [`TYPED_TEST_P`](#TYPED_TEST_P).

For example:

```cpp
// Define the test suite and tests.
TYPED_TEST_SUITE_P(MyFixture);
TYPED_TEST_P(MyFixture, HasPropertyA) { ... }
TYPED_TEST_P(MyFixture, HasPropertyB) { ... }

// Register the tests in the test suite.
REGISTER_TYPED_TEST_SUITE_P(MyFixture, HasPropertyA, HasPropertyB);
```

See also [`INSTANTIATE_TYPED_TEST_SUITE_P`](#INSTANTIATE_TYPED_TEST_SUITE_P) and
[Type-Parameterized Tests](../advanced.md#type-parameterized-tests) for more
information.

### INSTANTIATE_TYPED_TEST_SUITE_P {#INSTANTIATE_TYPED_TEST_SUITE_P}

`INSTANTIATE_TYPED_TEST_SUITE_P(`*`InstantiationName`*`,`*`TestSuiteName`*`,`*`Types`*`)`

Instantiates the type-parameterized test suite *`TestSuiteName`*. The test suite
must be registered with
[`REGISTER_TYPED_TEST_SUITE_P`](#REGISTER_TYPED_TEST_SUITE_P).

The argument *`InstantiationName`* is a unique name for the instantiation of the
test suite, to distinguish between multiple instantiations. In test output, the
instantiation name is added as a prefix to the test suite name
*`TestSuiteName`*.

The argument *`Types`* is a [`Types`](#Types) object representing the list of
types to run the tests on, for example:

```cpp
using MyTypes = ::testing::Types<char, int, unsigned int>;
INSTANTIATE_TYPED_TEST_SUITE_P(MyInstantiation, MyFixture, MyTypes);
```

The type alias (`using` or `typedef`) is necessary for the
`INSTANTIATE_TYPED_TEST_SUITE_P` macro to parse correctly.

For more information, see
[Type-Parameterized Tests](../advanced.md#type-parameterized-tests).

### FRIEND_TEST {#FRIEND_TEST}

`FRIEND_TEST(`*`TestSuiteName`*`,`*`TestName`*`)`

Within a class body, declares an individual test as a friend of the class,
enabling the test to access private class members.

If the class is defined in a namespace, then in order to be friends of the
class, test fixtures and tests must be defined in the exact same namespace,
without inline or anonymous namespaces.

For example, if the class definition looks like the following:

```cpp
namespace my_namespace {

class MyClass {
  friend class MyClassTest;
  FRIEND_TEST(MyClassTest, HasPropertyA);
  FRIEND_TEST(MyClassTest, HasPropertyB);
  ... definition of class MyClass ...
};

}  // namespace my_namespace
```

Then the test code should look like:

```cpp
namespace my_namespace {

class MyClassTest : public ::testing::Test {
  ...
};

TEST_F(MyClassTest, HasPropertyA) { ... }
TEST_F(MyClassTest, HasPropertyB) { ... }

}  // namespace my_namespace
```

See [Testing Private Code](../advanced.md#testing-private-code) for more
information.

### SCOPED_TRACE {#SCOPED_TRACE}

`SCOPED_TRACE(`*`message`*`)`

Causes the current file name, line number, and the given message *`message`* to
be added to the failure message for each assertion failure that occurs in the
scope.

For more information, see
[Adding Traces to Assertions](../advanced.md#adding-traces-to-assertions).

See also the [`ScopedTrace` class](#ScopedTrace).

### GTEST_SKIP {#GTEST_SKIP}

`GTEST_SKIP()`

Prevents further test execution at runtime.

Can be used in individual test cases or in the `SetUp()` methods of test
environments or test fixtures (classes derived from the
[`Environment`](#Environment) or [`Test`](#Test) classes). If used in a global
test environment `SetUp()` method, it skips all tests in the test program. If
used in a test fixture `SetUp()` method, it skips all tests in the corresponding
test suite.

Similar to assertions, `GTEST_SKIP` allows streaming a custom message into it.

See [Skipping Test Execution](../advanced.md#skipping-test-execution) for more
information.

### GTEST_ALLOW_UNINSTANTIATED_PARAMETERIZED_TEST {#GTEST_ALLOW_UNINSTANTIATED_PARAMETERIZED_TEST}

`GTEST_ALLOW_UNINSTANTIATED_PARAMETERIZED_TEST(`*`TestSuiteName`*`)`

Allows the value-parameterized test suite *`TestSuiteName`* to be
uninstantiated.

By default, every [`TEST_P`](#TEST_P) call without a corresponding
[`INSTANTIATE_TEST_SUITE_P`](#INSTANTIATE_TEST_SUITE_P) call causes a failing
test in the test suite `GoogleTestVerification`.
`GTEST_ALLOW_UNINSTANTIATED_PARAMETERIZED_TEST` suppresses this failure for the
given test suite.

## Classes and types

GoogleTest defines the following classes and types to help with writing tests.

### AssertionResult {#AssertionResult}

`::testing::AssertionResult`

A class for indicating whether an assertion was successful.

When the assertion wasn't successful, the `AssertionResult` object stores a
non-empty failure message that can be retrieved with the object's `message()`
method.

To create an instance of this class, use one of the factory functions
[`AssertionSuccess()`](#AssertionSuccess) or
[`AssertionFailure()`](#AssertionFailure).

### AssertionException {#AssertionException}

`::testing::AssertionException`

Exception which can be thrown from
[`TestEventListener::OnTestPartResult`](#TestEventListener::OnTestPartResult).

### EmptyTestEventListener {#EmptyTestEventListener}

`::testing::EmptyTestEventListener`

Provides an empty implementation of all methods in the
[`TestEventListener`](#TestEventListener) interface, such that a subclass only
needs to override the methods it cares about.

### Environment {#Environment}

`::testing::Environment`

Represents a global test environment. See
[Global Set-Up and Tear-Down](../advanced.md#global-set-up-and-tear-down).

#### Protected Methods {#Environment-protected}

##### SetUp {#Environment::SetUp}

`virtual void Environment::SetUp()`

Override this to define how to set up the environment.

##### TearDown {#Environment::TearDown}

`virtual void Environment::TearDown()`

Override this to define how to tear down the environment.

### ScopedTrace {#ScopedTrace}

`::testing::ScopedTrace`

An instance of this class causes a trace to be included in every test failure
message generated by code in the scope of the lifetime of the `ScopedTrace`
instance. The effect is undone with the destruction of the instance.

The `ScopedTrace` constructor has the following form:

```cpp
template <typename T>
ScopedTrace(const char* file, int line, const T& message)
```

Example usage:

```cpp
::testing::ScopedTrace trace("file.cc", 123, "message");
```

The resulting trace includes the given source file path and line number, and the
given message. The `message` argument can be anything streamable to
`std::ostream`.

See also [`SCOPED_TRACE`](#SCOPED_TRACE).

### Test {#Test}

`::testing::Test`

The abstract class that all tests inherit from. `Test` is not copyable.

#### Public Methods {#Test-public}

##### SetUpTestSuite {#Test::SetUpTestSuite}

`static void Test::SetUpTestSuite()`

Performs shared setup for all tests in the test suite. GoogleTest calls
`SetUpTestSuite()` before running the first test in the test suite.

##### TearDownTestSuite {#Test::TearDownTestSuite}

`static void Test::TearDownTestSuite()`

Performs shared teardown for all tests in the test suite. GoogleTest calls
`TearDownTestSuite()` after running the last test in the test suite.

##### HasFatalFailure {#Test::HasFatalFailure}

`static bool Test::HasFatalFailure()`

Returns true if and only if the current test has a fatal failure.

##### HasNonfatalFailure {#Test::HasNonfatalFailure}

`static bool Test::HasNonfatalFailure()`

Returns true if and only if the current test has a nonfatal failure.

##### HasFailure {#Test::HasFailure}

`static bool Test::HasFailure()`

Returns true if and only if the current test has any failure, either fatal or
nonfatal.

##### IsSkipped {#Test::IsSkipped}

`static bool Test::IsSkipped()`

Returns true if and only if the current test was skipped.

##### RecordProperty {#Test::RecordProperty}

`static void Test::RecordProperty(const std::string& key, const std::string&
value)` \
`static void Test::RecordProperty(const std::string& key, int value)`

Logs a property for the current test, test suite, or entire invocation of the
test program. Only the last value for a given key is logged.

The key must be a valid XML attribute name, and cannot conflict with the ones
already used by GoogleTest (`name`, `status`, `time`, `classname`, `type_param`,
and `value_param`).

`RecordProperty` is `public static` so it can be called from utility functions
that are not members of the test fixture.

Calls to `RecordProperty` made during the lifespan of the test (from the moment
its constructor starts to the moment its destructor finishes) are output in XML
as attributes of the `<testcase>` element. Properties recorded from a fixture's
`SetUpTestSuite` or `TearDownTestSuite` methods are logged as attributes of the
corresponding `<testsuite>` element. Calls to `RecordProperty` made in the
global context (before or after invocation of `RUN_ALL_TESTS` or from the
`SetUp`/`TearDown` methods of registered `Environment` objects) are output as
attributes of the `<testsuites>` element.

#### Protected Methods {#Test-protected}

##### SetUp {#Test::SetUp}

`virtual void Test::SetUp()`

Override this to perform test fixture setup. GoogleTest calls `SetUp()` before
running each individual test.

##### TearDown {#Test::TearDown}

`virtual void Test::TearDown()`

Override this to perform test fixture teardown. GoogleTest calls `TearDown()`
after running each individual test.

### TestWithParam {#TestWithParam}

`::testing::TestWithParam<T>`

A convenience class which inherits from both [`Test`](#Test) and
[`WithParamInterface<T>`](#WithParamInterface).

### TestSuite {#TestSuite}

Represents a test suite. `TestSuite` is not copyable.

#### Public Methods {#TestSuite-public}

##### name {#TestSuite::name}

`const char* TestSuite::name() const`

Gets the name of the test suite.

##### type_param {#TestSuite::type_param}

`const char* TestSuite::type_param() const`

Returns the name of the parameter type, or `NULL` if this is not a typed or
type-parameterized test suite. See [Typed Tests](../advanced.md#typed-tests) and
[Type-Parameterized Tests](../advanced.md#type-parameterized-tests).

##### should_run {#TestSuite::should_run}

`bool TestSuite::should_run() const`

Returns true if any test in this test suite should run.

##### successful_test_count {#TestSuite::successful_test_count}

`int TestSuite::successful_test_count() const`

Gets the number of successful tests in this test suite.

##### skipped_test_count {#TestSuite::skipped_test_count}

`int TestSuite::skipped_test_count() const`

Gets the number of skipped tests in this test suite.

##### failed_test_count {#TestSuite::failed_test_count}

`int TestSuite::failed_test_count() const`

Gets the number of failed tests in this test suite.

##### reportable_disabled_test_count {#TestSuite::reportable_disabled_test_count}

`int TestSuite::reportable_disabled_test_count() const`

Gets the number of disabled tests that will be reported in the XML report.

##### disabled_test_count {#TestSuite::disabled_test_count}

`int TestSuite::disabled_test_count() const`

Gets the number of disabled tests in this test suite.

##### reportable_test_count {#TestSuite::reportable_test_count}

`int TestSuite::reportable_test_count() const`

Gets the number of tests to be printed in the XML report.

##### test_to_run_count {#TestSuite::test_to_run_count}

`int TestSuite::test_to_run_count() const`

Get the number of tests in this test suite that should run.

##### total_test_count {#TestSuite::total_test_count}

`int TestSuite::total_test_count() const`

Gets the number of all tests in this test suite.

##### Passed {#TestSuite::Passed}

`bool TestSuite::Passed() const`

Returns true if and only if the test suite passed.

##### Failed {#TestSuite::Failed}

`bool TestSuite::Failed() const`

Returns true if and only if the test suite failed.

##### elapsed_time {#TestSuite::elapsed_time}

`TimeInMillis TestSuite::elapsed_time() const`

Returns the elapsed time, in milliseconds.

##### start_timestamp {#TestSuite::start_timestamp}

`TimeInMillis TestSuite::start_timestamp() const`

Gets the time of the test suite start, in ms from the start of the UNIX epoch.

##### GetTestInfo {#TestSuite::GetTestInfo}

`const TestInfo* TestSuite::GetTestInfo(int i) const`

Returns the [`TestInfo`](#TestInfo) for the `i`-th test among all the tests. `i`
can range from 0 to `total_test_count() - 1`. If `i` is not in that range,
returns `NULL`.

##### ad_hoc_test_result {#TestSuite::ad_hoc_test_result}

`const TestResult& TestSuite::ad_hoc_test_result() const`

Returns the [`TestResult`](#TestResult) that holds test properties recorded
during execution of `SetUpTestSuite` and `TearDownTestSuite`.

### TestInfo {#TestInfo}

`::testing::TestInfo`

Stores information about a test.

#### Public Methods {#TestInfo-public}

##### test_suite_name {#TestInfo::test_suite_name}

`const char* TestInfo::test_suite_name() const`

Returns the test suite name.

##### name {#TestInfo::name}

`const char* TestInfo::name() const`

Returns the test name.

##### type_param {#TestInfo::type_param}

`const char* TestInfo::type_param() const`

Returns the name of the parameter type, or `NULL` if this is not a typed or
type-parameterized test. See [Typed Tests](../advanced.md#typed-tests) and
[Type-Parameterized Tests](../advanced.md#type-parameterized-tests).

##### value_param {#TestInfo::value_param}

`const char* TestInfo::value_param() const`

Returns the text representation of the value parameter, or `NULL` if this is not
a value-parameterized test. See
[Value-Parameterized Tests](../advanced.md#value-parameterized-tests).

##### file {#TestInfo::file}

`const char* TestInfo::file() const`

Returns the file name where this test is defined.

##### line {#TestInfo::line}

`int TestInfo::line() const`

Returns the line where this test is defined.

##### is_in_another_shard {#TestInfo::is_in_another_shard}

`bool TestInfo::is_in_another_shard() const`

Returns true if this test should not be run because it's in another shard.

##### should_run {#TestInfo::should_run}

`bool TestInfo::should_run() const`

Returns true if this test should run, that is if the test is not disabled (or it
is disabled but the `also_run_disabled_tests` flag has been specified) and its
full name matches the user-specified filter.

GoogleTest allows the user to filter the tests by their full names. Only the
tests that match the filter will run. See
[Running a Subset of the Tests](../advanced.md#running-a-subset-of-the-tests)
for more information.

##### is_reportable {#TestInfo::is_reportable}

`bool TestInfo::is_reportable() const`

Returns true if and only if this test will appear in the XML report.

##### result {#TestInfo::result}

`const TestResult* TestInfo::result() const`

Returns the result of the test. See [`TestResult`](#TestResult).

### TestParamInfo {#TestParamInfo}

`::testing::TestParamInfo<T>`

Describes a parameter to a value-parameterized test. The type `T` is the type of
the parameter.

Contains the fields `param` and `index` which hold the value of the parameter
and its integer index respectively.

### UnitTest {#UnitTest}

`::testing::UnitTest`

This class contains information about the test program.

`UnitTest` is a singleton class. The only instance is created when
`UnitTest::GetInstance()` is first called. This instance is never deleted.

`UnitTest` is not copyable.

#### Public Methods {#UnitTest-public}

##### GetInstance {#UnitTest::GetInstance}

`static UnitTest* UnitTest::GetInstance()`

Gets the singleton `UnitTest` object. The first time this method is called, a
`UnitTest` object is constructed and returned. Consecutive calls will return the
same object.

##### original_working_dir {#UnitTest::original_working_dir}

`const char* UnitTest::original_working_dir() const`

Returns the working directory when the first [`TEST()`](#TEST) or
[`TEST_F()`](#TEST_F) was executed. The `UnitTest` object owns the string.

##### current_test_suite {#UnitTest::current_test_suite}

`const TestSuite* UnitTest::current_test_suite() const`

Returns the [`TestSuite`](#TestSuite) object for the test that's currently
running, or `NULL` if no test is running.

##### current_test_info {#UnitTest::current_test_info}

`const TestInfo* UnitTest::current_test_info() const`

Returns the [`TestInfo`](#TestInfo) object for the test that's currently
running, or `NULL` if no test is running.

##### random_seed {#UnitTest::random_seed}

`int UnitTest::random_seed() const`

Returns the random seed used at the start of the current test run.

##### successful_test_suite_count {#UnitTest::successful_test_suite_count}

`int UnitTest::successful_test_suite_count() const`

Gets the number of successful test suites.

##### failed_test_suite_count {#UnitTest::failed_test_suite_count}

`int UnitTest::failed_test_suite_count() const`

Gets the number of failed test suites.

##### total_test_suite_count {#UnitTest::total_test_suite_count}

`int UnitTest::total_test_suite_count() const`

Gets the number of all test suites.

##### test_suite_to_run_count {#UnitTest::test_suite_to_run_count}

`int UnitTest::test_suite_to_run_count() const`

Gets the number of all test suites that contain at least one test that should
run.

##### successful_test_count {#UnitTest::successful_test_count}

`int UnitTest::successful_test_count() const`

Gets the number of successful tests.

##### skipped_test_count {#UnitTest::skipped_test_count}

`int UnitTest::skipped_test_count() const`

Gets the number of skipped tests.

##### failed_test_count {#UnitTest::failed_test_count}

`int UnitTest::failed_test_count() const`

Gets the number of failed tests.

##### reportable_disabled_test_count {#UnitTest::reportable_disabled_test_count}

`int UnitTest::reportable_disabled_test_count() const`

Gets the number of disabled tests that will be reported in the XML report.

##### disabled_test_count {#UnitTest::disabled_test_count}

`int UnitTest::disabled_test_count() const`

Gets the number of disabled tests.

##### reportable_test_count {#UnitTest::reportable_test_count}

`int UnitTest::reportable_test_count() const`

Gets the number of tests to be printed in the XML report.

##### total_test_count {#UnitTest::total_test_count}

`int UnitTest::total_test_count() const`

Gets the number of all tests.

##### test_to_run_count {#UnitTest::test_to_run_count}

`int UnitTest::test_to_run_count() const`

Gets the number of tests that should run.

##### start_timestamp {#UnitTest::start_timestamp}

`TimeInMillis UnitTest::start_timestamp() const`

Gets the time of the test program start, in ms from the start of the UNIX epoch.

##### elapsed_time {#UnitTest::elapsed_time}

`TimeInMillis UnitTest::elapsed_time() const`

Gets the elapsed time, in milliseconds.

##### Passed {#UnitTest::Passed}

`bool UnitTest::Passed() const`

Returns true if and only if the unit test passed (i.e. all test suites passed).

##### Failed {#UnitTest::Failed}

`bool UnitTest::Failed() const`

Returns true if and only if the unit test failed (i.e. some test suite failed or
something outside of all tests failed).

##### GetTestSuite {#UnitTest::GetTestSuite}

`const TestSuite* UnitTest::GetTestSuite(int i) const`

Gets the [`TestSuite`](#TestSuite) object for the `i`-th test suite among all
the test suites. `i` can range from 0 to `total_test_suite_count() - 1`. If `i`
is not in that range, returns `NULL`.

##### ad_hoc_test_result {#UnitTest::ad_hoc_test_result}

`const TestResult& UnitTest::ad_hoc_test_result() const`

Returns the [`TestResult`](#TestResult) containing information on test failures
and properties logged outside of individual test suites.

##### listeners {#UnitTest::listeners}

`TestEventListeners& UnitTest::listeners()`

Returns the list of event listeners that can be used to track events inside
GoogleTest. See [`TestEventListeners`](#TestEventListeners).

### TestEventListener {#TestEventListener}

`::testing::TestEventListener`

The interface for tracing execution of tests. The methods below are listed in
the order the corresponding events are fired.

#### Public Methods {#TestEventListener-public}

##### OnTestProgramStart {#TestEventListener::OnTestProgramStart}

`virtual void TestEventListener::OnTestProgramStart(const UnitTest& unit_test)`

Fired before any test activity starts.

##### OnTestIterationStart {#TestEventListener::OnTestIterationStart}

`virtual void TestEventListener::OnTestIterationStart(const UnitTest& unit_test,
int iteration)`

Fired before each iteration of tests starts. There may be more than one
iteration if `GTEST_FLAG(repeat)` is set. `iteration` is the iteration index,
starting from 0.

##### OnEnvironmentsSetUpStart {#TestEventListener::OnEnvironmentsSetUpStart}

`virtual void TestEventListener::OnEnvironmentsSetUpStart(const UnitTest&
unit_test)`

Fired before environment set-up for each iteration of tests starts.

##### OnEnvironmentsSetUpEnd {#TestEventListener::OnEnvironmentsSetUpEnd}

`virtual void TestEventListener::OnEnvironmentsSetUpEnd(const UnitTest&
unit_test)`

Fired after environment set-up for each iteration of tests ends.

##### OnTestSuiteStart {#TestEventListener::OnTestSuiteStart}

`virtual void TestEventListener::OnTestSuiteStart(const TestSuite& test_suite)`

Fired before the test suite starts.

##### OnTestStart {#TestEventListener::OnTestStart}

`virtual void TestEventListener::OnTestStart(const TestInfo& test_info)`

Fired before the test starts.

##### OnTestPartResult {#TestEventListener::OnTestPartResult}

`virtual void TestEventListener::OnTestPartResult(const TestPartResult&
test_part_result)`

Fired after a failed assertion or a `SUCCEED()` invocation. If you want to throw
an exception from this function to skip to the next test, it must be an
[`AssertionException`](#AssertionException) or inherited from it.

##### OnTestEnd {#TestEventListener::OnTestEnd}

`virtual void TestEventListener::OnTestEnd(const TestInfo& test_info)`

Fired after the test ends.

##### OnTestSuiteEnd {#TestEventListener::OnTestSuiteEnd}

`virtual void TestEventListener::OnTestSuiteEnd(const TestSuite& test_suite)`

Fired after the test suite ends.

##### OnEnvironmentsTearDownStart {#TestEventListener::OnEnvironmentsTearDownStart}

`virtual void TestEventListener::OnEnvironmentsTearDownStart(const UnitTest&
unit_test)`

Fired before environment tear-down for each iteration of tests starts.

##### OnEnvironmentsTearDownEnd {#TestEventListener::OnEnvironmentsTearDownEnd}

`virtual void TestEventListener::OnEnvironmentsTearDownEnd(const UnitTest&
unit_test)`

Fired after environment tear-down for each iteration of tests ends.

##### OnTestIterationEnd {#TestEventListener::OnTestIterationEnd}

`virtual void TestEventListener::OnTestIterationEnd(const UnitTest& unit_test,
int iteration)`

Fired after each iteration of tests finishes.

##### OnTestProgramEnd {#TestEventListener::OnTestProgramEnd}

`virtual void TestEventListener::OnTestProgramEnd(const UnitTest& unit_test)`

Fired after all test activities have ended.

### TestEventListeners {#TestEventListeners}

`::testing::TestEventListeners`

Lets users add listeners to track events in GoogleTest.

#### Public Methods {#TestEventListeners-public}

##### Append {#TestEventListeners::Append}

`void TestEventListeners::Append(TestEventListener* listener)`

Appends an event listener to the end of the list. GoogleTest assumes ownership
of the listener (i.e. it will delete the listener when the test program
finishes).

##### Release {#TestEventListeners::Release}

`TestEventListener* TestEventListeners::Release(TestEventListener* listener)`

Removes the given event listener from the list and returns it. It then becomes
the caller's responsibility to delete the listener. Returns `NULL` if the
listener is not found in the list.

##### default_result_printer {#TestEventListeners::default_result_printer}

`TestEventListener* TestEventListeners::default_result_printer() const`

Returns the standard listener responsible for the default console output. Can be
removed from the listeners list to shut down default console output. Note that
removing this object from the listener list with
[`Release()`](#TestEventListeners::Release) transfers its ownership to the
caller and makes this function return `NULL` the next time.

##### default_xml_generator {#TestEventListeners::default_xml_generator}

`TestEventListener* TestEventListeners::default_xml_generator() const`

Returns the standard listener responsible for the default XML output controlled
by the `--gtest_output=xml` flag. Can be removed from the listeners list by
users who want to shut down the default XML output controlled by this flag and
substitute it with custom one. Note that removing this object from the listener
list with [`Release()`](#TestEventListeners::Release) transfers its ownership to
the caller and makes this function return `NULL` the next time.

### TestPartResult {#TestPartResult}

`::testing::TestPartResult`

A copyable object representing the result of a test part (i.e. an assertion or
an explicit `FAIL()`, `ADD_FAILURE()`, or `SUCCESS()`).

#### Public Methods {#TestPartResult-public}

##### type {#TestPartResult::type}

`Type TestPartResult::type() const`

Gets the outcome of the test part.

The return type `Type` is an enum defined as follows:

```cpp
enum Type {
  kSuccess,          // Succeeded.
  kNonFatalFailure,  // Failed but the test can continue.
  kFatalFailure,     // Failed and the test should be terminated.
  kSkip              // Skipped.
};
```

##### file_name {#TestPartResult::file_name}

`const char* TestPartResult::file_name() const`

Gets the name of the source file where the test part took place, or `NULL` if
it's unknown.

##### line_number {#TestPartResult::line_number}

`int TestPartResult::line_number() const`

Gets the line in the source file where the test part took place, or `-1` if it's
unknown.

##### summary {#TestPartResult::summary}

`const char* TestPartResult::summary() const`

Gets the summary of the failure message.

##### message {#TestPartResult::message}

`const char* TestPartResult::message() const`

Gets the message associated with the test part.

##### skipped {#TestPartResult::skipped}

`bool TestPartResult::skipped() const`

Returns true if and only if the test part was skipped.

##### passed {#TestPartResult::passed}

`bool TestPartResult::passed() const`

Returns true if and only if the test part passed.

##### nonfatally_failed {#TestPartResult::nonfatally_failed}

`bool TestPartResult::nonfatally_failed() const`

Returns true if and only if the test part non-fatally failed.

##### fatally_failed {#TestPartResult::fatally_failed}

`bool TestPartResult::fatally_failed() const`

Returns true if and only if the test part fatally failed.

##### failed {#TestPartResult::failed}

`bool TestPartResult::failed() const`

Returns true if and only if the test part failed.

### TestProperty {#TestProperty}

`::testing::TestProperty`

A copyable object representing a user-specified test property which can be
output as a key/value string pair.

#### Public Methods {#TestProperty-public}

##### key {#key}

`const char* key() const`

Gets the user-supplied key.

##### value {#value}

`const char* value() const`

Gets the user-supplied value.

##### SetValue {#SetValue}

`void SetValue(const std::string& new_value)`

Sets a new value, overriding the previous one.

### TestResult {#TestResult}

`::testing::TestResult`

Contains information about the result of a single test.

`TestResult` is not copyable.

#### Public Methods {#TestResult-public}

##### total_part_count {#TestResult::total_part_count}

`int TestResult::total_part_count() const`

Gets the number of all test parts. This is the sum of the number of successful
test parts and the number of failed test parts.

##### test_property_count {#TestResult::test_property_count}

`int TestResult::test_property_count() const`

Returns the number of test properties.

##### Passed {#TestResult::Passed}

`bool TestResult::Passed() const`

Returns true if and only if the test passed (i.e. no test part failed).

##### Skipped {#TestResult::Skipped}

`bool TestResult::Skipped() const`

Returns true if and only if the test was skipped.

##### Failed {#TestResult::Failed}

`bool TestResult::Failed() const`

Returns true if and only if the test failed.

##### HasFatalFailure {#TestResult::HasFatalFailure}

`bool TestResult::HasFatalFailure() const`

Returns true if and only if the test fatally failed.

##### HasNonfatalFailure {#TestResult::HasNonfatalFailure}

`bool TestResult::HasNonfatalFailure() const`

Returns true if and only if the test has a non-fatal failure.

##### elapsed_time {#TestResult::elapsed_time}

`TimeInMillis TestResult::elapsed_time() const`

Returns the elapsed time, in milliseconds.

##### start_timestamp {#TestResult::start_timestamp}

`TimeInMillis TestResult::start_timestamp() const`

Gets the time of the test case start, in ms from the start of the UNIX epoch.

##### GetTestPartResult {#TestResult::GetTestPartResult}

`const TestPartResult& TestResult::GetTestPartResult(int i) const`

Returns the [`TestPartResult`](#TestPartResult) for the `i`-th test part result
among all the results. `i` can range from 0 to `total_part_count() - 1`. If `i`
is not in that range, aborts the program.

##### GetTestProperty {#TestResult::GetTestProperty}

`const TestProperty& TestResult::GetTestProperty(int i) const`

Returns the [`TestProperty`](#TestProperty) object for the `i`-th test property.
`i` can range from 0 to `test_property_count() - 1`. If `i` is not in that
range, aborts the program.

### TimeInMillis {#TimeInMillis}

`::testing::TimeInMillis`

An integer type representing time in milliseconds.

### Types {#Types}

`::testing::Types<T...>`

Represents a list of types for use in typed tests and type-parameterized tests.

The template argument `T...` can be any number of types, for example:

```
::testing::Types<char, int, unsigned int>
```

See [Typed Tests](../advanced.md#typed-tests) and
[Type-Parameterized Tests](../advanced.md#type-parameterized-tests) for more
information.

### WithParamInterface {#WithParamInterface}

`::testing::WithParamInterface<T>`

The pure interface class that all value-parameterized tests inherit from.

A value-parameterized test fixture class must inherit from both [`Test`](#Test)
and `WithParamInterface`. In most cases that just means inheriting from
[`TestWithParam`](#TestWithParam), but more complicated test hierarchies may
need to inherit from `Test` and `WithParamInterface` at different levels.

This interface defines the type alias `ParamType` for the parameter type `T` and
has support for accessing the test parameter value via the `GetParam()` method:

```
static const ParamType& GetParam()
```

For more information, see
[Value-Parameterized Tests](../advanced.md#value-parameterized-tests).

## Functions

GoogleTest defines the following functions to help with writing and running
tests.

### InitGoogleTest {#InitGoogleTest}

`void ::testing::InitGoogleTest(int* argc, char** argv)` \
`void ::testing::InitGoogleTest(int* argc, wchar_t** argv)` \
`void ::testing::InitGoogleTest()`

Initializes GoogleTest. This must be called before calling
[`RUN_ALL_TESTS()`](#RUN_ALL_TESTS). In particular, it parses the command line
for the flags that GoogleTest recognizes. Whenever a GoogleTest flag is seen, it
is removed from `argv`, and `*argc` is decremented.

No value is returned. Instead, the GoogleTest flag variables are updated.

The `InitGoogleTest(int* argc, wchar_t** argv)` overload can be used in Windows
programs compiled in `UNICODE` mode.

The argument-less `InitGoogleTest()` overload can be used on Arduino/embedded
platforms where there is no `argc`/`argv`.

### AddGlobalTestEnvironment {#AddGlobalTestEnvironment}

`Environment* ::testing::AddGlobalTestEnvironment(Environment* env)`

Adds a test environment to the test program. Must be called before
[`RUN_ALL_TESTS()`](#RUN_ALL_TESTS) is called. See
[Global Set-Up and Tear-Down](../advanced.md#global-set-up-and-tear-down) for
more information.

See also [`Environment`](#Environment).

### RegisterTest {#RegisterTest}

```cpp
template <typename Factory>
TestInfo* ::testing::RegisterTest(const char* test_suite_name, const char* test_name,
                                  const char* type_param, const char* value_param,
                                  const char* file, int line, Factory factory)
```

Dynamically registers a test with the framework.

The `factory` argument is a factory callable (move-constructible) object or
function pointer that creates a new instance of the `Test` object. It handles
ownership to the caller. The signature of the callable is `Fixture*()`, where
`Fixture` is the test fixture class for the test. All tests registered with the
same `test_suite_name` must return the same fixture type. This is checked at
runtime.

The framework will infer the fixture class from the factory and will call the
`SetUpTestSuite` and `TearDownTestSuite` methods for it.

Must be called before [`RUN_ALL_TESTS()`](#RUN_ALL_TESTS) is invoked, otherwise
behavior is undefined.

See
[Registering tests programmatically](../advanced.md#registering-tests-programmatically)
for more information.

### RUN_ALL_TESTS {#RUN_ALL_TESTS}

`int RUN_ALL_TESTS()`

Use this function in `main()` to run all tests. It returns `0` if all tests are
successful, or `1` otherwise.

`RUN_ALL_TESTS()` should be invoked after the command line has been parsed by
[`InitGoogleTest()`](#InitGoogleTest).

This function was formerly a macro; thus, it is in the global namespace and has
an all-caps name.

### AssertionSuccess {#AssertionSuccess}

`AssertionResult ::testing::AssertionSuccess()`

Creates a successful assertion result. See
[`AssertionResult`](#AssertionResult).

### AssertionFailure {#AssertionFailure}

`AssertionResult ::testing::AssertionFailure()`

Creates a failed assertion result. Use the `<<` operator to store a failure
message:

```cpp
::testing::AssertionFailure() << "My failure message";
```

See [`AssertionResult`](#AssertionResult).

### StaticAssertTypeEq {#StaticAssertTypeEq}

`::testing::StaticAssertTypeEq<T1, T2>()`

Compile-time assertion for type equality. Compiles if and only if `T1` and `T2`
are the same type. The value it returns is irrelevant.

See [Type Assertions](../advanced.md#type-assertions) for more information.

### PrintToString {#PrintToString}

`std::string ::testing::PrintToString(x)`

Prints any value `x` using GoogleTest's value printer.

See
[Teaching GoogleTest How to Print Your Values](../advanced.md#teaching-googletest-how-to-print-your-values)
for more information.

### PrintToStringParamName {#PrintToStringParamName}

`std::string ::testing::PrintToStringParamName(TestParamInfo<T>& info)`

A built-in parameterized test name generator which returns the result of
[`PrintToString`](#PrintToString) called on `info.param`. Does not work when the
test parameter is a `std::string` or C string. See
[Specifying Names for Value-Parameterized Test Parameters](../advanced.md#specifying-names-for-value-parameterized-test-parameters)
for more information.

See also [`TestParamInfo`](#TestParamInfo) and
[`INSTANTIATE_TEST_SUITE_P`](#INSTANTIATE_TEST_SUITE_P).
# Actions Reference

[**Actions**](../gmock_for_dummies.md#actions-what-should-it-do) specify what a
mock function should do when invoked. This page lists the built-in actions
provided by GoogleTest. All actions are defined in the `::testing` namespace.

## Returning a Value

| Action                            | Description                                   |
| :-------------------------------- | :-------------------------------------------- |
| `Return()`                        | Return from a `void` mock function.           |
| `Return(value)`                   | Return `value`. If the type of `value` is     different to the mock function's return type, `value` is converted to the latter type <i>at the time the expectation is set</i>, not when the action is executed. |
| `ReturnArg<N>()`                  | Return the `N`-th (0-based) argument.         |
| `ReturnNew<T>(a1, ..., ak)`       | Return `new T(a1, ..., ak)`; a different      object is created each time. |
| `ReturnNull()`                    | Return a null pointer.                        |
| `ReturnPointee(ptr)`              | Return the value pointed to by `ptr`.         |
| `ReturnRef(variable)`             | Return a reference to `variable`.             |
| `ReturnRefOfCopy(value)`          | Return a reference to a copy of `value`; the  copy lives as long as the action. |
| `ReturnRoundRobin({a1, ..., ak})` | Each call will return the next `ai` in the list, starting at the beginning when the end of the list is reached. |

## Side Effects

| Action                             | Description                             |
| :--------------------------------- | :-------------------------------------- |
| `Assign(&variable, value)` | Assign `value` to variable. |
| `DeleteArg<N>()` | Delete the `N`-th (0-based) argument, which must be a pointer. |
| `SaveArg<N>(pointer)` | Save the `N`-th (0-based) argument to `*pointer`. |
| `SaveArgPointee<N>(pointer)` | Save the value pointed to by the `N`-th (0-based) argument to `*pointer`. |
| `SetArgReferee<N>(value)` | Assign `value` to the variable referenced by the `N`-th (0-based) argument. |
| `SetArgPointee<N>(value)` | Assign `value` to the variable pointed by the `N`-th (0-based) argument. |
| `SetArgumentPointee<N>(value)` | Same as `SetArgPointee<N>(value)`. Deprecated. Will be removed in v1.7.0. |
| `SetArrayArgument<N>(first, last)` | Copies the elements in source range [`first`, `last`) to the array pointed to by the `N`-th (0-based) argument, which can be either a pointer or an iterator. The action does not take ownership of the elements in the source range. |
| `SetErrnoAndReturn(error, value)` | Set `errno` to `error` and return `value`. |
| `Throw(exception)` | Throws the given exception, which can be any copyable value. Available since v1.1.0. |

## Using a Function, Functor, or Lambda as an Action

In the following, by "callable" we mean a free function, `std::function`,
functor, or lambda.

| Action                              | Description                            |
| :---------------------------------- | :------------------------------------- |
| `f` | Invoke `f` with the arguments passed to the mock function, where `f` is a callable. |
| `Invoke(f)` | Invoke `f` with the arguments passed to the mock function, where `f` can be a global/static function or a functor. |
| `Invoke(object_pointer, &class::method)` | Invoke the method on the object with the arguments passed to the mock function. |
| `InvokeWithoutArgs(f)` | Invoke `f`, which can be a global/static function or a functor. `f` must take no arguments. |
| `InvokeWithoutArgs(object_pointer, &class::method)` | Invoke the method on the object, which takes no arguments. |
| `InvokeArgument<N>(arg1, arg2, ..., argk)` | Invoke the mock function's `N`-th (0-based) argument, which must be a function or a functor, with the `k` arguments. |

The return value of the invoked function is used as the return value of the
action.

When defining a callable to be used with `Invoke*()`, you can declare any unused
parameters as `Unused`:

```cpp
using ::testing::Invoke;
double Distance(Unused, double x, double y) { return sqrt(x*x + y*y); }
...
EXPECT_CALL(mock, Foo("Hi", _, _)).WillOnce(Invoke(Distance));
```

`Invoke(callback)` and `InvokeWithoutArgs(callback)` take ownership of
`callback`, which must be permanent. The type of `callback` must be a base
callback type instead of a derived one, e.g.

```cpp
  BlockingClosure* done = new BlockingClosure;
  ... Invoke(done) ...;  // This won't compile!

  Closure* done2 = new BlockingClosure;
  ... Invoke(done2) ...;  // This works.
```

In `InvokeArgument<N>(...)`, if an argument needs to be passed by reference,
wrap it inside `std::ref()`. For example,

```cpp
using ::testing::InvokeArgument;
...
InvokeArgument<2>(5, string("Hi"), std::ref(foo))
```

calls the mock function's #2 argument, passing to it `5` and `string("Hi")` by
value, and `foo` by reference.

## Default Action

| Action        | Description                                            |
| :------------ | :----------------------------------------------------- |
| `DoDefault()` | Do the default action (specified by `ON_CALL()` or the built-in one). |

{: .callout .note}
**Note:** due to technical reasons, `DoDefault()` cannot be used inside a
composite action - trying to do so will result in a run-time error.

## Composite Actions

| Action                         | Description                                 |
| :----------------------------- | :------------------------------------------ |
| `DoAll(a1, a2, ..., an)`       | Do all actions `a1` to `an` and return the result of `an` in each invocation. The first `n - 1` sub-actions must return void and will receive a  readonly view of the arguments. |
| `IgnoreResult(a)`              | Perform action `a` and ignore its result. `a` must not return void. |
| `WithArg<N>(a)`                | Pass the `N`-th (0-based) argument of the mock function to action `a` and perform it. |
| `WithArgs<N1, N2, ..., Nk>(a)` | Pass the selected (0-based) arguments of the mock function to action `a` and perform it. |
| `WithoutArgs(a)`               | Perform action `a` without any arguments. |

## Defining Actions

| Macro                              | Description                             |
| :--------------------------------- | :-------------------------------------- |
| `ACTION(Sum) { return arg0 + arg1; }` | Defines an action `Sum()` to return the sum of the mock function's argument #0 and #1. |
| `ACTION_P(Plus, n) { return arg0 + n; }` | Defines an action `Plus(n)` to return the sum of the mock function's argument #0 and `n`. |
| `ACTION_Pk(Foo, p1, ..., pk) { statements; }` | Defines a parameterized action `Foo(p1, ..., pk)` to execute the given `statements`. |

The `ACTION*` macros cannot be used inside a function or class.
# Mocking Reference

This page lists the facilities provided by GoogleTest for creating and working
with mock objects. To use them, include the header
`gmock/gmock.h`.

## Macros {#macros}

GoogleTest defines the following macros for working with mocks.

### MOCK_METHOD {#MOCK_METHOD}

`MOCK_METHOD(`*`return_type`*`,`*`method_name`*`, (`*`args...`*`));` \
`MOCK_METHOD(`*`return_type`*`,`*`method_name`*`, (`*`args...`*`),
(`*`specs...`*`));`

Defines a mock method *`method_name`* with arguments `(`*`args...`*`)` and
return type *`return_type`* within a mock class.

The parameters of `MOCK_METHOD` mirror the method declaration. The optional
fourth parameter *`specs...`* is a comma-separated list of qualifiers. The
following qualifiers are accepted:

| Qualifier                  | Meaning                                      |
| -------------------------- | -------------------------------------------- |
| `const`                    | Makes the mocked method a `const` method. Required if overriding a `const` method. |
| `override`                 | Marks the method with `override`. Recommended if overriding a `virtual` method. |
| `noexcept`                 | Marks the method with `noexcept`. Required if overriding a `noexcept` method. |
| `Calltype(`*`calltype`*`)` | Sets the call type for the method, for example `Calltype(STDMETHODCALLTYPE)`. Useful on Windows. |
| `ref(`*`qualifier`*`)`     | Marks the method with the given reference qualifier, for example `ref(&)` or `ref(&&)`. Required if overriding a method that has a reference qualifier. |

Note that commas in arguments prevent `MOCK_METHOD` from parsing the arguments
correctly if they are not appropriately surrounded by parentheses. See the
following example:

```cpp
class MyMock {
 public:
  // The following 2 lines will not compile due to commas in the arguments:
  MOCK_METHOD(std::pair<bool, int>, GetPair, ());              // Error!
  MOCK_METHOD(bool, CheckMap, (std::map<int, double>, bool));  // Error!

  // One solution - wrap arguments that contain commas in parentheses:
  MOCK_METHOD((std::pair<bool, int>), GetPair, ());
  MOCK_METHOD(bool, CheckMap, ((std::map<int, double>), bool));

  // Another solution - use type aliases:
  using BoolAndInt = std::pair<bool, int>;
  MOCK_METHOD(BoolAndInt, GetPair, ());
  using MapIntDouble = std::map<int, double>;
  MOCK_METHOD(bool, CheckMap, (MapIntDouble, bool));
};
```

`MOCK_METHOD` must be used in the `public:` section of a mock class definition,
regardless of whether the method being mocked is `public`, `protected`, or
`private` in the base class.

### EXPECT_CALL {#EXPECT_CALL}

`EXPECT_CALL(`*`mock_object`*`,`*`method_name`*`(`*`matchers...`*`))`

Creates an [expectation](../gmock_for_dummies.md#setting-expectations) that the
method *`method_name`* of the object *`mock_object`* is called with arguments
that match the given matchers *`matchers...`*. `EXPECT_CALL` must precede any
code that exercises the mock object.

The parameter *`matchers...`* is a comma-separated list of
[matchers](../gmock_for_dummies.md#matchers-what-arguments-do-we-expect) that
correspond to each argument of the method *`method_name`*. The expectation will
apply only to calls of *`method_name`* whose arguments match all of the
matchers. If `(`*`matchers...`*`)` is omitted, the expectation behaves as if
each argument's matcher were a [wildcard matcher (`_`)](matchers.md#wildcard).
See the [Matchers Reference](matchers.md) for a list of all built-in matchers.

The following chainable clauses can be used to modify the expectation, and they
must be used in the following order:

```cpp
EXPECT_CALL(mock_object, method_name(matchers...))
    .With(multi_argument_matcher)  // Can be used at most once
    .Times(cardinality)            // Can be used at most once
    .InSequence(sequences...)      // Can be used any number of times
    .After(expectations...)        // Can be used any number of times
    .WillOnce(action)              // Can be used any number of times
    .WillRepeatedly(action)        // Can be used at most once
    .RetiresOnSaturation();        // Can be used at most once
```

See details for each modifier clause below.

#### With {#EXPECT_CALL.With}

`.With(`*`multi_argument_matcher`*`)`

Restricts the expectation to apply only to mock function calls whose arguments
as a whole match the multi-argument matcher *`multi_argument_matcher`*.

GoogleTest passes all of the arguments as one tuple into the matcher. The
parameter *`multi_argument_matcher`* must thus be a matcher of type
`Matcher<std::tuple<A1, ..., An>>`, where `A1, ..., An` are the types of the
function arguments.

For example, the following code sets the expectation that
`my_mock.SetPosition()` is called with any two arguments, the first argument
being less than the second:

```cpp
using ::testing::_;
using ::testing::Lt;
...
EXPECT_CALL(my_mock, SetPosition(_, _))
    .With(Lt());
```

GoogleTest provides some built-in matchers for 2-tuples, including the `Lt()`
matcher above. See [Multi-argument Matchers](matchers.md#MultiArgMatchers).

The `With` clause can be used at most once on an expectation and must be the
first clause.

#### Times {#EXPECT_CALL.Times}

`.Times(`*`cardinality`*`)`

Specifies how many times the mock function call is expected.

The parameter *`cardinality`* represents the number of expected calls and can be
one of the following, all defined in the `::testing` namespace:

| Cardinality         | Meaning                                             |
| ------------------- | --------------------------------------------------- |
| `AnyNumber()`       | The function can be called any number of times.     |
| `AtLeast(n)`        | The function call is expected at least *n* times.   |
| `AtMost(n)`         | The function call is expected at most *n* times.    |
| `Between(m, n)`     | The function call is expected between *m* and *n* times, inclusive. |
| `Exactly(n)` or `n` | The function call is expected exactly *n* times. If *n* is 0, the call should never happen. |

If the `Times` clause is omitted, GoogleTest infers the cardinality as follows:

*   If neither [`WillOnce`](#EXPECT_CALL.WillOnce) nor
    [`WillRepeatedly`](#EXPECT_CALL.WillRepeatedly) are specified, the inferred
    cardinality is `Times(1)`.
*   If there are *n* `WillOnce` clauses and no `WillRepeatedly` clause, where
    *n* >= 1, the inferred cardinality is `Times(n)`.
*   If there are *n* `WillOnce` clauses and one `WillRepeatedly` clause, where
    *n* >= 0, the inferred cardinality is `Times(AtLeast(n))`.

The `Times` clause can be used at most once on an expectation.

#### InSequence {#EXPECT_CALL.InSequence}

`.InSequence(`*`sequences...`*`)`

Specifies that the mock function call is expected in a certain sequence.

The parameter *`sequences...`* is any number of [`Sequence`](#Sequence) objects.
Expected calls assigned to the same sequence are expected to occur in the order
the expectations are declared.

For example, the following code sets the expectation that the `Reset()` method
of `my_mock` is called before both `GetSize()` and `Describe()`, and `GetSize()`
and `Describe()` can occur in any order relative to each other:

```cpp
using ::testing::Sequence;
Sequence s1, s2;
...
EXPECT_CALL(my_mock, Reset())
    .InSequence(s1, s2);
EXPECT_CALL(my_mock, GetSize())
    .InSequence(s1);
EXPECT_CALL(my_mock, Describe())
    .InSequence(s2);
```

The `InSequence` clause can be used any number of times on an expectation.

See also the [`InSequence` class](#InSequence).

#### After {#EXPECT_CALL.After}

`.After(`*`expectations...`*`)`

Specifies that the mock function call is expected to occur after one or more
other calls.

The parameter *`expectations...`* can be up to five
[`Expectation`](#Expectation) or [`ExpectationSet`](#ExpectationSet) objects.
The mock function call is expected to occur after all of the given expectations.

For example, the following code sets the expectation that the `Describe()`
method of `my_mock` is called only after both `InitX()` and `InitY()` have been
called.

```cpp
using ::testing::Expectation;
...
Expectation init_x = EXPECT_CALL(my_mock, InitX());
Expectation init_y = EXPECT_CALL(my_mock, InitY());
EXPECT_CALL(my_mock, Describe())
    .After(init_x, init_y);
```

The `ExpectationSet` object is helpful when the number of prerequisites for an
expectation is large or variable, for example:

```cpp
using ::testing::ExpectationSet;
...
ExpectationSet all_inits;
// Collect all expectations of InitElement() calls
for (int i = 0; i < element_count; i++) {
  all_inits += EXPECT_CALL(my_mock, InitElement(i));
}
EXPECT_CALL(my_mock, Describe())
    .After(all_inits);  // Expect Describe() call after all InitElement() calls
```

The `After` clause can be used any number of times on an expectation.

#### WillOnce {#EXPECT_CALL.WillOnce}

`.WillOnce(`*`action`*`)`

Specifies the mock function's actual behavior when invoked, for a single
matching function call.

The parameter *`action`* represents the
[action](../gmock_for_dummies.md#actions-what-should-it-do) that the function
call will perform. See the [Actions Reference](actions.md) for a list of
built-in actions.

The use of `WillOnce` implicitly sets a cardinality on the expectation when
`Times` is not specified. See [`Times`](#EXPECT_CALL.Times).

Each matching function call will perform the next action in the order declared.
For example, the following code specifies that `my_mock.GetNumber()` is expected
to be called exactly 3 times and will return `1`, `2`, and `3` respectively on
the first, second, and third calls:

```cpp
using ::testing::Return;
...
EXPECT_CALL(my_mock, GetNumber())
    .WillOnce(Return(1))
    .WillOnce(Return(2))
    .WillOnce(Return(3));
```

The `WillOnce` clause can be used any number of times on an expectation.

#### WillRepeatedly {#EXPECT_CALL.WillRepeatedly}

`.WillRepeatedly(`*`action`*`)`

Specifies the mock function's actual behavior when invoked, for all subsequent
matching function calls. Takes effect after the actions specified in the
[`WillOnce`](#EXPECT_CALL.WillOnce) clauses, if any, have been performed.

The parameter *`action`* represents the
[action](../gmock_for_dummies.md#actions-what-should-it-do) that the function
call will perform. See the [Actions Reference](actions.md) for a list of
built-in actions.

The use of `WillRepeatedly` implicitly sets a cardinality on the expectation
when `Times` is not specified. See [`Times`](#EXPECT_CALL.Times).

If any `WillOnce` clauses have been specified, matching function calls will
perform those actions before the action specified by `WillRepeatedly`. See the
following example:

```cpp
using ::testing::Return;
...
EXPECT_CALL(my_mock, GetName())
    .WillRepeatedly(Return("John Doe"));  // Return "John Doe" on all calls

EXPECT_CALL(my_mock, GetNumber())
    .WillOnce(Return(42))        // Return 42 on the first call
    .WillRepeatedly(Return(7));  // Return 7 on all subsequent calls
```

The `WillRepeatedly` clause can be used at most once on an expectation.

#### RetiresOnSaturation {#EXPECT_CALL.RetiresOnSaturation}

`.RetiresOnSaturation()`

Indicates that the expectation will no longer be active after the expected
number of matching function calls has been reached.

The `RetiresOnSaturation` clause is only meaningful for expectations with an
upper-bounded cardinality. The expectation will *retire* (no longer match any
function calls) after it has been *saturated* (the upper bound has been
reached). See the following example:

```cpp
using ::testing::_;
using ::testing::AnyNumber;
...
EXPECT_CALL(my_mock, SetNumber(_))  // Expectation 1
    .Times(AnyNumber());
EXPECT_CALL(my_mock, SetNumber(7))  // Expectation 2
    .Times(2)
    .RetiresOnSaturation();
```

In the above example, the first two calls to `my_mock.SetNumber(7)` match
expectation 2, which then becomes inactive and no longer matches any calls. A
third call to `my_mock.SetNumber(7)` would then match expectation 1. Without
`RetiresOnSaturation()` on expectation 2, a third call to `my_mock.SetNumber(7)`
would match expectation 2 again, producing a failure since the limit of 2 calls
was exceeded.

The `RetiresOnSaturation` clause can be used at most once on an expectation and
must be the last clause.

### ON_CALL {#ON_CALL}

`ON_CALL(`*`mock_object`*`,`*`method_name`*`(`*`matchers...`*`))`

Defines what happens when the method *`method_name`* of the object
*`mock_object`* is called with arguments that match the given matchers
*`matchers...`*. Requires a modifier clause to specify the method's behavior.
*Does not* set any expectations that the method will be called.

The parameter *`matchers...`* is a comma-separated list of
[matchers](../gmock_for_dummies.md#matchers-what-arguments-do-we-expect) that
correspond to each argument of the method *`method_name`*. The `ON_CALL`
specification will apply only to calls of *`method_name`* whose arguments match
all of the matchers. If `(`*`matchers...`*`)` is omitted, the behavior is as if
each argument's matcher were a [wildcard matcher (`_`)](matchers.md#wildcard).
See the [Matchers Reference](matchers.md) for a list of all built-in matchers.

The following chainable clauses can be used to set the method's behavior, and
they must be used in the following order:

```cpp
ON_CALL(mock_object, method_name(matchers...))
    .With(multi_argument_matcher)  // Can be used at most once
    .WillByDefault(action);        // Required
```

See details for each modifier clause below.

#### With {#ON_CALL.With}

`.With(`*`multi_argument_matcher`*`)`

Restricts the specification to only mock function calls whose arguments as a
whole match the multi-argument matcher *`multi_argument_matcher`*.

GoogleTest passes all of the arguments as one tuple into the matcher. The
parameter *`multi_argument_matcher`* must thus be a matcher of type
`Matcher<std::tuple<A1, ..., An>>`, where `A1, ..., An` are the types of the
function arguments.

For example, the following code sets the default behavior when
`my_mock.SetPosition()` is called with any two arguments, the first argument
being less than the second:

```cpp
using ::testing::_;
using ::testing::Lt;
using ::testing::Return;
...
ON_CALL(my_mock, SetPosition(_, _))
    .With(Lt())
    .WillByDefault(Return(true));
```

GoogleTest provides some built-in matchers for 2-tuples, including the `Lt()`
matcher above. See [Multi-argument Matchers](matchers.md#MultiArgMatchers).

The `With` clause can be used at most once with each `ON_CALL` statement.

#### WillByDefault {#ON_CALL.WillByDefault}

`.WillByDefault(`*`action`*`)`

Specifies the default behavior of a matching mock function call.

The parameter *`action`* represents the
[action](../gmock_for_dummies.md#actions-what-should-it-do) that the function
call will perform. See the [Actions Reference](actions.md) for a list of
built-in actions.

For example, the following code specifies that by default, a call to
`my_mock.Greet()` will return `"hello"`:

```cpp
using ::testing::Return;
...
ON_CALL(my_mock, Greet())
    .WillByDefault(Return("hello"));
```

The action specified by `WillByDefault` is superseded by the actions specified
on a matching `EXPECT_CALL` statement, if any. See the
[`WillOnce`](#EXPECT_CALL.WillOnce) and
[`WillRepeatedly`](#EXPECT_CALL.WillRepeatedly) clauses of `EXPECT_CALL`.

The `WillByDefault` clause must be used exactly once with each `ON_CALL`
statement.

## Classes {#classes}

GoogleTest defines the following classes for working with mocks.

### DefaultValue {#DefaultValue}

`::testing::DefaultValue<T>`

Allows a user to specify the default value for a type `T` that is both copyable
and publicly destructible (i.e. anything that can be used as a function return
type). For mock functions with a return type of `T`, this default value is
returned from function calls that do not specify an action.

Provides the static methods `Set()`, `SetFactory()`, and `Clear()` to manage the
default value:

```cpp
// Sets the default value to be returned. T must be copy constructible.
DefaultValue<T>::Set(value);

// Sets a factory. Will be invoked on demand. T must be move constructible.
T MakeT();
DefaultValue<T>::SetFactory(&MakeT);

// Unsets the default value.
DefaultValue<T>::Clear();
```

### NiceMock {#NiceMock}

`::testing::NiceMock<T>`

Represents a mock object that suppresses warnings on
[uninteresting calls](../gmock_cook_book.md#uninteresting-vs-unexpected). The
template parameter `T` is any mock class, except for another `NiceMock`,
`NaggyMock`, or `StrictMock`.

Usage of `NiceMock<T>` is analogous to usage of `T`. `NiceMock<T>` is a subclass
of `T`, so it can be used wherever an object of type `T` is accepted. In
addition, `NiceMock<T>` can be constructed with any arguments that a constructor
of `T` accepts.

For example, the following code suppresses warnings on the mock `my_mock` of
type `MockClass` if a method other than `DoSomething()` is called:

```cpp
using ::testing::NiceMock;
...
NiceMock<MockClass> my_mock("some", "args");
EXPECT_CALL(my_mock, DoSomething());
... code that uses my_mock ...
```

`NiceMock<T>` only works for mock methods defined using the `MOCK_METHOD` macro
directly in the definition of class `T`. If a mock method is defined in a base
class of `T`, a warning might still be generated.

`NiceMock<T>` might not work correctly if the destructor of `T` is not virtual.

### NaggyMock {#NaggyMock}

`::testing::NaggyMock<T>`

Represents a mock object that generates warnings on
[uninteresting calls](../gmock_cook_book.md#uninteresting-vs-unexpected). The
template parameter `T` is any mock class, except for another `NiceMock`,
`NaggyMock`, or `StrictMock`.

Usage of `NaggyMock<T>` is analogous to usage of `T`. `NaggyMock<T>` is a
subclass of `T`, so it can be used wherever an object of type `T` is accepted.
In addition, `NaggyMock<T>` can be constructed with any arguments that a
constructor of `T` accepts.

For example, the following code generates warnings on the mock `my_mock` of type
`MockClass` if a method other than `DoSomething()` is called:

```cpp
using ::testing::NaggyMock;
...
NaggyMock<MockClass> my_mock("some", "args");
EXPECT_CALL(my_mock, DoSomething());
... code that uses my_mock ...
```

Mock objects of type `T` by default behave the same way as `NaggyMock<T>`.

### StrictMock {#StrictMock}

`::testing::StrictMock<T>`

Represents a mock object that generates test failures on
[uninteresting calls](../gmock_cook_book.md#uninteresting-vs-unexpected). The
template parameter `T` is any mock class, except for another `NiceMock`,
`NaggyMock`, or `StrictMock`.

Usage of `StrictMock<T>` is analogous to usage of `T`. `StrictMock<T>` is a
subclass of `T`, so it can be used wherever an object of type `T` is accepted.
In addition, `StrictMock<T>` can be constructed with any arguments that a
constructor of `T` accepts.

For example, the following code generates a test failure on the mock `my_mock`
of type `MockClass` if a method other than `DoSomething()` is called:

```cpp
using ::testing::StrictMock;
...
StrictMock<MockClass> my_mock("some", "args");
EXPECT_CALL(my_mock, DoSomething());
... code that uses my_mock ...
```

`StrictMock<T>` only works for mock methods defined using the `MOCK_METHOD`
macro directly in the definition of class `T`. If a mock method is defined in a
base class of `T`, a failure might not be generated.

`StrictMock<T>` might not work correctly if the destructor of `T` is not
virtual.

### Sequence {#Sequence}

`::testing::Sequence`

Represents a chronological sequence of expectations. See the
[`InSequence`](#EXPECT_CALL.InSequence) clause of `EXPECT_CALL` for usage.

### InSequence {#InSequence}

`::testing::InSequence`

An object of this type causes all expectations encountered in its scope to be
put in an anonymous sequence.

This allows more convenient expression of multiple expectations in a single
sequence:

```cpp
using ::testing::InSequence;
{
  InSequence seq;

  // The following are expected to occur in the order declared.
  EXPECT_CALL(...);
  EXPECT_CALL(...);
  ...
  EXPECT_CALL(...);
}
```

The name of the `InSequence` object does not matter.

### Expectation {#Expectation}

`::testing::Expectation`

Represents a mock function call expectation as created by
[`EXPECT_CALL`](#EXPECT_CALL):

```cpp
using ::testing::Expectation;
Expectation my_expectation = EXPECT_CALL(...);
```

Useful for specifying sequences of expectations; see the
[`After`](#EXPECT_CALL.After) clause of `EXPECT_CALL`.

### ExpectationSet {#ExpectationSet}

`::testing::ExpectationSet`

Represents a set of mock function call expectations.

Use the `+=` operator to add [`Expectation`](#Expectation) objects to the set:

```cpp
using ::testing::ExpectationSet;
ExpectationSet my_expectations;
my_expectations += EXPECT_CALL(...);
```

Useful for specifying sequences of expectations; see the
[`After`](#EXPECT_CALL.After) clause of `EXPECT_CALL`.
# Assertions Reference

This page lists the assertion macros provided by GoogleTest for verifying code
behavior. To use them, include the header `gtest/gtest.h`.

The majority of the macros listed below come as a pair with an `EXPECT_` variant
and an `ASSERT_` variant. Upon failure, `EXPECT_` macros generate nonfatal
failures and allow the current function to continue running, while `ASSERT_`
macros generate fatal failures and abort the current function.

All assertion macros support streaming a custom failure message into them with
the `<<` operator, for example:

```cpp
EXPECT_TRUE(my_condition) << "My condition is not true";
```

Anything that can be streamed to an `ostream` can be streamed to an assertion
macro—in particular, C strings and string objects. If a wide string (`wchar_t*`,
`TCHAR*` in `UNICODE` mode on Windows, or `std::wstring`) is streamed to an
assertion, it will be translated to UTF-8 when printed.

## Explicit Success and Failure {#success-failure}

The assertions in this section generate a success or failure directly instead of
testing a value or expression. These are useful when control flow, rather than a
Boolean expression, determines the test's success or failure, as shown by the
following example:

```c++
switch(expression) {
  case 1:
    ... some checks ...
  case 2:
    ... some other checks ...
  default:
    FAIL() << "We shouldn't get here.";
}
```

### SUCCEED {#SUCCEED}

`SUCCEED()`

Generates a success. This *does not* make the overall test succeed. A test is
considered successful only if none of its assertions fail during its execution.

The `SUCCEED` assertion is purely documentary and currently doesn't generate any
user-visible output. However, we may add `SUCCEED` messages to GoogleTest output
in the future.

### FAIL {#FAIL}

`FAIL()`

Generates a fatal failure, which returns from the current function.

Can only be used in functions that return `void`. See
[Assertion Placement](../advanced.md#assertion-placement) for more information.

### ADD_FAILURE {#ADD_FAILURE}

`ADD_FAILURE()`

Generates a nonfatal failure, which allows the current function to continue
running.

### ADD_FAILURE_AT {#ADD_FAILURE_AT}

`ADD_FAILURE_AT(`*`file_path`*`,`*`line_number`*`)`

Generates a nonfatal failure at the file and line number specified.

## Generalized Assertion {#generalized}

The following assertion allows [matchers](matchers.md) to be used to verify
values.

### EXPECT_THAT {#EXPECT_THAT}

`EXPECT_THAT(`*`value`*`,`*`matcher`*`)` \
`ASSERT_THAT(`*`value`*`,`*`matcher`*`)`

Verifies that *`value`* matches the [matcher](matchers.md) *`matcher`*.

For example, the following code verifies that the string `value1` starts with
`"Hello"`, `value2` matches a regular expression, and `value3` is between 5 and
10:

```cpp
#include "gmock/gmock.h"

using ::testing::AllOf;
using ::testing::Gt;
using ::testing::Lt;
using ::testing::MatchesRegex;
using ::testing::StartsWith;

...
EXPECT_THAT(value1, StartsWith("Hello"));
EXPECT_THAT(value2, MatchesRegex("Line \\d+"));
ASSERT_THAT(value3, AllOf(Gt(5), Lt(10)));
```

Matchers enable assertions of this form to read like English and generate
informative failure messages. For example, if the above assertion on `value1`
fails, the resulting message will be similar to the following:

```
Value of: value1
  Actual: "Hi, world!"
Expected: starts with "Hello"
```

GoogleTest provides a built-in library of matchers—see the
[Matchers Reference](matchers.md). It is also possible to write your own
matchers—see [Writing New Matchers Quickly](../gmock_cook_book.md#NewMatchers).
The use of matchers makes `EXPECT_THAT` a powerful, extensible assertion.

*The idea for this assertion was borrowed from Joe Walnes' Hamcrest project,
which adds `assertThat()` to JUnit.*

## Boolean Conditions {#boolean}

The following assertions test Boolean conditions.

### EXPECT_TRUE {#EXPECT_TRUE}

`EXPECT_TRUE(`*`condition`*`)` \
`ASSERT_TRUE(`*`condition`*`)`

Verifies that *`condition`* is true.

### EXPECT_FALSE {#EXPECT_FALSE}

`EXPECT_FALSE(`*`condition`*`)` \
`ASSERT_FALSE(`*`condition`*`)`

Verifies that *`condition`* is false.

## Binary Comparison {#binary-comparison}

The following assertions compare two values. The value arguments must be
comparable by the assertion's comparison operator, otherwise a compiler error
will result.

If an argument supports the `<<` operator, it will be called to print the
argument when the assertion fails. Otherwise, GoogleTest will attempt to print
them in the best way it can—see
[Teaching GoogleTest How to Print Your Values](../advanced.md#teaching-googletest-how-to-print-your-values).

Arguments are always evaluated exactly once, so it's OK for the arguments to
have side effects. However, the argument evaluation order is undefined and
programs should not depend on any particular argument evaluation order.

These assertions work with both narrow and wide string objects (`string` and
`wstring`).

See also the [Floating-Point Comparison](#floating-point) assertions to compare
floating-point numbers and avoid problems caused by rounding.

### EXPECT_EQ {#EXPECT_EQ}

`EXPECT_EQ(`*`val1`*`,`*`val2`*`)` \
`ASSERT_EQ(`*`val1`*`,`*`val2`*`)`

Verifies that *`val1`*`==`*`val2`*.

Does pointer equality on pointers. If used on two C strings, it tests if they
are in the same memory location, not if they have the same value. Use
[`EXPECT_STREQ`](#EXPECT_STREQ) to compare C strings (e.g. `const char*`) by
value.

When comparing a pointer to `NULL`, use `EXPECT_EQ(`*`ptr`*`, nullptr)` instead
of `EXPECT_EQ(`*`ptr`*`, NULL)`.

### EXPECT_NE {#EXPECT_NE}

`EXPECT_NE(`*`val1`*`,`*`val2`*`)` \
`ASSERT_NE(`*`val1`*`,`*`val2`*`)`

Verifies that *`val1`*`!=`*`val2`*.

Does pointer equality on pointers. If used on two C strings, it tests if they
are in different memory locations, not if they have different values. Use
[`EXPECT_STRNE`](#EXPECT_STRNE) to compare C strings (e.g. `const char*`) by
value.

When comparing a pointer to `NULL`, use `EXPECT_NE(`*`ptr`*`, nullptr)` instead
of `EXPECT_NE(`*`ptr`*`, NULL)`.

### EXPECT_LT {#EXPECT_LT}

`EXPECT_LT(`*`val1`*`,`*`val2`*`)` \
`ASSERT_LT(`*`val1`*`,`*`val2`*`)`

Verifies that *`val1`*`<`*`val2`*.

### EXPECT_LE {#EXPECT_LE}

`EXPECT_LE(`*`val1`*`,`*`val2`*`)` \
`ASSERT_LE(`*`val1`*`,`*`val2`*`)`

Verifies that *`val1`*`<=`*`val2`*.

### EXPECT_GT {#EXPECT_GT}

`EXPECT_GT(`*`val1`*`,`*`val2`*`)` \
`ASSERT_GT(`*`val1`*`,`*`val2`*`)`

Verifies that *`val1`*`>`*`val2`*.

### EXPECT_GE {#EXPECT_GE}

`EXPECT_GE(`*`val1`*`,`*`val2`*`)` \
`ASSERT_GE(`*`val1`*`,`*`val2`*`)`

Verifies that *`val1`*`>=`*`val2`*.

## String Comparison {#c-strings}

The following assertions compare two **C strings**. To compare two `string`
objects, use [`EXPECT_EQ`](#EXPECT_EQ) or [`EXPECT_NE`](#EXPECT_NE) instead.

These assertions also accept wide C strings (`wchar_t*`). If a comparison of two
wide strings fails, their values will be printed as UTF-8 narrow strings.

To compare a C string with `NULL`, use `EXPECT_EQ(`*`c_string`*`, nullptr)` or
`EXPECT_NE(`*`c_string`*`, nullptr)`.

### EXPECT_STREQ {#EXPECT_STREQ}

`EXPECT_STREQ(`*`str1`*`,`*`str2`*`)` \
`ASSERT_STREQ(`*`str1`*`,`*`str2`*`)`

Verifies that the two C strings *`str1`* and *`str2`* have the same contents.

### EXPECT_STRNE {#EXPECT_STRNE}

`EXPECT_STRNE(`*`str1`*`,`*`str2`*`)` \
`ASSERT_STRNE(`*`str1`*`,`*`str2`*`)`

Verifies that the two C strings *`str1`* and *`str2`* have different contents.

### EXPECT_STRCASEEQ {#EXPECT_STRCASEEQ}

`EXPECT_STRCASEEQ(`*`str1`*`,`*`str2`*`)` \
`ASSERT_STRCASEEQ(`*`str1`*`,`*`str2`*`)`

Verifies that the two C strings *`str1`* and *`str2`* have the same contents,
ignoring case.

### EXPECT_STRCASENE {#EXPECT_STRCASENE}

`EXPECT_STRCASENE(`*`str1`*`,`*`str2`*`)` \
`ASSERT_STRCASENE(`*`str1`*`,`*`str2`*`)`

Verifies that the two C strings *`str1`* and *`str2`* have different contents,
ignoring case.

## Floating-Point Comparison {#floating-point}

The following assertions compare two floating-point values.

Due to rounding errors, it is very unlikely that two floating-point values will
match exactly, so `EXPECT_EQ` is not suitable. In general, for floating-point
comparison to make sense, the user needs to carefully choose the error bound.

GoogleTest also provides assertions that use a default error bound based on
Units in the Last Place (ULPs). To learn more about ULPs, see the article
[Comparing Floating Point Numbers](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/).

### EXPECT_FLOAT_EQ {#EXPECT_FLOAT_EQ}

`EXPECT_FLOAT_EQ(`*`val1`*`,`*`val2`*`)` \
`ASSERT_FLOAT_EQ(`*`val1`*`,`*`val2`*`)`

Verifies that the two `float` values *`val1`* and *`val2`* are approximately
equal, to within 4 ULPs from each other.

### EXPECT_DOUBLE_EQ {#EXPECT_DOUBLE_EQ}

`EXPECT_DOUBLE_EQ(`*`val1`*`,`*`val2`*`)` \
`ASSERT_DOUBLE_EQ(`*`val1`*`,`*`val2`*`)`

Verifies that the two `double` values *`val1`* and *`val2`* are approximately
equal, to within 4 ULPs from each other.

### EXPECT_NEAR {#EXPECT_NEAR}

`EXPECT_NEAR(`*`val1`*`,`*`val2`*`,`*`abs_error`*`)` \
`ASSERT_NEAR(`*`val1`*`,`*`val2`*`,`*`abs_error`*`)`

Verifies that the difference between *`val1`* and *`val2`* does not exceed the
absolute error bound *`abs_error`*.

## Exception Assertions {#exceptions}

The following assertions verify that a piece of code throws, or does not throw,
an exception. Usage requires exceptions to be enabled in the build environment.

Note that the piece of code under test can be a compound statement, for example:

```cpp
EXPECT_NO_THROW({
  int n = 5;
  DoSomething(&n);
});
```

### EXPECT_THROW {#EXPECT_THROW}

`EXPECT_THROW(`*`statement`*`,`*`exception_type`*`)` \
`ASSERT_THROW(`*`statement`*`,`*`exception_type`*`)`

Verifies that *`statement`* throws an exception of type *`exception_type`*.

### EXPECT_ANY_THROW {#EXPECT_ANY_THROW}

`EXPECT_ANY_THROW(`*`statement`*`)` \
`ASSERT_ANY_THROW(`*`statement`*`)`

Verifies that *`statement`* throws an exception of any type.

### EXPECT_NO_THROW {#EXPECT_NO_THROW}

`EXPECT_NO_THROW(`*`statement`*`)` \
`ASSERT_NO_THROW(`*`statement`*`)`

Verifies that *`statement`* does not throw any exception.

## Predicate Assertions {#predicates}

The following assertions enable more complex predicates to be verified while
printing a more clear failure message than if `EXPECT_TRUE` were used alone.

### EXPECT_PRED* {#EXPECT_PRED}

`EXPECT_PRED1(`*`pred`*`,`*`val1`*`)` \
`EXPECT_PRED2(`*`pred`*`,`*`val1`*`,`*`val2`*`)` \
`EXPECT_PRED3(`*`pred`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`)` \
`EXPECT_PRED4(`*`pred`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`,`*`val4`*`)` \
`EXPECT_PRED5(`*`pred`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`,`*`val4`*`,`*`val5`*`)`

`ASSERT_PRED1(`*`pred`*`,`*`val1`*`)` \
`ASSERT_PRED2(`*`pred`*`,`*`val1`*`,`*`val2`*`)` \
`ASSERT_PRED3(`*`pred`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`)` \
`ASSERT_PRED4(`*`pred`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`,`*`val4`*`)` \
`ASSERT_PRED5(`*`pred`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`,`*`val4`*`,`*`val5`*`)`

Verifies that the predicate *`pred`* returns `true` when passed the given values
as arguments.

The parameter *`pred`* is a function or functor that accepts as many arguments
as the corresponding macro accepts values. If *`pred`* returns `true` for the
given arguments, the assertion succeeds, otherwise the assertion fails.

When the assertion fails, it prints the value of each argument. Arguments are
always evaluated exactly once.

As an example, see the following code:

```cpp
// Returns true if m and n have no common divisors except 1.
bool MutuallyPrime(int m, int n) { ... }
...
const int a = 3;
const int b = 4;
const int c = 10;
...
EXPECT_PRED2(MutuallyPrime, a, b);  // Succeeds
EXPECT_PRED2(MutuallyPrime, b, c);  // Fails
```

In the above example, the first assertion succeeds, and the second fails with
the following message:

```
MutuallyPrime(b, c) is false, where
b is 4
c is 10
```

Note that if the given predicate is an overloaded function or a function
template, the assertion macro might not be able to determine which version to
use, and it might be necessary to explicitly specify the type of the function.
For example, for a Boolean function `IsPositive()` overloaded to take either a
single `int` or `double` argument, it would be necessary to write one of the
following:

```cpp
EXPECT_PRED1(static_cast<bool (*)(int)>(IsPositive), 5);
EXPECT_PRED1(static_cast<bool (*)(double)>(IsPositive), 3.14);
```

Writing simply `EXPECT_PRED1(IsPositive, 5);` would result in a compiler error.
Similarly, to use a template function, specify the template arguments:

```cpp
template <typename T>
bool IsNegative(T x) {
  return x < 0;
}
...
EXPECT_PRED1(IsNegative<int>, -5);  // Must specify type for IsNegative
```

If a template has multiple parameters, wrap the predicate in parentheses so the
macro arguments are parsed correctly:

```cpp
ASSERT_PRED2((MyPredicate<int, int>), 5, 0);
```

### EXPECT_PRED_FORMAT* {#EXPECT_PRED_FORMAT}

`EXPECT_PRED_FORMAT1(`*`pred_formatter`*`,`*`val1`*`)` \
`EXPECT_PRED_FORMAT2(`*`pred_formatter`*`,`*`val1`*`,`*`val2`*`)` \
`EXPECT_PRED_FORMAT3(`*`pred_formatter`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`)` \
`EXPECT_PRED_FORMAT4(`*`pred_formatter`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`,`*`val4`*`)`
\
`EXPECT_PRED_FORMAT5(`*`pred_formatter`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`,`*`val4`*`,`*`val5`*`)`

`ASSERT_PRED_FORMAT1(`*`pred_formatter`*`,`*`val1`*`)` \
`ASSERT_PRED_FORMAT2(`*`pred_formatter`*`,`*`val1`*`,`*`val2`*`)` \
`ASSERT_PRED_FORMAT3(`*`pred_formatter`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`)` \
`ASSERT_PRED_FORMAT4(`*`pred_formatter`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`,`*`val4`*`)`
\
`ASSERT_PRED_FORMAT5(`*`pred_formatter`*`,`*`val1`*`,`*`val2`*`,`*`val3`*`,`*`val4`*`,`*`val5`*`)`

Verifies that the predicate *`pred_formatter`* succeeds when passed the given
values as arguments.

The parameter *`pred_formatter`* is a *predicate-formatter*, which is a function
or functor with the signature:

```cpp
testing::AssertionResult PredicateFormatter(const char* expr1,
                                            const char* expr2,
                                            ...
                                            const char* exprn,
                                            T1 val1,
                                            T2 val2,
                                            ...
                                            Tn valn);
```

where *`val1`*, *`val2`*, ..., *`valn`* are the values of the predicate
arguments, and *`expr1`*, *`expr2`*, ..., *`exprn`* are the corresponding
expressions as they appear in the source code. The types `T1`, `T2`, ..., `Tn`
can be either value types or reference types; if an argument has type `T`, it
can be declared as either `T` or `const T&`, whichever is appropriate. For more
about the return type `testing::AssertionResult`, see
[Using a Function That Returns an AssertionResult](../advanced.md#using-a-function-that-returns-an-assertionresult).

As an example, see the following code:

```cpp
// Returns the smallest prime common divisor of m and n,
// or 1 when m and n are mutually prime.
int SmallestPrimeCommonDivisor(int m, int n) { ... }

// Returns true if m and n have no common divisors except 1.
bool MutuallyPrime(int m, int n) { ... }

// A predicate-formatter for asserting that two integers are mutually prime.
testing::AssertionResult AssertMutuallyPrime(const char* m_expr,
                                             const char* n_expr,
                                             int m,
                                             int n) {
  if (MutuallyPrime(m, n)) return testing::AssertionSuccess();

  return testing::AssertionFailure() << m_expr << " and " << n_expr
      << " (" << m << " and " << n << ") are not mutually prime, "
      << "as they have a common divisor " << SmallestPrimeCommonDivisor(m, n);
}

...
const int a = 3;
const int b = 4;
const int c = 10;
...
EXPECT_PRED_FORMAT2(AssertMutuallyPrime, a, b);  // Succeeds
EXPECT_PRED_FORMAT2(AssertMutuallyPrime, b, c);  // Fails
```

In the above example, the final assertion fails and the predicate-formatter
produces the following failure message:

```
b and c (4 and 10) are not mutually prime, as they have a common divisor 2
```

## Windows HRESULT Assertions {#HRESULT}

The following assertions test for `HRESULT` success or failure. For example:

```cpp
CComPtr<IShellDispatch2> shell;
ASSERT_HRESULT_SUCCEEDED(shell.CoCreateInstance(L"Shell.Application"));
CComVariant empty;
ASSERT_HRESULT_SUCCEEDED(shell->ShellExecute(CComBSTR(url), empty, empty, empty, empty));
```

The generated output contains the human-readable error message associated with
the returned `HRESULT` code.

### EXPECT_HRESULT_SUCCEEDED {#EXPECT_HRESULT_SUCCEEDED}

`EXPECT_HRESULT_SUCCEEDED(`*`expression`*`)` \
`ASSERT_HRESULT_SUCCEEDED(`*`expression`*`)`

Verifies that *`expression`* is a success `HRESULT`.

### EXPECT_HRESULT_FAILED {#EXPECT_HRESULT_FAILED}

`EXPECT_HRESULT_FAILED(`*`expression`*`)` \
`EXPECT_HRESULT_FAILED(`*`expression`*`)`

Verifies that *`expression`* is a failure `HRESULT`.

## Death Assertions {#death}

The following assertions verify that a piece of code causes the process to
terminate. For context, see [Death Tests](../advanced.md#death-tests).

These assertions spawn a new process and execute the code under test in that
process. How that happens depends on the platform and the variable
`::testing::GTEST_FLAG(death_test_style)`, which is initialized from the
command-line flag `--gtest_death_test_style`.

*   On POSIX systems, `fork()` (or `clone()` on Linux) is used to spawn the
    child, after which:
    *   If the variable's value is `"fast"`, the death test statement is
        immediately executed.
    *   If the variable's value is `"threadsafe"`, the child process re-executes
        the unit test binary just as it was originally invoked, but with some
        extra flags to cause just the single death test under consideration to
        be run.
*   On Windows, the child is spawned using the `CreateProcess()` API, and
    re-executes the binary to cause just the single death test under
    consideration to be run - much like the `"threadsafe"` mode on POSIX.

Other values for the variable are illegal and will cause the death test to fail.
Currently, the flag's default value is
**`"fast"`**.

If the death test statement runs to completion without dying, the child process
will nonetheless terminate, and the assertion fails.

Note that the piece of code under test can be a compound statement, for example:

```cpp
EXPECT_DEATH({
  int n = 5;
  DoSomething(&n);
}, "Error on line .* of DoSomething()");
```

### EXPECT_DEATH {#EXPECT_DEATH}

`EXPECT_DEATH(`*`statement`*`,`*`matcher`*`)` \
`ASSERT_DEATH(`*`statement`*`,`*`matcher`*`)`

Verifies that *`statement`* causes the process to terminate with a nonzero exit
status and produces `stderr` output that matches *`matcher`*.

The parameter *`matcher`* is either a [matcher](matchers.md) for a `const
std::string&`, or a regular expression (see
[Regular Expression Syntax](../advanced.md#regular-expression-syntax))—a bare
string *`s`* (with no matcher) is treated as
[`ContainsRegex(s)`](matchers.md#string-matchers), **not**
[`Eq(s)`](matchers.md#generic-comparison).

For example, the following code verifies that calling `DoSomething(42)` causes
the process to die with an error message that contains the text `My error`:

```cpp
EXPECT_DEATH(DoSomething(42), "My error");
```

### EXPECT_DEATH_IF_SUPPORTED {#EXPECT_DEATH_IF_SUPPORTED}

`EXPECT_DEATH_IF_SUPPORTED(`*`statement`*`,`*`matcher`*`)` \
`ASSERT_DEATH_IF_SUPPORTED(`*`statement`*`,`*`matcher`*`)`

If death tests are supported, behaves the same as
[`EXPECT_DEATH`](#EXPECT_DEATH). Otherwise, verifies nothing.

### EXPECT_DEBUG_DEATH {#EXPECT_DEBUG_DEATH}

`EXPECT_DEBUG_DEATH(`*`statement`*`,`*`matcher`*`)` \
`ASSERT_DEBUG_DEATH(`*`statement`*`,`*`matcher`*`)`

In debug mode, behaves the same as [`EXPECT_DEATH`](#EXPECT_DEATH). When not in
debug mode (i.e. `NDEBUG` is defined), just executes *`statement`*.

### EXPECT_EXIT {#EXPECT_EXIT}

`EXPECT_EXIT(`*`statement`*`,`*`predicate`*`,`*`matcher`*`)` \
`ASSERT_EXIT(`*`statement`*`,`*`predicate`*`,`*`matcher`*`)`

Verifies that *`statement`* causes the process to terminate with an exit status
that satisfies *`predicate`*, and produces `stderr` output that matches
*`matcher`*.

The parameter *`predicate`* is a function or functor that accepts an `int` exit
status and returns a `bool`. GoogleTest provides two predicates to handle common
cases:

```cpp
// Returns true if the program exited normally with the given exit status code.
::testing::ExitedWithCode(exit_code);

// Returns true if the program was killed by the given signal.
// Not available on Windows.
::testing::KilledBySignal(signal_number);
```

The parameter *`matcher`* is either a [matcher](matchers.md) for a `const
std::string&`, or a regular expression (see
[Regular Expression Syntax](../advanced.md#regular-expression-syntax))—a bare
string *`s`* (with no matcher) is treated as
[`ContainsRegex(s)`](matchers.md#string-matchers), **not**
[`Eq(s)`](matchers.md#generic-comparison).

For example, the following code verifies that calling `NormalExit()` causes the
process to print a message containing the text `Success` to `stderr` and exit
with exit status code 0:

```cpp
EXPECT_EXIT(NormalExit(), testing::ExitedWithCode(0), "Success");
```
# Matchers Reference

A **matcher** matches a *single* argument. You can use it inside `ON_CALL()` or
`EXPECT_CALL()`, or use it to validate a value directly using two macros:

| Macro                                | Description                           |
| :----------------------------------- | :------------------------------------ |
| `EXPECT_THAT(actual_value, matcher)` | Asserts that `actual_value` matches `matcher`. |
| `ASSERT_THAT(actual_value, matcher)` | The same as `EXPECT_THAT(actual_value, matcher)`, except that it generates a **fatal** failure. |

{: .callout .note}
**Note:** Although equality matching via `EXPECT_THAT(actual_value,
expected_value)` is supported, prefer to make the comparison explicit via
`EXPECT_THAT(actual_value, Eq(expected_value))` or `EXPECT_EQ(actual_value,
expected_value)`.

Built-in matchers (where `argument` is the function argument, e.g.
`actual_value` in the example above, or when used in the context of
`EXPECT_CALL(mock_object, method(matchers))`, the arguments of `method`) are
divided into several categories. All matchers are defined in the `::testing`
namespace unless otherwise noted.

## Wildcard

Matcher                     | Description
:-------------------------- | :-----------------------------------------------
`_`                         | `argument` can be any value of the correct type.
`A<type>()` or `An<type>()` | `argument` can be any value of type `type`.

## Generic Comparison

| Matcher                | Description                                         |
| :--------------------- | :-------------------------------------------------- |
| `Eq(value)` or `value` | `argument == value`                                 |
| `Ge(value)`            | `argument >= value`                                 |
| `Gt(value)`            | `argument > value`                                  |
| `Le(value)`            | `argument <= value`                                 |
| `Lt(value)`            | `argument < value`                                  |
| `Ne(value)`            | `argument != value`                                 |
| `IsFalse()`            | `argument` evaluates to `false` in a Boolean context. |
| `IsTrue()`             | `argument` evaluates to `true` in a Boolean context. |
| `IsNull()`             | `argument` is a `NULL` pointer (raw or smart).      |
| `NotNull()`            | `argument` is a non-null pointer (raw or smart).    |
| `Optional(m)`          | `argument` is `optional<>` that contains a value matching `m`. (For testing whether an `optional<>` is set, check for equality with `nullopt`. You may need to use `Eq(nullopt)` if the inner type doesn't have `==`.)|
| `VariantWith<T>(m)`    | `argument` is `variant<>` that holds the alternative of type T with a value matching `m`. |
| `Ref(variable)`        | `argument` is a reference to `variable`.            |
| `TypedEq<type>(value)` | `argument` has type `type` and is equal to `value`. You may need to use this instead of `Eq(value)` when the mock function is overloaded. |

Except `Ref()`, these matchers make a *copy* of `value` in case it's modified or
destructed later. If the compiler complains that `value` doesn't have a public
copy constructor, try wrap it in `std::ref()`, e.g.
`Eq(std::ref(non_copyable_value))`. If you do that, make sure
`non_copyable_value` is not changed afterwards, or the meaning of your matcher
will be changed.

`IsTrue` and `IsFalse` are useful when you need to use a matcher, or for types
that can be explicitly converted to Boolean, but are not implicitly converted to
Boolean. In other cases, you can use the basic
[`EXPECT_TRUE` and `EXPECT_FALSE`](assertions.md#boolean) assertions.

## Floating-Point Matchers {#FpMatchers}

| Matcher                          | Description                        |
| :------------------------------- | :--------------------------------- |
| `DoubleEq(a_double)`             | `argument` is a `double` value approximately equal to `a_double`, treating two NaNs as unequal. |
| `FloatEq(a_float)`               | `argument` is a `float` value approximately equal to `a_float`, treating two NaNs as unequal. |
| `NanSensitiveDoubleEq(a_double)` | `argument` is a `double` value approximately equal to `a_double`, treating two NaNs as equal. |
| `NanSensitiveFloatEq(a_float)`   | `argument` is a `float` value approximately equal to `a_float`, treating two NaNs as equal. |
| `IsNan()`   | `argument` is any floating-point type with a NaN value. |

The above matchers use ULP-based comparison (the same as used in googletest).
They automatically pick a reasonable error bound based on the absolute value of
the expected value. `DoubleEq()` and `FloatEq()` conform to the IEEE standard,
which requires comparing two NaNs for equality to return false. The
`NanSensitive*` version instead treats two NaNs as equal, which is often what a
user wants.

| Matcher                                           | Description              |
| :------------------------------------------------ | :----------------------- |
| `DoubleNear(a_double, max_abs_error)`             | `argument` is a `double` value close to `a_double` (absolute error <= `max_abs_error`), treating two NaNs as unequal. |
| `FloatNear(a_float, max_abs_error)`               | `argument` is a `float` value close to `a_float` (absolute error <= `max_abs_error`), treating two NaNs as unequal. |
| `NanSensitiveDoubleNear(a_double, max_abs_error)` | `argument` is a `double` value close to `a_double` (absolute error <= `max_abs_error`), treating two NaNs as equal. |
| `NanSensitiveFloatNear(a_float, max_abs_error)`   | `argument` is a `float` value close to `a_float` (absolute error <= `max_abs_error`), treating two NaNs as equal. |

## String Matchers

The `argument` can be either a C string or a C++ string object:

| Matcher                 | Description                                        |
| :---------------------- | :------------------------------------------------- |
| `ContainsRegex(string)` | `argument` matches the given regular expression.   |
| `EndsWith(suffix)`      | `argument` ends with string `suffix`.              |
| `HasSubstr(string)`     | `argument` contains `string` as a sub-string.      |
| `IsEmpty()`             | `argument` is an empty string.                     |
| `MatchesRegex(string)`  | `argument` matches the given regular expression with the match starting at the first character and ending at the last character. |
| `StartsWith(prefix)`    | `argument` starts with string `prefix`.            |
| `StrCaseEq(string)`     | `argument` is equal to `string`, ignoring case.    |
| `StrCaseNe(string)`     | `argument` is not equal to `string`, ignoring case. |
| `StrEq(string)`         | `argument` is equal to `string`.                   |
| `StrNe(string)`         | `argument` is not equal to `string`.               |

`ContainsRegex()` and `MatchesRegex()` take ownership of the `RE` object. They
use the regular expression syntax defined
[here](../advanced.md#regular-expression-syntax). All of these matchers, except
`ContainsRegex()` and `MatchesRegex()` work for wide strings as well.

## Container Matchers

Most STL-style containers support `==`, so you can use `Eq(expected_container)`
or simply `expected_container` to match a container exactly. If you want to
write the elements in-line, match them more flexibly, or get more informative
messages, you can use:

| Matcher                                   | Description                      |
| :---------------------------------------- | :------------------------------- |
| `BeginEndDistanceIs(m)` | `argument` is a container whose `begin()` and `end()` iterators are separated by a number of increments matching `m`. E.g. `BeginEndDistanceIs(2)` or `BeginEndDistanceIs(Lt(2))`. For containers that define a `size()` method, `SizeIs(m)` may be more efficient. |
| `ContainerEq(container)` | The same as `Eq(container)` except that the failure message also includes which elements are in one container but not the other. |
| `Contains(e)` | `argument` contains an element that matches `e`, which can be either a value or a matcher. |
| `Contains(e).Times(n)` | `argument` contains elements that match `e`, which can be either a value or a matcher, and the number of matches is `n`, which can be either a value or a matcher. Unlike the plain `Contains` and `Each` this allows to check for arbitrary occurrences including testing for absence with `Contains(e).Times(0)`. |
| `Each(e)` | `argument` is a container where *every* element matches `e`, which can be either a value or a matcher. |
| `ElementsAre(e0, e1, ..., en)` | `argument` has `n + 1` elements, where the *i*-th element matches `ei`, which can be a value or a matcher. |
| `ElementsAreArray({e0, e1, ..., en})`, `ElementsAreArray(a_container)`, `ElementsAreArray(begin, end)`, `ElementsAreArray(array)`, or `ElementsAreArray(array, count)` | The same as `ElementsAre()` except that the expected element values/matchers come from an initializer list, STL-style container, iterator range, or C-style array. |
| `IsEmpty()` | `argument` is an empty container (`container.empty()`). |
| `IsSubsetOf({e0, e1, ..., en})`, `IsSubsetOf(a_container)`, `IsSubsetOf(begin, end)`, `IsSubsetOf(array)`, or `IsSubsetOf(array, count)` | `argument` matches `UnorderedElementsAre(x0, x1, ..., xk)` for some subset `{x0, x1, ..., xk}` of the expected matchers. |
| `IsSupersetOf({e0, e1, ..., en})`, `IsSupersetOf(a_container)`, `IsSupersetOf(begin, end)`, `IsSupersetOf(array)`, or `IsSupersetOf(array, count)` | Some subset of `argument` matches `UnorderedElementsAre(`expected matchers`)`. |
| `Pointwise(m, container)`, `Pointwise(m, {e0, e1, ..., en})` | `argument` contains the same number of elements as in `container`, and for all i, (the i-th element in `argument`, the i-th element in `container`) match `m`, which is a matcher on 2-tuples. E.g. `Pointwise(Le(), upper_bounds)` verifies that each element in `argument` doesn't exceed the corresponding element in `upper_bounds`. See more detail below. |
| `SizeIs(m)` | `argument` is a container whose size matches `m`. E.g. `SizeIs(2)` or `SizeIs(Lt(2))`. |
| `UnorderedElementsAre(e0, e1, ..., en)` | `argument` has `n + 1` elements, and under *some* permutation of the elements, each element matches an `ei` (for a different `i`), which can be a value or a matcher. |
| `UnorderedElementsAreArray({e0, e1, ..., en})`, `UnorderedElementsAreArray(a_container)`, `UnorderedElementsAreArray(begin, end)`, `UnorderedElementsAreArray(array)`, or `UnorderedElementsAreArray(array, count)` | The same as `UnorderedElementsAre()` except that the expected element values/matchers come from an initializer list, STL-style container, iterator range, or C-style array. |
| `UnorderedPointwise(m, container)`, `UnorderedPointwise(m, {e0, e1, ..., en})` | Like `Pointwise(m, container)`, but ignores the order of elements. |
| `WhenSorted(m)` | When `argument` is sorted using the `<` operator, it matches container matcher `m`. E.g. `WhenSorted(ElementsAre(1, 2, 3))` verifies that `argument` contains elements 1, 2, and 3, ignoring order. |
| `WhenSortedBy(comparator, m)` | The same as `WhenSorted(m)`, except that the given comparator instead of `<` is used to sort `argument`. E.g. `WhenSortedBy(std::greater(), ElementsAre(3, 2, 1))`. |

**Notes:**

*   These matchers can also match:
    1.  a native array passed by reference (e.g. in `Foo(const int (&a)[5])`),
        and
    2.  an array passed as a pointer and a count (e.g. in `Bar(const T* buffer,
        int len)` -- see [Multi-argument Matchers](#MultiArgMatchers)).
*   The array being matched may be multi-dimensional (i.e. its elements can be
    arrays).
*   `m` in `Pointwise(m, ...)` and `UnorderedPointwise(m, ...)` should be a
    matcher for `::std::tuple<T, U>` where `T` and `U` are the element type of
    the actual container and the expected container, respectively. For example,
    to compare two `Foo` containers where `Foo` doesn't support `operator==`,
    one might write:

    ```cpp
    MATCHER(FooEq, "") {
      return std::get<0>(arg).Equals(std::get<1>(arg));
    }
    ...
    EXPECT_THAT(actual_foos, Pointwise(FooEq(), expected_foos));
    ```

## Member Matchers

| Matcher                         | Description                                |
| :------------------------------ | :----------------------------------------- |
| `Field(&class::field, m)`       | `argument.field` (or `argument->field` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_. |
| `Field(field_name, &class::field, m)` | The same as the two-parameter version, but provides a better error message. |
| `Key(e)`                        | `argument.first` matches `e`, which can be either a value or a matcher. E.g. `Contains(Key(Le(5)))` can verify that a `map` contains a key `<= 5`. |
| `Pair(m1, m2)`                  | `argument` is an `std::pair` whose `first` field matches `m1` and `second` field matches `m2`. |
| `FieldsAre(m...)`                   | `argument` is a compatible object where each field matches piecewise with the matchers `m...`. A compatible object is any that supports the `std::tuple_size<Obj>`+`get<I>(obj)` protocol. In C++17 and up this also supports types compatible with structured bindings, like aggregates. |
| `Property(&class::property, m)` | `argument.property()` (or `argument->property()` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_. The method `property()` must take no argument and be declared as `const`. |
| `Property(property_name, &class::property, m)` | The same as the two-parameter version, but provides a better error message.

**Notes:**

*   You can use `FieldsAre()` to match any type that supports structured
    bindings, such as `std::tuple`, `std::pair`, `std::array`, and aggregate
    types. For example:

    ```cpp
    std::tuple<int, std::string> my_tuple{7, "hello world"};
    EXPECT_THAT(my_tuple, FieldsAre(Ge(0), HasSubstr("hello")));

    struct MyStruct {
      int value = 42;
      std::string greeting = "aloha";
    };
    MyStruct s;
    EXPECT_THAT(s, FieldsAre(42, "aloha"));
    ```

*   Don't use `Property()` against member functions that you do not own, because
    taking addresses of functions is fragile and generally not part of the
    contract of the function.

## Matching the Result of a Function, Functor, or Callback

| Matcher          | Description                                       |
| :--------------- | :------------------------------------------------ |
| `ResultOf(f, m)` | `f(argument)` matches matcher `m`, where `f` is a function or functor. |

## Pointer Matchers

| Matcher                   | Description                                     |
| :------------------------ | :---------------------------------------------- |
| `Address(m)`              | the result of `std::addressof(argument)` matches `m`. |
| `Pointee(m)`              | `argument` (either a smart pointer or a raw pointer) points to a value that matches matcher `m`. |
| `Pointer(m)`              | `argument` (either a smart pointer or a raw pointer) contains a pointer that matches `m`. `m` will match against the raw pointer regardless of the type of `argument`. |
| `WhenDynamicCastTo<T>(m)` | when `argument` is passed through `dynamic_cast<T>()`, it matches matcher `m`. |

## Multi-argument Matchers {#MultiArgMatchers}

Technically, all matchers match a *single* value. A "multi-argument" matcher is
just one that matches a *tuple*. The following matchers can be used to match a
tuple `(x, y)`:

Matcher | Description
:------ | :----------
`Eq()`  | `x == y`
`Ge()`  | `x >= y`
`Gt()`  | `x > y`
`Le()`  | `x <= y`
`Lt()`  | `x < y`
`Ne()`  | `x != y`

You can use the following selectors to pick a subset of the arguments (or
reorder them) to participate in the matching:

| Matcher                    | Description                                     |
| :------------------------- | :---------------------------------------------- |
| `AllArgs(m)`               | Equivalent to `m`. Useful as syntactic sugar in `.With(AllArgs(m))`. |
| `Args<N1, N2, ..., Nk>(m)` | The tuple of the `k` selected (using 0-based indices) arguments matches `m`, e.g. `Args<1, 2>(Eq())`. |

## Composite Matchers

You can make a matcher from one or more other matchers:

| Matcher                          | Description                             |
| :------------------------------- | :-------------------------------------- |
| `AllOf(m1, m2, ..., mn)` | `argument` matches all of the matchers `m1` to `mn`. |
| `AllOfArray({m0, m1, ..., mn})`, `AllOfArray(a_container)`, `AllOfArray(begin, end)`, `AllOfArray(array)`, or `AllOfArray(array, count)` | The same as `AllOf()` except that the matchers come from an initializer list, STL-style container, iterator range, or C-style array. |
| `AnyOf(m1, m2, ..., mn)` | `argument` matches at least one of the matchers `m1` to `mn`. |
| `AnyOfArray({m0, m1, ..., mn})`, `AnyOfArray(a_container)`, `AnyOfArray(begin, end)`, `AnyOfArray(array)`, or `AnyOfArray(array, count)` | The same as `AnyOf()` except that the matchers come from an initializer list, STL-style container, iterator range, or C-style array. |
| `Not(m)` | `argument` doesn't match matcher `m`. |
| `Conditional(cond, m1, m2)` | Matches matcher `m1` if `cond` evalutes to true, else matches `m2`.|

## Adapters for Matchers

| Matcher                 | Description                           |
| :---------------------- | :------------------------------------ |
| `MatcherCast<T>(m)`     | casts matcher `m` to type `Matcher<T>`. |
| `SafeMatcherCast<T>(m)` | [safely casts](../gmock_cook_book.md#SafeMatcherCast) matcher `m` to type `Matcher<T>`. |
| `Truly(predicate)`      | `predicate(argument)` returns something considered by C++ to be true, where `predicate` is a function or functor. |

`AddressSatisfies(callback)` and `Truly(callback)` take ownership of `callback`,
which must be a permanent callback.

## Using Matchers as Predicates {#MatchersAsPredicatesCheat}

| Matcher                       | Description                                 |
| :---------------------------- | :------------------------------------------ |
| `Matches(m)(value)` | evaluates to `true` if `value` matches `m`. You can use `Matches(m)` alone as a unary functor. |
| `ExplainMatchResult(m, value, result_listener)` | evaluates to `true` if `value` matches `m`, explaining the result to `result_listener`. |
| `Value(value, m)` | evaluates to `true` if `value` matches `m`. |

## Defining Matchers

| Macro                                | Description                           |
| :----------------------------------- | :------------------------------------ |
| `MATCHER(IsEven, "") { return (arg % 2) == 0; }` | Defines a matcher `IsEven()` to match an even number. |
| `MATCHER_P(IsDivisibleBy, n, "") { *result_listener << "where the remainder is " << (arg % n); return (arg % n) == 0; }` | Defines a matcher `IsDivisibleBy(n)` to match a number divisible by `n`. |
| `MATCHER_P2(IsBetween, a, b, absl::StrCat(negation ? "isn't" : "is", " between ", PrintToString(a), " and ", PrintToString(b))) { return a <= arg && arg <= b; }` | Defines a matcher `IsBetween(a, b)` to match a value in the range [`a`, `b`]. |

**Notes:**

1.  The `MATCHER*` macros cannot be used inside a function or class.
2.  The matcher body must be *purely functional* (i.e. it cannot have any side
    effect, and the result must not depend on anything other than the value
    being matched and the matcher parameters).
3.  You can use `PrintToString(x)` to convert a value `x` of any type to a
    string.
4.  You can use `ExplainMatchResult()` in a custom matcher to wrap another
    matcher, for example:

    ```cpp
    MATCHER_P(NestedPropertyMatches, matcher, "") {
      return ExplainMatchResult(matcher, arg.nested().property(), result_listener);
    }
    ```
# Googletest Mocking (gMock) Framework

### Overview

Google's framework for writing and using C++ mock classes. It can help you
derive better designs of your system and write better tests.

It is inspired by:

*   [jMock](http://www.jmock.org/)
*   [EasyMock](http://www.easymock.org/)
*   [Hamcrest](http://code.google.com/p/hamcrest/)

It is designed with C++'s specifics in mind.

gMock:

-   Provides a declarative syntax for defining mocks.
-   Can define partial (hybrid) mocks, which are a cross of real and mock
    objects.
-   Handles functions of arbitrary types and overloaded functions.
-   Comes with a rich set of matchers for validating function arguments.
-   Uses an intuitive syntax for controlling the behavior of a mock.
-   Does automatic verification of expectations (no record-and-replay needed).
-   Allows arbitrary (partial) ordering constraints on function calls to be
    expressed.
-   Lets a user extend it by defining new matchers and actions.
-   Does not use exceptions.
-   Is easy to learn and use.

Details and examples can be found here:

*   [gMock for Dummies](https://google.github.io/googletest/gmock_for_dummies.html)
*   [Legacy gMock FAQ](https://google.github.io/googletest/gmock_faq.html)
*   [gMock Cookbook](https://google.github.io/googletest/gmock_cook_book.html)
*   [gMock Cheat Sheet](https://google.github.io/googletest/gmock_cheat_sheet.html)

Please note that code under scripts/generator/ is from the
[cppclean project](http://code.google.com/p/cppclean/) and under the Apache
License, which is different from GoogleMock's license.

GoogleMock is a part of
[GoogleTest C++ testing framework](http://github.com/google/googletest/) and a
subject to the same requirements.
# Content Moved

We are working on updates to the GoogleTest documentation, which has moved to
the top-level [docs](../../docs) directory.
# Customization Points

The custom directory is an injection point for custom user configurations.

## Header `gmock-port.h`

The following macros can be defined:

### Flag related macros:

*   `GMOCK_DECLARE_bool_(name)`
*   `GMOCK_DECLARE_int32_(name)`
*   `GMOCK_DECLARE_string_(name)`
*   `GMOCK_DEFINE_bool_(name, default_val, doc)`
*   `GMOCK_DEFINE_int32_(name, default_val, doc)`
*   `GMOCK_DEFINE_string_(name, default_val, doc)`
# Please Note:

Files in this directory are no longer supported by the maintainers. They
represent mostly historical artifacts and supported by the community only. There
is no guarantee whatsoever that these scripts still work.
### Generic Build Instructions

#### Setup

To build GoogleTest and your tests that use it, you need to tell your build
system where to find its headers and source files. The exact way to do it
depends on which build system you use, and is usually straightforward.

### Build with CMake

GoogleTest comes with a CMake build script
([CMakeLists.txt](https://github.com/google/googletest/blob/master/CMakeLists.txt))
that can be used on a wide range of platforms ("C" stands for cross-platform.).
If you don't have CMake installed already, you can download it for free from
<http://www.cmake.org/>.

CMake works by generating native makefiles or build projects that can be used in
the compiler environment of your choice. You can either build GoogleTest as a
standalone project or it can be incorporated into an existing CMake build for
another project.

#### Standalone CMake Project

When building GoogleTest as a standalone project, the typical workflow starts
with

```
git clone https://github.com/google/googletest.git -b release-1.11.0
cd googletest        # Main directory of the cloned repository.
mkdir build          # Create a directory to hold the build output.
cd build
cmake ..             # Generate native build scripts for GoogleTest.
```

The above command also includes GoogleMock by default. And so, if you want to
build only GoogleTest, you should replace the last command with

```
cmake .. -DBUILD_GMOCK=OFF
```

If you are on a \*nix system, you should now see a Makefile in the current
directory. Just type `make` to build GoogleTest. And then you can simply install
GoogleTest if you are a system administrator.

```
make
sudo make install    # Install in /usr/local/ by default
```

If you use Windows and have Visual Studio installed, a `gtest.sln` file and
several `.vcproj` files will be created. You can then build them using Visual
Studio.

On Mac OS X with Xcode installed, a `.xcodeproj` file will be generated.

#### Incorporating Into An Existing CMake Project

If you want to use GoogleTest in a project which already uses CMake, the easiest
way is to get installed libraries and headers.

*   Import GoogleTest by using `find_package` (or `pkg_check_modules`). For
    example, if `find_package(GTest CONFIG REQUIRED)` succeeds, you can use the
    libraries as `GTest::gtest`, `GTest::gmock`.

And a more robust and flexible approach is to build GoogleTest as part of that
project directly. This is done by making the GoogleTest source code available to
the main build and adding it using CMake's `add_subdirectory()` command. This
has the significant advantage that the same compiler and linker settings are
used between GoogleTest and the rest of your project, so issues associated with
using incompatible libraries (eg debug/release), etc. are avoided. This is
particularly useful on Windows. Making GoogleTest's source code available to the
main build can be done a few different ways:

*   Download the GoogleTest source code manually and place it at a known
    location. This is the least flexible approach and can make it more difficult
    to use with continuous integration systems, etc.
*   Embed the GoogleTest source code as a direct copy in the main project's
    source tree. This is often the simplest approach, but is also the hardest to
    keep up to date. Some organizations may not permit this method.
*   Add GoogleTest as a git submodule or equivalent. This may not always be
    possible or appropriate. Git submodules, for example, have their own set of
    advantages and drawbacks.
*   Use CMake to download GoogleTest as part of the build's configure step. This
    approach doesn't have the limitations of the other methods.

The last of the above methods is implemented with a small piece of CMake code
that downloads and pulls the GoogleTest code into the main build.

Just add to your `CMakeLists.txt`:

```cmake
include(FetchContent)
FetchContent_Declare(
  googletest
  # Specify the commit you depend on and update it regularly.
  URL https://github.com/google/googletest/archive/609281088cfefc76f9d0ce82e1ff6c30cc3591e5.zip
)
# For Windows: Prevent overriding the parent project's compiler/linker settings
set(gtest_force_shared_crt ON CACHE BOOL "" FORCE)
FetchContent_MakeAvailable(googletest)

# Now simply link against gtest or gtest_main as needed. Eg
add_executable(example example.cpp)
target_link_libraries(example gtest_main)
add_test(NAME example_test COMMAND example)
```

Note that this approach requires CMake 3.14 or later due to its use of the
`FetchContent_MakeAvailable()` command.

##### Visual Studio Dynamic vs Static Runtimes

By default, new Visual Studio projects link the C runtimes dynamically but
GoogleTest links them statically. This will generate an error that looks
something like the following: gtest.lib(gtest-all.obj) : error LNK2038: mismatch
detected for 'RuntimeLibrary': value 'MTd_StaticDebug' doesn't match value
'MDd_DynamicDebug' in main.obj

GoogleTest already has a CMake option for this: `gtest_force_shared_crt`

Enabling this option will make gtest link the runtimes dynamically too, and
match the project in which it is included.

#### C++ Standard Version

An environment that supports C++11 is required in order to successfully build
GoogleTest. One way to ensure this is to specify the standard in the top-level
project, for example by using the `set(CMAKE_CXX_STANDARD 11)` command. If this
is not feasible, for example in a C project using GoogleTest for validation,
then it can be specified by adding it to the options for cmake via the
`DCMAKE_CXX_FLAGS` option.

### Tweaking GoogleTest

GoogleTest can be used in diverse environments. The default configuration may
not work (or may not work well) out of the box in some environments. However,
you can easily tweak GoogleTest by defining control macros on the compiler
command line. Generally, these macros are named like `GTEST_XYZ` and you define
them to either 1 or 0 to enable or disable a certain feature.

We list the most frequently used macros below. For a complete list, see file
[include/gtest/internal/gtest-port.h](https://github.com/google/googletest/blob/master/googletest/include/gtest/internal/gtest-port.h).

### Multi-threaded Tests

GoogleTest is thread-safe where the pthread library is available. After
`#include "gtest/gtest.h"`, you can check the
`GTEST_IS_THREADSAFE` macro to see whether this is the case (yes if the macro is
`#defined` to 1, no if it's undefined.).

If GoogleTest doesn't correctly detect whether pthread is available in your
environment, you can force it with

    -DGTEST_HAS_PTHREAD=1

or

    -DGTEST_HAS_PTHREAD=0

When GoogleTest uses pthread, you may need to add flags to your compiler and/or
linker to select the pthread library, or you'll get link errors. If you use the
CMake script, this is taken care of for you. If you use your own build script,
you'll need to read your compiler and linker's manual to figure out what flags
to add.

### As a Shared Library (DLL)

GoogleTest is compact, so most users can build and link it as a static library
for the simplicity. You can choose to use GoogleTest as a shared library (known
as a DLL on Windows) if you prefer.

To compile *gtest* as a shared library, add

    -DGTEST_CREATE_SHARED_LIBRARY=1

to the compiler flags. You'll also need to tell the linker to produce a shared
library instead - consult your linker's manual for how to do it.

To compile your *tests* that use the gtest shared library, add

    -DGTEST_LINKED_AS_SHARED_LIBRARY=1

to the compiler flags.

Note: while the above steps aren't technically necessary today when using some
compilers (e.g. GCC), they may become necessary in the future, if we decide to
improve the speed of loading the library (see
<http://gcc.gnu.org/wiki/Visibility> for details). Therefore you are recommended
to always add the above flags when using GoogleTest as a shared library.
Otherwise a future release of GoogleTest may break your build script.

### Avoiding Macro Name Clashes

In C++, macros don't obey namespaces. Therefore two libraries that both define a
macro of the same name will clash if you `#include` both definitions. In case a
GoogleTest macro clashes with another library, you can force GoogleTest to
rename its macro to avoid the conflict.

Specifically, if both GoogleTest and some other code define macro FOO, you can
add

    -DGTEST_DONT_DEFINE_FOO=1

to the compiler flags to tell GoogleTest to change the macro's name from `FOO`
to `GTEST_FOO`. Currently `FOO` can be `ASSERT_EQ`, `ASSERT_FALSE`, `ASSERT_GE`,
`ASSERT_GT`, `ASSERT_LE`, `ASSERT_LT`, `ASSERT_NE`, `ASSERT_TRUE`,
`EXPECT_FALSE`, `EXPECT_TRUE`, `FAIL`, `SUCCEED`, `TEST`, or `TEST_F`. For
example, with `-DGTEST_DONT_DEFINE_TEST=1`, you'll need to write

    GTEST_TEST(SomeTest, DoesThis) { ... }

instead of

    TEST(SomeTest, DoesThis) { ... }

in order to define a test.
# Content Moved

We are working on updates to the GoogleTest documentation, which has moved to
the top-level [docs](../../docs) directory.
# Customization Points

The custom directory is an injection point for custom user configurations.

## Header `gtest.h`

### The following macros can be defined:

*   `GTEST_OS_STACK_TRACE_GETTER_` - The name of an implementation of
    `OsStackTraceGetterInterface`.
*   `GTEST_CUSTOM_TEMPDIR_FUNCTION_` - An override for `testing::TempDir()`. See
    `testing::TempDir` for semantics and signature.

## Header `gtest-port.h`

The following macros can be defined:

### Flag related macros:

*   `GTEST_FLAG(flag_name)`
*   `GTEST_USE_OWN_FLAGFILE_FLAG_` - Define to 0 when the system provides its
    own flagfile flag parsing.
*   `GTEST_DECLARE_bool_(name)`
*   `GTEST_DECLARE_int32_(name)`
*   `GTEST_DECLARE_string_(name)`
*   `GTEST_DEFINE_bool_(name, default_val, doc)`
*   `GTEST_DEFINE_int32_(name, default_val, doc)`
*   `GTEST_DEFINE_string_(name, default_val, doc)`
*   `GTEST_FLAG_GET(flag_name)`
*   `GTEST_FLAG_SET(flag_name, value)`

### Logging:

*   `GTEST_LOG_(severity)`
*   `GTEST_CHECK_(condition)`
*   Functions `LogToStderr()` and `FlushInfoLog()` have to be provided too.

### Threading:

*   `GTEST_HAS_NOTIFICATION_` - Enabled if Notification is already provided.
*   `GTEST_HAS_MUTEX_AND_THREAD_LOCAL_` - Enabled if `Mutex` and `ThreadLocal`
    are already provided. Must also provide `GTEST_DECLARE_STATIC_MUTEX_(mutex)`
    and `GTEST_DEFINE_STATIC_MUTEX_(mutex)`
*   `GTEST_EXCLUSIVE_LOCK_REQUIRED_(locks)`
*   `GTEST_LOCK_EXCLUDED_(locks)`

### Underlying library support features

*   `GTEST_HAS_CXXABI_H_`

### Exporting API symbols:

*   `GTEST_API_` - Specifier for exported symbols.

## Header `gtest-printers.h`

*   See documentation at `gtest/gtest-printers.h` for details on how to define a
    custom printer.
# Please Note:

Files in this directory are no longer supported by the maintainers. They
represent mosty historical artifacts and supported by the community only. There
is no guarantee whatsoever that these scripts still work.
Physical validation reference
=============================

`physical_validation` is a package aimed at testing results obtained
by molecular dynamics simulations for their physical validity.

Please check [http://physical_validation.readthedocs.io](http://physical_validation.readthedocs.io)
for the full reference.

`physical_validation` largely incorporates the functionality of
[checkensemble](https://github.com/shirtsgroup/checkensemble).

This software is developed in the Shirts group at University of 
Colorado in Boulder.

GROMACS-bundled version
-----------------------
The version of physical_validation shipped with GROMACS 
corresponds to commit 8b80492.
It requires
* numpy
* scipy
* pymbar
# Documentation strategy

## Documentation types

User documentation: Mostly extracted from the most user-facing module docstrings,
but curated in the framework of RST docs to facilitate organization of classes and
functions into sections, potentially mixing auto-extracted documentation with sample
documentation for proposed or incomplete features (to facilitate collaborative design
and code review).

User reference documentation: Function and class docstrings from the most user-facing public entities.

API reference: function and class documentation for public entities not included by
default in the top-level namespace. Should link to user docs when higher-level collaborators exist.

Design documentation and additional developer docs: module documentation for modules
not included in regular documentation.

Documentation for maintainers: static RST for versioning, releases, packaging, testing infrastructure, source code maintenance.

Note that the RST sources are also used by the GROMACS webpage-sphinx CMake target.
Dynamic selections {#page_selections}
==================

The \ref module_selection module provides a mechanism that allows selections
specified as text, and the engine evaluates them to atoms, or more generally to
a set of positions, for one or more sets of coordinates.  The selected atoms
can depend on the trajectory frame.  This allows writing general-purpose
analysis tools that only operate on positions, and get a lot of flexibility for
free from the selection engine.  For example, such tools can readily operate on
centers of mass of groups in addition to individual atoms as long as they do
not require access to atomic properties.

For people familiar with VMD, the selection syntax is quite familiar, but there
are some differences.  Not all the keywords supported by VMD are there, and
there are some extensions related to the support to evaluate to center-of-mass
positions in addition to individual atoms.
For old-time \Gromacs users, tools that support selections do not generally
need `make_ndx`.

Structural overview
===================

Central concepts useful for understanding the selection engine are explained
below.  A graph represents the relations between the different parts, and a
textual description of the user-visible components and other concepts follows.
The graph also includes an overview of how the selection engine integrates into
the \ref page_analysisframework.  When using selections from the analysis
framework, the parts in gray are managed by the framework.
When using selections outside the framework, it is either possible to use only
the core components (shown in the graph as a box), or to also use the selection
option mechanisms.  In both cases, the caller is responsible of managing all
the objects owned by the framework in the graph.

\dot
    digraph selection_overview {
        subgraph cluster_framework {
            label = "analysis framework"
            analysisframework [label="framework", fillcolor=grey75, style=filled]
            options [label="options collection", fillcolor=grey75, style=filled]
            analysistool [label="analysis tool"]
        }
        subgraph cluster_core {
            label = "core engine"
            labelloc = b
            selectioncollection [label="selection collection", fillcolor=grey75, style=filled]
            selectiondata [label="internal selection data", fillcolor=grey75, style=filled]
            selection [label="selection object"]
        }
        selectionoption [label="selection option"]
        selectionoptionmanager [label="selection option manager", fillcolor=grey75, style=filled]

        selectioncollection -> selection [label="creates"]
        selectioncollection -> selectiondata [label="owns and updates"]
        selectionoption -> selection [label="returns"]
        selection -> selectiondata [label="reads data", constraint=false]
        selectionoptionmanager -> selectionoption [label="provides values to"]
        selectionoptionmanager -> selectioncollection [label="gets selection objects"]
        analysistool -> selectionoption [label="declares"]
        analysistool -> selection [label="reads data from"]
        analysistool -> options [label="declares options"]
        analysisframework -> selectionoptionmanager [label="owns"]
        analysisframework -> selectioncollection [label="owns"]
        analysisframework -> options [label="owns"]
        options -> selectionoption [label="contains"]
    }
\enddot

 - _selection_: Evaluates to a single list of _selection positions_.
   Note in particular that the output is positions, not a list of atoms.
   A tool can accept one or more selections, and expect different semantics for
   different selections.
 - _dynamic selection_: The word _dynamic_ refers to selections for which the
   set of positions (instead of only the positions themselves) depends on the
   input coordinates.
 - _selection position_: A single coordinate as returned by a selection.
   This can correspond to an individual atom, but also to a collective
   coordinate such as a center of mass of a group of atoms.
   In addition to the output coordinates, the position provides information
   about the atoms that constitute it, and metadata that allows one to
   associate positions between different frames if different positions
   are returned at the same time.
 - _selection collection_: Group of selections that are processed as a unit
   against the same topology and sets of coordinates.
   In the analysis framework, there is always a single selection collection
   managed by the framework.
 - _selection variable_: When providing selections through text, it is possible
   to create variables and use them as part of selections.  This makes it
   easier to write repetitive selections by making complex common
   subexpressions into variables.  This also provides optimization
   opportunities for the selection engine: the variable value is not repeatedly
   evaluated.  Variables always exist in the context of a selection collection.
 - _selection object_: When a selection is _parsed_ (see below), the selection
   collection gives a handle to the selection as a _selection object_.  This
   handle is valid for the lifetime of the selection collection, and can be
   used to access information about the selection.  Operations on the selection
   collection (_compilation_ and _evaluation_, see below) alter the values
   returned by the selection objects.
 - _selection option_: A special type of command-line option that directly
   returns selection objects.  This higher-level construct is used by the
   analysis framework to provide a convenient interface for analysis tools:
   they can simply declare one or more selection options, and get a list of
   _selection objects_ as a return value for each of these.  Other parts of the
   selection engine are managed by the framework.

Core selection engine
=====================

The core of the selection engine is the _selection collection_ object.
The graph below shows how it handles selections.  The operations that the
collection object supports and their sequence is shown in the boxes in the
middle.  Inputs are shown at top, and outputs at the bottom.

\dot
    digraph selection_process {
        subgraph cluster_collection {
            label = "selection collection"
            subgraph actions {
                rank = same
                create [shape=box]
                parse [shape=box]
                compile [shape=box]
                evaluate [shape=box]
                evaluatefinal [label="finish evaluation",shape=box]

                create -> parse
                parse:ne -> parse:nw
                parse -> compile
                compile -> evaluate
                evaluate:ne -> evaluate:nw
                evaluate -> evaluatefinal
            }
            selectiondata [label="internal selection data"]
        }

        selectiontext [label="selection text"]
        topology [label="topology/\natom count"]
        frame [label="frame coordinates"]

        selection [label="selection object"]

        selectiontext -> parse
        parse:s -> selection:nw [label="returns"]
        parse -> selectiondata [label="creates"]
        topology -> compile
        compile -> selectiondata [label="initializes\npositions"]
        frame -> evaluate
        evaluate -> selectiondata [label="sets\npositions"]
        evaluatefinal -> selectiondata [label="resets to\npost-compilation\nstate"]
        selectiondata -> selection [label="reads data", dir=back]
    }
\enddot

 - _parsing_: after creating an empty selection collection,
   selections need to be parsed from text.  As a result, the selection
   collection initializes an internal data object to hold some basic
   information about the selections, and returns _selection objects_ as a
   handle to this data.  It is possible to parse more than one set of
   selections into the same collection by calling the parsing methods more than
   once.  The input string to parsing can also contain variable declarations,
   which get added into the collection and can be used in later calls to the
   parser.

 - _compilation_: when all selections are parsed, the whole selection
   collection is compiled.  This analyzes the provided selections, and
   evaluates all parts that do not depend on atom coordinates (e.g.,
   (sub)selections based on atom or residue names).  After compilation,
   the coordinates in the output positions are not initialized, but all other
   information is initialized as if all atoms satisfied any dynamic conditions.
   This means that any subsequent evaluation will return a subset of the
   positions returned at this point.  The caller can use this information to
   check the selections for validity and allocate memory for its own
   processing.
   Compilation also allocates all the memory necessary to do the evaluation.

   In the figure, topology is shown as input to the compilation, but generally
   it can be set at any point before the compilation.  If the selection text
   does not require any information from the topology for evaluation, it is
   sufficient to set only the atom count.

 - _evaluation_: after the selections are compiled, they can be evaluated for
   one or more sets of atom coordinates.  This updates the set of positions
   accessible through the selection objects.  For dynamic selections, the group
   of positions can change; for static selections, only the coordinates of the
   positions are updated.

 - _final evaluation_: This returns the selections to the state they were after
   compilation, i.e., to the maximum possible set of positions.  The
   coordinates of the positions are again uninitialized, but other information
   is available.  The caller can use this information to do post-processing
   and, e.g., produce labels in its output based on the selection positions.

\if internal
Internal implementation
=======================

Implementation details of different parts of the module are discussed on
separate pages.

  - \subpage page_module_selection_custom
  - \subpage page_module_selection_parser
  - \subpage page_module_selection_compiler
  - \subpage page_module_selection_insolidangle
\endif
Using \Gromacs as a library {#page_usinglibrary}
===========================

Getting started
===============

The \Gromacs library (`libgromacs`) provides a few different alternatives for
using it.  These are listed here from the highest level of abstraction to the
low-level functions.
 - If you are writing a trajectory analysis tool, please see
   \ref page_analysisframework.  \ref page_analysistemplate should contain
   all the ingredients to get started.
   If you have an existing tool written using the analysis template from 4.5 or
   4.6 (using the selection engine added in 4.5), you need to do some
   conversion work to get this work with the new template.  This is mostly
   straightforward, but requires some studying to understand the new framework.
 - If you are writing a command line tool for some other purpose, you can use
   the facilities provided by \ref module_commandline.  There are a few
   different alternatives, depending on how much control you want to give
   \Gromacs:
    - For C++ code, you can implement gmx::ICommandLineOptionsModule and
      use gmx::runCommandLineModule() to execute it.  This interface assumes
      the use of the gmx::Options mechanism for declaring command-line options
      (see \ref module_options).
      For a lower-level interface, gmx::ICommandLineModule can be used,
      but this requires you to implement `-h` output and command-line parsing
      yourself (possibly using classes that \Gromacs provides).
    - For C code, you can use gmx_run_cmain() to wrap an existing C main
      method.  The only constraint on the provided main method is that it
      should use parse_common_args() for argument processing.
      This approach should allow you to convert existing C tools written
      against pre-5.0 \Gromacs (e.g., using the analysis template from 4.0 or
      earlier) to the new version.
    - If you want more control (for example, you do not want the default
      command line options added by \Gromacs), you can directly initialize
      \Gromacs using gmx::initForCommandLine() before calling other \Gromacs
      routines.  This allows you to write your own handling for command line
      options from scratch.  This is also discussed in \ref module_commandline.
 - For most control, you can use gmx::init() to do basic initialization, create
   your own implementation for gmx::IProgramContext, and set that using
   gmx::setProgramContext().  This allows you to customize how the \Gromacs
   library shows the name of the program in messages, as well as how it locates
   its own data files.

If these do not fit your needs, you may need to modify the \Gromacs source code
yourself.  In particular, it is currently relatively difficult to extend the
functionality of `mdrun` without modifying the source code directly.
If you think that some particular API would be necessary for your work, and
think that it would be easy to expose, please drop a line on the
`gmx-developers` mailing list, or contribute the necessary changes on
http://gerrit.gromacs.org/.

Linking against `libgromacs`
============================

\Gromacs is a bit picky on how the headers need to be used: depending on
compilation options used for \Gromacs, some preprocessor defines may need to be
set, the required include path may also depend on compilation options, and some
extra libraries may need to be linked.  You will also likely need to use the
same compiler (or sufficiently similar one that uses the same standard library)
that was used to compile \Gromacs.

To manage this more easily, \Gromacs provides two mechanisms for getting the
correct flags for compilation and linking against the \Gromacs library:
 - `pkg-config`: \Gromacs installs `libgromacs.pc` file (suffixed with the
   library suffix) for use with `pkg-config` if that is present on the system.
   Sourcing `GMXRC` adjusts the `pkg-config` search path such that these files
   are found automatically.
   See `Makefile.pkg` installed with the analysis template for one example of
   how to use it (to use it with a differently suffixed \Gromacs, just replace
   `libgromacs` with `libgromacs`<em>_suffix</em> in the `pkg-config` calls).
 - CMake package configuration files and a find module that allow
   `find_package(GROMACS)` to work.  See below for details about how to use
   this in CMake.  Sourcing `GMXRC` sets an environment variable that allows
   CMake to find the configuration file automatically.
   See `CMakeLists.txt` installed with the analysis template for one example of
   how to use it.

These mechanisms are currently provided on a best-effort basis, but are not
routinely tested on a wide range of configurations.  Please report any issues
with details of how \Gromacs was built so that the mechanism can be improved.
Known issues:
 - `pkg-config` files are not relocatable, i.e., they hard-code the
   installation prefix as an absolute path.
 - Installing both static and shared libraries with the same suffix to the same
   installation prefix is guaranteed to work only if both are built with
   exactly the same configuration options (except for `BUILD_SHARED_LIBS`) from
   exactly the same version.  There are several files that are shared between
   the installations in such a case, and the latter installation will overwrite
   those from the former.
 - Further, if both static and shared libraries have been installed in the past
   to a prefix, then future installations to the same prefix should also
   install both static and shared libraries.  Otherwise, some obsolete CMake
   package configuration files will be left behind which can lead to finding
   the old library.  Alternatively, you can delete `share/cmake/` from the
   installation directory before doing the install.
 - If a mechanism other than the CMake-generated `install` target is used to
   install \Gromacs over an existing installation, and the build type (e.g.,
   Release vs.\ Debug) does not match what was previously installed, some
   obsolete CMake import target definition files are left behind in
   `share/cmake/`, and may cause failures whey trying to use the package
   configuration files.
 - If \Gromacs is built with `GMX_BUILD_OWN_FFTW=ON`, the CMake-generated
   import definitions for `libgromacs` reference a `gmxfftw` target that was
   used in the build to reference the `fftw` library.  As this library only
   exists in the \Gromacs build tree, and the CMake machinery does not write
   any import definitions for it anywhere, linking will fail with errors about
   not being able to find a `gmxfftw` library.  So the CMake package
   configuration files can only be used with `GMX_BUILD_OWN_FFTW=OFF`.

CMake `find_package(GROMACS)` details
-------------------------------------

The CMake machinery to support `find_package(GROMACS)` has two parts: a
`FindGROMACS.cmake` find module (found in `share/gromacs/template/cmake/` in
the installation and `share/template/cmake/` in the source tree), and actual
package configuration files (`gromacs-config.cmake` and supporting files
installed to `share/cmake/` from input files in `src/gromacs/`).

`FindGROMACS.cmake` is a simple wrapper over the package configuration files,
providing a somewhat more convenient interface to the machinery that supports
multiple suffixed \Gromacs installations in the same installation prefix (see
`GROMACS_SUFFIX` variable below).  This file is intended to be version-agnostic
and remain both forward- and backward-compatible even between major \Gromacs
releases.  All version-specific information and the actual details about the
compilation and linking settings is in the package configuration files.
Build systems willing to utilize `FindGROMACS.cmake` can create a local copy of
it and use it like it is used in the installed
`share/gromacs/template/CMakeLists.txt`.
The package configuration files can also be used directly if desired, bypassing
`FindGROMACS.cmake`.

Input options for influencing what to find:

<dl>
<dt>`GROMACS_SUFFIX` (only for `FindGROMACS.cmake`)</dt>
<dd>This CMake variable can be set before calling `find_package(GROMACS)` to
specify the \Gromacs suffix to search for.  If not set, an unsuffixed version
is searched for.  If using the package configuration files directly, the suffix
must be set using `find_package(GROMACS NAMES gromacs<suffix>)`.</dd>
<dt>`GROMACS_PREFER_STATIC`</dt>
<dd>This CMake variable can be set before calling `find_package(GROMACS)` to
specify whether static or shared libraries are preferred if both are available.
It does not affect which \Gromacs installation is chosen, but if that
installation has both static and shared libraries available (installed from two
different builds with the same suffix), then this chooses the library to be
returned in `GROMACS_LIBRARIES`.</dd>
<dt>`GROMACS_DIR`</dt>
<dd>This CMake (cache) variable is a standard mechanism provided by
`find_package`, and can be used to specify a hint where to search for \Gromacs.
Also `CMAKE_PREFIX_PATH` can be used for this purpose; see CMake documentation
for `find_package` for more details.
`GROMACS_DIR` can also be set as an environment variable, and this is done by
`GMXRC`.</dd>
</dl>

Output variables that specify how the found `libgromacs` and header should be
used:

<dl>
<dt>`GROMACS_INCLUDE_DIRS`</dt>
<dd>List of include directories necessary to compile against the \Gromacs
headers.  Currently, this includes the path to \Gromacs headers.</dd>
<dt>`GROMACS_LIBRARIES`</dt>
<dd>List of libraries to link with to link against \Gromacs.
Under the hood, this uses imported CMake targets to represent `libgromacs`.</dd>
<dt>`GROMACS_DEFINITIONS`</dt>
<dd>List of compile definitions (with `-D` in front) that are required to
compile the \Gromacs headers.</dd>
<dt>`GROMACS_IS_DOUBLE`</dt>
<dd>Whether the found \Gromacs was compiled in double precision.</dd>
<dt>`GROMACS_CXX_FLAGS`</dt>
<dd>Required compiler flags.</dd>
</dl>

Additionally an imported target named `Gromacs::libgromacs` is provided and can
be used with `target_link_libraries(foo PRIVATE Gromacs::libgromacs)`.

Declared macros/functions that can be used for checking for correctness of some
settings:

<dl>
<dt>`gromacs_check_double(GMX_DOUBLE)`</dt>
<dd>Checks that the found \Gromacs is in the expected precision.
The parameter `GMX_DOUBLE` should be the name of a cache variable that
specified whether double-precision was requested.</dd>
<dt>`gromacs_check_compiler(LANG)`<dt>
<dd>Checks that the found \Gromacs was compiled with the same compiler
that is used by the current CMake system.
Currently only `LANG=CXX` is supported.</dd>
</dl>

Notes on \Gromacs API
=====================

The headers for the public \Gromacs API are installed in `include/gromacs/`
under the installation directory.  The layout reflects the source code layout
under the `src/gromacs/` directory (see \linktodevmanual{overview,dev-doc-layout,Source
code layout}).  The headers
directly under `include/gromacs/` do not contain any declarations, but instead
include a collection of headers from subdirectories.
You should prefer to include these convenience headers instead of individual
headers from the subdirectories, since they are much more stable.  The
individual headers in the subdirectories can be renamed or moved, but the goal
is to only rarely change the name of these top-level headers.

Pre-5.0 versions of \Gromacs installed (nearly) all headers directly under
`include/gromacs/`.  Most of these headers still exist, but are no longer
installed.  The long-term goal is to reintroduce those parts of the API that
make sense, but unfortunately this can take a long time.  Thus, you should not
expect much stability from the API in these headers.

For headers under other subdirectories, some effort has been put to design the
API for stability.  However, with limited development resources, and the focus
of \Gromacs being in high performance simulations, all the APIs are subject to
change without notice.  With each new release (with possible exception of patch
releases), you should expect incompatible API changes.

The header version.h (installed as `gromacs/version.h`) provides defines that
calling code can use to check the exact (released) version of \Gromacs that
installed the headers.

This Doxygen documentation only covers part of the API.
Framework for trajectory analysis {#page_analysisframework}
=================================

\Gromacs provides a framework for implementing flexible trajectory analysis
routines.  It consists of a few components that can also be used individually,
but in most cases it is desirable to use features from all of them to get most
out of the framework.  The main features are:

 - Support for flexible selections that can be used to provide the set of
   coordinates to analyze.  They can be dynamic, i.e., select different atoms
   for different trajectory frames, and also support evaluation of
   center-of-mass/center-of-geometry coordinates for a group of atoms.
   The latter means that a tool written to use the framework can automatically
   analyze also center-of-mass positions (or a mixture of center-of-mass and
   atomic positions) in addition to real atomic positions.
 - Support for per-frame parallelization.  The framework is designed to
   support running the analysis in parallel for multiple frames for cases where
   different frames can be analyzed (mostly) independently.  At this time, the
   actual parallelization is not implemented, but tools written to use the
   framework should be able to take advantage of it as soon as it materializes
   with no or minimal changes.
 - Access to a library of basic analysis routines.  Things such as computing
   averages and histogramming are provided as reusable modules.
 - Tool code can focus on the actual analysis.  Tools are implemented by
   subclassing an abstract class and providing an implementation for selected
   pure virtual methods.  The framework takes care of initialization tasks,
   loading the trajectory and looping over it, evaluating selections, and also
   provides basic features like making molecules whole before passing the frame
   to the analysis code.
   This approach also makes it possible to reuse the same tool code from a
   scripting language such as Python simply by implementing general support for
   such language bindings in the framework (no such integration is implemented
   at this time, though).

There are also some reusable analysis routines that can be used independent of
the framework:
 - \subpage page_analysisnbsearch

For a crash course on how to implement an analysis tool using the framework, see
\subpage page_analysistemplate.


High-level framework
====================

The \ref module_trajectoryanalysis module provides the high-level framework
that integrates all the pieces together.
It provides the abstract base class for analysis tool modules
(gmx::TrajectoryAnalysisModule), and the code that runs such a module as a
command-line tool (gmx::TrajectoryAnalysisCommandLineRunner).
See the [analysis template](\ref page_analysistemplate) and the
[trajectoryanalysis module documentation](\ref module_trajectoryanalysis) for
more details.


Selections
==========

The \ref module_selection module provides the support for selections.
Most of the work of managing the selections is taken care by the command-line
runner and the framework, and the analysis tool code only sees two main
classes:

 - gmx::SelectionOption and associated classes are used to declare the
   number and type of selections the tool accepts (see below for
   [details of the option support](#section_analysisframework_options)).
 - The tool receives a set of gmx::Selection objects as a value of the
   selection option.  These classes provide the evaluated values for the
   selections during the analysis.  The framework evaluates them for each
   frame such that when the tool is called, it can access the selections for
   the current frame in the gmx::Selection objects it owns.

A conceptual overview of the selection engine is available on a separate page:
\subpage page_selections.  In the full internal documentation, this page
also provides an overview of the implementation of the selections.

More technical details of the selection engine are also available in the
[selection module documentation](\ref module_selection).
This is useful in particular for understanding how the selections work in
detail, or if you want to use the selection code outside the trajectory
analysis framework.

The selection module also provides functionality to do neighborhood searching
in analysis tools.  For the most common case of full 3D periodic boundary
conditions, grid-based searching is implemented.  See gmx::AnalysisNeighborhood
for more details.  This class can be used independently of other selection
functionality.


Output data handling
====================

The \ref module_analysisdata module provides two things:

 - Support for uniformly providing output data from analysis tools.
   Tools compute their output values and place them into a
   _data object_ for further processing.  This allows two things:
     - Reusable data modules can be applied across different tools to do common
       post-processing.
     - The data object provides parallelization support.
 - Set of reusable data modules for post-processing the data.  These include
   functionality like averaging data, computing histograms, and plotting the
   data into a file.  Many of these modules also provide their output as a data
   object, allowing further data modules to be attached to them.

The general concept is explained in more detail on a separate page:
\subpage page_analysisdata.
The [analysisdata module documentation](\ref module_analysisdata) provides more
technical details.


Input options {#section_analysisframework_options}
=============

To declare input data for the tool (typically, command-line options, including
input files and selections), \ref module_options module is used.
The analysis tool code receives an instance of gmx::IOptionsContainer for one of
its initialization methods, and uses it to provide its input options.
Basic options are declared in basicoptions.h, and also gmx::SelectionOption is
used in the same manner.  For each option, the tool declares a local variable
that will receive the value for that option.  After the options are parsed from
the command line (by the framework), the tool code can read the values from
these variables.  The option declarations filled into the
gmx::IOptionsContainer object are also used to provide help to the user (also
handled by the framework).
See the documentation for gmx::TrajectoryAnalysisModule and the
[options module documentation](\ref module_options) for more details.

Coordinate data output
======================

The \ref module_coordinateio module allows modules to output coordinate data
used or generated during the analysis. It provides two main components:

 - An OutputManager for handling the file opening, writing, closing and
   registration of modules to change metainformation.
 - A set of modules to change the metainformation in coordinate data frames
   and to cross check the requirements for data output and file formats.

More detailed information, as well as an interaction diagram can be found in the
[module documentation](\ref module_coordinateio).
Example code for writing trajectory analysis tools {#page_analysistemplate}
==================================================

\Gromacs installation includes a template for writing trajectory analysis
tools using \ref page_analysisframework.
It can be found from `share/gromacs/template/` under the installation
directory, and from `share/template/` in the source distribution.

The full source code for the file is also included in this documentation:
\ref template.cpp "template.cpp"
The rest of this page walks through the code to explain the different parts.

\dontinclude template.cpp

Global definitions
==================

We start by including some generic C++ headers:
\skip  <string>
\until <vector>
and continue by including the header for the analysis library:
\skipline <gromacs/trajectoryanalysis.h>
This header includes other headers that together define all the basic data
types needed for writing trajectory analysis tools.
For convenience, we also import all names from the ::gmx namespace into the
global scope to avoid repeating the name everywhere:
\skipline using namespace


Tool module class declaration
=============================

We then define a class that implements our analysis tool:
\skip  AnalysisTemplate
\until };
The analysis tool class inherits from gmx::TrajectoryAnalysisModule, which
is an interface with a few convenience functions for easier interfacing
with other code.
Below, we walk through the different methods as implemented in the
template (note that the template does not implement some of the virtual
methods because they are less often needed), discussing some issues that can
arise in more complex cases.
See documentation of gmx::TrajectoryAnalysisModule for a full description of
the available virtual methods and convenience functions.
The first block of member variables are used to contain values provided to
the different options.  They will vary depending on the needs of the
analysis tool.
The AnalysisNeighborhood object provides neighborhood searching that is used
in the analysis.
The final block of variables are used to process output data.
See initAnalysis() for details on how they are used.

For the template, we do not need any custom frame-local data.  If you think
you need some for more complex analysis needs, see documentation of
gmx::TrajectoryAnalysisModuleData for more details.
If you do not care about parallelization, you do not need to consider this
part.  You can simply declare all variables in the module class itself,
initialize them in gmx::TrajectoryAnalysisModule::initAnalysis(), and do any
postprocessing in gmx::TrajectoryAnalysisModule::finishAnalysis()).


Construction
============

The constructor (and possible destructor) of the analysis module should be
simple: the constructor should just initialize default values, and the
destructor should free any memory managed by the module.  For the template,
we have no attributes in our class that need to be explicitly freed, so we
declare only a constructor:
\skip  AnalysisTemplate
\until }


Input options
=============

Initialization of the module is split into a few methods, two of which are
used in the template.  gmx::TrajectoryAnalysisModule::initOptions() is used
to set up options understood by the module, as well as for setting up
different options through gmx::TrajectoryAnalysisSettings (see the
documentation of that class for more details):
\skip  void
\until settings->
\until }
For the template, we first set a description text for the tool (used for
help text).  Then we declare an option to specify the output file name,
followed by options that are used to set selections, and finally an option
to set a cutoff value.  For the cutoff, the default value will be the one
that was set in the constructor, but it would also be possible to explicitly
set it here.  The values provided by the user for the options will be stored
in member variables.  Finally, we indicate that the tool always requires
topology information.  This is done for demonstration purposes only; the
code in the template works even without a topology.

For additional documentation on how to define different kinds of options, see
gmx::IOptionsContainer, basicoptions.h, and gmx::SelectionOption.  You only need to
define options that are specific to the analysis; common options, e.g., for
specifying input topology and trajectories are added by the framework.

To adjust settings or selection options (e.g., the number of accepted
selections) based on option values, you need to override
gmx::TrajectoryAnalysisModule::optionsFinished().  For simplicity,
this is not done in the template.


Analysis initialization
=======================

The actual analysis is initialized in
gmx::TrajectoryAnalysisModule::initAnalysis():
\skip  void
\until }
\until }
Information about the topology is passed as a parameter.  The settings
object can also be used to access information about user input.

One of the main tasks of this method is to set up appropriate
gmx::AnalysisData objects and modules for them (see
gmx::TrajectoryAnalysisModule for the general approach).
These objects will be used to process output from the tool.  Their main
purpose is to support parallelization, but even if you don't care about
parallelism, they still provide convenient building blocks, e.g., for
histogramming and file output.

For the template, we first set the cutoff for the neighborhood search.

Then, we create and register one gmx::AnalysisData object
that will contain, for each frame, one column for each input selection.
This will contain the main output from the tool: minimum distance between
the reference selection and that particular selection.
We then create and setup a module that will compute the average distance
for each selection (see writeOutput() for how it is used).
Finally, if an output file has been provided, we create and setup a module
that will plot the per-frame distances to a file.

If the analysis module needs some temporary storage during processing of a
frame (i.e., it uses a custom class derived from
gmx::TrajectoryAnalysisModuleData), this should be allocated in
gmx::TrajectoryAnalysisModule::startFrames() (see below) if parallelization
is to be supported.

If you need to do initialization based on data from the first frame (most
commonly, based on the box size), you need to override
gmx::TrajectoryAnalysisModule::initAfterFirstFrame(), but this is not used
in the template.


Analyzing the frames
====================

There is one more initialization method that needs to be overridden to
support automatic parallelization: gmx::TrajectoryAnalysisModule::startFrames().
If you do not need custom frame-local data (or parallelization at all), you
can skip this method and ignore the last parameter to
gmx::TrajectoryAnalysisModule::analyzeFrame() to make things simpler.
In the template, this method is not necessary.

The main part of the analysis is (in most analysis codes) done in the
gmx::TrajectoryAnalysisModule::analyzeFrame() method, which is called once
for each frame:
\skip  void
\until {
The \p frnr parameter gives a zero-based index of the current frame
(mostly for use with gmx::AnalysisData), \p pbc contains the PBC
information for the current frame for distance calculations with,
e.g., pbc_dx(), and \p pdata points to a data structure created in
startFrames().
Although usually not necessary (except for the time field), raw frame
data can be accessed through \p fr.
In most cases, the analysis should be written such that it gets all
position data through selections, and does not assume a constant size for
them.  This is all that is required to support the full flexibility of the
selection engine.

For the template, we first get data from our custom data structure for
shorthand access (if you use a custom data object, you need a \c static_cast
here):
\skip  AnalysisDataHandle
\until parallelSelection

We then do a simple calculation and use the AnalysisDataHandle class to set
the per-frame output for the tool:
\skip  nb
\until finishFrame()

After all the frames have been processed,
gmx::TrajectoryAnalysisModule::finishAnalysis() is called once.  This is the
place to do any custom postprocessing of the data.  For the template, we do
nothing, because all necessary processing is done in the data modules:
\skip  void
\until }

If the data structure created in gmx::TrajectoryAnalysisModule::startFrames()
is used to aggregate data across frames, you need to override
gmx::TrajectoryAnalysisModule::finishFrames() to combine the data from the
data structures (see documentation of the method for details).
This is not necessary for the template, because the ModuleData structure
only contains data used during the analysis of a single frame.


Output
======

Finally, most programs need to write out some values after the analysis is
complete.  In some cases, this can be achieved with proper chaining of data
modules, but often it is necessary to do some custom processing.
All such activities should be done in
gmx::TrajectoryAnalysisModule::writeOutput().  This makes it easier to reuse
analysis modules in, e.g., scripting languages, where output into files
might not be desired.  The template simply prints out the average distances
for each analysis group:
\skip  void
\until }
\until }
Here, we use the \c avem_ module, which we initialized in initAnalysis() to
aggregate the averages of the computed distances.


Definition of main()
====================

Now, the only thing remaining is to define the main() function.
To implement a command-line tool, it should create a module and run it using
gmx::TrajectoryAnalysisCommandLineRunner using the boilerplate code below:
\skip  int
\until }


\if libapi
Tools within \Gromacs
====================

Analysis tools implemented using the template can also be easily included into
the \Gromacs library.  To do this, follow these steps:

 1. Put your tool source code into `src/gromacs/trajectoryanalysis/modules/`.
 2. Remove `using namespace gmx;` and enclose all the code into
    `gmx::analysismodules` namespace, and the tool class into an unnamed
    namespace within this.
 3. Create a header file corresponding to your tool and add the following class
    into it withing `gmx::analysismodules` namespace (replace `Template` with
    the name of your tool):
~~~~{.cpp}
    class TemplateInfo
    {
        public:
            static const char name[];
            static const char shortDescription[];
            static TrajectoryAnalysisModulePointer create();
    };
~~~~
 4. Add definition for these items in the source file, outside the unnamed
    namespace (replace `Template`, `AnalysisTemplate` and the strings with
    correct values):
~~~~{.cpp}
    const char TemplateInfo::name[]             = "template";
    const char TemplateInfo::shortDescription[] =
        "Compute something";

    TrajectoryAnalysisModulePointer TemplateInfo::create()
    {
        return TrajectoryAnalysisModulePointer(new AnalysisTemplate);
    }
~~~~
 5. Register your module in `src/gromacs/trajectoryanalysis/modules.cpp`.
 6. Done.  Your tool can now be invoked as `gmx template`, using the string you
    specified as the name.

See existing tools within the `src/gromacs/trajectoryanalysis/modules/` for
concrete examples and preferred layout of the files.  Please document yourself
as the author of the files, using Doxygen comments like in the existing files.

\endif
Neighborhood search for analysis tools {#page_analysisnbsearch}
======================================

The header nbsearch.h declares a C++ interface to a relatively flexible and
efficient neighborhood search.  It is currently implemented within the
selection module where it originated, but it does not have any dependencies on
the other selection code and can be easily split out in the future.

The emphasis is on flexibility and ease of use; one main driver is to have
one common implementation of grid-based searching to avoid replicating this in
multiple tools (and to make more tools take advantage of the significant
performance improvement this allows).  The main features that it provides:

 - Grid-based searching with any triclinic box shape that \Gromacs supports
   (i.e., a triangular box matrix and not too skewed).
 - Grid-based searching with all PBC options except for screw boundary
   conditions.
 - With no PBC, grid-based searching where the grid is constructed based on the
   bounding box of the gridded atoms.
 - Efficient, rectangular grid cells whose size is determined by particle
   density and not limited by the cutoff.
 - Transparent fallback to a simple all-pairs search if the cutoff is too long
   for the algorithm or grid searching is not otherwise supported.
 - Support for either N-vs-M pair search with two sets of coordinates, or for
   all pairs within a single set of coordinates.
 - Support for computing all distances in the XY plane only (and still
   grid-based).
 - Convenience functions for finding the shortest distance or the nearest pair
   between two sets of positions.
 - Basic support for exclusions.
 - Thread-safe handling of multiple concurrent searches with the same cutoff
   with the same or different reference positions.

Usage
=====

The neighborhood search works conceptually with two different sets of
coordinates:

 - _reference positions_: When initiating the search, you provide one set of
   reference positions that get placed on the search grid and determine the
   size of the grid.
 - _test positions_: For each set of reference positions, you provide a set of
   test positions (or a single position).  The search is performed from each
   test position, finding the reference positions within the cutoff from this
   point.  It is possible to perform multiple searches against the same set of
   reference positions (and the same grid).

To start using the neighborhood search, you need to first create an instance of
gmx::AnalysisNeighborhood.  This class allows you to set some global properties
for the search (most notably, the cutoff distance).  Then you provide the
reference positions as a gmx::AnalysisNeighborhoodPositions and PBC information
to get a gmx::AnalysisNeighborhoodSearch instance.  You can then either use
methods directly in this class to find, e.g., the nearest reference point from
a test position, or you can do a full pair search that returns you all the
reference-test pairs within a cutoff.  The pair search is performed using an
instance of gmx::AnalysisNeighborhoodPairSearch that the search object returns.
Methods that return information about pairs return an instance of
gmx::AnalysisNeighborhoodPair, which can be used to access the indices of
the reference and test positions in the pair, as well as the computed distance.
See the class documentation for these classes for details.

For use together with selections, an instance of gmx::Selection or
gmx::SelectionPosition can be transparently passed as the positions for the
neighborhood search.

Implementation
==============

This section provides a high-level overview of the algorithm used.  It is not
necessary to understand all the details to use the API, but it can be useful to
get the best performance out of it.  The main audience is developers who may
need to extend the API to make it suitable for more cases.

The grid for the search is initialized based on the reference positions and the
PBC information:

 - The grid cells are always rectangular, even for fully triclinic boxes.
 - If there is no PBC, the grid edges are defined from the bounding box of the
   reference positions; with PBC, the grid covers the unit cell.
 - The grid cell size is determined such that on average, each cell contains
   ten particles.  Special considerations are in place for cases where the grid
   will only be one- or two-dimensional because of a flat box.
 - If the resulting grid has too few cells in some dimensions, the code
   falls back automatically to an all-pairs search.  For correct operation, the
   grid algorithm needs three cells in each dimension, but the code can fall
   back to a non-gridded search for each dimension separately.
 - The initialization also pre-calculates the shifts required across the
   periodic boundaries for triclinic cells, i.e., the fractional number of
   cells that the grid origin is shifted when crossing the periodic boundary in
   Y or Z directions.
 - Finally, all the reference positions are mapped to the grid cells.

The average number of particles within a cell is somewhat heuristic in the
above logic.  This has not been particularly optimized for best performance.

When doing the search for test positions, each test position is considered
independently:

 - The coordinates of the test position are mapped to the grid coordinate
   system.  The coordinates here are fractional and may lay outside the grid
   for non-periodic dimensions.
 - The bounding box of the cutoff sphere centered at the mapped coordinates is
   determined, and each grid cell that intersects with this box is used for
   searching the reference positions.  So the searched grid cells may vary
   depending on the coordinates of the test position, even if the test position
   is within the same cell.
 - Possible triclinic shifts in the grid are considered when looping over the
   cells in the cutoff box if the coordinates wrap around a periodic dimension.
   This is done by shifting the search range in the other dimensions when the Z
   or Y dimension loop crosses the boundary.
Help formatting {#page_onlinehelp}
===============

Some parts of \Gromacs use in-source strings as a documentation source.  The
most notable use of these is the description and options list printed out by
the `-h` command line, and this case is exposed also to code that uses \Gromacs
as a library to write command-line tools.  The help text is declared as an
array of strings:

    const char *const desc[] = {
        "First paragraph.",
        "",
        "Second paragraph",
        "with more text",
        "and [TT]some formatting[tt].",
    };

The array variable is then passed to a function that exposes it as the help
text.  Some of the help content is also generated based on, e.g., the list of
options that the program declares.

The same approach is also used internally in \Gromacs in a few other places.
The same help text is used for console output (like in the `-h` case), as well
as for producing reStructuredText.  The reStructuredText output is passed to
Sphinx to produce a HTML user guide and Unix man pages.

Formatting markup
=================

Partly due to historical reasons, the markup allowed within the help text is a
mixture of reStructuredText and \Gromacs-specific markup.  The allowed
formatting is currently not that extensive, but basic constructs should work.

The general approach to formatting is that the text is written to
reStructuredText as-is, after replacement of the \Gromacs-specific markup, with
line breaks between each string in the input array.  This means that the commas
at the end of each line (separating the strings) are critical for proper
formatting.  This also means that any reStructuredText construct will appear
correctly in the HTML and man pages (as long as the output format supports it).

For console output, there input string is parsed for some basic
reStructuredText constructs to be able to rewrap the text to the console width
(currently fixed at 78 characters).  This parsing is one major constraint on
what reStructuredText constructs can be used; paragraph-level markup that is
not recognized by this parser results in messy console output.  Inline markup
is currently not processed in any way, so any construct that renders reasonably
in plain text can in principle be used.

reStructuredText
----------------

The following reStructuredText constructs are recognized and work for console
output:
 - Paragraphs, i.e., blocks of text separated by an empty line.  Text within
   each paragraph is wrapped separately, and indentation is preserved (as long
   as the whole paragraph has the same indentation level, which is expected for
   reStructuredText).  This means that block quotes are also rendered
   reasonably, since they are just indented paragraphs.
 - Literal blocks, i.e., indented paragraphs where the preceding paragraph ends
   with `::`.  Line breaks within such paragraphs are preserved.  The rules for
   handling the `::` are the same as in reStructuredText.
   Multiple paragraphs within a literal block are not currently supported.
 - Titles, i.e., a line underlined by a punctuation character.
   Title formatting is currently preserved as-is, so it must be manually
   ensured that the used punctuation character properly fits into the context
   (i.e., other titles in the same generated reStructuredText document).
   Titles with both under- and overline are not currently supported.
 - Bullet lists.  Only lists that start with `*` are currently recognized.
   Indentation for the second and subsequent lines is determined from
   the first non-space character after the bullet and/or from the second line
   in the input (if these are not the same, the minimum is used).
   Note that in reStructuredText, the `*` must not be indented with respect to
   the preceding paragraph; otherwise, the bullet list is rendered within a
   block quote.  Also, an empty line needs to precede a bullet list.
 - Enumerated lists.  Only lists that start with digits are supported (e.g.,
   `1.`).  Multi-digit numbers can be used.
   Indentation is determined as for bullet lists.
   Lists are not renumbered automatically.

\Gromacs-specific markup
------------------------

Markup within paragraphs is currently done with \Gromacs-specific constructs
limited with brackets.  In the future, some of these may get replaced with more
reStructuredText constructs.  The following are used:
 - `[TT]`/`[tt]`: text between these tags is formatted in a monospace font.
 - `[BB]`/`[bb]`: text between these tags is formatted in a bold font.
 - `[IT]`/`[it]`: text between these tags is formatted in an italic font.
 - `[MAG]`/`[mag]`: text between these tags is rendered between `|` (bar)
   characters (which is a special character in reStructuredText).
 - `[PAR]`: this is replaced by two newlines to produce a paragraph break.
   For any new help text, an explicit empty line is preferred.
Various other markup constructs, mainly related to math, are also used in some
places, but currently these are always replaced with the same text irrespective
of the output format, and a new approach is needed for proper math support.

Additionally, the following replacements are possible (not necessarily in all
contexts):
 - `[REF]`/`[ref]`: replaced with a link to a section that describes the term
   between these tags.  Only affects the reStructuredText output; the tags are
   simply removed from console output.
   The mechanism for managing these crosslinks would need additional work.
 - `[THISMODULE]`: replaced with the name of the current module/command
   (e.g., `gmx angle`).
 - `[PROGRAM]`: replaced with the name of the current executable (e.g., `gmx`).

\if libapi
Implementation
==============

See \ref module_onlinehelp module documentation for implementation details.

See \ref page_wrapperbinary for details of how the reStructuredText help is
exported and processed further.
\endif
Analysis output data handling {#page_analysisdata}
=============================

The \ref module_analysisdata module provides support for common data analysis
tasks within the \ref page_analysisframework.  The basic approach used in the
module is visualized below:

\dot
  digraph analysisdata_overview {
    rankdir = BT
    dataobject [label="data object\n(subclass of gmx::AbstractAnalysisData)"]
    datamodule1 [label="data module\n(implements gmx::IAnalysisDataModule)"]
    datamodule2 [label="data module\nthat also provides data"]
    datamodule3 [label="data module"]
    datamodule1 -> dataobject
    datamodule2 -> dataobject
    datamodule3 -> datamodule2
  }
\enddot

Typically, an analysis tool provides its raw data output through one or more
gmx::AnalysisData objects (the root _data object_ in the diagram above).
This object provides only storage for the data.

To perform operations on the data, one or more _data modules_ can be attached
to the data object.  Examples of such operations are averaging, histogramming,
and plotting the data into a file.  Some data modules are provided by the \ref
module_analysisdata module.  To implement new ones, it is necessary to create a
class that implements gmx::IAnalysisDataModule.

In many cases, such data modules also provide data that can be processed
further, acting as data objects themselves.  This makes it possible to attach
further data modules to form a processing chain.  In simple cases, such a chain
ends in a module that writes the data into a file, but it is also possible to
access the data in a data object (whether a plain data object or a data module)
programmatically to do further computation or post-processing outside the
framework.  To do this, the data object typically needs to be told in advance
such that it knows to store the data permanently even if attached modules do
not require it.

The modules can do their processing online, i.e., as the data is produced.
If all the attached modules support this, it is not necessary to store all the
raw data in memory.  The module design also supports processing frames in
parallel: in such cases, the data may become available out of order.  In
particular for writing the per-frame data into a file, but also for other types
of post-processing, it is necessary to reorder the data sequentially.  This is
implemented once in the framework, and analysis tools do not need to worry,
other than using the provided API.


Structure of data
=================

At the highest level, data can be structured into separate
gmx::AbstractAnalysisData objects that operate independently.  Each such object
has an independent set of post-processing modules.

Within a gmx::AbstractAnalysisData object, data is structured along three
"dimensions":

 - _frames_: There is one or more frames in each data object.  For raw data
   produced by an analysis tool, these typically correspond to input trajectory
   frames.  For other data set, it can be viewed as an X axis of a graph.
 - _data sets_: There is one or more data sets in each data object.  For most
   purposes, data sets work independently (i.e., the post-processing modules
   operate on each data set separately), but some modules reduce the data sets
   into single columns in the output.  The main purpose for using multiple data
   sets is to share the same post-processing chain for multiple sets of data
   (e.g., multiple RDFs computed by the same tool in one pass), in particular
   for cases where the number of data sets is not known at compile time.
   Note that each data set contains the same number of frames.
 - _columns_: There is one or more columns in each data set.  Different data
   sets can contain a different number of columns.  Each column in a frame can
   contain a single value (see below for supported values).

Programmatically the data within each frame is organized into _point sets_.
Each point set consists of a continuous range of columns from a single data
set.  There are two types of data:

 - _simple_: For each frame, there is exactly one point set for each data set,
   and that point set spans all columns in that data set.
 - _multipoint_: For each frame, there can be any number of point sets, and
   they may span arbitrary columns.  It is allowed that point sets overlap,
   i.e., that multiple point sets specify a value for the same column.

The main purpose of multipoint data is to support cases where it is not known
in advance how many values there will be for each frame, or where that number
is impractically large.  The need to do this is mainly a matter of
performance/implementation complexity tradeoff: with a more complex internal
implementation, it would be possible to support larger data sets without a
performance/memory impact they currently impose.  The current implementation
places the burden of deciding on the appropriate usage pattern on the user
code, allowing for much simpler internal implementation.

An individual value (identified by frame, data set, and column) consists of a
single value of type `real`, an optional error value, and some flags.
The flags identify what parts of the value are really available.  The following
states are possible:
 - _present_: The value is set.
 - _missing_: The value is marked as missing by the data source.  In this
   state, the value can still be accessed, and the returned `real` value has
   some meaning.  Different data modules handle these cases differently.
 - _unset_: The value is not set.  It is not allowed to access the value for
   other than querying the state.  Data modules that ignore missing values
   (by skipping all values not _present_) can also handle unset values.
   Other data modules typically do not allow unset values.


Data provider classes
=====================

The base class for all data objects (including data modules that provide data)
is gmx::AbstractAnalysisData.  This class provides facilities for attaching
data modules to the data, and to query the data.  It does not provide any
methods to alter the data; all logic for managing the actual data is in derived
classes.

The main root (non-module) data object class for use in analysis tools is
gmx::AnalysisData.  This class provides methods to set properties of the data,
and to add frames to it.  The interface is frame-based: you construct one frame
at a time, and after it is finished, you move to the next frame.  The frames
are not constructed directly using gmx::AnalysisData, but instead separate
_data handles_ are used.  This is explained in more detail below under
\ref section_analysisdata_parallelization.

For simple needs and small amounts of data, gmx::AnalysisArrayData is also
provided.  This class allows for all the data to be prepared in memory as a
single big array, and allows random access to the data while setting the
values.  When all the values are set to their final values, it then notifies
the attached data modules by looping over the array.


Parallelization {#section_analysisdata_parallelization}
===============

One major driver for the design of the analysis data module has been to provide
support for transparently processing multiple frames in parallel.  In such
cases, output data for multiple frames may be constructed simultaneously, and
must be ordered correctly for some data modules, such as writing it into a
file.  This ordering is taken care of by the framework, allowing the analysis
tool writer to concentrate on the actual analysis task.

From a user's point of view, the main player in this respect is the
gmx::AnalysisData object.  If there are two threads doing the processing in
parallel, it allows creating a separate gmx::AnalysisDataHandle for each
object.  Each of these handles can be used independently to construct frames
into the output data, and the gmx::AnalysisData object internally takes care of
notifying the modules correctly.  If necessary, it stores finished frames into
a temporary buffer until all preceding frames have also been finished.

For increased efficiency, some data modules are also parallelization-aware:
they have the ability to process the data in any order, allowing
gmx::AnalysisData to notify them as soon as a frame becomes available.
If there are only parallel data modules attached, no frame reordering or
temporary buffers are needed.  If a non-parallel data module is attached to a
parallel data module, then that parallel data module takes the responsibility
of ordering its output frames.  Ideally, such data modules produce
significantly less data than what they take in, making it cheaper to do the
ordering only at this point.

Currently, no parallel runner has been implemented, but it is likely that
applicable tools written to use the framework require minimal or no changes to
take advantage of frame-level parallelism once such a runner materializes.


Provided data processing modules
================================

Data modules provided by the \ref module_analysisdata module are listed below
with a short description.  See the documentation of the individual classes for
more details.
Note that this list is manually maintained, so it may not always be up-to-date.
A comprehensive list can be found by looking at the inheritance graph of
gmx::IAnalysisDataModule, but the list here is more user-friendly.

<dl>
<dt>gmx::AnalysisDataAverageModule</dt>
<dd>
Computes averages and standard deviations for columns in input data.
One output value for each input column.
</dd>
<dt>gmx::AnalysisDataFrameAverageModule</dt>
<dd>
Computes averages for each frame in input data.
One output value for each input data set for each frame.
</dd>
<dt>gmx::AnalysisDataBinAverageModule</dt>
<dd>
Computes averages within bins.  Input is pairs of values, where the first
value defines the bin, and the second value sets the value to accumulate into
the average within the bin.
One output histogram for each input data set.
</dd>
<dt>gmx::AnalysisDataSimpleHistogramModule</dt>
<dd>
Computes histograms.  All values within a data set are added into a histogram.
One output histogram for each input data set.
Provides the histogram for each input frame separately, and also the full
histogram over frames (through an internal submodule).
</dd>
<dt>gmx::AnalysisDataWeightedHistogramModule</dt>
<dd>
Computes histograms.  Input is pairs of values, where the first value defines
the bin, and the second value sets the value to add into that bin.
Output like with gmx::AnalysisDataSimpleHistogramModule.
</dd>
<dt>gmx::AnalysisDataLifetimeModule</dt>
<dd>
Computes lifetime histograms.  For each input column, determines the time
intervals during which a value is continuously present/non-zero, and creates a
histogram from the lengths of these intervals.
One output histogram for each input data set.
</dd>
<dt>gmx::AnalysisDataPlotModule</dt>
<dt>gmx::AnalysisDataVectorPlotModule</dt>
<dd>
Writes data into a file.
</dd>
</dl>
\Gromacs {#mainpage}
=======

\Gromacs is a versatile package to perform molecular dynamics, i.e. simulate
the Newtonian equations of motion for systems with hundreds, to millions
of particles.  See [www.gromacs.org](http://www.gromacs.org) for more
information.

This documentation generated by Doxygen is (mostly) extracted from the source
code, and provides documentation for understanding the source code.
The documentation can be generated with different levels of details.
This documentation has been generated to include
\if internal
all documentation, including internal functions and classes used for internal
implementation purposes.

The main audience for this level of detail are people who want to understand
detailed implementation of some area, or try to find some specific function
within the library.  If you are overwhelmed by the amount of details, the
[library API documentation](../html-lib/index.xhtml) skips functions not meant
to be used outside a single module.
\elseif libapi
documentation of functions in the library intended for reuse within the
library (a subset of these functions is also exposed as a public API).
Also overview documentation aimed at \Gromacs developers is included at this
level.

The main audience for this level of detail are users and developers who want to
understand the \Gromacs code in general.
If you only want to call \Gromacs, but not modify it, the
[public API documentation](../html-user/index.xhtml) provides a cleaner entry
point.
If you are interested in internal implementation details not described here,
you can try searching the [full documentation](../html-full/index.xhtml).
\else
documentation of functions exposed through installed headers and intended as
part of a public API.  Note that definition of the public API is very
preliminary, and subject to change.

The main audience for this level of detail are users of \Gromacs who are
interested in writing their own analysis tools that use \Gromacs as a library,
as well as other developers who want to link against \Gromacs.
To understand the inner workings of \Gromacs, or if you want to contribute to
\Gromacs, see the more detailed
[library API documentation](../html-lib/index.xhtml) or
[full documentation](../html-full/index.xhtml).
\endif

Currently, only parts of the code are documented here.  The following pages
give an overview of some of the topics that are documented:

 - \subpage page_analysisframework <br/>
   Provides an overview of the framework that the \Gromacs library provides for
   writing (trajectory) analysis tools.
 - \subpage page_onlinehelp <br/>
   Provides an overview of the formatting markup available in help texts.
 - \subpage page_usinglibrary <br/>
   Provides general guidance for writing software that uses the \Gromacs
   library.
\if libapi
 - \subpage page_wrapperbinary <br/>
   Provides an overview of how the `gmx` wrapper binary is implemented.
 - \subpage page_logging <br/>
   Documentation for logging and status output (for now, within mdrun).
 - \subpage page_simd <br/>
   Documentation about the new SIMD module that makes it possible to write
   highly accelerated CPU code that is still portable.
 - \subpage page_nbnxm <br/>
   Documentation about the non-bonded module which uses NxM atom clusters.
 - \subpage page_awh <br/>
   Documentation about the accelerated weight histogram (AWH) method,
   which is used for accelerating sampling along reaction coordinates.
 - \subpage page_mdmodules <br/>
   Documentation for work-in-progress modularization of parts of mdrun, that
   should make it easier to implement additional features as add-ons on top of
   a common interface.
 - \subpage page_refdata <br/>
   Documentation for writing tests that use reference data generated by the
   same test.
 - \subpage page_modularsimulator <br/>
   Documentation of the modular simulator approach.

 - \subpage page_modulegraph <br/>
   Automatically generated module dependency graph.
\endif

This list will hopefully expand over time.
The NxM atom-cluster non-bonded algorithm {#page_nbnxm}
=========================================

The algorithm
=============

Computing non-bonded pair interactions is the most time consuming part
of most molecular dynamics simulations. It is therefore necessary to
(highly) optimize this to achieve good simulation performance.
The standard atom pair lists are not a good match for modern SIMD
(single-instruction multiple-data) CPU architectures, nor for GPGPU
accelerators. To achieve higher (cache) data reuse and instruction
parallelism, we cluster atoms in groups of size N and M, where N and M
are either the same or differ by a factor of 2. This is done by spatial
gridding and binning. We then construct a pair list between these
clusters instead of single atoms. This not only leads to a smaller list,
but also regularizes the data access. The non-bonded pair-interaction
kernels can then compute interactions between all atom-pairs in
a cluster-pair simultaneously. For GPUs there is another layer:
superclusters consisting of multiple clusters to increase data reuse.

Architecture support
====================

Currently the module supports 5 different kernel architectures:
* Plain C++: slow, only for reference.
* SIMD 4xM: targets CPUs using SIMD intrinsics with N=4 and M=2, 4 or 8, SIMD width 2, 4 or 8.
* SIMD 2xMM: targets CPUs using SIMD intrinsics with N=4 and M=4 or 8, SIMD width 8 or 16.
* GPU: targets GPUs with N=M=8 or N=M=4, depending on
  `GMX_GPU_NB_CLUSTER_SIZE` compilation option value.
mdrun modules {#page_mdmodules}
=============

Currently, most of mdrun is constructed as a set of C routines calling each
other, and sharing data through a couple of common data structures (t_inputrec,
t_forcerec, t_state etc.) that flow throughout the code.

The electric field code (in `src/gromacs/applied-forces/`) implements an
alternative concept that allows keeping everything related to the electric
field functionality in a single place.  At least for most special-purpose
functionality, this would hopefully provide a more maintainable approach that
would also support more easily adding new functionality.  Some core features
may still need stronger coupling than this provides.

The rest of the page documents those parts of the modularity mechanism that
have taken a clear form.  Generalizing and designing other parts may require
more code to be converted to modules to have clearer requirements on what the
mechanism needs to support and what is the best way to express that in a
generally usable form.

Structure of a module
---------------------

Each module implements a factory that returns an instance of gmx::IMDModule.
This interface has methods that in turn refer to other interfaces:
gmx::IMdpOptionProvider, gmx::IMDOutputProvider, and gmx::IForceProvider.
The module also implements these interfaces (or a subset of them), and code
outside the module only calls methods in these interfaces.

See documentation of the individual interfaces for details of what they
support.

Implementation of a module
--------------------------

Modules are constructed by composition of interfaces (i.e. abstract classes,
general with pure virtual methods lacking implementations), so that e.g.
trajectory-writing code can loop over containers of pointers to
gmx::IMDOutputProvider without needing to know about all the concrete types
that might implement that interface.

The module classes should not be extended by using them as a base
class, which is expressed with the final keyword in the class
definition. Generally, modules will implement different flavours of
functionality, perhaps based on user choices, or available computing
resources. This should generally be implemented by providing variable
behavior for the methods that are called through the above
interfaces. Either code should branch at run time upon some data
contained by the module (e.g. read from the mdp options), or that the
module class should contain a pointer to an internal interface class
whose concrete type might be chosen during setup from the set of
implementations of that internal interface. Such an approach keeps
separate the set of interfaces characteristic of "MD modules" from
those that are particular to flavours of any specific module.

The virtual methods that the module classes inherit from their
interfaces should be declared as `override`, to express the intent
that they implement a virtual function from the interface. This
permits the compiler to check that this is true, e.g. if the interface
class changes. The `virtual` keyword should not be specified,
because this is redundant when `override` is used. This follows
the Cpp Core Guidelines (guideline C.128).

Handling mdp input
------------------

To accept parameters from an mdp file, a module needs to implement
gmx::IMdpOptionProvider.

initMdpOptions() should declare the required input parameters using the options
module.  In most cases, the parameters should be declared as nested sections
instead of a flat set of options.  The structure used should be such that in
the future, we can get the input values from a structured mdp file (e.g., JSON
or XML), where the structure matches the declared options.  As with other uses
of the options module, the module needs to declare local variables where the
values from the options will be assigned.  The defined structure will also be
used for storing in the tpr file (see below).

initMdpTransform() should declare the mapping from current flat mdp format to
the structured format defined in initMdpOptions().  For now, this makes it
possible to have an internal forward-looking structured representation while
the input is still a flat list of values, but in the future it also allows
supporting both formats side-by-side as long as that is deemed necessary.

On the implementation side, the framework (and other code that interacts with
the modules) will do the following things to make mdp input work:

* When grompp reads the mdp file, it will first construct a flat
  KeyValueTreeObject, where each input option is set as a property.

  It then calls initMdpTransform() for the module(s), and uses the produced
  transform to convert the flat tree into a structured tree, performing any
  defined conversions in the process.  This transformation is one-way only,
  although the framework keeps track of the origin of each value to provide
  sensible error messages that have the original mdp option name included.

  It calls initMdpOptions() for the module(s), initializing a single Options
  object that has the input options.

  It processes the structured tree using the options in two steps:

  * For any option that is not specified in the input, it adds a property to
    the tree with a default value.  For options specified in the input, the
    values in the tree are converted to native values for the options (e.g.,
    from string to int for integer options).
  * It assigns the values from the tree to the Options object.  This will make
    the values available in the local variables the module defined in
    initMdpOptions().

  Note that currently, the module(s) cannot use storeIsSet() in options to know
  whether a particular option has been provided from the mdp file.  This will
  always return true for all the options.  This is a limitation in the current
  implementation, but it also, in part, enforces that the mdp file written out
  by `gmx grompp -po` cannot produce different behavior because of set/not-set
  differences.

* grompp -po writes an mdp file that was equivalent to the input,
  which is implemented by calling buildMdpOutput() for each module, to
  prepare a builder object that is used with writeKeyValueTreeAsMdp().
  As with the old flat tree, the values given by the user's input are
  preserved, but not the ordering of options, or their formatting.

* When grompp writes the tpr file, it writes the structured tree (after the
  default value and native value conversion) into the tpr file.

* When mdrun reads the tpr file, it reads the structured tree.
  It then broadcasts the structure to all ranks.  Each rank calls
  initMdpOptions() for the modules, and assigns the values from the tree to the
  Options object.  After this, the modules will be exactly in the same state as
  in grompp.

* When other tools (gmx dump or gmx check in particular) read the tpr file,
  they read the structured tree.  In principle, they could operate directly on
  this tree (and `gmx dump` in particular does, with the `-orgir` option).
  However, in the future with proper tpr backward compatibility support, they
  need to call to the modules to ensure that the tree has the structure that
  this version expects, instead of what the original version that wrote the
  file had.  Currently, these tools only call initMdpOptions() and do the basic
  default+native value conversion.

* Any code that is not interested in the parameters for these modules can just
  read the t_inputrec from the tpr file and ignore the tree.

* For compatibility with old tpr files that did not yet have the structured
  tree, the I/O code converts old values for the modules to parameters in the
  structured tree (in tpxio.cpp).

Currently, there is no mechanism for changing the mdp input parameters (adding
new or removing old ones) that would maintain tpr and mdp backward
compatibility.  The vision for this is to use the same transformation engine as
for initMdpTransform() to support specifying version-to-version conversions for
any changed options, and applying the necessary conversions in sequence.  The
main challenge is keeping track of the versions to know which conversions to
apply.

Callbacks to modules during setup and simulation
------------------------------------------------

During setup and simulation, modules receive required information like topologies
and local atom sets by subscribing to callback functions.

To include a notification for your module

* Add the function signature for the callback function to the
  `MDModulesNotifiers` in `mdmodulesnotifiers.h`,

  ```C++
    BuildMDModulesNotifier<...,
                      YourCallbackSignature,
                      ...,
  ```

  (keep alphabetical order for ease of git merge)

* Hand the notifier_ member of the MDModules Implementation class to your
  builder createYourModule(&notifier_)

* Add the function you want to subscribe with in the builder,
  `notifier->subscribe(yourFunction)`

  * To subscribe class member functions of your module, you can use lambda expressions

  ```C++
    notifier->notifier_.subscribe([modulePointer = yourModule.get()]
      (YourCallbackSignature argument){modulePointer(argument);});
  ```

* During setup in , e.g., within `Mdrunner` use

  ```C++
    YourCallbackSignature argument();
    mdModules_.notifier().notifier_.notify(argument);
  ```

Storing non-mdp option module parameters
----------------------------------------

Some mdrun modules want to store data that is non-mdp input, e.g., the result of
computation during setup. Atom indices of index groups are one example:
they are evaluated from strings during grompp time and stored as list of
integers in the run input file. During the mdrun setup the information to
evaluate the index groups is no longer available.

To store parameters, subscribe to the `KeyValueTreeBuilder*` notification that
provides a handle to a KeyValueTreeBuilder that allows adding own information to
that tree.

To restore parameters, subscribe to the `const KeyValueTreeObject &`
notification that returns the tree that is build by the KeyValueTreeBuilder*.
Module dependency graph {#page_modulegraph}
=======================

The graph below shows the dependencies between the source code modules,
computed from include statements in the code.
For documented modules (those that do not have a gray background), clicking on
the module takes you to the module documentation.
Legend for the graph can be found below the graph.

\ifnot xml
\dotfile module-deps.dot
\endif

Legend
======

The graph below annotates the colors and line styles used in the module
dependency graph above.  More detailed textual annotation is below the graph.

\dot
digraph legend {
    node [fontname="FreeSans",fontsize=10,height=.2,shape=box]
    edge [fontname="FreeSans",fontsize=10]
    rankdir = "LR"
    subgraph cluster_nodes {
        label = "Nodes"
        legacy    [label="undocumented", fillcolor=grey75, style="filled"]
        analysis  [label="analysis", fillcolor="0 .2 1", style="filled"]
        utility   [label="utility", fillcolor=".08 .2 1", style="filled"]
        mdrun     [label="mdrun", fillcolor=".75 .2 1", style="filled"]
        installed [label="installed", color=".66 .5 1", penwidth=3]
    }
    subgraph cluster_edges {
        label = "Edges"
        node [label="<any>"]
        invalid1 -> invalid2 [label="invalid", color=red]
        legacy1 -> legacy2 [label="legacy", color=grey75]
        legacy2 [label="undoc"]
        public1 -> public2 [label="public", color=black]
        public1 [label="public"]
        public2 [label="public"]
        library1 -> library2 [label="library", color=".66 .8 .8"]
        library1 [label="library"]
        pubimpl1 -> pubimpl2 [color=black, style=dashed]
        pubimpl1 [label="internal"]
        pubimpl2 [label="public"]
        libimpl1 -> libimpl2 [color=".66 .8 .8", style=dashed]
        libimpl1 [label="internal"]
        libimpl2 [label="library"]
        test1 -> test2 [label="test", color=".33 .8 .8", style=dashed]
        test1 [label="test"]
    }
    legacy -> invalid1 [style="invis"]
}
\enddot

Node colors:
<dl>
<dt>gray background</dt>
<dd>undocumented module</dd>
<dt>orange background</dt>
<dd>documented utility modules</dd>
<dt>red background</dt>
<dd>documented analysis modules</dd>
<dt>violet background</dt>
<dd>documented MD execution modules</dd>
<dt>light blue border</dt>
<dd>module contains public API (installed) headers</dd>
</dl>

Edge colors (an edge with a certain color indicates that types above it in the
list are not present):
<dl>
<dt>red</dt>
<dd>invalid dependency</dd>
<dt>gray</dt>
<dd>legacy dependency
(dependency on undocumented file, or to undocumented directories)</dd>
<dt>solid black</dt>
<dd>public header depends on the other module</dd>
<dt>solid blue</dt>
<dd>library header depends on the other module</dd>
<dt>dashed blue</dt>
<dd>source file depends on library header in the other module</dd>
<dt>dashed black</dt>
<dd>source file depends on public header in the other module</dd>
<dt>dashed green</dt>
<dd>test file depends on the other module</dd>
</dl>
Using reference data in C++ tests {#page_refdata}
=================================

The \ref module_testutils module provides (among other things) utilities to
write Google Test tests that compare their results against stored reference
data.  This can either be used for

 * regression-style tests, just ensuring that the output does not change, or
 * combined with manual checking of the reference data, as a different kind of
   assertion, where the expected results would be tedious to express directly
   as C++ code (e.g., when checking complicated data structures for
   correctness).

The current reference data functionality is quite basic, but it can be extended
if/when more control over, e.g., comparison tolerances is needed.

Reference data organization
===========================

Conceptually, the reference data consists of a tree-like structure of nodes.
Each leaf node checks a single primitive value (an integer, a floating-point
value, a string etc.), and each inner node acts as a _compound_ value that
helps organizing the data.  Within each compound node (including the root of
the tree), child nodes are identified by an `id` string.  Each node within a
single compound must have a unique `id`, and it is possible to compare
multiple values produced by the test against this single node (naturally, the
test only passes if the test produces the same value in all such cases).

Each node also has a type (a string).  For leaf nodes, the type is from a
predetermined set of strings, and identifies the type of the value stored in
the node.  For compound nodes, the type is just a string provided by the test.
In all cases, the type in the reference data must match the type provided by
the test.  This provides additional safety when changing the test to detect
mismatches between the test and the reference data.  The intention is that
compound nodes whose contents have the same structure would have the same type;
this will simplify using XSLT for viewing the reference data (see below).

Some compound types are predefined, e.g., for simple sequences, but more
complicated compounds can be defined ad-hoc in tests that need them.  See below
for how to use them in the code.

As a special case, the `id` can be empty (`NULL`).  This is intended for
cases where one is checking for a sequence of items, and the only thing
distinguishing the items is their position in this sequence.  Using an empty
`id` removes the need to generate unique identifiers for the items, and makes
textual diffs of the reference data files easier to read.
Only a single sequence of nodes with an empty `id` is supported within one
parent node: if you first check some nodes with an empty `id`, followed by a
non-empty `id`, the next check for an empty `id` will again match the first
node in the sequence.
For clarity, all the nodes that have an empty `id` should be of the same
type, but this is not enforced.

Using reference data in code
============================

To use reference data in a test, the test should first create exactly one
instance of gmx::test::TestReferenceData.  It can do so as a local variable in
the test, as a member variable in its test fixture, or by subclassing a test
fixture that already contains such a variable (e.g., gmx::test::StringTestBase
or gmx::test::CommandLineTestBase).
Only use the default constructor!  The other constructor is intended for
self-testing utility code used in other tests (including self-testing the
reference data implementation itself), and behaves differently from what is
described here.

To access the root node of the data,
gmx::test::TestReferenceData::rootChecker() needs to be called.
This returns a gmx::test::TestReferenceChecker that provides various
`check*()` methods that can be used to check values against top-level nodes.
gmx::test::TestReferenceChecker::checkCompound() can be called to create custom
compound types: it returns another gmx::test::TestReferenceChecker that can be
used to check values against child nodes of the created compound.

Whenever a gmx::test::TestReferenceChecker method detects a mismatch against
reference data, it will generate a non-fatal Google Test failure in the current
test.  The test can naturally also use its own test assertions for additional
checks, but any mismatch will automatically also fail the test.

It is also possible to read values of the reference data items using
gmx::test::TestReferenceChecker, so that they can be used programmatically.
For this to work, those items should first be written in the same test.
This supports tests that want to both check data against a reference, and use
that reference as a persistence layer for storing information.  This is useful
at least for serialization tests.
This is currently not supported for all use cases, but with some caveats, it is
possible to use this for testing.

When using floating-point values in reference data, the tolerance for the
comparison can be influenced with
gmx::test::TestReferenceChecker::setDefaultTolerance().
Per-comparison tolerances would be possible to implement if necessary, but
currently you can either change the default tolerance whenever you need to, or
create copies of the gmx::test::TestReferenceChecker object and set different
tolerances in the different instances.  Note that there is an implicit
assumption that a mixed- and a double-precision build will produce the same
results (within the given tolerance).  This means that some things cannot be
tested with the reference data (e.g., multiple steps of MD integration), and
that reference data for such tests needs to be always generated in double
precision (unless the results are nice, exact binary floating-point numbers).

Just creating a gmx::test::TestReferenceData instance does not enforce using
reference data in the test; the data is loaded/used only when
gmx::test::TestReferenceData::rootChecker() is first called.  If the test never
calls this method, the gmx::test::TestReferenceData object does nothing.  This
allows using the same test fixture (e.g., CommandLineTestBase) also in tests
that do not need the reference data, but benefit from other features of the
fixture.

Running tests that use reference data
=====================================

To run a test that uses the reference data, you just execute the test binary as
you would otherwise.  However, when you first add a test, the reference data
does not exist, and the test will fail with an assertion message saying that
the reference data could not be found.  To generate the reference data, you
need to run the test binary with a `-ref-data create` command-line option
(it is also possible to use any of the `update` options below to generate the
reference data).

If you change a test (or the tested code) such that the reference data needs to
be changed, you need to run the test binary with `-ref-data update-all` or
`-ref-data update-changed`.  The first will recreate the reference data from
scratch.  The latter will retain old reference values if they are still valid.
In other words, floating-point reference values that are within the test
tolerance will be kept at their old values.  Only values that are outside the
tolerance (or otherwise do not match or do not exist) are updated.
This is useful (at least) for tests that contain floating-point data, where it
is not expected that those floating-point values would actually need to change.
This allows you to update other parts of the reference data without doing a
double-precision build, and also makes it easier to avoid spurious changes in
the last bits of other reference data values when just a single output value is
expected to change.

To create or update reference data, the test needs to pass when run with the
corresponding flag.  All comparisons against reference data will pass in these
modes, but you need to ensure that other assertions in the test also pass, and
that the test does not throw exceptions.
Note that if your test does multiple comparisons against the same `id` node,
reference data comparison can still fail during create/update if the test does
not produce the same results for each comparison.

With all the operations that create or update the reference data, you can use
the `--gtest_filter=<...>` command-line option provided by Google Test to
select the tests whose reference data you want to influence.

Persistence
===========

The reference data is stored in XML files under
`src/gromacs/`<em>module</em>`/tests/refdata/` in the source tree.
This part of the framework depends on `tinyxml2`, which is bundled in `src/external`.
One file is produced per test that uses reference data.  If you rename tests or
otherwise change the reference data, you currently need to manually manage the
files with `git`.

For inspecting the reference data in a browser, there are XSLT stylesheets that
transform the XML files into HTML.  Such custom transformations need to be
written for each type of test if the output is not easy to check otherwise.
Because of security features in browsers, the transformations may not work for
all browsers.  For the same reason, the XSLT files must be in the same folder
as the XML files.  For cases where the XSLT files are shared between multiple
modules, `src/testutils/copy_xsl.sh` takes care to synchronize the files after
a master copy is edited.
The accelerated weight histogram method (AWH) {#page_awh}
=============================================

Accelerating sampling with AWH
==============================

AWH calculates the free energy along an order parameter of the system.
Free energy barriers are overcome by adaptively tuning a bias potential along
the order parameter such that the biased distribution along the parameter
converges toward a chosen target distribution.
The fundamental equation governing the tuning is: log(target) = bias - free energy, where
the bias and free energy are initially unknown. Typically the target distribution is simply
chosen uniform, such that the bias completely flattens the free energy landscape.


Design of the AWH module
========================

The module implements AWH for the case when the order parameter corresponds to a reaction coordinate,
here referred to as coordinate for short, i.e. a function of the system configuration.
The bias is coupled to the system by a bias potential: either in the form of an harmonic ("umbrella") potential
Monte-Carlo (MC) "jumping" around the current coordinate value, or as a smooth convolution of the umbrellas.

The AWH module is organizes as follows:
The Awh class is the interface between the outside and inside of the module.
The Awh class contains one or more BiasCoupledToSystem objects.
The BiasCoupledToSystem class takes care of the reaction coordinate input
and force output for the single Bias object it containts.
The Bias class is a container and wrapper for a object BiasState + helpers.
All computation takes place in the BiasState object and its sub-classes.
The Bias class also contains a BiasWriter object that takes care of i/o.

Use of AWH in mdrun
===================

The basic use of Awh in mdrun consists of 2 method calls:
Call the constructor Awh() after the pull module has been initialized.
Call applyBiasForcesAndUpdateBias() at every MD step after the pull
potential calculation function has been called.

In grompp the pull potential provider should be registered using
registerAwhWithPull() so grompp can check for unregistered potentials.

The main tasks of AWH are:
- calculate and set the bias force given the current coordinate value.
- after accumulating a number of coordinate samples, update the free energy estimate and the bias.

AWH currently relies on the pull code for the first task. Pull provides AWH with updated coordinate values
and distributes the bias force that AWH calculates to the atoms making up the coordinate. This
also means that there are some order dependencies where pull functions need to be called before AWH
functions (see below).

The implementation is quite general. There can be multiple independent AWH biases coupled to the system
simultaneously. This makes sense if the system is made up of several fairly independent parts,
like monomers in a protein. Each bias acts on exactly one, possibly multidimensional, coordinate.
Each coordinate dimension maps to exactly one pull coordinate. Thus, an n-dimensional
biased coordinate is defined by a set of n pull coordinates. Periodicity is taken care of for coordinate
dimensions that require it (dihedral angles). For increased parallelism, there is the option of
having multiple communicating simulations sharing all samples. All simulations would then share a single
bias and free energy estimate. Alternatively, one may partition the sampling domain into smaller
subdomains with some overlap and have multiple independent simulations sample each subdomain.

Note that internally the AWH module keep tracks of free energies in units
of the thermal energy kT. This is because we mostly deal with free energies
in the form of -log(probability) and using any other unit would be bug prone.
All energy type variables are explicitly documented to be in units of kT.
Also the checkpoint and energy file data is in units of kT. The analysis
tool will by default convert energies to kJ/mol, but there is also
a kT option.

Logging {#page_logging}
=======

Currently, mdrun is using a combination of direct C-style I/O into `fplog` and
`stderr`, and the facilities described here.  However, more and more should get
moved to this interface in the future.

The parts that make up the logging system are shown below.

\dot
    digraph logging_overview {
        builder [label="LoggerBuilder", URL="\ref gmx::LoggerBuilder"]
        owner [label="LoggerOwner", URL="\ref gmx::LoggerOwner"]
        logger [label="MDLogger", URL="\ref gmx::MDLogger"]
        target [label="ILogTarget", URL="\ref gmx::ILogTarget"]
        user [label="using code"]

        builder -> owner [label="builds"]
        owner -> logger
        owner -> target [label="owns"]
        logger -> target [label="references"]
        user -> builder [label="set logging targets"]
        user -> logger [label="write with\nGMX_LOG()"]
    }
\enddot

To initialize the logging system, the using code creates an instance of
gmx::LoggerBuilder, and sets the desired logging targets with provided methods.
Once all targets have been initialized, the code calls
gmx::LoggerBuilder::build() and gets a gmx::LoggerOwner, which is responsible
of managing the memory allocated for the logger.

To log information, the using code uses an gmx::MDLogger returned by
gmx::LoggerOwner::logger() with the ::GMX_LOG macro.  Code that writes to the
log only needs to know of this class (and helper classes used to implement the
macro), which is a relatively simple container for references to the logging
targets.  If there is no log target that would consume the information written
with ::GMX_LOG, the whole statement evaluates to a conditional that reads the
log target from a member variable and compares it against `nullptr`.  All the
code that formats the output is skipped in this case.

Currently the implementation is geared to making ::GMX_LOG behavior stable, and
to be relatively extensible.  However, using any other approach than ::GMX_LOG
for writing to the log should first think about how the API could be best
organized for that.

All information written to the log is composed of _log entries_.  Each
::GMX_LOG statement writes a single log entry, meaning that newlines are
automatically added.

The logging methods are not thread-safe, so it is the responsibility of the
calling code to only use them from a single thread or otherwise synchronize
access.
Wrapper binary implementation {#page_wrapperbinary}
=============================

This page mainly describes the implementation of the `gmx` wrapper binary.
Many of the details are not visible to most of the code, but this documentation
is included as part of the library API documentation to make it easier to
understand the overall implementation without reading extensive documentation.

%main() implementation
======================

The %main() method for the wrapper binary is implemented in
`src/programs/gmx.cpp`.  This is a very simple code that does these basic
tasks:
 1. Initializes \Gromacs using gmx::initForCommandLine()
    (see \ref page_usinglibrary).
 2. Creates a gmx::CommandLineModuleManager instance for the wrapper binary.
 3. Calls various methods to add modules to the manager and initialize it
    otherwise.  Many of the pre-5.0 binaries are added from
    `src/programs/legacymodules.cpp`.  New C++ tools are added from
    `src/gromacs/trajectoryanalysis/modules.cpp`.
 4. Passes control to the manager (see below).
 5. On successful return, deinitializes \Gromacs and returns the exit code from
    the manager.
The %main() method also catches all exceptions, and if one is caught, prints an
error message and terminates the program cleanly.

Command line modules
====================

All modules within the wrapper binary are implemented as classes that implement
the gmx::ICommandLineModule interface.  There is generally some helper
class in between:
 * General C++ modules typically use gmx::Options for their command-line
   handling.  Instead of each module implementing parsing and help separately
   with identical code, they implement gmx::ICommandLineOptionsModule
   instead.  The framework then provides a bridge class that contains the
   common code and wraps gmx::ICommandLineOptionsModule into a
   gmx::ICommandLineModule.
 * For C++ trajectory analysis modules, there is a general implementation for
   running the gmx::TrajectoryAnalysisModule subclasses in cmdlinerunner.cpp.
 * For old C-style %main() functions, see \ref section_wrapperbinary_cmain.

Command line manager {#section_wrapperbinary_manager}
====================

The core of the wrapper binary is the gmx::CommandLineModuleManager::run()
method.  This method:
 1. Parses the command line arguments before the module name as arguments to
    the wrapper binary.  Some arguments such as `-h` and `-version` cause rest
    of the command (the module name and all that follows) to be ignored.
 2. If a module is specified, also checks the command line arguments after the
    module name for the options understood by the wrapper binary, such as `-h`
    and `-version` (see below for details of how `-h` works).  Any such options
    are handled by the manager and removed from the command line for further
    processing.
 3. Print the startup header (contents of which can be controlled by the
    command line options).
 4. If a command line option requests termination after the startup header
    (such as `-version`), return.
 5. Passes control to the selected module.  If there is no module specified,
    the help module is invoked (see below).
 6. Print a quote at the end, and return the exit code from the module.

Command line help
-----------------

To handle the `gmx help ...` command, as well as for `gmx -h` and for
`gmx` _module_ `-h`, the command line manager internally creates a module that
handles the `help` command.  All command lines containing the `-h`, as well as
invocation of `gmx` without any arguments, are translated to corresponding
`gmx help` commands.  For example, `gmx` _module_ `-h` is handled exactly like
`gmx help` _module_.  Note that if `-h` is specified for a module, the command
line manager throws away all the other arguments before passing control to the
module.

After the above translations, the internal help module handles all the help
output.  All the help is organized into a hierarchy of gmx::IHelpTopic
instances.  The help module internally creates a root help topic that is
printed with `gmx help`.  If there are additional words after the `gmx help`
command, then those are taken to specify the topic to show in the hierarchy.

gmx::CommandLineModuleManager internally creates a help topic for each added
module.  These topics are shown when `gmx help` _module_ is invoked.
They forward the request to the actual module (to
gmx::ICommandLineModule::writeHelp()).

In addition to the topics created internally, gmx::CommandLineModuleManager
provides methods to add additional help topics.  Currently, this is used to
expose some reference material for the selections (the same content that is
accessible using `help` in the selection prompt).

Help in other formats
---------------------

The build system provides a target, `make sphinx-programs`, that generates
reStructuredText help for the commands, which in turn is used to generate man
and HTML help.  Internally, this executes `gmx help -export rst`, which
triggers special handling in the internal help module.
See documentation for
\linktodevmanual{build-system,special targets in the build system} for details
of which targets to use for generating the documentation..

If this option is set, the help module loops through all the modules in the
binary, writing help for each into a separate file.  The help module writes
common headers and footers, and asks the actual module to write the
module-specific content (with gmx::ICommandLineModule::writeHelp(),
using a different help context than for console output).

Additionally, a list of all the modules is generated (`gromacs.7` for man
pages, and alphabetical and by-topic lists for the HTML pages).

Handling C %main() functions {#section_wrapperbinary_cmain}
----------------------------

Many pre-5.0 modules are still implemented as a function with a C %main()
signature.  All these binaries call parse_common_args() as more or less the
first thing in their processing.  In order to implement the above approach, the
module manager internally creates a command line module for these (in
gmx::CommandLineModuleManager::addModuleCMain()).  The created module
collaborates with parse_common_args() to achieve the same functionality as for
the new C++ modules.

Running the module simply executes the provided %main() method.
Help writing is more complex, as it requires the help context to be passed from
the module to parse_common_args().  This is handled using a global instance of
the context (see gmx::GlobalCommandLineHelpContext).  This context is set in
the module, and if parse_common_args() detects it, it prints out the help and
returns `false` to indicate to the caller that it should immediately return.
Single-instruction Multiple-data (SIMD) coding {#page_simd}
==============================================

Coding with SIMD instructions
=============================

One important way for \Gromacs to achieve high performance is
to use modern hardware capabilities where a single assembly
instruction operates on multiple data units, essentially short
fixed-length vectors (usually 2, 4, 8, or 16 elements). This provides
a very efficient way for the CPU to increase floating-point
performance, but it is much less versatile than general purpose
registers. For this reason it is difficult for the compiler to
generate efficient SIMD code, so the user has to organize the
data in a way where it is possible to access as vectors, and
these vectors often need to be aligned on cache boundaries.

We have supported a number of different SIMD instruction sets in
the group kernels for ages, and it is now also present in the
Verlet kernels and a few other places. However, with the increased
usage and several architectures with different capabilities we now
use a vendor-agnostic \Gromacs SIMD module, as documented in
\ref module_simd.

Design of the \Gromacs SIMD module
==================================

The functions in `src/gromacs/simd` are intended to be used for writing
architecture-independent SIMD intrinsics code. Rather than making assumptions
based on architecture, we have introduced a limited number of
predefined preprocessor macros that describe the capabilities of the
current implementation - these are the ones you need to check when
writing SIMD code. As you will see, the functionality exposed by
this module as typically a small subset of general SIMD implementations,
and in particular we do not even try to expose advanced shuffling or
permute operations, simply because we haven't been able to describe those
in a generic way that can be implemented efficiently regardless of the
hardware. However, the advantage of this approach is that it is straightforward
to extend with support for new simd instruction sets in the future,
and that will instantly speed up old code too.

To support the more complex stuff in the \Gromacs nonbonded kernels and
to make it possible to use SIMD intrinsics even for some parts of the code
where the data is not in SIMD-friendly layout, we have also added about 10
higher-level utility routines. These perform gather/scatter operations
on coordinate triplets, they load table data and aligned pairs (Lennard-Jones
parameters), and sum up the forces needed in the outer loop of the nonbonded
kernels. They are very straightforward to implement, but since they are
performance-critical we want to exploit all features of each architecture,
and for this reason they are part of the SIMD implementation.

Finally, for some architectures with large or very large SIMD width (e.g. AVX
with 8 elements in single precision, or AVX-512 with 16), the nonbonded
kernels can become inefficient. Since all such architectures presently known
(AVX, AVX2, AVX512) also provide extensive support for accessing
parts of the register, we optionally define a handful of routines to
perform load, store, and reduce operations based on half-SIMD-width data,
which can improve performance. It is only useful for wide implementations,
and it can safely be ignored first when porting to new platforms - they
are only needed for the so-called 2xnn SIMD kernels.

Unfortunately there is no standard for SIMD architectures. The available
features vary a lot, but we still need to use quite a few of them to
get the best performance possible. This means some features will only
be available on certain platforms, and it is critical that we do NOT make
too many assumptions about the storage formats, their size or SIMD width.
Just to give a few examples:

- On x86, double precision (64-bit) floating-point values always convert
  to 32-bit integers, while many other platforms use 64-bit, and some cannot
  use 32-bit integers at all. This means we cannot use a mask (boolean)
  derived from integer operations to select double-precision floating-point
  values, and it could get very complex for higher-level code if all these
  decisions were exposed. Instead, we want to keep integers 32-bit since
  all algorithms anyway need to work in single precision (w. 32-bit ints).
- AVX1 only supports 4-wide 128-bit integer SIMD arithmetics, but the integer
  _conversions_ can still be done 8-wide which corresponds to the single
  precision floating-point width. Similarly, with AVX1 conversions between
  double-precision and integers use the 32-bit 4-wide 128bit registers where
  we can also do integer arithmetics. AVX2 adds proper arithmetics for
  8-wide integers. We would severely limit performance if we had to say
  that integer support was not present, so instead we stick to 32-bit ints
  but limit the operations we expose (and do shuffling internally).
- For SSE2 through SSE4.1, double precision is 2-wide, but when we convert
  to integers they will be put in the first two elements of a 4-wide integer
  type. This means we cannot assume that floating-point SIMD registers and
  corresponding integer registers (after conversion) have the same width.
- Since boolean values can have different width for float/double and the
  integers corresponding to float/double, we need to use separate boolean
  types for all these values and convert between them if we e.g. want to use
  the result of an integer compare to select floating-point values.

While this might sound complicated, it is actually far easier than writing
separate SIMD code for 10 architectures in both single & double. The point
is not that you need to remember the limitations above, but it is critical
that you *never assume anything about the SIMD implementation*. We
typically implement SIMD support for a new architecture in days with this
new module, and the extensions required for Verlet kernels
are also very straightforward (group kernels can be more complex, but those
are gradually on their way out). For the higher-level
code, the only important thing is to never _assume_ anything about the SIMD
architecture. Our general strategy in \Gromacs is to split the SIMD coding
in three levels:

<dl>
<dt>Base level generic SIMD</dt>
<dd>
The base level SIMD module (which we get by including `gromacs/simd/simd.h`
provides the API to define and manipulate SIMD datatypes. This will be enough
for lots of cases, and it is a huge advantage that there is roughly
parity between different architectures.
</dd>
<dt>Higher-level architecture-specific SIMD utility functions</dt>
<dd>
For some parts of the code this is not enough. In particular, both the
group and Verlet kernels do insane amounts of floating-point operations,
and since we spend 85-90% of the time in these kernels it is critical that
we can optimize them as much as possible. Here, our strategy is first to
define larger high-level functions that e.g. take a number of distances
and load the table interactions for this interaction. This way we can
move this architecture-specific implementation to the SIMD module, and
both achieve a reasonably clean kernel but still optimize a lot. This
is what we have done for the approximately 10 functions for the nonbonded
kernels, to load tables and Lennard-Jones parameters, and to sum up the
forces in the outer loop. These functions have intentionally been given
names that describe what they do with the data, rather than what their
function is in \Gromacs. By looking at the documentation for these routines,
and the reference implementation, it should be quite straightforward to
implement them for a new architecture too.
</dd>
<dt>Half-SIMD-width architecture-specific utility functions</dt>
<dd>
As described earlier, as the SIMD width increases to 8 or more elements,
the nonbonded kernels can become inefficient due to the large j-particle
cluster size. Things will still work, but if an architecture supports
efficient access to partial SIMD registers (e.g. loading half the width),
we can use this to alter the balance between memory load/store operations
and floating-point arithmetic operations by processing either e.g. 4-by-4
or 2-by-8 interactions in one iteration. When \ref
GMX_SIMD_HAVE_HSIMD_UTIL_REAL is set, a handful of routines to
use this in the nonbonded kernels is present. Avoid using these routines
outside the nonbonded kernels since they are slightly more complex, and
is is not straightforward to determine which alternative provides the best
performance.
</dd>
<dt>Architecture-specific kernels (directories/files)</dt>
<dd>
No code outside the SIMD module implementation directories should try
to execute anything hardware specific. Note that this includes even checking
for what architecture the current SIMD implementation is - you should check
for features instead, so it will work with future ports too.
</dd>
</dl>

File organization
=================

The SIMD module uses a couple of different files:

<dl>
<dt>`gromacs/simd/simd.h`</dt>
<dd>
This is the top-level wrapper that you should always include first.
It will check the settings made at configuration time and include a
suitable low-level implementation (that can be either single, double,
or both). It also contains the routines for memory alignment, and
based on the current \Gromacs precision it will set aliases to 'real'
SIMD datatypes (see further down) so the implementations do not have
to care about \Gromacs-specific details. However, note that you might
not get all SIMD support you hoped for: If you compiled \Gromacs in
double precision but the hardware only supports single-precision SIMD
there will not be any SIMD routines for default \Gromacs 'real' precision.
There are \#defines you can use to check this, as described further down.
</dd>
<dt>`gromacs/simd/impl_reference/impl_reference.h`</dt>
<dd>
This is an example of a low-level implementation. You should never, ever,
work directly with these in higher-level code. The reference implementation
contains the documentation for all SIMD wrappers, though. This file will
in turn include other separate implementation files for single, double,
simd4, etc. Since we want to be able to run the low-level SIMD implementation
in simulators for new platforms, these files are intentionally not using
the rest of the GROMACS infrastructure, e.g. for asserts().
</dd>
<dt>`gromacs/simd/simd_math.h`</dt>
<dd>
SIMD math functions. All functions in this file have to be designed
so they work no matter whether the hardware supports integer SIMD, logical
operations on integer or floating-point SIMD, or arithmetic operations
on integers. However, a few routines check for defines and use faster
algorithms if these features are present.
</dd>
<dt>`gromacs/simd/vector_operations.h`</dt>
<dd>
This file contains a few rvec-related SIMD functions, e.g. to
calculate scalar products, norms, or cross products. They obviously
cannot operate on scalar \Gromacs rvec types, but use separate SIMD
variables for X,Y, and Z vector components.
</dd>
</dl>


SIMD datatypes
==============

The SIMD module handles the challenges mentioned in the introduction
by introducing a number of datatypes;
many of these might map to the same underlying SIMD types, but we need separate
types because some architectures use different registers e.g. for boolean
types.

Floating-point data
-------------------

<dl>
<dt>`#gmx::SimdReal`</dt>
<dd>
This is the SIMD-version of \Gromacs' real type,
which is set based on the CMake configuration and internally aliased
to one of the next two types.
</dd>
<dt>`#gmx::SimdFloat`</dt>
<dd>
This is always single-precision data, but it
might not be supported on all architectures.
</dd>
<dt>`gmx::SimdDouble`</dt>
<dd>
This is always double precision when available,
and in rare cases you might want to use a specific precision.
</dd>
</dl>

Integers corresponding to floating-point values
-----------------------------------------------

For these types, 'correspond' means that it is the integer type we
get when we convert data e.g. from single (or double) precision
floating-point SIMD variables. Those need to be different, since many
common implementations only use half as many elements for double as
for single SIMD variables, and then we only get half the number of
integers too.

<dl>
<dt>`#gmx::SimdInt32`</dt>
<dd>
This is used for integers when converting to/from \Gromacs default "real" type.
</dd>
<dt>`gmx::SimdFInt32`</dt>
<dd>
Integers obtained when converting from single precision, or intended to be
converted to single precision floating-point. These are normal integers
(not a special conversion type), but since some SIMD architectures such as
SSE or AVX use different registers for integer SIMD variables having the
same width as float and double, respectively, we need to separate these
two types of integers. The actual operations you perform on them are normal
ones such as addition or multiplication.
This will also be the widest integer data type if you want to do pure
integer SIMD operations, but that will not be supported on all platforms.
If the architecture does not support any SIMD integer type at all, this
will likely be defined from the floating-point SIMD type, without support
for any integer operations apart from load/store/convert.
</dd>
<dt>`gmx::SimdDInt32`</dt>
<dd>
Integers used when converting to/from double. See the preceding item
for a detailed explanation. On many architectures,
including all x86 ones, this will be a narrower type than `gmx::SimdFInt32`.
</dd>
</dl>

Note that all integer load/stores operations defined here load/store 32-bit
integers, even when the internal register storage might be 64-bit, and we
set the "width" of the SIMD implementation based on how many float/double/
integers we load/store - even if the internal width could be larger.

Boolean values
--------------

We need a separate boolean datatype for masks and comparison results, since
we cannot assume they are identical either to integers, floats or double -
some implementations use specific predicate registers for booleans.

<dl>
<dt>`#gmx::SimdBool`</dt>
<dd>
Results from boolean operations involving reals, and the booleans we use
to select between real values. The corresponding routines have suffix `B`,
like `gmx::simdOrB()`.
</dd>
<dt>`gmx::SimdFBool`</dt>
<dd>
Booleans specifically for single precision.
</dd>
<dt>`gmx::SimdDBool`</dt>
<dd>
Operations specifically on double.
</dd>
<dt>`#gmx::SimdIBool`</dt>
<dd>
Boolean operations on integers corresponding to real (see floating-point
descriptions above).
</dd>
<dt>`gmx::SimdFIBool`</dt>
<dd>
Booleans for integers corresponding to float.
</dd>
<dt>`gmx::SimdDIBool`</dt>
<dd>
Booleans for integers corresponding to double.
</dd>
</dl>

Note: You should NOT try to store and load boolean SIMD types to memory - that
is the whole reason why there are no store or load operations provided for
them. While it will be technically possible to achieve by defining objects
inside a structure and then doing a placement new with aligned memory, this
can be a very expensive operation on platforms where special single-bit
predicate registers are used to represent booleans. You will need to find
a more portable algorithm for your code instead.

The subset you should use in practice
-------------------------------------

If this seems daunting, in practice you should only need to use these types
when you start coding:

<dl>
<dt>`#gmx::SimdReal`</dt>
<dd>
Floating-point data.
</dd>
<dt>`#gmx::SimdBool`</dt>
<dd>
Booleans.
</dd>
<dt>`#gmx::SimdInt32`</dt>
<dd>
Integer data. Might not be supported, so you must check
the preprocessor macros described below.
</dd>
</dl>

Operations on these types will be defined to either float/double (or
corresponding integers) based on the current \Gromacs precision, so the
documentation is occasionally more detailed for the lower-level actual
implementation functions.

Note that it is critical for these types to be aligned in memory. This
should always be the case when you declare variables on the stack, but
unfortunately some compilers (at least clang-3.7 on OS X) appear to be
buggy when our SIMD datatypes are placed inside a structure. Somewhere
in the processes where this structure includes our class, which in turn
includes the actual SIMD datatype, the alignment appears to be lost.
Thus, even though the compiler will not warn you, until further notice
we need to avoid putting the SIMD datatypes into other structures. This
is particular severe when allocating memory on the heap, but it occurs
for stack structures/classes too.


SIMD4 implementation
--------------------

The above should be sufficient for code that works with the full SIMD width.
Unfortunately reality is not that simple. Some algorithms like lattice
summation need quartets of elements, so even when the SIMD width is >4 we
need width-4 SIMD if it is supported. The availability of SIMD4 is indicated
by \ref GMX_SIMD4_HAVE_FLOAT and \ref GMX_SIMD4_HAVE_DOUBLE. For now we only
support a small subset of SIMD operations for SIMD4. Because SIMD4 doesn't
scale with increasingly large SIMD width it should be avoided for all new
code and SIMD4N should be used instead.

SIMD4N implementation
---------------------

Some code, like lattice summation, has inner loops which are smaller
than the full SIMD width. In GROMACS algorithms 3 and 4 iterations are common
because of PME order and three dimensions. This makes 4 an important special
case. Vectorizing such loops efficiently requires to collapse the two
most inner loops and using e.g. one 8-wide SIMD vector for 2 outer
and 4 inner iterations or one 16-wide SIMD vector for 4 outer and 4 inner
iterations. For this SIMD4N functions are
provided. The availability of these function is indicated by
\ref GMX_SIMD_HAVE_4NSIMD_UTIL_FLOAT and
\ref GMX_SIMD_HAVE_4NSIMD_UTIL_DOUBLE.
These functions return the type alias Simd4NFloat / Simd4NDouble which is
either the normal SIMD type or the SIMD4 type and thus only supports
the operations the SIMD4 type supports.

Predefined SIMD preprocessor macros
===================================

Functionality-wise, we have a small set of core features that we
require to be present on all platforms, while more avanced features can be
used in the code when defines like e.g. \ref GMX_SIMD_HAVE_LOADU have the
value 1.

This is a summary of the currently available preprocessor defines that
you should use to check for support when using the corresponding features.
We first list the float/double/int defines set by the _implementation_; in
most cases you do not want to check directly for float/double defines, but
you should instead use the derived "real" defines set in this file - we list
those at the end below.

Preprocessor predefined macro defines set by the low-level implementation.
These only have the value 1 if they work for all datatypes;
\ref GMX_SIMD_HAVE_LOADU thus means we can load both float, double, and
integers from unaligned memory, and that the unaligned loads are available
for SIMD4 too.

<dl>
<dt>\ref GMX_SIMD</dt>
<dd>
Some sort of SIMD architecture is enabled.
</dd>
<dt>\ref GMX_SIMD_HAVE_FLOAT</dt>
<dd>
Single-precision instructions available.
</dd>
<dt>\ref GMX_SIMD_HAVE_DOUBLE</dt>
<dd>
Double-precision instructions available.
</dd>
<dt>\ref GMX_SIMD_HAVE_LOADU</dt>
<dd>
Load from unaligned memory available.
</dd>
<dt>\ref GMX_SIMD_HAVE_STOREU</dt>
<dd>
Store to unaligned memory available.
</dd>
<dt>\ref GMX_SIMD_HAVE_LOGICAL</dt>
<dd>
Support for and/andnot/or/xor on floating-point variables.
</dd>
<dt>\ref GMX_SIMD_HAVE_FMA</dt>
<dd>
Floating-point fused multiply-add.
Note: We provide emulated FMA instructions if you do not have FMA
support, but in that case you might be able to code it more efficient w/o FMA.
</dd>
<dt>\ref GMX_SIMD_HAVE_FINT32_EXTRACT</dt>
<dd>
Support for extracting integer SIMD elements from `gmx::SimdFInt32`.
</dd>
<dt>\ref GMX_SIMD_HAVE_FINT32_LOGICAL</dt>
<dd>
Bitwise shifts on `gmx::SimdFInt32`.
</dd>
<dt>\ref GMX_SIMD_HAVE_FINT32_ARITHMETICS</dt>
<dd>
Arithmetic ops for `gmx::SimdFInt32`.
</dd>
<dt>\ref GMX_SIMD_HAVE_DINT32_EXTRACT</dt>
<dd>
Support for extracting integer SIMD elements from `gmx::SimdDInt32`.
</dd>
<dt>\ref GMX_SIMD_HAVE_DINT32_LOGICAL</dt>
<dd>
Bitwise shifts on `gmx::SimdDInt32`.
</dd>
<dt>\ref GMX_SIMD_HAVE_DINT32_ARITHMETICS</dt>
<dd>
Arithmetic ops for `gmx::SimdDInt32`.
</dd>
<dt>\ref GMX_SIMD_HAVE_HSIMD_UTIL_FLOAT</dt>
<dd>
Half-SIMD-width nonbonded kernel utilities available for float SIMD.
</dd>
<dt>\ref GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE</dt>
<dd>
Half-SIMD-width nonbonded kernel utilities available for double SIMD.
</dd>
<dt>\ref GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_FLOAT</dt>
<dd>
Can load pairs of unaligned floats from simd offsets (meant for linear tables).
</dd>
<dt>\ref GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_DOUBLE</dt>
<dd>
Can load pairs of unaligned doubles from simd offsets (meant for linear tables).
</dd>
</dl>

There are also two macros specific to SIMD4: \ref GMX_SIMD4_HAVE_FLOAT is set
if we can use SIMD4 in single precision, and \ref GMX_SIMD4_HAVE_DOUBLE
similarly denotes support for a double-precision SIMD4 implementation. For
generic properties (e.g. whether SIMD4 FMA is supported), you should check
the normal SIMD macros above.

Implementation properties
-------------------------

Higher-level code can use these macros to find information about the implementation,
for instance what the SIMD width is:

<dl>
<dt>\ref GMX_SIMD_FLOAT_WIDTH</dt>
<dd>
Number of elements in `gmx::SimdFloat`, and practical width of `gmx::SimdFInt32`.
</dd>
<dt>\ref GMX_SIMD_DOUBLE_WIDTH</dt>
<dd>
Number of elements in `gmx::SimdDouble`, and practical width of `gmx::SimdDInt32`</dd>
<dt>\ref GMX_SIMD_RSQRT_BITS</dt>
<dd>
Accuracy (bits) of 1/sqrt(x) lookup step.
</dd>
<dt>\ref GMX_SIMD_RCP_BITS</dt>
<dd>
Accuracy (bits) of 1/x lookup step.
</dd>
</dl>

After including the low-level architecture-specific implementation, this
header sets the following derived defines based on the current precision;
these are the ones you should check for unless you absolutely want to dig
deep into the explicit single/double precision implementations:

<dl>
<dt>\ref GMX_SIMD_HAVE_REAL</dt>
<dd>
Set to either \ref GMX_SIMD_HAVE_FLOAT or \ref GMX_SIMD_HAVE_DOUBLE
</dd>
<dt>\ref GMX_SIMD4_HAVE_REAL</dt>
<dd>
Set to either \ref GMX_SIMD4_HAVE_FLOAT or \ref GMX_SIMD4_HAVE_DOUBLE
</dd>
<dt>\ref GMX_SIMD_REAL_WIDTH</dt>
<dd>
Set to either \ref GMX_SIMD_FLOAT_WIDTH or \ref GMX_SIMD_DOUBLE_WIDTH
</dd>
<dt>\ref GMX_SIMD_HAVE_INT32_EXTRACT</dt>
<dd>
Set to either \ref GMX_SIMD_HAVE_FINT32_EXTRACT or \ref GMX_SIMD_HAVE_DINT32_EXTRACT
</dd>
<dt>\ref GMX_SIMD_HAVE_INT32_LOGICAL</dt>
<dd>
Set to either \ref GMX_SIMD_HAVE_FINT32_LOGICAL or \ref GMX_SIMD_HAVE_DINT32_LOGICAL
</dd>
<dt>\ref GMX_SIMD_HAVE_INT32_ARITHMETICS</dt>
<dd>
Set to either \ref GMX_SIMD_HAVE_FINT32_ARITHMETICS or \ref GMX_SIMD_HAVE_DINT32_ARITHMETICS
</dd>
<dt>\ref GMX_SIMD_HAVE_HSIMD_UTIL_REAL</dt>
<dd>
Set to either \ref GMX_SIMD_HAVE_HSIMD_UTIL_FLOAT or \ref GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE
</dd>
<dt>\ref GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_REAL</dt>
<dd>
Set to either \ref GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_FLOAT or \ref GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_DOUBLE
</dd>
</dl>

For convenience we also define \ref GMX_SIMD4_WIDTH to 4. This will never vary,
but using it helps you make it clear that a loop or array refers to the
SIMD4 width rather than some other '4'.

While all these defines are available to specify the features of the
hardware, we would strongly recommend that you do NOT sprinkle your code
with defines - if nothing else it will be a debug nightmare. Instead you can
write a slower generic SIMD function that works everywhere, and then override
this with faster architecture-specific versions for some implementations. The
recommended way to do that is to add a define around the generic function
that skips it if the name is already defined. The actual implementations in
the lowest-level files are typically defined to an architecture-specific name
(such as `simdSinCosD_Sse2`) so we can override it (e.g. in SSE4) by
simply undefining and setting a new definition. Still, this is an
implementation detail you won't have to worry about until you start writing
support for a new SIMD architecture.


Function naming
---------------

We rely on C++ overloading, so the name of a function is usually identical
regardless of what datatype it operates on. There are a few exceptions to this
for functions that do not take arguments but only return a value, e.g. setZero(),
since overloading only works if the formal parameters are different. To solve this,
we use different low-level function names in these cases, but then create proxy
objects in the high-level `gromacs/simd/simd.h` so that you can still get the
functionality by simply writing setZero() in the code.

Automated checking
------------------

Having fallback implementations when SIMD is not supported can be a
performance problem if the code does not correctly include
`gromacs/simd/simd.h`, particularly after refactoring.
`make check-source` checks the whole code for the use of symbols defined
in `gromacs/simd/simd.h` and requires that files using those symbols
do the correct include. Similar checking is done for higher-level
SIMD-management headers, e.g. `gromacs/ewald/pme_simd.h`.


The SIMD math library
=====================

In addition to the low-level SIMD instructions, \Gromacs comes with a fairly
extensive SIMD math library in `gromacs/simd/simd_math.h` to support various
mathematical functions. The functions are available both in single and
double precision (overloaded on the usual math function names), and we also
provide a special version of functions that use double precision arguments,
but that only evaluate the result to single precision accuracy. This is
useful when you don’t need highly accurate results, but you want to avoid
the overhead of doing multiple single/double conversions, or if the hardware
architecture only provides a double precision SIMD implementation.

For a few functions such as the square root and exponential that are
performance-critical, we provide additional tempate parameters where the
default choice is to execute the normal function version, but it is also
possible to choose an unsafe execution path that completely bypass all
argument checking. Make absolutely sure your arguments always fulfil the
restrictions listed in the documentation of such a function before using it,
and it might even be a good idea to add a note before each call to an unsafe
function justifying why that flavor is fine to use here.
The modular simulator {#page_modularsimulator}
==============================================

A new modular approach to the GROMACS simulator is described. The
simulator in GROMACS is the object which carries out a simulation. The
simulator object is created and owned by the runner object, which is
outside of the scope of this new approach, and will hence not be further
described. The simulator object provides access to some generally used
data, most of which is owned by the runner object.

## Using the modular simulator
GROMACS will automatically use the modular simulator for the velocity
verlet integrator (`integrator = md-vv`), if the functionality chosen
in the other input parameters is implemented in the new framework.
Currently, this includes NVE, NVT, NPH, and NPT simulations,
with or without free energy perturbation, using all available
temperature and pressure coupling algorithms. It also includes pull and
expanded ensemble simulations.

To disable the modular simulator for cases defaulting to the new framework,
the environment variable `GMX_DISABLE_MODULAR_SIMULATOR=ON` can be set. To
use the new framework also for `integrator = md` (where the functionality is
implemented), the environment variable `GMX_USE_MODULAR_SIMULATOR=ON` can 
be set to override legacy default.

## Legacy implementation

In the legacy implementation, the simulator consisted of a number of
independent functions carrying out different type of simulations, such
as `do_md` (MD simulations), `do_cg` and `do_steep` (minimization),
`do_rerun` (force and energy evaluation of simulation trajectories),
`do_mimic` (MiMiC QM/MM simulations), `do_nm` (normal mode analysis),
and `do_tpi` (test-particle insertion).

The legacy approach has some obvious drawbacks:

* *Data management:* Each of the `do_*` functions defines local data,
  including complex objects encapsulating some data and functionality,
  but also data structures effectively used as "global variables" for
  communication between different parts of the simulation. Neither the
  ownership nor the access rights (except for `const` qualifiers) are
  clearly defined.
* *Dependencies:* Many function calls in the `do_*` functions are
  dependent on each others, i.e. rely on being called in a specific
  order, but these dependencies are not clearly defined.
* *Branches:* The flow of the `do_*` functions are hard to understand
  due to branching. At setup time, and then at every step of the
  simulation run, a number of booleans are set (e.g. `bNS` (do neighbor
  searching), `bCalcEner` (calculate energies), `do_ene` (write
  energies), `bEner` (energy calculation needed), etc). These booleans
  enable or disable branches of the code (for the current step or the
  entire run), mostly encoded as `if(...)` statements in the main `do_*`
  loop, but also in functions called from there.
* *Task scheduling:* Poorly defined dependencies and per-step branching
  make task scheduling (e.g. parallel execution of independent tasks)
  very difficult.
* *Error-prone for developers:* Poorly defined dependencies and unclear
  code flow make changing the simulator functions very error-prone,
  rendering the implementation of new methods tedious.

## The modular simulator approach

The main design goals of the new, fully modular simulator approach
include
* *Extensibility:* We want to ease maintenance and the implementation
  of new integrator schemes.
* *Monte Carlo:* We want to add MC capability, which can be mixed with
  MD to create hybrid MC/MD schemes.
* *Data locality & interfaces:* We aim at localizing data in objects,
  and offer interfaces if access from other objects is needed.
* *Multi-stepping:* We aim at a design which intrinsically supports
  multi-step integrators, e.g. having force calls at different
  frequencies, or avoid having branches including rare events
  (trajectory writing, neighbor search, ...) in the computation loops.
* *Task parallelism:* Although not first priority, we want to have a
  design which can be extended to allow for task parallelism.

The general design approach is that of a **task scheduler**. *Tasks*
are argument-less functions which perform a part of the computation.
Periodically during the simulation, the scheduler builds a
*queue of tasks*, i.e. a list of tasks which is then run through in
order. Over time, with data dependencies clearly defined, this
approach can be modified to have independent tasks run in parallel.

### Simulator elements

The task scheduler holds a list of *simulator elements*, defined by
the `ISimulatorElement` interface. These elements have a
`scheduleTask(Step, Time)` function, which gets called by the task
scheduler. This allows the simulator element to register one (or more)
function pointers to be run at that specific `(Step, Time)`. From the
point of view of the element, it is important to note that the
computation will not be carried out immediately, but that it will be
called later during the actual (partial) simulation run. From the
point of view of the builder of the task scheduler, it is important to
note that the order of the elements determines the order in which
computation is performed.

    class ISimulatorElement
    {
    public:
        /*! \\brief Query whether element wants to run at step / time
         *
         * Element can register one or more functions to be run at that step through
         * the registration pointer.
         */
        virtual void scheduleTask(Step, Time, const RegisterRunFunction&) = 0;
        //! Method guaranteed to be called after construction, before simulator run
        virtual void elementSetup() = 0;
        //! Method guaranteed to be called after simulator run, before deconstruction
        virtual void elementTeardown() = 0;
        //! Standard virtual destructor
        virtual ~ISimulatorElement() = default;
    }; 


The task scheduler periodically loops over
its list of elements, builds a queue of function pointers to run, and
returns this list of tasks. As an example, a possible application
would be to build a new queue after each domain-decomposition (DD) /
neighbor-searching (NS) step, which might occur every 100 steps. The
scheduler would loop repeatedly over all its elements, with elements
like the trajectory-writing element registering for only one or no
step at all, the energy-calculation element registering for every
tenth step, and the force, position / velocity propagation, and
constraining algorithms registering for every step. The result would
be a (long) queue of function pointers including all computations
needed until the next DD / NS step, which can be run without any
branching.

### Signallers

Some elements might require computations by other elements. If for
example, the trajectory writing is an element independent from the
energy-calculation element, it needs to signal to the energy element
that it is about to write a trajectory, and that the energy element
should be ready for that (i.e. perform an energy calculation in the
upcoming step). This requirement, which replaces the boolean branching
in the current implementation, is fulfilled by a Signaller - Client
model. Classes implementing the `ISignaller` interface get called
*before* every loop of the element list, and can inform registered
clients about things happening during that step. The trajectory
element, for example, can tell the energy element that it will write
to trajectory at the end of this step. The energy element can then
register an energy calculation during that step, being ready to write
to trajectory when requested.

    class ISignaller
    {
    public:
        //! Function run before every step of scheduling
        virtual void signal(Step, Time) = 0;
        //! Method guaranteed to be called after construction, before simulator run
        virtual void setup() = 0;
    };
    
### The modular simulator

The approach is most easily displayed using some simplified (pseudo) code.
    
The simulator itself is responsible to **store the elements in the 
right order** (in `addIntegrationElements`) This includes the different 
order of elements in different algorithms (e.g. leap-frog vs. velocity
verlet), but also logical dependencies (energy output after compute
globals). Once the algorithm has been built, the simulator simply
executes one task after the next, until the end of the simulation is
reached.

    class ModularSimulator : public ISimulator
    {
        public:
            //! Run the simulator
            void run() override;
    }

    void ModularSimulator::run()
    {

        ModularSimulatorAlgorithmBuilder algorithmBuilder();
        addIntegrationElements(&algorithmBuilder);
        auto algorithm = algorithmBuilder.build();
    
        while (const auto* task = algorithm.getNextTask())
        {
            // execute task
            (*task)();
        }
    }
    
The following snippet illustrates building a leap-frog integration
algorithm. The algorithm builder allows for a concise description of 
the simulator algorithm. 
    
    void ModularSimulator::addIntegrationElements(ModularSimulatorAlgorithmBuilder* builder)
    {
        if (legacySimulatorData_->inputrec->eI == eiMD)
        {
            // The leap frog integration algorithm
            builder->add<ForceElement>();
             // We have a full state here (positions(t), velocities(t-dt/2), forces(t)
            builder->add<StatePropagatorData::Element>();
            if (legacySimulatorData_->inputrec->etc == TemperatureCoupling::VRescale)
            {
                builder->add<VRescaleThermostat>(-1,
                                                 VRescaleThermostatUseFullStepKE::No,
                                                 PropagatorTag("LeapFrogPropagator"));
            }
            builder->add<Propagator<IntegrationStage::LeapFrog>>(PropagatorTag("LeapFrogPropagator"),
                                                                legacySimulatorData_->inputrec->delta_t);
            if (legacySimulatorData_->constr)
            {
                builder->add<ConstraintsElement<ConstraintVariable::Positions>>();
            }
            builder->add<ComputeGlobalsElement<ComputeGlobalsAlgorithm::LeapFrog>>();
            // We have the energies at time t here
            builder->add<EnergyData::Element>();
            if (legacySimulatorData_->inputrec->epc == PressureCoupling::ParrinelloRahman)
            {
                builder->add<ParrinelloRahmanBarostat>(-1, PropagatorTag("LeapFrogPropagator"));
            }
        }
    }
    
### The simulator algorithm
    
The simulator algorithm is responsible to **decide if elements need to
run at a specific time step**. The elements get called in order, and
decide whether they need to run at a specific step. This can be
pre-computed for multiple steps. In the current implementation, the
tasks are pre-computed for the entire life-time of the neighbor
list.

The simulator algorithm offers functionality to get the next task
from the queue. It owns all elements involved in the simulation
and is hence controlling their lifetime. This ensures that pointers and
callbacks exchanged between elements remain valid throughout the duration
of the simulation run. It also maintains the list of tasks,
and updates it when needed.
    
    class ModularSimulatorAlgorithm
    {
    public:
        //! Get next task in queue
        [[nodiscard]] const SimulatorRunFunction* getNextTask();
    private:
        //! List of signalers
        std::vector<std::unique_ptr<ISignaller>> signallerList_;
        //! List of elements
        std::vector<std::unique_ptr<ISimulatorElement>> elementsList_;

        //! The run queue
        std::vector<SimulatorRunFunction> taskQueue_;
        //! The task iterator
        std::vector<SimulatorRunFunction>::const_iterator taskIterator_;

        //! Update task queue
        void updateTaskQueue();
    }
    
The `getNextTask()` function is returning the next task in the task
queue. It rebuilds the task list when needed.
    
    const SimulatorRunFunction* ModularSimulatorAlgorithm::getNextTask()
    {
        if (!taskQueue_.empty())
        {
            taskIterator_++;
        }
        if (taskIterator_ == taskQueue_.end())
        {
            if (runFinished_)
            {
                return nullptr;
            }
            updateTaskQueue();
            taskIterator_ = taskQueue_.begin();
        }
        return &*taskIterator_;
    }
    
Updating the task queue involves calling all signallers and
elements for every step of the scheduling period. This refills
the task queue. It is important to keep in mind that the *scheduling step* is not
necessarily identical to the *current step* of the simulation. Most of
the time, the scheduling step is ahead, as we are pre-scheduling steps.
    
    void ModularSimulatorAlgorithm::updateTaskQueue()
    {
        for (Step schedulingStep = currentStep; 
             schedulingStep < currentStep + schedulingPeriod;
             schedulingStep++)
        {
            Time time = getTime(schedulingStep);
            // Have signallers signal any special treatment of scheduling step
            for (const auto& signaller : signallerList)
            {
                signaller.signal(schedulingStep, time);
            }
            // Query all elements whether they need to run at scheduling step
            for (const auto& element : signallerList)
            {
                element.schedule(schedulingStep, time, registerRunFunction_);
            }
        }
    }

### Sequence diagrams

#### Pre-loop
In the loop preparation, the signallers and elements are created and
stored in the right order. The signallers and elements can then
perform any setup operations needed.

\msc
hscale="2";

ModularSimulatorBuilder [label="ModularSimulatorAlgorithmBuilder"],
ModularSimulator [label="ModularSimulatorAlgorithm"],
Signallers [label="ModularSimulatorAlgorithm::\nSignallers"],
Elements [label="ModularSimulatorAlgorithm::\nElements"],
TaskQueue [label="ModularSimulatorAlgorithm::\nTaskQueue"];

--- [ label = "constructElementsAndSignallers()" ];
    ModularSimulatorBuilder => Signallers [ label = "Create signallers\nand order them" ];
    ModularSimulatorBuilder => Elements [ label = "Create elements\nand order them" ];
--- [ label = "constructElementsAndSignallers()" ];
|||;
|||;

--- [ label = "setupAllElements()" ];
    ModularSimulator => Signallers [ label = "Call setup()" ];
    Signallers box Signallers [ label = "for signaler in Signallers\n    signaller->setup()" ];
    |||;
    ModularSimulator => Elements [ label = "Call setup()" ];
    Elements box Elements [ label = "for element in Elements\n    element->setup()" ];
--- [ label = "setupAllElements()" ];
\endmsc

#### Main loop
The main loop consists of two parts which are alternately run until the
simulation stop criterion is met. The first part is the population of
the task queue, which determines all tasks that will have to run to
simulate the system for a given time period. In the current implementation,
the scheduling period is set equal to the lifetime of the neighborlist.
Once the tasks have been predetermined, the simulator runs them in order.
This is the actual simulation computation, which can now run without any
branching.

\msc
hscale="2";

ModularSimulator [label="ModularSimulatorAlgorithm"],
Signallers [label="ModularSimulatorAlgorithm::\nSignallers"],
Elements [label="ModularSimulatorAlgorithm::\nElements"],
TaskQueue [label="ModularSimulatorAlgorithm::\nTaskQueue"];

ModularSimulator box TaskQueue [ label = "loop: while(not lastStep)" ];
ModularSimulator note TaskQueue [ label = "The task queue is empty. The simulation state is at step N.", textbgcolor="yellow" ];
|||;
|||;
ModularSimulator box ModularSimulator [ label = "populateTaskQueue()" ];
ModularSimulator =>> TaskQueue [ label = "Fill task queue with tasks until next neighbor-searching step" ];
|||;
|||;
ModularSimulator note TaskQueue [ label = "The task queue now holds all tasks needed to move the simulation from step N to step N + nstlist. The simulation for these steps has not been performed yet, however. The simulation state is hence still at step N.", textbgcolor="yellow" ];
|||;
|||;

ModularSimulator => TaskQueue [ label = "Run all tasks in TaskQueue" ];
TaskQueue box TaskQueue [label = "for task in TaskQueue\n    run task" ];
TaskQueue note TaskQueue [ label = "All simulation computations are happening in this loop!", textbgcolor="yellow" ];
|||;
|||;
ModularSimulator note TaskQueue [ label = "The task queue is now empty. The simulation state is at step N + nstlist.", textbgcolor="yellow" ];
ModularSimulator box TaskQueue [ label = "end loop: while(not lastStep)" ];

\endmsc

#### Task scheduling
A part of the main loop, the task scheduling in `populateTaskQueue()` 
allows the elements to push tasks to the task queue. For every scheduling 
step, the signallers are run first to give the elements information about 
the upcoming scheduling step. The scheduling routine elements are then 
called in order, allowing the elements to register their respective tasks.

\msc
hscale="2";

ModularSimulator [label="ModularSimulatorAlgorithm"],
Signallers [label="ModularSimulatorAlgorithm::\nSignallers"],
Elements [label="ModularSimulatorAlgorithm::\nElements"],
TaskQueue [label="ModularSimulatorAlgorithm::\nTaskQueue"];

--- [ label = "populateTaskQueue()" ];
    ModularSimulator box ModularSimulator [ label = "doDomainDecomposition()\ndoPmeLoadBalancing()" ];
    ModularSimulator =>> Elements [ label = "Update state and topology" ];
    |||;
    |||;

    ModularSimulator note ModularSimulator [ label = "schedulingStep == N\nsimulationStep == N", textbgcolor="yellow" ];
    ModularSimulator box TaskQueue [ label = "loop: while(not nextNeighborSearchingStep)" ];
        ModularSimulator => Signallers [ label = "Run signallers for schedulingStep" ];
        Signallers box Signallers [label = "for signaller in Signallers\n    signaller->signal(scheduleStep)" ];
        Signallers =>> Elements [ label = "notify" ];
        Signallers note Elements [ label = "The elements now know if schedulingStep has anything special happening, e.g. neighbor searching, log writing, trajectory writing, ...", textbgcolor="yellow" ];
        |||;
        |||;

        ModularSimulator => Elements [ label = "Schedule run functions for schedulingStep" ];
        Elements box Elements [label = "for element in Elements\n    element->scheduleTask(scheduleStep)" ];
        Elements =>> TaskQueue [ label = "Push task" ];
        Elements note TaskQueue [ label = "The elements have now registered everything they will need to do for schedulingStep.", textbgcolor="yellow" ];
        ModularSimulator note ModularSimulator [ label = "schedulingStep++", textbgcolor="yellow" ];

    ModularSimulator box TaskQueue [ label = "end loop: while(not nextNeighborSearchingStep)" ];
--- [ label = "populateTaskQueue()" ];
ModularSimulator note ModularSimulator [ label = "schedulingStep == N + nstlist\nsimulationStep == N", textbgcolor="yellow" ];

\endmsc

## Acceptance tests and further plans

Acceptance tests which need to be 
fulfilled to make the modular simulator the default code path:

* End-to-end tests pass on both `do_md` and the new loop in
  Gitlab pre- and post-submit pipelines
* Physical validation cases pass on the new loop
* Performance on different sized benchmark cases, x86 CPU-only
  and NVIDIA GPU are at most 1% slower -
  https://github.com/ptmerz/gmxbenchmark has been developed to
  this purpose.

After the MD bare minimum, we will want to add support for

* Pulling
* Full support of GPU (current implementation does not support
GPU update)

Using the new modular simulator framework, we will then explore
adding new functionality to GROMACS, including

* Monte Carlo barostat
* hybrid MC/MD schemes
* multiple-time-stepping integration

We will also explore optimization opportunities, including

* re-use of the same queue if conditions created by user input are 
  sufficiently favorable (by design or when observed)
* simultaneous execution of independent tasks

We will probably not prioritize support for (and might consider
deprecating from do_md in a future GROMACS version)

* Simulated annealing
* REMD
* Simulated tempering
* Multi-sim
* Membrane embedding
* QM/MM
* FEP lambda vectors
* Fancy mdp options for FEP output
* MTTK
* Essential dynamics
* Constant acceleration groups
* Ensemble-averaged restraints
* Time-averaged restraints
* Freeze, deform, cos-acceleration

## Signaller and element details

The current implementation of the modular simulator consists of
the following signallers and elements:

### Signallers

All signallers have a list of pointers to clients, objects that
implement a respective interface and get notified of events the
signaller is communicating.

* `NeighborSearchSignaller`: Informs its clients whether the
  current step is a neighbor-searching step.
* `LastStepSignaller`: Informs its clients when the current step
  is the last step of the simulation.
* `LoggingSignaller`: Informs its clients whether output to the
  log file is written in the current step.
* `EnergySignaller`: Informs its clients about energy related
  special steps, namely energy calculation steps, virial
  calculation steps, and free energy calculation steps.
* `TrajectorySignaller`: Informs its clients if writing to
  trajectory (state [x/v/f] and/or energy) is planned for the
  current step.

### Simulator Elements

#### `TrajectoryElement`
The `TrajectoryElement` is calling its trajectory clients, passing them a valid
output pointer and letting them write to trajectory. Unlike the
legacy implementation, the trajectory element itself knows nothing
about the data that is written to file - it is only responsible
to inform clients about trajectory steps, and providing a valid
file pointer to the objects that need to write to trajectory.

#### `ComputeGlobalsElement`
The `ComputeGlobalsElement` encapsulates the legacy calls to
`compute_globals`. While a new approach to the global reduction
operations has been discussed, it is currently not part of this
effort. This element therefore aims at offering an interface
to the legacy implementation which is compatible with the new
simulator approach.

The element currently comes in 3 (templated) flavors: the leap-frog case,
the first call during a velocity-verlet integrator, and the second call
during a velocity-verlet integrator. It is the responsibility of the
simulator builder to place them at the right place of the
integration algorithm.

#### `ForceElement` and `ShellFCElement`
The `ForceElement` and the `ShellFCElement` encapsulate the legacy
calls to `do_force` and `do_shellfc`, respectively. It is the
responsibility of the simulator builder to place them at the right
place of the integration algorithm. Moving forward, a version of these
elements which would allow calling of do_force with subsets of the topology
would be desirable to pave the way towards multiple time step integrators
within modular simulator, allowing to integrate slower degrees of freedom
at a different frequency than faster degrees of freedom.

#### `ConstraintElement`
The constraint element is implemented for the two cases of constraining
both positions and velocities, and only velocities. It does not change the constraint
implementation itself, but replaces the legacy `constrain_coordinates`
and `constrain_velocities` calls from update.h by elements implementing
the ISimulatorElement interface and using the new data management.

#### `Propagator`
The propagator element can, through templating, cover the different
propagation types used in the currently implemented MD schemes. The
combination of templating, static functions, and having only the
inner-most operations in the static functions allows to have performance
comparable to fused update elements while keeping easily re-orderable
single instructions.

Currently, the (templated) implementation covers four cases:

 * *PositionsOnly:* Moves the position vector by the given time step
 * *VelocitiesOnly:* Moves the velocity vector by the given time step
 * *LeapFrog:* A manual fusion of the previous two propagators
 * *VelocityVerletPositionsAndVelocities:* A manual fusion of VelocitiesOnly 
    and PositionsOnly, where VelocitiesOnly is only propagated by half the 
    time step of PositionsOnly.

The propagators also allow to implement temperature and pressure coupling
schemes by offering (templated) scaling of the velocities. In order to
link temperature / pressure coupling objects to the propagators, the
propagator objects have a tag (of strong type `PropagatorTag`). The
temperature and pressure coupling objects can then connect to the
matching propagator by comparing their target tag to the different
propagators. Giving the propagators their tags and informing the
temperature and pressure coupling algorithms which propagator they are
connecting to is in the responsibility of the simulation algorithm
builder.

#### `CompositeSimulatorElement`
The composite simulator element takes a list of elements and implements
the ISimulatorElement interface, making a group of elements effectively
behave as one. This simplifies building algorithms.

#### `VRescaleThermostat`
The `VRescaleThermostat` implements the v-rescale thermostat. It takes a
callback to the propagator and updates the velocity scaling factor
according to the v-rescale thermostat formalism.

#### `ParrinelloRahmanBarostat`
The `ParrinelloRahmanBarostat` implements the Parrinello-Rahman barostat.
It integrates the Parrinello-Rahman box velocity equations, takes a
callback to the propagator to update the velocity scaling factor, and
scales the box and the positions of the system.

#### `StatePropagatorData::Element`
The `StatePropagatorData::Element` takes part in the simulator run, as it might
have to save a valid state at the right moment during the
integration. Placing the StatePropagatorData correctly is for now the
duty of the simulator builder - this might be automated later
if we have enough meta-data of the variables (i.e., if
`StatePropagatorData` knows at which time the variables currently are,
and can decide when a valid state (full-time step of all
variables) is reached. The `StatePropagatorData::Element` is also a client of
both the trajectory signaller and writer - it will save a
state for later writeout during the simulator step if it
knows that trajectory writing will occur later in the step,
and it knows how to write to file given a file pointer by
the `TrajectoryElement`.

#### `EnergyData::Element`
The `EnergyData::Element` takes part in the simulator run, 
either adding data (at energy calculation steps), or
recording a non-calculation step (all other steps). It is the
responsibility of the simulator builder to ensure that the
`EnergyData::Element` is called at a point of the simulator run
at which it has access to a valid energy state.

It subscribes to the trajectory signaller, the energy signaller,
and the logging signaller to know when an energy calculation is
needed and when a non-recording step is enough. The EnergyData
element is also a subscriber to the trajectory writer element, 
as it is responsible to write energy data to trajectory.

#### `FreeEnergyPerturbationData::Element`
The `FreeEnergyPerturbationData::Element` is a member class of
`FreeEnergyPerturbationData` that updates the lambda
values during the simulation run if lambda is non-static. It
implements the checkpointing client interface to save the current
state of `FreeEnergyPerturbationData` for restart.

## Data structures

### `StatePropagatorData`
The `StatePropagatorData` contains a little more than the pure
statistical-physical micro state, namely the positions,
velocities, forces, and box matrix, as well as a backup of
the positions and box of the last time step. While it takes
part in the simulator loop to be able to backup positions /
boxes and save the current state if needed, it's main purpose
is to offer access to its data via getter methods. All elements
reading or writing to this data need a pointer to the
`StatePropagatorData` and need to request their data explicitly. This
will later simplify the understanding of data dependencies
between elements.

Note that the `StatePropagatorData` can be converted to and from the
legacy `t_state` object. This is useful when dealing with
functionality which has not yet been adapted to use the new
data approach. Of the elements currently implemented, only
domain decomposition, PME load balancing, and the initial
constraining are using this.

### `EnergyData`
The EnergyData owns the EnergyObject, and is hence responsible
for saving energy data and writing it to trajectory.
The EnergyData offers an interface to add virial contributions,
but also allows access to the raw pointers to tensor data, the
dipole vector, and the legacy energy data structures.

### `FreeEnergyPerturbationData`
The `FreeEnergyPerturbationData` holds the lambda vector and the
current FEP state, offering access to its values via getter
functions.

## Simulator algorithm builder
Elements that define the integration algorithm (i.e. which are
added using the templated `ModularSimulatorAlgorithmBuilder::add`
method) need to implement a `getElementPointerImpl` factory function.
This gives them access to the data structures and some other
infrastructure, but also allows elements to accept additional
arguments (e.g frequency, offset, ...).

    template<typename Element, typename... Args>
    void ModularSimulatorAlgorithmBuilder::add(Args&&... args)
    {
        // Get element from factory method
        auto* element = static_cast<Element*>(getElementPointer<Element>(
                legacySimulatorData_, &elementAdditionHelper_, statePropagatorData_.get(),
                energyData_.get(), freeEnergyPerturbationData_.get(), &globalCommunicationHelper_,
                std::forward<Args>(args)...));

        // Make sure returned element pointer is owned by *this
        // Ensuring this makes sure we can control the life time
        if (!elementExists(element))
        {
            throw ElementNotFoundError("Tried to append non-existing element to call list.");
        }
    
        // Register element with infrastructure
    }
    
Note that `getElementPointer<Element>` will call `Element::getElementPointerImpl`,
which needs to be implemented by the different elements.

### Data management
Modular simulator encourages design localizing data as much as possible. It
also offers access to generally used data structures (such as the current
state or energies). To allow for generic data to be shared between elements,
the simulator algorithm builder also allows to store objects with life time
guaranteed to be either equal to the simulator algorithm builder or equal to
the simulator algorithm object (i.e. longer than the life time of the elements).

## Infrastructure
### `DomDecHelper` and `PmeLoadBalanceHelper`
These infrastructure elements are responsible for domain decomposition and 
PME load balancing, respectively. They encapsulate function calls which are 
important for performance, but outside the scope of this effort. They rely 
on legacy data structures for the state (both) and the topology (domdec).
    
The elements do not implement the ISimulatorElement interface, as
the Simulator is calling them explicitly between task queue population
steps. This allows elements to receive the new topology / state before
deciding what functionality they need to run.

### Checkpointing
The `CheckpointHelper` is responsible to write checkpoints, and to offer
its clients access to the data read from checkpoint.

Writing checkpoints is done just before neighbor-searching (NS) steps,
or before the last step. Checkpointing occurs periodically (by default,
every 15 minutes), and needs two NS steps to take effect - on the first
NS step, the checkpoint helper on master rank signals to all other ranks
that checkpointing is about to occur. At the next NS step, the checkpoint
is written. On the last step, checkpointing happens immediately before the
step (no signalling). To be able to react to last step being signalled,
the CheckpointHelper also implements the `ISimulatorElement` interface,
but only registers a function if the last step has been called.

Checkpointing happens at the top of a simulation step, which gives a
straightforward re-entry point at the top of the simulator loop.

#### Implementation details
##### Other (older) approaches
**Legacy checkpointing approach:** All data to be checkpointed needs to be
stored in one of the following data structures:

* `t_state`, which also holds pointers to
  - `history_t` (history for restraints)
  - `df_history_t` (history for free energy)
  - `ekinstate`
  - `AwhHistory`
* `ObservableHistory`, consisting of
  - `energyhistory_t`
  - `PullHistory`
  - `edsamhistory_t`
  - `swaphistory_t`
* Checkpoint further saves details about the output files being used

These data structures are then serialized by a function having knowledge of
their implementation details. One possibility to add data to the checkpoint
is to expand one of the objects that is currently being checkpointed, and
edit the respective `do_cpt_XXX` function in `checkpoint.cpp` which interacts
with the XDR library. The alternative would be to write an entirely new data
structure, changing the function signature of all checkpoint-related functions,
and write a corresponding low-level routine interacting with the XDR library.

**The MDModule approach:** To allow for modules to write checkpoints, the legacy
checkpoint was extended by a KVTree. When writing to checkpoint, this tree gets
filled (via callbacks) by the single modules, and then serialized. When reading,
the KVTree gets deserialized, and then distributed to the modules which can read
back the data previously stored.

##### Modular simulator design

The MDModule checks off almost all requirements to a modularized checkpointing format.
The proposed design is therefore an evolved form of this approach. Notably, two
improvements include

* Hide the implementation details of the data structure holding the data (currently,
  a KV-Tree) from the clients. This allows to change the implementation details of
  reading / writing checkpoints without touching client code.
* Offer a unified way to read and write to data, allowing clients to write one
  (templated) function to read to and write from checkpoint. This allows to
  eliminate code duplication and the danger of having read and write functions
  getting out of sync.

The modular simulator checkpointing does not currently change the way that the
legacy simulator is checkpointing. Some data structures involved in the legacy
checkpoint did, however, get an implementation of the new approach. This is
needed for ModularSimulator checkpointing, but also gives a glimpse of how
implementing this for legacy data structures would look like.

The most important design part is the `CheckpointData` class. It exposes methods
to read and write scalar values, ArrayRefs, and tensors. It also allows to create
a "sub-object" of the same type `CheckpointData` which allows to have more complex
members implement their own checkpointing routines (without having to be aware that
they are a member). All methods are templated on the chosen operation,
`CheckpointDataOperation::Read` or `CheckpointDataOperation::Write`, allowing clients
to use the same code to read and write to checkpoint. Type traits and constness are
used to catch as many errors as possible at compile time. `CheckpointData` uses a
KV-tree to store the data internally. This is however never exposed to the client.
Having this abstraction layer gives freedom to change the internal implementation
in the future.

All `CheckpointData` objects are owned by a `ReadCheckpointDataHolder` or
`WriteCheckpointDataHolder`. These holder classes own the internal KV-tree, and offer
`deserialize(ISerializer*)` and `serialize(ISerializer*)` functions, respectively,
which allow to read from / write to file. This separation clearly defines ownership
and separates the interface aimed at file IO from the interface aimed at objects
reading / writing checkpoints.

Checkpointing for modular simulator is tied in the general checkpoint facility by
passing a `ReadCheckpointDataHolder` or `WriteCheckpointDataHolder` object to the
legacy checkpoint read and write operations.

##### Notes about the modular simulator checkpointing design

**Distinction of data between clients:** The design requires that separate
clients have independent sub-`CheckpointData` objects identified by a unique key.
This key is the only thing that needs to be unique between clients, i.e. clients are
free to use any key _within_ their sub-`CheckpointData` without danger to overwrite
data used by other clients.

**Versioning:** The design relies on clients keeping their own versioning system
within their sub-`CheckpointData` object. As the data stored by clients is opaque
to the top level checkpointing facility, it has no way to know when the internals
change. Only fundamental changes to the checkpointing architecture can still be
tracked by a top-level checkpoint version.

**Key existence:** The currently uploaded design does not allow to check whether
a key is present in `CheckpointData`. This could be introduced if needed - however,
if clients write self-consistent read and write code, this should never be needed.
Checking for key existence seems rather to be a lazy way to circumvent versioning,
and is therefore discouraged.

**Callback method:** The modular simulator and MDModules don't use the exact same
way of communicating with clients. The two methods could be unified if needed.
The only _fundamental_ difference is that modular simulator clients need to identify
with a unique key to receive their dedicated sub-data, while MDModules all read from
and write to the same KV-tree. MDModules could be adapted to that by either requiring
a unique key from the modules, or by using the same `CheckpointData` for all modules
and using a single unique key (something like "MDModules") to register that object
with the global checkpoint.

**Performance:** One of the major differences between the new approach and the legacy
checkpointing is that data gets _copied_ into `CheckpointData`, while the legacy
approach only took a pointer to the data and serialized it. This slightly reduces
performance. Some thoughts on that:

* By default, checkpointing happens at the start of the simulation (only if reading
from checkpoint), every 15 minutes during simulation runs, and at the end of the
simulation run. This makes it a low priority target for optimization. Consequently,
not much thoughts have been put in the optimization, but there's certainly some way
to improve things here and there if we consider it necessary.
* The copying will only have measurable effect when large data gets checkpointed -
likely only for saving the positions / velocities of the entire state, so that
should be the first target for optimization if needed.
* Copying data could have advantages moving forward - we could continue the
simulation as soon as the data is written to the `CheckpointData` object, and don't
necessarily need to wait for writing to the physical medium to happen. It also
simplifies moving the point at which checkpointing is performed within the
integrator. One could envision clients storing their data any time during the
integration step, and serializing the resulting `CheckpointData` after the step.
This avoids the need to find a single point within the loop at which all clients
need to be in a state suitable for checkpointing.
* If, however, we wanted to use the same approach for other, more frequent
(and hence more perfomance critical) operations such as saving/restoring states
for MC type algorithms or swapping of states between running simulations in
multi-sim type settings, performance would become more of an issue.

**ISerializer vs KV-tree:** The new approach uses a KV tree internally. The
KV tree is well suited to represent the design philosophy of the approach:
Checkpointing offers a functionality which allows clients to write/read any data
they want. This data remains opaque to the checkpointing element. Clients can
read or write in any order, and in the future, maybe even simultaneously. Data
written by any element should be protected from access from other elements to
avoid bugs. The downside of the KV tree is that all data gets copied before
getting written to file (see above).

Replacing a KV tree by a single ISerializer object which gets passed to clients
would require elements to read and write sequentially in a prescribed order. With
the help of InMemorySerializer, a KV-Tree could likely be emulated (with sub-objects
that serialize to memory, and then a parent object that serializes this memory to
file), but that doesn't present a clear advantage anymore.

### `TopologyHolder`
The topology object owns the local topology and holds a constant reference
to the global topology owned by the ISimulator.

The local topology is only infrequently changed if domain decomposition is
on, and never otherwise. The topology holder therefore offers elements to register
as ITopologyHolderClients. If they do so, they get a handle to the updated local 
topology whenever it is changed, and can rely that their handle is valid 
until the next update. The domain decomposition element is defined as friend 
class to be able to update the local topology when needed.

### Reference temperature manager

Some simulation techniques such as simulated annealing and simulated tempering need
to be able to change the reference temperature of the simulation. The reference
temperature manager allows elements to register callbacks so they are informed
when the reference temperature is changed. They can then perform any action they
need upon change of the reference temperature, such as updating a local value,
scaling velocities, or recalculating a temperature coupling integral.

When changing temperature, the clients are also informed about which
algorithm changed the temperature. This is required for compatibility
to the legacy implementation - different algorithms react differently
(or not at all) to reference temperature change from different sources.
The current implementation does not attempt to fix these inconsistencies, but
rather makes the choices in the legacy implementation very explicit, which will
allow to tackle these issues more easily moving forward.
**Summary**

(What do we need to set/change a policy for?)

**Impact**

(Policies do not replace doing work, every policy means one more thing people need to read, and we cannot have policies for every single question. Is this something that is absolutely required to have a policy for that warrants the entire team being involved in spending time discussing it, and that definitely cannot be handled with common sense? Is having this policy worth adding more things new developers must obey, and get asked to change in their future merge requests? Policy issues should be VERY rare, such that we can discuss a small number of them in general meetings. Do not open multiple policy issues in a short timeframe as a way to gather feedback for your own work needs, because they often become some of our most time-consuming issues, and we are all busy.)

**Why**

(What would happen if we don't have, or don't change, this policy?)

**Where**

(Where should the policy be described? There should never be more than one place for this, so we keep it up-to-date.)

**Who**

(Who can take responsibility for documenting this policy in a way that is clearly understandable to new developers?)

/label ~Policy

**Follow-up description**

(Describe the actual follow-up. Devs are unlikely to prioritize issues that cannot be understood without having to go and read an older discussion first. Did the original author agree this should be a follow-up they will address in the short term? If yes, assign it to them. If not, please resolve that discussion in the original thread instead of just postponing the conflict until nobody works on the follow-up issue.)

**Impact**

(Is this something that must be done, and which we (including you) will prioritize, rather than one of a million things that could be done, but that won't be prioritized in practice? Avoid creating follow-up issues neither you nor the original author will work on.)

**Other contributors**

(Apart from the original author, who else will contribute to this?)

**Timeframe**

(When will this be completed? Assign a suitable milestone in the near future. Our experience says that follow-ups scheduled several years into the future or not having any milestones at all won't see any action at all. Then it's better not to create them rather than somebody else having to close it 6 months from now due to inactivity.)

/label ~Follow-up
**Summary**

(Short and sweet description for a greater concept covering many different sub-issues/features. Make sure this is clear and understandable to all developers, not just the ones already working on the feature)

**Use cases**

(Describe how this general concept/feature will make a differece - from a user point of view, not just developers.)

**Impact**

(What users would this matter to? Is it likely to have large impact relative to the amount of work required?)

**Detailed description**

(Describe the concept in detail, and how it related to other umbrella issues. Avoid creating multiple umbrella issues in closely related areas, and make sure developers not working on this part of the code will be able to understand the concept even if they are not on top of all your abbreviations. Create detailed bullet list with things that need to be done and why, link to other issues, and make sure this stays up-to-date.)

**Responsible developer**

(Umbrella issues must have a developer assigned, who has responsibility for keeping it updated.)

**Time plan**

(Over what timeframe is this work expected to happen? Since Umbrella issues are usually longer-lived, you will be expected to update this text such that other developers understand how the umbrella issue is making progress - bullet lists are great for this.)

**Links/references/implementations**

(Having a link to a paper can be a nice addition to a detailed description, but it's unlikely developers will have time to e.g. go and read a paper if you didn't have time to describe the feature in detail here. Would you be willing to write the implementation?)

/label ~Umbrella-Issue

**Summary**

(Why would this be useful?)

**Use cases**

(How will this enhancement make a difference to users, rather than developers?)

**Impact**

(For whom will this matter? Is it likely to have large impact relative to the amount of work required? If you are a developer, is this something you expect to prioritize higher than the (many) other things that could be done to the code? Will it simplify/remove code, rather than add more code? Avoid adding very general nice-to-have features unless you are planning to work on it yourself in the immediate timeframe.)

**Detailed description**

(Please describe the enhancement in detail. Avoid merely linking to external descriptions; developers are unlikely to find time to read external descriptions if the person proposing the enhancement didn't have time to describe it.) 

/label ~Enhancement
**Summary**

(Summarize the bug encountered concisely)

**GROMACS version**

(Paste the output of `gmx -quiet --version` here, and select the relevant version (year is enough) if you can find it in the drop-down label list. We support the current stable release (typically the same as the current year), and also fix bugs that have direct/critical relevance for scientific results in the very-stable-release (typically last year's release). If your bug appears in a version older than that, or a version of the code that you modified, please confirm you can reproduce it with a currently supported version of the code first.)

**Steps to reproduce**

(Please describe how we can reproduce the bug, and share all files needed - ideally both the TPR file and the raw GRO/MDP/TOP files needed to regenerate it. Bugs that only appear after running for 3 hours on 200 GPUs unfortunately tend to not get a lot of attention. You will typically get much faster attention if you have been able to narrow it down to the smallest possible input, command line, system size, etc.)

**What is the current bug behavior?**

(What actually happens)

**What did you expect the correct behavior to be?**

(What you should see instead)

(Please include at least the top of the GROMACS log file, as well as the end if there is any info about a possible crash. This file contains a lot of information about the hardware, software versions, libraries and compilers that help us in debugging). 

**Possible fixes**

(Any suggestions or thoughts are welcome. If you can, link to the line of code that might be responsible for the problem)

/label ~Bug

**Summary**

(Why would this be useful?)

**Use cases**

(Describe how the feature will make a differece - from a user point of view, not just developers.)

**Impact**

(What users would this matter to? Is it likely to have large impact relative to the amount of work required?)

**Detailed description**

(Describe the feature in detail. If this is e.g. a new algorithm you developed, are there a lot of people who have cited the paper, or other implementations available? How does it go  beyond the current state of the code?)

**Requirements**

(Is there other stuff needed?)

**Links/references/implementations**

(Having a link to a paper can be a nice addition to a detailed description, but it's unlikely developers will have time to e.g. go and read a paper if you didn't have time to describe the feature in detail here. Would you be willing to write the implementation?)

/label ~Feature

# Python package sources

This directory exists as a staging area supporting GROMACS enhancement
[#2045](https://gitlab.com/gromacs/gromacs/-/issues/2045),
which attempts to update the gmxapi efforts from GROMACS 2019,
merge external repositories from
https://github.com/kassonlab/gmxapi
and
https://github.com/kassonlab/sample_restraint,
and build the new functionality proposed at
https://github.com/kassonlab/gmxapi-scripts

## Repository organization

**TODO: testing infrastructure and project management conventions to allow fully integrated development**
**TODO: Consider long term homes of these directory contents.**

## gmxapi

Python framework for gmxapi high-level interface.

The `src` directory provides the files that will be copied to the GROMACS installation location from which users may 
install Python packages.
This allows C++ extension modules to be built against a user-chosen GROMACS installation,
but for a Python interpreter that is very likely different from that used
by the system administrator who installed GROMACS.

To build and install the Python package,
first install GROMACS to `/path/to/gromacs`.
Then, install the package in a Python virtualenv.

    source /path/to/gromacs/bin/GMXRC
    python3 -m venv $HOME/somevirtualenv
    source $HOME/somevirtualenv/bin/activate
    (cd src && pip install -r requirements.txt && pip install .)
    python -c 'import gmxapi as gmx'

Use `pytest` to run unit tests and integration tests.

    pip install -r requirements-test.txt
    pytest src/test
    pytest test

For additional discussion on packaging and distribution, see
https://gitlab.com/gromacs/gromacs/-/issues/2896

## Sample MD extension code

`sample_restraint` is a subtree containing a complete CMake project for building
pluggable GROMACS MD extensions for execution through gmxapi. Up to and
including version 0.0.7 of the sample code, the sub-project lived at
https://github.com/kassonlab/sample_restraint/ and was supported by GROMACS 2019.

The GROMACS repository becomes the upstream source for the sample code for
GROMACS releases 2020 and higher. Refer to [README.md](sample_restraint/README.md)
in `python_packaging/sample_restraint` for more information.

To use a plugin based on the sample restraint, you will need to build and install
the gmxapi Python package (above).

**todo** CookieCutter repo for easy forking.

## Docker and Travis-CI testing

**TODO: Migrate to Jenkins-based CI as Docker infrastructure becomes available.**
Infastructure described here is transitional and reflects our need to be able to see code work 
in order to review it satisfactorily in the period before GROMACS CI infrastructure 
is ready for the load. At some point the Docker aspects will change,
or be removed as appropriate.

The Python packaging will be tested on Jenkins with Docker-based CI, but this
infrastructure is a little way off. In the mean time, we are trying to submit
changes that do not affect main line GROMACS development or building and to
perform testing with Docker externally. Users may build and run Docker images
from the `python_packaging/docker` directory. The `kassonlab` Travis-CI account
will automatically build and run Docker-based tests for each outstanding
feature branch.

The Dockerfiles
* direct a few different Linux, Python, and GROMACS configurations,
* build and install the `gmxapi` and `sample_restraint` packages, and
* provide a few styles of testing through the `scripts` accessible through `entrypoint.sh`.

In successive build stages, Travis-CI is directed to use a series of Docker images,
referred to here with their dockerhub repository, an explanation of tags,
and the Dockerfiles from which they are built.
The image naming scheme encodes a build matrix element in the repository name and
a git branch or reference in the image tag (described below).
Additional information in `python_packaging/docker/README.md`.

1. `gmxapi/gromacs-dependencies-<matrix>:<tag>` Ubuntu distribution with dependencies for
   various GROMACS build configurations. `<matrix>` encodes the build matrix dimensions
   for things like compiler and MPI flavor. Travis-CI will rebuild this for commits to
   `kassonLabFork`, but if the `<matrix>` string changes, a more privileged dockerhub
   account will have to push the new repository the first time and then grant access
   to the service account used by the Travis-CI configuration.
   `<tag>` is the (short) git revision hash
   of the `master` branch commit corresponding to the current state of the `kassonLabFork`
   branch.
2. `gmxapi/gromacs-<matrix>:<tag>` Builds on `gromacs-dependencies-<matrix>`, where
   `<matrix>` has the same meaning as above. `<tag>` is the (short) git revision hash
   of the `master` branch commit corresponding to the current state of the `kassonLabFork`
   branch.
   This is recorded in the `kassonLabFork` `.travis.yml`.
3. `gmxapi/ci-<matrix>:<tag>` starts with `gromacs-<matrix>` and merges in the
    `python_packaging` changes associated with the feature branch indicated by `<tag>`

Hint: the fork point from `master` and the current git ref can be set as environment variables:

    FORKPOINT=$(git show -s --pretty=format:"%h" `git merge-base master HEAD`)
    REF=`git show -s --pretty=format:"%h"`

## External project code

Refer to `./src/external/README.md` for current details on the copied external
sources.

# pybind11

Python bindings are expressed in C++ using the
[pybind11](https://pybind11.readthedocs.io/en/stable/)
template library.
The pybind11 repository is mirrored in GROMACS project sources and
installed with GROMACS for convenience and reproducibility.

# Build and install

## Cross compiling

On some systems, GROMACS will have been built and installed for a different
architecture than the system on which the Python package will be compiled.
We need to use CMake Tool-chains to support cross-compiling for the target architecture.

## Offline installation

The `pip install` options `--no-index` and `--find-links` allow for an offline stash of package archives so that
satisfying dependencies for a new virtualenv does not require network access or lengthy build times.

# Dependencies

## OS X
Some dependencies (notably, a Python installation itself) may require some fiddling
with the XCode SDK.
https://developer.apple.com/documentation/xcode_release_notes/xcode_10_release_notes#3035624

# Tests for gmxapi Python packages distributed with GROMACS

## Requirements

Python tests use the `unittest` standard library module and the `unittest.mock`
submodule, included in Python 3.3+.

The additional `pytest` package allows tests to be written more easily and
concisely, with easier test fixtures (through decorators), log handling, and
other output handling.

## Files

Python files beginning with `test_` are collected by the Python testing
framework during automatic test discovery.

`conftest.py` and `pytest.ini` provide configuration for `pytest`.

## Usage

For basic tests, install the Python package(s) (presumably into a virtualenv),
then use the `pytest` executable to run these tests against the installed
package(s).

`pytest $LOCAL_REPO_DIR/python_packaging/src/test`

where `$LOCAL_REPO_DIR` is the path to the local copy of the GROMACS source repository.

For multi-process tests, run with an MPI execution wrapper and the `mpi4py` module.

`mpiexec -n 2 python -m mpi4py -m pytest $LOCAL_REPO_DIR/python_packaging/test`

## Controlling output

Refer to pytest documentation for command line options to control the type and detail of output.
Some high level overview and basic tasks are online at https://docs.pytest.org/en/3.9.3/usage.html
but you should run `pytest -h` in a terminal to get the complete set of available options
(in particular, note *log_cli* and *log_level*).
Sample MD restraint plugin
==========================

This [repository](https://github.com/kassonlab/sample_restraint)
provides a complete and working implementation of a few GROMACS
restraint potentials. It is intended as both a tutorial and as a
template for implementing new custom restraint potentials.

Restraint potentials are implemented as \"plugins\" to GROMACS.
GROMACS must be [configured with
GMXAPI=ON](http://manual.gromacs.org/current/install-guide/index.html#gmxapi-external-api)

The plugin potentials are loaded and configured via Python and are
compatible with the [gmxapi](https://github.com/kassonlab/gmxapi) Python
package for MD simulation workflows.

For a quick start, consider pulling a recent Docker image that has
already been configured for gmxapi and this plug-in.
**todo:** check and update (ref: [GitHub issue 230](https://github.com/kassonlab/gmxapi/issues/230))

Reference:

Irrgang, M. E., Hays, J. M., & Kasson, P. M. gmxapi: a high-level
interface for advanced control and extension of molecular dynamics
simulations. *Bioinformatics* 2018. DOI:
[10.1093/bioinformatics/bty484](https://doi.org/10.1093/bioinformatics/bty484)

Repository Contents
-------------------

This repository uses CMake to build and install a Python C++ extension
package.

-   `CMakeLists.txt`, `cmake/FindGROMACS.cmake`, and
    `src/CMakeLists.txt` provide necessary CMake infrastructure. You
    should not need to edit these.
-   `src/cpp` contains a header and `cpp` file for each restraint
    potential built with this module. When adding new potentials, you
    will update `CMakeLists.txt` to create build targets. Use the
    existing potentials as examples.
-   `src/pythonmodule/` contains `CMakeLists.txt`, `export_plugin.h`,
    and `export_plugin.cpp`. When you have written a new potential, you
    can add it to `CMakeLists.txt` and `export_plugin.cpp`. This is the
    code that produces the C++ extension for Python.
    `EnsemblePotential` applies a restrained ensemble potential and
    uses additional facilities provided by gmxapi.
-   <strike>`src/pybind11` is just a copy of the Python bindings framework from
    the Pybind project (ref <https://github.com/pybind/pybind11> ). It
    is used to wrap the C++ restraint code and give it a Python
    interface.</strike> Note: pybind is currently retrieved while configuring
    with CMake. Ref issues [3027](https://gitlab.com/gromacs/gromacs/-/issues/3027)
    and [3033](https://gitlab.com/gromacs/gromacs/-/issues/3033)
-   `tests/` contains C++ and Python tests for the provided code. Update
    `CMakeLists.txt` to add your own, based on these examples. C++ unit
    tests use [googletest](https://github.com/google/googletest). Python
    tests use the [pytest](https://docs.pytest.org/en/latest/). Refer to
    those respective projects for more about how they make test-writing
    easier. Note: googletest is currently downloaded while configuring with
    CMake. Ref [3033](https://gitlab.com/gromacs/gromacs/-/issues/3033)
-   `examples` contains a sample SLURM job script and
    `restrained-ensemble.py` gmxapi script that have been used to do
    restrained ensemble simulations. `example.py` and `example.ipynb`
    explore a toy alanine dipeptide system. `strip_notebook.py` is a
    helper script to remove extra output and state data from an iPython
    notebook before checking updates back into the repository.
-   `Dockerfile` is a recipe to build a Docker image from the root of
    the repository. **todo:** Check and update.
    ref: GitHub issue [230](https://github.com/kassonlab/gmxapi/issues/230)

Docker quick-start
------------------

**todo: check and update** ref: [GitHub issue 230](https://github.com/kassonlab/gmxapi/issues/230)

Pull the docker image and launch a container with port 8888 on the host
mapped to port 8888 in the container. :

    docker run --rm -ti -p 8888:8888 gmxapi/sample_restraint:devel

Note that the `--rm` option tells docker not to save any changes you
make after launching the container. You can, however, download any
changes you make to the notebook through the web interface. Refer to the
[Docker documentation](https://docs.docker.com) for more options on
managing containers.

You should then see something like the following, but with a different
`token` for the URL. Open the URL in a browser on the same (host)
machine to access the notebook server. Browse to `sample_restraint` and
`examples` and then launch the `example` notebook for an interactive
walk-through. Example output:

    Execute the command: jupyter notebook
    [I 15:26:07.683 NotebookApp] Writing notebook server cookie secret to /home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret
    [W 15:26:08.184 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
    [I 15:26:08.223 NotebookApp] JupyterLab alpha preview extension loaded from /opt/conda/lib/python3.6/site-packages/jupyterlab
    [I 15:26:08.230 NotebookApp] Serving notebooks from local directory: /home/jovyan
    [I 15:26:08.230 NotebookApp] 0 active kernels
    [I 15:26:08.230 NotebookApp] The Jupyter Notebook is running at:
    [I 15:26:08.230 NotebookApp] http://[all ip addresses on your system]:8888/?token=948d611453ea3f03ad406dc375bfc186c4315fa68c50e23d
    [I 15:26:08.230 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
    [C 15:26:08.231 NotebookApp]

        Copy/paste this URL into your browser when you connect for the first time,
        to login with a token:
            http://localhost:8888/?token=948d611453ea3f03ad406dc375bfc186c4315fa68c50e23d

The basics
----------

This repository provides a potentially useful plugin, but also serves as
documentation by example and as a template for developing GROMACS
extension code in the gmxapi framework.

### Build and install

To download, build, and install, you may need to first install `wget`,
`git`, and/or `cmake`.

The plugin requires libgmxapi to build. See
[gmxapi](http://manual.gromacs.org/current/install-guide/index.html#gmxapi-external-api).
Download an official release from http://www.gromacs.org or the latest gmxapi
development branch from https://github.com/kassonlab/gmxapi/

We use CMake to configure and build a C++ library and a Python module
for interacting with it.

After installing GROMACS, either source the GMXRC file provided with the GROMACS
installation or set the `gmxapi_ROOT` CMake variable to the GROMACS installation path.

The GROMACS installation provides some additional CMake infrastructure to help us build compatible client software.
To help set the correct compilers, specify the CMake hints file with,
*e.g.*, `-C /usr/local/gromacs/share/cmake/gromacs/gromacs-hints.cmake` (for GROMACS installed
 to `/usr/local/gromacs`).
**todo:** Link to GROMACS docs for the toolchains file.

We recommend installing and using this code in a Python virtual
environment. (See the documentation for your `gmxapi` distribution or
<http://gmxapi.readthedocs.io/en/latest/install.html> ) Accordingly, if
you choose to install the plugin rather than just to use it out of
its build directory, consider whether you want to have to set your
`PYTHONPATH` environment variable or where you can install it that
Python will find it. You can explicitly set the installation location by
setting `-DGMXPLUGIN_INSTALL_PATH=/path/to/install/directory` or you can
let CMake determine an appropriate location automatically for your
Python interpreter. If you have administrative privileges (such as when
running on a desktop computer) or if you are using a Python virtual
environment (recommended), you don\'t need to specify anything
additional. If you are an unprivileged user (such as on a shared
machine) and are not in a Python virtual environment, set
-DGMXPLUGIN\_USER\_INSTALL=ON to install into the \"user\" Python
packages directory in your home directory. (Equivalent to the `--user`
option to `pip`)

If you have multiple Python installations or just want to be
unambiguous, provide CMake with the Python interpreter you wish to use
(the same as you are using for `gmxapi`) with
`-DPYTHON_EXECUTABLE=/path/to/python3`.

From the root directory of the GROMACS source, the sample_restraint source code is in
`python_packaging/sample_restraint`

    cd python_packaging/sample_restraint
    mkdir build
    cd build
    # Get the GROMACS environment settings.
    source $HOME/gromacs/bin/GMXRC
    # Configure the build environment with CMake
    cmake ..
    # or
    # cmake .. -DGMXPLUGIN_INSTALL_PATH=/path/to/install/directory
    # or
    # cmake .. -DGMXPLUGIN_USER_INSTALL=ON -DPYTHON_EXECUTABLE=`which python3`
    # Build myplugin.
    make
    # build and run C++ tests
    make tests
    make test
    # optionally, install
    make install

If you choose not to install the plugin module, you can tell Python
where to find it by setting your PYTHONPATH environment variable. For
instance, while still in the build directory:

    export PYTHONPATH=`pwd`/src/pythonmodule

The Python `gmxapi` package is required for testing.
See the [README.md](../README.md) 
file in the parent directory.

### Running

The `examples` directory contains some sample scripts for running
`gmxapi` workflows using the restraint potential samples in this
repository. You may also find [tests/test_binding.py](tests/test_binding.py) informative.

For a basic walk-through with a toy system, launch a Jupyter notebook
server and navigate to `examples/example.py`

**todo** These scripts have not been checked since migrating to the GROMACS source repository.

### What\'s going on

This sample project builds several C++ object files, which are used to build a
Python module named `myplugin`.

When setting up a workflow, a Python script provides gmxapi with
parameters and a factory function for a plugin restraint potential. This
Python interface is defined in `src/pythonmodule/export_plugin.cpp`.
When a Session is launched, a C++ object that performs restraint force
calculations is created and given to the GROMACS library. During each MD
step, part of the MD force evaluation includes a call to the
calculations performed by the restraint. For the pair restraints
demonstrated here, GROMACS provides relative coordinates of two atomic
sites to the calculation code in the plugin. If multiple restrained
pairs are needed, multiple restraints are attached to the simulation.
Coordination across an ensemble of simulations is possible using
resources provided by the Session.

Fundamentally, a new restraint potential is implemented by creating a
class that provides a `calculate()` method and using wrappers to give it
interfaces to GROMACS and to Python. C++ wrappers allow the basic class
implementing the potential to be presented to the GROMACS library in a
way that can be used to evaluate forces during a simulation. Other C++
template code wraps the potential in a portable way so that it can be
passed to GROMACS through a Python interface and to receive parameters
from the Python interpreter. Pybind11 syntax in `export_plugin.cpp`
provides the code to actually expose the plugin as a class in a Python
module that is compatible with the `gmx` package provided in the
`gmxapi` project.

By version 0.1.0, additional wrappers and boilerplate code will be
migrated out of the files that define the `calculate()` methods. Until
then, some amount of copy-and-paste or editing is necessary to implement
a new potential. Refer to `src/cpp/harmonicpotential.h` and to
`src/cpp/harmonicpotential.cpp` for a documented example of a simple
pair restraint. A more complex example is found in the
`ensemblepotential` files. The code in `src/cpp` is sufficient to
produce testable object code, but the Python module is exported in
`src/pythonmodule/export_plugin.cpp`. If you add additional source files
for a new potential, you will need to update `src/cpp/CMakeLists.txt` as
well.

Python tests
------------

For the Python-level testing, you will need `pytest` and `gmxapi`. We
recommend setting up a Python virtual environment as described in the gmxapi installation instructions.

You will also need a functioning MPI installation and the `mpi4py`
package.

Python tests can be run from the root directory of the repository after
building. Assuming you built in a subdirecory of the repository named
`build` (as above):

    PYTHONPATH=build/src/pythonmodule/ python -m pytest tests

This command causes the directory named `tests` to be explored for
Python files with names like `test_*.py` or `*_test.py`. Matching files
will be imported and any functions with similarly obvious names will be
run and errors reported. In particular, `assert` statements will be
evaluated to perform individual tests. See also
<https://docs.pytest.org/en/latest/goodpractices.html#test-discovery>

The tests assume that the package is already installed or is available
on the default Python path (such as by setting the `PYTHONPATH`
environment variable). If you just run `pytest` with no arguments, it
will discover and try to run tests from elsewhere in the repository that
were not intended, and they will fail.

To run the full set of tests for the ensemble workflow features, first
make sure that you have an MPI-capable environment and `mpi4py`
installed. Refer to <http://mpi4py.readthedocs.io/en/stable/> and
<https://github.com/kassonlab/gmxapi> for more information.

The ensemble tests assume that 2 ranks are available. After installing
the plugin, run (for example):

    mpiexec -n 2 python -m mpi4py -m pytest

**todo** check and update the following. (ref: [GitHub issue 230](https://github.com/kassonlab/gmxapi/issues/230))

If you do not have MPI set up for your system, you could build a docker
image using the Dockerfile in this repository.

    docker build -t samplerestraint . Dockerfile
    docker run --cpus 2 --rm -ti samplerestraint bash -c \
        "cd /home/jovyan/sample_restraint/tests && 
        mpiexec -n 2 python -m mpi4py -m pytest"

To test with a pre-built image from our docker hub repository, do

    docker run --cpus 2 --rm -ti gmxapi/sample_restraint bash -c \
            "cd /home/jovyan/sample_restraint/tests && 
            mpiexec -n 2 python -m mpi4py -m pytest"
# Docker images

This directory segregates the Dockerfiles to avoid clutter. The Dockerfiles
here help to build and test gmxapi software. They may be subsumed or supplanted
by future infrastructure.

Assume you have already checked out the commit you want to build for.
Assume the following definitions.

    FORKPOINT=$(git show -s --pretty=format:"%h" `git merge-base master HEAD`)
    TAG="fr1" # for functional requirement 1

## Building

Note that the examples show the builds tagged in the `gmxapi` dockerhub namespace.
If you don't have access to it, you can remove `gmxapi/` from the `-t` argument or use
a different dockerhub project space.

The different Dockerfiles require different build contexts (final path argument).

For `gromacs-dependencies`, the build context doesn't matter. Just use `.` in the
`docker` directory.

    docker build -t gmxapi/gromacs-dependencies-mpich -f gromacs-dependencies.dockerfile .
    # optional:
    docker tag gmxapi/gromacs-dependencies-mpich gmxapi/gromacs-dependencies-mpich:${FORKPOINT}

This should rarely be necessary, and the dependent images can probably just pull the `latest`
from dockerhub.

For `gromacs`, the build context needs to be the root of the GROMACS repository (`../..`).
In case images for feature branches diverge too much or become tightly coupled to particular revisions in `master`,
it may be useful to tag this image to annotate the GROMACS build.

    # Use DOCKER_CORES to let `make` use all cores available to the Docker engine.
    # optionally include an additional `--build-arg REF=${FORKPOINT}`
    docker build -t gmxapi/gromacs-mpich --build-arg DOCKER_CORES=4 -f gromacs.dockerfile ../..
    # optional:
    docker tag gmxapi/gromacs-mpich gmxapi/gromacs-mpich:${FORKPOINT}

For integration testing here, we only want the `python_packaging` subdirectory (`..`).
The image should be tagged according to the functionality it is intended to demonstrate.

    docker build -t gmxapi/ci-mpich:${TAG} --build-arg REF=${FORKPOINT} -f ci.dockerfile ..

## Running

**Warning:** The `--rm` flag tells Docker to remove the container after the
process completes. This prevents unnamed containers from consuming more disk
space on the host with each `run`.

Alternatively, replace `--rm` with `--name containername` to save a named copy
of the container and consider using `commit`ing snapshots of the container.

Refer to Docker documentation for details.

### ci.dockerfile

The default user for this image is `testing`. The gmxapi and sample_restraint
Python packages are installed into a Python 3 `venv` (virtual environment) owned
by the `testing` user.

The `entrypoint.sh` script activates the python venv and wraps commands in a `bash` `exec`.
The default command is a script sourced from `../scripts/run_pytest.sh`. You can use this,
other scripts, `bash`, etc.

    docker run --rm -t gmxapi/ci-mpich:${TAG}
    docker run --rm -t gmxapi/ci-mpich:${TAG} run_pytest_mpi
    docker run --rm -ti gmxapi/ci-mpich:${TAG} bash

### Why venv?

`venv` is the suggested and primary installation mode for the gmxapi Python package,
so it is the most important installation mode to test.

These scripts will ultimately be ported to as-yet-undefined GROMACS testing
infrastructure.
It seems equally plausible to have a single image with multiple Python installations
as to have multiple Docker images, or that single-Python docker images would use
some sort of Python virtualenv system to manage non-default Python interpreters.

Since the installation, tests, and shell environment for post-mortem all use the
"testing" user instead of "root", the venv provides a tidy place to work, avoids
the need for the `--user` flag to `pip`, and gives us a convenient place to do
`pip freeze` to get a known baseline of a working Python environment.

#### Entry points

Images have an ENTRYPOINT script that allows
a container to be launched with a reasonable default command, an executable
locatable in the container, or one of the scripts copied from the `scripts`
directory parallel to this one. These additional scripts are primarily to
allow easy execution of certain suites of tests.

See the `scripts` directory for details.

### Debugging

To be able to step through with gdb, run with something like the following, replacing
'imagename' with the name of the docker image built with this recipe.

    docker run --rm -ti --security-opt seccomp=unconfined imagename bash

### notebook.dockerfile

Built on `gmxapi/ci-mpich:latest`, this image adds a `notebook` entry point to
be used as the new default command. Run with port mapping for http port 8888 for
easy access to a Jupyter notebook server running in the docker container's
`testing` user home directory.

    docker run --rm -ti -p 8888:8888 gmxapi/notebook

Note that, when run with `--rm`, changes made to files in the container will be
lost when `docker run` completes.
To preserve work in a notebook run this way,
download the `ipynb` through theJupyter web interface
(such as when updating the examples in the repository).

### docs.dockerfile

For very quick and isolated documentation builds on top of the gmxapi/ci-mpich 
image, build the image from docs .dockerfile.
The resulting image is a small web server image (without GROMACS or gmxapi installed) 
with html content built in and copied from a temporary container.

    docker run --rm -p 8080:80 gmxapi/docs

Then browse to http://localhost:8080/

## Automation

*TODO: Update this section as CI infrastructure evolves.*

Travis-CI builds and pushes a chain of Docker images to the `gmxapi` dockerhub organization.
The `kassonlab` GitHub organization `gromacs-gmxapi` repository branches that are descended from the `kassonLabFork`
branch have the necessary Travis-CI configuration.
# Testing scripts

The scripts in this directory are for convenience when running different suites of tests.
They can be specified as arguments to the Docker containers based on `ci.dockerfile`

* `run_flake8` runs the Flake8 Python linting tool on the `gmxapi` package sources.
* `run_gmxapi_unittest` runs single-threaded tests for the gmxapi Python package.
* `run_sample_test` runs the tests for the sample_restraint MD plugin API client code.
* `run_full` runs all of the above tests.
* `run_full_mpi` launches a 2-rank MPI session for the various Python tests.
.. image:: https://travis-ci.org/beltoforion/muparser.svg?branch=master
    :target: https://travis-ci.org/beltoforion/muparser

.. image:: https://ci.appveyor.com/api/projects/status/u4882uj8btuspj9x?svg=true
    :target: https://ci.appveyor.com/project/jschueller/muparser-9ib44

muparser - Fast Math Parser 2.3.2
===========================

For a detailed description of the parser go to http://beltoforion.de/article.php?a=muparser.

See Install.txt for installation

Change Notes for Revision 2.3.2
------------
Changes:
------------
* removed "final" keyword from Parser class since this API change broke multiple client applications

Security Fixes: 
------------
The following issue was present in all older releases.

* https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=23410 (Heap-buffer-overflow)

API and ABI compliance check with version 2.2.6
------------

Version 2.3 will extend existing enumerators. New Error codes have been added. In the muparser base class protected functions for implementing basic mathematical operations such as sin,cos, sqrt,tan,... have been removed.

The binary interface should be compatible with versions 2.2.6 unless the parser is used in ways that i did not forsee. I checked the compliance against the sample application compiled for 2.2.6 by exchanging the library with the new version 2.3. I did not see any problems. You can find a complete ABI compliance report here:

https://www.beltoforion.de/en/muparser/compat_reports/2.2.6_to_2.3.2/compat_report.html

I recommend replacing existing versions of 2.2.6 with version 2.3.2. Please report all incompatibilities that you find (API and ABI). I will try to fix them before the final release (if reasonable)


Change Notes for Revision 2.3.1
------------
No changes, only prereleases exist. Version 2.3.2 replaced them.


Change Notes for Revision 2.3.0
------------

Version 2.3.0 will bring fixes for parsing in bulk mode. It will enable OpenMP by default thus allowing the parallelization of expression evaluation. It will also fix a range of issues reported by oss-fuz (https://github.com/google/oss-fuzz).

Changes:
------------

* using OpenMP is now the default settings for cmake based builds
* added optimization for trivial expressions. (Expressions with an RPN length of 1)
* introduced a maximum length for expressions (5000 Character)
* introduced a maximum length for identifiers (100 Characters)
* removed the MUP_MATH_EXCEPTION macro and related functionality. (C++ exceptions for divide by zero or sqrt of a negative number are no longer supported)
* removed ParserStack.h (replaced with std::stack)
* removed macros for defining E and PI 
* the MUP_ASSERT macro is no longer removed in release builds for better protection against segmentation faults

Security Fixes: 
------------

Fixed several issues reported by oss-fuzz. The issues were present in older releases. Most of them resulted in segmentation faults.

* https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=23330
* https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=22922
* https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=22938
* https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=23330
* Added additional runtime checks for release builds to prevent segmentation faults for invalid expressions

Bugfixes:
------------

* Fixed an issue where the bulk mode could hang on GCC/CLANG builds due to OpenMP chunksize dropping below 1.

=======================================
Welcome to the |Gromacs| documentation!
=======================================

..  todo::

    Consolidate at least some of the material in the
    Documentation links below into the new user guide, along with all
    of http://www.gromacs.org/Documentation/Cut-off_schemes,
    http://www.gromacs.org/Documentation/Acceleration_and_parallelization
    and http://www.gromacs.org/Documentation/Performance_checklist)

.. only:: html

        The complete documentation is also available as a `printable PDF here`_. The documentation
        for other versions of |GROMACS| can be found at http://manual.gromacs.org/documentation

        .. toctree::
           :maxdepth: 1
        
           download
           release-notes/index
           install-guide/index
           user-guide/index
           how-to/index
           reference-manual/index
           gmxapi/index
	   nblib/index
           dev-manual/index
        
        ==================
        Indices and tables
        ==================
        
        * :ref:`genindex`

.. only:: latex

      The release notes can be found online at http://manual.gromacs.org/current/release-notes/index.html

         .. toctree::
            :maxdepth: 1
         
            download
            install-guide/index
            user-guide/index
            how-to/index
            reference-manual/index
            gmxapi/index
	    nblib/index
            dev-manual/index


.. _printable PDF here: `gmx-manual`_


.. _downloads:

Downloads
=========

|GMX_MANUAL_DOI_STRING|

|GMX_SOURCE_DOI_STRING|

Source code
-----------
* |gmx-source-package-ftp|
* |gmx-source-package-http|
* (md5sum |SOURCE_MD5SUM|)

Other source code versions may be found at the
`web site <http://www.gromacs.org/Downloads>`_.

Regression tests
----------------
* |gmx-regressiontests-package|
* (md5sum |REGRESSIONTEST_MD5SUM|)
.. _doxygen-module-testutils: ../doxygen/html-lib/group__module__testutils.xhtml
.. _doxygen-page-modulegraph: ../doxygen/html-lib/page_modulegraph.xhtml
.. _doxygen-page-refdata: ../doxygen/html-lib/page_refdata.xhtml
.. _doxygen-page-wrapperbinary: ../doxygen/html-lib/page_wrapperbinary.xhtml
.. _style-guidelines:

Style guidelines
================

Different style guidelines are available under the respective sections of
this page.

.. toctree::
   :maxdepth: 2

   formatting
   includestyle
   naming
   language-features
   reportstyle
   commitstyle
   error-handling

:doc:`formatting`
  Guidelines for indentation and other code formatting.
:doc:`includestyle`
  Guidelines for #include style (ordering, paths to use, etc.).
:doc:`naming`
  Naming conventions for files and various code constructs.
:doc:`language-features`
  Allowed language features.
:doc:`error-handling`
  How to handle errors at run time
:ref:`dev-doxygen-guidelines`
  Guidelines for using Doxygen to document the source code are currently in a
  section on the page on general Doxygen usage.
:doc:`reportstyle`
  Guidelines for preparing and formatting bug reports.
:doc:`commitstyle`
  Guidelines for formatting git commits when sending in proposed fixes for code review.

.. todo:: Add more guidelines
Codebase overview
=================

The root directory of the |Gromacs| repository only contains :file:`CMakeLists.txt`
(the root file for the CMake build system), a few files supporting the build
system, and a few standard informative files (:file:`README` etc.).  The
:file:`INSTALL` is generated for source packages from
:file:`docs/install-guide/index.rst`.

All other content is in the following top-level directories:

:file:`admin/`
  Contains various scripts for developer use, as well as configuration files
  and scripts for some of the tools used.
:file:`cmake/`
  Contains code fragments and find modules for CMake.
  Some content here is copied and/or adapted from newer versions of CMake than
  the minimum currently supported.
  Default suppression file for valgrind is also included here.
  See :doc:`build-system` for details of the build system.
:file:`docs/`
  Contains the build system logic and source code for all documentation, both
  user-facing and developer-facing.  Some of the documentation is generated
  from the source code under :file:`src/`; see :ref:`dev-doc-layout`.
  This directory also contains some developer scripts that use the Doxygen
  documentation for their operation.
:file:`scripts/`
  Contains the templates for :file:`GMXRC` script, some other installed scripts,
  as well as installation rules for all these scripts.
:file:`share/`
  Contains data files that will be installed under :file:`share/`.  These
  include a template for writing C++ analysis tools, and data files used by
  |Gromacs|.
:file:`src/`
  Contains all source code.  See :ref:`dev-source-layout`.
:file:`tests/`
  Contains build system logic for some high-level tests.  Currently, only the
  regression test build system logic, while other tests are under :file:`src/`.

.. _dev-source-layout:

Source code organization
------------------------

The following figure shows a high-level view of components of what gets built
from the source code under :file:`src/` and how the code is organized.
Arrows indicate the direction of dependencies.
The build system is described in detail in :doc:`build-system`.
With default options, the green and white components are built as part of the
default target.
The gray parts are for testing, and are by default only built as part of the
``tests`` target, but if ``GMX_DEVELOPER_BUILD`` is ``ON``, then these are
included in the default build target.
See :doc:`testutils` for details of the testing side.

.. digraph:: dev_high_level_components

   concentrate = yes
   node [ shape=box, style=filled, width=2 ]

   subgraph {
     rank = same
     externals [
       label="externals\nsrc/external/", group=common, style=rounded
     ]
     gtest [
       label="Google Test & Mock\nsrc/external/googletest/", group=test
       style="rounded,filled", fillcolor="0 0 0.9"
     ]
   }
   subgraph {
     rank = same
     libgromacs [
       label="libgromacs\nsrc/gromacs/", group=gmx, fillcolor="0.33 0.3 1"
     ]
   }
   testutils [
     label="testutils\nsrc/testutils/", group=test
     style="rounded,filled", fillcolor="0 0 0.9"
   ]
   subgraph {
     rank = same
     gmx [
       label="gmx\nsrc/programs/", group=gmx, fillcolor="0.33 0.3 1"
     ]
     tests [
       label="test binaries\nsrc/.../tests/", group=test
       style="rounded,filled", fillcolor="0 0 0.9"
     ]
     template [
       label="analysis template\nshare/template/", group=common
       fillcolor="0.33 0.3 1"
     ]

     gmx -> template [ style=invis, constraint=no ]
   }

   libgromacs -> externals
   gmx -> libgromacs
   testutils -> externals
   testutils -> gtest
   testutils -> libgromacs
   tests -> gtest
   tests -> libgromacs
   tests -> testutils
   template -> libgromacs

All the source code (except for the analysis template) is under the
:file:`src/` directory.  Only a few files related to the build system are
included at the root level.  All actual code is in subdirectories:

:file:`src/gromacs/`
  The code under this directory is built into a single library,
  :file:`libgromacs`.  Installed headers are also located in this hierarchy.
  This is the main part of the code, and is organized into further subdirectories
  as *modules*.  See below for details.
:file:`src/programs/`
  The |Gromacs| executable ``gmx`` is built from code under this directory.
  Also found here is some of the driver code for the ``mdrun`` module called
  by ``gmx``, the whole of the ``gmx view`` visualization module, and numerous
  end-to-end tests of ``gmx mdrun``.

:file:`src/{...}/tests/`
  Various subdirectories under :file:`src/` contain a subdirectory named
  :file:`tests/`.  The code from each such directory is built into a test
  binary.  Some such directories also provide shared test code as object
  libraries that is linked into multiple test binaries from different folders.
  See :doc:`testutils` for details.
:file:`src/testutils/`
  Contains shared utility code for writing Google Test tests.
  See :doc:`testutils` for details.
:file:`src/external/`
  Contains bundled source code for various libraries and
  components that |Gromacs| uses internally.  All the code from these
  directories are built using our custom build rules into :file:`libgromacs`,
  or in some cases into the test binaries.  Some CMake options change which
  parts of this code are included in the build.
  See :doc:`build-system` for some explanation about how the code in this
  directory is used.
:file:`src/external/build-fftw/`
  This folder contains the build system code for
  downloading and building FFTW to be included into :file:`libgromacs`.

When compiling, the include search path is set to :file:`src/`.
Some directories from under :file:`src/external/` may also be included,
depending on the compilation options.

Organization under :file:`src/gromacs/`
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The :file:`libgromacs` library is built from code under :file:`src/gromacs/`.
Again, the top-level directory contains build and installation rules for the
library, and :dfn:`public API convenience headers`.  These convenience headers
provide the main installed headers that other code can use.  They do not
contain any declarations, but only include a suitable set of headers from the
subdirectories.  They typically also contain high-level Doxygen documentation
for the subdirectory with the same name: :file:`{module}.h` corresponds to
:file:`{module}/`.

The code is organized into subdirectories.  These subdirectories are denoted as
:dfn:`modules` throughout this documentation.  Each module consists of a set
of routines that do some well-defined task or a collection of tasks.

Installed headers are a subset of the headers under :file:`src/gromacs/`.
They are installed into a corresponding hierarchy under
:file:`include/gromacs/` in the installation directory.
Comments at the top of the header files contain a note about their visibility:
public (installed), intra-library (can be used from inside the library), or
intra-module/intra-file. All headers should compile by themselves,
with installed headers doing so without reference to variables
defined in ``config.h`` or requiring other headers to be included before it.
Not installed headers are allowed to include ``config.h``. Cyclic include dependencies
prevent this, and must be avoided because of this. This is best guaranteed
by including every header in some source file as the first header,
even before ``config.h``.

Code inside the library should not unnecessarily include headers. In
particular, headers should not include other headers if a forward
declaration of a type is enough for the header. Within the library
source files, include only headers from other modules that are
necessary for that file. You can use the public API header if you
really require everything declared in it.

See :doc:`naming` for some common naming patterns for files that can help
locating declarations.

Tests, and data required for them, are in a :file:`tests/` subdirectory under
the module directory.
See :doc:`testutils` for more details.

.. _dev-doc-layout:

Documentation organization
--------------------------

All documentation (including this developer guide) is produced from source
files under :file:`docs/`, except for some command-line help that is generated
from the source code (by executing the compiled :file:`gmx` binary).
The build system provides various custom targets that build the documentation;
see :doc:`build-system` for details.

:file:`docs/fragments/`
  Contains reStructuredText fragments used through ``.. include::`` mechanism
  from various places in the documentation.

User documentation
^^^^^^^^^^^^^^^^^^

:file:`docs/install-guide/`
  Contains reStructuredText source files for building the install guide section
  of the user documentation, as well as the :file:`INSTALL` file for the source
  package.
  The build rules are in :file:`docs/CMakeLists.txt`.
:file:`docs/reference-manual/`
  Contains reStructuredText source files to generate the reference manual for
  html and LaTeX.
:file:`docs/manual/`
  Contains LaTeX helper files to build the reference (PDF) manual.
:file:`docs/user-guide/`
  Contains reStructuredText source files used to build the user guide section
  of the user documentation.
  The build rules are in :file:`docs/CMakeLists.txt`.
:file:`docs/how-to/`
  Contains reStructuredText source files building the how-to section of
  the user focused documentation.

Unix man pages
^^^^^^^^^^^^^^

Man pages for programs are generated by running the :file:`gmx` executable
after compiling it, and then using Sphinx on the reStructuredText files that
:file:`gmx` writes out.

The build rules for the man pages are in :file:`docs/CMakeLists.txt`.

Developer guide
^^^^^^^^^^^^^^^

:file:`docs/dev-manual/`
  Contains reStructuredText source files used to build the developer guide.
  The build rules are in :file:`docs/CMakeLists.txt`.

The organization of the developer guide is explained on the :ref:`front page of
the guide <dev guide>`.

Doxygen documentation
^^^^^^^^^^^^^^^^^^^^^

:file:`docs/doxygen/`
  Contains the build rules and some overview content for the Doxygen
  documentation.
  See :doc:`doxygen` for details of how the Doxygen documentation is built and
  organized.

.. todo:: Create a separate page (at the front of the developer guide, and/or at
   the main index.rst) that describes the documentation from readers'
   perspective, and move relevant content there.  This should contain just an
   overview of how the documentation is organized in the source tree.

The Doxygen documentation is made of a few different parts.  Use the list
below as a guideline on where to look for a particular kind of content.
Since the documentation has been written over a long period of time and the
approach has evolved, not all the documentation yet follows these guidelines,
but this is where we are aiming at.

documentation pages
  These contain mainly overview content, from general-level introduction down
  into explanation of some particular areas of individual modules.
  These are generally the place to start familiarizing with the code or a new
  area of the code.
  They can be reached by links from the main page, and also through cross-links
  from places in the documentation where that information is relevant to
  understand the context.
module documentation
  These contain mainly techical content, explaining the general implementation of
  a particular module and listing the classes, functions etc. in the module.
  They complement pages that describe the concepts.
  They can be reached from the Modules tab, and also from all individual classes,
  functions etc. that make up the module.
class documentation
  These document the usage of an individual class, and in some cases that of
  closely related classes.  Where necessary (and time allowing), a broader
  overview is given on a separate page and/or in the module documentation.
method documentation
  These document the individual method.  Typically, the class documentation or
  other overview content is the place to look for how different methods interact.
file and namespace documentation
  These are generally only placeholders for links, and do not contain much else.
  The main content is the list of classes and other entities declared in that
  file.
.. _error handling:

Error handling
==============

To make |Gromacs| behave like a proper library, we need to handle
errors in a consistent and predictable way. In this section, "user"
refers to the end user of |Gromacs| whether via some command-line
tool, or a workflow, or a call to a public API. There are different
types of errors, and the handling reflects this. This section is a work
in progress, particularly as the broader C++ community is a long way
from consensus in these areas.

Brief summary on which method to use
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

More detailed rules and rationale are written below, but in short, when a reason
exists that code is unable to do its job:

* If the reason can be checked at compile-time, then use ``static_assert``.
* If the reason is normal in context, then express that in the types used
  (e.g. return ``std::optional``) and document that this is normal.
* If the reason is that an internal invariant or pre-condition is violated (e.g.
  unexpected null pointer passed) on a hot code path, then use ``GMX_ASSERT``.
* Otherwise, if the reason is that an internal invariant or pre-condition is violated
  then use ``GMX_RELEASE_ASSERT``.
* Otherwise, (typically an error returned from system call or GPU SDK, bad user
  input), then use ``GMX_THROW``.

Guiding principles
^^^^^^^^^^^^^^^^^^

* |Gromacs| should adopt approaches that have achieved consensus
  elsewhere, e.g. in the `C++ Core Guidelines
  <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines>`_. In
  particular, be guided by `its section on error handling
  <https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors>`_
* The library should not print out anything to stdio/stderr unless it
  is part of the API specification, and even then, there should be a
  way for the user to suppress or redirect the output.
* The library should normally not terminate the program without
  the user having control over this.
* Design interfaces of functions, classes, modules, and libraries so
  that values passed at run time are valid. Pass const references or
  ``not_null`` pointers rather than raw pointers. Return objects where
  possible. Use e.g. class enums for the type of passed
  values. Consider such enums as template parameters, rather than
  passing run-time values. Refactor existing interfaces to improve
  such aspects when starting new work in an area.
* Check user input at API boundaries and establish invariants as soon
  as possible, e.g. by expressing the user's choice in the type
  system. These form the pre-conditions that error handling will rely
  on.
* Use assertions to validate invariants and pre-conditions. There is value in
  using a different technique for checking such violations in order to make 
  the reason for the check clear to the maintainer.

Specific rules
^^^^^^^^^^^^^^

* Use ``static_assert`` wherever possible to detect errors at compile
  time.
* Throw *exceptions* to indicate that a function can't do its assigned
  task, per the `C++ Core Guidelines E.2
  <https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Re-throw>`_.
  In particular, constructors should throw when they cannot construct
  a valid object, per `C++ Core Guidelines C.42
  <https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Re-invariant>`_.
  However, recognize that in some cases the underlying reason is that
  some other component has not set up the correct pre-condition, and
  such cases should be handled with assertions (see below).
* At API boundaries, the assigned task of some code will be to
  validate the input, and that code should express failure to validate
  by throwing.
* Many programming errors violate pre-conditions of other
  functions. Until there is language support for contracts, the best
  that can be done is to check these with *assertions*. Note that only
  one component should have the responsibility for validating any
  particular input from the user, and other components should rely
  upon that validation in their pre-conditions.
* When asserting, use ``GMX_RELEASE_ASSERT`` by default. This macro
  will run its check in all build configurations, including
  ``Release``.
* When asserting in cases where the code is called in an inner loop of
  e.g. the MD step, ``GMX_ASSERT`` can be used. This macro will run
  its check only when ``NDEBUG`` is not defined, including the
  ``RelWithAssert`` build configuration (which is the default build
  type used in CI).
* It can be appropriate to provide both checked and unchecked
  interfaces, as ``std::vector`` does with ``at()`` and
  ``operator[]``, respectively. Note that even the latter is checked
  if you build e.g. ``libstdc++`` in the right configuration!
* When calling low-level APIs (including C and C++ standard
  libraries, GPU SDKs) always check for success/failure. Generally the
  correct thing to do upon failure will be to throw, perhaps including
  a descriptive string obtained from an error code with another API
  call.
* Do catch exceptions from lower-level components
  memory or file system IO errors. As a general guideline, incorrect
  user input should not produce an untrapped exception resulting
  in execution termination telling the user an exception occured.
  Instead, you should catch exceptions in an earlier stack frame,
  make a suitable decision about diagnostic messages, and then
  decide whether execution should be terminated (if that is in the
  scope of the code making the decision) and, if so, how to terminate.
* There is a global list of possible exceptions in
  ``api/legacy/include/gromacs/utility/exceptions.h``, and the library
  should throw one of these when it fails, possibly providing a more
  detailed description of the reason for the failure. The types of
  exceptions can be extended, and currently include:

  - Out of memory (e.g. ``std::bad_alloc``)

  - File I/O error (e.g. not found)

  - Invalid user input (could not be understood)

  - Inconsistent user input (parsed correctly, but has internal conflicts)

  - Simulation instability

  - Invalid API call/value/internal error (an assertion might also be used in such cases)

  - In the internals of a module called from code that is not
    exception safe, you can use exceptions for error handling, but
    avoid propagating them to caller code.

* Avoid using exceptions to propagate errors across regions that start
  or join threads with OpenMP, since OpenMP cannot make guarantees
  about whether exceptions are caught or if the program will crash.
  Currently we catch all exceptions before we leave an OpenMP threaded
  region.  If you throw an exception, make sure that it is caught and
  handled appropriately in the same thread/OpenMP section.
* Avoid using exceptions to propagate errors within regions where
  non-blocking API calls (e.g. to MPI or GPU SDKs) have been made,
  because the possible advantage of catching at a higher level and
  continuing execution is absent when the partner in the API call
  may be left blocked.
* There are also cases where a library routine wants to report a
  warning or a non-fatal error, but is still able to continue
  processing. In this case you should try to collect all issues and
  report and report them (similar to what grompp does with notes, warnings
  and errors) instead of just returning the first error. It is irritating
  to users if they fix the reported error, but then they keep getting
  a new error message every time the rerun the program.
* A function should not fail as part of its normal operation.
  However, doing nothing can be considered normal operation. A function
  accessing data should typically also be callable when no such data is
  available, but still return through normal means. If the failure is not
  normal, it is OK to rather throw an exception.
* Error handling with ``gmx_fatal``, ``gmx_warning``, ``gmx_incons``,
  ``gmx_comm`` etc.  is deprecated and should generally be refactored
  to throw or assert according to the above guidelines.
* There is currently no attempt made to check for error states on
  other MPI ranks during the simulation and provide a coordinated
  recovery. However setup code should do such checks routinely.
* We use ``GMX_RELEASE_ASSERT`` and ``GMX_ASSERT`` rather
  than ``assert`` to ensure that non-immediate strings can be
  used to describe the problem when the error is reported.
  This is particularly useful when troubleshooting issues where
  missing test coverage leads users to uncover such errors.

  
For coding guidelines to make this all work, see :ref:`implementing exceptions`.
Unit testing
============

The main goal of unit tests in |Gromacs| is to help developers while developing
the code.  They focus on testing functionality of a certain module or a group
of closely related modules.  They are designed for quick execution, such that
they are easy to run after every change to check that nothing has been broken.

Finding, building and running
-----------------------------

As described in :ref:`dev-source-layout`, ``src/gromacs/`` is divided into modules,
each corresponding to a subdirectory.  If available, unit tests for that module
can be found in a ``tests/`` subdirectory under the top-level module directory.
Typically, tests for code in :file:`{file}.h` in the module is in a corresponding
:file:`tests/{file}.cpp`.  Not all files have corresponding tests, as it may not
make sense to test that individual file in isolation.  Focus of the tests is on
functionality exposed outside the module.  Some of the tests, in particular for
higher-level modules, are more like integration tests, and test the
functionality of multiple modules.
Shared code used to implement the tests is in ``src/external/googletest/`` and
``src/testutils/`` (see below).

The tests are built if ``BUILD_TESTING=ON`` (the default) and
``GMX_BUILD_UNITTESTS=ON`` (the default) in CMake. Each module
produces at least one separate unit test binary
(:file:`{module}-test`) under ``bin/``, which can execute tests for
that module.

The tests can be executed in a few different ways:

- Build the ``test`` target (e.g., ``make test``):
  This runs all the tests using CTest.  This includes also the regression
  tests if CMake has been told where to find them (regression tests are not
  discussed further on this page).
  If some of the tests fail, this only prints basic summary information (only
  a pass/fail status for each test binary or regression test class).
  You can execute the failing test binaries individually to get more
  information on the failure.
  Note that ``make test`` does not rebuild the test binaries if you have changed
  the source code, so you need to separately run ``make`` or ``make tests``.
  The latter only builds the test binaries and their dependencies.
- Build the ``check`` target (e.g., ``make check``):
  This behaves the same as the ``test`` target, with a few extensions:

  1. Test binaries are rebuilt if they are outdated before the tests are run.
  2. If a test fails, the output of the test binary is shown.
  3. If unit tests and/or regression tests are not available, a message is
     printed.

- The implementation of ``make check`` calls CTest via the ``ctest`` binary
  to run all the individual test binaries. More fine-grained control is available
  there, e.g. filtering by test name or label, or increasing verbosity.
- Directly executing a test binary.  This provides the most useful
  output for diagnosing failures, and allows debugging test failures.
  The output identifies the individual test(s) that fail, and shows
  the results of all failing assertions.  Some tests also add extra
  information to failing assertions to make it easier to identify the
  reason. Some tests are skipped because they cannot run with the
  number of MPI ranks or GPU devices detected.  Explicit information
  about such cases can be obtained by using the ``-echo-reasons`` flag
  to the test binary.  It is possible to control which tests are run
  using command line options.  Execute the binary with ``--help`` to
  get additional information.

When executed using CTest, the tests produce XML output in
``Testing/Temporary/``, containing the result of each test as well as failure
messages.  This XML is used by GitLab CI for reporting the test status for
individual tests.  Note that if a test crashes or fails because of an assert or
a gmx_fatal() call, no XML is produced for the binary, and CI does not
report anything for the test binary.  The actual error is only visible in the
console output.

Unit testing framework
----------------------

The tests are written using `Google Test`_, which provides a framework for
writing unit tests and compiling them into a test binary.  Most of the command
line options provided by the test binaries are implemented by Google Test.  See
the `Google Test Primer`_ for an introduction.
Some tests also use `Google Mock`_, which provides a framework for creating
mock implementations of C++ classes.  Both components are included in the
source tree under ``src/external/googletest/``, and are compiled as part of the
unit test build.

``src/testutils/`` contains |Gromacs|-specific shared test code.  This includes
a few parts:

- CMake macros for declaring test binaries.  These take care of providing the
  ``main()`` method for the test executables and initializing the other parts of
  the framework, so that the test code in modules can focus on the actual
  tests.  This is the only part of the framework that you need to know to be
  able to write simple tests: you can use ``gmx_add_unit_test()`` in CMake to
  create your test binary and start writing the actual tests right away.
  See ``src/testutils/TestMacros.cmake`` and existing CMake code for examples
  how to use them.

- Generic test fixtures and helper classes.  The C++ API is documented on
  `Doxygen page for testutils`__.  Functionality here includes
  locating test input files from the source directory and constructing
  temporary files, adding custom command line
  options to the test binary, some custom test assertions
  for better exception and floating-point handling, utilities
  for constructing command line argument arrays, and
  test fixtures for tests that need to test long strings for correctness
  and for tests that execute legacy code where
  ``stdin`` reading etc. cannot be easily mocked.

  __ doxygen-module-testutils_

- Some classes and functions to support the above.  This code is for internal
  use of the CMake machinery to build and set up the test binaries, and to
  customize Google Test to suit our environment.

- Simple framework for building tests that check the results against reference
  data that is generated by the same test code.  This can be used if it is not
  easy to verify the results of the code with C/C++ code alone, but manual
  inspection of the results is manageable.  The general approach is
  documented on the `Doxygen page on using the reference data`__.

  __ doxygen-page-refdata_

In addition to ``src/testutils/``, some of the module test directories may
provide reusable test code that is used in higher-level tests.  For example,
the ``src/gromacs/analysisdata/tests/`` provides test fixtures, a mock
implementation for gmx::IAnalysisDataModule, and some helper classes
that are also used in ``src/gromacs/trajectoryanalysis/tests/``.
These cases are handled using CMake object libraries that are linked to all the
test binaries that need them.

.. _gmx-make-new-tests:

Getting started with new tests
------------------------------

To start working with new tests, you should first read the `Google Test`_
documentation to get a basic understanding of the testing framework, and read
the above description to understand how the tests are organized in |Gromacs|.
It is not necessary to understand all the details, but an overall understanding
helps to get started.

Writing a basic test is straightforward, and you can look at existing tests for
examples.  The existing tests have a varying level of complexity, so here are
some pointers to find tests that use certain functionality:

- ``src/gromacs/utility/tests/stringutil.cpp`` contains very simple tests for
  functions.  These do
  not use any fancy functionality, only plain Google Test assertions.
  The only thing required for these tests is the ``TEST()`` macro and the block
  following it, plus headers required to make them compile.
- The same file contains also simple tests using the reference framework to
  check line wrapping (the tests for ``gmx::TextLineWrapper``).  The test fixture
  for these tests is in ``src/testutils/include/testutils/stringtest.h``/``.cpp``.  The string test
  fixture also demonstrates how to add a custom command line option to the
  test binary to influence the test execution.
- ``src/gromacs/selection/tests/`` contains more complex use of the
  reference framework.  This is the code the reference framework was
  originally written for.
  ``src/gromacs/selection/tests/selectioncollection.cpp`` is the main file to
  look at.
- For more complex tests that do not use the reference framework, but instead
  do more complex verification in code, you can look at
  ``src/gromacs/selection/tests/nbsearch.cpp``.
- For complex tests with mock-up classes and the reference framework, you can
  look at ``src/gromacs/analysisdata/tests/``.

Here are some things to keep in mind when working with the unit tests:

- Try to keep the execution time for the tests as short as possible, while
  covering the most important paths in the code under test.  Generally, tests
  should take seconds instead of minutes to run, so that no one needs to
  hesitate before running the tests after they have done some changes.
  Long-running tests should go somewhere else than in the unit test set.
  Note that CI will run the tests in several build configuration and
  slow tests will significantly slow down the pipelines and can even cause
  them to timeout.
- Try to produce useful messages when a test assertion fails.  The assertion
  message should tell what went wrong, with no need to run the *test itself*
  under a debugger (e.g., if the assertion is within a loop, and the loop
  index is relevant for understanding why the assertion fails, it should be
  included in the message).  Even better if even a user can understand what
  goes wrong, but the main audience for the messages is the developer who
  caused the test to fail.

.. _Google Test: http://code.google.com/p/googletest/
.. _Google Test Primer: http://code.google.com/p/googletest/wiki/V1_7_Primer
.. _Google Mock: http://code.google.com/p/googlemock/

.. include:: /fragments/doxygen-links.rst

MPI tests
---------

If your test makes specific requirements on the number of MPI ranks,
or needs a communicator as part of its implementation, then there are
GROMACS-specific extensions that make normal-looking GoogleTests work
well in these cases. Use ``GMX_TEST_MPI(RankRequirement)`` and declare
the test with ``gmx_add_mpi_unit_test`` to teach ``CTest`` how to run
the test regardless of whether the build is with thread-MPI or real
MPI. See ``src/testutils/include/mpitest.h`` for details.
Allowed language features
=========================

Most of these are not strict rules, but you should have a very good
reason for deviating from them.

Portability considerations
^^^^^^^^^^^^^^^^^^^^^^^^^^

Most |Gromacs| files compile as C++17, but some files remain that compile as C99.
C++ has a lot of features, but to keep the source code maintainable and easy to read, 
we will avoid using some of them in |Gromacs| code. The basic principle is to keep things 
as simple as possible.

* MSVC supports only a subset of C99 and work-arounds are required in those cases.
* We should be able to use virtually all C++17 features outside of OpenCL kernels
  (which compile as C), and for consistency also in CUDA kernels.

C++ Standard Library
--------------------

|Gromacs| code must support the lowest common denominator of C++17 standard library
features available on supported platforms.
Some modern features are useful enough to warrant back-porting.
Consistent and forward-compatible headers are provided in ``src/gromacs/compat/``
as described in the `Library documentation <../doxygen/html-lib/group__group__compatibility.xhtml>`_

General considerations
^^^^^^^^^^^^^^^^^^^^^^
As a baseline, |Gromacs| follows the C++ Core Guidelines |linkref1|, unless
our own more specific guidelines below say otherwise. We tend to be more restrictive
in some areas, both because we depend on the code compiling with a lot of different
C++ compilers, and because we want to increase readability. However, |Gromacs| is an
advanced projects in constant development, and as our needs evolve we will both
relax and tighten many of these points. Some of these changes happen naturally as
part of agreements in code review, while major parts where we don't agree should be
pushed to a `issue tracker`_ thread. Large changes should be suggested early in the development
cycle for each release so we avoid being hit by last-minute compiler bugs just before
a release.

* Use namespaces. Everything in ``libgromacs`` should be in a ``gmx``
  namespace. Don't use using in headers except possibly for aliasing
  some commonly-used names, and avoid file-level blanket ``using
  namespace gmx`` and similar. If only a small number of ``gmx``
  namespace symbols needed in a not-yet-updated file, consider
  importing just those symbols. See also |linkref2|.
* Use STL, but do not use iostreams outside of the unit tests. iostreams can have
  a negative impact on performance compared to other forms 
  of string streams, depending on the use case. Also, they don't always
  play well with using C ``stdio`` routines at the same time, which
  are used extensively in the current code. However, since Google tests
  rely on iostreams, you should use it in the unit test code.
* Don't use non-const references as function parameters. They make it
  impossible to tell whether a variable passed as a parameter may
  change as a result of a function call without looking up the
  prototype.
* Use ``not_null<T>`` pointers wherever possible to convey the
  semantics that a pointer to a valid is required, and a reference
  is inappropriate. See also |linkrefnotnull1| and |linkrefnotnull2|.
* Use ``string_view`` in cases where you want to only use a read-only-sequence
  of characters instead of using ``const std::string &``. See also |linkrefstringview|.
  Because null termination expected by some C APIs (e.g. fopen, fputs, fprintf)
  is not guaranteed, string_view should not be used in such cases.
* Use ``optional<T>`` types in situations where there is exactly one,
  reason (that is clear to all parties) for having no value of type T,
  and where the lack of value is as natural as having any regular
  value of T, see |linkoptionalboost|. Good examples include the return type of a
  function that parses an integer value from a string, searching for a matching
  element in a range, or providing an optional name for a residue
  type. Do use optional for lazy loading of resources, e.g., objects that have
  no default constructor and are hard to construct.
  Prefer other constructs when the logic requires an explanation of the
  reason why no regular value for T exists, e.g.,  do not use ``optional<T>``
  for error handling. 
  ``optional<T>`` "models an object, not a pointer, even though operator*() and
  operator->() are defined" (|linkoptionalcppref|). No dynamic memory allocation
  ever takes place and forward declaration of objects stored in ``optional<T>``
  does not work. Thus refrain from optional when passing handles; in contrast to
  unique_ptr, optional has value semantics, not reference semantics.
* Don't use C-style casts; use ``const_cast``, ``static_cast`` or
  ``reinterpret_cast`` as appropriate. See the point on RTTI for
  ``dynamic_cast``. For emphasizing type (e.g. intentional integer division)
  use constructor syntax. For creating real constants use the user-defined literal
  ``_real`` (e.g. ``2.5_real`` instead of ``static_cast<real>(2.5)``).
* Use signed integers for arithmetic (including loop indices). Use ``ssize``
  (available as free function and member of ``ArrayRef``) to avoid casting.
* Avoid overloading functions unless all variants really do the same
  thing, just with different types. Instead, consider making the
  function names more descriptive.
* Avoid using default function arguments. They can lead to the code
  being less readable than without (see |linkref3|). If you think that your specific
  case improves readability (see |linkref4|), you can justify their use.
* Don't overload operators before thorough consideration whether it
  really is the best thing to do. Never overload ``&&``, ``||``, or
  the comma operator, because it's impossible to keep their original
  behavior with respect to evaluation order.
* Try to avoid complex templates, complex template specialization or
  techniques like SFINAE as much as possible. If nothing else, they
  can make the code more difficult to understand.
* Don't use multiple inheritance. Inheriting from multiple pure
  interfaces is OK, as long as at most one base class (which should be
  the first base class) has any code. Please also refer to the
  explanation |linkref5| and |linkref6|.
* Don't write excessively deep inheritance graphs. Try to not inherit
  implementation just to save a bit of coding; follow the principle
  "inherit to be reused, not to reuse." Also, you should not
  mix implementation and interface inheritance. For explanation please
  see |linkref7|.
* Don't include unnecessary headers. In header files, prefer to
  forward declare the names of types used only "in name" in the header
  file. This reduces compilation coupling and thus time. If a source
  file also only uses the type by name (e.g. passing a pointer received
  from the caller to a callee), then no include statements are needed!
* Make liberal use of assertions to help document your intentions (but
  prefer to write the code such that no assertion is necessary).
* Prefer ``GMX_ASSERT()`` and ``GMX_RELEASE_ASSERT()`` to naked
  ``assert()`` because the former permit you to add descriptive text.
* Use gmx::Mutex rather than pthreads, std or raw thread-MPI mutexes.
* Use proper enums for variable whose type can only contain one of a
  limited set of values. C++ is much better than C in catching errors
  in such code. Ideally, all enums should be typed enums, please
  see |linkref8|. 
* When writing a new class, think whether it will be necessary to make
  copies of that class. If not, declare the copy constructor and the
  assignment operator as private and don't define them, making any
  attempt to copy objects of that class fail. If you allow copies,
  either provide the copy constructor and the assignment operator, or
  write a clear comment that the compiler-generated ones will do (and
  make sure that they do what you
  want). ``src/gromacs/utility/classhelpers.h`` has some convenience
  macros for doing this well.
  You can also use deleted functions in this case.
* Declare all constructors with one parameter as explicit unless you
  really know what you are doing. Otherwise, they can be used for
  implicit type conversions, which can make the code difficult to
  understand, or even hide bugs that would be otherwise reported by
  the compiler. For the same reason, don't declare operators for
  converting your classes to other types without thorough
  consideration. For an explanation, please see |linkref9|.
* Write const-correct code (no ``const_cast`` unless absolutely
  necessary).
* Avoid using RTTI (run-time type information, in practice
  ``dynamic_cast`` and ``typeid``) unless you really need it. The cost
  of RTTI is very high, both in binary size (which you always
  pay if you compile with it) and in execution time (which you pay
  only if you use it). If your problem seems to require RTTI, think
  about whether there would be an alternative design that
  wouldn't. Such alternative designs are often better.
* Don't depend on compiler metadata propagation. struct elements
  and captured lambda parameters tend to have ``restrict`` and
  alignment qualifiers discarded by compilers, so when you later
  define an instance of that structure or allocate memory to
  hold it, the data member might not be aligned at all.
* Plan for code that runs in compute-sensitive kernels to have useful
  data layout for re-use, alignment for SIMD memory operations
* Recognize that some parts of the code have different requirements -
  compute kernels, mdrun setup code, high-level MD-loop code,
  simulation setup tools, and analysis tools have different needs, and
  the trade-off point between correctness vs reviewer time vs
  developer time vs compile time vs run time will differ.


.. |linkref1| replace:: `c++ guidelines <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines>`__
.. |linkref2| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#sf7-dont-write-using-namespace-in-a-header-file>`__
.. |linkref3| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#i23-keep-the-number-of-function-arguments-low>`__
.. |linkref4| replace:: `here <https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#f51-where-there-is-a-choice-prefer-default-arguments-over-overloading>`__
.. |linkref5| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#c135-use-multiple-inheritance-to-represent-multiple-distinct-interfaces>`__
.. |linkref6| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#c136-use-multiple-inheritance-to-represent-the-union-of-implementation-attributes>`__
.. |linkref7| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#c129-when-designing-a-class-hierarchy-distinguish-between-implementation-inheritance-and-interface-inheritance>`__
.. |linkref8| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Renum-class>`__
.. |linkref9| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-explicit>`__
.. |linkrefnotnull1| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Ri-nullptr>`__
.. |linkrefnotnull2| replace:: `here <http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rf-nullptr>`__
.. |linkrefstringview| replace:: `here <https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines.html#Rstr-view>`__
.. |linkoptionalboost| replace:: `here <https://www.boost.org/doc/libs/release/libs/optional>`__
.. |linkoptionalbartek| replace:: `here <https://www.bfilipek.com/2018/05/using-optional.html>`__
.. |linkoptionalcppref| replace:: `cppreference <https://en.cppreference.com/w/cpp/utility/optional>`__

.. _implementing exceptions:

Implementing exceptions for error handling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
See :ref:`error handling` for the approach to handling run-time
errors, ie. use exceptions.

* Write exception-safe code. All new code has to offer at least the
  basic or nothrow guarantee to make this feasible.
* Use std (or custom) containers wherever possible.
* Use smart pointers for memory management. By default, use
  ``std::unique_ptr`` and ``gmx::unique_cptr`` in assocation with any
  necessary raw ``new`` or ``snew`` calls. ``std::shared_ptr`` can be
  used wherever responsibility for lifetime must be shared.
  Never use ``malloc``.
* Use RAII for managing resources (memory, mutexes, file handles, ...).
* It is preferable to avoid calling a function which might throw an
  exception from a legacy function which is not exception safe. However,
  we make the practical exception to permit the use of features such
  as ``std::vector`` and ``std::string`` that could throw
  ``std::bad_alloc`` when out of memory. In particular, |Gromacs| has
  a lot of old C-style memory handling that checking tools continue
  to issue valid warnings about as the tools acquire more
  functionality, and fixing these with old constructs is an
  inefficient use of developer time.
* Functions / methods should be commented whether they are exception
  safe, whether they might throw an exception (even indirectly), and
  if so, which exception(s) they might throw.

Preprocessor considerations
^^^^^^^^^^^^^^^^^^^^^^^^^^^
* Don't use preprocessor defines for things other than directly
  related to configuring the build. Use templates or inline functions
  to generate code, and enums or const variables for constants.
* Preprocessing variables used for configuring the build should be
  organized so that a valid value is always defined, i.e. we never
  test whether one of our preprocessor variables is defined, rather we
  test what value it has. This is much more robust under maintenance,
  because a compiler can tell you that the variable is undefined.
* Avoid code with lengthy segments whose compilation depends on #if
  (or worse, #ifdef of symbols provided from outside |Gromacs|).
* Prefer to organize the definition of a const variable at the top of
  the source code file, and use that in the code.  This helps keep all
  compilation paths built in all configurations, which reduces the
  incidence of silent bugs.
* Indent nested preprocessor conditions if nesting is necessary and
  the result looks clearer than without indenting.
* Please strongly consider a comment repeating the preprocessor condition at the end
  of the region, if a lengthy region is necessary and benefits from
  that. For long regions this greatly helps in understanding 
  and debugging the code.
Source tree checker scripts
===========================

.. highlight:: bash

There is a set of Python scripts, currently under ``docs/doxygen/``, that check
various aspects of the source tree for consistency.  The script is based on
producing an abstract representation of the source tree from various sources:

* List of files in the source tree (for overall layout of the source tree)
* List of installed headers (extracted from the generated build system)
* git attributes (to limit the scope of some checks)
* Doxygen XML documentation:

  * For tags about public/private nature of documented headers and other
    constructs
  * For actual documented constructs, to check them for consistency

* Hard-coded knowledge about the |Gromacs| source tree layout

This representation is then used for various purposes:

* Checking Doxygen documentation elements for common mistakes: missing brief
  descriptions, mismatches in file and class visibility, etc.
* Checking for consistent usage and documentation of headers: e.g., a header
  that is documented as internal to a module should not be used outside that
  module.
* Checking for module-level cyclic dependencies
* Checking for consistent style and order of #include directives
  (see :doc:`includestyle`)
* Actually sorting and reformatting #include directives to adhere to the
  checked style
* Generating dependency graphs between modules and for files within modules

The checks are run as part of a single ``check-source`` target, but are described
in separate sections below.  In addition to printing the issues to ``stderr``,
the script also writes them into ``docs/doxygen/check-source.log`` for later
inspection.  CI runs the checks as part of all pipelines and CI will fail
if any issues are found.

For correct functionality, the scripts depend on correct usage of Doxygen
annotations described in :doc:`doxygen`, in particular the visibility and
API definitions in file-level comments.

For some false positives from the script, the suppression mechanism described
below is the easiest way to silence the script, but otherwise the goal would be
to minimize the number of suppressions.

The scripts require Python 2.7 (other versions may work, but have not been
tested).

To understand how the scripts work internally, see comments in the Python
source files under ``docs/doxygen/``.

Checker details
---------------

The ``check-source`` target currently checks for a few different types of issues.
These are listed in detail below, mainly related to documentation and include
dependencies.  Note in particular that the include dependency checks are much
stricter for code in modules/directories that are documented with a
``\defgroup``: all undocumented code is assumed to be internal to such modules.
The rationale is that such code has gotten some more attention, and some effort
should also have been put into defining what is the external interface of the
module and documenting it.

* For all Doxygen documentation (currently does not apply for members that do
  not appear in the documentation):

  * If a member has documentation, it should have a brief description.
  * A note is issued for in-body documentation for functions, since this is
    ignored by our current settings.
  * If a class has documentation, it should have public documentation only if
    it appears in an installed header.
  * If a class and its containing file has documentation, the class
    documentation should not be visible if the file documentation is not.

* For all files:

  * Consistent usage of ::

        #include "..." // This should be used for GROMACS headers

    and ::

        #include <...> // This should be used for system and external headers

  * When we again have installed headers, they must not include non-installed
    headers. Headers should be marked for install within ``CMakeLists.txt``
    files of their respective modules.
  * All source files must include "gmxpre.h" as the first header.
  * A source/header file should include "config.h," "gromacs/simd/simd.h",
    or "gromacs/ewald/pme_simd.h" if and only if it uses a macro declared
    in such files.
  * If the file has a git attribute to identify it as a candidate for include
    sorting, the include sorter described below should not produce any
    changes (i.e., the file should follow :doc:`includestyle`).

* For documented files:

  * Installed headers should have public documentation, and other files should
    not.
  * The API level specified for a file should not be higher than where its
    documentation is visible.  For example, only publicly documented headers
    should be specified as part of the public API.
  * If an ``\ingroup module_foo`` exists, it should match the subdirectory
    that the file is actually part of in the file system.
  * If a ``\defgroup module_foo`` exists for the subdirectory where the file
    is, the file should contain ``\ingroup module_foo``.
  * Files should not include other files whose documentation visibility is
    lower (if the included file is not documented, the check is skipped).

* For files that are part of documented modules
  (``\defgroup module_foo`` exists for the subdirectory), or are explicitly
  documented to be internal or in the library API:

  * Such files should not be included from outside their module if they are
    undocumented (for documented modules) or are not specified as part of
    library or public API.

* For all modules:

  * There should not be cyclic include dependencies between modules.

As a side effect, the XML extraction makes Doxygen parse all comments in the
code, even if they do not appear in the documentation.  This can reveal latent
issues in the comments, like invalid Doxygen syntax.  The messages from the XML
parsing are stored in ``docs/doxygen/doxygen-xml.log`` in the build tree, similar to
other Doxygen runs.

Suppressing issues
^^^^^^^^^^^^^^^^^^

The script is not currently perfect (either because of unfinished
implementation, or because Doxygen bugs or incompleteness of the Doxygen XML
output), and the current code also contains issues that the script detects, but
the authors have not fixed.  To allow the script to still be used,
``doxygen/suppressions.txt`` contains a list of issues that are filtered out from
the report.  The syntax is simple::

    <file>: <text>

where ``<file>`` is a path to the file that reports the message, and ``<text>`` is
the text reported.  Both support ``*`` as a wildcard.  If ``<file>`` is empty, the
suppression matches only messages that do not have an associated file.
``<file>`` is matched against the trailing portion of the file name to make it
work even though the script reports absolute paths.
Empty lines and lines starting with ``#`` are ignored.

To add a suppression for an issue, the line that reports the issue can be
copied into ``suppressions.txt``, and the line number (if any) removed.  If the
issue does not have a file name (or a pseudo-file) associated, a leading ``:``
must be added.  To cover many similar issues, parts of the line can then be
replaced with wildcards.

.. _dev-include-sorter:

Include order sorting
---------------------

The script checks include ordering according to :doc:`includestyle`.
If it is not obvious how the includes should be changed to make the script
happy, or bulk changes are needed in multiple files, e.g., because of a header
rename or making a previously public header private, it is possible to run a
Python script that does the sorting::

    docs/doxygen/includesorter.py -S . -B ../build <files>

The script needs to know the location of the source tree (given with ``-S``) and
the build tree (given with ``-B``), and sorts the given files.  To sort the whole
source tree, one can also use::

    admin/reformat_all.sh includesort -B=../build

For the sorter to work correctly, the build tree should contain up-to-date list
of installed files and Doxygen XML documentation.  The former is created
automatically when ``cmake`` is run, and the latter can be built using the
``doxygen-xml`` target.

Note that currently, the sorter script does not change between angle brackets
and quotes in include statements.

Include dependency graphs
-------------------------

The same set of Python scripts can also produce include dependency graphs with
some additional annotations compared to what, e.g., Doxygen produces for a
directory dependency graph.  Currently, a module-level graph is automatically
built when the Doxygen documentation is built and embedded in the documentation
(not in the public API documentation).  The graph, together with a legend, is
on a separate page: `Module dependency graph`__

__ doxygen-page-modulegraph_

The Python script produces the graphs in a format suitable for ``dot`` (from the
``graphviz`` package) to lay them out.  The build system also provides a
``dep-graphs`` target that generates PNG files from the intermediate ``dot`` files.
In addition to the module-level graph, a file-level graph is produced for
each module, showing the include dependencies within that module.
The file-level graphs can only be viewed as the PNG files, with some
explanation of the notation below.  Currently, these are mostly for eye candy,
but they can also be used for analyzing problematic dependencies to clean up
the architecture.

Both the intermediate ``.dot`` files and the final PNG files are put under
``docs/doxygen/depgraphs/`` in the build tree.

File graphs
^^^^^^^^^^^

The graphs are written to :file:`{module_name}-deps.dot.png`.

Node colors:

light blue
  public API (installed) headers
dark blue
  library API headers
gray
  source files
light green
  test files
white
  other files

Each edge signifies an include dependency; there is no additional information
currently included.

.. include:: /fragments/doxygen-links.rst
Guidelines for creating meaningful issue reports
================================================
This section gives some started on how to generate useful issues on the
|Gromacs| `issue tracker`_. The information here comes to a large extent
directly from there, to help you in preparing your reports.

What to report
^^^^^^^^^^^^^^
Please only report issues you have confirmed to be caused by |Gromacs| behaving in an
unintended way, and that you have investigated to the best of your ability. If you have
large simulations fail at some point, try to also trigger the problem with smaller test
cases that are more easily debuggable.

Bugs resulting from the use third-party software should be investigated first to make sure
that the fault is in |Gromacs| and not in other parts of the toolchain.

Please don't submit generic issues resulting from system instabilities and systems :ref:`blowing-up`.

What should be included
^^^^^^^^^^^^^^^^^^^^^^^
The report should include a general description of the problem with |Gromacs| indicating 
both the expected behaviour and the actual outcome. If the issue causes program
crashes, the report should indicate where the crash happens and if possible
include the stack trace right up to the crash. 


All bugs should include the necessary information for the developers to reproduce the errors, 
including if needed minimal input files (\*tpr, \*top, \*mdp, etc),
run commands or minimal version of run scripts, how you compiled |Gromacs| and if possible the system architecture.


The emphasis should be on having a *minimal* working example that is easy to follow for the developers, that 
does not result in any warnings or errors in itself. If your example generates errors, your issue will likely
not be considered as *real*, or at the minimum it will be much harder to analyse to find the actual issue.


If your inputs are sensitive, then it is possible to create private
`issues <https://gitlab.com/gromacs/gromacs/-/issues/>`_
so that the developer team can have access to solve the problem, while preventing widespread
visibility on the internet.


Supporting the developers
^^^^^^^^^^^^^^^^^^^^^^^^^
In general you should be able to answer questions posed to you by the developers
working on the program, if you want to help them in fixing the bug you found. This may
include things such as explaining run scripts or simulation set-up, as well as 
confirming issues with different versions of the program and different combinations
of supported libraries and compilers. 


Please refrain from setting things such as target version or deciding on unreasonable priorities. If you decide
to fix the issue on your own, please adhere to the other standards mentioned on the related pages
:ref:`code-formatting` and :ref:`code-commitstyle`.

.. seealso:: :doc:`contribute`

.. _issue workflow:

General issue workflow
^^^^^^^^^^^^^^^^^^^^^^

The general issue workflow is shown in the figure below:

.. image:: redmine-states.png
   :alt:  Sample procedure pathway for reported issues.

Project maintainers will apply
`Status labels <https://gitlab.com/gromacs/gromacs/-/labels?search=status>`__
as the issue is processed.

* `Status::Accepted <https://gitlab.com/gromacs/gromacs/-/issues?label_name%5B%5D=Status%3A%3AAccepted>`__:
  Bug confirmed / Desirable feature.
* `Status::In Progress <https://gitlab.com/gromacs/gromacs/-/issues?label_name%5B%5D=Status%3A%3AIn+Progress>`__:
  Assignee starts to work.
* `Status::Blocked <https://gitlab.com/gromacs/gromacs/-/issues?label_name%5B%5D=Status%3A%3ABlocked>`__: Progress requires feedback or other action.
* `Status::Rejected <https://gitlab.com/gromacs/gromacs/-/issues?label_name%5B%5D=Status%3A%3ARejected>`__:
  Invalid report or not a desirable feature.
* `Status::Fix uploaded <https://gitlab.com/gromacs/gromacs/-/issues?label_name%5B%5D=Status%3A%3AFix+uploaded>`__:
  Merge request is available for review
* `Status::Feedback-wanted <https://gitlab.com/gromacs/gromacs/-/issues?label_name%5B%5D=Status%3A%3AFeedback-wanted>`__: Resolution pending additional feedback or response
* `Status::Resolved <https://gitlab.com/gromacs/gromacs/-/issues?label_name%5B%5D=Status%3A%3AResolved>`__:
  The issue will be closed if there is no further discussion.

.. Text below is stolen from the old Gromacs web page

.. Before opening a new issue, take a minute and make it easy for everybody else (in particular the developers!) to help you - that way you are much more likely to get a solution to your problem.

.. 1. Isolate the problem as far as possible. If you submit a huge tpr file that sometimes fails after a million steps, it is pretty much guaranteed that nobody is going to debug it.

.. 2. Upload a single small example of how a simulation (or some other GROMACS program) crashes. This should ideally be a single (small) conf.gro file, topol.top, and grompp.mdp. Make sure that your input files are processed without warnings for the GROMACS version you are submitting a bug report for, and don't rely on some large external force field or long script. In most cases these additional files and warnings are of course completely unrelated to the problem, but particularly in that case you are helping others a lot by not having to take them into account.

.. 3. Provide a very concise report of exactly what commands you used (so it can be reproduced), what behavour you expected, and what you got.

.. 4. Please don't set a target version unless you are the person working on the bug.

.. 5. If you set the priority to "high" as a user, we assume this means you will also prioritize it yourself and provide close to instant feedback and/or help with testing. If you are a developer, setting the priority to "high" means you are working on fixing this bug yourself. In other words: Please do not set the priority to "high" just to get somebody else to fix it faster.

.. At some point it might be necessary to have more files (including those large scripts) to debug the problem, but you are much more likely to get help if developers do not have to search for files in several different places, read up on a number of threads on the mailing list, follow a long discussion about what you want to do, and then decipher scripts to understand what happened.
Documentation generation
========================

Building the |Gromacs| documentation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For now, there are multiple components, formats and tools for the
|Gromacs| documentation, which is aimed primarily at version-specific
deployment of the complete documentation on the website and in the
release tarball.

This is quite complex, because the dependencies for building the
documentation must not get in the way of building the code
(particularly when cross-compiling), and yet the code must build and
run in order for some documentation to be generated. Also, man page
documentation (and command-line completions) must be built from the
wrapper binary, in order to be bundled into the tarball. This helps
ensure that the functionality and the documentation remain in sync.

The outputs of interest to most developers are generally produced in the
``docs/html/`` subdirectory of the build tree.

You need to enable at least some of the following CMake options:

``GMX_BUILD_MANUAL``
  Option needed for trying to build the PDF reference manual
  (requires LaTeX and ImageMagick). See :cmake:`GMX_BUILD_MANUAL`.
``GMX_BUILD_HELP``
  Option that controls 1) whether shell completions are built automatically,
  and 2) whether built man pages are installed if available (the user still needs
  to build the ``man`` target manually before installing). See
  :cmake:`GMX_BUILD_HELP`.

Some documentation cannot be built when cross-compiling, as it
requires executing the ``gmx`` binary.

The following make targets are the most useful:

``manual``
  Builds the PDF reference manual.
``man``
  Makes man pages from the wrapper binary with Sphinx.
``doxygen-all``
  Makes the code documentation with Doxygen.
``install-guide``
  Makes the INSTALL file for the tarball with Sphinx.
``webpage-sphinx``
  Makes all the components of the |Gromacs| webpage that require Sphinx,
  including install guide and user guide.
``webpage``
  Makes the complete |Gromacs| webpage, requires everything. When complete,
  you can browse ``docs/html/index.html`` to find everything.

  If built from a release tarball, the ``SOURCE_MD5SUM``,
  ``SOURCE_TARBALL``, ``REGRESSIONTESTS_MD5SUM``, and
  ``REGRESSIONTESTS_TARBALL`` CMake variables can be set to pass in
  the md5sum values and names of those tarballs, for embedding into the
  final deployment to the |Gromacs| website.

Needed build tools
^^^^^^^^^^^^^^^^^^

The following tools are used in building parts of the documentation.

Doxygen
  `Doxygen <http://www.doxygen.org>`_ is used to extract documentation from
  source code comments.  Also some other overview
  content is laid out by Doxygen from Markdown source files.  Currently, version
  |EXPECTED_DOXYGEN_VERSION| is required for a warning-free build.  Thorough
  explanation of the Doxygen setup and instructions for documenting the source
  code can be found on a separate page: :doc:`doxygen`.

graphviz (dot)
  The Doxygen documentation uses ``dot`` from `graphviz
  <http://www.graphviz.org>`_ for building some graphs.  The tool is not
  mandatory, but the Doxygen build will produce warnings if it is not
  available, and the graphs are omitted from the documentation.

mscgen
  The Doxygen documentation uses `mscgen
  <http://www.mcternan.me.uk/mscgen/>`_ for building some graphs.  As with ``dot``,
  the tool is not mandatory, but not having it available will result in warnings
  and missing graphs.

Doxygen issue checker
  Doxygen produces warnings about some incorrect uses and wrong
  documentation, but there are many common mistakes that it does not detect.
  |Gromacs| uses an additional, custom Python script to check for such issues.
  This is most easily invoked through a ``check-source`` target in the build system.
  The script also checks that documentation for a header matches its use in the
  source code (e.g., that a header documented as internal to a module is not
  actually used from outside the module).  These checks are run in CI.
  Details for the custom checker are on a separate page (common for several
  checkers): :doc:`gmxtree`.

module dependency graphs
  |Gromacs| uses a custom Python script to generate an annotated dependency
  graph for the code, showing #include dependencies between modules.
  The generated graph is embedded into the Doxygen documentation:
  `Module dependency graph`__
  This script shares most of its implementation with the custom checkers, and is
  documented on the same page: :doc:`gmxtree`.

__ doxygen-page-modulegraph_

Sphinx
  `Sphinx <http://sphinx-doc.org/>`_; at least version |EXPECTED_SPHINX_VERSION| is used
  for building some parts of the documentation from reStructuredText
  source files.

LaTeX
  Also requires ImageMagick for converting graphics file formats.

linkchecker
  `linkchecker <http://wummel.github.io/linkchecker/>`__ is used together with the
  :file:`docs/linkcheckerrc` file to ensure
  that all the links in the documentation can be resolved correctly.

documentation exported from source files
  For man pages, HTML documentation of command-line options for executables,
  and for shell completions, the ``gmx`` binary has explicit C++ code to export
  the information required.  The build system provides targets that then invoke
  the built ``gmx`` binary to produce these documentation items.  The generated
  items are packaged into source tarballs so that this is not necessary when
  building from a source distribution (since in general, it will not work in
  cross-compilation scenarios).  To build and install these from a git
  distribution, explicit action is required.
  See `Doxygen documentation on the wrapper binary`__
  for some additional details.

__ doxygen-page-wrapperbinary_

.. include:: /fragments/doxygen-links.rst
.. _gmx-codeformatting:

Automatic source code formatting
================================

.. highlight:: bash

The source code can be automatically formatted using clang-format
since GROMACS 2020.
Both are formatting tools that apply the guidelines in :doc:`formatting`.
Additionally, other Python scripts are used for a few other automatic
formatting/checking tasks.  The overview tools page contains a list of these
tools: :ref:`dev-formatting-tools`.
This page provides more details for clang-format, clang-tidy and copyright scripts.

Our CI uses these same scripts (in particular, ``clang-format.sh``,
``copyright.sh``, ``clang-tidy.sh`` and the ``check-source`` target) to enforce that
the code stays invariant under such formatting.

.. _gmx-clang-format:

Setting up clang-format
-----------------------

|Gromacs| formatting is enforced with clang-format 11.0.1.
:command:`clang-format` is one of the core *clang* tools.
It may be included in a *clang* or *llvm* package from your favorite packaging
system or you may find a standalone *clang-format* package,
but you should confirm that the provided command is version 11.0.0 or 11.0.1.
Example::

    $ clang-format --version
    clang-format version 11.0.0

If you use a different version of clang-format,
you will likely get different formatting results than
the |Gromacs| continuous integration testing system,
and the commits that you push will fail the automated tests.

.. note::

    Refer to `LLVM <http://releases.llvm.org/download.html#11.0.0>`__ for
    source and binary downloads.
    If downloading sources, note that you will need to download both the
    *LLVM source code* and the *Clang source code*.
    As per the clang
    `INSTALL.txt <https://github.com/llvm/llvm-project/blob/release/11.x/clang/INSTALL.txt>`__,
    place the expanded clang source into a :file:`tools/clang` subdirectory within
    the expanded llvm archive, then run CMake against the llvm source directory.

.. todo::

    Consider referencing or providing binary packages and/or checking/managing
    the executable from an :file:`admin/` script.
    Reference: https://github.com/mongodb/mongo/blob/master/buildscripts/clang_format.py

In order to use the installed version of clang-format for ``clang-format.sh``
and for the pre-commit hook, you also need to run this in each of your |Gromacs| repositories::

  git config hooks.clangformatpath /path/to/clang-format

Alternatively, if you just want to use ``clang-format.sh``, you can set the
``CLANG_FORMAT`` environment variable to ``/path/to/clang-format``.

Using the pre-commit hook or git filters needs additional setup; see the
respective sections below.

clang-format discovers which formatting rules to apply from the
:file:`.clang-format` configuration file(s) in project directories,
which will be automatically updated (if necessary) when you :command:`git pull`
from the |Gromacs| repository.
For more about the tool and the :file:`.clang-format` configuration file,
visit https://releases.llvm.org/11.0.1/tools/clang/docs/ClangFormat.html

What is automatically formatted?
--------------------------------

To identify which files are subject to automatic formatting, the scripts use
git filters, specified in ``.gitattributes`` files.  Only files that have the
attribute ``filter`` set to one of the below values are processed:

- ``filter=complete_formatting``: Performs all formatting. Uses clang-format for code formatting.
                                  Files included here are also passed to the clang-tidy code checker.
- ``filter=clangformat``: clang-format is run. Again also runs clang-tidy.
- ``filter=includesort``: include order is enforced and copyright headers are checked.
- ``filter=copyright``: only copyright headers are checked.

Other files are ignored by ``clang-tidy.sh``, ``clang-format.sh``,
``copyright.sh`` and ``reformat_all.sh`` scripts (see below).

.. _gmx-clang-tidy:

Setting up clang-tidy
---------------------

|Gromacs| source code tidiness checking is enforced with clang-tidy provided
alongside *clang* compiler version 11.
:command:`clang-tidy` is one of the core *clang* tools.
It may be included in a *clang* or *llvm* package from your favorite packaging
system or you may find a standalone *clang-tidy* or *clang-tools* package,
but you should confirm that the provided command is version 11.
Example::

    $ clang-tidy --version
      LLVM (http://llvm.org/):
        LLVM version 11.0.0

If you use a different version of clang-tidy,
you will likely get different checking results than
the |Gromacs| continuous integration testing system,
and the commits that you push will fail the automated tests.

.. note::

    Refer to `LLVM <https://releases.llvm.org/download.html#11.0.1>`__ for
    source and binary downloads.
    If downloading sources, note that you will need to download both the
    *LLVM source code* and the *Clang source code*.
    As per the clang
    `INSTALL.txt <https://github.com/llvm/llvm-project/blob/release/11.x/clang/INSTALL.txt>`__,
    place the expanded clang source into a :file:`tools/clang` subdirectory within
    the expanded llvm archive, then run CMake against the llvm source directory.

In order to use the installed version of clang-tidy for ``clang-tidy.sh``
and for the pre-commit hook, you also need to run this in each of your |Gromacs| repositories::

  git config hooks.runclangtidypath /path/to/run-clang-tidy.py

Alternatively, if you just want to use ``clang-tidy.sh``, you can set the
``RUN_CLANG_TIDY`` environment variable to ``/path/to/run-clang-tidy.py``.

As above, see the sections below for using the pre-commit hook or git filters.

clang-tidy discovers which formatting rules to apply from the
:file:`.clang-tidy` configuration file(s) in project directories,
which will be automatically updated (if necessary) when you :command:`git pull`
from the |Gromacs| repository.
For more about the tool and the :file:`.clang-tidy` configuration file,
visit https://releases.llvm.org/11.0.0/tools/clang/tools/extra/docs/clang-tidy/index.html.

Scripts
-------

``copyright.py``
^^^^^^^^^^^^^^^^

This script provides low-level functionality to check and update copyright
headers in C/C++ source files, as well as in several other types of files like
CMake and Python scripts.

This file is also used as a loadable Python module for kernel generators, and
provides the functionality to generate conformant copyright headers for such
scripts.

You should rarely need to run this
directly, but instead the bash scripts below use it internally.  You can run
the script with ``--help`` option if you want to see what all options it provides
if you need to do some maintenance on the copyright headers themselves.

``copyright.sh``
^^^^^^^^^^^^^^^^

This script runs ``copyright.py`` on modified files and reports/applies the results.
By default, the current HEAD commit on the source branch is compared to the work tree,
and files that

1. are different between these two trees and
2. change under have outdated copyright header

are reported.  This behavior can be changed by

1. Specifying an ``--rev=REV`` argument, which uses ``REV`` instead of HEAD as
   the base of the comparison.  A typical use case is to specify ``--rev=HEAD^``
   to check the HEAD commit.
2. Specifying ``--copyright=<mode>``, which alters the level of copyright
   checking is done:

   ``off``
     does not check copyright headers at all
   ``year``
     only update copyright year in new-format copyright headers
   ``add``
     in addition to ``year``, add copyright headers to files that do not
     have any
   ``update``
     in addition to ``year`` and ``add``, also update new-format copyright
     headers if they are broken or outdated
   ``replace``
     replace any copyright header with a new-format copyright header
   ``full``
     do all of the above

By default, ``update-*`` refuses to update dirty files (i.e., that differ
between the disk and the index) to make it easy to revert the changes.
This can be overridden by adding a ``-f``/``--force`` option.

``clang-format.sh``
^^^^^^^^^^^^^^^^^^^

This script runs ``clang-format`` on modified files and reports/applies the results.
By default, the current HEAD commit on the source branch is compared to the work tree,
and files that

1. are different between these two trees and
2. change under clang-format

are reported.  This behavior can be changed by

1. Specifying an ``--rev=REV`` argument, which uses ``REV`` instead of HEAD as
   the base of the comparison.  A typical use case is to specify ``--rev=HEAD^``
   to check the HEAD commit.
2. Specifying an action:

   - ``check-*``:   reports the files that clang-format changes
   - ``diff-*``:    prints the actual diff of what would change
   - ``update-*``:  applies the changes to the repository
   - ``*-workdir``: operates on the working directory (files on disk)
   - ``*-index``:   operates on the index of the repository

   For convenience, if you omit the workdir/index suffix, workdir is assumed
   (i.e., ``diff`` equals ``diff-workdir``).
3. Specifying ``--format=off``, which does not run clang-format.

By default, ``update-*`` refuses to update dirty files (i.e., that differ
between the disk and the index) to make it easy to revert the changes.
This can be overridden by adding a ``-f``/``--force`` option.

Since the behaviour of clang-format can change between versions even when using the same options,
only clang-format from Clang 11 will give correct results. The path to the correct ``clang-format``
binary can be specified via ``CLANG_FORMAT`` environment variable or by running
``git config hooks.clangformatpath /path/to/clang-format-11`` in the repository root.

``clang-tidy.sh``
^^^^^^^^^^^^^^^^^

This script runs the ``clang-tidy`` source code checker on modified files
and either reports or applies resulting changes. By default, the current
HEAD commit on the source branch is compared to the work tree,
and files that

1. are different between these two trees and
2. change when applying clang-tidy

are reported. This behavior can be changed by

1. Specifying an ``--rev=REV`` argument, which uses ``REV`` instead of HEAD as
   the base of the comparison.  A typical use case is to specify ``--rev=HEAD^``
   to check the HEAD commit.
2. Specifying an action:

   - ``check-*``:   reports the files that clang-format changes
   - ``diff-*``:    prints the actual diff of what would change
   - ``update-*``:  applies the changes to the repository
   - ``*-workdir``: operates on the working directory (files on disk)
   - ``*-index``:   operates on the index of the repository

   For convenience, if you omit the workdir/index suffix, workdir is assumed
   (i.e., ``diff`` equals ``diff-workdir``).
3. Specifying ``--tidy=off``, which does not run clang-tidy.

By default, ``update-*`` refuses to update dirty files (i.e., that differ
between the disk and the index) to make it easy to revert the changes.
This can be overridden by adding a ``-f``/``--force`` option.


git pre-commit hook
^^^^^^^^^^^^^^^^^^^

If you want to run ``copyright.sh``, ``clang-tidy.sh`` and/or
``clang-format.sh`` automatically for changes you make, you can
configure a pre-commit hook using ``admin/git-pre-commit``:

1. Copy the ``git-pre-commit`` script to .git/hooks/pre-commit.

2. Specify the paths to ``run-clang-tidy`` and ``clang-format`` for the hook if you have not already done
   so::

     git config hooks.runclangtidypath /path/to/run-clang-tidy.py
     git config hooks.clangformatpath /path/to/clang-format

3. Set the operation modes for the hook::

     git config hooks.clangtidymode check
     git config hooks.clangformatmode check
     git config hooks.copyrightmode  update

With this configuration, all source files modified in the commit are run
through the code formatting tool, are checked with clang-tidy
and also checked for correct copyright headers.
If any file would be changed by ``clang-tidy.sh``, ``clang-format.sh`` or ``copyright.sh``,
the names of those files are reported and the commit is prevented.
The issues can be fixed by running the scripts manually.

To disable the hook without removing the ``pre-commit`` file, you can set ::

  git config hooks.clangtidymode off
  git config hooks.copyrightmode off
  git config hooks.clangformatmode off

To disable it temporarily for a commit, set NO_FORMAT_CHECK environment
variable.  For example, ::

    NO_FORMAT_CHECK=1 git commit -a

You can also run ``git commit --no-verify``, but that also disables other hooks.

Note that when you run ``git commit --amend``, the hook is only run for the
changes that are getting amended, not for the whole commit.  During a rebase,
the hook is not run.

The actual work is done by the ``admin/clang-tidy.sh``, ``admin/clang-format.sh``
and ``admin/copyright.sh`` scripts, which get run with the ``check-index`` action,
and with ``--copyright`` and ``--format`` getting set according
to the ``git config`` settings.

``reformat_all.sh``
^^^^^^^^^^^^^^^^^^^

This script runs clang-format, ``copyright.py``, or the include sorter for all
applicable files in the source tree.  See ``reformat_all.sh -h`` for the
invocation.

The script can also produce the list of files for which these commands would be
run.  To do this, specify ``list-files`` on the command line and use
``--filter=<type>`` to specify which command to get the file list for.  This can
be used together with, e.g., ``xargs`` to run other scripts on the same set of
files.

For all the operations, it is also possible to apply patters (of the same style
that various git commands accept, i.e., ``src/*.cpp`` matches all ``.cpp`` files
recursively under ``src/``).  The patterns can be specified with
``--pattern=<pattern>``, and multiple ``--pattern`` arguments can be given.

``-f``/``--force`` is necessary if the working tree and
the git index do not match.


Using git filters
-----------------

An alternative to using a pre-commit hook to automatically apply uncrustify or
clang-format on changes is to use a git filter (does not require either of the scripts,
only the ``.gitattributes`` file).  You can run ::

  git config filter.clangformat.clean \
      "/path/to/clang-format -i"

To configure a filter for all files that specify ``filter=complete_formatting`` attribute
that indicates that all formatting steps should be performed.

The pre-commit hook + manually running the scripts gives better/more
intuitive control (with the filter, it is possible to have a work tree that is
different from HEAD and still have an empty ``git diff``) and provides better
performance for changes that modify many files.  It is the only way that
currently also checks the copyright headers.

The filter allows one to transparently merge branches that have not been run
through the source checkers, and is applied more consistently (the pre-commit hook is
not run for every commit, e.g., during a rebase).
=================
Change Management
=================

This documentation assumes the reader is already familiar with using ``git``
for managing file revisions.

.. contents::
   :local:

Getting started
===============

GROMACS development happens on gitlab at https://gitlab.com/gromacs/gromacs.
Create a user account at https://gitlab.com/users/sign_in#register-pane or use
an existing account at gitlab.com. For more information on how to use gitlab have
a look at their extensive user documentation at https://docs.gitlab.com/ee/user/index.html.
We follow the workflow described in https://docs.gitlab.com/ee/topics/gitlab_flow.html. 

If you do not already have a GROMACS repository set up, user 
``git clone git@gitlab.com:gromacs/gromacs.git`` to obtain the current GROMACS
repository from gitlab. Otherwise use 
``git remote add gitlab git@gitlab.com:gromacs/gromacs.git``. 

Using gitlab, new code enters GROMACS by merging git development branches into
the master branch. 

To automatically detect issues in new code, it is tested within continuous
integration (CI) with a large combination of settings.
See `gmx-codeformatting` for help meeting and testing the style guidelines.

Setting up login credentials with gitlab
----------------------------------------

You will need a public ssh key::

    ssh-keygen -t rsa -C "your.email@address.com"
    cat ~/.ssh/id_rsa.pub

Copy the output of the last command, got to gitlab.com, find you user in the
right top corner and select settings.

Chose SSH keys in the menu on the left and past your key in the text field.

Creating issues
---------------

The meta-level code design and discussions is organised in issues and visible at
https://gitlab.com/gromacs/gromacs/-/issues. Please check if if your issue or a
similar issue already exists before creating a new one.

Note that all Redmine issues have been transferred to gitlab with the same issue
numbers as used in gitlab. However, comments and discussion are now represented
by gitlab user @acmnpv - the original authors are found inline at the bottom of
the comments. 

Uploading code for review - creating a merge request
----------------------------------------------------

Issues are addressed with new code via "merge requests" (MR). Find the current
MRs at https://gitlab.com/gromacs/gromacs/-/merge_requests. 
There are two ways of creating a merge request - either via the gitlab graphical
user interface or via the command line. 

To use the GUI, find the relevant issue or open a new one, then find the 
"create merge request" button to create a merge request related to that issue in gitlab.
The default selection is to mark this a work in progress (WIP) merge-request.
We recommend keeping this setting until you are completely satisfied with the 
code yourself and all tests are passed.

Select milestone and assignees to make tracking of the progress easier. 
Keep the requirements for merging as they are set by default.

You can also use ``git push`` on the command line directly and create a merge request 
following the link that is output on the command line.

Your repository should be in sync with the GROMACS repository. To ensure this,
use ``git fetch`` to obtain the newest branches, then merge the master branch
into your branch with ``git merge master`` while on your branch.

Naming branches
---------------

Good names: documentation_UpdateDevelopersDocsTOGitLab, nbnxm_MakeNbnxmGPUIntoClass, pme_FEPPMEGPU. 
Bad names: branch1234, mybranch, test, etc

Labels
======

`Labels <https://docs.gitlab.com/ee/user/project/labels.html>`__
help developers by allowing additional filtering of issues and merge requests.

The GROMACS project `defines many labels <https://gitlab.com/gromacs/gromacs/-/labels>`__.

.. Note: labeling guidelines TBD. See https://gitlab.com/gromacs/gromacs/-/issues/3949 and open new issues as appropriate.

To minimize duplicated documentation, refer to the
`GROMACS Labels <https://gitlab.com/gromacs/gromacs/-/labels>`__ web interface for label descriptions.

When creating a new label, please provide a short description
so that people can understand what the label is intended to convey,
and when they should apply it to their own issues or merge requests.

In general:

* Ongoing categorizations to help specify the GROMACS component or development area use the ``#7F8C8D`` color.
* Specific features or subproject areas targeting an upcoming release use the ``#8E44AD`` background color.
* Status labels use ``#428BCA``. Note that Status labels are also used for Issues,
  and are used according to
  :ref:`status label guidelines <status label guidelines>`

.. Best practices and labeling policies can be proposed as changes to this document. See https://gitlab.com/gromacs/gromacs/-/issues/3949

Code Review
===========

Reviewing someone else's uploaded code
--------------------------------------

The reviewing workflow is the following:

#. https://gitlab.com/gromacs/gromacs/-/merge_requests shows all open changes
#. A change needs two approvals to go in, of which one approval has to come from
   a member of either GMX Core or GMX Developers.
#. Usually a patch goes through several cycles of voting, commenting and
   updating before it becomes merged, with votes from the developers indicating
   if they think that change hat progressed enough to be included.
#. A change is submitted for merging and post-submit testing
   by clicking "Merge".

Do not review your own code. The point of the policy is that at least
two non-authors have approved, and that the issues are resolved in the
opinion of the person who applies an approval before a merge. If you have
uploaded a minor fix to someone else's patch, use your judgement in
whether to approve yourself.

Guide for reviewing
-------------------

-  First and foremost, check correctness to the extent possible;
-  As portability and performance are the next most important things do check 
   for potential issues;
-  Check adherence to the :ref:`GROMACS coding standards <style-guidelines>`;
-  We should try to ensure that commits that implement bugfixes (as
   well as important features and tasks) get an `issue tracker`_ entry created
   and linked. The linking is done **automatically** through
   `special syntax <https://gitlab.com/help/user/markdown#special-gitlab-references>`__
-  If the commit is a **bugfix**\ :

   -  if present in the `issue tracker`_, it has to contain a valid reference to the
      issue;
   -  if it's a **major bug**, there has to be a bug report filed in the
      `issue tracker`_  (with urgent or
      immediate priority) and referenced appropriately.

-  If the commit is a **feature/task** implementation:

   -  if it's present in the `issue tracker`_ it
      has to contain a valid reference to the issue;
   -  If no current issue is currently present and the change
      would benefit of one for future explanation on why it was
      added, a new issue should be created.

.. _status label guidelines:

Update the Status label
"""""""""""""""""""""""

-  Please update the Status label :ref:`for the issue <issue workflow>` when a merge request is under review.
-  Please update the Status label :ref:`for the merge request <merge request status>` when it is closed.

.. _merge request status:

Closing Merge Requests
----------------------

A merge request that has had no updates for six months or more can acquire the status label "Status::Stale"
If the proposed change still seems important and the next steps are unclear,
contributors with stale issues *are encouraged...*

- to contact existing reviewers (or potential reviewers),
- to participate in the developer mailing list, and
- to attend the biweekly teleconference to coordinate.

If the future of the merge request has not become clear within a month
(especially if it has become stale multiple times),
developers may close the merge request with a label indicating why it has entered a "closed" state.
`"Status::MR::..." labels <https://gitlab.com/gromacs/gromacs/-/labels?subscribed=&search=status%3A%3Amr>`__
do not indicate that the merge request has been reviewed
unless it is explicitly rejected.

See :issue:`4126` for background discussion.

- `Status::MR::Inactive <https://gitlab.com/gromacs/gromacs/-/merge_requests?label_name%5B%5D=Status%3A%3AMR%3A%3AInactive>`__: No response from contributor or no reviewers available for over six months.
- `Status::MR::Superseded <https://gitlab.com/gromacs/gromacs/-/merge_requests?label_name%5B%5D=Status%3A%3AMR%3A%3ASuperseded>`__: This merge request is no longer necessary.
- `Status::MR::Rejected <https://gitlab.com/gromacs/gromacs/-/merge_requests?label_name%5B%5D=Status%3A%3AMR%3A%3ARejected>`__: The solution (or its associated issue) will not be accepted.
- `Status::MR::Needs discussion <https://gitlab.com/gromacs/gromacs/-/merge_requests?label_name%5B%5D=Status%3A%3AMR%3A%3ANeeds+discussion>`__: More discussion must take place at the tracked issue before a MR is opened.
- `Status::Stale <https://gitlab.com/gromacs/gromacs/-/labels?subscribed=&search=status%3A%3AStale>`__: No activity for over six months.

.. seealso:: :ref:`issue workflow` for use of Status labels in Issue management.

More git tips
=============

.. rubric:: Q: Are there some other useful git configuration settings?

A: If you need to work with
branches that have large
differences (in particular, if a
lot of files have moved), it can
be helpful to set

::

    git config diff.renamelimit 5000

to increase the limit of inexact
renames that Git considers. The
default value is not sufficient,
for example, if you need to do a
merge or a cherry-pick from
a release branch to master.

.. rubric:: Q: How do I use git rebase (also ``git pull --rebase``)?

A: Assume you have a local
feature branch checked out, that
it is based on master, and master
has gotten new commits. You can
then do

::

    git rebase master

to move your commits on top of
the newest commit in master. This
will save each commit you did,
and replay them on top of master.
If any commit results in
conflicts, you need to resolve
them as usual (including marking
them as resolved using git add),
and then use

::

    git rebase --continue

Note that unless you are sure
about what you are doing, you
should not use any commands that
create or delete commits (git
commit, or git checkout or git
reset without paths). ``git rebase
--continue`` will create the commit
after conflicts have been
resolved, with the original
commit message (you will get a
chance to edit it).

If you realize that the conflicts
are too messy to resolve (or that
you made a mistake that resulted
in messy conflicts), you can use

::

    git rebase --abort

to get back into the state you
started from (before the
original git rebase master
invocation). If the rebase is
already finished, and you realize
you made a mistake, you can get
back where you started with
(use git
log <my-branch>@{1} and/or git
reflog <my-branch> to check that
this is where you want to go)

::

    git reset --hard <my-branch>@{1}

.. rubric:: Q: How do I prepare several commits at once?

A: Assume I have multiple independent changes in my working tree.
Use

::

    git add [-p] [file]

to add one independent change at
a time to the index. Use

::

    git diff --cached

to check that the index contains
the changes you want. You can
then commit this one change:

::

    git commit

 If you want to test that the
change works, use to temporarily
store away other changes, and do
your testing.

::

    git stash

If the testing fails, you can
amend your existing commit with
``git commit --amend``. After you are
satisfied, you can push the
commit for review. If
you stashed away your changes and
you want the next change to be
reviewed independently, do

::

    git reset --hard HEAD^
    git stash pop

(only do this if you pushed the
previous change upstream,
otherwise it is difficult to get
the old changes back!) and repeat
until each independent change is
in its own commit. If you skip
the ``git reset --hard`` step, you
can also prepare a local feature
branch from your changes.

.. rubric:: Q: How do I edit an earlier commit?

A: If you want to edit the latest
commit, you can simply do the
changes and use

::

    git commit --amend

If you want to edit some other
commit, and commits after that
have not changed the same lines,
you can do the changes as usual
and use

::

    git commit --fixup <commit>

or

::

    git commit --squash <commit>

where <commit> is the commit you
want to change (the difference is
that ``--fixup`` keeps the original
commit message, while ``--squash``
allows you to input additional
notes and then edit the original
commit message during ``git rebase
-i``). You can do multiple commits
in this way. You can also mix
``--fixup/--squash`` commits with
normal commits. When you are
done, use

::

    git rebase -i --autosquash <base-branch>

to merge the ``--fixup/--squash``
commits to the commits they
amend. See separate question on
``git rebase -i`` on how to choose
<base-branch>.

In this kind of workflow, you
should try to avoid to change the
same lines in multiple commits
(except in ``--fixup/--squash``
commits), but if you have already
changed some lines and want to
edit an earlier commit, you can
use

::

    git rebase -i <base-branch>

but you likely need to resolve
some conflicts later. See ``git
rebase -i`` question later.

.. rubric:: Q: How do I split a commit?

A: The instructions below apply
to splitting the HEAD commit; see
above how to use ``git rebase -i`` to
get an earlier commit as HEAD to
split it.

The simplest case is if you want
to split a commit A into a chain
A'-B-C, where A' is the first new
commit, and contains most of the
original commit, including the
commit message. Then you can do

::

    git reset -p HEAD^ [-- <paths>]
    git commit --amend

to selectively remove parts from
commit A, but leave them in your
working tree. Then you can create
one or more commits of the
remaining changes as described in
other tips.

If you want to split a commit A
into a chain where the original
commit message is reused for
something else than the first
commit (e.g., B-A'-C), then you
can do

::

    git reset HEAD^

to remove the HEAD commit, but
leave everything in your working
tree. Then you can create your
commits as described in other
tips. When you come to a point
where you want to reuse the
original commit message, you can
use

::

    git reflog

to find how to refer to your
original commit as ``HEAD@{n}``, and
then do

::

    git commit -c HEAD@{n}

.. rubric:: Q: How do I use git rebase -i to only edit local commits?

A: Assume that you have a local
feature branch checked out, this
branch has three commits, and
that it is based on master.
Further, assume that master has
gotten a few more commits after
you branched off. If you want to
use ``git rebase -i`` to edit your
feature branch (see above), you
probably want to do

::

    git rebase -i HEAD~3

followed by a separate

::

    git rebase master

The first command allows you to
edit your local branch without
getting conflicts from changes in
master. The latter allows you to
resolve those conflicts in a
separate rebase run. If you feel
brave enough, you can also do
both at the same time using

::

    git rebase -i master
Guidelines for #include directives
==================================

The following include order is used in |Gromacs|. An empty line should appear
between each group, and headers within each group sorted alphabetically.

1. Each *source* file should include ``gmxpre.h`` first.
2. If a *source* file has a corresponding header, it should be included next.
   If the header is in the same directory as the source, then it is included
   without any path (i.e., relative to the source). Otherwise, the canonical
   include path of ``libraryname/modulename/header.h`` is used.
3. If the file depends on defines from ``config.h``, that comes next.
4. This is followed by standard C/C++ headers, grouped as follows:

   1. Standard C headers (e.g., ``<stdio.h>``)
   2. C++ versions of the above (e.g., ``<cstdio>``)
   3. Standard C++ headers (e.g., ``<vector>``)

   Preferably, only one of the first two groups is present, but this is not
   enforced.
5. This is followed by other system headers: platform-specific headers such as
   ``<unistd.h>``, as well as external libraries such as
   ``<gtest/gtest.h>``.
6. |Gromacs|-specific libraries from ``src/external/``, such as
   ``"thread_mpi/threads.h"``.
7. |Gromacs| headers that are not part of the including module.
8. Public |Gromacs| headers that are part of the including module.
9. Finally, |Gromacs| headers that are internal to the including module,
   executable, or test target
   (typically at the same path as the source file).

All |Gromacs| headers are included with quotes (``"gromacs/utility/path.h"``),
other headers with angle brackets (``<stdio.h>``).  Headers under ``src/external/``
are generally included with quotes (whenever the include path is relative to
``src/``, as well as for thread-MPI and TNG), but larger third-party entities are
included as if they were provided by the system.  The latter group currently
includes gtest/gmock.

If there are any conditionally included headers (typically, only when some
#defines from ``config.h`` are set), these should be included at the end of
their respective group.  Note that the automatic checker/sorter script does not
act on such headers, nor on comments that are between #include statements; it
is up to the author of the code to put the headers in proper order in such
cases.  Trailing comments on the same line as #include statements are
preserved and do not affect the checker/sorter.

As part of the effort to build a proper API, a new scheme of separating between
public, library and module functionality in header files is planned.
See also :doc:`gmxtree` and
`API restructuring issues <https://gitlab.com/gromacs/gromacs/-/issues?label_name%5B%5D=API+restructuring>`__
for details.

Enforcing a consistent order and style has a few advantages:

* It makes it easy at a quick glance to find the dependencies of a file,
  without scanning through a long list of unorganized #includes.
* Including the header corresponding to the source file first makes most
  headers included first in some source file, revealing potential problems
  where headers would not compile unless some other header would be included
  first.  With this order, the person working on the header is most likely to
  see these problems instead of someone else seeing them later when
  refactoring unrelated code.
* Consistent usage of paths in ``#include`` directives makes it easy to use
  ``grep`` to find all uses of a header, as well as all include dependencies
  between two modules.
* An automatic script can be used to re-establish clean code after
  semi-automatic refactoring like renaming an include file with ``sed``, without
  causing other unnecessary changes.
.. _dev guide:

***************
Developer Guide
***************

.. highlight:: bash

This set of pages contains guidelines, instructions, and explanations related
to |Gromacs| development.  The actual code is documented in Doxygen
documentation linked below.

The focus is (at least for now) on things that are tightly tied to the code
itself, such as helper scripts that reside in the source repository and
organization of the code itself, and may require the documentation to be
updated in sync.

The guide is currently split into a few main parts:

* Overview of the |Gromacs| codebase.
* Collection of overview pages that describe some important implementation
  aspects.
* Generic guidelines to follow when developing |Gromacs|.
  For some of the guidelines, scripts exist (see below) to automatically
  reformat the code and/or enforce the guidelines for each commit.
* Instructions on what tools are used, and how to use them.

.. only:: html

        In addition to this, Doxygen documentation extracted from the comments
        in the C/C++ code is available to document the actual existing code.

.. only:: latex

        **The full code documentation generated from Doxygen can be found in the online
        documentation. It is not included here in order to save the trees.**

Some overview documentation that is closely related to the actual C/C++ code
appears in the Doxygen documentation, while some other overview content is in
the developer guide.  The reasons are partially technical, but crosslinks
between the developer guide and the Doxygen documentation are provided whenever
related content appears split between the two sources.

The documentation does not yet cover all areas, but more content is being
(slowly) added.
Wiki pages at http://www.gromacs.org/Developer_Zone may contain additional
information (much of it outdated, though), and can be linked from relevant
locations in the developer guide.

.. toctree::
   :maxdepth: 2

   contribute
   overview
   build-system
   change-management
   relocatable-binaries
   documentation-generation
   style
   tools
   known-issues

*********************
Doxygen documentation
*********************

.. only:: html

  * `Public API documentation <../doxygen/html-user/index.xhtml>`_
       This contains documentation for code that appears in installed headers,
       as well as some overview documentation to understand those parts of the
       code.
       Please note that the definition of the public API is very preliminary
       and subject to change, in particular for parts that have not been
       documented.
  * `Code documentation <../doxygen/html-lib/index.xhtml>`_
       This contains the public API documentation as a subset, but also has more
       details on the internal implementation of |Gromacs|.  This is a good
       place to start to understand some specific area of the code in general
       to, e.g., contribute.
  * `Full documentation <../doxygen/html-full/index.xhtml>`_
       This contains every single documented function from the codebase,
       including internal  There can be an overwhelming amount of detail, but
       this can be useful if trying to find some specific function within the
       codebase.

.. only:: latex

    The doxygen code documentation is available on the |Gromacs| webpage.


Relocatable binaries
====================

|Gromacs| (mostly) implements the concept of relocatable binaries, i.e., that
after initial installation to ``CMAKE_INSTALL_PREFIX`` (or binary packaging
with CPack), the whole installation tree can be moved to a different folder and
|Gromacs| continues to work without further changes to the installation tree.
This page explains how this is implemented, and the known limitations in the
implementation.  This information is mainly of interest to developers who need
to understand this or change the code, but it can also be useful for people
installing or packaging |Gromacs|.

A related feature that needs to be considered in all the code related to this
is that the executables should work directly when executed from the build tree,
before installation.  In such a case, the data files should also be looked up
from the source tree to make development easy.

Finding shared libraries
------------------------

If |Gromacs| is built with dynamic linking, the first part of making the
binaries relocatable is to make it possible for the executable to find
``libgromacs``, no matter how it is executed.  On platforms that support
a relative RPATH, this is used to make the |Gromacs| executables find the
``libgromacs`` from the same installation prefix.  This makes the executables
fully relocatable when it comes to linking, as long as the relative folder
structure between the executables and the library is kept the same.

If the RPATH mechanism does not work, ``GMXRC`` also adds the absolute path to
the ``libgromacs`` installed with it to ``LD_LIBRARY_PATH``.  On platforms that
support this, this makes the linker search for the library here, but it is less
robust, e.g., when mixing calls to different versions of |Gromacs|.  Note that
``GMXRC`` is currently not relocatable, but hardcodes the absolute path.

On native Windows, DLLs are not fully supported; it is currently only possible
to compile a DLL with MinGW, not with Visual Studio or with Intel compilers.
In this case, the DLLs are placed in the ``bin/`` directory instead of
``lib/`` (automatically by CMake, based on the generic binary type assignment
in ``CMakeLists.txt``).  Windows automatically searches DLLs from the
executable directory, so the correct DLL should always be found.

For external libraries, standard CMake linking mechanisms are used and RPATH
for the external dependencies is included in the executable; on Windows,
dynamic linking may require extra effort to make the loader locate the correct
external libraries.

To support executing the built binaries from the build tree without
installation (critical for executing tests during development), standard CMake
mechanism is used: when the binaries are built, the RPATH is set to the build
tree, and during installation, the RPATH in the binaries is rewritten by CMake
to the final (relative) value.  As an extra optimization, if the installation
tree has the same relative folder structure as the build tree, the final
relative RPATH is used already during the initial build.

The RPATH settings are in the root ``CMakeLists.txt``.  It is possible to
disable the use of RPATH during installation with standard CMake variables,
such as setting ``CMAKE_SKIP_INSTALL_RPATH=ON``.

Finding data files
------------------

The other, |Gromacs|-specific part, of making the binaries relocatable is
to make them able to find data files from the installation tree.  Such data
files are used for multiple purposes, including showing the quotes at the end
of program execution.  If the quote database is not found, the quotes are
simply not printed, but other files (mostly used by system preparation tools
like :ref:`gmx pdb2gmx` and :ref:`gmx grompp`, and by various analysis tools
for static data) will cause fatal errors if not found.

There are several considerations here:

* For relocation to work, finding the data files cannot rely on any hard-coded
  absolute path, but it must find out the location of the executing code by
  inspecting the system.  As a fallback, environment variables or such set by
  ``GMXRC`` or similar could be used (but currently are not).
* When running executables from the build tree, it is desirable that they will
  automatically use the data files from the matching source tree to facilitate
  easy testing.  The data files are not copied into the build tree, and the
  user is free to choose any relative locations for the source and build trees.
  Also, the data files are not in the same relative path in the source tree and
  in the installation tree (the source tree has ``share/top/``, the
  installation tree ``share/gromacs/top/``; the latter is customizable during
  CMake configuration).
* In addition to |Gromacs| executables, programs that link against
  ``libgromacs`` need to be able to find the data files if they call certain
  functions in the library.  In this case, the executable may not be in the
  same directory where |Gromacs| is.  In case of static linking, no part of the
  code is actually loaded from the |Gromacs| installation prefix, which makes
  it impossible to find the data files without external information.
* The user can always use the ``GMXLIB`` environment variable to provide
  alternative locations for the data files, but ideally this should never be
  necessary for using the data files from the installation.

Not all the above considerations are fully addressed by the current
implementation, which works like this:

1. It finds the path to the current executable based on ``argv[0]``.  If the
   value contains a directory, this is interpreted as absolute or as relative
   to the current working directory.  If there is no directory, then a file by
   that name is searched from the directories listed in ``PATH``.  On Windows,
   the current directory is also searched before ``PATH``.  If a file with a
   matching name is found, this is used without further checking.
2. If the executable is found and is a symbolic link, the symbolic links are
   traversed until a real file is found.  Note that links in the directory name
   are not resolved, and if some of the links contain relative paths, the end
   result may contain ``..`` components and such.
3. If an absolute path to the executable was found, the code checks whether the
   executable is located in the build output directory (using ``stat()`` or
   similar to account for possible symbolic links in the directory components).
   If it is, then the hard-coded source tree location is returned.
4. If an absolute path to the executable was found and it was not in the build
   tree, then all parent directories are checked.  If a parent directory
   contains :file:`share/{gromacs}/top/gurgle.dat`, this directory is returned
   as the installation prefix.  The file name ``gurgle.dat`` and the location
   are considered unique enough to ensure that the correct directory has been
   found.  The installation directory for read-only architecture-independent
   data files can be customized during CMake configuration by setting
   ``CMAKE_INSTALL_DATADIR``, and the subdirectory under this that hosts the
   GROMACS-specific data is set by ``GMX_INSTALL_DATASUBDIR``.

   Note that this search does not resolve symbolic links or normalize the input
   path beforehand: if there are ``..`` components *and* symbolic links in the
   path, the search may proceed to unexpected directories, but this should not
   be an issue as the correct installation prefix should be found before
   encountering such symbolic links (as long as the ``bin/`` directory is not a
   symbolic link).
5. If the data files have not been found yet, try a few hard-coded guesses
   (like the original installation ``CMAKE_INSTALL_PREFIX`` and
   ``/usr/local/``).  The first guess that contains suitable files
   (``gurgle.dat``) is returned.
6. If still nothing is found, return ``CMAKE_INSTALL_PREFIX`` and let the
   subsequent data file opening fail.

The above logic to find the installation prefix is in
``src/gromacs/commandline/cmdlineprogramcontext.cpp``.  Note that code that
links to ``libgromacs`` can provide an alternative implementation for
``gmx::IProgramContext`` for locating the data files, and is then fully
responsible of the above considerations.

Information about the used data directories is printed into the console output
(unless run with ``-quiet``), as well as to (some) error messages when locating
data files, to help diagnosing issues.

There is no mechanism to disable this probing search or affect the process
during compilation time, except for the CMake variables mentioned above.

Known issues
------------

* ``GMXRC`` is not relocatable: it hardcodes the absolute installation path in
  one assignment within the script, which no longer works after relocation.
  Contributions to get rid of this on all the shells the ``GMXRC`` currently
  supports are welcome.
* There is no version checking in the search for the data files; in case of
  issues with the search, it may happen that the installation prefix from some
  other installation of |Gromacs| is returned instead, and only cryptic errors
  about missing or invalid files may reveal this.
* If the searching for the installation prefix is not successful, hard-coded
  absolute guesses are used, and one of those returned.  These guesses include
  the absolute path in ``CMAKE_INSTALL_PREFIX`` used during compilation of
  ``libgromacs``, which will be incorrect after relocation.
* The search for the installation prefix is based on the locating the
  executable.  This does not work for programs that link against
  ``libgromacs``, but are not installed in the same prefix.  For such cases,
  the hard-coded guesses will be used, so the search will not find the correct
  data files after relocation.  The calling code can, however, programmatically
  provide the |Gromacs| installation prefix, but ideally this would work
  without offloading work to the calling code.
* One option to (partially) solve the two above issues would be to use the
  ``GMXDATA`` environment variable set by ``GMXRC`` as the fallback (currently
  this environment variable is set, but very rarely used).
* Installed ``pkg-config`` files are not relocatable: they hardcode the
  absolute installation path.
Physical validation
===================

Physical validation tests check whether simulation results correspond
to physical (or mathematical) expectations.

Unlike the existing tests, we are not be able to keep these tests in
the "seconds, not minutes" time frame, rather aiming for "hours, not
days".  They should therefore be ran periodically, but probably not
for every build.

Also, given the long run time, it will in many cases be necessary to
separate running of the systems (e.g. to run it at a specific time, or
on a different resource), such that the make script does give the
option to

* prepare run files and an execution script,
* analyze already present simulations,
* or prepare, run and analyze in one go.


Test description
----------------

Currently, simulation results are tested against three physically /
mathematically expected results:

* *Integrator convergence*: A symplectic integrator can be shown to
  conserve a constant of motion (such as the energy in a
  micro-canonical simulation) up to a fluctuation that is quadratic in
  time step chosen. Comparing two or more constant-of-motion
  trajectories realized using different time steps (but otherwise
  unchanged simulation parameters) allows a check of the symplecticity
  of the integration. Note that lack of symplecticity does not
  necessarily imply an error in the integration algorithm, it can also
  hint at physical violations in other parts of the model, such as
  non-continuous potential functions, imprecise handling of
  constraints, etc.
* *Kinetic energy distribution*: The kinetic energy trajectory of a
  (equilibrated) system sampling a canonical or an isothermal-isobaric
  ensemble is expected to be Maxwell-Boltzmann distributed. The
  similarity between the physically expected and the observed
  distribution allows to validate the sampled kinetic energy ensemble.
* *Distribution of configurational quantities*: As the distribution of
  configurational quantities like the potential energy or the volume
  are in general not known analytically, testing the likelihood of a
  trajectory sampling a given ensemble is less straightforward than
  for the kinetic energy. However, generally, the ratio of the
  probability distribution between samples of the same ensemble at
  different state points (e.g. at different temperatures, different
  pressures) is known. Comparing two simulations at different state
  points therefore allows a validation of the sampled ensemble.

The physical validation included in GROMACS tests a range of the
most-used settings on several systems. The general philosophy is to
leave most settings to default values with the exception of the ones
explicitly tested in order to be sensitive to changes in the default
values. The test set will be enlarged as we discover interesting test
systems and corner cases. Under double precision, some additional
tests are ran, and some other tests are ran using a lower tolerance.


Integrator convergence
^^^^^^^^^^^^^^^^^^^^^^

All simulations performed under NVE on Argon (1000 atoms) and water
(900 molecules) systems. As these tests are very sensitive to
numerical imprecision, they are performed with long-range corrections
for both Lennard-Jones and electrostatic interactions, with a very low
pair-list tolerance (``verlet-buffer-tolerance = 1e-10``), and high
LINCS settings where applicable.

**Argon**:

* *Integrators*:
  - ``integrator = md``
  - ``integrator = md-vv``
* *Long-range corrections LJ*:
  - ``vdwtype = PME``
  - ``vdwtype = cut-off``, ``vdw-modifier = force-switch``, ``rvdw-switch = 0.8``

**Water**:

* *Integrators*:
  - ``integrator = md``
  - ``integrator = md-vv``
* *Long-range corrections LJ*:
  - ``vdwtype = PME``
  - ``vdwtype = cut-off``, ``vdw-modifier = force-switch``, ``rvdw-switch = 0.8``
* *Long-range corrections electrostatics*:
  - ``coulombtype = PME``, ``fourierspacing = 0.05``
* *Constraint algorithms*:
  - ``constraint-algorithm = lincs``, ``lincs-order = 6``, ``lincs-iter = 2``
  - ``constraint-algorithm = none``
  - SETTLE


Ensemble tests
^^^^^^^^^^^^^^

The generated ensembles are tested with Argon (1000 atoms) and water
(900 molecules, with SETTLE and PME) systems, in the following
combinations:

* ``integrator = md``, ``tcoupl = v-rescale``, ``tau-t = 0.1``,
  ``ref-t = 87.0`` (Argon) or ``ref-t = 298.15`` (Water)
* ``integrator = md``, ``tcoupl = v-rescale``, ``tau-t = 0.1``,
  ``ref-t = 87.0`` (Argon) or ``ref-t = 298.15`` (Water), ``pcoupl =
  parrinello-rahman``, ``ref-p = 1.0``, ``compressibility = 4.5e-5``
* ``integrator = md-vv``, ``tcoupl = v-rescale``, ``tau-t = 0.1``,
  ``ref-t = 87.0`` (Argon) or ``ref-t = 298.15`` (Water)
* ``integrator = md-vv``, ``tcoupl = nose-hoover``, ``tau-t = 1.0``,
  ``ref-t = 87.0`` (Argon) or ``ref-t = 298.15`` (Water), ``pcoupl =
  mttk``, ``ref-p = 1.0``, ``compressibility = 4.5e-5``

All thermostats are applied to the entire system (``tc-grps =
system``). The simulations run for 1ns at 2fs time step with Verlet
cut-off. All other settings left to default values.


Building and testing using the build system
-------------------------------------------

Since these tests can not be ran at the same frequency as the current
tests, they are kept strictly opt-in via
``-DGMX_PHYSICAL_VALIDATION=ON``, with
``-DGMX_PHYSICAL_VALIDATION=OFF`` being the default. Independently of
that, all previously existing build targets are unchanged, including
``make check``.

If physical validation is turned on, a number of additional make
targets can be used:

* ``make check`` is unchanged, it builds the main binaries and the unit
  tests, then runs the unit tests and, if available, the regression
  tests.
* ``make check-phys`` builds the main binaries, then runs the physical
  validation tests. **Warning**: This requires to simulate all systems
  and might take several hours on a average machine!
* ``make check-all`` combines ``make check`` and ``make check-phys``.

As the simulations needed to perform the physical validation tests may
take long, it might be advantageous to run them on an external
resource. To enable this, two additional make targets are present:

* ``make check-phys-prepare`` prepares all simulation files under
  ``tests/physicalvalidation`` of the build directory, as well as a
  rudimentary run script in the same directory.
* ``make check-phys-analyze`` runs the same tests as ``make
  check-phys``, but does not simulate the systems. Instead, this
  target assumes that the results can be found under
  ``tests/physicalvalidation`` of the build directory.

The intended usage of these additional targets is to prepare the
simulation files, then run them on a different resource or at a
different time, and later analyze them. If you want to use this, be
aware *(i)* that the run script generated is very simple and might
need (considerable) tuning to work with your setup, and *(ii)* that
the analysis script is sensitive to the folder structure, so make sure
to preserve it when copying the results to / from another resource.

Additionally to the mentioned make targets, a number of internal make
targets are defined. These are not intended to be used directly, but
are necessary to support the functionality described above, especially
the complex dependencies. These internal targets include
``run-ctest``, ``run-ctest-nophys``, ``run-ctest-phys`` and
``run-ctest-phys-analyze`` running the different tests,
``run-physval-sims`` running the simulations for physical validation,
and ``missing-tests-notice``, ``missing-tests-notice-all``,
``missing-phys-val-phys``, ``missing-phys-val-phys-analyze`` and
``missing-phys-val-all`` notifying users about missing tests.


Direct usage of the python script
---------------------------------

The ``make`` commands mentioned above are calling the python script
``tests/physicalvalidation/gmx_physicalvalidation.py``, which can be
used independently of the make system. Use the ``-h`` flag for the
general usage information, and the ``--tests`` for more details on the
available physical validations.

The script requires a ``json`` file defining the tests as an input.
Among other options, it allows to define the GROMACS binary and the
working directory to be used, and to decide whether to only prepare
the simulations, prepare and run the simulations, only analyze the
simulations, or do all three steps at once.


Adding new tests
----------------

The available tests are listed in the ``systems.json`` (tests
standardly used for single precision builds) and ``systems_d.json``
(tests standardly used for double precision builds) files in the same
directory, the GROMACS files are in the folder ``systems/``.

The ``json`` files lists the different test. Each test has a
``"name"`` attribute, which needs to be unique, a ``"dir"`` attribute,
which denotes the directory of the system (inside the ``systems/``
directory) to be tested, and a ``"test"`` attribute which lists the
validations to be performed on the system. Additionally, the optional
``"grompp_args"`` and ``"mdrun_args"`` attributes allow to pass
specific arguments to ``gmx grompp`` or ``gmx mdrun``, respectively. A
single test can contain several validations, and several independent
tests can be performed on the same input files.

To add a new test to a present system, add the test name and the
arguments to the ``json`` file(s). To use a new system, add a
subfolder in the ``systems/`` directory containing
``input/system.{gro,mdp,top}`` files defining your system.
Using Doxygen
=============

This page documents how Doxygen is set up in the |Gromacs| source tree,
as well as guidelines for adding new Doxygen comments.  Examples are included,
as well as tips and tricks for avoiding Doxygen warnings.  The guidelines focus
on C++ code and other new code that follows the new module layout.
Parts of the guidelines are still applicable to documenting older code (e.g.,
within ``gmxlib/`` or ``mdlib/``), in particular the guidelines about formatting
the Doxygen comments and the use of ``\internal``.
See :ref:`dev-doc-layout` for the overall structure of the documentation.

To get started quickly, you only need to read the first two sections to
understand the overall structure of the documentation, and take a look at the
examples at the end.  The remaining sections provide the details for
understanding why the examples are the way they are, and for more complex
situations.  They are meant more as a reference to look up solutions for
particular problems, rather than single-time reading.  To understand or find
individual Doxygen commands, you should first look at the Doxygen documentation
(http://www.doxygen.nl/manual/).


Documentation flavors
---------------------

The |Gromacs| source tree is set up to produce several different levels of Doxygen
documentation:

1. Public API documentation (suffix ``-user``), which documents functions and
   classes exported from the library and intended for use outside the |Gromacs|
   library.
2. Library API documentation (suffix ``-lib``), which additionally includes
   functions and classes that are designed to be used from other parts of
   |Gromacs|, as well as some guidelines that are mostly of interest to
   developers.
3. Full documentation (suffix ``-full``), which includes (nearly) all (documented)
   functions and classes in the source tree.
4. Maximally verbose documentation (suffix ``-dev``) with everything doxygen can
   extract as well as additional internal links.

Each subsequent level of documentation includes all the documentation from the
levels above it.  The suffixes above refer to the suffixes of Doxygen input and
output files, as well as the name of the output directory.  When all the
flavors have been built, the front pages of the documentation contain links to
the other flavors, and explain the differences in more detail.

As a general guideline, the public API documentation should be kept free of
anything that a user linking against an unmodified |Gromacs| does not see.
In other words, the public API documentation should mainly document the
contents of installed headers, and provide the necessary overview of using
those.  Also, verbosity requirements for the public API documentation are
higher: ideally, readers of the documentation could immediately start using the
API based on the documentation, without any need to look at the implementation.

Similarly, the library API documentation should not contain things that other
modules in |Gromacs| can or should never call.  In particular, anything declared
locally in source files should be only available in the full documentation.
Also, if something is documented, and is not identified to be in the library
API, then it should not be necessary to call that function from outside its
module.


Building the documentation
--------------------------

If you want to see up-to-date documentation, you can download artifacts from 
the ``webpage`` job of the latest scheduled pipeline for a corresponding branch
(https://gitlab.com/gromacs/gromacs/-/pipelines?page=1&scope=all&source=schedule).
CI also runs Doxygen for all changes pushed to GitLab for
release and master branches, and the resulting documentation can be
found in the artifacts of the corresponding ``webpage`` job.
The Doxygen job will fail if it introduces any Doxygen warnings.

You may need to build the documentation locally if you want to check the
results after adding/modifying a significant amount of comments.  This is
recommended in particular if you do not have much experience with Doxygen.
It is a good idea to build with all the different settings to see that the
result is what you want, and that you do not produce any warnings.
For local work, it is generally a good idea to set ``GMX_COMPACT_DOXYGEN=ON``
CMake option, which removes some large generated graphs from the documentation
and speeds up the process significantly. There are also "fast" versions
of the ``make`` targets that skip the additional diagrams built for the ``lib``
level and lower.

All files related to Doxygen reside in the ``docs/doxygen/`` subdirectory in the source
and build trees.  In a freshly checked out source tree, this directory contains
various ``Doxyfile-*.cmakein`` files.  When you run CMake, corresponding files
``Doxyfile-user``, ``Doxyfile-lib``, ``Doxyfile-full``, ``Doxyfile-dev`` are generated at the
corresponding location in the build tree.  There is also a
``Doxyfile-common.cmakein``, which is used to produce ``Doxyfile-common``.
This file contains settings that are shared between all the input files.
``Doxyfile-compact`` provides the extra settings for ``GMX_COMPACT_DOXYGEN=ON``.

You can run Doxygen directly with one of the generated files (all output will
be produced under the current working directory), or build one of the
``doxygen-user``, ``doxygen-lib``, ``doxygen-full``, ``doxygen-dev`` targets.  The targets run
Doxygen in a quieter mode and only show the warnings if there were any, and put
the output under ``docs/html/doxygen/`` in the build tree, so that the Doxygen
build cooperates with the broader ``webpage`` target.
The ``doxygen-all`` target builds all three targets with less typing.

The generated documentation is put under ``html-user/``, ``html-lib/``,
``html-full/``, and/or ``html-dev/``.  Open ``index.xhtml`` file from one of
these subdirectories to start browsing (for |Gromacs| developers, the
``html-lib/`` is a reasonable starting point).  Log files with all Doxygen
warnings are also produced as ``docs/doxygen/doxygen-*.log``, so you can inspect them after
the run.

You will need Doxygen |EXPECTED_DOXYGEN_VERSION| to build the current
documentation.  Other versions may work, but likely also produce warnings.
Additionally, `graphviz <http://www.graphviz.org>`_ and
`mscgen <http://www.mcternan.me.uk/mscgen/>`_ are required for some graphs in
the documentation, and ``latex`` for formulas.  Working versions are likely
available through most package managers.  It is possible to build the
documentation without these tools, but you will see some errors and the related
figures will be missing from the documentation.

.. _dev-doxygen-guidelines:

General guidelines for Doxygen markup
-------------------------------------

Doxygen provides quite a few different alternative styles for documenting the
source code.  There are subtleties in how Doxygen treats the different types of
comments, and this also depends somewhat on the Doxygen configuration.  It is
possible to change the meaning of a comment by just changing the style of
comment it is enclosed in.  To avoid such issues, and to avoid needing to
manage all the alternatives, a single style throughout the source tree is
preferable.  When it comes to treatment of styles, |Gromacs| uses the default
Doxygen configuration with one exception: ``JAVADOC_AUTOBRIEF`` is set ``ON`` to
allow more convenient one-line brief descriptions in C code.

Majority of existing comments in |Gromacs| uses Qt-style comments (``/*!`` and
``//!`` instead of ``/**`` and ``///``, ``\brief`` instead of ``@brief`` etc.),
so these should be used also for new documentation.  There is a single
exception for brief comments in C code; see below.

Similarly, existing comments use ``/*!`` for multiline comments in both C and
C++ code, instead of using multiple ``//!`` lines for C++.  The rationale is that
since the code will be a mixture of both languages for a long time, it is more
uniform to use similar style in both.  Also, since files will likely transition
from C to C++ gradually, rewriting the comments because of different style
issues should not generally be necessary.  Finally, multi-line ``//!`` comments
can work differently depending on Doxygen configuration, so it is better to
avoid that ambiguity.

When adding comments, ensure that a short brief description is always produced.
This is used in various listings, and should briefly explain the purpose of the
method without unnecessarily expanding those lists.
The basic guideline is to start all comment blocks with ``\brief`` (possibly
after some other Doxygen commands).
If you want to avoid the ``\brief`` for one-liners, you can use ``//!``, but the
description must fit on a single line; otherwise, it is not interpreted as a
brief comment.  Note in particular that a simple ``/*!`` without a ``\brief``
does not produce a brief description.
Also note that ``\brief`` marks the whole following paragraph as a brief
description, so you should insert an empty line after the intended brief
description.

In C code, ``//`` comments must be avoided because some compilers do not like
them.  If you want to avoid the ``\brief`` for one-liners in C code, use
``/**`` instead of ``//!``.  If you do this, the brief description should not
contain unescaped periods except at the end.  Because of this, you should
prefer ``//!`` in C++ code.

Put the documentation comments in the header file that contains the
declaration, if such a header exists.
Implementation-specific comments that do not influence how a method
is used can go into the source file, just before the method definition, with an
``\internal`` tag in the beginning of the comment block.  Doxygen-style comments
within functions are not generally usable.

At times, you may need to exclude some part of a header or a source file such
that Doxygen does not see it at all.  In general, you should try to avoid this,
but it may be necessary to remove some functions that you do not want to appear
in the public API documentation, and which would generate warnings if left
undocumented, or to avoid Doxygen warnings from code it does not understand.
Prefer ``\cond`` and ``\endcond`` to do this.  If ``\cond`` does not work for
you, you can also use ``#ifndef DOXYGEN``.  If you exclude a class method in
a header, you also need to exclude it in the source code to avoid warnings.


|Gromacs| specifics
-------------------

The general guidelines on the style of Doxygen comments were given above.
This section introduces |Gromacs| specific constructs currently used in Doxygen
documentation, as well as how |Gromacs| uses Doxygen groups to organize the
documentation.

Some consistency checks are done automatically using custom scripts.
See :doc:`gmxtree` for details.

Controlling documentation visibility
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To control in which level of documentation a certain function appears, three
different mechanisms are used:

* Global Doxygen configuration.  This is mainly used to include
  declarations local to source files only in the full documentation.
  You can find the details from the ``Doxyfile-*.cmakein`` files, and some of
  them are also mentioned below on individual code constructs.
* The standard Doxygen command ``\internal`` marks the documentation to be only
  extracted into the full documentation (``INTERNAL_DOCS`` is ``ON`` only for the
  full documentation).  This should be used as a first command in a comment
  block to exclude all the documentation.  It is possible to use ``\internal``
  and ``\endinternal`` to exclude individual paragraphs, but ``\if internal``
  is preferred (see below).
  In addition, |Gromacs|-specific custom Doxygen command ``\libinternal`` is
  provided, which should be used the same way to exclude the documentation from
  the public API documentation.  This command expands to either ``\internal``
  or to a no-op, depending on the documentation level.
* Doxygen commands ``\if`` and ``\cond`` can be used with section names
  ``libapi`` and ``internal`` to only include the documentation in library API and
  the full documentation, respectively.  ``libapi`` is also defined in the full
  documentation.  These are declared using ``ENABLED_SECTIONS`` in the Doxygen
  configuration files.

Examples of locations where it is necessary to use these explicit commands are
given below in the sections on individual code constructs.

Modules as Doxygen groups
^^^^^^^^^^^^^^^^^^^^^^^^^

As described in :ref:`dev-source-layout`, each subdirectory under ``src/gromacs/``
represents a *module*, i.e., a somewhat coherent collection of routines.
Doxygen cannot automatically generate a list of routines in a module; it only
extracts various alphabetical indexes that contain more or less all documented
functions and classes.  To help reading the documentation, the routines for a
module should be visible in one place.

|Gromacs| uses Doxygen groups to achieve this: for each documented module, there
is a ``\defgroup`` definition for the module, and all the relevant classes and
functions need to be manually added to this group using ``\ingroup`` and
``\addtogroup``.
The group page also provides a natural place for overview documentation about
the module, and can be navigated to directly from the "Modules" tab in the
generated documentation.

Some notes about using ``\addtogroup`` are in order:

* ``\addtogroup`` only adds the elements that it directly contains into the
  group.  If it contains a namespace declaration, only the namespace is added
  to the group, but none of the namespace contents are.  For this reason,
  ``\addtogroup`` should go within the innermost scope, around the members that
  should actually be added.
* If the module should not appear in the public API documentation, its
  definition (``\defgroup``) should be prefixed with a ``\libinternal``.
  In this case, also all ``\addtogroup`` commands for this module should be
  similarly prefixed.  Otherwise, they create the group in the public API
  documentation, but without any of the content from the ``\defgroup``
  definition.  This may also cause the contents of the ``\addtogroup`` section
  to appear in the public API documentation, even if it otherwise would not.

Public API and library API groups
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In addition to the module groups, two fixed groups are provided:
``group_publicapi`` and ``group_libraryapi``.  Classes and files can be added to
these groups using |Gromacs| specific custom ``\inpublicapi`` and
``\inlibraryapi`` commands.  The generated group documentation pages are not
very useful, but annotated classes and files show the API definition under the
name, making this information more easily accessible.  These commands in
file-level comments are also used for some automatic intermodule dependency
validation (see below).

Note that functions, enumerations, and other entities that do not have a
separate page in the generated documentation can only belong to one group;
in such a case, the module group is preferred over the API group.


Documenting specific code constructs
------------------------------------

This section describes the techical details and some tips and tricks for
documenting specific code constructs such that useful documentation is
produced.  If you are wondering where to document a certain piece of
information, see the documentation structure section in :ref:`dev-doc-layout`.
The focus of the documentation should be on the overview content: Doxygen pages
and the module documentation.  An experienced developer can relatively easily
read and understand individual functions, but the documentation should help
in getting the big picture.

Doxygen pages
^^^^^^^^^^^^^

The pages that are accessible through navigation from the front page are
written using Markdown and are located under ``docs/doxygen/``.  Each page should be
placed in the page hierarchy by making it a subpage of another page, i.e., it
should be referenced once using ``\subpage``.  ``mainpage.md`` is the root of the
hierarchy.

There are two subdirectories, ``user/`` and ``lib/``, determining the highest
documentation level where the page appears.  If you add pages to ``lib/``, ensure
that there are no references to the page from public API documentation.
``\if libapi`` can be used to add references in content that is otherwise
public.
Generally, the pages should be on a high enough level and provide overview
content that is useful enough such that it is not necessary to exclude them
from the library API documentation.

Modules
^^^^^^^

For each module, decide on a header file that is the most important one for
that module (if there is no self-evident header, it may be better to designate,
e.g., ``module-doc.h`` for this purpose, but this is currently not done for any
module).  This header should contain the ``\defgroup`` definition for the
module.  The name of the group should be :file:`module_{name}`, where *name*
is the name of the subdirectory that hosts the module.

The module should be added to an appropriate group (see ``docs/doxygen/misc.cpp`` for
definitions) using ``\ingroup`` to organize the "Modules" tab in the generated
documentation.

One or more contact persons who know about the contents of the module should be
listed using ``\author`` commands.  This provides a point of contact if one
has questions. Authors should be listed in chronological order of contributions,
where possible.

Classes/structs
^^^^^^^^^^^^^^^

Classes and structs in header files appear always in Doxygen documentation,
even if their enclosing file is not documented.  So start the documentation
blocks of classes that are not part of the public API with ``\internal`` or
``\libinternal``.  Classes declared locally in source files or in unnamed
namespaces only appear in the full documentation.

If a whole class is not documented, this does not currently generate any
warning.  The class is simply exluded from the documentation.  But if a member
of a documented class is not documented, a warning is generated.  Guidelines for
documenting free functions apply to methods of a class as well.

For base classes, the API classification (``\inpublicapi`` or
``\inlibraryapi``) should be based on where the class is meant to be
subclassed.  The visibility (``\internal`` or ``\libinternal``), in contrast,
should reflect the API classification of derived classes such that the base
class documentation is always generated together with the derived classes.

For classes that are meant to be subclassed and have protected members, the
protected members should only appear at the documentation level where the class
is meant to be subclassed.  For example, if a class is meant to be subclassed
only within a module, the protected members should only appear in the
full documentation.  This can be accomplished using ``\cond`` (note that you
will need to add the ``\cond`` command also to the source files to hide the
same methods from Doxygen, otherwise you will get confusing warnings).

Methods/functions/enums/macros
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

These items do not appear in the documentation unless their enclosing scope is
documented.  For class members, the scope is the class; otherwise, it is the
namespace if one exists, or the file.  An ``\addtogroup`` can also define a
scope if the group has higher visibility than the scope outside it.
So if a function is not within a namespace (mostly applicable to C code) and
has the same visibility as its enclosing file, it is not necessary to add a
``\internal`` or ``\libinternal``.

Static functions are currently extracted for all documentation flavors to allow
headers to declare ``static inline`` functions (used in, for example, math code).
Functions in anonymous namespaces are only extracted into the full
documentation.  Together with the above rules, this means that you should avoid
putting a ``static`` function within a documented namespace, even within source
files, or it may inadvertently appear in the public API documentation.

If you want to exclude an item from the documentation, you need to put in
inside a ``\cond`` block such that Doxygen does not see it.
Otherwise, a warning for an undocumented function is generated.  You need to
enclose both the declaration and the definition with ``\cond``.

Files
^^^^^

Each documented file should start with a documentation block (right after the
copyright notice) that documents the file.  See the examples section for exact
formatting.  Things to note:

* Please do not specify the file name explicitly after ``\file``.  By default,
  a file comment applies to the file it is contained in, and an explicit file
  name only adds one more thing that can get out of date.
* ``\brief`` cannot appear on the same line as the ``\file``, but should be on
  the next line.
* ``\internal`` or ``\libinternal`` should indicate where the header is visible.
  As a general guideline, all installed headers should appear in the public API
  documentation, i.e., not contain these commands.  If nothing else, then to
  document that it does not contain any public API functions.  Headers that
  declare anything in the library API should be marked with ``\libinternal``,
  and the rest with ``\internal``.
* All source files, as well as most test files, should be documented with
  ``\internal``, since they do not provide anything to public or library API,
  and this avoids unintentionally extracting things from the file into those
  documentations.  Shared test files used in tests from other modules should be
  marked with ``\libinternal``.
* ``\inpublicapi`` or ``\inlibraryapi`` should be used to indicate where the
  header is meant to be directly included.
* As with modules, one or more contact persons should be listed with ``\author``.
  If you make significant modifications or additions to a file, consider adding
  an ``\author`` line for yourself.

Directories
^^^^^^^^^^^

Directory documentation does not typically contain useful information beyond a
possible brief description, since they correspond very closely to modules, and
the modules themselves are documented.  A brief description is still useful to
provide a high-level overview of the source tree on the generated "Files" page.
A reference to the module is typically sufficient as a brief description for a
directory.  All directories are currently documented in
``docs/doxygen/directories.cpp``.


Examples
--------

.. highlight:: c++

Basic C++
^^^^^^^^^

Here is an example of documenting a C++ class and its containing header file.
Comments in the code and the actual documentation explain the used Doxygen
constructs. ::

  /*! \libinternal \file
   * \brief
   * Declares gmx::MyClass.
   *
   * More details.  The documentation is still extracted for the class even if
   * this whole comment block is missing.
   *
   * \author Example Author <example@author.com>
   * \inlibraryapi
   * \ingroup module_mymodule
   */

  namespace gmx
  {

  /*! \libinternal
   * \brief
   * Brief description for the class.
   *
   * More details.  The \libinternal tag is required for classes, since they are
   * extracted into the documentation even in the absence of documentation for
   * the enclosing scope.
   * The \libinternal tag is on a separate line because of a bug in Doxygen
   * 1.8.5 (only affects \internal, but for clarity it is also worked around
   * here).
   *
   * \inlibraryapi
   * \ingroup module_mymodule
   */
  class MyClass
  {
      public:
          // Trivial constructors or destructors do not require documentation.
          // But if a constructor takes parameters, it should be documented like
          // methods below.
          MyClass();
          ~MyClass();

          /*! \brief
           * Brief description for the method.
           *
           * \param[in] param1  Description of the first parameter.
           * \param[in] param2  Description of the second parameter.
           * \returns   Description of the return value.
           * \throws    std::bad_alloc if out of memory.
           *
           * More details describing the method.  It is not an error to put this
           * above the parameter block, but most existing code has it here.
           */
          int myMethod(int param1, const char *param2) const;

          //! Brief description for the accessor.
          int simpleAccessor() const { return var_; }
          /*! \brief
           * Alternative, more verbose way of specifying a brief description.
           */
          int anotherAccessor() const;
          /*! \brief
           * Brief description for another accessor that is so long that it does
           * not conveniently fit on a single line cannot be specified with //!.
           */
          int secondAccessor() const;

      private:
          // Private members (whether methods or variables) are currently ignored
          // by Doxygen, so they don't need to be documented.  Documentation
          // doesn't hurt, though.
          int var_;
  };

  } // namespace gmx

Basic C
^^^^^^^

Here is another example of documenting a C header file (so avoiding all
C++-style comments), and including free functions.  It also demonstrates the use
of ``\addtogroup`` to add multiple functions into a module group without repeated
``\ingroup`` tags. ::

  /*! \file
   * \brief
   * Declares a collection of functions for performing a certain task.
   *
   * More details can go here.
   *
   * \author Example Author <example@author.com>
   * \inpublicapi
   * \ingroup module_mymodule
   */

  /*! \addtogroup module_mymodule */
  /*! \{ */

  /*! \brief
   * Brief description for the data structure.
   *
   * More details.
   *
   * \inpublicapi
   */
  typedef struct {
      /** Brief description for member. */
      int  member;
      int  second; /**< Brief description for the second member. */
      /*! \brief
       * Brief description for the third member.
       *
       * Details.
       */
      int  third;
  } gmx_mystruct_t;

  /*! \brief
   * Performs a simple operation.
   *
   * \param[in] value  Input value.
   * \returns   Computed value.
   *
   * Detailed description.
   * \inpublicapi cannot be used here, because Doxygen only allows a single
   * group for functions, and module_mymodule is the preferred group.
   */
  int gmx_function(int value);

  /* Any . in the brief description should be escaped as \. */
  /** Brief description for this function. */
  int gmx_simple_function();

  /*! \} */

Scoping and visibility rules
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The rules where Doxygen expects something to be documented, and when are
commands like ``\internal`` needed, can be complex.  The examples below
describe some of the pitfalls. ::

  /*! \libinternal \file
   * \brief
   * ...
   *
   * The examples below assume that the file is documented like this:
   * with an \libinternal definition at the beginning, with an intent to not
   * expose anything from the file in the public API.  Things work similarly for
   * the full documentation if you replace \libinternal with \internal
   * everywhere in the example.
   *
   * \ingroup module_example
   */


  /*! \brief
   * Brief description for a free function.
   *
   * A free function is not extracted into the documentation unless the enclosing
   * scope (in this case, the file) is.  So a \libinternal is not necessary.
   */
  void gmx_function();

  // Assume that the module_example group is defined in the public API.

  //! \addtogroup module_example
  //! \{

  //! \cond libapi
  /*! \brief
   * Brief description for a free function within \addtogroup.
   *
   * In this case, the enclosing scope is actually the module_example group,
   * which is documented, so the function needs to be explicitly excluded.
   * \\libinternal does not work, since it would produce warnings about an
   * undocumented function, so the whole declaration is hidden from Doxygen.
   */
  void gmx_function();
  //! \endcond

  //! \}

  // For modules that are only declared in the library API, \addtogroup
  // cannot be used without an enclosing \cond.  Otherwise, it will create
  // a dummy module with the identifier as the name...

  //! \cond libapi
  //! \addtogroup module_libmodule
  //! \{

  /*! \brief
   * Brief description.
   *
   * No \libinternal is necessary here because of the enclosing \cond.
   */
  void gmx_function();

  //! \}
  //! \endcond

  // An alternative to the above is use this, if the enclosing scope is only
  // documented in the library API:

  //! \libinternal \addtogroup module_libmodule
  //! \{

  //! Brief description.
  void gmx_function()

  //! \}

  /*! \libinternal \brief
   * Brief description for a struct.
   *
   * Documented structs and classes from headers are always extracted into the
   * documentation, so \libinternal is necessary to exclude it.
   * Currently, undocumented structs/classes do not produce warnings, so \cond
   * is not necessary.
   */
  struct t_example
  {
      int  member1; //!< Each non-private member should be documented.
      bool member2; //!< Otherwise, Doxygen will produce warnings.
  };

  // This namespace is documented in the public API.
  namespace gmx
  {

  //! \cond libapi
  /*! \brief
   * Brief description for a free function within a documented namespace.
   *
   * In this case, the enclosing scope is the documented namespace,
   * so a \cond is necessary to avoid warnings.
   */
  void gmx_function();
  //! \endcond

  /*! \brief
   * Class meant for subclassing only within the module, but the subclasses will
   * be public.
   *
   * This base class still provides public methods that are visible through the
   * subclasses, so it should appear in the public documentation.
   * But it is not marked with \inpublicapi.
   */
  class BaseClass
  {
      public:
          /*! \brief
           * A public method.
           *
           * This method also appears in the documentation of each subclass in
           * the public and library API docs.
           */
          void method();

      protected:
          // The \cond is necessary to exlude this documentation from the public
          // API, since the public API does not support subclassing.
          //! \cond internal
          //! A method that only subclasses inside the module see.
          void methodForSubclassToCall();

          //! A method that needs to be implemented by subclasses.
          virtual void virtualMethodToImplement() = 0;
          //! \endcond
  };

  } // namespace gmx

Module documentation
^^^^^^^^^^^^^^^^^^^^

Documenting a new module should place a comment like this in a central header
for the module, such that the "Modules" tab in the generated documentation can
be used to navigate to the module. ::

  /*! \defgroup module_example "Example module (example)"
   * \ingroup group_utilitymodules
   * \brief
   * Brief description for the module.
   *
   * Detailed description of the module.  Can link to a separate Doxygen page for
   * overview, and/or describe the most important headers and/or classes in the
   * module as part of this documentation.
   *
   * For modules not exposed publicly, \libinternal can be added at the
   * beginning (before \defgroup).
   *
   * \author Author Name <author.name@email.com>
   */

  // In other code, use \addtogroup module_example and \ingroup module_example to
  // add content (classes, functions, etc.) onto the module page.

Common mistakes
^^^^^^^^^^^^^^^

The most common mistake, in particular in C code, is to forget to document the
file.  This causes Doxygen to ignore most comments in the file, so it
does not validate the contents of the comments either, nor is it possible to
actually check how the generated documentation looks like.

The following examples show some other common mistakes (and some less common)
that do not produce correct documentation, as well as Doxygen "features"/bugs
that can be confusing.

* The struct itself is not documented; other comments within the declaration
  are ignored. ::

    struct t_struct {

        // The comment tries to document both members at once, but it only
        // applies to the first.  The second produces warnings about missing
        // documentation (if the enclosing struct was documented).

        //! Angle parameters.
        double alpha, beta;
    };

* This does not produce any brief documentation.
  An explicit ``\brief`` is required, or ``//!`` (C++) or ``/** */`` (C)
  should be used. ::

    /*! Brief comment. */
    int gmx_function();

* This does not produce any documentation at all, since a ``!`` is missing at
  the beginning. ::

    /* \brief
     * Brief description.
     *
     * More details.
     */
    int gmx_function();

* This puts the whole paragraph into the brief description.
  A short description is preferable, separated by an empty line from the rest
  of the text. ::

    /*! \brief
     * Brief description. The description continues with all kinds of details about
     * what the function does and how it should be called.
     */
    int gmx_function();

* This may be a Doxygen bug, but this does not produce any brief description. ::

    /** \internal Brief description. */
    int gmx_function();

* If the first declaration below appears in a header, and the second in a
  source file, then Doxygen does not associate them correctly and complains
  about missing documentation for the latter.  The solution is to explicitly
  add a namespace prefix also in the source file, even though the compiler
  does not require it. ::

    // Header file
    //! Example function with a namespace-qualified parameter type.
    int gmx_function(const gmx::SomeClass &param);

    // Source file
    using gmx::SomeClass;

    int gmx_function(const SomeClass &param);

* This puts the namespace into the mentioned module, instead of the contents
  of the namespace.  ``\addtogroup`` should go within the innermost scope. ::

    //! \addtogroup module_example
    //! \{

    namespace gmx
    {

    //! Function intended to be part of module_example.
    int gmx_function();

    }

Existing code
^^^^^^^^^^^^^

More examples you can find by looking at existing code in the source tree.  In
particular new C++ code such as that in the ``src/gromacs/analysisdata/`` and
``src/gromacs/options/`` subdirectories contains a large amount of code
documented mostly along these guidelines.  Some comments in
``src/gromacs/selection/`` (in particular, any C-like code) predate the
introduction of these guidelines, so those are not the best examples.

.. include:: /fragments/doxygen-links.rst
==========
Containers
==========

|Gromacs| project infrastructure uses Docker containerization to
isolate automated tasks.
A number of images are maintained to provide a breadth of testing coverage.

Scripts and configuration files for building images are stored in the repository
under :file:`admin/containers/`
Images are (re)built manually by |Gromacs| project staff and pushed to
DockerHub and GitLab.
See https://hub.docker.com/u/gromacs and https://gitlab.com/gromacs/gromacs/container_registry

GitLab Container Registry
=========================

CI Pipelines use a GitLab container registry instead of pulling from Docker Hub.

Project members with role ``Developer`` or higher privilege can
`push images <https://docs.gitlab.com/ee/user/packages/container_registry/index.html#build-and-push-images-by-using-docker-commands>`__
to the container registry.

Steps:

1. Create a `personal access token <https://gitlab.com/-/profile/personal_access_tokens>`__ (`docs <https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html>`__)
   with ``write_registry`` and ``read_registry`` scopes. Save the hash!
2. Authenticate from the command line with ``docker login registry.gitlab.com -u <user name> -p <hash>``
3. ``docker push registry.gitlab.com/gromacs/gromacs/<imagename>``

Refer to :file:`buildall.sh` in the ``master`` branch for the set of images
currently built.

Within :doc:`pipeline jobs <gitlab-ci>`, jobs specify a Docker image with the *image* property.
For image naming convention, see :py:func:`utility.image_name`.
Images from the GitLab registry
are easily accessible with the same identifier as above.
For portability, CI environment variables may be preferable for parts of the image identifier.
Example::

    some_job:
      image: ${CI_REGISTRY_IMAGE}/ci-<configuration>
      ...

For more granularity,
consider equivalent expressions ``${CI_REGISTRY}/${CI_PROJECT_PATH}``
or ``${CI_REGISTRY}/${CI_PROJECT_NAMESPACE}/${CI_PROJECT_NAME}``
Ref: https://docs.gitlab.com/ee/ci/variables/predefined_variables.html

Utilities
=========

:file:`utility.py`
------------------

.. automodule:: utility
    :members:

:file:`scripted_gmx_docker_builds.py`
-------------------------------------

.. automodule:: scripted_gmx_docker_builds
.. _code-formatting:

Guidelines for code formatting
==============================

The following list provides the general formatting/indentation rules for
|Gromacs| code (C/C++):

* Basic indentation is four spaces.
* Keep lines at a reasonable length. Keep every line at least below 120
  characters.  If you end up indenting very deeply, consider splitting the code
  into functions.
* Do not use tabs, only spaces.  Most editors can be configured to generate
  spaces even when pressing tab.  Tabs (in particular when mixed with spaces)
  easily break indentation in contexts where settings are not exactly equal
  (e.g., in ``git diff`` output).
* No trailing whitespace.
* Use braces always for delimiting blocks, even when there is only a single
  statement in an ``if`` block or similar.
* Put braces on their own lines.  The only exception is short one-line inline
  functions in C++ classes, which can be put on a single line.
* Use spaces liberally.
* ``extern "C"`` and ``namespace`` blocks are not indented, but all others
  (including ``class`` and ``switch`` bodies) are. Namespace blocks have
  to have a closing comment with the name of it.

Additionally:

* All source files and other non-trivial scripts should contain a copyright
  header with a predetermined format and license information (check existing
  files).  Copyright holder should be "the |Gromacs| development team" for the
  years where the code has been in the |Gromacs| source repository, but earlier
  years can hold other copyrights.
* Whenever you update a file, you should check that the current year is listed
  as a copyright year.

Most of the above guidelines are enforced using clang-format or uncrustify,
which are both  automatic source code formatting tool. The copyright guidelines
are enforced by a separate Python script. See :doc:`code-formatting` for details.
Note that due to the nature of those scripts (they only do all-or-nothing formatting),
all the noted formatting rules are enforced at the same time.

Enforcing a consistent formatting has a few advantages:

* No one needs to manually review code for most of these formatting issues,
  and people can focus on content.
* A separate automatic script (see below) can be applied to re-establish the
  formatting after refactoring like renaming symbols or changing some
  parameters, without needing to manually do it all.

A number of user provided set-ups are available for the correct settings of your
favourite text editor. They are provided for convenience only, and may not
exactly conform to the expectations of either formatting tool.

Emacs formatting set-up
-----------------------
Insert the following into your .emacs configuration file::

    (defun gromacs-c-mode-common-hook ()
    ;; GROMACS customizations for c-mode

    (c-set-offset 'substatement-open 0)
    (c-set-offset 'innamespace 0)
    ;; other customizations can go here

    (setq c++-tab-always-indent t)
    (setq c-basic-offset 4)                  ;; Default is 2
    (setq c-indent-level 4)                  ;; Default is 2
    (setq c-file-style "stroustrup")
    (setq tab-stop-list '(4 8 12 16 20 24 28 32 36 40 44 48 52 56 60))
    (setq tab-width 4)
    (setq indent-tabs-mode nil)  ; use tabs if t
    )
    (add-hook 'c-mode-common-hook 'gromacs-c-mode-common-hook)

    (defun gromacs-c++-mode-common-hook ()
    ;; GROMACS customizations for c++-moe

    (c++-set-offset 'substatement-open 0)
    (c++-set-offset 'innamespace 0)
    ;; other customizations can go here

    (setq c++-tab-always-indent t)
    (setq c++-basic-offset 4)                  ;; Default is 2
    (setq c++-indent-level 4)                  ;; Default is 2
    (setq c++-file-style "stroustrup")
    
    (setq tab-stop-list '(4 8 12 16 20 24 28 32 36 40 44 48 52 56 60))
    (setq tab-width 4)
    (setq indent-tabs-mode nil)  ; use tabs if t
    )
    
    (add-hook 'c++-mode-common-hook 'gromacs-c++-mode-common-hook)

This configuration is based on content from `stackoverflow`_.

.. _stackoverflow: http://stackoverflow.com/questions/663588/emacs-c-mode-incorrect-indentation

Eclipse/cdt formatting set-up
-----------------------------

For correct formatting, please use `this profile`_.

.. _this profile: https://gist.github.com/rolandschulz/74f4fae8985d65f33ff6
.. _code-commitstyle:

Guidelines for formatting of git commits
========================================

While there is no true correct way on how to submit new commits for 
code review for |Gromacs|, following these guidelines will help the
review process go smoothly.

General rules for newly submitted code
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

New code should follow the other :ref:`style rules<style-guidelines>`
outlined above before submitting. This will make it less likely that your change
will be rejected due to that. If your change modifies some existing
code that does not yet conform to the style, then a preliminary
patch that cleans up the surrounding area is a good idea. We like
to slowly improve the quality while we add or change functionality.

Guidelines for git commit messages
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Commit messages should contain a quick explanation in verb form on what has been
changed or what has been the purpose of the change. If available, the final
part of the message before the ChangeId should be a short section like
**Fixes #issue-id** to link the change to a possibly previously
posted issue, or **Refs #issue-id** if the present patch is somehow
related to that work without necessarily fixing the whole issue.

Concerning inline code comments
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

New code should be sufficiently commented so that other people will be able to 
understand the purpose of the code, and less about the current operation.
Preferably the variable naming and code structure clarify the mechanics, and
comments should only refer to higher-level things, such as choice of algorithm,
or the desire to be consistent with some other part of the code.

For example, the following comment would be insufficient to explain the 
(made up example) of iteration over a list of interactions::

    /* Code takes each item and iterates over them in a loop
     * to store them.
     */

A much better example would be explaining why the iteration takes place::

    /* We iterate over the items in the list to get 
     * the specific interaction type for all of them
     * and store them in the new data type for future 
     * use in function foo
     */

From the second example, someone debugging might be able to deduce better
if an error observed in *foo* is actually caused by the previous assignment.
GitLab CI Pipeline Execution
============================

The repository contains DockerFiles and GitLab Runner configuration
files to support automated testing and documentation builds.
General information on configuring GitLab CI pipelines can be found
in the official `Gitlab documentation <https://docs.gitlab.com/ee/ci/yaml/>`_.

The GitLab CI configuration entry point is the :file:`.gitlab-ci.yml` file
at the root of the source tree.
Configuration templates are found in the files in the
:file:`admin/ci-templates/` directory.

Docker images used by GitLab Runner are available on `Docker Hub <https://hub.docker.com/u/gromacs>`__.
Images are (re)built manually using details in :file:`admin/containers`.

.. todo:: (:issue:`3617`) Comment on the number of pipelines that can be or which are likely to be running at the same time.

.. note::

    Full automated testing is only available for merge requests originating from
    branches of the main https://gitlab.com/gromacs/gromacs repository.
    GitLab CI pipelines created for forked repositories will include fewer jobs
    in the testing pipeline. Non-trivial merge requests may need to be issued
    from a branch in the ``gromacs`` project namespace in order to receive
    sufficient testing before acceptance.

Configuration files
-------------------

At the root of the repository, :file:`.gitlab-ci.yml` defines the stages and
some default parameters, then includes files from :file:`admin/gitlab-ci/` to
define jobs to be executed in the pipelines.

Note that job names beginning with a period (``.``) are
`"hidden" <https://docs.gitlab.com/ee/ci/yaml/#hidden-keys-jobs>`_.
Such jobs are not directly eligible to run, but may be used as templates
via the `*extends* job property <https://docs.gitlab.com/ee/ci/yaml/#extends>`_.

Job parameters
--------------

Refer to https://docs.gitlab.com/ee/ci/yaml for complete documentation on
GitLab CI job parameters, but note the following GROMACS-specific conventions.

.. glossary::

    before_script
        Used by several of our templates to prepend shell commands to
        a job *script* parameter.
        Avoid using *before-script* directly, and be cautious
        about nested *extends* overriding multiple *before_script* definitions.

    job cache
        There is no global default, but jobs that build software will likely
        set *cache*. To explicitly unset *cache* directives, specify a job
        parameter of ``cache: {}``.
        Refer to `GitLab docs <https://docs.gitlab.com/ee/ci/yaml/#cache>`__
        for details. In particular, note the details of cache identity according
        to `cache:key <https://docs.gitlab.com/ee/ci/yaml/#cachekey>`__

    image
        See :doc:`/dev-manual/containers` for more about the Docker images used for the
        CI pipelines. If a job depends on artifacts from previous jobs, be sure
        to use the same (or a compatible) image as the dependency!

    rules
    only
    except
    when
        *Job* parameters for controlling the circumstances under which jobs run.
        (Some key words may have different meanings when occurring as elements
        of other parameters, such as *archive:when*, to which this note is not
        intended to apply.)
        Instead of setting any of these directly in a job definition, try to use
        one of the pre-defined behaviors (defined as ``.rules:<something>`` in
        :file:`admin/gitlab-ci/rules.gitlab-ci.yml`).
        Errors or unexpected behavior will occur if you specify more than one
        *.rules:...* template, or if you use these parameters in combination
        with a *.rules...* template.
        To reduce errors and unexpected behavior, restrict usage of these controls
        to regular job definitions (don't use in "hidden" or parent jobs).
        Note that *rules* is not compatible with the older *only* and *except*
        parameters. We have standardized on the (newer) *rules* mechanism.

    tags
        Jobs that can only run in the |Gromacs| GitLab CI Runner infrastructure
        should require the ``k8s-scilifelab`` tag.
        These include jobs that specify Kubernetes configuration variables or
        require special facilities, such as GPUs or MPI.
        Note that the *tag* controls which Runners are eligible to take a job.
        It does not affect whether the job is eligible for addition to a particular pipeline.
        Additional *rules* logic should be used to make sure that jobs with the
        ``k8s-scilifelab`` do not become eligible for pipelines launched outside
        of the |Gromacs| project environment.
        See, for instance, :term:`CI_PROJECT_NAMESPACE`

    variables
        Many job definitions will add or override keys in *variables*.
        Refer to `GitLab <https://docs.gitlab.com/ee/ci/yaml/#variables>`__
        for details of the merging behavior. Refer to :ref:`variables` for local usage.

Schedules and triggers
----------------------

Pipeline `schedules <https://gitlab.com/help/ci/pipelines/schedules>`__ are
configured through the GitLab web interface.
Scheduled pipelines may provide different variable definitions through the
environment to jobs that run under the ``schedules``
`condition <https://gitlab.com/help/ci/pipelines/schedules#using-only-and-except>`__.

Nightly scheduled pipelines run against ``master`` and *release* branches in
the GROMACS repository.

Running post-merge-acceptance pipelines
"""""""""""""""""""""""""""""""""""""""

The Gitlab CI for |Gromacs| runs a set of jobs by default only after a MR has been
accepted and the resulting commit is included in the target branch if it is ``master``
or one of the *release* branches. Those jobs can be triggered manually using the
``POST_MERGE_ACCEPTANCE`` input variable documented below when executing a new pipeline
through the Gitlab web interface.

Global templates
----------------

In addition to the templates in the main job definition files,
common "mix-in" functionality and behavioral templates are defined in
:file:`admin/gitlab-ci/global.gitlab-ci.yml`.
For readability, some parameters may be separated into their own files, named
according to the parameter (e.g. :file:`rules.gitlab-ci.yml`).

Jobs beginning with ``.use-`` provide mix-in behavior, such as boilerplate for
jobs using a particular tool chain.

Jobs beginning with a `parameter <https://docs.gitlab.com/ee/ci/yaml>`__
name allow parameters to be set in a single place for common job characteristics.
If providing more than a default parameter value, the job name should be suffixed
by a meaningful descriptor and documented within
:file:`admin/gitlab-ci/global.gitlab-ci.yml`

Job names
---------

Job names should

1. Indicate the purpose of the job.
2. Indicate relationships between multi-stage tasks.
3. Distinguish jobs in the same stage.
4. Distinguish job definitions throughout the configuration.

Jobs may be reassigned to different stages over time, so including the stage
name in the job name is not helpful, generally. If tags like "pre" and "post,"
or "build" and "test" are necessary to distinguish phases of, say, "webpage,"
then such tags can be buried at the end of the job name.

Stylistically, it is helpful to use delimiters like ``:`` to distinguish the
basic job name from qualifiers or details. Also consider
`grouping jobs <https://docs.gitlab.com/ee/ci/pipelines/index.html#grouping-jobs>`__

.. _variables:

Updating regression tests
-------------------------

Changes in |Gromacs| that require changes in regression-tests are notoriously hard,
because a merge request that tests against the non-updated version of the
regression tests will necessarily fail, while updating regression tests while
the current change is not integrated into master, might cause other
merge request pipelines to fail.

The solution is a new regression-test branch or commit, uploaded to gitlab.
Then set that regression test branch with REGRESSIONTESTBRANCH or
the specific commit with REGRESSIONTESTCOMMIT when
running the specific pipeline that requires the regressiontest-update.
See below on how to set variables for specific pipelines.

Variables
---------

The GitLab CI framework, GitLab Runner, plugins, and our own scripts set and
use several `variables <https://docs.gitlab.com/ee/ci/variables/README.html>`__.

Default values are available from the ``.variables:default`` definition in
:file:`admin/gitlab-ci/global.gitlab-ci.yml`.
Many of the mix-in / template jobs provide additional or overriding definitions.
Other variables may be set when making final job definitions.

Variables may control the behvior of GitLab-CI (those beginning with ``CI_``),
GitLab Runner and supporting infrastructure, or may be used by job definitions,
or passed along to the environment of executed commands.

*variables* keys beginning with ``KUBERNETES_`` relate to the GitLab Runner
`Kubernets executor <https://docs.gitlab.com/runner/executors/kubernetes.html#the-kubernetes-executor>`__

Other important variable keys are as follows.

.. glossary::
    CI_PROJECT_NAMESPACE
        Distinguishes pipelines created for repositories in the ``gromacs``
        GitLab project space. May be used to pre-screen jobs to determine
        whether |Gromacs| GitLab infrastructure is available to the pipeline
        before the job is created.

    COMPILER_MAJOR_VERSION
        Integer version number provided by toolchain mix-in for convenience and
        internal use.

    CMAKE
        ``gromacs/ci-...`` Docker images built after October 2020 have several
        versions of CMake installed. The most recent version of CMake in the
        container will be appear first in ``PATH``. To allow individual jobs to
        use specific versions of CMake, please write the job *script* sections
        using ``$CMAKE`` instead of ``cmake`` and begin the *script* section with
        a line such as ``- CMAKE=${CMAKE:-$(which cmake)}``. Specify a CMake
        version by setting the *CMAKE* variable to the full executable path for
        the CMake version you would like to use. See also :doc:`containers`.

    CMAKE_COMPILER_SCRIPT
        CMake command line options for a tool chain. A definition is provided by
        the mix-in toolchain definitions (e.g. ``.use-gcc8``) to be appended to
        :command:`cmake` calls in a job's *script*.

    CMAKE_MPI_OPTIONS
        Provide CMake command line arguments to define GROMACS MPI build options.

    GROMACS_MAJOR_VERSION
        Read-only environment variable for CI scripts to check the
        library API version to expect from the ``build`` job artifacts.
        Initially, this variable is only defined in
        :file:`admin/gitlab-ci/api-client.matrix/gromacs-master.gitlab-ci.yml`
        but could be moved to :file:`admin/gitlab-ci/global.gitlab-ci.yml` if found
        to be of general utility.

    GROMACS_RELEASE
        Read-only environment variable that can be checked to see if a job is
        executing in a pipeline for preparing a tagged release.
        Can be set when launching pipelines via the GitLab web interface.
        For example, see *rules* mix-ins in :file:`admin/gitlab-ci/global.gitlab-ci.yml`.

    REGRESSIONTESTBRANCH
        Use this branch of the regressiontests rather than master to allow for
        merge requests that require updated regression tests with valid CI tests.

    REGRESSIONTESTCOMMIT
        Use this commit to the regressiontests rather than the head on master to
        allow for merge requests that require updated regression tests with
        valid CI tests.

    POST_MERGE_ACCEPTANCE
        Read-only environment variable that indicates that only jobs scheduled to
        run after a commit has been merged into its target branch should be executed.
        Can be set to run pipelines through the web interface or as schedules.
        For use please see the *rules* mix-ins in :file:`admin/gitlab-ci/global.gitlab-ci.yml`.

Setting variables
-----------------

Variables for individual piplelines are set in the gitlab interface under 
``CI/CD``; ``Pipelines``. Then chose in the top right corner ``Run Piplelines``.
Under ``Run for``, the desired branch may be selected, and variables may be set
in the fields below.
Naming conventions
==================

The conventions here should be applied to all new code, and with common sense
when modifying existing code.  For example, renaming a widely used, existing
function to follow these conventions may not be justified unless the whole code
is getting a rework.

Currently, this only documents the present state of the code: no particular
attempt has been made to consolidate the naming.

Files
-----

* C++ source files have a ``.cpp`` extension, C source files ``.c``, and
  headers for both use ``.h``.
* For source file :file:`{file}.c`/:file:`{file}.cpp`, declarations that are
  visible outside the source file should go into a correspondingly named
  header: :file:`{file}.h`.  Some code may deviate from this rule to improve
  readability and/or usability of the API, but this should then be clearly
  documented.

  There can also be a :file:`{file}_impl.h` file that declares classes or
  functions that are not accessible outside the module.  If the whole file only
  declares symbols internal to the module, then the :file:`_impl.h` suffix is
  omitted.

  In most cases, declarations that are not used outside a single source file
  are in the source file.
* Use suffix :file:`-doc.h` for files that contain only Doxygen documentation
  for some module or such, for cases where there is no natural single header
  for putting the documentation.
* For C++ files, prefer naming the file the same as the (main) class it
  contains.  Currently all file names are all-lowercase, even though class
  names contain capital letters.
  It is OK to use commonly known abbreviations, and/or omit the name of the
  containing directory if that would cause unnecessary repetition (e.g., as a
  common prefix to every file name in the directory) and the remaining part of
  the name is unique enough.
* Avoid having multiple files with the same name in different places within
  the same library.  In addition to making things harder to find, C++ source
  files with the same name can cause obscure problems with some compilers.
  Currently, unit tests are an exception to the rule (there is only one
  particular compiler that had problems with this, and a workaround is
  possible if/when that starts to affect more than a few of the test files).

Common guidelines for C and C++ code
------------------------------------

* Preprocessor macros should be all upper-case.  Do not use leading
  underscores, as all such names are reserved according to the C/C++ standard.
* Name include guards like ``GMX_DIRNAME_HEADERNAME_H``.
* Avoid abbreviations that are not obvious to a general reader.
* If you use acronyms (e.g., PME, DD) in names, follow the Microsoft policy on
  casing: two letters is uppercase (DD), three or more is lowercase (Pme).
  If the first letter would be lowercase in the context where it is used
  (e.g., at the beginning of a function name, or anywhere in a C function
  name), it is clearest to use all-lowercase acronym.

C code
------

* All function and variable names are lowercase, with underscores as word
  separators where needed for clarity.
* All functions that are part of the public API should start with ``gmx_``.
  Preferably, other functions should as well.
  Some parts of the code use a ``_gmx_`` prefix for internal functions, but
  strictly speaking, these are reserved names, so, e.g., a trailing underscore
  would be better.
* Old C code and changes to it can still use the hungarian notation for
  booleans and enumerated variable names, as well as enum values, where they
  are prefixed with ``b`` and ``e`` respectively, or you can gradually move
  to the C++ practice below. Whatever you choose, avoid complex abbreviations.

C++ code
--------

* Use CamelCase for all names.  Start types (such as classes, structs,
  typedefs and enum values) with a capital letter, other names (functions,
  variables) with a lowercase letter.
  You may use an all-lowercase name with underscores if your class closely
  resembles an external construct (e.g., a standard library construct) named
  that way.
* C++ interfaces are named with an ``I`` prefix, such as in ICommandLineModule.
  This keeps interfaces identifiable, without introducing too much clutter
  (as the interface is typically used quite widely, spelling out
  ``Interface`` would make many of the names unnecessarily long).
* Abstract base classes are typically named with an ``Abstract`` prefix.
* Member variables are named with a trailing underscore.
* Accessors for a variable ``foo_`` are named ``foo()`` and ``setFoo()``.
* Global variables are named with a ``g_`` prefix.
* Global and file-static variables are named with a ``g_`` prefix.
* Static class and function variables are named with an ``s_`` prefix.
* Static ``constexpr`` file, class, or function members are named with a ``sc_`` prefix.
* Global constants are often named with a ``c_`` prefix.
* If the main responsibility of a file is to implement a particular class,
  then the name of the file should match that class, except for possible
  abbreviations to avoid repetition in file names (e.g., if all classes within
  a module start with the module name, omitting or abbreviating the module
  name is OK).  Currently, all source file names are lowercase, but this
  casing difference should be the only difference.
* For new C++ code, avoid using the hungarian notation that is a descendant
  from the C code (i.e., the practice of using a ``b`` prefix for boolean
  variables and an ``e`` prefix for enumerated variables and/or values).
  Instead, make the names long with a good description of what they control,
  typically including a verb for boolean variables, like ``foundAtom``.
* Prefer class enums over regular ones, so that unexpected conversions to
  int do not happen.
* Name functions to convert class enum values to strings as ``enumValueToString``.
* When using a non-class enum, prefer to include the name of the enumeration type
  as a base in the name of enum values, e.g., ``HelpOutputFormat_Console``,
  in particular for settings exposed to other modules.
* Prefer to use enumerated types and values instead of booleans as control
  parameters to functions. It is reasonably easy to understand what the
  argument ``HelpOutputFormat_Console`` is controlling, while it is almost
  impossible to decipher ``TRUE`` in the same place without checking the
  documentation for the role of the parameter.

The rationale for the trailing underscore and the global/static prefixes is
that it is immediately clear whether a variable referenced in a method is local
to the function or has wider scope, improving the readability of the code.

Code for GPUs
-------------

Rationale: on GPUs, using the right memory space is often performance critical.

* In CUDA device code ``sm_``, ``gm_``, and ``cm_`` prefixes are used for
  shared, global and constant memory. The absence of a prefix indicates
  register space. Same prefixes are used in OpenCL code, where ``sm_``
  indicates local memory and no prefixes are added to variables in private
  address space.
* Data transferred to and from host has to live in both CPU and GPU memory
  spaces. Therefore it is typical to have a pointer or container (in CUDA), or
  memory buffer (in OpenCL) in host memory that has a device-based counterpart.
  To easily distinguish these, the variables names for such objects are
  prefixed ``h_`` and ``d_`` and have identical names otherwise. Example:
  ``h_masses``, and ``d_masses``.
* In all other cases, pointers to host memory are not required to have the
  prefix ``h_`` (even in parts of the host code, where both host and device
  pointers are present). The device pointers should always have the prefix
  ``d_`` or ``gm_``.
* In case GPU kernel arguments are combined into a structure, it is preferred
  that all device memory pointers within the structure have the prefix ``d_``
  (i.e. ``kernelArgs.d_data`` is preferred to ``d_kernelArgs.data``,
  whereas both ``d_kernelArgs.d_data`` and ``kernelArgs.data`` are not
  acceptable).
* Note that the same pointer can have the prefix ``d_`` in the host code,
  and ``gm_`` in the device code. For example, if ``d_data`` is passed to
  the kernel as an argument, it should be aliased to ``gm_data`` in the
  kernel arguments list. In case a device pointer is a field of a passed
  structure, it can be used directly or aliased to a pointer with ``gm_``
  prefix (i.e. ``kernelArgs.d_data`` can be used as is or aliased to
  ``gm_data`` inside the kernel).
* Avoid using uninformative names for CUDA warp, thread, block indexes and
  their OpenCL analogs (i.e. ``threadIndex`` is preferred to ``i`` or
  ``atomIndex``).

Unit tests
----------

* Test fixtures (the first parameter to ``TEST``/``TEST_F``) are named with a
  ``Test`` suffix.
* Classes meant as base classes for test fixtures (or as names to be typedefed
  to be fixtures) are named with a ``TestBase`` or ``Fixture`` suffix.
* The CTest test is named with CamelCase, ending with ``Tests`` (e.g.,
  ``OptionsUnitTests``).
* The test binary is named with the name of the module and a ``-test`` suffix.
.. highlight:: bash

Build system overview
=====================

The |Gromacs| build system uses CMake (version
|CMAKE_MINIMUM_REQUIRED_VERSION| or newer is required) to generate the
actual build system for the build tool chosen by the user.  See CMake
documentation for general introduction to CMake and how to use it.  This
documentation focuses on how the |Gromacs| build system is organized and
implemented, and what features it provides to developers (some of which may be
of interest to advanced users).

Most developers use ``make`` or ``ninja`` as the underlying build system, so
there can be parts of the build system that are specifically designed for
command-line consumption with these tools, and may not work ideally with other
environments, but basic building should be possible with all the environments
supported by CMake.

Also, the build system and version control is designed for out-of-source
builds.  In-source builds mostly work (there are a few custom targets that do
not), but no particular effort has been put to, e.g., having :file:`.gitignore`
files that exclude all the build outputs, or to have the ``clean`` target
remove all possible build outputs.

Build types
-----------

Build types is a CMake concept that provides overall control of how
the build tools are used on the given platform to produce executable
code. These can be set in CMake in various ways, including on a
command line such as ``cmake -DCMAKE_BUILD_TYPE=Debug``. |Gromacs|
supports the following standard CMake build types:

**Release**
  Fully optimized code intended for use in production simulation. This is the
  default.

**Debug**
  Compiled code intended for use with debugging tools, with low optimization levels
  and debug information for symbols.

**RelWithDebInfo**
  As Release, but with debug information for symbol names, which can help debugging
  issues that only emerge in optimized code.

**MinSizeRel**
  As Release, but optimized to minimize the size of the resulting executable. This
  is never a concern for |Gromacs| installations, so should not be used, but
  probably works.

Additionally, |Gromacs| provides the following build types for development and
testing. Their implementations can be found in ``cmake/gmxBuildTypeXXX.cmake``.

**Reference**
  This build type compiles a version of |Gromacs| aimed solely at correctness. All
  parallelization and optimization possibilities are disabled. This build type is
  compiled with GCC 7 to generate the regression test reference values, against
  which all other |Gromacs| builds are tested.

**RelWithAssert**
  As Release, but removes ``-DNDEBUG`` from compiler command lines, which makes
  all assertion statements active (and can have other safety-related side effects
  in |Gromacs| and code upon which it depends).

**Profile**
  As Release, but adds ``-pg`` for use with profiling tools. This is not
  likely to be effective for profiling the performance of :ref:`gmx mdrun`, but can
  be useful for the tools.

**TSAN**
  Builds |Gromacs| for use with ThreadSanitizer in gcc and clang
  (https://clang.llvm.org/docs/ThreadSanitizer.html) to detect
  data races. This disables the use of atomics in ThreadMPI,
  preferring the mutex-based implementation.

**ASAN**
  Builds |Gromacs| for use with AddressSanitizer in gcc and
  clang (https://clang.llvm.org/docs/AddressSanitizer.html) to
  detect many kinds of memory mis-use. By default, AddressSanitizer
  includes LeakSanitizer.

**MSAN**
  Builds |Gromacs| for use with MemorySanitizer in clang
  (https://clang.llvm.org/docs/MemorySanitizer.html) to detect
  reads of uninitialized memory. This functionality requires that
  dependencies of the |Gromacs| build have been built in a compatible
  way (roughly, static libraries with ``-g -fsanitize=memory
  -fno-omit-frame-pointer``), which generally requires at least the C++
  standard library to have been built specially. The path where the
  includes and libraries for dependencies should be found for this
  build type is set in the CMake cache variable
  ``GMX_MSAN_PATH``. Only internal XDR and internal fftpack are
  supported at this time.

For all of the sanitizer builds, to get readable stack traces, you may
need to ensure that the ``ASAN_SYMBOLIZER_PATH`` environment variable
(or your ``PATH``) includes that of the ``llvm-symbolizer`` binary.

With some generators, CMake generates the build system for more than a
single ``CMAKE_BUILD_TYPE`` from one pass over the ``CMakeLists.txt``
files, so any code that uses ``CMAKE_BUILD_TYPE`` in
``CMakeLists.txt`` directly will break. |Gromacs| does use such CMake
code, so we do not fully support all these build types in such
generators (which includes Visual Studio).

CMake cache variables
---------------------

This section provides a (currently incomplete) list of cache variables that
developers or advanced users can set to affect what CMake generates and/or what
will get built.

.. todo::

   Figure out where to document basic variables intended for user
   consumption, and how does it relate to documentation here.

.. todo::

   Document the remaining variables below, and identify any variables
   missing from the list.

Compiler flags
^^^^^^^^^^^^^^

Standard CMake mechanism for specifying the compiler flags is to use
``CMAKE_C_FLAGS``/``CMAKE_CXX_FLAGS`` for flags that affect all build types,
and :samp:`CMAKE_C_FLAGS_{buildtype}`/:samp:`CMAKE_CXX_FLAGS_{buildtype}` for
flags that only affect a specific build type.  CMake provides some default flags.

|Gromacs| determines its own set of default flags, grouped into two categories:

* Generic flags that are appended to the above default CMake flag variables
  (possibly for multiple build types), generally specifying optimization flags
  to use and controlling compiler warnings.
* Specific flags for certain features that the build system determines to be
  necessary for successful compilation.  One example is flags that determine
  what SIMD instruction set the compiler is allowed to use/needs to support.

All of the above flags are only added after testing that they work with the
provided compiler.

There is one cache variable to control the behavior of automatic compiler flags:

.. cmake:: GMX_SKIP_DEFAULT_CFLAGS

   If set ``ON``, the build system will not add any compiler flags
   automatically (neither generic nor specific as defined above), and will skip
   most linker flags as well.
   The default flags that would have been added are instead printed out when
   :command:`cmake` is run, and the user can set the flags themselves using the
   CMake variables.
   If ``OFF`` (the default), the flags are added as described above.

The code the determine the default generic flags is in
:file:`cmake/gmxCFlags.cmake`.
Code that sets the specific flags (e.g., SIMD flags) is in the main
:file:`CMakeLists.txt`; search for :cmake:`GMX_SKIP_DEFAULT_CFLAGS`.
The variables used there can be traced back to the locations where the actual
flags to use are determined.

Variables affecting compilation/linking
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. cmake:: GMX_BROKEN_CALLOC

   Enable emulation of ``calloc`` via ``malloc``/``memset``.
   Only needed on machines with a broken ``calloc(3)``, e.g. in ``-lgmalloc``
   on Cray XT3.
   Defaults to ``OFF``, and there should not be any need to change this unless
   you are sure it is required.

.. cmake:: GMX_BUILD_FOR_COVERAGE

   Special variable set ``ON`` by CI when doing a build for the coverage
   job.  Allows the build system to set options to produce as useful coverage
   metrics as possible.  Currently, it disables all asserts to avoid them
   showing up as poor conditional coverage.
   Defaults to ``OFF``, and there should not be any need to change this in a
   manual build.

   .. todo:: This could likely be replaced by a (yet another) build type.

.. cmake:: GMX_BUILD_OWN_FFTW

   If set ``ON``, |Gromacs| build system will download and build FFTW from source
   automatically. Not supported on Windows or with ``ninja`` build system.

.. cmake:: GMX_BUILD_SHARED_EXE

   Build executables as shared binaries. If not set, this disables ``-rpath`` and dynamic
   linker flags in an attempt to build a static binary, but this may require setting up
   the toolchain properly and making appropriate libraries available. Defaults to ``ON``.

.. cmake:: GMX_COMPILER_WARNINGS

   If set ``ON``, various compiler warnings are enabled for compilers that
   CI uses for verification.
   Defaults to ``OFF`` when building from a source tarball so that users
   compiling with versions not tested in CI are not exposed to our rather
   aggressive warning flags that can trigger a lot of warnings with, e.g., new
   versions of the compilers we use.
   When building from a git repository, defaults to ``ON``.

.. cmake:: GMX_CYCLE_SUBCOUNTERS

   If set to ``ON``, enables performance subcounters that offer more
   fine-grained mdrun performance measurement and evaluation than the default
   counters. See :doc:`/user-guide/mdrun-performance` for the description of
   subcounters which are available.
   Defaults to ``OFF``.

.. cmake:: GMX_ENABLE_CCACHE

    If set to ``ON``, attempts to set up the `ccache <https://ccache.dev/>`_
    caching compiler wrapper to speed up repeated builds.
    The ``ccache`` executable is searched for with ``find_package()`` if CMake
    is being run with a compatible build type.
    If the executable is found and a compatible compiler is configured,
    CMake launch wrapper scripts are set.
    If enabled, the ``ccache`` executable location discovered by CMake must be
    accessible during build, as well.
    Defaults to ``OFF`` to minimize build system complexity.

.. cmake:: GMX_INSTALL_DATASUBDIR

   Sets the subdirectory under CMAKE_INSTALL_DATADIR where GROMACS-specific
   read-only architecture-independent data files are installed. The default
   is ``gromacs``, which means the files will go under ``share/gromacs``.
   To alter the ``share`` part, change CMAKE_INSTALL_DATADIR.
   See :doc:`relocatable-binaries` for how this influences the build.

.. cmake:: GMX_DOUBLE

   Many part of |Gromacs| are implemented in terms of "real" precision,
   which is actually either a single- or double-precision type,
   according to the value of this flag. Some parts of the code
   deliberately use single- or double-precision types, and these are
   unaffected by this setting. See
   :doc:`Mixed or Double precision </reference-manual/definitions>`
   for further information.

.. cmake:: GMX_EXTRAE

   Add support for tracing using `Extrae <https://tools.bsc.es/extrae>`_.

.. cmake:: GMX_EXTERNAL_BLAS

   If not set (the default), CMake will first try to use an external BLAS library,
   and, if unsuccessful, fall back to using the one bundled with |Gromacs|.
   If set to ``OFF``, CMake will use the bundled one immediately.
   If set to ``ON``, CMake will use the external one, and raise an error if it is not found.

.. cmake:: GMX_EXTERNAL_LAPACK

   See ``GMX_EXTERNAL_BLAS``.

.. cmake:: GMX_EXTERNAL_TNG

   Use external TNG library for trajectory-file handling. Default: ``OFF``.

.. cmake:: GMX_FFT_LIBRARY

   Choose the CPU FFT library to use. Possible values: ``fftw``, ``mkl``, ``fftpack``.
   The default selection depends on the compiler and build type.

.. cmake:: GMX_GIT_VERSION_INFO

   Whether to generate version information dynamically from git for each build
   (e.g., HEAD commit hash).
   Defaults to ``ON`` if the build is from a git repository and :command:`git`
   is found, otherwise ``OFF``.
   If ``OFF``, static version information from
   :file:`cmake/gmxVersionInfo.cmake` is used.

.. cmake:: GMX_GPU

   Choose the backend for GPU offload. Possible values: ``CUDA``, ``OpenCL``, ``SYCL``.
   Please see the :ref:`Installation guide <gmx-gpu-support>` for more information.

.. cmake:: GMX_CLANG_CUDA

   Use clang for compiling CUDA GPU code, both host and device.
   Please see the :ref:`Installation guide <gmx-gpu-support>` for more information.

.. cmake:: GMX_CUDA_CLANG_FLAGS

    Pass additional CUDA-only compiler flags to clang using this variable.

.. cmake:: CMAKE_INSTALL_LIBDIR

   Sets the installation directory for libraries (default is determined by
   standard CMake package ``GNUInstallDirs``).
   See :doc:`relocatable-binaries` for how this influences the build.

.. cmake:: GMX_USE_PLUGINS

   Enable support for dynamic plugins (e.g. VMD-supported file formats).
   Default: ``OFF``.

.. cmake:: GMX_MPI

   Enable MPI (not thread-MPI) support for inter-node parallelism. Defaults to ``OFF``.
   Please see the :ref:`Installation guide <mpi-support>` for more information.

.. cmake:: GMX_OPENMP

   Enable OpenMP support. Default is ``ON``.

.. cmake:: GMX_PREFER_STATIC_LIBS

   Prefer statically linking to external libraries. Defaults to ``OFF``, unless
   ``GMX_BUILD_SHARED_EXE`` is disabled.

.. cmake:: GMX_SIMD

   Choose SIMD instruction set to use. Default is: ``Auto`` (best one for the current CPU).
   Please see the :ref:`Installation guide <gmx-simd-support>` for more information.

.. cmake:: GMX_THREAD_MPI

   Enable thread-MPI support for inter-node parallelism. Defaults to ``ON``.

.. cmake:: GMX_USE_RDTSCP

   Use low-latency ``RDTSCP`` instruction for x86 CPU-based timers for mdrun execution.
   Ignored on non-x86 machines. Might need to be set to ``OFF`` when compiling for
   for heterogeneous environments or a very old x86 CPU.

.. cmake:: GMX_USE_TNG

   Use the TNG library for trajectory I/O. Defaults to ``ON``.

.. cmake:: GMX_VMD_PLUGIN_PATH

   Path to VMD plugins for molfile I/O. Only used when ``GMX_USE_PLUGINS`` is enabled.

.. cmake:: GMX_X11

   Enable ``gmx view`` tool. Default: ``OFF``. Deprecated.

.. cmake:: GMX_XML

   Currently, this option has no effect on the compilation or linking, since
   there is no code outside the tests that would use :file:`libxml2`.

Variables affecting the ``all`` target
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. cmake:: BUILD_TESTING

   Standard variable created by CTest that enables/disables all tests.
   Defaults to ``ON``.

.. cmake:: GMX_BUILD_HELP

   Controls handling of man pages and shell completions.  Possible values:

   ``OFF`` (default for builds from release source distribution)
     Man pages and shell completions are not generated as part of the ``all``
     target, and only installed if compiling from a source package.
   ``AUTO`` (default for builds from development version)
     Shell completions are generated by executing the :file:`gmx` binary as
     part of the ``all`` target.  If it fails, a message is printed, but the
     build succeeds.
     Man pages need to be generated manually by invoking the ``man`` target.
     Man pages and shell completions are installed if they have been
     successfully generated.
   ``ON``
     Works the same as ``AUTO``, except that if invoking the :file:`gmx` binary
     fails, the build fails as well.

.. cmake:: GMX_DEVELOPER_BUILD

   If set ``ON``, the ``all`` target will include also the test binaries using
   Google Test (if :cmake:`GMX_BUILD_UNITTESTS` is ``ON``).
   Also, :cmake:`GMX_COMPILER_WARNINGS` is always enabled.
   In the future, other developer convenience features (as well as features
   inconvenient for a general user) can be added to the set controlled by this
   variable.

.. cmake:: GMX_CLANG_TIDY

  `clang-tidy <https://releases.llvm.org/11.0.0/tools/clang/tools/extra/docs/clang-tidy/index.html>`_
  is used for static code analysis and (some) automated fixing of issues detected. clang-tidy is easy to install.
  It is contained in
  the llvm binary `package <http://releases.llvm.org/download.html#11.0.0>`_. Only
  version 11.0.* is supported. Others might miss tests or give false positives.
  It is run automatically in GitLab CI for each commit. Many checks have fixes which can automatically be
  applied. To run it, the build has to be configured with
  ``cmake -DGMX_CLANG_TIDY=ON -DCMAKE_BUILD_TYPE=Debug``.
  Any ``CMAKE_BUILD_TYPE`` which enables asserts (e.g. ASAN) works. Such a configured build will
  run both the compiler as well as clang-tidy when building. The name of the clang-tidy executable is set with
  ``-DCLANG_TIDY=...``, and the full path to it can be set with ``-DCLANG_TIDY_EXE=...``.
  To apply the automatic fixes to the issues identified, clang-tidy should be run separately (running clang-tidy
  with ``-fix-errors`` as part of the build can corrupt header files). To fix a specific file run
  ``clang-tidy -fix-errors -header-filter '.*' {file}``, to fix all files in parallel
  ``run-clang-tidy.py -fix -header-filter '.*' '(?<!/selection/parser\.cpp|selection/scanner\.cpp)$'``,
  and to fix all modified files ``run-clang-tidy.py -fix -header-filter '.*' $(git diff HEAD --name-only)``.
  The :file:`run-clang-tidy.py` script is in the
  ``share/clang/`` subfolder of the llvm distribution. ``clang-tidy`` has to be able to find the
  ``compile_commands.json`` file. Either run from the build folder or add a symlink to the source folder.
  :cmake:`GMX_ENABLE_CCACHE` does not work with clang-tidy.

Variables affecting special targets
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. cmake:: GMXAPI

    If set ``ON``, the additional ``gmxapi`` C++ library is configured and the
    ``gmxapi`` headers will be installed. Provides the additional build tree
    targets ``gmxapi-cppdocs`` and ``gmxapi-cppdocs-dev`` when Doxygen is
    available. Also exports CMake configuration files for ``gmxapi`` that allow
    ``find_package(gmxapi)`` to import the ``Gromacs::gmxapi`` CMake target in
    client projects that search the GROMACS installation root.

.. cmake:: GMX_BUILD_MANUAL

   If set ``ON``, CMake detection for LaTeX and other prerequisites for the
   reference PDF manual is done, and the ``manual`` target for building the
   manual is generated.
   If ``OFF`` (the default), all detection is skipped and the manual cannot be
   built.

   .. todo:: Consider if this is really necessary, or if we could just use
      GMX_DEVELOPER_BUILD.

.. cmake:: GMX_BUILD_TARBALL

   If set ``ON``, ``-dev`` suffix is stripped off from version strings and some
   other version info logic is adjusted such that the man pages and other
   documentation generated from this build is suitable for releasing (on the
   web page and/or in the source distribution package).
   Defaults to ``OFF``.

.. cmake:: GMX_BUILD_UNITTESTS

   If ``ON``, test binaries using Google Test are built (either as the separate
   ``tests`` target, or also as part of the ``all`` target, depending on
   :cmake:`GMX_DEVELOPER_BUILD`).  All dependencies required for building the
   tests (Google Test and Google Mock frameworks, and tinyxml2) are
   included in :file:`src/external/`.
   Defaults to ``ON`` if :cmake:`BUILD_TESTING` is ``ON``.

.. cmake:: GMX_COMPACT_DOXYGEN

   If set ``ON``, Doxygen configuration is changed to avoid generating large
   dependency graphs, which makes it significantly faster to run Doxygen and
   reduces disk usage.  This is typically useful when developing the
   documentation to reduce the build times.
   Defaults to ``OFF``.

.. cmake:: REGRESSIONTEST_DOWNLOAD

   If set ``ON``, CMake will download the regression tests and extract them to
   a local directory.  :cmake:`REGRESSIONTEST_PATH` is set to the extracted
   tests.  Note that this happens during the configure phase, not during the
   build.
   After the download is done, the variable is automatically reset to ``OFF``
   again to avoid repeated downloads.  Can be set to ``ON`` to download again.
   Defaults to ``OFF``.

.. cmake:: REGRESSIONTEST_PATH

   Path to extracted regression test suite matching the source tree (the
   directory containing :file:`gmxtest.pl`)
   If set, CTest tests are generated to run the regression tests.
   Defaults to empty.

.. cmake:: SOURCE_MD5SUM

   Sets the MD5 sum of the release tarball when generating the HTML
   documentation.  It gets inserted into the download section of the HTML
   pages.

External libraries
------------------

.. todo::

   List external libraries used (either from src/external/, or from the
   system), whether they are required or optional, what functionality they
   provide for Gromacs, and how to control their use.

Special targets
---------------

In addition to the default ``all`` target, the generated build system has
several custom targets that are intended to be explicitly built to perform
various tasks (some of these may also run automatically).  There are various
other targets as well used internally by these, but those are typically not
intended to be invoked directly.

check
   Builds all the binaries needed by the tests and runs the tests.  If some
   types of tests are not available, shows a note to the user.
   This is the main target intended for normal users to run the tests.
   See :doc:`testutils`.
check-source
   Runs a custom Python checker script to check for various source-level
   issues.  Uses Doxygen XML documentation as well as rudimentary parsing of
   some parts of the source files.
   This target is used as part of the CI.
   All CMake code is currently in :file:`docs/doxygen/`.
   See :doc:`gmxtree`.
completion
   Runs the compiled :file:`gmx` executable to generate shell command-line
   completion definitions.  This target is only added if
   :cmake:`GMX_BUILD_HELP` is not ``OFF``, and it is run automatically as part
   of the default ``all`` target.  See :cmake:`GMX_BUILD_HELP`.
   All CMake code is in :file:`src/programs/`.
dep-graphs*
   Builds include dependency graphs for the source files using :command:`dot`
   from graphviz.
   All CMake code is in :file:`docs/doxygen/`.
   See :doc:`gmxtree`.
doxygen-*
   Targets that run Doxygen to generate the documentation.
   The ``doxygen-all`` target runs as part of the ``webpage`` target, which in
   turn runs as part of the CI.
   All CMake code is in :file:`docs/doxygen/`.
   See :doc:`doxygen`.
gmxapi-cppdocs
    Builds API documentation for gmxapi. Useful to authors of client software.
    Documentation is generated in :file:`docs/api-user` in the build directory.
gmxapi-cppdocs-dev
    Extract documentation for gmxapi and GROMACS developers to
    :file:`docs/api-dev`.
install-guide
   Runs Sphinx to generate a plain-text INSTALL file for the source package.
   The files is generated at :file:`docs/install-guide/text/`, from where it
   gets put at the root of the source package by CPack.
   All CMake code is in :file:`docs/`.
man
   Runs Sphinx to generate man pages for the programs.
   Internally, also runs the compiled :file:`gmx` executable to generate the
   input files for Sphinx.
   All CMake code is in :file:`docs/`.
   See :cmake:`GMX_BUILD_HELP` for information on when the man pages are
   installed.
manual
   Runs LaTeX to generate the reference PDF manual.
   All CMake code is in :file:`docs/manual/`.
   See :cmake:`GMX_BUILD_MANUAL`.
package_source
   Standard target created by CPack that builds a source package.
   This target is used to generate the released source packages.
test
   Standard target created by CTest that runs all the registered tests.
   Note that this does not build the test binaries, only runs them, so you need
   to first ensure that they are up-to-date.
   See :doc:`testutils`.
tests
   Builds all the binaries needed by the tests (but not ``gmx``).
   See :doc:`testutils`.
webpage
   Collection target that runs the other documentation targets to generate the
   full set of HTML (and linked) documentaion.
   This target is used as part of the CI.
   All CMake code is in :file:`docs/`.
webpage-sphinx
   Runs Sphinx to generate most content for the HTML documentation (the set of
   web pages this developer guide is also part of).
   Internally, also runs the compiled :file:`gmx` executable to generate some
   input files for Sphinx.
   All CMake code is in :file:`docs/`.

Passing information to source code
----------------------------------

The build system uses a few different mechanisms to influence the compilation:

* On the highest level, some CMake options select what files will be compiled.
* Some options are passed on the compiler command line using ``-D`` or
  equivalent, such that they are available in every compilation unit.  This
  should be used with care to keep the compiler command lines manageable.
  You can find the current set of such defines with ::

    git grep add_definitions

* A few header files are generated using CMake ``configure_file()`` and
  included in the desired source files.  These files must exist for the
  compilation to pass.  Only a few files use an ``#ifdef HAVE_CONFIG_H`` to
  protect against inclusion in case the define is not set; this is used in
  files that may get compiled outside the main build system.

  :file:`buildinfo.h`
    Contains various strings about the build environment, used mainly for
    outputting version information to log files and when requested.
  :file:`config.h`
    Contains defines for conditional compilation within source files.
  :file:`gmxpre-config.h`
    Included by :file:`gmxpre.h` as the first thing in every source file.
    Should only contain defines that are required before any other header for
    correct operation.  For example, defines that affect the behavior of system
    headers fall in this category.  See Doxygen documentation for
    :file:`gmxpre.h`.

  The above files are available through the INTERFACE_INCLUDE_DIR of
  the ``common`` CMake target. I.e. to ``#include "config.h"``, be sure to
  ``target_link_libraries(mymodule PRIVATE common)``

  Additionally, the following file is generated by the build system:

  :file:`baseversion-gen.cpp`
    Provides definitions for declarations in :file:`baseversion_gen.h` for
    version info output.  The contents are generated either from Git version
    info, or from static version info if not building from a git repository.
Development-time tools
======================

Several tools have their own individual pages and are listed below.

.. toctree::
   :maxdepth: 2

   doxygen
   change-management
   infrastructure
   releng/index
   gmxtree
   code-formatting
   testutils
   physical_validation

.. todo:: :issue:`3032`

   Consider what is the most reasonable structure; currently, this list
   here does not make much sense in the overall organization and creates a
   confusing TOC for the developer guide.

.. todo:: :issue:`3267`

   Add details for most of the tools, either in the form of links to wiki,
   or to a separate page that explains more details.

Change management
-----------------

|Gromacs| change management uses git and `GitLab`_ for code uploading and testing as well as issues tracking.
(For change submission guidelines, refer to :doc:`contribute`.)

git
  |Gromacs| uses `git <https://git-scm.com/>`__ as the version control system.
  Instructions for setting up git for |Gromacs|, as well as tips and tricks for
  its use, can be found in :doc:`change-management`.

  Other basic tutorial material for ``git`` can be found on the `web <https://git-scm.com/doc/ext>`__.

GitLab
  Bugs and issues, as well as some random features and discussions,
  are tracked, and all code changes go through a code review system at
  https://gitlab.com/gromacs/gromacs.

Build testing
  All changes pushed to GitLab are automatically compiled and otherwise
  checked on various platforms.
  :doc:`infrastructure` documents how builds are automated,
  providing information on how to replicate the builds (e.g., to
  diagnose issues).
  :doc:`releng/index` provides more information on the technical implementation
  of the builds.

.. _Git Tips & Tricks: http://www.gromacs.org/index.php?title=Developer_Zone/Git/Git_Tips_%26_Tricks

Build system
------------

.. todo:: details, ASAN, others?

CMake
  Main tool used in the build system.

packaging for distribution (CPack)

unit testing (CTest)
  |Gromacs| uses a unit testing framework based on Google C++ Testing
  Framework (gtest) and CTest.  All unit tests are automatically run in GitLab CI
  for each commit.
  Details can be found on a separate page on :doc:`testutils`.

clang static analyzer

coverage

regression tests

floating-point exceptions
  In debug builds, floating-point exceptions (FPEs) are generated whenever one of the
  following operations is encountered: division by zero, floating-point overflow,
  invalid operation (e.g., taking sqrt of a negative number).
  Such checks are *not* performed in the following configurations:

  - release build,
  - any build by GCC 7.x or Clang with optimizations,
  - build with SYCL support.

  In these configurations, FPEs can be enabled by adding ``-fpexcept`` flag to ``gmx``
  invocation. However, FPEs are not supported on Windows and non-x86 Apple hardware.
  See ``api/legacy/include/gromacs/math/utilities.h`` for more details.

.. _dev-formatting-tools:

Code formatting and style
-------------------------

The tools and scripts listed below are used to automatically check/apply
formatting that follows |Gromacs| style guidelines described on a separate page:
:doc:`style`.

clang-format
  We use clang-format to enforce a consistent coding style, with the
  settings recorded in ``.clang-format`` in the main tree.
  See :ref:`gmx-clang-format` for details.

clang-tidy
  The source code linter clang-tidy is used to enforce common restrictions to the
  code, with the checks collected under ``.clang-tidy`` at the top of the main tree.
  See :ref:`gmx-clang-tidy` for details.

``admin/copyright.py``
  This Python script adds and formats copyright headers in source files.
  ``copyright.sh`` (see below) uses the script to check/update copyright years on
  changed files automatically.

``admin/copyright.sh``
  This ``bash`` script runs the ``copyright.py`` python script to enforce
  correct copyright information in all files that have local changes
  and checks that they conform to the prescribed
  style.  Optionally, the script can also apply changes to make the files
  conform.
  This script is automatically run by the CI to ensure that all commits adhere
  to :doc:`formatting`.  If the copyright job does not succeed, it
  means that this script has something to complain.
  See :doc:`code-formatting` for details.

``admin/clang-format.sh``
  This script enforces coding style using clang-format.
  This script is automatically run by our CI to ensure that all commits adhere
  to :doc:`formatting`.

``admin/clang-tidy.sh``
  The clang-tidy code correctness restrictions are enforced by this script.
  The script is also used by the CI to verify the code, in addition to nightly
  compilations using clang-tidy on the whole tree.

``admin/git-pre-commit``
  This sample git pre-commit hook can be used if one wants to apply
  ``clang-tidy.sh``, ``copyright.sh`` and ``clang-format.sh`` automatically
  before every commit to check for formatting
  issues.  See :doc:`code-formatting` for details.

``docs/doxygen/includesorter.py``
  This Python script sorts and reformats #include directives according to
  the guidelines at :doc:`includestyle`.  Details are documented on a
  separate page (with the whole suite of Python scripts used for source code
  checks): :ref:`dev-include-sorter`.

include directive checker
  In its present form, the above include sorter script cannot be conveniently
  applied in the formatting script.  To check for issues, it is instead integrated into
  a ``check-source`` build target.  When this target is built, it also checks for
  include formatting issues.  Internally, it uses the sorter script.  This check
  is run in the CI as part of the Documentation job.
  Details for the checking mechanism are on a separate page (common for several
  checkers): :doc:`gmxtree`.

``admin/reformat_all.sh``
  This ``bash`` script runs clang-format/``copyright.py``/include sorter
  on all relevant files in the source tree (or in a particular directory).
  The script can also produce the list of files where these scripts are applied,
  for use with other scripts.  See :doc:`code-formatting` for details.

git attributes
  git attributes (specified in ``.gitattributes`` files) are used to annotate
  which files are subject to automatic formatting checks (and for automatic
  reformatting by the above scripts).  See ``man gitattributes`` for an overview of
  the mechanism.  We use the ``filter`` attribute to specify the type of automatic
  checking/formatting to apply.  Custom attributes are used for specifying some
  build system dependencies for easier processing in CMake.

Understanding Jenkins builds
============================

This page documents what different Jenkins builds actually run at
http://jenkins.gromacs.org/ from the |Gromacs| source tree.
The purpose is two-fold:

* Provide information on how to interpret Jenkins failures and how to run the
  same tasks locally to diagnose issues (in most cases, referring to the
  special targets described in :doc:`build-system`).
* Provide information on what changes in the build system (or other parts of
  the repository) need special care to not break Jenkins builds.

.. todo:: Add a link to a wiki page about general Jenkins documentation, once
   there is more of that.

Pre-submit verification
-----------------------

The following builds are triggered for each patch set uploaded to Gerrit.

Compilation and tests
^^^^^^^^^^^^^^^^^^^^^

The main build compiles |Gromacs| with different configurations and runs the
tests.  The configurations used for Jenkins verification are specified in
:file:`admin/builds/pre-submit-matrix.txt`.

The exact build sequence can be found in :file:`admin/builds/gromacs.py`,
including the logic that translates the build options in the matrix file to
CMake options.

Documentation
^^^^^^^^^^^^^

This build builds various types of documentation:

* PDF reference manual using LaTeX
* Doxygen documentation extracted from the source code
* Set of HTML pages containing an installation guide, a user guide, and a
  developer guide, as well as links to the above.  This set of HTML pages can
  be browsed from Jenkins.
* Man pages
* INSTALL text file

The last three require building the :file:`gmx` binary and running it, so
compilation failures will also show in this build.
All log files that contain warnings are archived as artifacts in the build, and
presence of any warnings marks the build unstable.  Brief description of which
part failed is reported back to Gerrit.

Additionally, the build runs some source code checks that rely on the Doxygen
documentation.  See the description of the ``check-source`` target in
:doc:`gmxtree`.

:doc:`doxygen` provides general guidelines for Doxygen usage, which can be
helpful in understanding and solving Doxygen warnings and some of the
``check-source`` issues.
:doc:`includestyle` provides guidelines for #include order and style, which is
another part of ``check-source`` checks.

The exact build sequence is in :file:`admin/builds/documentation.py`.
See that file for details of what it exactly builds and how.  Most changes in the
documentation build system will require changes in this script, but Jenkins
configuration should be more static.

clang static analysis
^^^^^^^^^^^^^^^^^^^^^

The file :file:`admin/builds/clang-analyzer.py` specifies the exact build
sequence and the CMake cache variables used for clang static analysis.  This
file also specifies the clang version used for the analysis, as well as the C++
compiler used (``clang-static-analyzer-<version>``).

To run the analysis outside Jenkins, you should run both ``cmake`` and ``make``
under ``scan-build`` command using the same CMake cache variables as in the
build script. When you do the initial CMake configuration with ``scan-build``,
it sets the C++ compiler to the analyzer. Note that using ``scan-build`` like
this will also analyze C code, but Jenkins ignores C code for analysis. This
can result in extra warnings, which can be suppressed by manually setting
CMAKE_C_COMPILER to a value other than Clang static analyzer.

uncrustify
^^^^^^^^^^

This build checks for source code formatting issues with uncrustify, and enforces
the copyright style.  See :doc:`formatting` for the guidelines that are enforced.

The exact build sequence is in :file:`admin/builds/uncrustify.py`, which
essentially just runs ::

  admin/uncrustify.sh check --rev=HEAD^

If the any changes are required, the build is marked unstable.
If the script completely fails (should be rare), the build fails.
A file with issues found by the script is archived as an artifact in the build,
and a summary is reported back to Gerrit (or the actual issues if there are
only a few).
See :doc:`code-formatting` for more details on code-formatting tools
and on scripts to run them.

clang-format
^^^^^^^^^^^^

This build checks and enforces code formatting, e.g.,  indentation.
Also, a second part of the build enforces the source code formatting.
As above, see :doc:`formatting` for the style guidelines.

The build runs according to :file:`admin/builds/clang-format.py`, resulting
in running ::

 admin/clang-format.sh check --rev=HEAD^

The build is marked unstable if the code formatting resulted in
any changes to the source code.

On-demand builds
----------------

These builds can be triggered on request for certain changes in Gerrit, or
manually from Jenkins.  See :ref:`releng-triggering-builds` for details on
how to trigger these.

Coverage
^^^^^^^^

This build compiles one configuration of |Gromacs| with instrumentation for
coverage, runs the tests, and produces a coverage report using gcovr.
The report can be browsed on Jenkins.

The exact build sequence is in :file:`admin/builds/coverage.py`, including
specification of the configuration tested.

Source tarball
^^^^^^^^^^^^^^

This build creates the source tarball for distribution.  Some of the content
that is put into the tarball is generated by executing the :command:`gmx`
binary, so this build also compiles the source code (with a minimal set of
options).

The build compiles the code and those targets that generate content necessary
for the tarball, followed by building the ``package_source`` target.
After that, it just generates a file that is used by other builds.

The exact build sequence is in :file:`admin/builds/source-package.py`.

Release workflow
^^^^^^^^^^^^^^^^

This build creates source and regressiontest tarballs, builds, installs, and
tests a few configuration using those, and builds documentation to be placed on
the documentation web site for a new release.  The set of configurations tested
is specified in :file:`admin/builds/release-matrix.txt`.

The exact build sequence is desribed in :ref:`releng-workflow-release`.
The build uses the source tarball build as a subbuild, and parts of the build
are executed using :file:`admin/builds/gromacs.py` and
:file:`admin/builds/documentation.py`.

:file:`admin/builds/get-version-info.py` is used for getting the version
information from the source tree as part of this workflow.

:file:`admin/builds/update-regtest-hash.py` has logic to update the
regressiontests tarball MD5 sum for the released tarball automatically.

Updating regressiontests data
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Sometimes we add new tests to the regressiontests repository. Also, as
the source code or data files change, it is sometimes necessary to
update regressiontests. This requires a particular CMake build type
and both a single and double-precision build of |Gromacs| to generate
all the data. Jenkins can automate much of the tedium here.

* Upload a regressiontests change that lacks the relevant reference
  data (either because you deleted the outdated data, or because the
  test is new). Jenkins will do the normal thing, which we ignore.
  There is now a Gerrit patch number for that change, symbolized here
  with ``MMMM``.

* Go to change ``MMMM`` on gerrit, select the patch set you want to
  update with new reference data (usually the latest one), and comment

    ``[JENKINS] Update``

  to update against the HEAD of the matching source-code branch, or

    ``[JENKINS] Cross-verify NNNN update``

  to update from builds of |Gromacs| from the latest version of
  Gerrit source-code patch ``NNNN``. You will need to do this when
  functionality changes in ``NNNN`` affect either the layout of
  the files in the reference data, or the results of the simulation,
  or the results of the subsequent analysis.

* Eventually, Jenkins will upload a new version of the regressiontests
  patch to Gerrit, which will contain the updated regressiontest data.
  That upload will again trigger Jenkins to do the normal pre-submit
  verify, which will now pass (but perhaps will only pass under
  cross-verify with patch ``NNNN``, as above).

* Later, if you later need to verify an updated version of source-code
  patch ``NNNN`` against the newly generated reference data, go to the
  source-code patch ``NNNN`` and comment

    ``[JENKINS] Cross-verify MMMM``
=============================
Automation and Infrastructure
=============================

Starting from 2020 release, automated testing and documentation builds are
performed by GitLab and GitLab Runner.

..  toctree::
    :maxdepth: 2

    jenkins
    gitlab-ci
    containers

.. _gmx-dev-known-issues:

Known issues relevant for developers
====================================

This is a non-exhaustive list of known issues that have been observed
and can be of interest for developers. These have not been solved
because they are either outside the scope of the GROMACS project
or are are simply too difficult or tedious to address ourselves.

Issues with GPU timer with OpenCL
---------------------------------

When building using OpenCL in ``Debug`` mode, it can happen that the GPU timer state gets
corrupted, leading to an assertion failure during the :ref:`mdrun <gmx mdrun>`.
This seems to be related to the load of other, unrelated tasks on the GPU.

GPU emulation does not work
---------------------------

The non-bonded GPU emulation mode does not work, at least for builds
with GPU support; then a GPU setup call is called.
Also dynamic pruning needs to be implemented for GPU emulation.

OpenCL on NVIDIA Volta and later broken
---------------------------------------

The OpenCL code produces incorrect results on Volta and Turing GPU architectures
from NVIDIA (CC 7.0 and 7.5). This is an issue that affects certain flavors of 
the nonboded kernels, most likely a result of miscompilation, and there is no
known workaround.

.. _gmx-contribute:

Contribute to |Gromacs|
=======================

|Gromacs| is a community-driven project, and we love getting
contributions from people. Contributions are welcome in many forms,
including improvements to documentation, patches to fix bugs, advice
on the forums, bug reports that let us reproduce the issue, and new
functionality.

If you are planning to contribute new functionality to |Gromacs|, we
strongly encourage you to get in contact with us first at an early
stage. New things can lead to exciting science, and we love
that. However, the subsequent code maintenance is time-consuming and
requires both "up front" and long-term commitment from you, and others
who might not share your particular scientific enthusiasm. Please read
this page first, and at least post on the `developer mailing list`_.
Sometimes we'll be able to save you a lot of time even at the
planning stage!

Much of the documentation is found alongside the source code in the
git repository. If you have changes to suggest there, those
contributions can be done using the same mechanism as the source code
contributions, and will be reviewed in similar ways.

Checklist
---------

Before you send us your code for review and inclusion into |Gromacs|,
please make sure that you have checked all the points on this list:

* *Usefulness*: Your code should have wide applicability within the scientific
  community. You are welcome to have smaller projects tracking our code,
  but we are not prepared to include and maintain code that will only have
  limited application. Evidence that people are already using your code or
  method is one good way to show that your code is useful.
  Scientific publications is another, but those publications should
  ideally come from several different research groups to show
  widespread adoption of the method.

* *Advance discussion*: Please communicate with the other developers,
  e.g.  on the `developer mailing list`_ mailing list, or
  `issue tracker`_ to let them know of the general
  nature of your plans. This will prevent duplicate or wasted
  effort. It is also a good idea to search those resources as well as
  the literature and WWW for other projects that may be relevant.

* *Verifiable*: If you propose a new method that passes the first check,
  please make sure that we can easily verify that it will be correct
  from a physics point of view. That must include documentation (both
  in the source code and as later additions to the user guide and/or
  reference manual) that a capable graduate student can read and
  understand well enough to use your method appropriately. The source
  code documentation will also help in maintenance and later
  development.

  This will be facilitated by the inclusions of unit tests for your code,
  as described in the section on how to write
  :ref:`new tests <gmx-make-new-tests>`.

  We also need some form of automated high-level test of your code,
  because people who do not understand its details need to be able to
  change the infrastructure that you depend on. |Gromacs| uses
  automated continuous-integration testing in :doc:`GitLab <gitlab-ci>`,
  and we need quick feedback about whether your
  code would be affected by a proposed change. This means the users of
  your feature can continue to do good science based upon trustworthy
  results generated by new versions of |Gromacs| released after you've
  contributed your feature.

* *Structured change process*: Reviewing code for correctness, quality
  and performance is a very time consuming process, which we are
  committed to because it is necessary in order to deliver software
  that is of high enough quality for reliable scientific
  results. However, human beings are busy and have short attention
  spans, and a proposed change affecting 10,000 lines of code is
  likely to generate little enthusiasm from other developers to review
  it. Your local git commit history is likely full of changes that are
  no longer present in the version you'd like to contribute, so we
  can't reasonably review that, either. It might be reasonable to
  break the process into manageable pieces, such as

    * the functionality to read the :doc:`mdp settings <../user-guide/mdp-options>` you might require and
      write a :ref:`tpr`,
    * the functionality for :ref:`mdrun <gmx mdrun>` to execute the simplest form of your
      feature,
    * further extensions and/or optimizations for your feature, and
    * functionality for an analysis tool to do useful things with the
      simulation output.

  Do get in touch with us, e.g. on the `developer mailing list`_, to
  exchange ideas here.

* *Timeliness*: We make an annual release of |Gromacs|, with a feature
  freeze (and git branch fork) on a fixed date, which is agreed more
  than six months in advance. We still need a month or more to do
  quality testing on that branch, after the fork and before the
  release, so there's a period when we cannot accept certain kinds of
  potentially risky changes. (The master branch will remain open for
  all kinds of changes, but it is likely that the focus of many of the
  core developers will be on the release process.) If you have a large
  change to propose, you need to

    * make a group of smaller changes,
    * negotiate in advance who will do the code review, and
    * have them available for review and improvement months(!) before
      that date. Even smaller changes are unlikely to be prioritized
      by others for review in the last month or so!

* *Coding style*: Please make sure that your code follows all the
  :doc:`coding style <style>` and :ref:`code formatting <code-formatting>`
  guidelines. This will make the code review go more smoothly on both sides. There are a number of
  tools already included with |Gromacs| to facilitate this, please have
  a look at :ref:`the respective part of the documentation <gmx-codeformatting>`.

* *Code documentation*: To ensure proper code documentation, please follow the
  instructions provided for the use of :doc:`doxygen <doxygen>`. In addition to this,
  the new functionality should be documented in the manual and possibly the user guide .

* In addition to coding style, please also follow the instructions given
  concerning the :ref:`commit style <code-commitstyle>`. This will also
  facilitate the code review process.

Preparing code for submission
-----------------------------

|Gromacs| uses ``git`` for :doc:`change-management`.
Instead of accepting "pull requests", |Gromacs| changes are submitted as individual
commits on the tip of the ``master`` branch hosted at `gitlab`_.
Preparing, submitting, and managing patches for a change requires a little bit
of set-up. Refer to :doc:`change-management` for information about

* accessing the |Gromacs| *git* repository
* structure of the repository
* source control without merge commits
* ``git`` usage that may be less common in other development work flows

Alternatives
------------

|Gromacs| has a public mirror available on GitHub at
https://github.com/gromacs/gromacs. You may wish to fork the project
under your own GitHub account and make your feature available that
way. This should help you to generate a following of users that would
help make the case for contributing the feature to the core. This
process would then still need to follow the remaining criteria
outlined here.  If you fork |Gromacs|, please set the CMake variable
``GMX_VERSION_STRING_OF_FORK`` to an appropriate descriptive string
- see cmake/gmxVersionInfo.cmake for details.

There is a project underway to develop a stable API for |Gromacs|,
which promises to be a great tool for permitting innovation while
ensuring ongoing quality of the core functionality. You might prefer
to plan to port your functionality to that API when it becomes
available. Do keep in touch on the `developer mailing list`_, so
you'll be the first to know when such functionality is ready for people to
explore!

Do you have more questions?
---------------------------

If you have questions regarding these points, or would like feedback on your ideas for contributing,
please feel free to contact us through the `developer mailing list`_.
If your code is of interest to the wider |Gromacs| community, we will be happy to assist you
in the process of including it in the main source tree.

.. _developer mailing list: https://maillist.sys.kth.se/mailman/listinfo/gromacs.org_gmx-developers

Removing functionality
----------------------

This is occasionally necessary, and there is :ref:`policy for such
occasions <deprecation-policy>`. For users, there are also lists of
:ref:`anticipated changes <anticipated-changes>` and :ref:`deprecated
functionality <deprecated-functionality>` as of |Gromacs| 2019.
.. This file is a placeholder that is used in case RELENG_PATH does not
   identify the location of the releng repository.

.. _releng-workflow-release:

Release engineering with GitLab
===============================

.. toctree::
   :hidden:

We are currently switching our build and testing system to use GitLab
and the integrated CI system, with information for the general system found
in the official `GitLab documentation <https://docs.gitlab.com/ee/ci/yaml/>`_.
The new configuration for the builds and tests can be found in the file
``.gitlab-ci.yml``, with the templates for configuring is found in the files in the
``admin/ci-templates/`` directory. This section is going to be extended
with individual build information as it comes available.

.. seealso:: :doc:`../infrastructure`

.. _releng-triggering-builds:

Triggering builds on GitLab
---------------------------

Pipelines can be triggered through the web interface, with different
pipelines available through the use of specified environment variables
in the trigger interface.

This section is going to be extended with information for how to trigger
different builds and their individual behaviour.
.. _reference manual: gmx-manual-parent-dir_

.. _gmx-membrane:

Running membrane simulations in |Gromacs|
-----------------------------------------

Running Membrane Simulations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Users frequently encounter problems when running simulations of lipid bilayers, especially
when a protein is involved. Users seeking to simulate membrane proteins may find this
`tutorial <http://www.mdtutorials.com/gmx/membrane_protein/index.html>`__ useful.

One protocol for the simulation of membrane proteins consists of the following steps:

#. Choose a force field for which you have parameters for the protein and lipids.
#. Insert the protein into the membrane. (For instance, use g_membed on a pre-formed bilayer or do a
   coarse-grained self-assembly simulation and then convert back to the atomistic representation.)
#. Solvate the system and add ions to neutralize excess charges and adjust the final ion concentration.
#. Energy minimize.
#. Let the membrane adjust to the protein. Typically run MD for ~5-10ns with restraints (1000 kJ/(mol nm2) on all protein heavy atoms.
#. Equilibrate without restraints.
#. Run production MD.

Adding waters with genbox
^^^^^^^^^^^^^^^^^^^^^^^^^

When generating waters around a pre-formed lipid membrane with :ref:`solvate <gmx solvate>` you may find that
water molecules get introduced into interstices in the membrane. There are several approaches to removing these, including

* a short MD run to get the hydrophobic effect to exclude these waters. In general this
  is sufficient to reach a water-free hydrophobic phase, as the molecules are usually
  expelled quickly and without disrupting the general structure. If your setup relies
  on a completely water-free hydrophobic phase at the start, you can try to follow
  the advice below:
* Set the ``-radius`` option in :ref:`gmx solvate` to change the water exclusion radius,
* copy ``vdwradii.dat`` from your ``$GMXLIB`` location to the working directory, and edit it to
  increase the radii of your lipid atoms (between 0.35 and 0.5nm is suggested for carbon) to
  prevent :ref:`solvate <gmx solvate>` from seeing interstices large enough for water insertion,
* editing your structure by hand to delete them (remembering to adjust your atom count for :ref:`gro` files
  and to account for any changes in the :ref:`topology <top>`), or
* use a script someone wrote to remove them.

External material
^^^^^^^^^^^^^^^^^

* `Membrane simulations slides <https://extras.csc.fi/chem/courses/gmx2007/Erik_Talks/membrane_simulations.pdf>`_ ,
  `membrane simulations video <http://tv.funet.fi/medar/showRecordingInfo.do?id=/metadata/fi/csc/courses/gromacs_workshop_2007/SpeedingupSimulationsAlgorithmsApplications.xml>`_ - (Erik Lindahl).
* |Gromacs| `tutorial for membrane protein simulations
  <http://www.mdtutorials.com/gmx/membrane_protein/index.html>`__ - designed to demonstrate what sorts of
  questions and problems occur when simulating proteins that are embedded within a lipid bilayer.
* `Combining the OPLS-AA forcefield with the Berger lipids <http://pomes.biochemistry.utoronto.ca/files/lipidCombinationRules.pdf>`_
  A detailed description of the motivation, method, and testing.

* Several Topologies for membrane proteins with different force fields gaff, charmm berger
  Shirley W. I. Siu, Robert Vacha, Pavel Jungwirth, Rainer A. Böckmann: Biomolecular simulations of membranes:
  `Physical properties from different force fields <https://doi.org/10.1063/1.2897760>`_.
* `Lipidbook <https://www.lipidbook.org/>`_ is a public repository for force-field parameters of lipids,
  detergents and other molecules that are used in
  the simulation of membranes and membrane proteins. It is described in: J. Domański, P. Stansfeld, M.S.P. Sansom,
  and O. Beckstein. J. Membrane Biol. 236 (2010), 255—258. `doi:10.1007/s00232-010-9296-8 <http://dx.doi.org/10.1007/s00232-010-9296-8>`_.


Parameterization of novel molecules
-----------------------------------

Most of your parametrization questions/problems can be resolved very simply, by remembering the following two rules:

* **You should not mix and match force fields**. :ref:`Force fields <gmx-force-field>` are (at best) designed to be self-consistent,
  and will not typically work well with other force fields. If you simulate part of your system with one
  force field and another part with a different force field which is not parametrized with the first force
  field in mind, your results will probably be questionable, and hopefully reviewers will be concerned.
  Pick a force field. Use that force field.
* If you need to develop new parameters, derive them in a manner consistent with how the rest of the force field
  was originally derived, which means that you will need to review the original literature. There isn't a single
  right way to derive force field parameters; what you need is to derive parameters that are consistent with the rest
  of the force field. How you go about doing this depends on which force field you want to use. For example, with
  AMBER force fields, deriving parameters for a non-standard amino acid would probably involve doing a number of
  different quantum calculations, while deriving GROMOS or OPLS parameters might involve more (a) fitting various fluid
  and liquid-state properties, and (b) adjusting parameters based on experience/chemical intuition/analogy. Some
  suggestions for automated approaches can be found :doc:`here <../user-guide/system-preparation>`.

It would be wise to have a reasonable amount of simulation experience with |Gromacs| before
attempting to parametrize new force fields, or new molecules for existing force fields.
These are expert topics, and not suitable for giving to (say) undergraduate students for
a research project, unless you like expensive quasi-random number generators. A very thorough knowledge
of :ref:`Chapter 5 <ff>` of the |Gromacs| Reference Manual will be required. If you haven't been warned
strongly enough, please read below about parametrization for exotic species.

Another bit of advice: Don't be more haphazard in obtaining parameters than you would be buying
fine jewellery. Just because the guy on the street offers to sell you a *diamond* necklace for $10
doesn't mean that's where you should buy one. Similarly, it isn't necessarily the best strategy
to just download parameters for your molecule of interest from the website of someone you've
never heard of, especially if they don't explain how they got the parameters.

Be forewarned about using `PRODRG <http://davapc1.bioch.dundee.ac.uk/cgi-bin/prodrg>`_ topologies
without verifying their contents: the artifacts of doing so are now `published <http://pubs.acs.org/doi/abs/10.1021/ci100335w>`_,
along with some tips for properly deriving parameters for the GROMOS family of force fields.

Exotic Species
^^^^^^^^^^^^^^

So, you want to simulate a protein/nucleic acid system, but it binds various exotic metal
ions (ruthenium?), or there is an iron-sulfur cluster essential for its functionality, or similar.
But, (unfortunately?) there aren't parameters available for these in the force field you want
to use. What should you do? You shoot an e-mail to the |Gromacs| users emailing list, and get referred to the FAQs.

If you really insist on simulating these in molecular dynamics, you'll need to obtain parameters
for them, either from the literature, or by doing your own parametrization. But before doing so,
it's probably important to stop and think, as sometimes there is a reason there may not already
be parameters for such atoms/clusters. In particular, here are a couple of basic questions you
can ask yourself to see whether it's reasonable to develop/obtain standard parameters for these and use them in molecular dynamics:

* Are quantum effects (i.e. charge transfer) likely to be important? (i.e., if you have a
  divalent metal ion in an enzyme active site and are interested in studying enzyme
  functionality, this is probably a huge issue).
* Are standard force field parametrization techniques used for my force field of choice
  likely to fail for an atom/cluster of this type? (i.e. because Hartree-Fock 6-31G* can't
  adequately describe transition metals, for example)

If the answer to either of these questions is "Yes", you may want to consider doing your
simulations with something other than classical molecular dynamics.

Even if the answer to both of these is "No", you probably want to consult with someone who
is an expert on the compounds you're interested in, before attempting your own parametrization.
Further, you probably want to try parametrizing something more straightforward before you embark on one of these.


Potential of Mean Force
-----------------------

The potential of mean force (PMF) is defined as the potential that gives an average force over all the
configurations of a given system.  There are several ways to calculate the PMF in |Gromacs|, probably
the most common of which is to make use of the pull code. The steps for obtaining a PMF using umbrella
sampling, which allows for sampling of statistically-improbable states, are:

* Generate a series of configurations along a reaction coordinate (from a steered MD simulation,
  a normal MD simulation, or from some arbitrarily-created configurations)
* Use umbrella sampling to restrain these configurations within sampling windows.
* Use :ref:`gmx wham` to make use of the WHAM algorithm to reconstruct a PMF curve.

A more detailed tutorial is linked `here for umbrella
sampling <http://www.mdtutorials.com/gmx/umbrella/index.html>`__.


Single-Point Energy
-------------------

Computing the energy of a single configuration is an operation that is sometimes useful. The best
way to do this with |Gromacs| is with the :ref:`mdrun <gmx mdrun>` ``-rerun`` mechanism, which
applies the model physics in the :ref:`tpr` to the configuration in the trajectory or coordinate file supplied to mdrun.

::

    mdrun -s input.tpr -rerun configuration.pdb

Note that the configuration supplied must match the topology you used when generating the :ref:`tpr`
file with :ref:`grompp <gmx grompp>`. The configuration you supplied to :ref:`grompp <gmx grompp>`
is irrelevant, except perhaps for atom names. You can also use this feature with energy groups
(see the `Reference manual`_), or with a trajectory of multiple configurations (and in this case,
by default :ref:`mdrun <gmx mdrun>` will do neighbour searching for each configuration, because
it can make no assumptions about the inputs being similar).

A zero-step energy minimization does a step before reporting the energy, and a zero-step MD run
has (avoidable) complications related to catering to possible restarts in the presence of
constraints, so neither of those procedures are recommended.


Carbon Nanotube
---------------

Robert Johnson's Tips
^^^^^^^^^^^^^^^^^^^^^

Taken from Robert Johnson's posts on the gmx-users mailing list.

* Be absolutely sure that the "terminal" carbon atoms are sharing a bond in the topology file.
* Use ``periodic_molecules = yes`` in your :ref:`mdp` file for input in :ref:`gmx grompp`.
* Even if the topology is correct, crumpling may occur if you place the nanotube in a box of wrong
  dimension, so use `VMD`_ to visualize the nanotube and its periodic images and make sure that the
  space between images is correct. If the spacing is too small or too big, there will be a large amount
  of stress induced in the tube which will lead to crumpling or stretching.
* Don't apply pressure coupling along the axis of the nanotube. In fact, for debugging purposes,
  it might be better to turn off pressure coupling altogether until you figure out if anything
  is going wrong, and if so, what.
* When using :ref:`x2top <gmx x2top>` with a specific force field, things are assumed about the
  connectivity of the molecule. The terminal carbon atoms of your nanotube will only be bonded to,
  at most, 2 other carbons, if periodic, or one if non-periodic and capped with hydrogens.
* You can generate an "infinite" nanotube with the ``-pbc`` option to :ref:`x2top <gmx x2top>`.
  Here, :ref:`x2top <gmx x2top>` will recognize that the terminal C atoms actually share a
  chemical bond. Thus, when you use :ref:`grompp <gmx grompp>` you won't get an error
  about a single bonded C.

 
Andrea Minoia's tutorial
^^^^^^^^^^^^^^^^^^^^^^^^

Modeling Carbon Nanotubes with |Gromacs| (also archived
as http://chembytes.wikidot.com/grocnt) contains
everything to set up simple simulations of a CNT using OPLS-AA
parameters. Structures of simple CNTs can
be easily generated e.g. by `buildCstruct`_ (Python script that also adds
terminal hydrogens) or `TubeGen Online`_ (just copy and paste the
PDB output into a file and name it cnt.pdb).

To make it work with modern |Gromacs| you'll probably want to do the following:

* make a directory cnt_oplsaa.ff
* In this directory, create the following files, using the data from the tutorial page:

  * forcefield.itp from the file in section :ref:`itp`
  * atomnames2types.n2t from the file in section :ref:`n2t`
  * aminoacids.rtp from the file in section :ref:`rtp`

* generate a topology with the custom forcefield (the cnt_oplsaa.ff directory must be in the same directory as where the :ref:`gmx x2top`
  command is run or it must be found on the GMXLIB path), ``-noparam`` instructs :ref:`gmx x2top` to not use
  bond/angle/dihedral force constants from the command line (-kb, -ka, -kd) but rely on the force field files;
  however, this necessitates the next step (fixing the dihedral functions)

::

    gmx x2top -f cnt.gro -o cnt.top -ff cnt_oplsaa -name CNT -noparam

The function type for the dihedrals is set to '1' by :ref:`gmx x2top` but the force field file specifies type '3'.
Therefore, replace func type  '1' with '3' in the ``[ dihedrals ]`` section of the topology file. A quick way
is to use sed (but you might have to adapt this to your operating system; also manually look at the top file
and check that you only changed the dihedral func types):

::

    sed -i~ '/\[ dihedrals \]/,/\[ system \]/s/1 *$/3/' cnt.top

Once you have the topology you can set up your system. For instance, a simple in-vacuo simulation (using your
favourite parameters in em.\ :ref:`mdp` and md.\ :ref:`mdp`):

Put into a slightly bigger box:

::

    gmx editconf -f cnt.gro -o boxed.gro -bt dodecahedron -d 1

Energy minimise in vacuuo:

::

    gmx grompp -f em.mdp -c boxed.gro -p cnt.top -o em.tpr
    gmx mdrun -v -deffnm em

MD in vacuuo:

::

    gmx grompp -f md.mdp -c em.gro -p cnt.top -o md.tpr
    gmx mdrun -v -deffnm md

Look at trajectory:

::

    gmx trjconv -f md.xtc -s md.tpr -o md_centered.xtc -pbc mol -center
    gmx trjconv -s md.tpr -f md_centered.xtc -o md_fit.xtc -fit rot+trans
    vmd em.gro md_fit.xtc

.. _buildCstruct: http://chembytes.wikidot.com/buildcstruct
.. _TubeGen Online: http://turin.nss.udel.edu/research/tubegenonline.html


*******************
Short How-To guides
*******************

.. highlight:: bash

A number of short guides are presented here to help users getting started with simulations.
Useful third-party tutorials provided by Justin Lemkul are found here http://www.mdtutorials.com/.

.. toctree::
   :maxdepth: 2

   beginners
   topology
   special
   visualize
.. _reference manual: gmx-manual-parent-dir_

.. _gmx-beginners:

Beginners
---------

For those just starting out with |Gromacs| and / or :ref:`Molecular Dynamics Simulations <gmx-md>` it can be very daunting.
It is highly recommended that the various and extensive documentation that has been made available for |Gromacs|
is read first, plus papers published in the area of interest.

Resources
^^^^^^^^^

* |Gromacs| :doc:`/reference-manual/index/` - very detailed document that can also act as a very good introduction for :ref:`MD <gmx-md>` in general.
* :doc:`Flow Chart </user-guide/flow>`- simple flow chart of a typical |Gromacs| MD run of a protein in a box of water.
* Molecular dynamics simulations and GROMACS introduction
  (`slides <https://extras.csc.fi/chem/courses/gmx2007/Berk_talks/forcef.pdf>`_,
  `video <http://tv.funet.fi/medar/showRecordingInfo.do?id=/metadata/fi/csc/courses/gromacs_workshop_2007/IntroductiontoMolecularSimulationandGromacs_1.xml>`_)
  - force fields, integrators, control of temperature and pressure (Berk Hess).

.. _gmx_add_residue:


Adding a Residue to a Force Field
---------------------------------

Adding a new residue
^^^^^^^^^^^^^^^^^^^^

If you have the need to introduce a new residue into an existing force field so that you can
use :ref:`pdb2gmx <gmx pdb2gmx>`, or modify an existing one, there are several files you will
need to modify. You must consult the :doc:`/reference-manual/index/` for description of the required format. Follow these steps:

#. Add the residue to the :ref:`rtp` file for your chosen force field. You might be able to copy
   an existing residue, rename it and modify it suitably, or you may need to use an external
   topology generation tool and adapt the results to the :ref:`rtp` format.
#. If you need hydrogens to be able to be added to your residue, create an entry in the relevant :ref:`hdb` file.
#. If you are introducing new atom types, add them to the ``atomtypes.atp`` and ``ffnonbonded.itp`` files.
#. If you require any new bonded types, add them to ``ffbonded.itp``.
#. Add your residue to ``residuetypes.dat`` with the appropriate specification (Protein, DNA, Ion, etc).
#. If the residue involves special connectivity to other residues, update ``specbond.dat``.

Note that if all you are doing is simulating some weird ligand in water, or some weird ligand
with a normal protein, then the above is more work than generating a standalone :ref:`itp`
file containing a ``[moleculetype]`` (for example, by modifying the :ref:`top` produced by some
parameterization server), and inserting an ``#include`` of that :ref:`itp` file into a :ref:`top`
generated for the system without that weird ligand.

Modifying a force field
^^^^^^^^^^^^^^^^^^^^^^^

Modifying a force field is best done by making a full copy of the installed forcefield directory and
``residuetypes.dat`` into your local working directory::

    cp -r $GMXLIB/residuetypes.dat $GMXLIB/amber99sb.ff .

Then, modify those local copies as above. :ref:`pdb2gmx <gmx pdb2gmx>` will then find both the original
and modified version and you can choose the modified version interactively from the list, or if
you use the :ref:`pdb2gmx <gmx pdb2gmx>` ``-ff`` option the local version will override the system version.

.. _gmx-solvate-water:

Water solvation
---------------

When using :ref:`solvate <gmx solvate>` to generate a box of solvent, you
need to supply a pre-equilibrated box of a suitable solvent for :ref:`solvate <gmx solvate>`
to stack around your solute(s), and then to truncate to give the simulation volume you desire. When
using any 3-point model (e.g. ``SPC``, ``SPC/E`` or ``TIP3P``) you should specify ``-cs spc216.gro``
which will take this file from ``the gromacs/share/top`` directory. Other water models (e.g.
``TIP4P`` and ``TIP5P``) are available as well. Check the contents of the ``/share/top`` subdirectory
of your GROMACS installation. After solvation, you should then be sure to equilibrate for at
least 5-10ps at the desired temperature. You will need to select the right water model in your
:ref:`top` file, either with the ``-water`` flag to :ref:`pdb2gmx <gmx pdb2gmx>`, or by editing
your :ref:`top` file appropriately by hand.

For information about how to use solvents other than pure water, please see
:ref:`Non-Water Solvation <gmx-solvate-other>` or :ref:`Mixed Solvents <gmx-solvate-mix>`.

.. _gmx-solvate-other:

Non water solvent
-----------------

It is possible to use solvents other than water in |Gromacs|. The only requirements are that you
have a pre-equilibrated box of whatever solvent you need, and suitable parameters for this species
in a simulation.  One can then pass the solvent box to the -cs switch of :ref:`solvate <gmx solvate>` to accomplish solvation.

A series of about 150 different equilibrated liquids validated for use with |Gromacs|,
and for the OPLS/AA and GAFF force fields, can be found at `virtualchemistry <http://virtualchemistry.org/>`_.

Making a non-aqueous solvent box
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Choose a box density and box size. The size does not have to be that of your eventual simulation
box - a 1nm cube is probably fine. Generate a single molecule of the solvent. Work out how much
volume a single molecule would have in the box of your chosen density and size. Use :ref:`editconf <gmx editconf>`
to place a box of that size around your single molecule. Then use :ref:`editconf <gmx editconf>` to move the
molecule a little bit off center. Then use :ref:`genconf <gmx genconf>` ``-rot`` to replicate that box into a large
one of the right size and density. Then equilibrate thoroughly to remove the residual ordering of
the molecules, using NVT and periodic boundary conditions. Now you have a box you can pass to
:ref:`solvate <gmx solvate>` ``-cs``, which will replicate it to fit the size of the actual simulation box.


.. _gmx-solvate-mix:

Mixed solvent
-------------

A common question that new users have is how to create a system with mixed solvent (urea or
DMSO at a given concentration in water, for example). The simplest procedure for accomplishing
this task is as follows:

* Determine the number of co-solvent molecules necessary, given the box dimensions of your system.
* Generate a coordinate file of a single molecule of your co-solvent (i.e., ``urea.gro``).
* Use the ``-ci -nmol`` options of :ref:`gmx insert-molecules` to add the required number of co-solvent molecules to the box.
* Fill the remainder of the box with water (or whatever your other solvent is) using :ref:`gmx solvate` or :ref:`gmx insert-molecules`.
* Edit your :ref:`topology <top>` to ``#include`` the appropriate :ref:`itp` files, as well as make
  changes to the ``[ molecules ]`` directive to account for all the species in your system.


Making Disulfide Bonds
----------------------

The easiest way to do this is by using the mechanism implemented with the ``specbond.dat``
file and :ref:`pdb2gmx <gmx pdb2gmx>`. You may find :ref:`pdb2gmx <gmx pdb2gmx>` ``-ss yes``
is useful. The sulfur atoms will need to be in the same unit that :ref:`pdb2gmx <gmx pdb2gmx>`
is converting to a ``moleculetype``, so invoking :ref:`pdb2gmx <gmx pdb2gmx>` ``-chainsep``
correctly may be required. See :ref:`pdb2gmx <gmx pdb2gmx>` ``-h``. This requires that the
two sulfur atoms be within a distance + tolerance (usually 10%) in order to be recognised
as a disulfide. If your sulfur atoms are not this close, then either you can

* edit the contents of ``specbond.dat`` to allow the bond formation and do energy
  minimization very carefully to allow the bond to relax to a sensible length, or
* run a preliminary EM or MD with a distance restraint (and no disulfide bond)
  between these sulfur atoms with a large force constant so that they approach within
  the existing ``specbond.dat`` range to provide a suitable coordinate file for a
  second invocation of :ref:`pdb2gmx <gmx pdb2gmx>`.

Otherwise, editing your :ref:`top` file by hand is the only option.
.. _reference manual: gmx-manual-parent-dir_

.. _gmx-visualize:

Visualization Software
----------------------

Some programs that are useful for visualizing either a trajectory file and/or a coordinate file are:

* `VMD`_ - a molecular visualization program for displaying, animating, and analyzing
  large biomolecular systems using 3-D graphics and built-in scripting. Reads |Gromacs| trajectories.
* `PyMOL`_ - capable molecular viewer with support for animations, high-quality rendering, crystallography,
  and other common molecular graphics activities. Does not read |Gromacs| trajectories in default
  configuration, requiring conversion to PDB or similar format. When compiled with `VMD`_ plugins,
  :ref:`trr` & :ref:`xtc` files can be loaded.
* `Rasmol`_ - the derivative software `Protein Explorer`_ (below) might be a better alternative, but
  the Chime component requires windows. `Rasmol`_ works fine on Unix.
* `Protein Explorer`_ - a `RasMol`_\ -derivative, is the easiest-to-use and most powerful software
  for looking at macromolecular structure and its relation to function. It runs on Windows or Macintosh/PPC computers.
* `Chimera`_ - A full featured, Python-based visualization program with all sorts of features for
  use on any platform. The current version reads |Gromacs| trajectories.
* `Molscript`_ - This is a script-driven program form high-quality display of molecular 3D structures
  in both schematic and detailed representations. You can get an academic license for free from Avatar.

Also if appropriate libraries were found at configure-time, :ref:`gmx view` can useful.
 
Topology bonds vs Rendered bonds
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Remember that each of these visualization tools is only looking at the coordinate file you gave it
(except when you give :ref:`gmx view` a :ref:`tpr` file). Thus it's not using your topology which is
described in either your :ref:`top` file or your :ref:`tpr` file. Each of these programs makes their
own guesses about where the chemical bonds are for rendering purposes, so do not be surprised if the
heuristics do not always match your topology.

.. _Rasmol: http://www.umass.edu/microbio/rasmol/index2.htm
.. _Protein Explorer: http://www.umass.edu/microbio/rasmol/
.. _Chimera: http://www.rbvi.ucsf.edu/chimera/
.. _Molscript: https://github.com/pekrau/MolScript


Extracting Trajectory Information
---------------------------------

There are several techniques available for finding information in |Gromacs|
trajectory (:ref:`trr`, :ref:`xtc`, :ref:`tng`) files.

* use the |Gromacs| trajectory analysis utilities
* use :ref:`gmx traj` to write a :ref:`xvg` file and read that in an external program as above
* write your own C code using ``gromacs/share/template/template.cpp`` as a template
* use :ref:`gmx dump` and redirect the shell output to a file and read that in an external
  program like MATLAB, or Mathematica or other spreadsheet software.

External tools to perform trajectory analysis
---------------------------------------------

In recent years several external tools have matured sufficiently to analyse diverse sets
of trajectory data from several simulation packages. Below is a short list of tools (in an alphabetical order)
that are known to be able to analyse |Gromacs| trajectory data.

* `LOOS <http://loos.sourceforge.net/>`__
* `MDAnalysis <https://www.mdanalysis.org/>`__
* `MDTraj <http://mdtraj.org/latest/index.html>`__
* `Pteros <https://github.com/yesint/pteros/>`__


Plotting Data
-------------

The various |Gromacs| analysis utilities can generate :ref:`xvg` files. These are text files
that have been specifically formatted for direct use in Grace. You can, however, in
all |Gromacs| analysis programs turn off the Grace specific codes by running the programs
with the ``-xvg none`` option. This circumvents problems with tools like gnuplot and Excel (see below).

Note that Grace uses some embedded backslash codes to indicate superscripts, normal script, etc. in units. So "Area (nm\S2\N)" is nm squared. 

Software
^^^^^^^^

Some software packages that can be used to graph data in a :ref:`xvg` file:

* Grace - WYSIWYG 2D plotting tool for the X Window System and M\*\ tif. Grace runs on practically
  any version of Unix-like OS, provided that you can satisfy its library dependencies (Lesstif is a
  valid free alternative to Motif). It is also available for the other common operation systems.
* gnuplot - portable command-line driven interactive data and function plotting utility for UNIX,
  IBM OS/2, MS Windows, DOS, Macintosh, VMS, Atari and many other platforms. Remember to use::

    set datafile commentschars "#@&"

  to avoid gnuplot trying to interpret Grace-specific commands in the :ref:`xvg` file or use
  the ``-xvg none`` option when running the analysis program. For simple usage,::

    plot "file.xvg" using 1:2 with lines

  is a hack that will achieve the right result.
* MS Excel - change the file extension to .csv and open the file (when prompted, choose to ignore the
  first 20 or so rows and select fixed-width columns, if you are using German MS Excel version, you
  have to change decimal delimiter from "," to ".", or use your favourite \*nix tool.
* Sigma Plot A commercial tool for windows with some useful analysis tools in it.
* R - freely available language and environment for statistical computing and graphics which provides
  a wide variety of statistical and graphical techniques: linear and nonlinear modelling, statistical
  tests, time series analysis, classification, clustering, etc.
* SPSS A commercial tool (Statistical Product and Service Solutions), which can also plot and analyse data.


Micelle Clustering
------------------

This is necessary for the :ref:`gmx spatial` tool if you have a fully-formed single aggregate and
want to generate the spatial distribution function for that aggregate or for solvent around that aggregate.

Clustering to ensure that the micelle is not split across a :ref:`periodic boundary condition <gmx-pbc>`
border is an essential step prior to calculating properties such as the radius of gyration and the
radial distribution function. Without this step your results will be incorrect (a sign of this error
is unexplained huge fluctuations in the calculated value when the visualized trajectory looks fine).

Three steps are required:

* use :ref:`trjconv <gmx trjconv>` ``-pbc cluster`` to obtain a single frame that has all of the
  lipids in the unit cell. This must be the first frame of your trajectory. A similar frame
  from some previous timepoint will not work.
* use :ref:`grompp <gmx grompp>` to make a new :ref:`tpr` file based on the frame that was output from the step above.
* use :ref:`trjconv <gmx trjconv>` ``-pbc nojump`` to produce the desired trajectory using the newly produced :ref:`tpr` file.

More explicitly, the same steps are:

::

 gmx trjconv -f a.xtc -o a_cluster.gro -e 0.001 -pbc cluster
 gmx grompp -f a.mdp -c a_cluster.gro -o a_cluster.tpr
 gmx trjconv -f a.xtc -o a_cluster.xtc -s a_cluster.tpr -pbc nojump


.. Note that this must be a single rst file in order for Sphinx
   to build into into a single plain-text file to place in the
   installation tarball.

.. _install guide:

******************
Installation guide
******************

.. highlight:: bash

Introduction to building |Gromacs|
----------------------------------

These instructions pertain to building |Gromacs|
|version|. You might also want to check the `up-to-date installation instructions`_.

Quick and dirty installation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1. Get the latest version of your C and C++ compilers.
2. Check that you have CMake version |CMAKE_MINIMUM_REQUIRED_VERSION| or later.
3. Get and unpack the latest version of the |Gromacs| tarball.
4. Make a separate build directory and change to it.
5. Run ``cmake`` with the path to the source as an argument
6. Run ``make``, ``make check``, and ``make install``
7. Source ``GMXRC`` to get access to |Gromacs|

Or, as a sequence of commands to execute:

.. parsed-literal::

    tar xfz gromacs-|version|.tar.gz
    cd gromacs-|version|
    mkdir build
    cd build
    cmake .. -DGMX_BUILD_OWN_FFTW=ON -DREGRESSIONTEST_DOWNLOAD=ON
    make
    make check
    sudo make install
    source /usr/local/gromacs/bin/GMXRC

This will download and build first the prerequisite FFT library
followed by |Gromacs|. If you already have FFTW installed, you can
remove that argument to ``cmake``. Overall, this build of |Gromacs|
will be correct and reasonably fast on the machine upon which
``cmake`` ran. On another machine, it may not run, or may not run
fast. If you want to get the maximum value for your hardware with
|Gromacs|, you will have to read further. Sadly, the interactions of
hardware, libraries, and compilers are only going to continue to get
more complex.

Quick and dirty cluster installation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

On a cluster where users are expected to be running across multiple
nodes using MPI, make one installation similar to the above, and
another using ``-DGMX_MPI=on``.
The latter will install binaries and libraries named using
a default suffix of ``_mpi`` ie ``gmx_mpi``. Hence it is safe
and common practice to install this into the same location where
the non-MPI build is installed.

Typical installation
^^^^^^^^^^^^^^^^^^^^

As above, and with further details below, but you should consider
using the following `CMake options`_ with the
appropriate value instead of ``xxx`` :

* ``-DCMAKE_C_COMPILER=xxx`` equal to the name of the C99 `Compiler`_ you wish to use (or the environment variable ``CC``)
* ``-DCMAKE_CXX_COMPILER=xxx`` equal to the name of the C++17 `compiler`_ you wish to use (or the environment variable ``CXX``)
* ``-DGMX_MPI=on`` to build using `MPI support`_
* ``-DGMX_GPU=CUDA`` to build with NVIDIA CUDA support enabled.
* ``-DGMX_GPU=OpenCL`` to build with OpenCL_ support enabled.
* ``-DGMX_GPU=SYCL`` to build with SYCL_ support enabled (using `Intel oneAPI DPC++`_ by default).
* ``-DGMX_SYCL_HIPSYCL=on`` to build with SYCL_ support using hipSYCL_ (requires ``-DGMX_GPU=SYCL``).
* ``-DGMX_SIMD=xxx`` to specify the level of `SIMD support`_ of the node on which |Gromacs| will run
* ``-DGMX_DOUBLE=on`` to build |Gromacs| in double precision (slower, and not normally useful)
* ``-DCMAKE_PREFIX_PATH=xxx`` to add a non-standard location for CMake to `search for libraries, headers or programs`_
* ``-DCMAKE_INSTALL_PREFIX=xxx`` to install |Gromacs| to a `non-standard location`_ (default ``/usr/local/gromacs``)
* ``-DBUILD_SHARED_LIBS=off`` to turn off the building of shared libraries to help with `static linking`_
* ``-DGMX_FFT_LIBRARY=xxx`` to select whether to use ``fftw3``, ``mkl`` or ``fftpack`` libraries for `FFT support`_
* ``-DCMAKE_BUILD_TYPE=Debug`` to build |Gromacs| in debug mode

Building older versions
^^^^^^^^^^^^^^^^^^^^^^^

Installation instructions for old |Gromacs| versions can be found at
the |Gromacs| `documentation page
<http://manual.gromacs.org/documentation>`_.

Prerequisites
-------------

Platform
^^^^^^^^

|Gromacs| can be compiled for many operating systems and
architectures.  These include any distribution of Linux, Mac OS X or
Windows, and architectures including x86, AMD64/x86-64, several
PowerPC including POWER8, ARM v8, and SPARC VIII.

Compiler
^^^^^^^^

|Gromacs| can be compiled on any platform with ANSI C99 and C++17
compilers, and their respective standard C/C++ libraries. Good
performance on an OS and architecture requires choosing a good
compiler. We recommend gcc, because it is free, widely available and
frequently provides the best performance.

You should strive to use the most recent version of your
compiler. Since we require full C++17 support the minimum
compiler versions supported by the GROMACS team are

* GNU (gcc/libstdc++) 7
* LLVM (clang/libc++) 7
* Microsoft (MSVC) 2019

Other compilers may work (Cray, Pathscale, older clang) but do
not offer competitive performance. We recommend against PGI because
the performance with C++ is very bad.

The Intel classic compiler (icc/icpc) is no longer supported in
|Gromacs|. Use Intel's newer clang-based compiler from oneAPI, or
gcc.

The xlc compiler is not supported and version 16.1 does not compile on
POWER architectures for |Gromacs|\ -\ |version|. We recommend to use
the gcc compiler instead, as it is being extensively tested.

You may also need the most recent version of other compiler toolchain
components beside the compiler itself (e.g. assembler or linker);
these are often shipped by your OS distribution's binutils package.

C++17 support requires adequate support in both the compiler and the
C++ library. The gcc and MSVC compilers include their own standard
libraries and require no further configuration. If your vendor's
compiler also manages the standard library library via compiler flags,
these will be honored. For configuration of other compilers, read on.

On Linux, the clang compilers use the libstdc++ which
comes with gcc as the default C++ library. For |Gromacs|, we require
the compiler to support libstc++ version 7.1 or higher. To select a
particular libstdc++ library, provide the path to g++ with
``-DGMX_GPLUSPLUS_PATH=/path/to/g++``.

To build with clang and llvm's libcxx standard library, use
``-DCMAKE_CXX_FLAGS=-stdlib=libc++``.

If you are running on Mac OS X, the best option is gcc. The Apple
clang compiler provided by MacPorts will work, but does not support
OpenMP, so will probably not provide best performance.

For all non-x86 platforms, your best option is typically to use gcc or
the vendor's default or recommended compiler, and check for
specialized information below.

For updated versions of gcc to add to your Linux OS, see

* Ubuntu: `Ubuntu toolchain ppa page`_
* RHEL/CentOS: `EPEL page`_ or the RedHat Developer Toolset

Compiling with parallelization options
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For maximum performance you will need to examine how you will use
|Gromacs| and what hardware you plan to run on. Often OpenMP_
parallelism is an advantage for |Gromacs|, but support for this is
generally built into your compiler and detected automatically.

.. _gmx-gpu-support:

GPU support
~~~~~~~~~~~

|Gromacs| has excellent support for NVIDIA GPUs supported via CUDA.
On Linux, NVIDIA CUDA_ toolkit with minimum version |REQUIRED_CUDA_VERSION|
is required, and the latest version is strongly encouraged. NVIDIA GPUs with at
least NVIDIA compute capability |REQUIRED_CUDA_COMPUTE_CAPABILITY| are
required. You are strongly recommended to
get the latest CUDA version and driver that supports your hardware, but
beware of possible performance regressions in newer CUDA versions on
older hardware.
While some CUDA compilers (nvcc) might not
officially support recent versions of gcc as the back-end compiler, we
still recommend that you at least use a gcc version recent enough to
get the best SIMD support for your CPU, since |Gromacs| always runs some
code on the CPU. It is most reliable to use the same C++ compiler
version for |Gromacs| code as used as the host compiler for nvcc.

To make it possible to use other accelerators, |Gromacs| also includes
OpenCL_ support. The minimum OpenCL version required is
|REQUIRED_OPENCL_MIN_VERSION| and only 64-bit implementations are supported.
The current OpenCL implementation is recommended for
use with GCN-based AMD GPUs, and on Linux we recommend the ROCm runtime.
Intel integrated GPUs are supported with the Neo drivers.
OpenCL is also supported with NVIDIA GPUs, but using
the latest NVIDIA driver (which includes the NVIDIA OpenCL runtime) is
recommended. Also note that there are performance limitations (inherent
to the NVIDIA OpenCL runtime).
It is not possible to support both Intel and other vendors' GPUs with OpenCL.
A 64-bit implementation of OpenCL is required and therefore OpenCL is only
supported on 64-bit platforms.

Since |Gromacs| 2021, the support for SYCL_ is added.
The current SYCL implementation can be compiled either with `Intel oneAPI DPC++`_
compiler for Intel GPUs, or with hipSYCL_ compiler and ROCm runtime for
AMD GFX9 and CDNA GPUs. Using other devices supported by these compilers is
possible, but not recommended.

It is not possible to configure several GPU backends in the same build
of |Gromacs|.


.. _mpi-support:

MPI support
~~~~~~~~~~~

|Gromacs| can run in parallel on multiple cores of a single
workstation using its built-in thread-MPI. No user action is required
in order to enable this.

If you wish to run in parallel on multiple machines across a network,
you will need to have an MPI library installed that supports the MPI
2.0 standard. That's true for any MPI library version released since
about 2009, but the |Gromacs| team recommends the latest version (for
best performance) of either your vendor's library, OpenMPI_ or MPICH_.

To compile with MPI set your compiler to the normal (non-MPI) compiler
and add ``-DGMX_MPI=on`` to the cmake options. It is possible to set
the compiler to the MPI compiler wrapper but it is neither necessary
nor recommended.

GPU-aware MPI support
~~~~~~~~~~~~~~~~~~~~~~

In simulations using multiple GPUs, an MPI implementation with GPU support
allows communication to be performed directly between the
distinct GPU memory spaces without staging through CPU memory, often
resulting in higher bandwidth and lower latency communication. The only
current support for this in |Gromacs| is with a CUDA build targeting
Nvidia GPUs using "CUDA-aware" MPI libraries.  For
more details, see `Introduction to CUDA-aware MPI
<https://developer.nvidia.com/blog/introduction-cuda-aware-mpi/>`_.

To use CUDA-aware MPI for direct GPU communication we recommend
using the latest OpenMPI version (>=4.1.0) with the latest UCX version
(>=1.10), since most GROMACS internal testing on CUDA-aware support has 
been performed using these versions. OpenMPI with CUDA-aware support can 
be built following the procedure in `these OpenMPI build instructions
<https://www.open-mpi.org/faq/?category=buildcuda>`_.

With ``GMX_MPI=ON``, |Gromacs| attempts to automatically detect CUDA support
in the underlying MPI library at compile time, and enables direct GPU 
communication when this is detected.  However, there are some cases when
GROMACS may fail to detect existing CUDA-aware support, in which case
it can be manually enabled by setting environment variable ``GMX_FORCE_GPU_AWARE_MPI=1``
at runtime (although such cases still lack substantial
testing, so we urge the user to carefully check correctness of results
against those using default build options, and report any issues).

CMake
^^^^^

|Gromacs| builds with the CMake build system, requiring at least
version |CMAKE_MINIMUM_REQUIRED_VERSION|. You can check whether
CMake is installed, and what version it is, with ``cmake
--version``. If you need to install CMake, then first check whether
your platform's package management system provides a suitable version,
or visit the `CMake installation page`_ for pre-compiled binaries,
source code and installation instructions. The |Gromacs| team
recommends you install the most recent version of CMake you can.

.. _FFT support:

Fast Fourier Transform library
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Many simulations in |Gromacs| make extensive use of fast Fourier
transforms, and a software library to perform these is always
required. We recommend FFTW_ (version 3 or higher only) or Intel
MKL_. The choice of library can be set with ``cmake
-DGMX_FFT_LIBRARY=<name>``, where ``<name>`` is one of ``fftw3``,
``mkl``, or ``fftpack``. FFTPACK is bundled with |Gromacs| as a
fallback, and is acceptable if simulation performance is not a
priority. When choosing MKL, |Gromacs| will also use MKL for BLAS and
LAPACK (see `linear algebra libraries`_). Generally, there is no
advantage in using MKL with |Gromacs|, and FFTW is often faster.
With PME GPU offload support using CUDA, a GPU-based FFT library
is required. The CUDA-based GPU FFT library cuFFT is part of the
CUDA toolkit (required for all CUDA builds) and therefore no additional
software component is needed when building with CUDA GPU acceleration.

Using FFTW
~~~~~~~~~~

FFTW_ is likely to be available for your platform via its package
management system, but there can be compatibility and significant
performance issues associated with these packages. In particular,
|Gromacs| simulations are normally run in "mixed" floating-point
precision, which is suited for the use of single precision in
FFTW. The default FFTW package is normally in double
precision, and good compiler options to use for FFTW when linked to
|Gromacs| may not have been used. Accordingly, the |Gromacs| team
recommends either

* that you permit the |Gromacs| installation to download and
  build FFTW from source automatically for you (use
  ``cmake -DGMX_BUILD_OWN_FFTW=ON``), or
* that you build FFTW from the source code.

If you build FFTW from source yourself, get the most recent version
and follow the `FFTW installation guide`_. Choose the precision for
FFTW (i.e. single/float vs. double) to match whether you will later
use mixed or double precision for |Gromacs|. There is no need to
compile FFTW with threading or MPI support, but it does no harm. On
x86 hardware, compile with *both* ``--enable-sse2`` and
``--enable-avx`` for FFTW-3.3.4 and earlier. From FFTW-3.3.5, you
should also add ``--enable-avx2`` also. On Intel processors supporting
512-wide AVX, including KNL, add ``--enable-avx512`` also.
FFTW will create a fat library with codelets for all different instruction sets,
and pick the fastest supported one at runtime.
On ARM architectures with SIMD support and IBM Power8 and later, you
definitely want version 3.3.5 or later,
and to compile it with ``--enable-neon`` and ``--enable-vsx``, respectively, for
SIMD support. If you are using a Cray, there is a special modified
(commercial) version of FFTs using the FFTW interface which can be
slightly faster.

Using MKL
~~~~~~~~~

Use MKL bundled with Intel compilers by setting up the compiler
environment, e.g., through ``source /path/to/compilervars.sh intel64``
or similar before running CMake including setting
``-DGMX_FFT_LIBRARY=mkl``.

If you need to customize this further, use

::

    cmake -DGMX_FFT_LIBRARY=mkl \
          -DMKL_LIBRARIES="/full/path/to/libone.so;/full/path/to/libtwo.so" \
          -DMKL_INCLUDE_DIR="/full/path/to/mkl/include"

The full list and order(!) of libraries you require are found in Intel's MKL documentation for your system.

Using ARM Performance Libraries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The ARM Performance Libraries provides FFT transforms implementation for ARM
architectures.
Preliminary support is provided for ARMPL in |Gromacs| through its FFTW-compatible API.
Assuming that the ARM HPC toolchain environment including the ARMPL paths
are set up (e.g. through loading the appropriate modules like
``module load Module-Prefix/arm-hpc-compiler-X.Y/armpl/X.Y``) use the following cmake
options:

::

    cmake -DGMX_FFT_LIBRARY=fftw3 \
          -DFFTWF_LIBRARY="${ARMPL_DIR}/lib/libarmpl_lp64.so" \
          -DFFTWF_INCLUDE_DIR=${ARMPL_DIR}/include


Other optional build components
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

* Run-time detection of hardware capabilities can be improved by
  linking with hwloc. By default this is turned off since it might
  not be supported everywhere, but if you have hwloc installed it
  should work by just setting ``-DGMX_HWLOC=ON``
* Hardware-optimized BLAS and LAPACK libraries are useful
  for a few of the |Gromacs| utilities focused on normal modes and
  matrix manipulation, but they do not provide any benefits for normal
  simulations. Configuring these is discussed at
  `linear algebra libraries`_.
* The built-in |Gromacs| trajectory viewer ``gmx view`` requires X11 and
  Motif/Lesstif libraries and header files. You may prefer to use
  third-party software for visualization, such as VMD_ or PyMol_.
* An external TNG library for trajectory-file handling can be used
  by setting ``-DGMX_EXTERNAL_TNG=yes``, but TNG
  |GMX_TNG_MINIMUM_REQUIRED_VERSION| is bundled in the |Gromacs|
  source already.
* The lmfit library for Levenberg-Marquardt curve fitting is used in
  |Gromacs|. Only lmfit |GMX_LMFIT_REQUIRED_VERSION| is supported.  A
  reduced version of that library is bundled in the |Gromacs|
  distribution, and the default build uses it. That default may be
  explicitly enabled with ``-DGMX_USE_LMFIT=internal``. To use an
  external lmfit library, set ``-DGMX_USE_LMFIT=external``, and adjust
  ``CMAKE_PREFIX_PATH`` as needed.  lmfit support can be disabled with
  ``-DGMX_USE_LMFIT=none``.
* zlib is used by TNG for compressing some kinds of trajectory data
* Building the |Gromacs| documentation is optional, and requires
  ImageMagick, pdflatex, bibtex, doxygen, python 3.6, sphinx
  |EXPECTED_SPHINX_VERSION|, and pygments.
* The |Gromacs| utility programs often write data files in formats
  suitable for the Grace plotting tool, but it is straightforward to
  use these files in other plotting programs, too.
* Set ``-DGMX_PYTHON_PACKAGE=ON`` when configuring |Gromacs| with CMake to
  enable additional CMake targets for the gmxapi Python package and
  sample_restraint package from the main |Gromacs| CMake build. This supports
  additional testing and documentation generation.

Doing a build of |Gromacs|
--------------------------

This section will cover a general build of |Gromacs| with CMake_, but it
is not an exhaustive discussion of how to use CMake. There are many
resources available on the web, which we suggest you search for when
you encounter problems not covered here. The material below applies
specifically to builds on Unix-like systems, including Linux, and Mac
OS X. For other platforms, see the specialist instructions below.

.. _configure-cmake:

Configuring with CMake
^^^^^^^^^^^^^^^^^^^^^^

CMake will run many tests on your system and do its best to work out
how to build |Gromacs| for you. If your build machine is the same as
your target machine, then you can be sure that the defaults and
detection will be pretty good. However, if you want to control aspects
of the build, or you are compiling on a cluster head node for back-end
nodes with a different architecture, there are a few things you
should consider specifying.

The best way to use CMake to configure |Gromacs| is to do an
"out-of-source" build, by making another directory from which you will
run CMake. This can be outside the source directory, or a subdirectory
of it. It also means you can never corrupt your source code by trying
to build it! So, the only required argument on the CMake command line
is the name of the directory containing the ``CMakeLists.txt`` file of
the code you want to build. For example, download the source tarball
and use

.. parsed-literal::

    tar xfz gromacs-|version|.tgz
    cd gromacs-|version|
    mkdir build-gromacs
    cd build-gromacs
    cmake ..

You will see ``cmake`` report a sequence of results of tests and
detections done by the |Gromacs| build system. These are written to the
``cmake`` cache, kept in ``CMakeCache.txt``. You can edit this file by
hand, but this is not recommended because you could make a mistake.
You should not attempt to move or copy this file to do another build,
because file paths are hard-coded within it. If you mess things up,
just delete this file and start again with ``cmake``.

If there is a serious problem detected at this stage, then you will see
a fatal error and some suggestions for how to overcome it. If you are
not sure how to deal with that, please start by searching on the web
(most computer problems already have known solutions!) and then
consult the gmx-users mailing list. There are also informational
warnings that you might like to take on board or not. Piping the
output of ``cmake`` through ``less`` or ``tee`` can be
useful, too.

Once ``cmake`` returns, you can see all the settings that were chosen
and information about them by using e.g. the curses interface

::

    ccmake ..

You can actually use ``ccmake`` (available on most Unix platforms)
directly in the first step, but then
most of the status messages will merely blink in the lower part
of the terminal rather than be written to standard output. Most platforms
including Linux, Windows, and Mac OS X even have native graphical user interfaces for
``cmake``, and it can create project files for almost any build environment
you want (including Visual Studio or Xcode).
Check out `running CMake`_ for
general advice on what you are seeing and how to navigate and change
things. The settings you might normally want to change are already
presented. You may make changes, then re-configure (using ``c``), so that it
gets a chance to make changes that depend on yours and perform more
checking. It may take several configuration passes to reach the desired
configuration, in particular if you need to resolve errors.

When you have reached the desired configuration with ``ccmake``, the
build system can be generated by pressing ``g``.  This requires that the previous
configuration pass did not reveal any additional settings (if it did, you need
to configure once more with ``c``).  With ``cmake``, the build system is generated
after each pass that does not produce errors.

You cannot attempt to change compilers after the initial run of
``cmake``. If you need to change, clean up, and start again.

.. _non-standard location:

Where to install |Gromacs|
~~~~~~~~~~~~~~~~~~~~~~~~~~

|Gromacs| is installed in the directory to which
``CMAKE_INSTALL_PREFIX`` points. It may not be the source directory or
the build directory.  You require write permissions to this
directory. Thus, without super-user privileges,
``CMAKE_INSTALL_PREFIX`` will have to be within your home directory.
Even if you do have super-user privileges, you should use them only
for the installation phase, and never for configuring, building, or
running |Gromacs|!

.. _cmake options:

Using CMake command-line options
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Once you become comfortable with setting and changing options, you may
know in advance how you will configure |Gromacs|. If so, you can speed
things up by invoking ``cmake`` and passing the various options at once
on the command line. This can be done by setting cache variable at the
cmake invocation using ``-DOPTION=VALUE``. Note that some
environment variables are also taken into account, in particular
variables like ``CC`` and ``CXX``.

For example, the following command line

::

    cmake .. -DGMX_GPU=CUDA -DGMX_MPI=ON -DCMAKE_INSTALL_PREFIX=/home/marydoe/programs

can be used to build with CUDA GPUs, MPI and install in a custom
location. You can even save that in a shell script to make it even
easier next time. You can also do this kind of thing with ``ccmake``,
but you should avoid this, because the options set with ``-D`` will not
be able to be changed interactively in that run of ``ccmake``.

.. _gmx-simd-support:

SIMD support
~~~~~~~~~~~~

|Gromacs| has extensive support for detecting and using the SIMD
capabilities of many modern HPC CPU architectures. If you are building
|Gromacs| on the same hardware you will run it on, then you don't need
to read more about this, unless you are getting configuration warnings
you do not understand. By default, the |Gromacs| build system will
detect the SIMD instruction set supported by the CPU architecture (on
which the configuring is done), and thus pick the best
available SIMD parallelization supported by |Gromacs|. The build system
will also check that the compiler and linker used also support the
selected SIMD instruction set and issue a fatal error if they
do not.

Valid values are listed below, and the applicable value with the
largest number in the list is generally the one you should choose.
In most cases, choosing an inappropriate higher number will lead
to compiling a binary that will not run. However, on a number of
processor architectures choosing the highest supported value can
lead to performance loss, e.g. on Intel Skylake-X/SP and AMD Zen.

1. ``None`` For use only on an architecture either lacking SIMD,
   or to which |Gromacs| has not yet been ported and none of the
   options below are applicable.
2. ``SSE2`` This SIMD instruction set was introduced in Intel
   processors in 2001, and AMD in 2003. Essentially all x86
   machines in existence have this, so it might be a good choice if
   you need to support dinosaur x86 computers too.
3. ``SSE4.1`` Present in all Intel core processors since 2007,
   but notably not in AMD Magny-Cours. Still, almost all recent
   processors support this, so this can also be considered a good
   baseline if you are content with slow simulations and prefer
   portability between reasonably modern processors.
4. ``AVX_128_FMA`` AMD Bulldozer, Piledriver (and later Family 15h) processors have this.
5. ``AVX_256`` Intel processors since Sandy Bridge (2011). While this
   code will work on the  AMD Bulldozer and Piledriver processors, it is significantly less
   efficient than the ``AVX_128_FMA`` choice above - do not be fooled
   to assume that 256 is better than 128 in this case.
6. ``AVX2_128`` AMD Zen/Zen2 and Hygon Dhyana microarchitecture processors;
   it will enable AVX2 with 3-way fused multiply-add instructions.
   While these microarchitectures do support 256-bit AVX2 instructions,
   hence ``AVX2_256`` is also supported, 128-bit will generally be faster,
   in particular when the non-bonded tasks run on the CPU -- hence
   the default ``AVX2_128``. With GPU offload however ``AVX2_256``
   can be faster on Zen processors.
7. ``AVX2_256`` Present on Intel Haswell (and later) processors (2013),
   and it will also enable Intel 3-way fused multiply-add instructions.
8. ``AVX_512`` Skylake-X desktop and Skylake-SP Xeon processors (2017);
   it will generally be fastest on the higher-end desktop and server
   processors with two 512-bit fused multiply-add units (e.g. Core i9
   and Xeon Gold). However, certain desktop and server models
   (e.g. Xeon Bronze and Silver) come with only one AVX512 FMA unit
   and therefore on these processors ``AVX2_256`` is faster
   (compile- and runtime checks try to inform about such cases).
   Additionally, with GPU accelerated runs ``AVX2_256`` can also be
   faster on high-end Skylake CPUs with both 512-bit FMA units enabled.
9. ``AVX_512_KNL`` Knights Landing Xeon Phi processors
10. ``IBM_VSX`` Power7, Power8, Power9 and later have this.
11. ``ARM_NEON_ASIMD`` 64-bit ARMv8 and later.
12. ``ARM_SVE`` 64-bit ARMv8 and later with the Scalable Vector Extensions (SVE).
    The SVE vector length is fixed at CMake configure time. The default vector
    length is automatically detected, and this can be changed via the
    ``GMX_SIMD_ARM_SVE_LENGTH`` CMake variable.
    Minimum required compiler versions are GNU >= 10, LLVM >=13, or ARM >= 21.1. 
    For maximum performance we strongly suggest the latest gcc compilers,
    or at least LLVM 14 (when released) or ARM 22.0 (when released). 
    Lower performance has been observed with LLVM 13 and Arm compiler 21.1.

The CMake configure system will check that the compiler you have
chosen can target the architecture you have chosen. mdrun will check
further at runtime, so if in doubt, choose the lowest number you
think might work, and see what mdrun says. The configure system also
works around many known issues in many versions of common HPC
compilers.

A further ``GMX_SIMD=Reference`` option exists, which is a special
SIMD-like implementation written in plain C that developers can use
when developing support in |Gromacs| for new SIMD architectures. It is
not designed for use in production simulations, but if you are using
an architecture with SIMD support to which |Gromacs| has not yet been
ported, you may wish to try this option instead of the default
``GMX_SIMD=None``, as it can often out-perform this when the
auto-vectorization in your compiler does a good job. And post on the
|Gromacs| mailing lists, because |Gromacs| can probably be ported for new
SIMD architectures in a few days.

CMake advanced options
~~~~~~~~~~~~~~~~~~~~~~

The options that are displayed in the default view of ``ccmake`` are
ones that we think a reasonable number of users might want to consider
changing. There are a lot more options available, which you can see by
toggling the advanced mode in ``ccmake`` on and off with ``t``. Even
there, most of the variables that you might want to change have a
``CMAKE_`` or ``GMX_`` prefix. There are also some options that will be
visible or not according to whether their preconditions are satisfied.

.. _search for libraries, headers or programs:

Helping CMake find the right libraries, headers, or programs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If libraries are installed in non-default locations their location can
be specified using the following variables:

* ``CMAKE_INCLUDE_PATH`` for header files
* ``CMAKE_LIBRARY_PATH`` for libraries
* ``CMAKE_PREFIX_PATH`` for header, libraries and binaries
  (e.g. ``/usr/local``).

The respective ``include``, ``lib``, or ``bin`` is
appended to the path. For each of these variables, a list of paths can
be specified (on Unix, separated with ":"). These can be set as
environment variables like:

::

    CMAKE_PREFIX_PATH=/opt/fftw:/opt/cuda cmake ..

(assuming ``bash`` shell). Alternatively, these variables are also
``cmake`` options, so they can be set like
``-DCMAKE_PREFIX_PATH=/opt/fftw:/opt/cuda``.

The ``CC`` and ``CXX`` environment variables are also useful
for indicating to ``cmake`` which compilers to use. Similarly,
``CFLAGS``/``CXXFLAGS`` can be used to pass compiler
options, but note that these will be appended to those set by
|Gromacs| for your build platform and build type. You can customize
some of this with advanced CMake options such as ``CMAKE_C_FLAGS``
and its relatives.

See also the page on `CMake environment variables`_.

.. _CUDA GPU acceleration:

CUDA GPU acceleration
~~~~~~~~~~~~~~~~~~~~~

If you have the CUDA_ Toolkit installed, you can use ``cmake`` with:

::

    cmake .. -DGMX_GPU=CUDA -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda

(or whichever path has your installation). In some cases, you might
need to specify manually which of your C++ compilers should be used,
e.g. with the advanced option ``CUDA_HOST_COMPILER``.

By default, code will be generated for the most common CUDA architectures.
However, to reduce build time and binary size we do not generate code for
every single possible architecture, which in rare cases (say, Tegra systems)
can result in the default build not being able to use some GPUs.
If this happens, or if you want to remove some architectures to reduce
binary size and build time, you can alter the target CUDA architectures.
This can be done either with the ``GMX_CUDA_TARGET_SM`` or
``GMX_CUDA_TARGET_COMPUTE`` CMake variables, which take a semicolon delimited
string with the two digit suffixes of CUDA (virtual) architectures names, for
instance "35;50;51;52;53;60". For details, see the "Options for steering GPU
code generation" section of the nvcc man / help or Chapter 6. of the nvcc
manual.

The GPU acceleration has been tested on AMD64/x86-64 platforms with
Linux, Mac OS X and Windows operating systems, but Linux is the
best-tested and supported of these. Linux running on POWER 8 and ARM v8
CPUs also works well.

Experimental support is available for compiling CUDA code, both for host and
device, using clang (version 6.0 or later).
A CUDA toolkit is still required but it is used only for GPU device code
generation and to link against the CUDA runtime library.
The clang CUDA support simplifies compilation and provides benefits for development
(e.g. allows the use code sanitizers in CUDA host-code).
Additionally, using clang for both CPU and GPU compilation can be beneficial
to avoid compatibility issues between the GNU toolchain and the CUDA toolkit.
clang for CUDA can be triggered using the ``GMX_CLANG_CUDA=ON`` CMake option.
Target architectures can be selected with  ``GMX_CUDA_TARGET_SM``,
virtual architecture code is always embedded for all requested architectures
(hence GMX_CUDA_TARGET_COMPUTE is ignored).
Note that this is mainly a developer-oriented feature and it is not recommended
for production use as the performance can be significantly lower than that
of code compiled with nvcc (and it has also received less testing).
However, note that since clang 5.0 the performance gap is only moderate
(at the time of writing, about 20% slower GPU kernels), so this version
could be considered in non performance-critical use-cases.


OpenCL GPU acceleration
~~~~~~~~~~~~~~~~~~~~~~~

The primary targets of the |Gromacs| OpenCL support is accelerating
simulations on AMD and Intel hardware. For AMD, we target both
discrete GPUs and APUs (integrated CPU+GPU chips), and for Intel we
target the integrated GPUs found on modern workstation and mobile
hardware. The |Gromacs| OpenCL on NVIDIA GPUs works, but performance
and other limitations make it less practical (for details see the user guide).

To build |Gromacs| with OpenCL_ support enabled, two components are
required: the OpenCL_ headers and the wrapper library that acts
as a client driver loader (so-called ICD loader).
The additional, runtime-only dependency is the vendor-specific GPU driver
for the device targeted. This also contains the OpenCL_ compiler.
As the GPU compute kernels are compiled  on-demand at run time,
this vendor-specific compiler and driver is not needed for building |Gromacs|.
The former, compile-time dependencies are standard components,
hence stock versions can be obtained from most Linux distribution
repositories (e.g. ``opencl-headers`` and ``ocl-icd-libopencl1`` on Debian/Ubuntu).
Only the compatibility with the required OpenCL_ version |REQUIRED_OPENCL_MIN_VERSION|
needs to be ensured.
Alternatively, the headers and library can also be obtained from vendor SDKs,
which must be installed in a path found in ``CMAKE_PREFIX_PATH`` (or via the environment
variables ``AMDAPPSDKROOT`` or ``CUDA_PATH``).

To trigger an OpenCL_ build the following CMake flags must be set

::

    cmake .. -DGMX_GPU=OpenCL

To build with support for Intel integrated GPUs, it is required
to add ``-DGMX_GPU_NB_CLUSTER_SIZE=4`` to the cmake command line,
so that the GPU kernels match the characteristics of the hardware.
The `Neo driver <https://github.com/intel/compute-runtime/releases>`_
is recommended.

On Mac OS, an AMD GPU can be used only with OS version 10.10.4 and
higher; earlier OS versions are known to run incorrectly.

By default, any clFFT library on the system will be used with
|Gromacs|, but if none is found then the code will fall back on a
version bundled with |Gromacs|. To require |Gromacs| to link with an
external library, use

::

    cmake .. -DGMX_GPU=OpenCL -DclFFT_ROOT_DIR=/path/to/your/clFFT -DGMX_EXTERNAL_CLFFT=TRUE

SYCL GPU acceleration
~~~~~~~~~~~~~~~~~~~~~

SYCL_ is a modern portable heterogeneous acceleration API, with multiple
implementations targeting different hardware platforms (similar to OpenCL_).

Currently, supported platforms in |Gromacs| are:

* Intel GPUs using `Intel oneAPI DPC++`_ (both OpenCL and LevelZero backends), 
* AMD GPUs with hipSYCL_: only discrete GPUs with GFX9 (RX Vega 64, Pro VII, 
  Instinct MI25, Instinct MI50) and CDNA (Instinct MI100) architectures,
* NVIDIA GPUs (experimental) using either hipSYCL_ or open-source 
  `Intel LLVM <https://github.com/intel/llvm>`_.

Feature support is broader than that of the OpenCL, but not yet on par with CUDA.

The SYCL_ support in |Gromacs| is intended to eventually replace
OpenCL_ as an acceleration mechanism for AMD and Intel hardware.

Note: SYCL_ support in |Gromacs| is less mature than either OpenCL or CUDA.
Please, pay extra attention to simulation correctness when you are using it.

SYCL GPU acceleration for Intel GPUs
""""""""""""""""""""""""""""""""""""

You should install the recent `Intel oneAPI DPC++`_ compiler toolkit.
For |Gromacs| 2022, version 2021.4 is recommended.
Using open-source `Intel LLVM <https://github.com/intel/llvm>`_ is possible,
but not extensively tested. We also recommend installing the most recent
`Neo driver <https://github.com/intel/compute-runtime/releases>`_.

With the toolkit installed and added to the environment (usually by running
``source /opt/intel/oneapi/setvars.sh`` or using an appropriate
:command:`module load` on an HPC system), the following CMake flags
must be set:

::

   cmake .. -DCMAKE_C_COMPILER=icx -DCMAKE_CXX_COMPILER=icpx -DGMX_GPU=SYCL

SYCL GPU acceleration for AMD GPUs
""""""""""""""""""""""""""""""""""

Using the most recent hipSYCL_ ``develop`` branch and the most recent ROCm
release is recommended.

Additionally, we strongly recommend using the ROCm-bundled LLVM for building
both hipSYCL and |Gromacs|.

The following CMake command can be used **when configuring hipSYCL** to ensure
that the proper Clang is used (assuming ``ROCM_PATH``
is set correctly, e.g. to ``/opt/rocm`` in the case of default installation):

::

   cmake .. -DCMAKE_C_COMPILER=${ROCM_PATH}/llvm/bin/clang -DCMAKE_CXX_COMPILER=${ROCM_PATH}/llvm/bin/clang++ -DLLVM_DIR=${ROCM_PATH}/llvm/lib/cmake/llvm/

After compiling and installing hipSYCL, the following settings can be used for
building |Gromacs| itself (set ``HIPSYCL_TARGETS`` to the target hardware):

::

   cmake .. -DCMAKE_C_COMPILER=${ROCM_PATH}/llvm/bin/clang -DCMAKE_CXX_COMPILER=${ROCM_PATH}/llvm/bin/clang++ -DGMX_GPU=SYCL -DGMX_SYCL_HIPSYCL=ON -DHIPSYCL_TARGETS='hip:gfxXYZ'

SYCL GPU acceleration for NVIDIA GPUs
"""""""""""""""""""""""""""""""""""""

SYCL support for NVIDIA GPUs is highly experimental. For production, please use CUDA_
(`CUDA GPU acceleration`_). Note that FFT is not currently supported on NVIDIA devices 
when using SYCL, PME offload is only possible in mixed mode (``-pme gpu -pmefft cpu``).

NVIDIA GPUs can be used with either hipSYCL_ or the open-source
`Intel LLVM <https://github.com/intel/llvm>`_.

For hipSYCL, make sure that hipSYCL itself is compiled with CUDA support,
and supply proper devices via ``HIPSYCL_TARGETS`` (e.g., ``-DHIPSYCL_TARGETS=cuda:sm_75``).
When compiling for CUDA, we recommend using the mainline Clang, not the ROCm-bundled one.

For Intel LLVM, make sure it is compiled with CUDA and OpenMP support, then use
the following CMake invocation:

::

   cmake .. -DCMAKE_C_COMPILER=/path/to/intel/clang -DCMAKE_CXX_COMPILER=/path/to/intel/clang++ -DGMX_GPU=SYCL -DGMX_GPU_NB_CLUSTER_SIZE=8 -DSYCL_CXX_FLAGS_EXTRA=-fsycl-targets=nvptx64-nvidia-cuda


SYCL GPU compilation options
""""""""""""""""""""""""""""

The following flags can be passed to CMake in order to tune |Gromacs|:

``-DGMX_GPU_NB_CLUSTER_SIZE``
      changes the data layout of non-bonded kernels. Default values: 4 when
      compiling with `Intel oneAPI DPC++`_, 8 when compiling with hipSYCL_.
      Those are reasonable defaults for Intel and AMD devices, respectively.

``-DGMX_SYCL_USE_USM``
      switches between SYCL buffers (``OFF``) and USM (``ON``) for data management.
      Default: on (for performance reasons).

Static linking
~~~~~~~~~~~~~~

Dynamic linking of the |Gromacs| executables will lead to a
smaller disk footprint when installed, and so is the default on
platforms where we believe it has been tested repeatedly and found to work.
In general, this includes Linux, Windows, Mac OS X and BSD systems.
Static binaries take more space, but on some hardware and/or under
some conditions they are necessary, most commonly when you are running a parallel
simulation using MPI libraries (e.g. Cray).

* To link |Gromacs| binaries statically against the internal |Gromacs|
  libraries, set ``-DBUILD_SHARED_LIBS=OFF``.
* To link statically against external (non-system) libraries as well,
  set ``-DGMX_PREFER_STATIC_LIBS=ON``. Note, that in
  general ``cmake`` picks up whatever is available, so this option only
  instructs ``cmake`` to prefer static libraries when both static and
  shared are available. If no static version of an external library is
  available, even when the aforementioned option is ``ON``, the shared
  library will be used. Also note that the resulting binaries will
  still be dynamically linked against system libraries on platforms
  where that is the default. To use static system libraries,
  additional compiler/linker flags are necessary, e.g. ``-static-libgcc
  -static-libstdc++``.
* To attempt to link a fully static binary set
  ``-DGMX_BUILD_SHARED_EXE=OFF``. This will prevent CMake from explicitly
  setting any dynamic linking flags. This option also sets
  ``-DBUILD_SHARED_LIBS=OFF`` and ``-DGMX_PREFER_STATIC_LIBS=ON`` by
  default, but the above caveats apply. For compilers which don't
  default to static linking, the required flags have to be specified. On
  Linux, this is usually ``CFLAGS=-static CXXFLAGS=-static``.

gmxapi C++ API
~~~~~~~~~~~~~~

For dynamic linking builds and on non-Windows platforms, an extra library and
headers are installed by setting ``-DGMXAPI=ON`` (default).
Build targets ``gmxapi-cppdocs`` and ``gmxapi-cppdocs-dev`` produce documentation in
``docs/api-user`` and ``docs/api-dev``, respectively.
For more project information and use cases,
refer to the tracked :issue:`2585`,
associated GitHub `gmxapi <https://github.com/kassonlab/gmxapi>`_ projects,
or DOI `10.1093/bioinformatics/bty484 <https://doi.org/10.1093/bioinformatics/bty484>`_.

gmxapi is not yet tested on Windows or with static linking, but these use cases
are targeted for future versions.

Portability aspects
~~~~~~~~~~~~~~~~~~~

A |Gromacs| build will normally not be portable, not even across
hardware with the same base instruction set, like x86. Non-portable
hardware-specific optimizations are selected at configure-time, such
as the SIMD instruction set used in the compute kernels. This
selection will be done by the build system based on the capabilities
of the build host machine or otherwise specified to ``cmake`` during
configuration.

Often it is possible to ensure portability by choosing the least
common denominator of SIMD support, e.g. SSE2 for x86. In rare cases
of very old x86 machines, ensure that
you use ``cmake -DGMX_USE_RDTSCP=off`` if any of the target CPU
architectures does not support the ``RDTSCP`` instruction.  However, we
discourage attempts to use a single |Gromacs| installation when the
execution environment is heterogeneous, such as a mix of AVX and
earlier hardware, because this will lead to programs (especially
mdrun) that run slowly on the new hardware. Building two full
installations and locally managing how to call the correct one
(e.g. using a module system) is the recommended
approach. Alternatively, one can use different suffixes to install 
several versions of |Gromacs| in the same location. To achieve this,
one can first build a full installation with the
least-common-denominator SIMD instruction set, e.g. ``-DGMX_SIMD=SSE2``,
in order for simple commands like ``gmx grompp`` to work on all machines,
then build specialized ``gmx`` binaries for each architecture present in
the heterogeneous environment. By using custom binary and library
suffixes (with CMake variables ``-DGMX_BINARY_SUFFIX=xxx`` and
``-DGMX_LIBS_SUFFIX=xxx``), these can be installed to the same
location.

Linear algebra libraries
~~~~~~~~~~~~~~~~~~~~~~~~

As mentioned above, sometimes vendor BLAS and LAPACK libraries
can provide performance enhancements for |Gromacs| when doing
normal-mode analysis or covariance analysis. For simplicity, the text
below will refer only to BLAS, but the same options are available
for LAPACK. By default, CMake will search for BLAS, use it if it
is found, and otherwise fall back on a version of BLAS internal to
|Gromacs|. The ``cmake`` option ``-DGMX_EXTERNAL_BLAS=on`` will be set
accordingly. The internal versions are fine for normal use. If you
need to specify a non-standard path to search, use
``-DCMAKE_PREFIX_PATH=/path/to/search``. If you need to specify a
library with a non-standard name (e.g. ESSL on Power machines
or ARMPL on ARM machines), then
set ``-DGMX_BLAS_USER=/path/to/reach/lib/libwhatever.a``.

If you are using Intel MKL_ for FFT, then the BLAS and
LAPACK it provides are used automatically. This could be
over-ridden with ``GMX_BLAS_USER``, etc.

On Apple platforms where the Accelerate Framework is available, these
will be automatically used for BLAS and LAPACK. This could be
over-ridden with ``GMX_BLAS_USER``, etc.

.. _installing with MiMiC:

Building with MiMiC QM/MM support
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

MiMiC QM/MM interface integration will require linking against MiMiC
communication library, that establishes the communication channel
between |Gromacs| and CPMD. The MiMiC Communication library can be
downloaded `here <https://gitlab.com/MiMiC-projects/CommLib>`__.
Compile and install it. Check that the installation folder of the
MiMiC library is added to CMAKE_PREFIX_PATH if it is installed in
non-standard location. Building QM/MM-capable version requires
double-precision version of |Gromacs| compiled with MPI support:

* ``-DGMX_DOUBLE=ON -DGMX_MPI -DGMX_MIMIC=ON``

.. _installing with CP2K:

Building with CP2K QM/MM support
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

CP2K QM/MM interface integration will require linking against libcp2k
library, that incorporates CP2K functionality into |Gromacs|. 

1. Download, compile and install CP2K (version 8.1 or higher is required).
CP2K latest distribution can be downloaded `here <https://github.com/cp2k/cp2k/releases/>`_.
For CP2K specific instructions please `follow <https://github.com/cp2k/cp2k/blob/master/INSTALL.md>`_.
You can also check instructions on the `official CP2K web-page <https://www.cp2k.org/howto>`_.

2. Make :file:`libcp2k.a` library by executing the following command::
    make ARCH=<your arch file> VERSION=<your version like psmp> libcp2k

The library archive (*e.g.* :file:`libcp2k.a`) should appear in the :file:`{<cp2k dir>}/lib/{<arch>}/{<version>}/` directory.

3. Configure |Gromacs| with :command:`cmake`, adding the following flags.

Build should be static: ``-DBUILD_SHARED_LIBS=OFF -DGMXAPI=OFF -DGMX_INSTALL_NBLIB_API=OFF``

Double precision in general is better than single for QM/MM 
(however both options are viable): ``-DGMX_DOUBLE=ON``

FFT, BLAS and LAPACK libraries should be the same between CP2K and |Gromacs|.
Use the following flags to do so:

* ``-DGMX_FFT_LIBRARY=<your library like fftw3> -DFFTWF_LIBRARY=<path to library> -DFFTWF_INCLUDE_DIR=<path to directory with headers>``
* ``-DGMX_BLAS_USER=<path to your BLAS>`` 
* ``-DGMX_LAPACK_USER=<path to your LAPACK>``

4. Compilation of QM/MM interface is controled by the following flags.

``-DGMX_CP2K=ON``
    Activates QM/MM interface compilation
``-DCP2K_DIR="<path to cp2k>/lib/local/psmp``
    Directory with libcp2k.a library
``-DCP2K_LINKER_FLAGS="<combination of LDFLAGS and LIBS>"`` (optional for CP2K 9.1 or newer)
    Other libraries used by CP2K. Typically that should be combination 
    of LDFLAGS and LIBS from the ARCH file used for CP2K compilation.
    Sometimes ARCH file could have several lines defining LDFLAGS and LIBS
    or even split one line into several using "\\". In that case all of them
    should be concatenated into one long string without any extra slashes 
    or quotes. For CP2K versions 9.1 or newer, CP2K_LINKER_FLAGS is not required
    but still might be used in very specific situations.

.. _suffixes:

Changing the names of |Gromacs| binaries and libraries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

It is sometimes convenient to have different versions of the same
|Gromacs| programs installed. The most common use cases have been single
and double precision, and with and without MPI. This mechanism can
also be used to install side-by-side multiple versions of mdrun
optimized for different CPU architectures, as mentioned previously.

By default, |Gromacs| will suffix programs and libraries for such builds
with ``_d`` for double precision and/or ``_mpi`` for MPI (and nothing
otherwise). This can be controlled manually with ``GMX_DEFAULT_SUFFIX
(ON/OFF)``, ``GMX_BINARY_SUFFIX`` (takes a string) and ``GMX_LIBS_SUFFIX``
(also takes a string). For instance, to set a custom suffix for
programs and libraries, one might specify:

::

    cmake .. -DGMX_DEFAULT_SUFFIX=OFF -DGMX_BINARY_SUFFIX=_mod -DGMX_LIBS_SUFFIX=_mod

Thus the names of all programs and libraries will be appended with
``_mod``.

Changing installation tree structure
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

By default, a few different directories under ``CMAKE_INSTALL_PREFIX`` are used
when when |Gromacs| is installed. Some of these can be changed, which is mainly
useful for packaging |Gromacs| for various distributions. The directories are
listed below, with additional notes about some of them. Unless otherwise noted,
the directories can be renamed by editing the installation paths in the main
CMakeLists.txt.

``bin/``
    The standard location for executables and some scripts.
    Some of the scripts hardcode the absolute installation prefix, which needs
    to be changed if the scripts are relocated.
    The name of the directory can be changed using ``CMAKE_INSTALL_BINDIR`` CMake
    variable.
``include/gromacs/``
    The standard location for installed headers.
``lib/``
    The standard location for libraries. The default depends on the system, and
    is determined by CMake.
    The name of the directory can be changed using ``CMAKE_INSTALL_LIBDIR`` CMake
    variable.
``lib/pkgconfig/``
    Information about the installed ``libgromacs`` library for ``pkg-config`` is
    installed here.  The ``lib/`` part adapts to the installation location of the
    libraries.  The installed files contain the installation prefix as absolute
    paths.
``share/cmake/``
    CMake package configuration files are installed here.
``share/gromacs/``
    Various data files and some documentation go here. The first part can
    be changed using ``CMAKE_INSTALL_DATADIR``, and the second by using
    ``GMX_INSTALL_DATASUBDIR`` Using these CMake variables is the preferred
    way of changing the installation path for
    ``share/gromacs/top/``, since the path to this directory is built into
    ``libgromacs`` as well as some scripts, both as a relative and as an absolute
    path (the latter as a fallback if everything else fails).
``share/man/``
    Installed man pages go here.

Compiling and linking
^^^^^^^^^^^^^^^^^^^^^

Once you have configured with ``cmake``, you can build |Gromacs| with ``make``.
It is expected that this will always complete successfully, and
give few or no warnings. The CMake-time tests |Gromacs| makes on the settings
you choose are pretty extensive, but there are probably a few cases we
have not thought of yet. Search the web first for solutions to
problems, but if you need help, ask on gmx-users, being sure to
provide as much information as possible about what you did, the system
you are building on, and what went wrong. This may mean scrolling back
a long way through the output of ``make`` to find the first error
message!

If you have a multi-core or multi-CPU machine with ``N``
processors, then using

::

    make -j N

will generally speed things up by quite a bit. Other build generator systems
supported by ``cmake`` (e.g. ``ninja``) also work well.

.. _building just the mdrun binary:

Installing |Gromacs|
^^^^^^^^^^^^^^^^^^^^

Finally, ``make install`` will install |Gromacs| in the
directory given in ``CMAKE_INSTALL_PREFIX``. If this is a system
directory, then you will need permission to write there, and you
should use super-user privileges only for ``make install`` and
not the whole procedure.

.. _getting access to |Gromacs|:

Getting access to |Gromacs| after installation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

|Gromacs| installs the script ``GMXRC`` in the ``bin``
subdirectory of the installation directory
(e.g. ``/usr/local/gromacs/bin/GMXRC``), which you should source
from your shell:

::

    source /your/installation/prefix/here/bin/GMXRC

It will detect what kind of shell you are running and set up your
environment for using |Gromacs|. You may wish to arrange for your
login scripts to do this automatically; please search the web for
instructions on how to do this for your shell.

Many of the |Gromacs| programs rely on data installed in the
``share/gromacs`` subdirectory of the installation directory. By
default, the programs will use the environment variables set in the
``GMXRC`` script, and if this is not available they will try to guess the
path based on their own location.  This usually works well unless you
change the names of directories inside the install tree. If you still
need to do that, you might want to recompile with the new install
location properly set, or edit the ``GMXRC`` script.

|Gromacs| also installs a CMake cache file to help with building client software
(using the `-C option <https://cmake.org/cmake/help/latest/manual/cmake.1.html#options>`__
when configuring the client software with CMake.)
For an installation at ``/your/installation/prefix/here``,
hints files will be installed at
``/your/installation/prefix/share/cmake/gromacs${GMX_LIBS_SUFFIX}/gromacs-hints${GMX_LIBS_SUFFIX}.cmake``
where ``${GMX_LIBS_SUFFIX}`` is :ref:`as documented above <suffixes>`.

Testing |Gromacs| for correctness
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Since 2011, the |Gromacs| development uses an automated system where
every new code change is subject to regression testing on a number of
platforms and software combinations. While this improves
reliability quite a lot, not everything is tested, and since we
increasingly rely on cutting edge compiler features there is
non-negligible risk that the default compiler on your system could
have bugs. We have tried our best to test and refuse to use known bad
versions in ``cmake``, but we strongly recommend that you run through
the tests yourself. It only takes a few minutes, after which you can
trust your build.

The simplest way to run the checks is to build |Gromacs| with
``-DREGRESSIONTEST_DOWNLOAD``, and run ``make check``.
|Gromacs| will automatically download and run the tests for you.
Alternatively, you can download and unpack the |Gromacs|
regression test suite |gmx-regressiontests-package| tarball yourself
and use the advanced ``cmake`` option ``REGRESSIONTEST_PATH`` to
specify the path to the unpacked tarball, which will then be used for
testing. If the above does not work, then please read on.

The regression tests are also available from the download_ section.
Once you have downloaded them, unpack the tarball, source
``GMXRC`` as described above, and run ``./gmxtest.pl all``
inside the regression tests folder. You can find more options
(e.g. adding ``double`` when using double precision, or
``-only expanded`` to run just the tests whose names match
"expanded") if you just execute the script without options.

Hopefully, you will get a report that all tests have passed. If there
are individual failed tests it could be a sign of a compiler bug, or
that a tolerance is just a tiny bit too tight. Check the output files
the script directs you too, and try a different or newer compiler if
the errors appear to be real. If you cannot get it to pass the
regression tests, you might try dropping a line to the
`GROMACS users forum <https://gromacs.bioexcel.eu/c/gromacs-user-forum>`__,
but then you should include a detailed description of
your hardware, and the output of ``gmx mdrun -version`` (which contains
valuable diagnostic information in the header).

Non-standard suffix
~~~~~~~~~~~~~~~~~~~

If your ``gmx`` program has been suffixed in a non-standard way, then
the ``./gmxtest.pl -suffix`` option will let you specify that suffix to the
test machinery. You can use ``./gmxtest.pl -double`` to test the
double-precision version. You can use ``./gmxtest.pl -crosscompiling``
to stop the test harness attempting to check that the programs can
be run. You can use ``./gmxtest.pl -mpirun srun`` if your command to
run an MPI program is called ``srun``.

Running MPI-enabled tests
~~~~~~~~~~~~~~~~~~~~~~~~~

The ``make check`` target also runs integration-style tests that may run
with MPI if ``GMX_MPI=ON`` was set. To make these work with various possible
MPI libraries, you may need to
set the CMake variables ``MPIEXEC``, ``MPIEXEC_NUMPROC_FLAG``,
``MPIEXEC_PREFLAGS`` and ``MPIEXEC_POSTFLAGS`` so that
``mdrun-mpi-test_mpi`` would run on multiple ranks via the shell command

::

    ${MPIEXEC} ${MPIEXEC_NUMPROC_FLAG} ${NUMPROC} ${MPIEXEC_PREFLAGS} \
          mdrun-mpi-test_mpi ${MPIEXEC_POSTFLAGS} -otherflags

A typical example for SLURM is

::

     cmake .. -DGMX_MPI=on -DMPIEXEC=srun -DMPIEXEC_NUMPROC_FLAG=-n -DMPIEXEC_PREFLAGS= -DMPIEXEC_POSTFLAGS=


Testing |Gromacs| for performance
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We are still working on a set of benchmark systems for testing
the performance of |Gromacs|. Until that is ready, we recommend that
you try a few different parallelization options, and experiment with
tools such as ``gmx tune_pme``.

Having difficulty?
^^^^^^^^^^^^^^^^^^

You are not alone - this can be a complex task! If you encounter a
problem with installing |Gromacs|, then there are a number of
locations where you can find assistance. It is recommended that you
follow these steps to find the solution:

1. Read the installation instructions again, taking note that you
   have followed each and every step correctly.

2. Search the |Gromacs| webpage_ and users emailing list for information
   on the error. Adding
   ``site:https://mailman-1.sys.kth.se/pipermail/gromacs.org_gmx-users``
   to a Google search may help filter better results.

3. Search the internet using a search engine such as Google.

4. Post to the |Gromacs| users emailing list gmx-users for
   assistance. Be sure to give a full description of what you have
   done and why you think it did not work. Give details about the
   system on which you are installing.  Copy and paste your command
   line and as much of the output as you think might be relevant -
   certainly from the first indication of a problem. In particular,
   please try to include at least the header from the mdrun logfile,
   and preferably the entire file.  People who might volunteer to help
   you do not have time to ask you interactive detailed follow-up
   questions, so you will get an answer faster if you provide as much
   information as you think could possibly help. High quality bug
   reports tend to receive rapid high quality answers.

.. _gmx-special-build:

Special instructions for some platforms
---------------------------------------

Building on Windows
^^^^^^^^^^^^^^^^^^^

Building on Windows using native compilers is rather similar to
building on Unix, so please start by reading the above. Then, download
and unpack the |Gromacs| source archive. Make a folder in which to do
the out-of-source build of |Gromacs|. For example, make it within the
folder unpacked from the source archive, and call it ``build-gromacs``.

For CMake, you can either use the graphical user interface provided on
Windows, or you can use a command line shell with instructions similar
to the UNIX ones above. If you open a shell from within your IDE
(e.g. Microsoft Visual Studio), it will configure the environment for
you, but you might need to tweak this in order to get either a 32-bit
or 64-bit build environment. The latter provides the fastest
executable. If you use a normal Windows command shell, then you will
need to either set up the environment to find your compilers and
libraries yourself, or run the ``vcvarsall.bat`` batch script provided
by MSVC (just like sourcing a bash script under Unix).

With the graphical user interface, you will be asked about what
compilers to use at the initial configuration stage, and if you use
the command line they can be set in a similar way as under UNIX.

Unfortunately ``-DGMX_BUILD_OWN_FFTW=ON`` (see `Using FFTW`_) does not
work on Windows, because there is no supported way to build FFTW on
Windows. You can either build FFTW some other way (e.g. MinGW), or
use the built-in fftpack (which may be slow), or `using MKL`_.

For the build, you can either load the generated solutions file into
e.g. Visual Studio, or use the command line with ``cmake --build`` so
the right tools get used.

Building on Cray
^^^^^^^^^^^^^^^^

|Gromacs| builds mostly out of the box on modern Cray machines, but
you may need to specify the use of static binaries with
``-DGMX_BUILD_SHARED_EXE=off``, and you may need to set the F77
environmental variable to ``ftn`` when compiling FFTW.
The ARM ThunderX2 Cray XC50 machines differ only in that the recommended
compiler is the ARM HPC Compiler (``armclang``).


Building on Solaris
^^^^^^^^^^^^^^^^^^^

The built-in |Gromacs| processor detection does not work on Solaris,
so it is strongly recommended that you build |Gromacs| with
``-DGMX_HWLOC=on`` and ensure that the ``CMAKE_PREFIX_PATH`` includes
the path where the hwloc headers and libraries can be found. At least
version 1.11.8 of hwloc is recommended.

Oracle Developer Studio is not a currently supported compiler (and
does not currently compile |Gromacs| correctly, perhaps because the
thread-MPI atomics are incorrectly implemented in |Gromacs|).

Intel Xeon Phi
^^^^^^^^^^^^^^

Xeon Phi processors, hosted or self-hosted, are supported.
The Knights Landing-based Xeon Phi processors behave like standard x86 nodes,
but support a special SIMD instruction set. When cross-compiling for such nodes,
use the ``AVX_512_KNL`` SIMD flavor.
Knights Landing processors support so-called "clustering modes" which
allow reconfiguring the memory subsystem for lower latency. |Gromacs| can
benefit from the quadrant or SNC clustering modes.
Care needs to be taken to correctly pin threads. In particular, threads of
an MPI rank should not cross cluster and NUMA boundaries.
In addition to the main DRAM memory, Knights Landing has a high-bandwidth
stacked memory called MCDRAM. Using it offers performance benefits if
it is ensured that ``mdrun`` runs entirely from this memory; to do so
it is recommended that MCDRAM is configured in "Flat mode" and ``mdrun`` is
bound to the appropriate NUMA node (use e.g. ``numactl --membind 1`` with
quadrant clustering mode).


Tested platforms
----------------

While it is our best belief that |Gromacs| will build and run pretty
much everywhere, it is important that we tell you where we really know
it works because we have tested it.
Every commit in our git source code repository
is currently tested with a range of configuration options on x86 with
gcc versions including 7 and 11,
clang versions including 7 and 13,
CUDA versions 11.0 and 11.4.2,
and
a version of oneAPI containing Intel's clang-based compiler.
For this testing, we use Ubuntu 20.04 operating system.
Other compiler, library, and OS versions are tested less frequently.
For details, you can have a look at the
`continuous integration server used by GROMACS <https://gitlab.com/gromacs/gromacs/>`_,
which uses GitLab runner on a local k8s x86 cluster with NVIDIA,
AMD, and Intel GPU support.

We test irregularly on ARM v8, Fujitsu A64FX, Cray, Power9,
and other environments, and
with other compilers and compiler versions, too.

Support
-------

Please refer to the `manual <http://manual.gromacs.org/>`_ for documentation,
downloads, and release notes for any GROMACS release.

Visit the `user forums <http://forums.gromacs.org/>`_ for discussions and advice.

Report bugs at https://gitlab.com/gromacs/gromacs/-/issues
.. _gmxapi:

=====================
gmxapi Python package
=====================

This documentation is part of the `GROMACS manual <http://manual.gromacs.org/current/>`_
and describes the *gmxapi* Python package.
:py:mod:`gmxapi` allows molecular simulation and analysis work to
be staged and run from Python.

From version 0.1, the latest official documentation is at http://manual.gromacs.org/current/gmxapi/.
Other releases can also be found at `GitHub <https://www.github.com/kassonlab/gmxapi>`_.

..  toctree::
    :maxdepth: 2
    :caption: Documentation sections

    userguide/userguide.rst

.. seealso::

    gmxapi publications

    Irrgang, M. E., Davis, C., & Kasson, P. M.
    gmxapi: A GROMACS-native Python interface for molecular dynamics with ensemble and plugin support.
    *PLOS Comput Biol* 2022.
    DOI: `10.1371/journal.pcbi.1009835 <https://dx.plos.org/10.1371/journal.pcbi.1009835>`_

    Irrgang, M. E., Hays, J. M., & Kasson, P. M.
    gmxapi: a high-level interface for advanced control and extension of molecular dynamics simulations.
    *Bioinformatics* 2018.
    DOI: `10.1093/bioinformatics/bty484 <https://doi.org/10.1093/bioinformatics/bty484>`_

Indices and tables
==================

* :ref:`genindex`
* :ref:`search`
==========
Change Log
==========

.. Record changes in API or behavior.

.. rubric:: 0.1
===============
Developer Guide
===============

.. toctree::
    :maxdepth: 2

    projectstructure
    extending
    contributing
    datamodel
    executionmodel
============
Contributing
============

Documentation for maintaining and contributing to this project.

gmxapi 0.1 Design notes
=======================

Open questions
==============

``output`` node
---------------

Placeholders for type and shape
-------------------------------

Python style preferences
------------------------

Subgraph
~~~~~~~~
=======================
Implementation overview
=======================

stub
===============
Execution model
===============

stub


=================
gmxapi data model
=================

stub

Basic data types, containers
============================

Handles and Futures
===================

Proxies and managed resources
=============================

Operations, factories, and data flow: declaration, definition, and initialization
=================================================================================

..  todo:: Reference https://gitlab.com/gromacs/gromacs/-/issues/2993

Expressing inputs and outputs
-----------------------------

Notes on data compatibility
===========================

Avoid dependencies
------------------

The same C++ symbol can have different bindings in each extension module, so
don't rely on C++ typing through bindings. Need schema for PyCapsules.

Adding gmxapi compatible Python bindings should not require dependency on gmxapi
Python package. Compatibility through interfaces instead of inheritance.

=========
Extending
=========

Documentation for building code that uses or collaborates with GROMACS through gmxapi.

stub

.. discuss
    * concepts
    * protocols
    * pure Python
    * C++
==============================
gmxapi Python module reference
==============================

.. contents:: :local:
    :depth: 2

.. Concise reference documentation extracted directly from code.
.. For new and non-backwards-compatible features, API versions must be given.

The Gromacs Python package includes a high-level scripting interface implemented
in pure Python and a lower-level API implemented as a C++ extension module.
The pure Python implementation provides the basic ``gmxapi`` module and
classes with a very stable syntax that can be maintained with maximal compatibility
while mapping to lower level interfaces that may take a while to sort out. The
separation also serves as a reminder that different execution contexts may be
implemented quite diffently, though Python scripts using only the high-level
interface should execute on all.

Package documentation is extracted from the ``gmxapi`` Python module and is also available
directly, using either ``pydoc`` from the command line or :py:func:`help` from within Python, such
as during an interactive session.

Refer to the Python source code itself for additional clarification.

.. seealso::

    This copy of the documentation was built without
    :doc:`installing the gmxapi package <../userguide/install>`,
    and therefore lacks the full module reference.
    Refer to :ref:`gmxapi_package_documentation` for instructions on building
    complete documentation, or `view online <http://manual.gromacs.org/current/gmxapi/>`__.
==============================
gmxapi Python module reference
==============================

.. contents:: :local:
    :depth: 2

.. Concise reference documentation extracted directly from code.
.. For new and non-backwards-compatible features, API versions must be given.

The Gromacs Python package includes a high-level scripting interface implemented
in pure Python and a lower-level API implemented as a C++ extension module.
The pure Python implementation provides the basic ``gmxapi`` module and
classes with a very stable syntax that can be maintained with maximal compatibility
while mapping to lower level interfaces that may take a while to sort out. The
separation also serves as a reminder that different execution contexts may be
implemented quite diffently, though Python scripts using only the high-level
interface should execute on all.

Package documentation is extracted from the ``gmxapi`` Python module and is also available
directly, using either ``pydoc`` from the command line or :py:func:`help` from within Python, such
as during an interactive session.

Refer to the Python source code itself for additional clarification.

.. seealso:: :ref:`gmxapi_package_documentation`

.. Configuration for doctest: automated syntax checking in documentation code snippets
.. testsetup::

    import gmxapi as gmx
    from gmxapi.data import tpr_filename

gmxapi basic package
=====================

::

    import gmxapi as gmx

.. automodule:: gmxapi

.. autodecorator:: function_wrapper

.. autofunction:: commandline_operation

.. autofunction:: subgraph

.. autofunction:: while_loop

Simulation module
=================

.. automodule:: gmxapi.simulation

.. py:currentmodule:: gmxapi

.. autofunction:: read_tpr

.. autofunction:: modify_input

.. autofunction:: mdrun

Utilities
=========

.. automodule:: gmxapi.utility

.. py:currentmodule:: gmxapi

.. autofunction:: concatenate_lists

.. autofunction:: join_arrays

.. autofunction:: logical_not

.. autofunction:: make_constant

Status messages and Logging
===========================

.. automodule:: gmxapi._logging
   :members:

Exceptions module
=================
..  automodule:: gmxapi.exceptions
    :members:

gmx.version module
==================
..  automodule:: gmxapi.version
    :members:

Core API
========

.. automodule:: gmxapi._gmxapi

Exceptions
----------

.. autoexception:: gmxapi._gmxapi.Exception

    Root exception for the C++ extension module. Derives from `gmxapi.exceptions.Error`.

.. autoexception:: gmxapi._gmxapi.MissingImplementationError

.. autoexception:: gmxapi._gmxapi.ProtocolError

.. autoexception:: gmxapi._gmxapi.UnknownException

.. autoexception:: gmxapi._gmxapi.UsageError

Functions
---------

Tools for launching simulations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autofunction:: gmxapi._gmxapi.from_tpr

Tools to manipulate TPR input files
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autofunction:: gmxapi._gmxapi.copy_tprfile

.. autofunction:: gmxapi._gmxapi.read_tprfile

.. autofunction:: gmxapi._gmxapi.write_tprfile

.. autofunction:: gmxapi._gmxapi.rewrite_tprfile

Classes
-------

.. autoclass:: gmxapi._gmxapi.Context
    :members:

.. autoclass:: gmxapi._gmxapi.MDArgs
    :members:

.. autoclass:: gmxapi._gmxapi.MDSession
    :members:

.. autoclass:: gmxapi._gmxapi.MDSystem
    :members:

.. autoclass:: gmxapi._gmxapi.SimulationParameters
    :members:

.. autoclass:: gmxapi._gmxapi.TprFile
    :members:
==============================
Full installation instructions
==============================

.. highlight:: bash

Installation instructions for the :py:mod:`gmxapi` Python package,
built on GROMACS.

Command line examples assume the `bash <https://www.gnu.org/software/bash/>`_ shell.

.. note:: Regarding multiple GROMACS installations:
    Many GROMACS users switch between multiple GROMACS installations on the same
    computer using an HPC module system and/or a :ref:`GMXRC <getting access to |Gromacs|>` configuration script.
    For the equivalent sort of environment switching with the :py:mod:`gmxapi` Python package,
    we recommend installing it in a different
    `Python virtual environment <https://www.google.com/search?q=python+virtual+environment>`_
    for each GROMACS installation.
    Once built, a particular copy of the :py:mod:`gmxapi` Python package always refers to the
    same GROMACS installation.

.. contents:: Contents
    :local:
    :depth: 2

.. note::

    The following documentation contains frequent references to the pip_ tool
    for installing Python packages. In some cases, an unprivileged user should
    use the ``--user`` command line flag to tell pip_ to install packages
    into the user site-packages directory rather than the default site-packages
    directory for the Python installation. This flag is not appropriate when
    running :command:`pip` in a virtual environment (as recommended) and is omitted in
    this documentation. If you need the ``--user`` flag, you should modify the
    example commands to look something like :command:`pip install --upgrade somepackage --user`

.. note::

    These instructions use the executable names :command:`python` and :command:`pip`
    instead of :command:`python3` or :command:`pip3`. Some Python installations require the ``3``
    suffix, but it is usually not necessary if you have already activated a Python
    virtual environment (recommended).

Overview
========

Typically, setting up the *gmxapi* Python package follows these three steps.
If this overview is sufficient for your computing environment,
you may disregard the rest of this document.

Install GROMACS
---------------

Locate your GROMACS installation, or build and install GROMACS 2020 or higher.

.. seealso:: `GROMACS installation <http://manual.gromacs.org/documentation/current/install-guide/index.html>`_

The following assumes GROMACS is installed to :file:`/path/to/gromacs`

Set up a Python virtual environment
-----------------------------------

::

    python3 -m venv $HOME/myvenv
    . $HOME/myvenv/bin/activate
    python -m ensurepip --default-pip
    pip install --upgrade pip setuptools wheel

.. seealso:: :ref:`gmxapi venv`

Install the gmxapi Python package
---------------------------------

::

    . /path/to/gromacs/bin/GMXRC
    pip install --no-cache-dir gmxapi

.. seealso:: :ref:`installation`

Background
==========

*gmxapi* comes in three parts:

* GROMACS gmxapi library for C++.
* This Python package, supporting Python 3.7 and higher
* MD restraint plugins and sample gmxapi client code

GROMACS requirements
--------------------

The Python package requires a GROMACS installation.
Locate an existing GROMACS installation, or
`build and install GROMACS <http://manual.gromacs.org/documentation/current/install-guide/index.html>`_
before proceeding.

.. note::

    Note that gmxapi requires that GROMACS is configured with ``GMXAPI=ON`` and ``BUILD_SHARED_LIBS=ON``.
    These are enabled by default in most cases. If these options were overridden
    for your GROMACS installation, you will see CMake errors when trying to build
    and install the gmxapi Python package or other client software.

Then, "source" the :file:`GMXRC` file from the GROMACS installation
:ref:`as you normally would <getting access to |Gromacs|>`
before using GROMACS, or note its installation location so that you can pass it
to the build configuration.

Build system requirements
-------------------------

gmxapi can be built for Python 3.7 and higher.

You will need a C++ 17 compatible compiler and a reasonably up-to-date version
of CMake.
Full gmxapi functionality may also require an MPI compiler (e.g. :command:`mpicc`).

Important: To build a module that can be imported by Python, you need a Python
installation that includes the Python headers. Unfortunately, it is not always
obvious whether these headers are present or where to find them. The simplest
answer is to just try to build the Python package using these instructions, and
if gmxapi is unable to find the Python tools it needs, try a different Python
installation or install the additional development packages.

On a Linux system, this may require installing packages such as ``python-dev``
and/or ``python3-dev``.
If you are building Python, either from scratch or with a tool like
:command:`pyenv install` (see
`wiki entry <https://github.com/pyenv/pyenv/wiki#how-to-build-cpython-with---enable-shared>`_
),
be sure to enable installation of the Python C library with the
``--enable-shared`` flag.
Alternatively, various Python distributions provide a
sufficient build environment while only requiring installation into a user
home directory. (Some examples below.)

If you are using an HPC system with software available through modules you may
be able to just :command:`module load` a different Python installation and find one
that works.

Python environment requirements
-------------------------------

gmxapi requires Python 3.7 or higher. Check your version with
:command:`python3 --version` or :command:`python --version`.

..  note::

    The following documentation assumes you do not need to use a trailing '3' to
    access a Python 3 interpreter on your system.
    The default Python interpreter on your system may use :command:`python3` and :command:`pip3`
    instead of :command:`python` and :command:`pip`. You can check the version with
    :command:`python3 --version` or :command:`python --version` and :command:`pip --version`.

To build and install, you need the Python packages for
cmake_, networkx_, and setuptools_
(all available from `PyPI with pip <https://pip.pypa.io/en/stable/>`_).

For full functionality, you should also have mpi4py_ and numpy_.
These requirements and version numbers are listed in :file:`requirements.txt`.

The easiest way to make sure you have the requirements installed, first update
pip_, then use the :file:`requirements.txt` file provided with the repository.
File paths in this section are relative to the root directory of your local copy
of the GROMACS source.

Confirm that pip_ is available, install pip_ if it is missing, or get
instructions on how to install pip_::

    python -m ensurepip --default-pip

Install or upgrade required components::

    python -m pip install --upgrade pip
    pip install --upgrade setuptools

"requirements" files in GROMACS source tree
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If you are building from source code in a local copy of the GROMACS source
repository, some helpful files allow you to preinstall the Python requirements
before installing the :py:mod:`gmxapi` package.

    pip install -r python_packaging/src/requirements.txt

If building documentation or running tests,
:command:`pip install -r python_packaging/requirements-docs.txt` or
:command:`pip install -r python_packaging/requirements-test.txt`,
respectively, or see below.

Documentation build requirements
--------------------------------

See :ref:`gmxapi_package_documentation`

.. _testing requirements:

Testing requirements
--------------------

Note that the test suite is only available in the GROMACS source tree.
(It is not part of the installed package.)
Acquire the GROMACS sources with :command:`git` or by downloading an archive, as documented elsewhere.

Testing is performed with `pytest <https://docs.pytest.org/en/latest/>`_.

:file:`python_packaging/requirements-test.txt` lists additional requirements for testing.
With pip_::

    pip install -r python_packaging/requirements-test.txt

To test the full functionality also requires an MPI parallel environment.
You will need the mpi4py_ Python package and an MPI launcher
(such as :command:`mpiexec`, :command:`mpirun`, a launcher provided by your HPC queuing system,
or whatever is provided by your favorite MPI package for your operating system).

.. _mpi_requirements:

MPI requirements
----------------

For the ensemble simulations features, you will need an MPI installation.
On an HPC system, this means you will probably have to use :command:`module load`
to load a compatible set of MPI tools and compilers.
Check your HPC documentation or try :command:`module avail` to look for an
``openmpi``, ``mpich``, or ``mvapich`` module and matching compiler module.
This may be as simple as::

    module load gcc
    module load mpicc

Note that the compilers loaded might not be the first compilers discovered
automatically by the build tools we will use below,
so you may have to specify compilers on the command line for consistency.
It may be necessary to require that GROMACS, gmxapi,
and the sample code are built with the same compiler(s).

Note that strange errors have been known to occur when mpi4py_ is built with
different a different tool set than has been used to build Python and gmxapi.
If the default compilers on your system are not sufficient for GROMACS or gmxapi,
you may need to build, e.g., OpenMPI or MPICH, and/or build mpi4py_ with a
specific MPI compiler wrapper. This can complicate building in environments such
as Conda_. You should be able to confirm that your MPI compiler wrapper is consistent
with your GROMACS tool chain by comapring the output of :command:`mpicc --version`
with the compiler information reported by :command:`gmx --version`.

Set the MPICC environment variable to the MPI compiler wrapper and forcibly
reinstall mpi4py_::

    export MPICC=`which mpicc`
    pip install --no-cache-dir --upgrade --no-binary ":all:" --force-reinstall mpi4py

If you have a different MPI C compiler wrapper, substitute it for :command:`mpicc` above.

.. _installation:

Installing the Python package
=============================

We recommend using Python's `pip <https://pip.pypa.io/en/stable/>`_
package installer to automatically download, build, and install the latest
version of the gmxapi package into a Python
`virtual environment <https://docs.python.org/3/tutorial/venv.html>`_,
though it is also possible to install without a virtual environment.
If installing without a virtual environment as an un-privileged user,
you may need to set the CMake variable ``GMXAPI_USER_INSTALL``
(``-DGMXAPI_USER_INSTALL=ON`` on the :command:`cmake` command line)
and / or use the ``--user`` option with :command:`pip install`.

Recommended installation
------------------------

The instructions in this section assume that *pip* is able to download files
from the internet. Alternatively, refer to :ref:`gmxapi offline install`.

Locate or install GROMACS
^^^^^^^^^^^^^^^^^^^^^^^^^

You need a GROMACS installation that includes the gmxapi headers and library.

.. warning:: gmxapi does not recognize multiple |Gromacs| installations to the same ``CMAKE_INSTALL_PREFIX``.

    The Python package uses files installed to ``.../share/cmake/gmxapi/`` to configure its C++
    component. These configuration files are overwritten when installing GROMACS to the same
    `CMAKE_INSTALL_PREFIX <https://cmake.org/cmake/help/latest/variable/CMAKE_INSTALL_PREFIX.html>`__.
    Overlapping GROMACS installations may occur when GROMACS is installed for multiple
    configurations of MPI support and floating point precision.
    (See :issue:`4334` and related issues.)

If GROMACS 2020 or higher is already installed,
*and* was configured with ``GMXAPI=ON`` at build time (the default),
you can just source the :ref:`GMXRC <getting access to |Gromacs|>`
(so that the Python package knows where to find GROMACS)
and skip to the next section.

Otherwise, install a supported version of GROMACS.
When building GROMACS from source, be sure to configure cmake with the flag
``-DGMXAPI=ON`` (default).

Set the environment variables for the GROMACS installation so that the gmxapi
headers and library can be found when building the Python package.
If you installed to a :file:`gromacs-gmxapi` directory in your home directory as
above and you use the :command:`bash` shell, do::

    source $HOME/gromacs-gmxapi/bin/GMXRC

If you are using a GROMACS installation that does not provide ``GMXRC``, see
`gmxapi cmake hints`_ and additional CMake hints below.

.. _gmxapi venv:

Set up a Python virtual environment
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We recommend installing the Python package in a virtual environment.
If not installing in a virtual environment, you may not be able to install
necessary prerequisites (e.g. if you are not an administrator of the system you are on).

The following instructions use the :py:mod:`venv` module.
Alternative virtual environments, such as Conda_,
should work fine, but are beyond the scope of this document.
(We welcome contributed recipes!)

Depending on your computing environment, the Python 3 interpreter may be accessed
with the command :command:`python` or :command:`python3`. Use :command:`python --version` and
:command:`python3 --version` to figure out which you need to use. The following assumes
the Python 3 interpreter is accessed with :command:`python3`.

Create a Python 3 virtual environment::

    python3 -m venv $HOME/myvenv

Activate the virtual environment. Your shell prompt will probably be updated with the name of the environment you
created to make it more obvious.

.. code-block:: none

    $ source $HOME/myvenv/bin/activate
    (myvenv)$

..  note::

    After activating the *venv*, :command:`python` and :command:`pip` are sufficient.
    (The '3' suffix will no longer be necessary and will be omitted in the rest
    of this document.)

Activating the virtual environment may change your shell prompt to indicate the
environment is active. The prompt is omitted from the remaining examples, but
the remaining examples assume the virtual environment is still active.
(Don't do it now, but you can deactivate the environment by running :command:`deactivate`.)

Install dependencies
^^^^^^^^^^^^^^^^^^^^

It is always a good idea to update pip_, setuptools_, and wheel_ before installing
new Python packages::

    pip install --upgrade pip setuptools wheel

The gmxapi installer requires a few additional packages. It is best to make sure
they are installed and up to date before proceeding.

::

    pip install --upgrade cmake pybind11

For MPI, we use mpi4py_.
Make sure it is using the same MPI installation that we are building
GROMACS against and building with compatible compilers.

::

    python -m pip install --upgrade pip setuptools
    MPICC=`which mpicc` pip install --upgrade mpi4py

.. seealso:: :ref:`mpi_requirements`

Install the latest version of gmxapi
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fetch and install the latest official version of gmxapi from the Python Packaging Index::

    # Get the latest official release.
    pip install --no-cache-dir gmxapi

.. note:: Use ``--no-cache-dir`` to force rebuild.

    ``pip`` downloads a source distribution archive for gmxapi, then builds a
    "wheel" package for your GROMACS installation.
    This "wheel" normally gets cached, and will be used by any later attempt to
    ``pip install gmxapi`` instead of rebuilding. This is not what you want,
    if you upgrade GROMACS or if you want to install the Python package for a
    different GROMACS configuration (e.g. double-precision or different MPI option.)
    See also :issue:`4335`

The `PyPI repository <https://pypi.org/project/gmxapi/#history>`_
may include pre-release versions,
but :command:`pip` will ignore them unless you use the ``--pre`` flag::

    # Get the latest version, including pre-release versions.
    pip install --no-cache-dir --pre gmxapi

If :command:`pip` does not find your GROMACS installation, use one of the following
environment variables to provide a hint.

The installer will also look for a ``CMAKE_ARGS`` environment variable. If found,
The ``$CMAKE_ARGS`` string will be split into additional arguments that will be
provided to CMake when building the *gmxapi* package.

.. _gmxapi cmake hints:

gmxapi_ROOT
~~~~~~~~~~~

If you have a single GROMACS installation at :file:`/path/to/gromacs`, it is usually
sufficient to provide this location to :command:`pip` through the :envvar:`gmxapi_ROOT`
environment variable.

Example::

    gmxapi_ROOT=/path/to/gromacs pip install --no-cache-dir gmxapi

Note that this is equivalent to providing the CMake variable definition::

    CMAKE_ARGS="-Dgmxapi_ROOT=/path/to/gromacs" pip install --no-cache-dir gmxapi

|Gromacs| CMake hints
~~~~~~~~~~~~~~~~~~~~~

If you have multiple builds of GROMACS distinguished by suffixes
(e.g. *_d*, *_mpi*, etcetera), or if you need to provide extra hints to :command:`pip`
about the software tools that were used to build GROMACS, you can specify a
CMake "hints" file by including a ``-C <initial-cache>`` option with your ``CMAKE_ARGS``.
(For more information, read about the ``-C``
`command line option <https://cmake.org/cmake/help/latest/manual/cmake.1.html#options>`__
for CMake.)

In the following example, ``${UNIQUE_PREFIX}`` is the path to the directory that holds the
|Gromacs| ``bin``, ``lib``, ``share`` directories, *etc*.
It is *unique* because GROMACS provides CMake support for only one build configuration at a time
through ``.../share/cmake/gmxapi/``, even if there are multiple library configurations installed to
the same location. See :issue:`4334`.

``${SUFFIX}`` is the suffix that distinguishes the
particular build of GROMACS you want to target (refer to GROMACS installation
instructions for more information.) ``${SUFFIX}`` may simply be empty, or ``''``.

You can export ``CMAKE_ARGS`` in your environment, or just provide it at the beginning
of the ``pip install`` command line::

    CMAKE_ARGS="-Dgmxapi_ROOT=${UNIQUE_PREFIX} -C ${UNIQUE_PREFIX}/share/cmake/gromacs${SUFFIX}/gromacs-hints.cmake" \
        pip install --no-cache-dir gmxapi

Install from source
-------------------

You can also install the :py:mod:`gmxapi` Python package from within a local copy of
the GROMACS source repository. Assuming you have already obtained the GROMACS
source code and you are in the root directory of the source tree, you will find
the :py:mod:`gmxapi` Python package sources in the :file:`python_packaging/src` directory.

::

    cd python_packaging/src
    pip install -r requirements.txt
    pip install .

.. _gmxapi offline install:

Offline install
---------------

If the required dependencies are already installed, you can do a quick installation
without internet access, either from the source directory or from a source archive.

For example, the last line of the previous example could be replaced with::

    pip install --no-cache-dir --no-deps --no-index .

Refer to pip_ documentation for descriptions of these options.

If you have built or downloaded a source distribution archive, you can provide
the archive file to :command:`pip` instead of the ``.`` argument::

    pip install gmxapi-0.1.0.tar.gz

In this example, the archive file name is as was downloaded from
`PyPI <https://pypi.org/project/gmxapi/#history>`_ or as built locally,
according to the following instructions.

Building a source archive
-------------------------

A source archive for the gmxapi python package can be built from the GROMACS
source repository using Python ``setuptools``.

Example::

    pip install --upgrade setuptools wheel pybind11 cmake
    cd python_packaging/src
    python setup.py sdist

This command will create a ``dist`` directory containing a source distribution
archive file. The file name has the form *gmxapi-<version>.<suffix>*, where
*<version>* is the version from the ``setup.py`` file, and *<suffix>* is
determined by the local environment or by additional arguments to ``setup.py``.

The new `build <https://pypa-build.readthedocs.io/en/latest/>`__ module is somewhat tidier.
It automatically manages a temporary venv with the necessary dependencies::

    pip install --upgrade build
    cd python_packaging/src
    python -m build --sdist .

.. seealso::

    Python documentation for
    `creating a source distribution
    <https://docs.python.org/3/distutils/sourcedist.html#creating-a-source-distribution>`_

Package maintainers may update the online repository by uploading a freshly
built ``sdist`` with ``python -m twine upload dist/*``

.. _gmxapi_package_documentation:

Accessing gmxapi documentation
==============================

Documentation for the Python classes and functions in the gmx module can
be accessed in the usual ways, using ``pydoc`` from the command line or
``help()`` in an interactive Python session.

The complete documentation (which you are currently reading)
can be browsed `online <http://manual.gromacs.org/current/gmxapi/>`__
or built from a copy of the GROMACS source repository.

Documentation is built from a combination of Python module documentation and
static content, and requires a local copy of the GROMACS source repository.

Build with GROMACS
------------------

To build the full gmxapi documentation with GROMACS, configure GROMACS with
``-DGMX_PYTHON_PACKAGE=ON`` and build the GROMACS documentation normally.
This will first build the *gmxapi* Python package and install it to a temporary
location in the build tree. Sphinx can then import the package to automatically
extract Python docstrings.

Note that this is an entirely CMake-driven installation and Python dependencies
will not be installed automatically. You can update your Python environment
(before configuring with CMake) using the :file:`requirements.txt` files provided
in the :file:`python_packaging/` directory of the repository. Example::

    pip install -r python_packaging/requirements-docs.txt

or

::

    pip install -r python_packaging/requirements-test.txt

Sometimes the build environment can choose a different Python interpreter than
the one you intended.
You can set the ``Python3_ROOT_DIR`` or ``CMAKE_PREFIX_PATH`` CMake variable to
explicitly choose the Python installation or *venv* directory.

If you use pyenv or pyenv-virtualenv to dynamically manage your Python version,
you can help identify a particular version with ``pyenv version-name`` and the
directory with ``pyenv prefix {version}``. For example::

    -DPython3_ROOT_DIR=$(pyenv prefix $(pyenv version-name))

Docker web server
-----------------

Alternatively, build the ``docs`` Docker image from ``python_packaging/docker/docs.dockerfile``
or pull a prebuilt image from DockerHub. Refer to the dockerfile or to
https://hub.docker.com/r/gmxapi/docs for more information.

.. todo::

    Document sample_restraint package. Reference :issue:`3027`

Testing
=======

Note `testing requirements`_ above.

After installing the :py:mod:`gmxapi` Python package,
you can run the Python test suite from the GROMACS source tree.
Example::

    # Assuming you are in the root directory of the repository:
    pytest python_packaging/src/test/

Refer to :file:`python_packaging/README.md` for more detailed information.

.. _gmxapi install troubleshooting:

Troubleshooting
===============

AttributeError: module 'enum' has no attribute 'IntFlag'
--------------------------------------------------------

If you had older versions of some of the dependencies installed,
you might have picked up a transitive dependency on the ``enum34`` package.
Try::

    pip uninstall -y enum34

and see if that fixes the problem. If not, try a fresh virtual environment
(see above) to help narrow down the problem before you
`open an issue <https://gitlab.com/gromacs/gromacs/-/issues/>`_.

Errors regarding pybind11
-------------------------

An error may occur in ``setup.py`` with output that contains something like the following::

      ModuleNotFoundError: No module named 'pybind11'
      Building wheel for gmxapi (pyproject.toml): finished with status 'error'
      ERROR: Failed building wheel for gmxapi
    Failed to build gmxapi
    ERROR: Could not build wheels for gmxapi, which is required to install pyproject.toml-based projects

The important information here is that ``pybind11`` was not found.

Build dependencies aren't always automatically installed.
Even if you are using ``pip``, you may have disabled automatic dependency fulfillment with an option like ``--no-build-isolation`` or ``--no-deps``.

In any case, the problem should be resolved by explicitly installing the ``pybind11``
Python package before attempting to build ``gmxapi``::

    pip install --upgrade pybind11

Couldn't find the ``gmxapi`` support library?
---------------------------------------------

If you don't want to "source" your :ref:`GMXRC <getting access to |Gromacs|>` file, you
can tell the package where to find a gmxapi compatible GROMACS installation with
``gmxapi_ROOT``. E.g. ``gmxapi_ROOT=/path/to/gromacs pip install .``

Before updating the ``gmxapi`` package it is generally a good idea to remove the
previous installation and to start with a fresh build directory. You should be
able to just ``pip uninstall gmxapi``.

Do you see something like the following?

.. code-block:: none

   CMake Error at gmx/core/CMakeLists.txt:45 (find_package):
      Could not find a package configuration file provided by "gmxapi" with any
      of the following names:

        gmxapiConfig.cmake
        gmxapi-config.cmake

      Add the installation prefix of "gmxapi" to CMAKE_PREFIX_PATH or set
      "gmxapi_ROOT" to a directory containing one of the above files.  If "gmxapi"
      provides a separate development package or SDK, be sure it has been
      installed.

This could be because

* GROMACS is not already installed
* GROMACS was built without the CMake variable ``GMXAPI=ON``
* or if ``gmxapi_ROOT`` (or ``GROMACS_DIR``) is not a path containing directories
  like ``bin`` and ``share``.

If you are not a system administrator you are encouraged to install in a Python
virtual environment, created with virtualenv or Conda_.
Otherwise, you will need to specify the ``--user`` flag to ``pip``.

Two of the easiest problems to run into are incompatible compilers and
incompatible Python. Try to make sure that you use the same C and C++
compilers for GROMACS, for the Python package, and for the sample
plugin. These compilers should also correspond to the :command:`mpicc` compiler
wrapper used to compile mpi4py_. In order to build the Python
package, you will need the Python headers or development installation,
which might not already be installed on the machine you are using. (If
not, then you will get an error about missing :file:`Python.h` at some
point.) If you have multiple Python installations (or modules available
on an HPC system), you could try one of the other Python installations,
or you or a system administrator could install an appropriate Python dev
package. Alternatively, you might try installing your own Anaconda or
MiniConda in your home directory.

If an attempted installation fails with CMake errors about missing
“gmxapi”, make sure that Gromacs is installed and can be found during
installation. For instance,

::

    gmxapi_ROOT=/Users/eric/gromacs python setup.py install --verbose

Pip and related Python package management tools can be a little too
flexible and ambiguous sometimes. If things get really messed up, try
explicitly uninstalling the :py:mod:`gmxapi` module and its dependencies, then do
it again and repeat until :command:`pip` can no longer find any version of any
of the packages.

::

    pip uninstall gmxapi
    pip uninstall cmake
    # ...

Successfully running the test suite is not essential to having a working
:py:mod:`gmxapi` package. We are working to make the testing more robust, but
right now the test suite is a bit delicate and may not work right, even
though you have a successfully built the :py:mod:`gmxapi` package. If you want to
troubleshoot, though, the main problems seem to be that automatic
installation of required python packages may not work (requiring manual
installations, such as with :command:`pip install somepackage`) and ambiguities
between python versions. 

If you are working in a development branch of the repository, note that
the upstream branch may be reset to ``master`` after a new release is
tagged. In general, but particularly on the ``devel`` branch, when you
do a :command:`git pull`, you should use the ``--rebase`` flag.

If you fetch this repository and then see a git status like this::

    $ git status
    On branch devel
    Your branch and 'origin/devel' have diverged,
    and have 31 and 29 different commits each, respectively.

then :py:mod:`gmxapi` has probably entered a new development cycle. You can
do :command:`git pull --rebase` to update to the latest development branch.

If you do a :command:`git pull` while in ``devel`` and get a bunch of unexpected
merge conflicts, do :command:`git merge --abort; git pull --rebase` and you should
be back on track.

If you are developing code for gmxapi, this should be an indication to
rebase your feature branches for the new development cycle.

.. _cmake: https://pypi.org/project/cmake/

.. _Conda: https://docs.conda.io/en/latest/

.. _mpi4py: https://pypi.org/project/mpi4py/

.. _networkx: https://pypi.org/project/networkx/

.. _numpy: https://www.numpy.org/

.. _pip: https://pip.pypa.io/en/stable/

.. _scikit-build: https://pypi.org/project/scikit-build/

.. _setuptools: https://pypi.org/project/setuptools/

.. _wheel: https://pypi.org/project/wheel/
========================
Using the Python package
========================

After installing GROMACS, sourcing the "GMXRC" (see GROMACS docs), and installing
the gmxapi Python package (see :doc:`install`), import the package in a Python
script or interactive interpreter. This documentation assumes a convenient alias
of ``gmx`` to refer to the ``gmxapi`` Python package.

::

    import gmxapi as gmx

For full documentation of the Python-level interface and API, use the ``pydoc``
command line tool or the :py:func:`help` interactive Python function, or refer to
the :doc:`pythonreference`.

Any Python *exception* raised by gmxapi
should be descended from (and catchable as) :class:`gmxapi.exceptions.Error`.
Additional status messages can be acquired through the :ref:`gmxapi logging`
facility.
Unfortunately, some errors occurring in the GROMACS library are not yet
recoverable at the Python level, and much of the standard GROMACS terminal
output is not yet accessible through Python.
If you find a particularly problematic scenario, please file a GROMACS bug report.

During installation, the *gmxapi* Python package becomes tied to a specific
GROMACS installation.
If you would like to access multiple GROMACS installations
from Python, build and install *gmxapi* in separate
:ref:`virtual environments <gmxapi venv>`.

.. _parallelism:

Notes on parallelism and MPI
============================

When launching a *gmxapi* script in an MPI environment,
such as with :command:`mpiexec` or :command:`srun`,
you must help *gmxapi* detect the MPI environment by ensuring that :py:mod:`mpi4py`
is loaded.
Refer to :ref:`mpi_requirements` for more on installing :py:mod:`mpi4py`.

Assuming you use :command:`mpiexec` to launch MPI jobs in your environment,
run a *gmxapi* script on two ranks with something like the following.
Note that it can be helpful to provide :command:`mpiexec` with the full path to
the intended Python interpreter since new process environments are being created.

::

    mpiexec -n 2 `which python` -m mpi4py myscript.py

*gmxapi* 0.1 has limited parallelism, but future versions will include seamless
acceleration as integration improves with the GROMACS library and computing
environment runtime resources.
Currently, *gmxapi* and the GROMACS library do not have an effective way to
share an MPI environment.
Therefore, if you intend to run more than one simulation at a time, in parallel,
in a *gmxapi* script, you should build GROMACS with *thread-MPI* instead of a
standard MPI library.
I.e. configure GROMACS with the CMake flag ``-DGMX_THREAD_MPI=ON``.
Then, launch your *gmxapi* script with one MPI rank per node, and *gmxapi* will
assign each (non-MPI) simulation to its own node, while keeping the full MPI
environment available for use via :py:mod:`mpi4py`.

Running simple simulations
==========================

Once the ``gmxapi`` package is installed, running simulations is easy with
:py:func:`gmxapi.read_tpr`.

::

    import gmxapi as gmx
    simulation_input = gmx.read_tpr(tpr_filename)
    md = gmx.mdrun(simulation_input)

Note that this sets up the work you want to perform, but does not immediately
trigger execution. You can explicitly trigger execution with::

    md.run()

or you can let gmxapi automatically launch work in response to the data you
request.

The :py:func:`gmxapi.mdrun` operation produces a simulation trajectory output.
You can use ``md.output.trajectory`` as input to other operations,
or you can get the output directly by calling ``md.output.trajectory.result()``.
If the simulation has not been run yet when ``result()`` is called,
the simulation will be run before the function returns.

Running ensemble simulations
============================

To run a batch of simulations, just pass an array of inputs.::

    md = gmx.read_tpr([tpr_filename1, tpr_filename2, ...])
    md.run()

Make sure to launch the script in an MPI environment with a sufficient number
of ranks to allow one rank per simulation.

For *gmxapi* 0.1, we recommend configuring the GROMACS build with
``GMX_THREAD_MPI=ON`` and allowing one rank per node in order to allow each
simulation ensemble member to run on a separate node.

.. seealso:: :ref:`parallelism`

.. _commandline:

Accessing command line tools
============================

In *gmxapi* 0.1, most GROMACS tools are not yet exposed as *gmxapi* Python operations.
:class:`gmxapi.commandline_operation` provides a way to convert a :command:`gmx`
(or other) command line tool into an operation that can be used in a *gmxapi*
script.

In order to establish data dependencies, input and output files need to be
indicated with the ``input_files`` and ``output_files`` parameters.
``input_files`` and ``output_files`` key word arguments are dictionaries
consisting of files keyed by command line flags.

For example, you might create a :command:`gmx solvate` operation as::

    solvate = gmx.commandline_operation('gmx',
                                        arguments=['solvate', '-box', '5', '5', '5'],
                                        input_files={'-cs': structurefile},
                                        output_files={'-p': topfile,
                                                      '-o': structurefile,
                                                      }

To check the status or error output of a command line operation, refer to the
``returncode`` and ``stderr`` outputs.
To access the results from the output file arguments, use the command line flags
as keys in the ``file`` dictionary output.

Example::

    structurefile = solvate.output.file['-o'].result()
    if solvate.output.returncode.result() != 0:
        print(solvate.output.erroroutput.result())

Preparing simulations
=====================

Continuing the previous example, the output of ``solvate`` may be used as the
input for ``grompp``::

    grompp = gmx.commandline_operation('gmx', 'grompp',
                                       input_files={
                                           '-f': mdpfile,
                                           '-p': solvate.output.file['-p'],
                                           '-c': solvate.output.file['-o'],
                                           '-po': mdout_mdp,
                                       },
                                       output_files={'-o': tprfile})

Then, ``grompp.output.file['-o']`` can be used as the input for :py:func:`gmxapi.read_tpr`.

Simulation input can be modified with the :py:func:`gmxapi.modify_input` operation
before being passed to :py:func:`gmxapi.mdrun`.
For *gmxapi* 0.1, a subset of MDP parameters may be overridden using the
dictionary passed with the ``parameters`` key word argument.

Example::

    simulation_input = gmx.read_tpr(grompp.output.file['-o'])
    modified_input = gmx.modify_input(input=simulation_input, parameters={'nsteps': 1000})
    md = gmx.mdrun(input=modified_input)
    md.run()

Using arbitrary Python functions
================================

Generally, a function in the *gmxapi* package returns an object that references
a node in a work graph,
representing an operation that will be run when the graph executes.
The object has an ``output`` attribute providing access to data Futures that
can be provided as inputs to other operations before computation has actually
been performed.

You can also provide native Python data as input to operations,
or you can operate on native results retrieved from a Future's ``result()``
method.
However, it is trivial to convert most Python functions into *gmxapi* compatible
operations with :py:func:`gmxapi.function_wrapper`.
All function inputs and outputs must have a name and type.
Additionally, functions should be stateless and importable
(e.g. via Python ``from some.module import myfunction``)
for future compatibility.

Simple functions can just use :py:func:`return` to publish their output,
as long as they are defined with a return value type annotation.
Functions with multiple outputs can accept an ``output`` key word argument and
assign values to named attributes on the received argument.

Examples::

    from gmxapi import function_wrapper

    @function_wrapper(output={'data': float})
    def add_float(a: float, b: float) -> float:
        return a + b


    @function_wrapper(output={'data': bool})
    def less_than(lhs: float, rhs: float, output=None):
        output.data = lhs < rhs

.. seealso::

    For more on Python type hinting with function annotations,
    check out :pep:`3107`.

Subgraphs
=========

Basic *gmxapi* work consists of a flow of data from operation outputs to
operation inputs, forming a directed acyclic graph (DAG).
In many cases, it can be useful to repeat execution of a subgraph with updated
inputs.
You may want a data reference that is not tied to the immutable result
of a single node in the work graph, but which instead refers to the most recent
result of a repeated operation.

One or more operations can be staged in a :py:class:`gmxapi.operation.Subgraph`,
a sort of meta-operation factory that can store input binding behavior so that
instances can be created without providing input arguments.

The subgraph *variables* serve as input, output, and mutable internal data
references which can be updated by operations in the subgraph.
Variables also allow state to be propagated between iterations when a subgraph
is used in a *while* loop.

Use :py:func:`gmxapi.subgraph` to create a new empty subgraph.
The ``variables`` argument declares data handles that define the state of the
subgraph when it is run.
To initialize input to the subgraph, give each variable a name and a value.

To populate a subgraph, enter a SubgraphContext by using a :py:func:`with` statement.
Operations created in the *with* block will be captued by the SubgraphContext.
Define the subgraph outputs by assigning operation outputs to subgraph variables
within the *with* block.

After exiting the *with* block, the subgraph may be used to create operation
instances or may be executed repeatedly in a *while* loop.

.. note::

    The object returned by :py:func:`gmxapi.subgraph` is atypical of *gmxapi*
    operations, and has some special behaviors. When used as a Python
    `context manager <https://docs.python.org/3/reference/datamodel.html#context-managers>`__,
    it enters a "builder" state that changes the behavior of its attribute
    variables and of operaton instantiation. After exiting the :py:func:`with`
    block, the subgraph variables are no longer assignable, and operation
    references obtained within the block are no longer valid.

Looping
=======

An operation can be executed an arbitrary number of times with a
:py:func:`gmxapi.while_loop` by providing a factory function as the
*operation* argument.
When the loop operation is run, the *operation* is instantiated and run repeatedly
until *condition* evaluates ``True``.

:py:func:`gmxapi.while_loop` does not provide a direct way to provide *operation*
arguments. Use a *subgraph* to define the data flow for iterative operations.

When a *condition* is a subgraph variable, the variable is evaluated in the
running subgraph instance at the beginning of an iteration.

Example::

    subgraph = gmx.subgraph(variables={'float_with_default': 1.0, 'bool_data': True})
    with subgraph:
        # Define the update for float_with_default to come from an add_float operation.
        subgraph.float_with_default = add_float(subgraph.float_with_default, 1.).output.data
        subgraph.bool_data = less_than(lhs=subgraph.float_with_default, rhs=6.).output.data
    operation_instance = subgraph()
    operation_instance.run()
    assert operation_instance.values['float_with_default'] == 2.

    loop = gmx.while_loop(operation=subgraph, condition=subgraph.bool_data)
    handle = loop()
    assert handle.output.float_with_default.result() == 6

.. _gmxapi logging:

Logging
=======

*gmxapi* uses the Python :py:mod:`logging` module to provide hierarchical
logging, organized by submodule.
You can access the logger at ``gmxapi.logger`` or, after importing *gmxapi*,
through the Python logging framework::

    import gmxapi as gmx
    import logging

    # Get the root gmxapi logger.
    gmx_logger = logging.getLogger('gmxapi')
    # Set a low default logging level
    gmx_logger.setLevel(logging.WARNING)
    # Make some tools very verbose
    #  by descending the hierarchy
    gmx_logger.getChild('commandline').setLevel(logging.DEBUG)
    #  or by direct reference
    logging.getLogger('gmxapi.mdrun').setLevel(logging.DEBUG)

You may prefer to adjust the log format or manipulate the log handlers.
For example, tag the log output with MPI rank::

    try:
        from mpi4py import MPI
        rank_number = MPI.COMM_WORLD.Get_rank()
    except ImportError:
        rank_number = 0
        rank_tag = ''
        MPI = None
    else:
        rank_tag = 'rank{}:'.format(rank_number)

    formatter = logging.Formatter(rank_tag + '%(name)s:%(levelname)s: %(message)s')

    # For additional console logging, create and attach a stream handler.
    ch = logging.StreamHandler()
    ch.setFormatter(formatter)
    logging.getLogger().addHandler(ch)

For more information, refer to the Python `logging documentation <https://docs.python.org/3/library/logging.html>`__.

More
====

Refer to the :doc:`pythonreference` for complete and granular documentation.

For more information on writing or using pluggable simulation extension code,
refer to https://gitlab.com/gromacs/gromacs/-/issues/3133.
(For gmxapi 0.0.7 and GROMACS 2019, see https://github.com/kassonlab/sample_restraint)

.. todo:: :issue:`3133`: Replace these links as resources for pluggable extension code become available.
=================
Python User Guide
=================

.. toctree::
    :maxdepth: 2

    install
    usage
    pythonreference

After installing GROMACS and the gmxapi Python package, use ``pydoc gmxapi``
from the command line or ``import gmxapi; help(gmxapi)`` within Python for
package and module documentation.

..  todo:: Example scripts. See issue `3014 <https://gitlab.com/gromacs/gromacs/-/issues/3014>`_
Adding New Listed-Interaction Types in NB-LIB
=============================================

NB-LIB currently has code paths for listed interactions that occur between two, three, four and five different particles.
It is easy to extend NB-LIB to support novel formulations of particle interactions by modifying the following three files.

Two center interactions must use the distance between the centers as an input to the force kernel.
Three center interactions take the form ``(particleI, particleJ, ParticleK)``.
In this case, the middle particle, ``particleJ`` is taken as the center around which the angle is computed.
This angle must be an input to a three center force kernel.
Likewise for four center interactions, the dihedral angle phi must be an input to the force kernel.
Accepting these constraints, it is possible to add a new kernel by modifying the following three files.

1) bondtypes.h_
2) definitions.h_
3) kernels.hpp_

.. _bondtypes.h:

1) bondtypes.h
---------------

This file contains one ``struct`` for each interaction type parameter set.
New interaction types are added here as separate structs. There
are no content requirements, but for convenience, the existing ``NAMED_MEBERS``
macro in combination with inheriting from a ``std::tuple`` or ``std::array``
may be used. The macro can be used to define the
parameter names for the corresponding setters and getters.
For example, ``NAMED_MEMBERS(forceConstant, equilDistance)`` will expand to

.. code:: cpp

   inline auto& forceConstant() { return std::get<0>(*this); }
   inline auto& equilDistance() { return std::get<1>(*this); }
   inline const auto& forceConstant() const { return std::get<0>(*this); }
   inline const auto& equilDistance() const { return std::get<1>(*this); }

Putting everything together, one could define the complete parameter set for a new interaction type as follows.

.. code:: cpp

   /*! \brief new bond type
    *
    * V(r; forceConstant, equilDistance, scaleFactor)
    *      = forceConstant * exp( (r - equilDistance) / scaleFactor)
    */
   struct NewBondType : public std::tuple<real, real, int>
   {
       NewBondType() = default;
       NewBondType(ForceConstant f, EquilDistance d, ScaleFactor s) :
           std::tuple<real, real, int>{ f, d, s }
       {
       }

       NAMED_MEMBERS(forceConstant, equilDistance, scaleFactor)
   };

.. _definitions.h:

2) definitions.h
------------------------

This file begins with pre-processor macro lists that classify concrete interaction types into two, three, four and five center types.
To add a new type, the user must add the interaction type parameter struct name to the macro of the correct center number.
In this case, ``NewBondType`` is an example of a two center interaction.
As such it would get added to the ``SUPPORTED_TWO_CENTER_TYPES`` macro.
Assuming that the only other two center interaction is called ``DefaultBond``, the result would look like the following snippet.

.. code:: cpp

    #define SUPPORTED_TWO_CENTER_TYPES DefaultBond, NewBondType

.. _kernels.hpp:

Adding ``NewBondType`` to this macro ensures that the NBLIB ``molecule``
class ``addInteraction`` function supports adding the new bond type
and includes it in the listed interaction data that the ``topology`` class
provides.

Note that, as of C++17, there's no alternative to preprocessor macros for adding
the required template instantiations controlled through the macros described here.
In NBLIB, the design decision we took, was that we did not want to expose a templated
interface in a user header and it is for this reason that we explicitly need
to instantiate the interface with all the supported listed interaction types defined
in this macro.

3) kernels.hpp
---------------------

In this file the actual force kernels for each interaction type are implemented.
Each kernel call is templated to allow various precisions and is
accessed through an overload ``bondKernel`` that extracts the relevant
parameters from a ``const NewBondType&`` argument.
The kernel return type is always an ``std::tuple`` of the force and the potential.

.. code:: cpp

   /*! \brief kernel to calculate the new bond type force
    *
    * \param k     Force constant
    * \param x0    Equilibrium distance
    * \param scale The scaling factor
    * \param x     Input bond length
    *
    * \return tuple<force, potential energy>
    */
   template <class T>
   std::tuple<T, T> newBondForce(T k, T x0, T scale, T x)
   {
       real exponent = std::exp( (x - x0) / scale);
       real epot = k * exponent;
       real force =  epot / scale;
       return std::make_tuple(force, epot);
   }

  template <class T>
  inline auto bondKernel(T dr, const NewBondType& bond)
  {
      return newBondForce(bond.forceConstant(), bond.equilDistance(), bond.scaleFactor(), dr);
  }

.. _nblib:

=========
NBLIB API
=========

This documentation is part of the `GROMACS manual <http://manual.gromacs.org/current/>`_
and describes the *nblib* API.


..  toctree::
    :maxdepth: 1
    :caption: Documentation sections

    guide-to-writing-MD-programs.rst
Guide to Writing MD Programs
============================

The goal of NB-LIB’s is to enable researchers to programmatically define molecular simulations.
Traditionally these have been performed using a collection of executables and a manual workflow followed by a “black-box” simulation engine.
NB-LIB allows users to script a variety of novel simulation and analysis workflows at a more granular level.

Many possible use cases are facilitated by the flexibility that NB-LIB allows.
These include customized update rules, defining custom forces, or orchestrating swarms of simulations.
NB-LIB also allows for writing conventional MD simulations and analysis.

This document goes over the steps to write MD programs using the API in NB-LIB that exposes features that are a part of the GROMACS package.

Global Definitions
------------------

NB-LIB programs are written in C++ so its headers for I/O or advanced tasks must be included.
In addition, one must include the headers for various capabilities and abstractions NB-LIB exposes as well.
This can be directly copied from here.
Finally, we use the namespace ``nblib`` for the data structures defined in the library.
The last line in the block allows one to skip this specifier each time a function or a data structure is used.

.. code:: cpp

   #include <cstdio>

   #include "nblib/box.h"
   #include "nblib/forcecalculator.h"
   #include "nblib/integrator.h"
   #include "nblib/molecules.h"
   #include "nblib/nbkerneloptions.h"
   #include "nblib/particletype.h"
   #include "nblib/simulationstate.h"
   #include "nblib/topology.h"

   using namespace nblib;

Define Particle Data
--------------------

.. code:: cpp

   // Parameters from a GROMOS compatible force-field 2016H66

   struct OWaterAtom
   {
       ParticleName         name = "Ow";
       Mass                 mass = 15.999;
       C6                   c6   = 0.0026173456;
       C12                  c12  = 2.634129e-06;
   };

   struct HwAtom
   {
       ParticleName         name = "Hw";
       Mass                 mass = 1.00784;
       C6                   c6   = 0.0;
       C12                  c12  = 0.0;  
   };

   struct CMethAtom
   {
       ParticleName         name = "Cm";
       Mass                 mass = 12.0107;
       C6                   c6   = 0.01317904;
       C12                  c12  = 34.363044e-06;
   };

   struct HcAtom
   {
       ParticleName         name = "Hc";
       Mass                 mass = 1.00784;
       C6                   c6   = 8.464e-05;
       C12                  c12  = 15.129e-09;  
   };

There can be as many structs of this kind as there are particle types in the system.
Organizing the data like this is not strictly necessary, but is shown for the purpose of clarity.
As shown here, there can be multiple particles that correspond to a single element as atomic mass can vary by molecular context.
For example, the carbon atom in a carboxyl group would have different parameters from one in the methyl group.
We can obtain the parameter set from any standard force-field, or generate new parameters to study new compounds or force fields.
This example comes from the `2016H66 Parameter Set <https://pubs.acs.org/doi/10.1021/acs.jctc.6b00187>`__.

Defining Coordinates, Velocities and Force Buffers
--------------------------------------------------

.. code:: cpp

   std::vector<gmx::RVec> coordinates = {
       { 0.794, 1.439, 0.610 }, { 1.397, 0.673, 1.916 }, { 0.659, 1.080, 0.573 },
       { 1.105, 0.090, 3.431 }, { 1.741, 1.291, 3.432 }, { 1.936, 1.441, 5.873 },
       { 0.960, 2.246, 1.659 }, { 0.382, 3.023, 2.793 }, { 0.053, 4.857, 4.242 },
       { 2.655, 5.057, 2.211 }, { 4.114, 0.737, 0.614 }, { 5.977, 5.104, 5.217 },
   };

   std::vector<gmx::RVec> velocities = {
       { 0.0055, -0.1400, 0.2127 }, { 0.0930, -0.0160, -0.0086 }, { 0.1678, 0.2476, -0.0660 },
       { 0.1591, -0.0934, -0.0835 }, { -0.0317, 0.0573, 0.1453 }, { 0.0597, 0.0013, -0.0462 },
       { 0.0484, -0.0357, 0.0168 }, { 0.0530, 0.0295, -0.2694 }, { -0.0550, -0.0896, 0.0494 },
       { -0.0799, -0.2534, -0.0079 }, { 0.0436, -0.1557, 0.1849 }, { -0.0214, 0.0446, 0.0758},
   };

   std::vector<gmx::RVec> forces = {
       { 0.0000, 0.0000, 0.0000 }, { 0.0000, 0.0000, 0.0000 }, { 0.0000, 0.0000, 0.0000 },
       { 0.0000, 0.0000, 0.0000 }, { 0.0000, 0.0000, 0.0000 }, { 0.0000, 0.0000, 0.0000 },
       { 0.0000, 0.0000, 0.0000 }, { 0.0000, 0.0000, 0.0000 }, { 0.0000, 0.0000, 0.0000 },
       { 0.0000, 0.0000, 0.0000 }, { 0.0000, 0.0000, 0.0000 }, { 0.0000, 0.0000, 0.0000 },
   };

We can initialize coordinates for our particles using ``std::vector`` of ``gmx::RVec`` which is a specific data type for holding 3D vector quantities. `Doxygen page on RVec here`__.

  __ doxygen-ref-rvec_

Writing the MD Program
----------------------

As with as any basic C++ program, there needs to be a ``main()`` function.


Define ParticleTypes
~~~~~~~~~~~~~~~~~~~~

.. code:: cpp

   int main()
   {
       // Bring the parameter structs to scope
       OwAtom      owAtom;
       HwAtom      hwAtom;
       CMethAtom   cmethAtom;
       HcAtom      hcAtom;
     
       // Create the particles
       ParticleType Ow(owAtom.name, owAtom.mass);
       ParticleType Hw(hwAtom.name, hwAtom.mass);
       ParticleType Cm(cmethAtom.name, cmethAtom.mass);
       ParticleType Hc(hcAtom.name, hcAtom.mass);

As before, the helper struct to define ``ParticleType`` data is not strictly needed, but is shown for clarity.
The line ``ParticleType CMethAtom(ParticleName("Cm"), Mass(12.0107));`` would be sufficient.

Define Non-Bonded Interactions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code:: cpp

   ParticleTypeInteractions interactions(CombinationRule::Geometric);

   // add non-bonded interactions for the particle types
   interactions.add(owAtom.name, owAtom.c6, owAtom.c12);
   interactions.add(hwAtom.name, hwAtom.c6, hwAtom.c12);
   interactions.add(cmethAtom.name, cmethAtom.c6, cmethAtom.c12);
   interactions.add(hcAtom.name, hcAtom.c6, hcAtom.c12);

For the Lennard-Jones interactions, we define a ``ParticleTypeInteractions`` object.
Each particle of the ``ParticleType`` interacts with each other based on the ``C6`` and ``C12`` parameters.
These parameters of the two different particles are averaged using ``Geometric`` or ``LorentzBerthelot`` ``CombinationRule``.
More details `here <http://manual.gromacs.org/documentation/2019/reference-manual/functions/nonbonded-interactions.html#the-lennard-jones-interaction>`__.
By default ``CombinationRule::Geometric`` is selected.

We add the interaction parameters of each of the particle types into the ``ParticleTypeInteractions`` object.
The result is a table that has interactions specified for all ``ParticleType`` pairs.
The following matrix describes the pair-wise C6 parameter created using ``CombinationRule::Geometric``.

== ====== === ======= =======
#  Ow     Hw  Cm      Hc
== ====== === ======= =======
Ow 0.0026 0.0 0.42    4.7e-4
Hw 0.0    0.0 0.0     0.0
Cm 0.42   0.0 0.013   1.05e-3
Hc 4.7e-4 0.0 1.05e-3 8.5e-5
== ====== === ======= =======

For a particular interaction pair, the user can also override the specified ``CombinationRule`` with custom parameters.
The following overload would replace the parameters computed from a ``CombinationRule``  between ``Ow`` and ``Cm`` particle types.

.. code:: cpp

   interactions.add("Ow", "Cm", 0.42, 42e-6);

To facilitate modular, reusable code, it is possible to combine multiple ``ParticleTypeInteractions`` objects.
Assuming ``otherInteractions`` is defined, this can be done with ``interactions.merge(otherInteractions)``

Define Molecules
~~~~~~~~~~~~~~~~

.. code:: cpp

   Molecule water("Water");
   Molecule methane("Methane");

   water.addParticle(ParticleName("O"), Ow);
   water.addParticle(ParticleName("H1"), Hw);
   water.addParticle(ParticleName("H2"), Hw);

   water.addExclusion("H1", "O");
   water.addExclusion("H2", "O");

   methane.addParticle(ParticleName("C"), Cm);
   methane.addParticle(ParticleName("H1"), Hc);
   methane.addParticle(ParticleName("H2"), Hc);
   methane.addParticle(ParticleName("H3"), Hc);
   methane.addParticle(ParticleName("H4"), Hc);

   methane.addExclusion("H1", "C");
   methane.addExclusion("H2", "C");
   methane.addExclusion("H3", "C");
   methane.addExclusion("H4", "C");

We begin declaring molecules with their constituent particles.
A string identifier must uniquely identify a specific particle within the molecule.
It is also possible to define partial charges on each particle for the computation of Coulomb interactions.
``water.addParticle(ParticleName("O"), Charge(-0.04), Ow);``

Adding exclusions ensures that non-bonded interactions are only computed when necessary.
For example, if two  particles share a bond, the potential energy of the bond makes the non-bonded term negligible.
Particle self-exclusions are enabled by default.
We use the unique identifiers specified during ``addParticle()`` for this and the listed interactions later.

Define Listed Interactions
~~~~~~~~~~~~~~~~~~~~~~~~~~

Within a molecule, one can define interactions such as bonds, angles and dihedrals between the constituent particles.
NB-LIB provides concrete implementations of several commonly used 2, 3 and 4 center interactions.

.. code:: cpp

   HarmonicBondType ohHarmonicBond(1, 1);
   HarmonicBondType hcHarmonicBond(2, 1);

   DefaultAngle hohAngle(Degrees(120), 1);
   DefaultAngle hchAngle(Degrees(109.5), 1);

   //add harmonic bonds for water
   water.addInteraction("O", "H1", ohHarmonicBond);
   water.addInteraction("O", "H2", ohHarmonicBond);

   // add the angle for water
   water.addInteraction("H1", "O", "H2", hohAngle);

   // add harmonic bonds for methane
   methane.addInteraction("H1", "C", hcHarmonicBond);
   methane.addInteraction("H2", "C", hcHarmonicBond);
   methane.addInteraction("H3", "C", hcHarmonicBond);
   methane.addInteraction("H4", "C", hhcHarmonicBondc);

   // add the angles for methane
   methane.addInteraction("H1", "C", "H2", hchAngle);
   methane.addInteraction("H1", "C", "H3", hchAngle);
   methane.addInteraction("H1", "C", "H4", hchAngle);
   methane.addInteraction("H2", "C", "H3", hchAngle);
   methane.addInteraction("H2", "C", "H4", hchAngle);
   methane.addInteraction("H3", "C", "H4", hchAngle);

Define Options for the Simulation and Non-Bonded Calculations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code:: cpp

   // Define a box for the simulation
   Box box(6.05449);

   // Define options for the non-bonded kernels
   NBKernelOptions options;

One can define the bounding box either with a single argument for a cube and 3 arguments to specify length, breadth and height separately.

``NBKernelOptions`` contains a set of flags and configuration options for both hardware context and the relevant calculations for the simulation.
The following table describes the possible options that can be set.

+----------------------+------+---------------------------------------+
| Flag or Config       | Type | Implications                          |
| Option               |      |                                       |
+======================+======+=======================================+
| ``useGpu``           | Bool | Use GPU for non-bonded computations   |
|                      | ean  |                                       |
+----------------------+------+---------------------------------------+
| ``numThreads``       | Inte | Number of CPU threads to use          |
|                      | ger  |                                       |
+----------------------+------+---------------------------------------+
| ``nbnxmSimd``        | Enum | Kernel SIMD type                      |
|                      |      | (``SimdAuto``/``SimdNo``/``Simd4XM``/ |
|                      |      | ``Simd2XMM``)                         |
+----------------------+------+---------------------------------------+
| ``ljCombination      | Enum | Lennard-Jones combination rule        |
| Rule``               |      | (``Geometric``/``LorentzBerthelot``)  |
+----------------------+------+---------------------------------------+
| ``useHalfLJOptimizat | Bool | Enable i-cluster half-LJ optimization |
| ion``                | ean  |                                       |
+----------------------+------+---------------------------------------+
| ``pairlistCutoff``   | Real | Specify pairlist and interaction      |
|                      |      | cut-off                               |
+----------------------+------+---------------------------------------+
| ``computeVirialAndEn | Bool | Enable energy computations            |
| ergy``               | ean  |                                       |
+----------------------+------+---------------------------------------+
| ``coulombType``      | Enum | Coulomb interaction function          |
|                      |      | (``Pme``/``Cutoff``/``ReactionField`` |
|                      |      | )                                     |
+----------------------+------+---------------------------------------+
| ``useTabulatedEwaldC | Bool | Use tabulated PME grid correction     |
| orr``                | ean  | instead of analytical                 |
+----------------------+------+---------------------------------------+
| ``numIterations``    | Inte | Specify number of iterations for each |
|                      | ger  | kernel                                |
+----------------------+------+---------------------------------------+
| ``cyclesPerPair``    | Bool | Enable printing cycles/pair instead   |
|                      | ean  | of pairs/cycle                        |
+----------------------+------+---------------------------------------+
| ``timestep``         | Real | Specify the time step                 |
+----------------------+------+---------------------------------------+

Define Topology and Simulation State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We build the system topology using the ``TopologyBuilder`` class.
We add the ``Molecule`` objects that we defined previously along with the ``ParticleTypesInteractions`` using its public functions.
We get the actual ``Topology`` object complete with all exclusions, interaction maps and listed interaction data constructed based on the defined entities using the ``buildTopology()``\ function.

.. code:: cpp

   TopologyBuilder topologyBuilder;

   // add molecules
   topologyBuilder.addMolecule(water, 10);
   topologyBuilder.addMolecule(methane, 10);

   // add non-bonded interaction map
   topologyBuilder.addParticleTypesInteractions(interactions);

   Topology topology = topologyBuilder.buildTopology();

We now have all we need to fully describe our system using the ``SimulationState`` object.
This is built using the topology, the box, and the particle coordinates and velocities.
This object serves as a snapshot of the system that can be used for analysis or to start simulations from known states.

.. code:: cpp

   SimulationState simulationState(coordinates, velocities, forces, box, topology);



Writing the MD Loop
~~~~~~~~~~~~~~~~~~~

Now that we have fully described our system and the problem, we need two entities to write an MD loop.
The first is the ``ForceCalculator`` and the second is an Integrator.
NB-LIB comes with a ``LeapFrog`` integrator but it is also possible for users to write custom integrators.

.. code:: cpp

   // The force calculator contains all the data needed to compute forces
   ForceCalculator forceCalculator(simulationState, options);

   // Integration requires masses, positions, and forces
   LeapFrog integrator(simulationState);

   // Allocate a force buffer
   gmx::ArrayRef<gmx::RVec> userForces(topology.numParticles());

   // MD Loop
   int numSteps = 100;

   for (i = 0; i < numSteps; i++)
   {
     userForces = forceCalculator.compute();

     // The forces are not automatically updated in case the user wants to add their own
     std::copy(userForces.begin(), userForces.end(), begin(simulationState.forces()));

     // Integrate with a time step of 1 fs
     integrator.integrate(1.0);
   }

   return 0;
   } // main

.. _doxygen-ref-rvec: ../doxygen/html-lib/namespacegmx.xhtml#a139c1919a9680de4ad1450f42e37d33bDesign goals and motivation for the data format of bonded forces in NB-LIB
--------------------------------------------------------------------------


The current format for listed forces in GROMACS looks like this:

.. code:: cpp

   struct InteractionDefinitions
   {
       std::vector<t_iparams> iparams;
       std::array<std::vector<int>, F_NRE> il;
   };

The format covers all interaction types, i.e. \ ``t_iparams`` is a union
type which can hold the parameters of any type.
The other member called ``il`` contains the
indices for each interaction type, where ``F_NRE`` is the number of
interaction types that GROMACS supports. More precisely, each
member of ``il``, a ``std::vector<int>``, is a flattened list of all
interactions for a given interaction type. The vector contains ``N+1`` integer indices
for each interaction, where ``N`` is the number of particles that are
involved in the interaction. An additional index is needed to retrieve
the correct parameters in ``iparams``, hence the total number of indices sums up
to ``N+1`` per interaction.

The big advantage of storing all types in a union data type is (was),
that it allows looping over all types with a simple for-loop.
In pre C++11 and perhaps even pre C++14 times, looping over different
types was a big hassle and the union data type approach likely was the
only practicable solution. One downside of this approach, however, is
that with just a single (union) type, one can't leverage the compiler's
type system, most importantly static branching, for example with overload resolution.
As a consequence, only dynamic branching with ``if`` statements remains.

Consider, for instance, the implementation of the top-level
``calc_listed(const InteractionDefinitions& idef, ...)`` in GROMACS, which in its essence,
looks like this:

.. code:: cpp

   void calc_listed(const InteractionDefinitions& idef, ...)
   {
       // manage timing and multi-threading 

       for (int ftype = 0; ftype < F_NRE; ++type)
       {
           // branch out and descend stack for 2 intermediate functions based on
           // the type of interaction that ftype corresponds to
           // then call a function from a pointer table

           bondFunction* bonded = bondedInteractionFunctions[ftype]; 

           // compute all forces for ftype
           bonded(idef.iparams, idef.il[ftype], ...);
       }

       // reduce thread output
   }

GROMACS supports a lot of different listed interaction types, such as different
types of bonds, angles and proper and improper dihedrals. These different types
require different handling and finally the right force kernel chosen from a table
of function pointers.
The handling code required to correctly branch out to all the different cases
results in quite a deep call stack, a lot of branching logic and ends up accounting
for a fair part of the overall complexity, which should ideally just consist of
the type-specific force calculation implementations.


A type-aware approach to listed forces
--------------------------------------

NB-LIB aims to reduce the overall code complexity with a type-aware data format
where each interaction type is implemented as a separate (C++)-type.
The format for a given interaction type looks like this:

.. code:: cpp

   template <class Interaction>
   struct InteractionData
   {
       std::vector<Index<Interaction>> indices;
       std::vector<Interaction>        parameters;
   };

For each type of interaction, we store the interaction indices plus the
interaction parameters. While the (C++)-types are different, the actual data stored is
exactly the same: ``N+1`` integer indices per ``N``-center interaction plus the unique parameters.
An example for ``Interaction`` would be ``HarmonicBond``, the public part of which looks like this:

.. code:: cpp

   class HarmonicBond
   {
   public:
       // return lvalue ref for use with std::tie
       // in order to leverage std::tuple comparison ops
       const real& forceConstant();
       const real& equilDistance();
   };

The ``Index`` traits class deduces to ``std::array<int, 3>``, because
for each harmonic bond, we need two ``int``\ s for the coordinate
indices and a third ``int`` to look up the bond parameters in the
``parameters`` vector. For angles and dihedrals, the ``Index`` trait
would add an additional one or two ``int``\ s to hold the additional
coordinate indices.

Finally, we gather all types of interactions in a
``std::tuple``, such that the complete definition for listed forces
in NB-LIB looks like this:

.. code:: cpp

   using ListedInteractions = std::tuple<InteractionData<HarmonicBond>, ..., InteractionData<HarmonicAngle>, ...>;

One important property of ``ListedInteractions`` is that it stores exactly the same information as ``InteractionDefinitions``
and therefore conversion in either direction is easy to implement.


The NB-LIB listed forces pipeline
---------------------------------

Given the listed interaction data provided in the format described above,
the steps required to calculate the corresponding forces
are, in brief: 

  * Loop over all interaction types
  * Loop over all interactions for given type
  * Call interaction type kernel, store forces and return energy


This procedure is identical to the current implementation in GROMACS.
In actual code, the first step looks like this:

.. code:: cpp

   template<class Buffer, class Pbc>
   auto reduceListedForces(const ListedInteractions& interactions,
                           const std::vector<gmx::RVec>& x,
                           Buffer* forces,
                           const Pbc& pbc)
   {
       std::array<real, std::tuple_size<ListedInteractions>::value> energies;

       // lambda function, will be applied to each type
       auto computeForceType = [forces, &x, &energies, &pbc](const auto& ielem) {
           real energy = computeForces(ielem.indices, ielem.parameters, x, forces, pbc);
           energies[FindIndex<std::decay_t<decltype(ilem)>, ListedInteractions>{}] = energy;
       };

       // apply the lambda to all bond types
       for_each_tuple(computeForceType, interactions);

       return energies;
   }

With the help of a generic lambda and C++17’s ``std::apply`` in the
one-liner ``for_each_tuple``, we can generate the loop over the
different types in the tuple quite effortlessly. While
``reduceListedForces`` implements a loop over the interaction types, the
next layer, ``computeForces`` implements a loop over all interactions of
a given type:

.. code:: cpp

   template <class Index, class InteractionType, class Buffer, class Pbc>
   real computeForces(const std::vector<Index>& indices,
                      const std::vector<InteractionType>& iParams,
                      const std::vector<gmx::RVec>& x,
                      Buffer* forces,
                      const Pbc& pbc)
   {
       real Epot = 0.0;

       for (const auto& index : indices)
       {
           Epot += dispatchInteraction(index, iParams, x, forces);
       }

       return Epot;
   }

Compared to the union data type approach where this loop has been manually
implemented for all interaction types, in NB-LIB, only a single implementation
is required.

We’re now down to the level of individual bonds, angles and dihedrals.
At this point, the next steps depend on the actual type of the
interaction. But instead of dispatching each harmonic bond, cubic bond,
harmonic angle and so on to their seperate paths just yet, we just
differentiate based on the number of interaction centers for now.
Through overload resolution, the appropriate version
``dispatchInteraction`` gets called now, such as this one for the case
of 2-center interactions:

.. code:: cpp

   template <class Buffer, class TwoCenterType, class Pbc>
   std::enable_if_t<IsTwoCenter<TwoCenterType>::value, real>
   dispatchInteraction(const InteractionIndex<TwoCenterType>& index,
                       const std::vector<TwoCenterType>& bondInstances,
                       const std::vector<gmx::RVec>& x,
                       Buffer* forces,
                       const Pbc& pbc)
   {
       int i = std::get<0>(index);
       int j = std::get<1>(index);
       const gmx::RVec& x1 = x[i];
       const gmx::RVec& x2 = x[j];
       const TwoCenterType& bond = bondInstances[std::get<2>(index)];

       gmx::RVec dx;
       // calculate x1 - x2 modulo pbc
       pbc.dxAiuc(x1, x2, dx);
       real dr2 = dot(dx, dx);
       real dr  = std::sqrt(dr2);

       auto [force, energy] = bondKernel(dr, bond);

       // avoid division by 0
       if (dr2 != 0.0)
       {
           force /= dr;
           detail::spreadTwoCenterForces(force, dx, &(*forces)[i], &(*forces)[j]);
       }

       return energy;
   }

We can again observe that common parts among different 2-center interaction types
are reused. The common parts are 

 * coordinate retrieval
 * computation of the scalar distance
 * spreading of the scalar part of the force to the two centers

The only remaining thing to do now is to call the actual
kernel to compute the force. Since ``bond`` has a distinct type, we can
again use overload resolution:

.. code:: cpp

   template <class T>
   auto bondKernel(T dr, const HarmonicBond& bond)
   {
       return harmonicScalarForce(bond.forceConstant(), bond.equilDistance(), dr);
   }

and call the actual kernel, which in its simplest form for a harmonic
bond looks like this:

.. code:: cpp

   template <class T>
   std::tuple<T, T> harmonicScalarForce(T k, T x0, T x)
   {
       real dx  = x - x0;
       real dx2 = dx * dx;

       real force = -k * dx;
       real epot = 0.5 * k * dx2;

       return std::make_tuple(force, epot);

       /* That was 6 flops */
   }

That’s it! The approach outlined here manages to reuse (between different types)
a significant part of the code that feeds input data to force kernels.
Notably, not a single ``if(ftype)`` is required to implement the control flow.
The remaining parts for a feature complete implementation are
overloads of ``dispatchInteraction`` for the 3- to 5-center interactions and
the type-aware wrappers for all the different kernels implemented in
GROMACS. They have been omitted for brevity.

A note on **multithreading**: multithreading is handled above the top-level
``reduceListedForces`` described here. For parallel execution, the
input ``ListedInteractions`` tuple is split into ``nThreads`` parts and a
``Buffer`` object is set up for each thread. ``reduceListedForces`` is then
called once by each thread with the assigned fraction of ``ListedInteractions``
and the ``Buffer`` as argument.
The lifetime of the ``ListedInteractions`` splits is coupled to the domain decomposition.

Summary
-------

NB-LIB listed forces employs a (C++)-type aware data format that
is otherwise equivalent to its counter-part in GROMACS.
The type-aware data format is then used to simplify the "routing" layer that
connects data input to the appropriate kernels. Thanks to static branching and polymorphism,
increased code reuse and simplified branching logic could be achieved.
**The force kernels themselves do not need to be changed and NB-LIB refers to
GROMACS for their implementation.**


Outlook
-------

The data flow management for listed forces described here allows further
improvements to be implemented:

* Aggregate interaction types: fuse interactions of different types into
  aggregated types. For example, a dihedral interaction and the bonds and angles
  that are present among the same four particle indices can be combined into a single
  aggregated interaction. This allows to reuse the particle coordinates loaded from memory
  for multiple types and also combines the store operations for the forces.
  Type aggregates also likely simplify an efficient GPU implementation of listed forces.

* Separation of a topology containing both parameter sets for a system state A and B into two
  separate topologies for the A and B system states.
.. _release-notes:

Release notes
=============

These release notes record the changes made in all major and patch
releases of |Gromacs|. Major releases contain changes to the
functionality supported, whereas patch releases contain only fixes for
issues identified in the corresponding major releases.

Two version series of |Gromacs| are under active maintenance and
within support lifetime at any time. In 2023, they are the 2023 series
and the 2022 series. In the latter, only highly conservative fixes
will be made, and only to address issues that affect scientific
correctness. Naturally, some of those releases will be made after the
year 2022 ends, but we keep the year of the original release in the
version name so that users understand how up to date their version
is. Such fixes will also be incorporated into the more recent release
series, as appropriate. Around the time the 2024 release is made, the
2022 series will no longer be maintained.

Where issue numbers are reported in these release notes, more details
can be found on the `issue tracker`_ at that issue number.

|Gromacs| 2023 series
---------------------

.. todolist::

Patch releases
^^^^^^^^^^^^^^
.. toctree::
   :maxdepth: 1

   2022/2022.1


Major release
^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2023/major/highlights
   2023/major/features
   2023/major/performance
   2023/major/api
   2023/major/tools
   2023/major/bugs-fixed
   2023/major/deprecated-functionality
   2023/major/removed-functionality
   2023/major/portability
   2023/major/miscellaneous


|Gromacs| 2022 series
---------------------

Major release
^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2022/major/highlights
   2022/major/features
   2022/major/performance
   2022/major/api
   2022/major/tools
   2022/major/bugs-fixed
   2022/major/deprecated-functionality
   2022/major/removed-functionality
   2022/major/portability
   2022/major/miscellaneous


Older (unmaintained) |Gromacs| series
-------------------------------------------------------

|Gromacs| 2021 series
---------------------

Patch releases
^^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2021/2021.5
   2021/2021.4
   2021/2021.3
   2021/2021.2
   2021/2021.1


Major release
^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2021/major/highlights
   2021/major/features
   2021/major/performance
   2021/major/tools
   2021/major/bugs-fixed
   2021/major/deprecated-functionality
   2021/major/removed-functionality
   2021/major/portability
   2021/major/miscellaneous


|Gromacs| 2020 series
---------------------

Patch releases
^^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2020/2020.7
   2020/2020.6
   2020/2020.5
   2020/2020.4
   2020/2020.3
   2020/2020.2
   2020/2020.1

Major release
^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2020/major/highlights
   2020/major/features
   2020/major/performance
   2020/major/tools
   2020/major/bugs-fixed
   2020/major/deprecated-functionality
   2020/major/removed-functionality
   2020/major/portability
   2020/major/miscellaneous


|Gromacs| 2019 series
---------------------

Patch releases
^^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2019/2019.6
   2019/2019.5
   2019/2019.4
   2019/2019.3
   2019/2019.2
   2019/2019.1

Major release
^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2019/major/highlights
   2019/major/features
   2019/major/performance
   2019/major/tools
   2019/major/bugs-fixed
   2019/major/deprecated-functionality
   2019/major/removed-functionality
   2019/major/portability
   2019/major/miscellaneous

|Gromacs| 2018 series
---------------------

Patch releases
^^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2018/2018.7
   2018/2018.6
   2018/2018.5
   2018/2018.4
   2018/2018.3
   2018/2018.2
   2018/2018.1

Major release
^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2018/major/highlights
   2018/major/features
   2018/major/performance
   2018/major/tools
   2018/major/bugs-fixed
   2018/major/removed-features
   2018/major/portability
   2018/major/miscellaneous

|Gromacs| 2016 series
---------------------

Patch releases
^^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2016/2016.5
   2016/2016.4
   2016/2016.3
   2016/2016.2
   2016/2016.1


Major release
^^^^^^^^^^^^^

.. toctree::
   :maxdepth: 1

   2016/major/highlights
   2016/major/new-features
   2016/major/performance
   2016/major/tools
   2016/major/bugs-fixed
   2016/major/removed-features
   2016/major/miscellaneous


.. toctree::
   :maxdepth: 1

   older/index
GROMACS 2021.6 release notes
----------------------------

This version was released on TODO, 2022. These release notes
document the changes that have taken place in GROMACS since the
previous 2021.5 version, to fix known issues. It also incorporates all
fixes made in version 2020.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Extend error message for free-energy exclusion beyond rlist
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With free-energy decoupling simulations an error for exclusions beyond rlist
can occur due to a too small box. This cause is now added to the error
message.

:issue:`3403`
:issue:`3808`

Fix running with LJ PME only
""""""""""""""""""""""""""""

Simulations with only LJ PME but not electrostatic PME would fail to run due
to an error in task assignment.

:issue:`4362`

Fix missing synchronization in CUDA update kernels
""""""""""""""""""""""""""""""""""""""""""""""""""

When using GPU update with SETTLE or LINCS constraints, virial calculations
could have been incorrect on Volta and newer NVIDIA GPUs, which in turn
would lead to incorrect pressure. The GPU update is not enabled by default,
so the error can only appear in simulations where it was manually selected,
and even in this case the error might be rare since we have not observed it
in practice in the testing we have performed.

To check whether your runs could have been affected, please examine your mdrun log file:

- Look for the line "GPU support:        CUDA";
- Look for the line "PP task will update and constrain coordinates on the GPU";
- Check whether any GPU the value of "compute cap." 7.0 or higher in the "GPU Info:" section.

If all three are present, than the bug could have perturbed the virial calculation and,
in turn, led to incorrect pressure coupling. All |Gromacs| version prior to 2021.6 and 2022.0
that allow offloading of the update and constraint calculations to GPUs are affected.

:issue:`4393`


Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Do not try to guess atom names in ``gmx rms`` unless needed
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Guessing atomic masses based on atom names may sometimes fail.
When ``-nomw`` switch is used, atom masses are not needed, but ``gmx rms``
was trying to guess them anyway, throwing a fatal error when an unknown 
element was encountered. Now, the error is only raised when masses are
actually needed.

:issue:`4356`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^

Corrects units for AWH interval in the user guide
"""""""""""""""""""""""""""""""""""""""""""""""""

When applying AWH to angles or dihedrals, the units of bonds of the sampling
interval listed in the mdp section of the user guide are now stated to be
in degrees. The guide incorrectly stated that there were in radians, whereas
the code interprets the user input as degrees.

:issue:`4367`

Fix distance restraint force calculation in case of negative prefactor
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When calculating distance restraint forces, the quadratic regime for weak
restraint violation and the linear regime for strong restraint violation were
interchanged in case of a negative force constant.

:issue:`4347`

GROMACS 2021.5 release notes
----------------------------

This version was released on January 14th, 2022. These release notes
document the changes that have taken place in GROMACS since the
previous 2021.4 version, to fix known issues. It also incorporates all
fixes made in version 2020.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Do not scale coordinates of frozen atoms during Parrinello-Rahman pressure coupling
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When Parrinello-Rahman pressure coupling was used, the box scaling was applied to all the atoms,
causing frozen atoms to shift. The effect is more drastic towards the sides of the box and when the
pressure is changed significantly during the simulations. Now, the frozen atoms will be ignored by
the coupling and atoms with frozen dimensions shall keep such values.

:issue:`3075`

Properly account for DeltaH contribution from PME when running AWH with FEP
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The linear dHdL contribution from PME, when PME was calculated on GPU or on a separate PME
rank, was calculated too late to be taken into account for FEP steered by AWH.
Please verify your simulation results from simulations running FEP steered by AWH
with PME on GPU or using a separate PME rank.

:issue:`4294`

Fix reading of AWH user PMF reading with large PMF values
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""
 
The reading of user supplied AWH input in mdrun with PMF values larger than
88 kT would cause mdrun to exit with an assertion failure. Now values up to
700 kT are allowed and exceeding those causes an exit with a clear error message.

:issue:`4299`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

``gmx make_edi`` now closes its output file properly
""""""""""""""""""""""""""""""""""""""""""""""""""""

Previously the file was not closed explicitly, leaving the result up
to the runtime environment. Now it will work with all environments.

Out-of-bounds, overflow and incorrect outputs fixes in ``gmx spatial``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

There were several issues with memory management in ``gmx spatial``, which were addressed:
1. Out-of-bound memory writes.
2. Confusing error message when the coordinate is exactly on the boundary (happens with .xtc files).
3. Norm could become negative due to integer overflow.
4. Having negative ``-ign`` (default ``-1``) led to incorrect number of grid points
5. The coordinates of the grid points were incorrect especially when ``-ign`` is non-zero.
6. Norm calculation was incorrect.
7. Default ``-nab`` value is increased from 4 to 16.

:issue:`3214`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^
Performance improvements when running on Ampere-class Nvidia GPUs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Improved performance of the short-ranged non-bonded kernels by up to 12%.

:issue:`3873`

GROMACS 2021.1 release notes
----------------------------

This version was released on March 8th, 2021. These release notes
document the changes that have taken place in GROMACS since the
previous 2021 version, to fix known issues. It also incorporates all
fixes made in version 2020.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix MiMiC with virtual sites
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

It is likely that MiMiC with virtual sites has not worked
correctly because the call to construct the sites was placed
after the call that uses the sites. Now it should work, but we have not tested that it does.

:issue:`3866`

Fix mass perturbation to dH/dlambda
"""""""""""""""""""""""""""""""""""

The contribution for perturbed mass was missing in dH/dlambda.
Note that this contribution was not missing from the foreign energy
differences used for the Bennett acceptance ratio method.

:issue:`3943`

Running AWH with a convolved potential and an FEP dimension gives wrong results.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The output PMF is wrong when using awh-potential = convolved with a
pull dimension combined with an FEP dimension. The FEP dimension
always uses an umbrella potential and the combination does not work
properly. This has been disabled in grompp.

:issue:`3946`

Remove velocity from partially frozen atoms in md-vv
""""""""""""""""""""""""""""""""""""""""""""""""""""

md-vv would add some velocity to the frozen dimensions of partially
frozen atoms during constraining. This did not lead to wrong
trajectories, as the frozen dimensions of the positions are kept fixed
during propagation. The non-zero velocities were, however, reported in
trajectories and final configurations. They might also have lead to
slightly wrong kinetic energies, since the reported kinetic energy is
calculated after the velocities are constrained. All effects are
expected to be relatively small, since they did not accumulate, as the
velocities were regularly reset to zero once per step.

:issue:`3849`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix periodic boundary conditions in analysis framework tools
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

There was a bug in the trajectory analysis framework which caused
molecules that were broken over PBC not to be made whole. This would
usually lead to obviously incorrect outliers in analysis output.

:issue:`3900`

Fix range checking bug in ``gmx covar``
"""""""""""""""""""""""""""""""""""""""

A check was inverted causing range checking to be applied wrong.

:issue:`3902`

Fix various bugs in ``gmx xpm2ps``
""""""""""""""""""""""""""""""""""

Numerous minor issues were introduced in refactoring since
|Gromacs| 5.1, now fixed.

:issue:`3881`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed compilation on Cygwin
"""""""""""""""""""""""""""

A |Gromacs| header file was not including the necessary standard
header. A problem with the ``M_PI`` math constant defined only by
POSIX and not by C++ was also worked around.

:issue:`3890`

Improve grompp checks of AWH settings when sampling an FEP dimension
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Ensure that the AWH sampling interval is compatible with nstcalcenergy
when sampling an FEP dimension using AWH. This avoids crashes in the
first AWH sampling step (step > 0) if the settings were not correct.

:issue:`3922`

Miscellaneous
^^^^^^^^^^^^^
* Updated |Gromacs| logos
GROMACS 2021.2 release notes
----------------------------

This version was released on May 5th, 2021. These release notes
document the changes that have taken place in GROMACS since the
previous 2021.1 version, to fix known issues. It also incorporates all
fixes made in version 2020.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Removed a potential race condition with GPU update
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed possible (but so far unobserved) race condition in coordinate copy when
using GPU update with dipole moment calculation.

:issue:`4024`

Avoided issues with global reduction observed with md-vv
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The new implementation for md-vv in the modular simulator could
produce floating-point exceptions computing values on non-master ranks
that were never used. This is now fixed by avoiding that
computation. The other integrators were unaffected because they
over-wrote the values computed.

:issue:`4031`

Prohibited SETTLE interactions for atoms with perturbed masses
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Older implementations produced varying degrees of wrong results because
this has never been implemented. Now both ``mdrun`` and ``grompp``
refuse to handle such a system, suggesting using normal constraints.

:issue:`3959`

Rerun now writes pull output correctly
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Refactoring omitted to preserve that pullf.xvg and pullx.xvg files
should be written during a rerun. All 2019 and 2020 versions were
affected, as well as 2021 and 2021.1. The pull output files are
now written as they used to be in 2018 and earlier.

:issue:`4043`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix incorrect behaviour with single residue chains in pdb2gmx
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The code for chcking for cyclic molecules could lead to single residue chains
incorrectly to be assigned as circular molecules.

:issue:`4029`

Fix grompp check for position restraints with absolute reference
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed that grompp with position restraints would always issue a warning about
using an absolute reference, even when an absolute reference was not used.

:issue:`3996`

Fix error when using VMD plugin
"""""""""""""""""""""""""""""""

Tools would crash with a C++ library assertion because the plugin loading
code incorrectly tried to construct a string from nullptr.

:issue:`3055`

Fix file permissions with ``gmx solvate`` and ``gmx genion``
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

These used to write temporary files with Unix permissions 0600. Now
they respect the umask of the process (typically 0644).

:issue:`4040`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Support for Intel oneAPI compiler 2021.2
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed compiler infinity math and MKL flags.

Fix Apple OpenCL build
""""""""""""""""""""""

:issue:`4008`

Fixed compilation issue with GCC 11
""""""""""""""""""""""""""""""""""""

:issue:`4039`

Miscellaneous
^^^^^^^^^^^^^

Fix bond type in GROMOS force fields
""""""""""""""""""""""""""""""""""""

The bond type for C and +N in [ACE] was incorrect.

:issue:`3995`


Allow PME on CPU in runs with domain decomposition and GPU update
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Relaxed a limitation which prevented running parallel runs with domain
decomposition and GPU update to use the CPU for PME (as long as combined
PP-PME ranks are used). This allows parallel runs to scale when the CPU
resources are sufficient for PME.

:issue:`4035`
GROMACS 2021.4 release notes
----------------------------

This version was released on November 5th, 2021. These release notes
document the changes that have taken place in GROMACS since the
previous 2021.3 version, to fix known issues. It also incorporates all
fixes made in version 2020.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed crash for large system with virtual sites
"""""""""""""""""""""""""""""""""""""""""""""""

When large system with virtual sites were ran with domain decomposition
and OpenMP threading, mdrun would crash when the number of atoms in
a domain and its halo were more than 200000.

:issue:`4167`

Fixed bug with GPU LINCS occasionally shifting atoms in wrong direction
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Due to missing blocking synchronizations in the CUDA version of LINCS,
the shared memory was occasionally overwritten with the new data. This
may slightly affect the final coordinates of the shifted atoms.

:issue:`4199`

Disabled the use of PME Mixed mode for FEP simulations
""""""""""""""""""""""""""""""""""""""""""""""""""""""

The use of Mixed mode PME (``-pme gpu -pmefft cpu``) led to incorrect
computation of :math:`{\frac{\partial V}{\partial {\lambda}}}` in FEP
simulations.

Mixed mode is only used when explicitly requested by the user.

:issue:`4190`

Fixed spurious nan in AWH free energy output when running FEP with other dimensions
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When running AWH with alchemical free energy perturbations as one of multiple dimensions
the free energy output could contain nan entries due to failing log operations. This did
not affect the AWH bias, which means that the simulations were not affected as such, but
the output was.

:issue:`4180`

Made mdrun work without MPI
"""""""""""""""""""""""""""

When configured with neither of MPI or thread-MPI, mdrun would terminate with an
assertion failure.

:issue:`4264`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix ``gmx convert-tpr -s -o``
"""""""""""""""""""""""""""""

Formerly, this combination could be used when supplying an index file.
Now this combination can also be used with default index groups when
not supplying an index file.

grompp now prints a note again when combining center of mass motion removal and position restraints
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`4128`

Static selections of large index groups now work
""""""""""""""""""""""""""""""""""""""""""""""""

Commands like ``gmx distance -f traj.xtc -n ndx.ndx -select "group
\"Contacts\""`` only worked if the size of ``Contacts`` was less than
the number of atoms. This restriction was a bug, and has been fixed so
that ``Contacts`` make take any size.

Other similar uses of static selections derived from index groups will
also now work.

:issue:`4148`

Static selections of index groups with repeated indices now work
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Static groups from index files referenced in selections (e.g. ``gmx
tool -select "group \"Contacts\""``) only worked correctly if they
never had adjacent repeats of the same index within the
group. Repeating the same index can be meaningful e.g. in lists of
inter-atomic distances to analyze with ``gmx distance`` to analyze
``"1 2 2 3"``. Previously, the index group had to be written like
``"2 3 1 2"`` in order to work.

:issue:`4149`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^

Fix a bug affecting re-run gmxapi scripts
"""""""""""""""""""""""""""""""""""""""""

A typo may have prevented gmxapi simulations from continuing from checkpoints
after being interrupted. Fixed in version 0.2.3 of the gmxapi Python package.

:issue:`4267`
GROMACS 2021.3 release notes
----------------------------

This version was released on August 18th, 2021. These release notes
document the changes that have taken place in GROMACS since the
previous 2021.2 version, to fix known issues. It also incorporates all
fixes made in version 2020.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix mdrun -ddorder pp_pme
"""""""""""""""""""""""""

When rank ordering PP-PME, mdrun would deadlock during the initialization
phase.

:issue:`4114`

Fixed gmxapi MD plugin binding
""""""""""""""""""""""""""""""

Molecular Dynamics extension code was not properly handled when added to a
simulation through the gmxapi Python interface.
This meant that restraint potentials would silently fail to be applied with
gmxapi versions >= 0.1.
Updates have been applied internally to gmxapi.

The gmxapi 0.2.2 Python package supports the updated GROMACS API and will
issue errors if a simulation attempts to bind external plugin code with
a compatible-but-broken API (GROMACS 2021 through 2021.2).

Third party code should not need to be updated, but developers will
note an additional "null restraint" in
https://gitlab.com/gromacs/gromacs/-/tree/master/python_packaging/sample_restraint
(for illustration and testing purposes).

:issue:`4078` and :issue:`4102`

Fixed multi-rank restarts from checkpoints written by single-rank simulations
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Currently a single-rank simulation never uses update groups, however a
multi-rank run can do so. This fix ensures that the atoms within
update groups always start in the same periodic image, which was not
guaranteed if the checkpoint was written by a single-rank simulation.

:issue:`4016`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix gmx nmr -viol option
""""""""""""""""""""""""

The tool would previously fail with a cryptic error.
Also enforces that this option is exclusive with other analysis modes.

:issue:`4060`

Fixed gmx dipoles -quad option
""""""""""""""""""""""""""""""

The tool now reports correct values.

:issue:`4080`

Make sure gmx convert-tpr -until works
""""""""""""""""""""""""""""""""""""""

This got broken during reworking the internals of the tool and didn't
calculate the number of remaining steps correctly.

:issue:`4056`

Fixed dihedral transition counting in gmx chi and gmx angle
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When a trajectory of only 1 frame is passed, transition counting is
avoided (formerly it was attempted and crashed).

When a trajectory of multiple frames is passed, transition counting is
correct (formerly it did not take place).

Fixed possible crash in gmx chi histogramming
"""""""""""""""""""""""""""""""""""""""""""""

Formerly an invalid reference to a temporary string was used for a
residue name, which might have caused a crash.

Fixed gmx chi -chi_prod
"""""""""""""""""""""""

Formerly it could crash or produce garbage results when the number of
relevant dihedrals differed from the number of residues
with dihedrals.

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Check that necessary python modules are available
"""""""""""""""""""""""""""""""""""""""""""""""""

The source code validation could otherwise fail a build with cryptic errors.

:issue:`3985`

Ensure that NB-LIB and gmxapi can be build even without tests enabled
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Could otherwise lead to cryptic build errors.

Miscellaneous
^^^^^^^^^^^^^

Removed performance loss in the mdrun domain decomposition
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With 16 or more so-called PP MPI ranks, the domain decomposition
repartitioning could incur large performance overheads due to a sub-optimally
sized hash table. This has now been fixed.

:issue:`4054`
Removed functionality
^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Removed GMX_SCSIGMA_MIN environment variable
""""""""""""""""""""""""""""""""""""""""""""

This was used to reproduce free-energy soft-core behavior of GROMACS versions before 4.5.
Bugs fixed
^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixed exported libgromacs CMake target
""""""""""""""""""""""""""""""""""""""

Update the exported libgromacs CMake target to not depend on non-
existing include paths and add GMX_DOUBLE define to interface
definitions. The target now gets exported into the Gromacs namespace.

:issue:`3468`

Fixed unsolicited changing of atom names in pdb file
""""""""""""""""""""""""""""""""""""""""""""""""""""

Remove functions to change atoms names when reading 
and writing pdb files. This affected naming of
H atoms in particular.

:issue:`3469`

pdb2gmx handles ASPH and GLUH inputs better
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The default is to treat all such residues as the unprotonated form,
and not to try to infer the protonation from the residue name in the
input. Protonated forms are only available via the interactive
selection options. Now pdb2gmx reports when it is converting such
input residues automatically. It also ensures that the output
configuration and topology are naming such residues correctly in both
the default and interactive-selection cases.

:issue:`2480`

Correct excluded perturbed interactions beyond the non-bonded cut-off distance
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With free-energy calculations without coupling of intermolecular interactions,
non-bonded pair interactions at distance longer than the cut-off distance can
be excluded. These interactions would still have PME long-range contributions.
The contributions are now removed. In addition, mdrun will stop with a fatal
error when interactions beyond the pair-list cut-off are present.

:issue:`3403`
:issue:`3808`

Corrected AWH initial histogram size
""""""""""""""""""""""""""""""""""""

The initial histogram size for AWH biases depended (weakly) on the force
constant. This dependence has been removed, which increases the histogram
size by a about a factor of 3. In practice this has only a minor effect
on the time to solution. For multiple dimensions, the histogram size was
underestimated, in particular with a combination of slower and faster
dimensions. The, now simplified, formula for the initial histogram size is
given in the reference manual.

:issue:`3751`

Fixed default for tick-mark spacing in gmx xpm2ps
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

This was inadvertently changed many years ago, leading to the intended
default of automatic tick-mark spacing being replaced with an
unsuitable fixed value.

:issue:`3881`

Fixed LJ Ewald exclusions when used with cut-off electrostatics
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The exclusion forces in CUDA and OpenCL kernels were computed incorrectly
if LJ Ewald was used together with cut-off electrostatics.

:issue:`3840`
Highlights
^^^^^^^^^^

|Gromacs| 2021 was released on January 28th, 2021. Patch releases may
have been made since then, please use the updated versions!  Here are
some highlights of what you can expect, along with more detail in the
links below!

As always, we've got several useful performance improvements, with or
without GPUs, all enabled and automated by default. In addition,
several new features are available for running simulations. We are extremely
interested in your feedback on how well the new release works on your
simulations and hardware. The new features are:

* Support for multiple time stepping, allowing for simple near doubling of simulation speed and is intended to replace the virtual site treatment
* Ability to use stochastic cell rescaling barostat for equilibration and production simulations
* Preliminary support for using SYCL as accelerator framework
* Support for performing free energy perturbation with AWH
* Support PME offloading to GPU for free energy simulations
* Support for ARM SVE and Fujitsu A64FX (contribution by Research Organization for Information Science and Technology (RIST))
* New nonbonded interaction API with NB-LIB (in collaboration with PRACE)
* New |Gromacs| logo!

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!
.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

The core |Gromacs| team wants to let users and downstream developers
know about impending changes so that disruption is minimized. Do get
in touch if you feel something inappropriate is planned!

Deprecated functionality often remains in |Gromacs| for a year or
more, but this should not be relied upon.

.. Note to maintainers!
   The sections below should general copy the contents from the previous major release,
   except where appropriate when code or planning changes have happened.

Changes anticipated to |Gromacs| 2021 functionality
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

``gmx mdrun -membed``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The feature for embedding a protein in a membrane will be retained,
but probably in a different form, such as ``gmx membed``.

``gmx mdrun -rerun``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The feature for computing potential energy quantities from a
trajectory will be retained, but probably in a different form, such as
``gmx rerun`` and ``gmx test-particle-insertion``.

Integrator .mdp options will only contain dynamical integrators
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Energy minimization will be accessed in a differt form, perhaps with
``gmx minimize`` and interpret an .mdp field for which minimizer to
use. Normal-mode analysis may be accessed with e.g. ``gmx
normal-modes``. The command-line help for these tools will then
be better able to document which functionality is supported when.

Much functionality in ``trjconv``, ``editconf``, ``eneconv`` and ``trjcat``
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The functionality in such tools is being separated to make it
available in composable modules, that we plan to make available as
simpler tools, and eventually via the GROMACS API that is under
development.

``gmx do_dssp`` to be replaced
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This tool is deprecated, because it is problematic for some users to
obtain and install a separate DSSP binary, so we plan to replace the
implementation at some point with a native implementation, likely
based upon xssp, and make it available under a new gmx tool name.

Functionality deprecated in |Gromacs| 2021
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

``mdrun -deffnm`` to be removed
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

This functionality is convenient when running very simple simulations,
because it permits grouping of a set of files that then differ only
their suffix. However, it does not work in the wider case of an
``mdrun`` module (or modules) writing multiple ``.xvg`` output
files. The resulting filenames collide. That, and its interaction with
checkpointing and appending, have led to quite a few bug reports.

Because users can use a folder to group files (a standard mechanism
that they understand from experience outside of |Gromacs|), we can
build and test better software for them if we remove the erstwhile
convenience of ``mdrun -deffnm``. Please update your workflows
accordingly.

:issue:`3818`

OpenCL to be removed as a GPU framework
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3818` Work is underway for ports to AMD and Intel GPUs, and it
is likely that those ports will not be based on the current |Gromacs|
OpenCL port. Nvidia GPUs are targeted by the CUDA port, and no changes
are expectd there. The core team can't maintain, test, and extend up
to 4 ports with current resource levels. Since there are no prospects
of an emerging GPU vendor in HPC needing OpenCL support, we will
remove the OpenCL port once AMD and Intel support is established in
other ways.

Intel KNC (MIC) support
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3818` This architecture is nearly extinct in HPC. Note that
KNL support will continue and is not affected by this deprecation.

Sparc64 HPC ACE
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This architecture is nearly extinct in HPC.

Legacy SIMD architecture support
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3818` We occasionally need to extend the |Gromacs| SIMD
framework, and so should slowly remove older architectures that are
difficult or impossible to test. The following implementations are
deprecated and will not support new functionality in future.

* Power 7
* ARMv7 (this platform was deprecated in |Gromacs| 2020)
* x86 MIC (this platform was deprecated in |Gromacs| 2021)
* Sparc64 HPC ACE  (this platform was deprecated in |Gromacs| 2021)

The mdrun-only build of |Gromacs|
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3808` Before |Gromacs| had the ``gmx`` wrapper binary, the
``mdrun`` binary could be built independently of the many other binary
tools that were built by default. That was useful for installing on
compute clusters because dependencies for ``mdrun`` were
minimized. However, we now manage such dependencies better with CMake,
and an mdrun-only build is no longer easier to build. The mdrun-only
build is also harder to test, and introduces complexity into
documenting |Gromacs| and teaching users to use it. So it is time to
remove that build.

Support for version 1 of the hardware locality library ``hwloc``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3818` Version 2 has been supported in |Gromacs| for several
years. The capabilities of newer hardware and hardware-support APIs
are of most interest for |Gromacs| moving forward, so we should
minimize our testing work and encourage clusters to upgrade older
``hwloc`` installations.

Legacy API
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3818` The legacy installed headers have been deprecated for a
while, however we wish to state more broadly that all headers found
within the ``src`` directory tree of |Gromacs| are intended for
internal consumption only, and are thus subject to change without
notice. Further, the form and contents of the ``libgromacs`` library
and related CMake targets may change as we move towards building APIs
and supporting machinery that can be stable and supported in the long
term.

Constant-acceleration MD
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`1354` This has been broken for many years, and will be removed
as nobody has been found with interest to fix it.

Reading .pdo files in ``gmx wham``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The pull code in |Gromacs| before version 4.0 wrote files in ``.pdo``
format. Analyses of such files are likely no longer relevant, and if
they are, using any older GROMACS version will work. ``gmx wham`` will be
simpler to maintain and extend if we no longer support reading
``.pdo`` files.

Functionality deprecated in |Gromacs| 2020
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Support for 32bit architectures
"""""""""""""""""""""""""""""""
:issue:`3252` There are no current or planned large scale resources using 32bit architectures,
and we have no ability to properly test and evaluate them.

Free-energy soft-core power 48
""""""""""""""""""""""""""""""
:issue:`3253` Free-energy soft-core power 48 is almost never used and is therefore deprecated.

Support for Armv7
"""""""""""""""""
:issue:`2990` There are several issues with current code for the architecture, and we don't
have the resources for support and fix issues related to it. As the architecture has no
large HPC impact it is thus deprecated.

Functionality deprecated in |Gromacs| 2019
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generation of virtual sites to replace aromatic rings in standard residues
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3254` These are thought to produce artefacts under some circumstances
(unpublished results), were never well tested, are not widely used,
and we need to simplify pdb2gmx.

Benchmarking options only available with ``gmx benchmark``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3255` Options such as ``-confout``, ``-resethway``, ``-resetstep`` are not
intended for use by regular mdrun users, so making them only available
with a dedicated tool is more clear. Also, this permits us to customize
defaults for e.g. writing files at the end of a simulation part in ways
that suit the respective mdrun and benchmark use cases, so ``-confout``
will no longer be required.

``gmx mdrun -nsteps``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3256` The number of simulation steps described by the .tpr file can be
changed with ``gmx convert-tpr``, or altered in .mdp file before the
call to ``gmx grompp``. The convenience of this mdrun option was
outweighted by the doubtful quality of its implementation, no clear
record in the log file, and lack of maintenance.

Portability
^^^^^^^^^^^

Python environment
""""""""""""""""""

Where Python is required,
`CPython <https://www.python.org>`__ versions 3.6 to 3.8 are supported.

CMake now detects Python using
`FindPython3 <https://cmake.org/cmake/help/v3.13/module/FindPython3.html>`__.
If you previously used ``PYTHON_EXECUTABLE`` to hint the location of the Python
interpreter, you should instead specify the Python "root" or "prefix" path
(the directory containing ``./bin/python3``) with CMake variable
``Python3_ROOT_DIR`` or ``CMAKE_PREFIX_PATH``. As other infrastructure evolves,
``PYTHON_EXECUTABLE`` may cease to have the desired effect without warning.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

CMake
"""""

Updated required CMake version to 3.13.

C++ standard
""""""""""""

|Gromacs| has updated the required C++ standards compliance from C++14 to C++17,
and requires 2017 standard library features. See the install guide for details.

Cygwin
""""""

|Gromacs| now builds on Cygwin with both gcc and clang compilers.

Windows
"""""""

|Gromacs| now builds correctly on Windows with MSVC even when the path
to the source or build directory has a space in it.

Builds with MSVC 2019 correctly detect the proper static linking setup
during CMake configuration.

RDTSCP usage and reporting
""""""""""""""""""""""""""

|Gromacs| now defaults always on x86 to use the RDTSCP machine
instruction for lower latency timing. Very old machines might need to
configure with ``GMX_USE_RDTSCP=off``. Non-x86 platforms are
unaffected, except that they will no longer report that RDTSCP is
disabled (because that is self-evident).

armv8+sve support (ARM_SVE)
"""""""""""""""""""""""""""
Support for ARM Scalable Vector Extensions (SVE) has been added.
|Gromacs| supports SVE vector length fixed at CMake configure time
(typically via the -msve-vector-bits=<len> compiler option),
which is at the time of the release supported in GNU GCC 10 and later,
and will supported soon by LLVM 12 and compilers based on this.
The default is to detect the default vector length at CMake configure time,
and that can be changed with the ``GMX_SIMD_ARM_SVE_LENGTH=<bits>`` option.
Supported values are 128, 256, 512 and 1024. Note that the nonbonded
kernels have not been optimized for ARM_SVE as of yet.
ARM_SVE support is contributed by the Research Organization for Science Information and Technology (RIST)
New and improved features
^^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Virtual site with single constructing atom
""""""""""""""""""""""""""""""""""""""""""

Added a virtual site that is constructed on top if its single constructing
atom. This can be useful for free-energy calculations.

Density-guided simulations can apply matrix multiplication and shift vector to structures
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The new mdp option "density-guided-simulation-shift-vector" defines a
shift vector that shifts the density-guided simulation group before the 
density forces are evaluated. With a known shift vector that aligns structure
and input density, this feature enables structure refinement to non-aligned
densities without the need to manipulate the input density data or structure.
The mdp option "density-guided-simulation-transformation-matrix" allows to 
define a matrix with which to multiply the structure coordinates, before the shift
vector is applied. This allows arbitrary rotation, skewing and scaling of input
structures with respect to the input densities.
A typical use case are membrane-embedded proteins which cannot easily be
shifted and rotated within membranes.

Lower energy drift due to SETTLE
""""""""""""""""""""""""""""""""

|Gromacs| already applied an improvement to the center of mass calculation in
SETTLE to reduce energy drift in single precision. Now the center of mass
calculation is completely avoided, which significantly reduces the energy
drift when large coordinate values are present. This allows for accurate
simulations of systems with SETTLE up to 1000 nm in size (but note that
constraining with LINCS and SHAKE still introduces significant drift,
which limits the system size to 100 to 200 nm).

mdrun now reports energy drift
""""""""""""""""""""""""""""""

With conservative integrators, mdrun now reports the drift of the conserved
energy quantity in the log file.

FEP using AWH
"""""""""""""

It is now possible to control the lambda state of a free energy perturbation
simulation using the Accelerated Weight Histogram method. This can be used
as one of multiple AWH dimensions, where the other(s) are coupled to pull
coordinates.

Support for cyclic molecules in pdb2gmx
"""""""""""""""""""""""""""""""""""""""

It is now possible to process cyclic molecules in pdb2gmx and generate |Gromacs|
topology files for them.

Stochastic cell rescaling barostat
""""""""""""""""""""""""""""""""""

Implementation of the stochastic cell rescaling barostat. This is a first-order,
stochastic barostat, that can be used both for equilibration and production.
Miscellaneous
^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Default values for temperature and pressure coupling intervals are now 10
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With the default mdp input value of -1 for nsttcouple and nstpcouple, grompp would
set these values to nstlist. Now these are set to 10 and thus independent of nstlist
(note that grompp may choose smaller values when needed for accurate integration).

Uniform and manual CMake GPU-support configuration
""""""""""""""""""""""""""""""""""""""""""""""""""
The GPU accelerations setup has been changed to be uniform for CUDA and OpenCL. Either
option is now enabled by setting GMX_GPU to CUDA or OpenCL in the CMake configuration.
To simplify the CMake code, we have also moved away from automated option selection
based on the build host. In particular, this means that CUDA will not be enabled unless
the GMX_GPU option is explicitly enabled, and CMake will no longer perform the extra
steps of trying to detect hardware and propose to install CUDA if hardware is available.
Apart from the simplification, this should also make it easier to handle multiple
different accelerator APIs targeting e.g. NVIDIA hardware.

Configuration-time trivalue options changed from autodetection to boolean on/off
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
To simplify the CMake configuration and avoid having multiple settings that
change outside of the users direct control we have removed the support for
automatically setting booleans. GMX_BUILD_HELP and GMX_HWLOC are now
disabled by default, while GMX_LOAD_PLUGINS is enabled by default.

gmxapi C++ interface
""""""""""""""""""""

``gmxapi::Context`` is now created with ``gmxapi::createContext()``, which allows
the client to provide an MPI communicator for the library to use instead of its default
(e.g MPI_COMM_WORLD). MPI-enabled clients may use the :file:`gmxapi/mpi/gmxapi_mpi.h`
template header and the ``assignResource()`` helper to generate the argument to
``createContext``.

Unification of several CUDA and OpenCL environment variables
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The environment variables that had exactly the same meaning in OpenCL and CUDA were unified:

* GMX_CUDA_NB_ANA_EWALD and GMX_OCL_NB_ANA_EWALD into GMX_GPU_NB_ANA_EWALD
* GMX_CUDA_NB_TAB_EWALD and GMX_OCL_NB_TAB_EWALD into GMX_GPU_NB_TAB_EWALD
* GMX_CUDA_NB_EWALD_TWINCUT and GMX_OCL_NB_EWALD_TWINCUT into GMX_GPU_NB_EWALD_TWINCUT

Dysfunctional parts of the QMMM interface has been removed
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Currently, GROMACS supports QM/MM officially only via MiMiC; a new CP2K QM/MM interface is being
developed within BioExcel. All other QM/MM
support has been untested and likely dysfunctional for years and has now been removed from .mdp
input and output, resulting in smaller .mdp output files from grompp.
Improvements to |Gromacs| tools
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Performance improvements
^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Added support for multiple time-stepping
""""""""""""""""""""""""""""""""""""""""

A two-level multiple time-stepping scheme has been implemented.
Any combination of five different force groups can be selected
to evaluate less frequently, thereby improving performance.

Extend supported use-cases for GPU version of update and constraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

GPU version of update and constraints can now be used for FEP, except mass and constraints
free-energy perturbation.
       
Reduce time spent in grompp with large numbers of distance restraints
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The time `gmx grompp` spent processing distance restraint has been
changed from quadratic in the number of restraints to linear.
       
:issue:`3457`

Support for offloading PME to GPU when doing Coulomb FEP
""""""""""""""""""""""""""""""""""""""""""""""""""""""""

PME calculations can be offloaded to GPU when doing Coulomb free-energy perturbations.

CPU SIMD accelerated implementation of harmonic bonds
"""""""""""""""""""""""""""""""""""""""""""""""""""""

SIMD acceleration for bonds slightly improves performance for systems
with H-bonds only constrained or no constraints. This gives a significant
improvement with multiple time stepping.

Allow offloading GPU update and constraints without direct GPU communication
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Allow domain-decomposition and separate PME rank parallel runs to offload update and
constraints to a GPU with CUDA without requiring the (experimental) direct GPU
communication features to be also enabled.

Tune CUDA short-range nonbonded kernel parameters on NVIDIA Volta and Ampere A100
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Recent compilers allowed re-tuning the nonbonded kernel defaults on NVIDIA Volta and
Ampere A100GPUs which improves performance of the Ewald kernels, especially those that
also compute energies.
GROMACS 2016.3 Release Notes
----------------------------

This version was released on March 14, 2017. These release notes
document the changes that have taken place in GROMACS since version
2016.2 to fix known issues. It also incorporates all fixes made in
version 5.1.4 and several since.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed mdrun with separate PME ranks hanging upon exit
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
A recent fix for another issue led to mdrun hanging while communicating
with PME ranks to coordinate end-of-run performance statistics.

:issue:`2131`

Fixed handling of previous virials with md-vv integrator
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
These quantities get written to checkpoint files only for the Trotter
pressure-coupling integrators that need them, but they were being
copied in do_md for all Trotter integrators. This meant that an
appending restart of md-vv plus nose-hoover plus no pressure coupling
truncated off a correct edr frame and wrote one with zero virial and
wrong pressure. And in the same case, a no-append restart writes a
duplicate frame that does not agree with the one written before
termination.

:issue:`1793`

Fixed an incorrect check that nstlog != 0 for expanded ensembles
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The original version was accidentally reversed, causing it to
fail when nstlog was not equal to 0.

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixed ``gmx tune_pme`` detection of GPU support
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed spacing in ``gmx tune_pme`` call to thread-MPI mdrun
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed minor issues in ``gmx traj -av -af``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Made the description of the xvg y-axis more useful. Also works for
option ``-af``.

:issue:`2133`

Removed rogue printing to xvg file in gmx mindist
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
``gmx mindist -xvg`` none is now adhered to, and printing is preceded by
a comment.

:issue:`2129`

Fixed bug in ``gmx solvate -shell`` if it yielded 0 SOL.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
In the transition from genbox to solvate, some incorrect logic was
introduced.

:issue:`2119`

Corrected output of ``gmx do_dssp -sc``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This code has always written a probability, and not a percentage, so
fixed the label. It still fits within the expected 8-character field.

:issue:`2120`

Improved documentation
^^^^^^^^^^^^^^^^^^^^^^

Made several minor improvements to documentation and messages to users
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Removed documentation of unimplemented ``gmx trjconv -clustercenter``.

Introduced system preparation section to user guide, to create
somewhere to document the use and limitations of vdwradii.dat.
Enchanced documentation of solvate and insert-molecules, similarly.

:issue:`2094`

Documented that we now support AMD GCN on Mesa/LLVM
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
AMD GPUs using Mesa 17.0+ and LLVM 4.0+ run GROMACS using OpenCL.

Documented running Clang static analyzer manually
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Portability enhancements
^^^^^^^^^^^^^^^^^^^^^^^^

Enabled avx512 in the GROMACS FFTW build only if the compiler supports it
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Enabling avx512 requires GCC 4.9 or newer or Clang 3.9 or newer. Since
we support compilers older than those, we can not afford to enable
avx512 in ``GMX_BUILD_OWN_FFTW=on`` unconditionally.

Worked around false positives in SIMD test from bug in xlc 13.1.5
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
atan2(0,0) should return 0.0, which the GROMACS simd implementation
does. However, since at least one compiler produces -nan for the
standard library version it's better to compare with the known
correct value rather than calling std:atan2(0,0).

:issue:`2102`

Fixed compile with icc of ``GMX_SIMD=None``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
ICC defines invsqrt in math.h
GROMACS 2016.2 Release Notes
----------------------------------------

This version was released on February 7, 2016. These release notes
document the changes that have taken place in GROMACS since version
2016.1 to fix known issues. It also incorporates all fixes made in
version 5.1.4 and several since.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Add grompp check for equipartition violation risk for decoupled modes
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When atoms involved in an angle with constrained bonds have very
different masses, there can be very weakly coupled dynamics modes.
Default mdp settings are often not sufficiently accurate to obtain
equipartitioning. This change adds a grompp check for this issue.

Part of :issue:`2071`

Disallow overwriting of dihedral type 9
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
It is no longer allowed to repeat blocks of parameter of multiple
lines for dihedrals of type 9. It is also no longer allowed to
override parameters or dihedrals of type 9. Both are too complex
to properly check. It is still allowed to repeat parameters blocks
consisting of a single line.
Repeating a block with the same parameters would lead to incorrect
dihedral potentials and forces.

:issue:`2077`

Fixed flat-bottom position restraints + DD + OpenMP
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
A (re)allocation was missing, causing a crash.

:issue:`2095`

Fixed multi-domain reruns
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Old code cleanup led multi-domain rerun to crash because it failed to
consider logic separated over two places.

:issue:`2105`

Fixes for mdrun performance issues
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Corrected CUDA sm_60 performance
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The kernel launch now suits the SM size of the GP100 architecture.

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixed some FFT handling in cross-corrrelation calculations
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
An array of complex number was created as an array of pointers and
then passed to gmx_fft_1d. This does not work.

:issue:`2109`

Fixed gmx rmsf -q -oq
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This led to the PDB file containing B-factors using coordinates based
on those from the -s file, rather than -q file. gmx rmsf -oq was
otherwise fine.

Fixed crash in gmx order
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
gmx order used a cumbersome floating point method to compute
a histogram, leading to an index value that could be negative.

:issue:`2104`

Fixed minor trjconv bug
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
gmx trjconv -novel -f in.pdb -o out.pdb probably works better now.

Fixed time label print in gmx vanhove
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Handled issuing warnings correctly in xpm2ps and membed
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The code should not (over)write the output file before checking for
errors. For membed, it is useful to require the user to fix issues in
their input file before we unilaterally over-write it.

Corrected documentation about eigenvalue handling
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Some file format docs were out of step with the implementation in
eigio.cpp.

The behaviour of gmx anaeig -eig -eig2 was not properly documented.

Made editconf B-factor attachment more useful in practice
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
B-factor values will be added to residues unless an index is larger
than the number of residues or an option is specified. Protein residue
indices can start from any number and, in case they start from a large
number, there is no way to add B-factor values to residues.

This patch changes it to add B-factor values to residues unless the
number of B-factor values is larger than the number of residues.

Fixed possible memory error with long selections
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If a selection was more than 1000 characters long and there was a
whitespace exactly at the 1000 point, a buffer overflow could occur.
Replaced the buffer with std::string, simplifying the code
significantly.

:issue:`2086`

Fixed use of position variables with plus/merge
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If a selection contained a position variable (e.g., 'com of ...') that
was used more than once, and at least one of those uses was with
plus/merge, there were out-of-bounds memory writes.  This was caused by
the internal position structure not getting fully initialized.
Incomplete initialization happens in all contexts with such variables,
but only plus/merge (and possibly permute) actually use the values that
remained uninitialized, which caused them to incorrectly compute the
amount of memory required to store the result.

:issue:`2086`

Improved documentation
^^^^^^^^^^^^^^^^^^^^^^

Made several minor improvements to documentation and messages to users
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
In particular, for selections:

- Explained resindex and resnr keywords in selection help.
- Explained how selection-enabled tools treat -s and -f input files.

:issue:`2083`

Clarified use of tau-p and pcoupltype
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
grompp used to permit the erroneous "tau-p = 5 5". This does not
reflect that only one time constant is permitted for pressure coupling
(unlike group-based temperature coupling). The recent fix for
:issue:`1893` leads to the user receiving a grompp warning, so this
improves the docs to make clear that pressure coupling is different.

:issue:`1893`

Portability enhancements
^^^^^^^^^^^^^^^^^^^^^^^^

Fixed x86 conditional on IBM s390x
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The CpuInfoTest.SupportLevel test fails on IBM s390x because wrong
condition was used.

Fixes: https://bugzilla.redhat.com/show_bug.cgi?id=1390149

:issue:`2072`

Build system enhancements
^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed compilation with CMAKE_CXX_FLAGS="-Wall -Werror"
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`2073`

Stopped trying to use objdump --reloc in the build system on Mac
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Recent Xcode objdump does not support --reloc.

The warning that is based on the output of running objdump was only
implemented to work on Linux-like things, so should not spam the cmake
output on other platforms.

Improved the support for plugin loading in the build system
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The mdrun-only and prefer-static-libs builds set the default for
BUILD_SHARED_LIBS to off, which silently disabled plugin support
for things like VMD-based I/O handling.

Converted GMX_LOAD_PLUGINS to tri-state ON/OFF/AUTO so that if the
preconditions for support are not met we can have suitable behaviour
in each case.

:issue:`2082`

Turn off hwloc support when static lib found
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Hwloc dependencies are not resolved at CMake time when static
libwloc.a is detected and in most of these cases link-time
errors will prevent building GROMACS. As it is hard for a user to know
how to solve such cryptic errors and hwloc is not a required dependency,
we turn off hwloc support when a static lib is detected. The user can
override this on the cmake command line.

:issue:`1919`

Fixed build with GMX_EXTERNAL_TNG=ON
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

House-keeping that reduces users' problems
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Mdrun prints invalid performance data less often
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If mdrun finished before a scheduled reset of the timing information
(e.g. from mdrun -resetstep or mdrun -resethway), then misleading
timing information should not be reported.

Related, the default reset step for gmx tune_pme was increased to 1500.

:issue:`2041`

Added a runtime check for number of threads in bonded code
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Replaced a debug assertion on the number of OpenMP threads not being
larger than GMX_OPENMP_MAX_THREADS by fatal error.
But since the listed-forces reduction is actually not required with
listed forces, these are now conditional and mdrun can run with more
than GMX_OPENMP_MAX_THREADS threads.

:issue:`2085`

Fixed integer narrowing in TNG reading for long trajectories
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Reading of TNG trajectories with sufficiently large numbers of frames
could truncate integers used for frame numbers. Fixed to use 64-bit
integers as originally intended.

Fixed logic of TRR reading
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When reading a trr file, reaching the end of the file was
indistinguishable from a reading error or a magic-number error. This
is now fixed, restoring the intended behaviour in each case.

:issue:`1926`
GROMACS 2016.4 Release Notes
----------------------------

This version was released on September 15, 2017. These release notes
document the changes that have taken place in GROMACS since version
2016.3 to fix known issues. It also incorporates all fixes made in
version 5.1.4 and several since.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Disabled PME tuning with the group scheme
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
PME tuning with the group cut-off scheme did not work correctly.
Interactions between charge-group pairs at distances between ``rlist``
and ``rcoulomb`` can go missing. The group scheme is deprecated, and
this issue would require considerable effort to fix and test, so we
have simply disabled PME tuning with the group scheme.

:issue:`2200`

Fixed value of Ewald shift
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
In all the Ewald short-ranged kernel flavours, the value of the
potential at the cutoff is subtracted from the potential at the actual
distance, which was done incorrectly (failing to divide the shift
value by cutoff distance). Fortunately, the value of that distance is
often close to 1, and the inconsistent shifts often cancel in
practice, and energy differences computed on neighbour lists of the
same size will have the error cancel. The difference doesn't even show
up in the regressiontests, but would if we had a unit test of a single
interaction.

:issue:`2215`

Fixed orientation restraint reference
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The resetting of the COM of the molecule with orientation restraints
for fitting to the reference structure was done with the COM of the
reference structure instead of the instantaneous structure. This does
not affect the restraining (unless ensemble averaging is used), only
the printed orientation tensor.

:issue:`2219`

Fixed bugs with setup for orientation restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The orientation restraint initialization got moved to before the
initialization of the domain decomposition, which made the check
for domain decomposition fail.
Also fixed orientation restraints not working with the whole system
as fitting group.

Worked around missing OpenMP implementation in orientation restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The orientation restraint code is not aware of OpenMP threads
and uses some global information. By only running it on the
master rank, results are now independent of number of threads
used.

:issue:`2223`

Enable group-scheme SIMD kernels on recent AVX extensions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The group-scheme code only runs using the feature set of AVX_256, but
that is supported on the more recent hardware, so we should have the
group scheme run with the maximum suitable SIMD. With previous releases,
building AVX_256 binaries was required for best performance with the
(deprecated) group scheme.

Fix FEP state with rerun
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When using FEP states with rerun, the FEP state was always 0.

:issue:`2244`

Fixed COM pull force with SD
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The reported COM pull force when using the SD integrator was random
only. Now the pull force is summed over the systematic and random SD
update components.  A better solution is to not add the random force
at all, but such a change should not be done in a release branch.

:issue:`2201`

Fix PBC bugs in the swap code
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`2245`

Fixed flat-bottomed position restraints with multiple ranks
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Reallocation was never done for flat-bottomed restraints, during
domain decomposition, so the indexing could go out of range, leading
to segfaults.

:issue:`2236`

Fixed null pointer print in DD
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixed a (rather harmless) print of a null pointer string during
DD initialization. This would only show up with ``gmx mdrun -dlb yes``.

Improved the "files not present" error message
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
It's possible to use ``gmx mdrun -deffnm`` in restarts even if it
wasn't used in the initial simulation. This can lead to absurd
situations such as:

  Expected output files not present or named differently:
    pullx.xvg
    pullf.xvg

where ``pullx.xvg`` and ``pullf.xvg`` are present and named exactly as
listed, but GROMACS expects them to be named as ``-deffnm`` requested.

The improved error message suggest to the user to check for that
possibility.

:issue:`942` (partial workaround)

Fixed LJ-PME + switch grompp error
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
An error call was missing in grompp when LJ-PME was requested in
combination with a force or potential switch modifier.

:issue:`2174`

Fixed unused SIMD PME table kernel
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The Verlet-scheme 2xNN PME kernel with tabulated correction had
several issues. This kernel flavor could only be selected manually by
setting an environment variable, so no user simulations should be
affected.

:issue:`2247`

Fixed bugs in most double-precision Simd4 implementations
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The double precision version of reduce() and dotProduct() returned a
float with AVX2_256, AVX_256, AVX_128_FMA, AVX_512, MIC and IBM_QPX.
Only reduce() is used in double, in the PME force gather, and the
difference is small.

:issue:`2162`

Avoid inf in SIMD double sqrt()
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Arguments > 0 and < float_min to double precision SIMD sqrt()
would produce inf on many SIMD architectures. Now sqrt() will
return 0 for arguments in this range, which is not fully correct,
but should be unproblematic.

:issue:`2164`
:issue:`2163`

Fix NVML error messages
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
These should refer to the API calls that failed, e.g. when users lack
permissions to change clocks.

Fixed IMD interface malfunctions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`2206`

Fixed initial temperature reporting
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When continuing a simulation from a checkpoint, mdrun could report
double the intial temperature when ``nstcalcenergy=1`` or ``nsttcoupl=1``.
Note that this only affected reporting, the actual velocities were
correct.
Now the initial temperature is no longer reported for continuation
runs, since at continuation there is no "initial" temperature.

:issue:`2199`

Fix exception in SIMD LJ PME solve
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Clear SIMD padding elements in solve helper arrays to avoid,
otherwise harmles, fp overflow exceptions.

:issue:`2242`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixed memory access issues in gmx solvate
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
There was out-of-bounds access if
 1) the solvent configuration was given as a .pdb file, or
 2) there was more than one type of residue in the solvent (which
    triggered sorting).

Also fix a memory leak in the sorting routine.

Should fix crashes mentioned in :issue:`2148`

Fixed a consistency check in ``gmx make_edi`` for flooding
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If one sets up a flooding .edi input file with ``gmx make_edi``,
the code should check that one does not use of the last 6 eigenvectors
of the covariance matrix, which correspond to the rotational and
translational degrees of freedom.
The check that was in the code erroneously checked against the
number of eigenvalues neig that was stored in the .xvg file,
not against the total number of eigenvectors which depends on
the number of atoms nav used in gmx covar. Thus the original
check would always fail if the .xvg eigenvalue file contained
1-6 values only.

Supported quiet trajectory-handling I/O
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Permits ``GMX_TRAJECTORY_IO_VERBOSITY=0`` to be set to keep frame-reading
code quiet, which is convenient for tools using libgromacs.

Improved documentation
^^^^^^^^^^^^^^^^^^^^^^

Migrated much content from the wiki to the user guide
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This includes
* expanding the "Performance" section,
* reworking extending simulations, doing restarts and reproducibility,
* adding documentation for mdp option ``simulation-part``.
* adding documentation for issues relating to floating-point arithmetic
* adding documentation for run-time errors

Corrected the PDF manual to reflect that all tools are called ``gmx <tool>``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
There were still a few occurrences of the old-style ``g_tool`` naming,
this patch removes. Deliberately left ``g_membed`` as is, because there
was never a ``gmx membed``, but instead it got incorporated into
``gmx mdrun``.

Clarified ``gmx editconf`` help text
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
It is possible that users can confuse ``-c`` with ``-center`` so this
patch makes it clear that ``-center`` doesn't do anything unless the
user really wants to shift the center of the system away from the
middle of the box.

:issue:`2171`

Added missing .mdp file documentation for the enforced rotation module
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed parameter description for dihedral_restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The force-constant parameter for dihedral_restraints was not
documented in the table of interaction types.

:issue:`2144`

Replaced instance of "group" by "coord" in pull .mdp documentation
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Portability enhancements
^^^^^^^^^^^^^^^^^^^^^^^^

Supported CUDA 9/Volta for nonbonded kernels
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Implemented production-quality support for Volta GPUs and CUDA 9.

The code was adapted to support changes to the nature of warp
synchrony, without disturbing support for older GPUs and/or
CUDA. Further improvements may be seen (e.g. in the 2017 release).

Really enabled AVX512 in the GROMACS-managed build of FFTW
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
An earlier attempt to enable AVX512 on GCC 4.9 or newer and
Clang 3.9 or newer was wrongly implemented. Now this works on
all compilers we officially support (MSVC, GCC, clang, ICC).

Fixed aspects for compiling and running on Solaris
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed AVX512F compiler flags
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Avoid using the MIC code generation flags for the Xeon code path.

Fixed compiler flags for using MKL
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixes compilation issues with ARM SIMD
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
ARM_NEON has never supported double precision SIMD, so disabled it
with GROMACS double-precision build.

The maskzR* functions used the wrong argument order in the debug-mode
pre-masking (and sometimes in a typo-ed syntax).

In the shift operators, the clang-based compilers (including the
armclang v6 compiler series) seem to check that the required immediate
integer argument is given before inlining the call to the operator
function. The inlining seems to permit gcc to recognize that the
callers always use an immediate. In theory, the new code might
generate code that runs a trifle slower, but we don't use it at the
moment and the cost might be negligible if other effects dominate
performance.
GROMACS 2016.5 Release Notes
----------------------------

This version was released on February 16, 2018. These release notes
document the changes that have taken place in GROMACS since version
2016.4 to fix known issues. It also incorporates all fixes made in
version 5.1.5 (which was the last planned release in that series).

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed triclinic domain decomposition bug
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With triclinic unit-cells with vectors a,b,c, the domain decomposition
would communicate an incorrect halo along dimension x when b[x]!=0
and vector c not parallel to the z-axis. The halo cut-off bound plane
was tilted incorrect along x/z with an error approximately
proportional to b[x]*(c[x] - b[x]*c[y]/b[y]).
When c[x] > b[x]*c[y]/b[y], the communicated halo was too small, which
could cause instabilities or silent errors.
When c[x] < b[x]*c[y]/b[y], the communicated halo was too large, which
could cause some communication overhead.

:issue:`2125`

Required -ntmpi with setting -ntomp with GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With GPUs and thread-MPI, setting only ``-ntomp`` could lead to
oversubscription of the hardware threads.
Now with GPUs and thread-MPI the user is required to set ``-ntmpi`` when
using ``-ntomp``. Here we chose that to also require ``-ntmpi`` when the user
specified both ``-nt`` and ``-ntomp``; here we could infer the number of
ranks, but it's safer to ask the user to explicity set ``-ntmpi``.
Note that specifying both ``-ntmpi`` and ``-nt`` has always worked correctly.

:issue:`2348`

Prevented dynamic load balancing activating immediately after exchange
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Turning on DLB right after exchanging replicas caused an assertion
failure and is also useless.

:issue:`2298`

Avoided confusing message at end of non-dynamical runs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
EM, TPI, NM, etc. are not targets for performance optimization
so we will not write performance reports. This commit fixes
and oversight whereby we would warn a user when the lack of
performance report is normal and expected.

:issue:`2172`

Changed to issue fewer messages when ``-cpi`` checkpoint file is not present
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Removed duplicated message.

:issue:`2173`

Disallowed combination of PME-user and Verlet cutoff
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`2332`

Added missing Ewald correction for pme-user
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With ``coulomb-type = pme-user``, the Ewald mesh energy was not subtracted
leading to (very) incorrect Coulomb energies and forces.

:issue:`2286`

Fixed thread-MPI rank choice for orientation restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Only a single rank is supported, so that must be what the thread-MPI
code will choose. There's another check later on that catches the
multi-rank MPI case.

Fixed nstlist increase warning print
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The log file warning message had a buggy conditional which this commit
fixes.

Removed incorrect comment for CHARMM tips3p
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed incorrect dV/dlambda for walls
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The free-energy derivative dV/dlambda for walls, which can
be perturbed by changing atom types of non-wall atoms, only
contained the B-state contribution.

:issue:`2267`

Fixed warning for confout with periodic molecules
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With periodic molecules, ``gmx mdrun`` would incorrectly attempt to make
molecules whole for writing the final state to confout.

:issue:`2275`

Fixed wrong megaflop accounting
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Some nrnb index entries were missing in the interaction_function
array, leading to that wrong megaflops accounting printed.

:issue:`2274`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixed ``gmx grompp`` net charge check
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The grompp check for the net charge would ignore molecule blocks
at the end when molecule types are used in multiple, non consecutive
molecule blocks.

:issue:`2407`

Extended ``gmx grompp`` missing energy term message
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`2301`

Fixed ``gmx genion`` charge summation accuracy
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
``gmx genion`` accumulated the charge is a float, which could cause
underestimation of the net charge for highly charged systems.

:issue:`2290`

Fixed ``gmx check`` for tprs with different #atoms
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`2279`

Fixed ``gmx grompp`` with Andersen massive and no COM removal
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixed a floating point exception leading to a crash.
Also fixed possible different rounding for the interval for
Andersen massive in ``gmx grompp`` from ``gmx mdrun`` for
the common case where ``tau_t`` is a multiple of ``delta_t``.

:issue:`2256`

Improved documentation
^^^^^^^^^^^^^^^^^^^^^^

Updated documention of Nose-Hoover output
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The documentation of Nose-Hoover chain variable printing was
(long) outdated.

:issue:`2301`

Clarified docs for Fmax in EM
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
GROMACS 2016.1 Release Notes
----------------------------------------

This version was released on October 28, 2016. These release notes
document the changes that have taken place in GROMACS since the
initial version 2016 to fix known issues. It also incorporates all
fixes made in version 5.1.4.

Made distance restraints work with threads and DD
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The NMR distance restraints use several buffers for summing distances
that were indexed based on the index of the thread+domain local ilist
force atoms. This gives incorrect results with OpenMP and/or domain
decomposition. Using the type index for the restraint and a domain-
local, but not thread-local index for the pair resolves these issues.
The are now only two limitations left:

* Time-averaged restraint don't work with DD.
* Multiple copies of molecules in the same system without ensemble
  averaging does not work with DD.

Note that these fixes have not been made in any 5.1.x release.

:issue:`1117`
:issue:`1989`
:issue:`2029`

Fixed Ewald surface+3DC corrections
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Ewald surface and 3DC correction forces were only applied up to,
but not including, the last atom with exclusions. With water at
the end of the system only the last H would not be corrected.
With ions at the end all ions would be missing.
In addition, with the Verlet scheme and domain decomposition
no force correction was applied at all.

:issue:`2040`

Fixed opening of wall table files
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`2033`

Fixed bug in gmx insert-molecules.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With option -ip, and if all trials were unsuccessful, a molecule was
eventually incorrectly placed at 0/0/0 due to a memory error
when referencing to rpos[XX][mol].

Made virial reproducible
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
OpenMP reduction was used to reduce virial contributions over threads,
which does not have a defined order. This leads to different rounding,
which makes runs non-reproducible (but still fully correct).
Now thread local buffers are used.
Also removed OpenMP parallezation for small count (e.g. shift forces).

Updated to support FFTW 3.3.5
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The auto-download of FFTW now gets FFTW 3.3.5 and builds it properly,
including with ``--enable-vsx`` when GMX_SIMD is set to VSX, i.e. for
Power8, and ``--enable-avx512`` when GMX_SIMD is any of the AVX flavours
(which is safe on non-512 now, works on KNL, and is presumed useful
for future AVX512 architectures).

Permitted automatic load balancing to disable itself when it makes the run slower
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Under certain conditions, especially with (shared) GPUs, DLB can
decrease the performance. We now measure the cycles per step before
turning on DLB. When the running average of cycles per step with DLB
gets above the average without DLB, we turn off DLB. We then measure
again without DLB. If without DLB the cycle count is still lower,
we keep DLB off for the remainder of the run. Otherwise is can turn
on again as before. This procedure ensures that the performance will
never deteriorate due to DLB.

Improved the accuracy of timing for dynamic load balancing with GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With OpenCL, the time for the local non-bonded to finish on the GPU
was ignored in the dynamic load balancing. This change lets OpenCL
take the same code path as CUDA.

One internal heuristic parameter was far too small for both CUDA and
OpenCL, which is now fixed.

Corrected kernel launch bounds for Tesla P100 GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This corrects our initial guess of kernel tuning parameters that resulted
in reduced occupancy on sm_60 GPU, and thus improves performance.

Improved logic handling if/when the run is terminated for SETTLE warnings
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The code now honours that when the environment variable
GMX_MAXCONSTRWARN is set to -1, there is no maximum number of warnings.

:issue:`2058`

Fixed bug in gmx wham for reading pullx files.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Because the order of columns in the pullx files has changed recently,
``gmx wham`` did not pick the reaction coordinate from ``pullx.xvg``
if the COM of the pull groups were written. ``gmx wham`` was tested
with various pull options and geometries.

Fixed ouput bug in gmx wham
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed deadlock with thread-MPI
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With thread-MPI mdrun could deadlock while pinning threads.

:issue:`2025`

Made error reporting in grompp more user friendly
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This tool now always reports the file and line in user input files
that lead to a condition such that subsequent parsing cannot continue.

Fixed SIMD suggestion for VMX
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed script xplor2gmx.pl to work with GMXDATA
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed default nice level in mdrun-only build
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Now an mdrun-only build should default to zero nice level, the same as
``gmx mdrun`` in a normal build.

Fixed math-test false positive
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Depending on the accuracy of the floating point division, the
input of the test function could be 1ulp too large or too small.
If it was too large the result of the test function wasn't
within 4ulp and the test failed.

Improved documentation
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Approaches for reducing overhead for GPU runs are now documented.

The available wallcycle counters and subcounters reported in the
md.log files are now listed and and explained in the user guide, along
with how to enable reporting of the subcounters.

Several install-guide sections have been improved, including those for
OpenCL, mdrun-only, and "make check". A "quick and dirty" cluster
installation section was added.

OpenCL error string are now written, instead of cryptic error codes
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed build with GMX_USE_TNG=off
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Removed variable-precision .gro writing
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The precision used when writing .gro files is now fixed to 3, 4 and 5
decimal places for x, v and box respectively to ensure compatibility with
other software. Variable-precision reading is still supported.

:issue:`2037`

Fixed BG/Q platform files and install guide
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Renamed the platform file to reflect normal practice
and the install guide.

Reduced the memory required for free-energy simulations
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Pair lists with atoms whose short-ranged parameters are perturbed
now use less memory.

:issue:`2014`
Bugs fixed
^^^^^^^^^^

These document fixes for issues that have been fixed for the 2016
release, but which have not been back-ported to other branches.

Fixed two problems related to restarts for velocity-Verlet
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The first problem is more serious; in addition to causing problems
with restarts in most cases for velocity-Verlet integrators plus either
Berendsen or v-rescale temperature-coupling algorithms, the
temperature coupling code was called twice. This made the distribution of
kinetic energies too broad (but with the correct average).
Other algorithm combinations were unaffected.

In the second problem, the initial step after restarts with velocity-Verlet
integrators and either Berendsen or v-rescale temperature-coupling algorithms
had too high a pressure because they used an empty virial matrix that
was only filled with MTTK pressure control. The effects of this bug were
very small; it only affected the volume integration for one step on restarts.

:issue:`1883`

Fixed Verlet buffer calculation with nstlist=1
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Under rare circumstances the Verlet buffer calculation code was
called with nstlist=1, which caused a division by zero. The division
by zero is now avoided.
Furthermore, grompp now also determines and prints the Verlet buffer
sizes with nstlist=1, which provider the user information and adds
consistency checks.

:issue:`1993`

Fixed large file issue on 32-bit platforms
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
At some point gcc started to issue a warning instead of a fatal error
for the checking code; fixed to really generate an error now.

:issue:`1834`

Avoided using abort() for fatal errors
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This avoids situations that produce useless core dumps.

:issue:`1866`

Fixed possible division by zero in polarization code
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Avoided numerical overflow with overlapping atoms in Verlet scheme
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The Verlet-scheme kernels did not allow overlapping atoms, even if
they were not interacting (in contrast to the group kernels). Fixed by
clamping the interaction distance so it can not become smaller than
~6e-4 in single and ~1e-18 in double, and when this number is later
multiplied by zero parameters it will not influence forces. The
clamping should never affect normal interactions; mdrun would
previously crash for distances that were this small.  On Haswell, RF
and PME kernels get 3% and 1% slower, respectively.  On CUDA, RF and
PME kernels get 1% and 2% faster, respectively.

:issue:`1958`

Relax pull PBC check
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The check in the pull code for COM distances close to half the box
was too strict for directional pulling. Now dimensions orthogonal
to the pull vector are no longer checked. (The check was actually
not strict enough for directional pulling along x or y in triclinic
units cells, but that is a corner case.)
Furthermore, the direction-periodic hint is now only printed with
geometry direction.

:issue:`1962`

Add detection for ARMv7 cycle counter support
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
ARMv7 requires special kernel settings to allow cycle
counters to be read. This change adds a cmake setting
to enable/disable counters. On all architectures but ARMv7
it is enabled by default, and on ARMv7 we run a small test
program to see if the can be executed successfully. When
cross-compiling to ARMv7 counters will be disabled, but
either choice can be overridden by setting a value for
GMX_CYCLECOUNTERS in cmake.

:issue:`1933`

Introduced fatal error for too few frames in ``gmx dos``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
To prevent ``gmx dos`` from crashing with an incomprehensible error
message when there are too few frames, test for this.

Part of :issue:`1813`

Properly reset CUDA application clocks
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We now store the application clock values we read when starting mdrun
and reset to these values, but only when clocks have not been changed
(by another process) in the meantime.

:issue:`1846`

Fixed replica-exchange debug output to all go to the debug file
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When ``mdrun -debug`` was selected with replica exchange, some of the
order description was printed to mdrun's log file, but it looks like the
actual numbers were being printed to the debug log. This puts them
both in the debug log.

Fixed gmx mdrun -membed to always run on a single rank
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This used to give a fatal error if default thread-MPI mdrun had chosen
more than one rank, but it will now correctly choose to use a single rank.

Fixed issues with using int for number of simulation steps
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Mostly we use a 64-bit integer, but we messed up a few
things.

During mdrun -rerun, edr writing complained about the negative step
number, implied it might be working around it, and threatened to
crash, which it can't do. Silenced the complaint during writing,
and reduced the scope of the message when reading.

Fixed TNG wrapper routines to pass a 64-bit integer like they should.

Made various infrastructure use gmx_int64_t for consistency, and noted
where in a few places the practical range of the value stored in such
a type is likely to be smaller. We can't extend the definition of XTC
or TRR, so there is no proper solution available. TNG is already good,
though.

:issue:`2006`

Fixed trr magic-number reading
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The trr header-reading routine returned an "OK" value even if the
magic number was wrong, which might lead to chaotic results
everywhere.  This led to problems if other code (e.g. cpptraj)
mistakenly wrote a wrong-endian trr file, which was then used with
GROMACS. (This should never be a thing for XDR files, which are
defined to be big endian, but such code has existed.)

:issue:`1926`

Changed to use only legal characters in OpenCL cache filename
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The option to cache JIT-compiled OpenCL short-ranged kernels needed to
be hardened, so that mdrun would write files whose names would usually
be specific to the device, but also only contain filenames that would
work everywhere, ie only alphanumeric characters from the current
locale.

Fixes for bugs introduced during development
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

These document fixes for issues that were identified as having been
introduced into the release-2016 branch since it diverged from
release-5-1. These will not appear in the final release notes, because
no formal release is thought to have had the problem. Of course, the
tracked `issues <https://gitlab.com/gromacs/gromacs/-/issues/>`_
remain available should further discussion arise.

Fixed bug in v-rescale thermostat & replica exchange
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Commit 2d0247f6 made random numbers for the v-rescale thermostat that
did not vary over MD steps, and similarly the replica-exchange random
number generator was being reset in the wrong place.

:issue:`1968`

Fixed vsite bug with MPI+OpenMP
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The recent commit b7e4f30d caused non-local virtual sites not be
treated when using OpenMP. This means their coordinates lagged one
step behind and their forces are not spread to the atoms, leading
to small errors in the forces. Note that non-local virtual sites are
only used when local virtual sites use them as a constructing atom;
the most common case is a C/N in a CH3/NH3 group with vsite H's.
Also added a check on the vsite count for debug builds.

:issue:`1981`

Fixed some thread affinity cases
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixed one deadlock in newly refactored thread-affinity code, which
happened with automatic pinning, if only part of the nodes were full.

There is one deadlock still theoretically possible: if thread-MPI
reports that setting the affinity is not possible only on a subset of
ranks, the code deadlocks.  This has always been there and might never
happen, so it is not fixed here.

Removed OpenMP overhead at high parallelization
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Commit 6d98622d introduced OpenMP parallelization for for loops
clearing rvecs of increasing rvecs. For small numbers of atoms per
MPI rank this can increase the cost of the loop by up to a factor 10.
This change disables OpenMP parallelization at low atom count.

Removed std::thread::hardware_concurrency()
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We should not use std::thread::hardware_concurrency() for determining
the logical processor count, since it only provides a hint.
Note that we still have 3 different sources for this count left.

Added support for linking against external TinyXML-2
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This permits convenient packaging of GROMACS by distributions, but
it got lost from gerrit while rebasing.

:issue:`1956`

Fixed data race in hwinfo with thread-MPI
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`1983`

Fixes for Power7 big-endian
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Now compiles and passes all tests in both double and single precision
with gcc 4.9.3, 5.4.0 and 6.1.0 for big-endian VSX.

The change for the code in incrStoreU and decrStoreU addresses an
apparent regression in 6.1.0, where the compiler thinks the type
returned by vec_extract is a pointer-to-float, but my attempts a
reduced test case haven't reproduced the issue.

Added some test cases that might hit more endianness cases in future.

We have not been able to test this on little-endian Power8; there is
a risk the gcc-specific permutations could be endian-sensitive. We'll
test this when we have hardware access, or if somebody runs the tests
for us.

:issue:`1997`
:issue:`1988`

Reduce hwloc & cpuid test requirements
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On some non-x86 linux platforms hwloc does not report
caches, which means it will fail our strict test
requirements of full topology support. There is no
problem whatsoever with this, so we reduce the
test to only require basic support from hwloc - this
is still better than anything we can get ourselves.
Similarly for CPUID, it is not an error for an
architecture to not provide any of the specific flags
we have defined, so avoid marking it as such.

:issue:`1987`

Work around compilation issue with random test on 32-bit machines
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
gcc 4.8.4 running on 32-bit Linux fails a few
tests for random distributions. This seems
to be caused by the compiler doing something
strange (that can lead to differences in the lsb)
when we do not use the result as floating-point
values, but rather do exact binary comparisions.
This is valid C++, and bad behaviour of the
compiler (IMHO), but technically it is not required
to produce bitwise identical results at high
optimization. However, by using floating-point
tests with zero ULP tolerance the problem
appears to go away.

:issue:`1986`

Updated ``gmx wham`` for the new pull setup
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This bring ``gmx wham`` up to date with the new pull setup where the pull
type and geometry can now be set per coordinate and the pull
coordinate has changed and is more configurable.

Fix membed with partial revert of 29943f
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The membrane embedding algorithm must be initialized before
we call init_forcerec(), so it cannot trivially be moved into
do_md(). This has to be cleaned up anyway for release-2017
since we will remove the group scheme be then, but for now
this fix will allow us have the method working in release-2016.

:issue:`1998`
Highlights
^^^^^^^^^^

|Gromacs| 2016 was released on August 4, 2016. Patch releases
have been made since then, please use the updated versions!  Here are
some highlights of what you can expect, along with more detail in the
links below!

* As always, we've got several useful performance improvements, with or
  without GPUs. CPU-side SIMD and threading enhancements will
  make GPU-accelerated simulations faster even if we'd left the GPU
  code alone! Thanks to these and additional GPU kernel improvements,
  in GPU-accelerated runs expect around 15% improvement
  in throughput. (And not just for plain vanilla MD, either... the
  pull code now supports OpenMP threading throughout, and
  multi-simulations have less coupling between simulations.)
* We have a new C++11 portability layer permitting us to accelerate in
  SIMD on the CPU lots of minor routines. These will also often
  improve runs that use accelerators or many nodes through better load
  balancing. POWER8, ARM64, AVX512 (KNL), and more are fully SIMD accelerated now
  because they are supported in the new portability layer!
* We made further SIMD acceleration of bonded interactions which
  reduces their calculation time by about a factor of 2. This improves
  load balance at high parallelization by a factor of 2, and shows
  significantly better scaling.
* Similarly, SIMD acceleration of SETTLE reduces the time for
  constraints by a factor of 3 to 5 - which has a strong effect for GPU runs.
* OpenCL GPU support is now available with all combinations of MPI,
  thread-MPI and GPU sharing (ie. the same as CUDA). Kernel performance
  has improved by up to 60%. AMD GPUs benefit the most, OpenCL on NVIDIA is
  generally still slow.
* Tools in the new analysis framework can handle trajectories that
  are subsets of the simulation system.
* New pull coordinate geometries angle-axis, dihedral, and normal angle.
* Checkpoint restarts work only in the cases where the implementation
  can always do what the user wants.
* The version numbering has changed to be the year of the release,
  plus (in future) a patch number. GROMACS 2016 will be the initial
  release from this branch, then GROMACS 2016.1 will have the set of
  bugs that have been fixed in GROMACS 2016, etc.
Removed mdrun features
^^^^^^^^^^^^^^^^^^^^^^

Removed SD2 integrator
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This integrator has known problems, and is in all ways inferior to
sd. It has no tests, and was deprecated in GROMACS 5.0. There are no
plans to replace it.

:issue:`1137`

Removed the twin-range scheme
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Only the (deprecated) group scheme supports this, and the Verlet scheme will not
support it in the foreseeable future.  There is now the explicit
requirement that rlist >= max(rcoulomb,rvdw).

Removed support for twin-range with VV integrators
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Group-scheme twin-ranged non-bonded interactions never worked with
velocity-Verlet integrators and constraints. There are no plans to
make that combination work.

:issue:`1137`, :issue:`1793`

Removed Reaction-Field-nec
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The reaction-field no-exclusion correction option was only introduced for
backward compatibility and a performance advantage for systems
with only rigid molecules (e.g. water). For all other systems
the forces are incorrect. The Verlet scheme does not support this
option and even if it would, it wouldn't even improve performance.

Removed AdResS module
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This feature requires the (deprecated) group scheme, and there are no
plans to port it to the Verlet scheme.

:issue:`1852`

Removed mdrun -compact
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
It is too complicated to support multiple ways of analysing per-step
data.

Removed lambda printing from mdrun log file
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`1773`

Removed GMX_NOCHARGEGROUPS
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This undocumented feature was only useful with the (deprecated) group
scheme.
Miscellaneous
^^^^^^^^^^^^^

Various improvements to documentation and tests
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

In particular, the definition of pressure in the reference manual
should be in bar, and a spurious r_ij in the force for the Morse
potential was removed. Added documentation and literature references
for membrane embedding. Improved template analysis program
documentation. gmock was patched to work with gcc 6.

:issue:`1932`

Improved make_ndx help text
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Clarified the use of boolean operators. The old help text could
incorrectly hint that AND, OR, and NOT would work as keywords.
Added a reference to ``gmx select`` that in most cases can serve as a
replacement.

:issue:`1976`

Addded checks on number of items read in mdp statements
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added checks for the number of items read in all
sscanf() statements processing data from the mdp
file.

:issue:`1945`.

Work around glibc 2.23 with CUDA
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
glibc 2.23 changed the behaviour of string.h in a way that broke all
versions of CUDA with all gcc compiler versions. The GROMACS build
system detects this glibc, and works around it by adding the
_FORCE_INLINE preprocessor define to CUDA compilation.

:issue:`1982`

Split NBNXN CUDA kernels into four compilation units
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The CUDA nonbonded kernels are now built in four different compilation units
when this is possible; ie. devices with compute capability >= 3.0. This
can dramatically reduce compilation time.

Forcing the use of a single compilation unit can be done using the
GMX_CUDA_NB_SINGLE_COMPILATION_UNIT cmake option.

:issue:`1444`

Added stream flushes when not writing newline character
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Some of our routines use the carriage return without a newline
to keep writing the status e.g. on stderr.
For some operating systems this seems to lead to the output
being cached in the buffers, so this change adds an explicit
fflush() for these print stamements.

Fixed :issue:`1772`

Supported cmap with QMMM
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Formerly, QMMM only supported bonded interactions using up to 4 atoms.
Now any number is supported and some hard-coded assumptions have been
removed.

Upgraded support for lmfit library
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Now based on lmfit 6.1. The CMake option GMX_EXTERNAL_LMFIT permits
linking an external lmfit package, rather than the one bundled in
GROMACS.

:issue:`1957`

libxml2 is no longer a dependency
""""""""""""""""""""""""""""""""""""""""""""""""""""""
GROMACS used to use libxml2 for running its test code. This has been
replaced by a bundled version of tinyxml2 (or optionally, a system
version of that library).

Disable automated FFTW3 builds on Windows
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The FFTW distribution does not include configurations to
build it automatically on windows, in particular not through
the ``./configure; make; make install`` triad.

:issue:`1961`

Remove warnings on checkpoint mismatch
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
mdrun now only warns for mismatch in minor version, build or
number of ranks used when reproducibility is requested.
Also added a separate message for not matching precision.

:issue:`1992`

Report the filename and the line number on failure
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Extend the call to gmx_fatal in fget_lines() to report the filename and
the line number where the read failed.

Handled constraint errors with EM
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
All energy minimizers could fail with random errors when constraining
produced NaN coordinates.
Steepest descents now rejects steps with a constraint error.
All other minimizer produce a fatal error with the suggestion to use
steepest descents first.

:issue:`1955`

Disable static libcudart on OS X
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Recent versions of CMake enable a static version of
libcudart by default, but this breaks builds at least
on the most recent version (10.11) of OS X, so we
disable it on this platform.

Fixed rare issue linking with clock_gettime
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Misuse of preprocessing commands might have led to inappropriate
use of clock_gettime().

:issue:`1980`

Disabled NVIDIA JIT cache with OpenCL
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The NVIDIA JIT caching is known to be broken with OpenCL compilation in
the case when the kernel source changes but the path does not change
(e.g. kernels get overwritten by a new installation). Therefore we disable
the JIT caching when running on NVIDIA GPUs. AMD GPUs are unaffected.


:issue:`1938`

Improvements to GROMACS tools
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Supported replacing solvent in ``gmx insert-molecules``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Make it possible to specify the solvent (or other set of atoms) with
``-replace`` (as a selection) for ``gmx insert-molecules``, and make the tool
replace residues from this set with the inserted molecules, instead of
not inserting there. It is assumed that the solvent consists of
single-residue molecules, since molecule information would require a tpr
input, which might not be commonly available when preparing the system.

Default random seeds have changed for some analysis tools
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
See individual tools documentation for their functionality. In some
cases, the magic value to obtain a generated seed has changed (or is
now documented.)

Made ``gmx solvate`` and ``gmx insert-molecules`` work better with PDB inputs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When both ``-f`` and ``-o`` were .pdb files, the pdbinfo struct got
out-of-sync when the atoms were added/removed.

:issue:`1887`

Tools in the new analysis framework can read trajectory files with subsets
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Make tools written for the new C++ analysis framework support analyzing
trajectories that contain an arbitrary subset of atoms.

:issue:`1861`

Made moleculetype name case sensitive
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This is useful in case you have more than 36 chains in your system
with chain IDs set. PDB allows using both uppercase letters, lowercase
letters and numbers for chain identifiers. Now we can use the maximum
of 62 chains.

Added number density normalization option for ``gmx rdf``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Add an option to ``gmx rdf`` that allows selecting a radial number density
as the normalization for the output (in addition to current raw
neighbor counts and the actual RDF).

Simplified ``gmx genconf`` by removing ``-block``, ``-sort`` and ``-shuffle``
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Option ``-block`` isn't useful since particle decomposition was removed.
Options ``-sort`` and ``-shuffle`` were undocumented and don't seem very
useful - these days they would be somebody's simple python script.

Used macros for units and conversions in ``gmx wham``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Also :issue:`1841`

Improved ``gmx sasa`` error message
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Print more information when an output group is not part of the group
selected for calculation, which should help the user diagnosing the issue.

Made ``gmx vanhove`` work without PBC
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fix ``gmx hbond`` group overlap check
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
``gmx hbond`` does not support partially overlapping analysis groups.
The check in the code was broken and never caught this, resulting
incorrect output that might OK at first sight.
Also corrected bitmasks = enums that (intentionally?) seemed to give
correct results by not using non power of 2 enum index entries.

Made ``gmx dos`` work again.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Due to an error in the index handling ``gmx dos`` always stopped with a fatal
error.

:issue:`1996`

Add checks for too much memory in ``gmx nmeig``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
``gmx nmeig`` could request storage for eigenvector output and matrices
for more than ``INT_MAX`` elements, but nearly all loop variables are int.
Now a fatal error is produced in this case. This also avoids the
confusing error message when too much memory is requested; the allocation
routine will get the correct size, but gmx_fatal prints it as a smaller
integer.
Added support for ``-first`` > 1 with sparse matrices.

Performance improvements
^^^^^^^^^^^^^^^^^^^^^^^^

GPU improvements
^^^^^^^^^^^^^^^^

In addition to those noted below, overall minor improvements contribute
up to 5% increase in CUDA performance, so depending on parameters and compilers
an 5-20% GPU kernel performance increase is expected.
These benefits are seen with CUDA 7.5 (which is now the version we recommend);
certain older versions (e.g. 7.0) see even larger improvements.

Even larger improvements in OpenCL performance on AMD devices are
expected, e.g. can be >50% with RF/plain cut-off and PME with potential shift
with recent AMD OpenCL compilers. 

Note that due to limitations of the NVIDIA OpenCL compiler CUDA is still superior
in performance on NVIDIA GPUs. Hence, it is recommended to use CUDA-based GPU acceleration
on NVIDIA hardware.


Improved support for OpenCL devices
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The OpenCL support is now fully compatible with all intra- and
inter-node parallelization mode, including MPI, thread-MPI, and GPU
sharing by PP ranks. (The previous limitations were caused by bugs in high-level
GROMACS code.)

Additionally some prefetching in the short-ranged kernels (similar to
that in the CUDA code) that had been disabled was found to be useful
after all.

Added Lennard-Jones combination-rule kernels for GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Implemented LJ combination-rule parameter lookup in the CUDA and
OpenCL kernels for both geometric and Lorentz-Berthelot combination
rules, and enabled it for plain LJ cut-off. This optimization was
already present in the CPU kernels. This improves performance with
e.g. OPLS, GROMOS and AMBER force fields by about 10-15% (but does not
help with CHARMM force fields because they use force-switched kernels).

Added support for CUDA CC 6.0/6.1
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added build-system and kernel-generator support for the Pascal
architectures announced so far (GP100: 6.0, GP104: 6.1) and supported
by the CUDA 8.0 compiler.

By default we now generate binary as well as PTX code for both sm_60 and
sm_61 and given the considerable differences between the two, we also
generate PTX for both virtual arch. For now we don't add CC 6.2 (GP102)
compilation support as we know nothing about it.

On the kernel-generation side, given the increased register file, for
CC 6.0 the "wider" 128 threads/block kernels are enabled, on 6.1 and
later the 64 threads/block remains.

Improved GPU pair-list splitting to improve performance
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Instead of splitting the GPU lists (to generate more work units) based
on a maximum cut-off, we now generate lists as close to the target
list size as possible. The heuristic estimate for the number of
cluster pairs is now too high by 0-1% instead of 10%. This results in
a few percent fewer pair lists, but still slightly more than
requested.

Improved CUDA GPU memory configuration
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This makes use of the larger amount of L1 cache
available for global load caching on hardware that supports it (K40,
K80, Tegra K1, & CC 5.2) by passing the appropriate command line
option ("-dlcm=ca").

:issue:`1804`

Automatic nstlist changes were tuned for Intel Knight's Landing
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

CPU improvements
^^^^^^^^^^^^^^^^

These improvements to individual kernels will provide incremental
improvements to CPU performance for simulations where they are active,
but their value for simulations using GPU offload are much higher,
because via the auto-tuning, they permit all kinds of resource
utilization and throughput to increase.

Optimized the bonded thread force reduction
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The code for multi-threading of bonded interactions has to combine the
forces afterwards. This reduction now uses fixed-size blocks of 32
atoms, and instead of dividing reduction of the whole range of blocks
uniformly over the threads, now only used blocks are divided
(uniformly) over the threads.  This speeds up the reduction by a
factor of the number of threads (!) for typical protein+water systems
when not using domain decomposition. With domain decomposition, the
speed up is up to a factor of 3.

Used SIMD transpose-scatter in bonded force reduction
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The angle and dihedral SIMD functions now use the SIMD transpose
scatter functions for force reduction. This change gives a massive
performance improvement for bondeds, mainly because the dihedral
force update did a lot of vector operations without SIMD that are
now fully replaced by SIMD operations.

Added SIMD implementation of Lennard-Jones 1-4 interactions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""-
The gives a few factors speed improvement. The main improvement comes
from simplified analytical LJ instead of tables; SIMD helps a bit.

Added SIMD implementation of SETTLE
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On Haswell CPUs, this makes SETTLE a factor 5 faster.

Added SIMD support for routines that do periodic boundary coordinate transformations
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Threading improvements
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

These improvements enhance the performance of code that runs over
multiple CPU threads.

Improved Verlet-scheme pair-list workload balancing
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Implemented near perfect load-balancing for Verlet-scheme CPU
pair-lists. This increases the search cost by 3%, but this is
outweighed by the more balanced non-bonded kernel times, particularly
for small systems.

Improved the threading of virtual-site code
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On many threads, a significant part of the vsites would end up in
the separate serial task, thereby limiting scaling. Now two weakly
dependent tasks are generated for each thread and one of them uses
a thread-local force buffer, parts of which are reduced by different
threads that are responsible for those parts.

Also the setup now runs multi-threaded.

Add OpenMP support to more loops
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Loops over number of atoms cause significant amount of serial time with
large number of threads, which limits scaling.

Add OpenMP parallelization for the pull code
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The pull code could take up to a third of the compute time for OpenMP
parallel simulation with large pull groups.
Now all pull-code loops over atoms have an OpenMP parallel version.

Other improvements
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Multi-simulations are coupled less frequently
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
For example, replica-exchange simulations communicate between simulations
only at exchange attempts. Plain multi-simulations do not communicate
between simulations. Overall performance will tend to improve any time
the progress of one simulation might be faster than others (e.g. it's
at a different pressure, or using a quieter part of the network).
New and improved features
^^^^^^^^^^^^^^^^^^^^^^^^^

Changed to require a C++11 compiler
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
GROMACS now requires both a C++11 and C99 compiler. For details, see
the install guide.

Changed to support only CUDA 5.0 and more recent versions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`1831`

Allowed rcoulomb > rvdw with PME
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
GROMACS has had kernels that support Coulomb PME + cut-off LJ
with rcoulomb > rvdw for a while, but these were only available via
PME load balancing. Now we allow this setup to be chosen also
through mdp options.

Added optional support for portable hardware locality (hwloc)
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added CMake support to detect and build GROMACS with hwloc, which
will improve GROMACS ability to recognize and take advantage of all
the available hardware. If hwloc is unavailable, GROMACS will fall back
on other detection routines.

Made normal-mode calculations work with shells and vsites
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Implemented shells and vsites in normal-mode analysis in mdrun and in
analysis of eigenvalues and frequencies. The normal-mode analysis
is done on real atoms only and the shells are minimized at each step
of the analysis.

:issue:`879`

Changed pull group count for coords stored in tpr file
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added a parameter ngroup to the pull coord parameters. This is now
also stored in the tpr file. This makes the pull geometry forward
compatible, which is useful since it avoid bumping the .tpr version
with every new geometry, and we expect that users want to experiment
with new geometries.

Added pull coordinate geometry angle-axis
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The new geometry is described in the docs.
Some checks in readpull.cpp where reorganized since adding new
geometries made some old logic a bit convoluted.

Added pull coordinate geometry dihedral (angle)
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
How to use the new geometry is explained in the docs.

Added pull coordinate geometry angle
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
A new subsection was added to the docs explaining the new geometry.

Replaced ``pull-print-com1,2`` mdp option with ``pull-print-com``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Changes were made to the pull output order and naming.

Added pull potential flat-bottom-high
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added the new pull coordinate type flat-bottom-high, which is a flat
potential above the reference value and harmonic below.

Added ``gmx grompp`` check for pull group
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added a check for valid pull groups in a pull coordinate.
Using a pull group index that was out of range would cause invalid
memory access.

Added new swapping functionality to computational electrophysiology module
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Support was added for ion/water position swapping for multiple ion
types and polyatomic ions, including use of a user-defined number of
ionic species, and (small) polyatomic ions.

Also added two extra .mdp file parameters 'bulk-offset' that allow the
user to specify an offset of the swap layers from the compartment
midplanes. This is useful for setups where e.g. a transmembrane
protein extends far into at least one of the compartments. Without an
offset, ions would be swapped in the vicinity of the protein, which is
not wanted. Adding an extended water layer comes at the cost of
performance, which is not the case for the offset solution.

Documentation and testing was improved.

Fixed logic for DD missing-interactions check
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The code that was intended to double check that the domain decomposition
algorithm has not missed any interactions was inactive in several
cases, and has been fixed.

:issue:`1882`, :issue:`1793`

Permitted forces and velocities to be written to compressed TNG
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If there is no uncompressed coordinate output, write forces
and velocities to the TNG file with compressed coordinate
output. If there is uncompressed coordinate output to a
TNG file, forces and velocities will be written to it.

Use a greatest common divisor to set the frequency of some TNG
data output to ensure lambdas and box shape are written at least
as often as anything else.

:issue:`1863`

Added new notes to the user when coupling algorithms are unavailable
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
mdrun will now give the user an explanatory note when pressure and/or
temperature coupling is turned off.

Added mdrun check for finite energies
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added a check that the total potential energy is finite. This check is
nearly free and can catch issues with incorrectly set up systems
before users get a confusing constraint or PME error. Note that this
check is only performed at steps where energies are calculated, so it
will often not catch an exploding system.

Added ``gmx grompp`` check for unbound atoms
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
``gmx grompp`` now prints a note for atoms that are not connected by a
potential or constraint to any other atom in the same moleculetype,
since this often means the user made a mistake.

:issue:`1958`

Improved multi-simulation signalling
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Multi-simulations (including REMD) may have need to send messages
between the simulations. For example, REMD needs to write a
fully-consistent set of checkpoint files so that the restart works
correctly, but normal multi-simulations are fine with decoupled
progress and will simulate more efficiently if they can do
so. Similarly, ``gmx_mpi mdrun -maxh -multi`` needs to synchronize
only for REMD. The implementation has been upgraded so that such
coupling happens only when an algorithm chosen by the user requires
it.

:issue:`860`, :issue:`692`, :issue:`1857`, :issue:`1942`

Changed multi-simulation nsteps behaviour
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""-

It is unclear what the expected behaviour of a multi-simulation should
be if the user supplies any of the possible non-uniform distributions
of init_step and nsteps, sourced from any of .mdp, .cpt or command
line. Previously mdrun adjusted the total number of stesps to run so
that each run did the same number of steps, but now it reports on the
non-uniformity and proceed, assuming the user knows what they are
doing.

:issue:`1857`

Added working directory to things reported in .log file
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When running GROMACS via a batch script, it is useful to know which
working directory is being used for relative paths (file names) in the
command line. This is now written alongside other header information.

Prevented fragile use cases involving checkpoint restarts and/or appending
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

All output files named in the checkpoint file (ie. that were
used in the previous run) must be present before a checkpoint
restart will be permitted. Thus,
workflows where people used things like
``gmx mdrun -s production -cpi equilibration``
are no longer available to do a "continuous" restart. Instead, use
``gmx grompp -t equilibration -o production``.

:issue:`1777`

Removed warning after OpenMP core-count check
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
In many cases ``gmx_mpi mdrun`` issued a warning that compared the total
core count with something different returned from OpenMP. This problem
is caused by inappropriate management of thread affinity masks, but
the wording of the message did not help the user realise this, so has
been removed. ``gmx_mpi mdrun -pin on`` may help improve performance in
such cases.

Preparation for hardware detection might try to force offline cores to work
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Hardware detection might be foiled by kernels that take cores offline
when work is unavailable. We are not aware of any such platforms on which
GROMACS is likely to be used, but we will probably start to see them
soon. On such platforms, if the number of cores physically present
differs from the count that are online, we try to force them online
before deciding how GROMACS will use the online cores. For now, no x86 or
PowerPC platforms need such code, so it will never run on those platforms.
The good news is that we no longer have to risk making a confusing warning
about such possibilities.

Added new suggestion for users to try e.g. hyper-threading, if its disabled
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
GROMACS tends to perform best with several hardware threads available
per core (e.g. hyper-threading turned on, on x86), and now the log file
will note explicitly when such opportunities exist.


GROMACS 2018.6 release notes
----------------------------

This version was released on February 22, 2019. These release notes document
the changes that have taken place in GROMACS since version 2018.5, to fix known
issues. It also incorporates all fixes made in previous versions,
which you can find described in the :ref:`release-notes`.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Correct free-energy Delta H output with mass lambda's
"""""""""""""""""""""""""""""""""""""""""""""""""""""

When separate lambda parameters were used for perturbed mass
free-energy contributions, these contributions were double counted
in the Delta H output used for BAR calculations. Note that dH/dlambda
was always correct

:issue:`2703`
:issue:`2849`

.. _release-notes-2018-6-gpu:

Fix incorrect LJ repulsion force switching on GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""

When using a CUDA or OpenCL GPU, the coefficient for the second order
term for the LJ repulsion in the force switching function, called 'A'
in the manual, had the wrong sign. This lead to very small errors in
the forces and the pressure. Note that the dispersion force switching
was correct. The effects of this bug on any physical results seems to
be negligible. Note that force switching is usually only used in
combination with the CHARMM force field.

:issue:`2845`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixes to improve portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix compiler flags for Power8
""""""""""""""""""""""""""""""""""""""""""""""""""

A compiler flag for Power8 processors lead to errors in the code and was removed.

:issue:`2747`
:issue:`2746`
:issue:`2734`

Miscellaneous
^^^^^^^^^^^^^
GROMACS 2018.3 release notes
----------------------------

This version was released on August 23, 2018. These release notes document
the changes that have taken place in GROMACS since version 2018.2, to fix known
issues. It also incorporates all fixes made in version 2016.5 and
earlier, which you can find described in the :ref:`release-notes`.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Multi-domain GPU runs can no longer miss pair interactions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With systems with empty space in the unit cell, GPU runs with domain
decomposition would not compute LJ and Coulomb interactions between
domains when there we no interactions between domains on a rank at some
point in time.

 - This bug only affects simulations running on GPUs with domain decomposition
   and containing empty regions of space that can lead to domains being empty.
 - Possible observations of this bug may have been seemingly random failures
   of calculations that where not reproducible when restarting a simulation
   from a checkpoint file, as the domain would then again be filled properly
   if interactions are present at the beginning.
 - It is unlikely that this bug will have unnoticed effects on all but
   very short simulations, as the missing interactions will inevitable lead
   to simulation instability and crashes.
 - If a simulation that crashed due to this bug is restarted it can contain
   a small region around the crash that will be unphysical due to some
   interactions not being calculated just before the crash itself.

**This is a critical fix and users of 2018.x series that run on GPUs should
update to this point release**

:issue:`2502`

Fix Conjugate Gradient assertion failure at end of minimization
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When the final step coincided with a coordinate output step,
conjugate gradient minimization would exit with an assertion failure
instead of writing confout.gro.

:issue:`2554`

Multi-domain Conjugate Gradient minimimization no longer segfaults.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2554`

Fix pairlist buffer with Brownian Dynamics
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With Brownian Dynamics and bd-fric > 0, the Verlet pairlist buffer would
be determined with incorrect masses for constrained atoms and virtual
sites. This would lead to a too small buffer for typical atomistic
systems with constraints.

:issue:`2613`

Avoid "atom moved to far" errors
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The introduction of the dual pair list has led to larger nstlist values,
which leads to larger atom displacements between domain decomposition
steps. This has made it more likely that the errors
"An atom moved too far between two domain decomposition steps" and
"N particles communicated to PME rank M are more than 2/3 times the cut-off
out of the domain decomposition cell ..." appear for stable systems.
Now atom displacements are correctly taken into account when determining
the minimum cell size, so these errors should only appear for unstable systems.

:issue:`2614`

grompp now checks that pull groups are not close to half the box size
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Pull groups that use a reference atom for periodic boundary treatment
should have all their atoms well within half the box size of this reference.
When this is not the case, grompp will issue a warning.

:issue:`2397`

Fixed segmentation fault in mdrun with QM/MM ONIOM scheme
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2617`

Correctly specified that PME on GPUs is only supported for dynamical integrators
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Previously PME on GPU support could run (but fail) for energy
minimization and normal-mode analysis runs.

:issue:`2578`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixed syntax error in make_gromos_rtp.py
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2557`

Fix gmx solvate topology updating
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Removed hard coded solvent names to allow updates to topology based on
solvent molecule information. Also allows updating with multiple solvent
types.

:issue:`1929`

Fix bfactor output error caused by fix for :issue:`2511`
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The fix for the PQR file output broke the output of bfactors from other tools.

:issue:`2575`

Made sure that gmx rms can skip values
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When requested to skip values, gmx rms would still output all values despite
the option. Now it only outputs values that are requested to be processed.

:issue:`2565`

Fix trjconv when not providing structure file
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

trjconv would fail with a segmentation violation when running without any structure
file due to incomplete initialization of the topology data structure. This fix adds
the missing checks that prevents the failure.

:issue:`2619`

Fix enforced rotation energy output
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""


Fixes to improve portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix nvcc host compiler check triggering
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2583`


Report up to date hwloc version information
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2591`


Disable single compilation unit with CUDA 9.0
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2561`


Miscellaneous
^^^^^^^^^^^^^

Avoid aborting mdrun when GPU sanity check detects errors
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2415`


Improve OpenCL kernel performance on AMD Vega GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The OpenCL kernel optimization flags did not explicitly turn off denorm handling
which could lead to performance loss. The optimization is now explicitly turned
on both for consistency with CUDA and performance reasons.
On AMD Vega GPUs (with ROCm) kernel performance improves by up to 30%.


GROMACS 2018.5 release notes
----------------------------

This version was released on January 22, 2019. These release notes document
the changes that have taken place in GROMACS since version 2018.4, to fix known
issues. A complete list of fixes and their descriptions can be found in
the :ref:`release-notes`.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed numerical derivative for normal-mode analysis with shell code
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Due to higher precision needs when using polarizable shell particles
the normal mode code did not work reproducibly with shells. In order
to fix this the step-size used for numerically computing the Hessian
was reduced to near machine precision. The change does not affect
the results for non-polarizable systems, such as proteins or small
molecules.

Make large PME grids work on GPU
"""""""""""""""""""""""""""""""""""""""""""

PME grids with size along Z larger than 511 would make mdrun exit
with a cryptic CUDA error.

:issue:`2779`

Fix LINCS accuracy with OpenMP when constraint triangles are present
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Constraint triangles, which usually only occur when replacing hydrogens
by virtual interaction sites in CH3 and NH3 groups, need double the number
of iterations as normal constraints. With OpenMP this would only happen
when the last OpenMP thread has at least one such triangle. This would
cause a slight loss of accuracy in inhomogeneous systems.

:issue:`2808`

Fix acceleration with ``cos-acceleration``
""""""""""""""""""""""""""""""""""""""""""

A factor of 2 was missing from the acceleration value, leading to incorrect
results when e.g. calculating viscosities.

:issue:`2572`

Fix checkpoint restart of tpr with infinite step count
""""""""""""""""""""""""""""""""""""""""""""""""""""""

An issue was introduced that caused :ref:`mdrun <gmx mdrun>` to refuse to start
when using infinite step counts. Now :ref:`mdrun <gmx mdrun>` properly accepts
those files again.

:issue:`2757`

Fix energy history file reading
"""""""""""""""""""""""""""""""

A check was missing when reading energy files from a simulation that was stopped
before the first value had been written to the file.

:issue:`2781`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix trjconv -ndec
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""

This only works for writing .xtc files. The code and documentation now
works correctly with .gro files, which was changed in 2016 release series so that
it would only write fixed-width columns.

:issue:`2813`
:issue:`2037`

Fixes to improve portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^

Warn for problematic coupling times with Nose-Hoover and Parrinello-Rahman
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When combining the Nose-Hoover and Parrinello-Rahman coupling algorithms,
resonances in the kinetic energy and pressure/volume can appear when
the two coupling times involved are similar. Now grompp warns when ``tau-p``
is less than two times ``tau-t``.

:issue:`2749`

Fixed efficiency issue with shell code minimization
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Code cleanup touching unnecessarily complex code created an efficiency
issue.  Both the issue and some of the complexity are now fixed.

:issue:`2705`

Added code generation support for NVIDIA Turing GPUs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With CUDA 10.0 NVIDIA Turing GPUs can be directly targeted by the nvcc
compiler. We now generate the appropriate set of flags for the Turing architecture
by default when using CUDA 10 (or later).

GROMACS 2018.7 release notes
----------------------------

This version was released on May 29, 2019. These release notes document
the changes that have taken place in GROMACS since version 2018.6, to fix known
issues. It also incorporates all fixes made in previous versions,
which you can find described in the :ref:`release-notes`.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Reverted broken change made in 2018.1
"""""""""""""""""""""""""""""""""""""""""""""""""

Reverted a change made in 2018.1 that broke simulations that used the
SHAKE constraint algorithm.

:issue:`2879`

Work around gcc 7 AVX512 compiler bug
"""""""""""""""""""""""""""""""""""""""

With gcc version 7 a compiler bug caused a large part of non-bonded
interactions to be ignored when compiled with AVX512 and running on more
than 16 OpenMP threads.

:issue:`2762`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixes to improve portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^

Updated release notes for 2018.6
""""""""""""""""""""""""""""""""

A :ref:`fix <release-notes-2018-6-gpu>` made to GPU kernels in 2018.6 was
thought to resolve :issue:`2845` but further investigation suggests that
the real cause is not yet known.

GROMACS 2018.2 release notes
----------------------------

This version was released on June 14, 2018. These release notes document
the changes that have taken place in GROMACS since version 2018.1, to fix known
issues. It also incorporates all fixes made in version 2016.5 and
earlier, which you can find described in the :ref:`release-notes`.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Prevented OpenCL timing memory leak
"""""""""""""""""""""""""""""""""""

When using OpenCL builds and timing, a memory leak would lead to all system memory being used up.

:issue:`2470`

Fixed MPI error after constraint failure during energy minimization
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2540`

Fixed moving frozen atoms with constraints
""""""""""""""""""""""""""""""""""""""""""

Frozen atoms which also had bond constraints could move.

:issue:`2542`

Fixed COM removal moving frozen atoms
"""""""""""""""""""""""""""""""""""""

When frozen atoms were part of center of mass motion removal groups,
they could accumulate momentum and move.

:issue:`2551`

Fixed AWH too infrequent checks for covering
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
For multidimensional AWH grids with many points relative to the number
of samples required for covering the grid, the detection of covering
could be delayed because of too infrequent checks.

:issue:`2487`

Fixed AWH continuation consistency checks
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Some kinds of changes upon restarts are now disallowed, as intended.

Fixed AWH awh-nsamples-update value checking
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Zero is now forbidden, as intended.

:issue:`2489`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixed buffer overflow in grompp warnings
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When grompp issued a warning or error with a filename/path of more than
255 characters, a buffer overflow would occur. This could also happens
during make check/test.

:issue:`2465`

Fixed infinite loop in gmx solvate
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When provided with a PDB file that had no box information for the solvent,
gmx solvate could be stuck in an infinite loop.
Fixed by disallowing empty boxes for solvent PDB files.

:issue:`2523`

Fixed enemat when the .edr file had no matching energy groups
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2508`

Fixed PQR file output
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
PQR files from gmx editconf violated the standard for the format because
they were always written in fixed format. This commit fixes the issue by
introducing a different output method for PQR files that follows the
standard.

:issue:`2511`

Fixed crash in gmx solvate
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
gmx solvate would crash due to memory corruption when using multiple solvent
molecule types.

Added check for unallowed periodic setups
"""""""""""""""""""""""""""""""""""""""""

Long distances between atoms in bonded interactions could lead to incorrect
periodicity removal. In such cases an inconsistent shift message was printed,
but the run or analysis was not terminated and other, confusing, errors
could be issued. Now an informative fatal error is issued.

:issue:`2549`

Fixes to improve portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed CUDA compilation on Windows.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2509`

Fixed SIMD support for POWER systems in double precision with gcc 8
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2421`


Fixed possible illegal instruction on KNL with Intel compiler
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2504`

Miscellaneous
^^^^^^^^^^^^^

Information message about OMP_NUM_THREADS now sent to log file
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Made it easier to track this information by writing it to the log file
in a clear way, rather than to stderr.

:issue:`2472`

Fixed inadvertent disabling of SIMD version of the integrator
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixed a bug so the SIMD version of the leap-frog integrator is chosen,
when possible. This may improve performance.

:issue:`2497`

Fixed own FFTW builds on certain AVX2/AVX512 hardware
"""""""""""""""""""""""""""""""""""""""""""""""""""""

Version 3.3.8 of FFTW fixes some known gcc-8 errors for AVX2 by removing the 
fast-math flag, and it also appears to fix an issue with failed unit tests on
AVX512-capable hardware, so we have bumped the version we download to 3.3.8.

:issue:`2541`

Switched to using more standard CMake variables for installing on GNU systems
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

GnuInstallDirs.cmake is a better approach.

Several documentation and output improvements
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

* Updated top-level README file for latest GROMACS core publication.
* Reporting about GPU detection has improved.
* ``gmx mindist -pi`` docs improved.
* Docs for mdp options relating to bonds improved.
* Fixed various typos.
* Removed a leftover mention of the twin-range scheme.
* ``gmx trjconv -ndec`` docs improved.
GROMACS 2018.1 release notes
----------------------------

This version was released on March 21, 2018. These release notes
document the changes that have taken place in GROMACS since the
initial version 2018, to fix known issues. It also incorporates all
fixes made in version 2016.5 and earlier, which you can find described
in the :ref:`release-notes`.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed leap-frog integrator with Nose-Hoover T coupling and Parrinello-Rahman P coupling
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With Parrinello-Rahman P coupling active, when applying Nose-Hoover T
coupling at an MD step where no P coupling occured, the update phase
could use outdated or garbage coupling data. Such simulations with
:mdp:`nsttcouple` equal to :mdp:`nstpcouple` are unaffected
by this issue, so few users will be impacted by this. Simulations
using other coupling algorithms are unaffected.

:issue:`2418`

Used SIMD bondeds without perturbed interactions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
In free-energy calculations that lacked bonded interactions between
perturbed atom types, the SIMD-accelerated bonded functions were
inadvertently disabled. This has been enabled, which will improve
the performance of some kinds of free-energy calculations.

Fixed bonds whose displacement was zero
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We should allow overlapping atoms in harmonic bonds. But the former
code would cause a floating point exception and incorrect free-energy
derivatives.

Fixed centre-of-mass motion removal on part of the system
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
COMM removal requested for part of the system acted on the whole
system.

:issue:`2381`

Fixed multi-simulations with multiple ranks per simulation
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
These used to crash or hang mysteriously before the simulation would
start.

:issue:`2403`

Improved inter-simulation signalling implementation
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Reduced communication overhead with either many simulations or many
ranks per simulation.

Fixed FEP calculations with SHAKE
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
All SHAKE + FEP calculations accumulated wrong values to dH/dl output,
but in some cases the result will look the same.

:issue:`2434`

Fixed handling of mdp ``define`` statement assigning preprocessor values
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Now .mdp files can configure the topology with values, as originally
intended, e.g. ``"define = -DBOOL -DVAR=VALUE"``.

:issue:`2392`

Prevented log file energy average printing dividing by zero
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If very few simulation frames have computed energies, then there may
be insufficient data for averages. If so, skip the average printing
entirely.

:issue:`2394`

Correctly set cutoff modifiers in forcerec
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The cutoff modifiers were not copied from interaction_const_t
to forcerec_t which meant only the generic kernels were used with
the group scheme. This fix will restore the performance of the
group scheme.

:issue:`2399`

Fixed box scaling in PME mixed mode using both GPU and CPU
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2385`

Re-enabled GPU support with walls and 1 energy group
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With a single non-bonded energy group and walls, we can now use a GPU
for non-bonded calculations.

Removed tumbling ice-cube warning with SD integrator
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With SD, there is friction, so ice cubes will not tumble.

Fixed assertion failure in test-particle insertion
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Erroneous logic in the TPI meant that it always failed without producing
any result.

:issue:`2398`

Avoided mdrun echoing "No option -multi"
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
mdrun would print as many messages "No option -multi" as there
are MPI ranks to stderr.
Also updated -multi to -multidir in an error message.

:issue:`2377`

Improved mdrun handling when GPUs are present but unavailable
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2415`

Fixed crash with AWH and awh1-equilibrate-histogram=yes
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When running AWH with awh1-equilibrate-histogram=yes and multiple MPI
ranks, the simulation would segmentation fault.

:issue:`2436`

Fixed issues with AWH and bias sharing
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When sharing AWH biases between multiple simulations, there were four
issues. An MPI error would occur when an individual simulation would
use more than one rank. The deconvoluted PMF would be garbage (but
the sampling was correct). with more than 32 MPI ranks for an individual
simulation, an error about a coordinate being 0 could occur.
And continuation from checkpoints could be refused.

:issue:`2433`
:issue:`2439`
:issue:`2441`
:issue:`2444`

Fixed virial with AWH and domain decomposiion
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When running AWH with domain decomposition, the AWH/pull virial
contribution would be multiplied with the number of MPI ranks.


Fixed restart bug with pull geometry direction-periodic
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With COM pulling with geometry direction-periodic, (only) at the step
of continuing from checkpoint the closest PBC image would be used
instead of the of the one closest to the reference value. This could
lead to a sharp spike in the pull force at the continuation step.

:issue:`2446`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Added check in grompp to avoid assertion failure
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With an mdp file with a parameter present with both the current name
and the old name which automatically gets replaced, an assertion
would fail. Now a fatal error is issued.

:issue:`2386`

Fixed grompp net charge check
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Use of multiple non-consecutive blocks of a moleculetype now works
correctly.

:issue:`2407`

Fixed issue with adding selection groups for TNG output
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When there were more molecule blocks than molecule types in the topology,
the output was wrong.

Fixed help text and functionality of ``pdb2gmx -missing``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This now permits dangling bonds at termini, which is occasionally useful.

Fixes to improve portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

PME on Fermi-era GPUs on large systems now works
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On older GPUs, it was possible to run into a hardware size limitation
that has now been fixed.

:issue:`2409`

GoogleTest death tests are now used in a more portable way
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Tests for GPU utility functionality are now more robust
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Non-GPU builds, and GPU builds that find incompatible or otherwise
unavailable devices will pass the tests in the manner intended.

:issue:`2405`

Used more portable python shebangs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Per https://www.python.org/dev/peps/pep-0394/#recommendation, we
should use env, and point it at python2. When we either make them 2/3
or just-3 compatible, this should change.

Some distros (notably Arch Linux) already point python at python3 so
we should choose to be explicit, and thus somewhat portable.

:issue:`2401`

Added work-around for GCC 5.3 targetting AVX512 hardware
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
GCC 5.3 has bug in overload resolution causing the AVX512
and scalar function to become ambiguous.

Used isfinite unambiguously
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Patch provdied by Veselin Kolev to quiet some compiler warnings.

:issue:`2400`

Worked around gcc-6 bug in tabulated group non-bonded kernels
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With the gcc-6 compiler, AVX and -O3, which is the default,
the tabulated non-bonded kernels of the (deprecated) group
cutoff-scheme produced incorrect energies and forces.
The errors are so large that they could not have caused latent issues.

:issue:`2424`

Detected correct AMD Zen SMT topology
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On recent AMD Zen processors, hardware thread detection and pinning
handling have been fixed, improving performance.

:issue:`2388`

Fixed POWER VSX SIMD usage for upcoming gcc version 8
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`2421`

Fixed clang 6 with CUDA 9
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Permits builds for sm_70 and may work around an issue with sm_37

:issue:`2443`

Miscellaneous
^^^^^^^^^^^^^

Made multi-atom TPI reproducible with different compilers
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Documentation enhancements
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
In particular, for handling options to mdrun relating to GPUs and
running mdrun with good performance.
GROMACS 2018.4 release notes
----------------------------

This version was released on November 12, 2018. These release notes document
the changes that have taken place in GROMACS since version 2018.3, to fix known
issues. It also incorporates all fixes made in version 2016.5 and
earlier, which you can find described in the :ref:`release-notes`.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Correct PME forces with free energy without perturbed charges/LJ
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With free-energies calculations with lambda not set to zero and no
actual perturbed charges or atom types for Lennard-Jones, the Coulomb
or LJ PME mesh forces would be scaled with lambda. Note that this bug
did not affect the, usual, setup where charges or atom types are actually
perturbed.

:issue:`2640`

Add constraint contribution to foreign Hamiltonian differences
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The contribution of perturbed constraints was missing from the foreign
Hamiltonian values. This is important for free energy calculations,
such as BAR.

:issue:`2703`

Add mass contribution to foreign Hamiltonian differences
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

For free energy calculations with perturbed masses, the kinetic energy
contribution was missing from the foreign Hamiltonian values.

:issue:`2703`

Work around bugs with expanded ensemble runs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With expanded ensemble runs, the energies would be outdated or zero
with the velocity Verlet integrator with nstcalcenergy>1 or with
other integrators when nstexpanded was not a multiple of nstcalcenergy.
In these cases mdrun now sets nstcalcenergy to 1.

:issue:`2714`
:issue:`2718`

Checkpoint continuations require suitable .tpr files
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The step of a checkpoint file used for an mdrun restart must now be
less than the number of steps in the .tpr. Formerly, the step in the
checkpoint could be any number, and mdrun -nsteps could be used to get
a particular result, but the use of that option is already deprecated.
Use gmx grompp or gmx convert-tpr to make a .tpr file that expresses
the intent.

:issue:`2717`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix mindist output file checks
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

mindist would not check if the output file needed to print residue names and
residue contacts over time was actually defined, leading to errors with
empty file name strings.

:issue:`2653`

Fix gmx helix segmentation faults
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The .tpr file is now read correctly, and the helix analysis correctly
handles selections that include proline residues.

:issue:`2701`

Fix bug in entropy calculation in gmx anaeig
""""""""""""""""""""""""""""""""""""""""""""

When gmx anaeig received an inconsistent number of atoms and
eigenvectors (fewer eigenvectors than three times the number of
atoms) the entropy calculations would use uninitialized values.

:issue:`2668`

Fixes to improve portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^

Fixed an issue where the log file could sometimes report an incorrect
initial dynamic load balancing state

:issue:`2631`

Fix Bromine parameters in amber forcefield files
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The forcefield entries for Bromine and Iron were missing the actual values to define
sigma and epsilon. The proper values have been included from parm99.dat for Bromine.
As Iron has no corresponding parameters, the entry has been removed.

:issue:`2711`

Made normal-mode analysis work for more than one molecule
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed an issue where normal mode analysis would only consider
the first copy of each molecule in a system. Also fixed issues
with vsites or shells in normal modes.

:issue:`2720`

Disallow rerun using same filename as output file
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When using identical filenames for ``-rerun`` a cryptic error was thrown because
the same file would be used for reading and writing. Now :ref:`mdrun <gmx mdrun>`
will give a helpful error message to get around this.

:issue:`2634`

Fix issue when building |Gromacs| without TNG
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Some compiler errors have been resolved that could show when building
|Gromacs| without TNG support enabled.

Bugs fixed
^^^^^^^^^^

Fixed multiple time stepping with Parrinello-Rahman and Nose-Hoover.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
These now work in correct Trotter style, applied once and scaled by
the correct number of steps.

Fixes :issue:`2031`
Fixes :issue:`2032`

Applied Berendsen pressure coupling only at nstpcouple steps
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Berendsen pressure coupling was mistakenly applied on successive
steps. Since there is no need for this, this is changed to act only on
nstpcouple steps. Note that this change prevents continuation from old
checkpoint files for Berendsen pressuring-coupling runs, since the
previous-step pressure is no longer stored.

Added missing Ewald correction for PME-User
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With :mdp-value:`coulombtype=PME-User`, the Ewald mesh energy was not subtracted
leading to (very) incorrect Coulomb energies and forces.

Fixes :issue:`2286`

Fixed incorrect dV/dlambda for walls
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The free-energy derivative dV/dlambda for walls, which can be
perturbed by changing atom types of non-wall atoms, only contained the
B-state contribution.

Fixes :issue:`2267`

Supported OpenMP for orientation restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Previously this was broken, but has been fixed and is now tested and
supported.

Fixed orientation restraint reference
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The resetting of the COM of the molecule with orientation restraints
for fitting to the reference structure was done with the COM of the
reference structure instead of the instantaneous structure. This does
not affect the restraining (unless ensemble averaging is used), only
the printed orientation tensor.

Fixes :issue:`2219`

Used graph with orientation restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With the Verlet cut-off scheme by default molecules are not made whole.
Now they are made whole when orientation restraints are used.
Added checks and assertions for correct PBC treatment with orientation
restraints.

Fixes :issue:`2228`

Fixed Ekin at step 0 with COM removal
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The kinetic energy at step 0 was computed from the velocities without
the center of mass velocity removed. This could cause a relatively
large jump in kinetic energy, especially for small systems.
Now compute_globals is called twice with COM removal so we get
the correct kinetic energy.

Fixed :ref:`gmx grompp` with Andersen massive and no COM removal
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixed a floating point exception leading to a segv.
Also fixed possible different rounding for the interval for
Andersen massive in :ref:`gmx grompp` in mdrun for the common case where tau-t
is a multiple of delta-t.

Fixes :issue:`2256`

Improved Verlet buffer constraint estimate
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The displacement estimate for a constrained atom (typically H)
rotating around the COM with a partner atom is now derived and
documented correctly.  Note that we (still) use a Gaussian with
matched variance, which results in a much larger buffer than
necessary, since the tail of the displacement distribution sets the
buffer size and the Gaussian has a long tail whereas the actual
distribution has no tail.

Fixed virtual site generation for water oxygens not named OW
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:ref:`gmx pdb2gmx` would break when generating virtual sites if water oxygens
were not named OW. Now checking for the atomnumber instead.

Fixes :issue:`2268`

Fixed thread-MPI rank choice for orientation restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Only a single rank is supported, so that must be what the thread-MPI
code will choose. There's another check later on that catches the
multi-rank MPI case.

Fixed some incorrect behavior with :ref:`gmx solvate`
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:ref:`gmx solvate` cannot replicate non-rectangular solvent boxes correctly
(there are several different places that assume a diagonal box matrix),
so give a fatal error if that is attempted.  To support some uses with
triclinic boxes, skip the replication step if the solvent and target box
sizes are already equal.

Support for general triclinic boxes can be added separately, and the
check introduced here can be valuable even in that case: it keeps a
pre-equilibrated solvent box intact if the target box size is the same.

Related to fix of :issue:`2148`

Fixed DD exact continuation in reproducible node
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With domain decomposition, the local atom density, used for setting
the search grid for sorting particles, was based on the local atom
count including atoms/charge groups that would be moved to neighboring
cells. This lead to a different density value, which in turn could
result in a different number of search grid cells and thus a different
summation order during a run compared with continuing that run from a
checkpoint, when no atoms would be moved. That difference violated
the intention of ``mdrun -reprod``, and is now fixed.

Refs Fixes :issue:`2318`

Made mdrun only stop at nstlist steps with mdrun -reprod
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Stopping mdrun with two INT or TERM signals (e.g. from Ctrl-C from the
terminal shell) would always happen right after the first global
communication step. But this breaks exact continuation. Now with
``mdrun -reprod`` a second signal will still stop at a pair-list
generation step, like with the first signal, so we can still have
exact continuation.

Fixes :issue:`2318`

Added check for GPU detection support before detecting GPU devices
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When a CUDA-enabled binary was run on a node with no CUDA driver
available, a note was issued that the version of the CUDA driver is
insufficient, which was wrong and now fixed.

Fixes :issue:`2322`

Removed duplicated lines from OPLS ffbonded.itp
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Identical lines have been removed, as identified with uniq.

Fixes :issue:`1678`.

mdrun no longer warns about NVML clocks that are at max
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If the clocks are already maxed out there is no point in echoing
warnings about not being able to set them.

Fixes :issue:`2313`.

Used reduced default tolerances for tpx comparison
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The tolerances for gmx check are mainly intended for handling slight
statistical deviations, but they can hide differences between tpr
files, when the user likely wants exact checks on small quantities
like Lennard-Jones parameters. This changes changes the default
relative tolerance to 0.000001 and the absolute tolerance to zero, so
that we only allow for any minor differences due to compiler
optimization.

Fixes :issue:`2024`.

Fixed return values of frame-reading functions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This function was based on read_first_x that returned the number of
atoms, and was documented to do the same, but has always returned a
logical boolean about whether a frame has been read. This led to
aspects of ``gmx spatial`` and ``gmx trjcat -demux`` being broken.

Fixed by returning a proper bool, and fixing the remaining logic that
used the return value in a non-boolean sense.

Refs :issue:`2157`

Removed PBC before generating TPR with group scheme
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Ensure that all molecules have been made whole before generating the
run input file when using the group scheme, to avoid error messages
for large charge groups when molecules are broken over PBC boundaries.

Fixes :issue:`2339`

Fixed PBC error in gmx_spatial
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Fixes :issue:`2157`.

Documented power spectrum options of gmx velacc
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixes :issue:`2019`.

Changed to require .tpr file for gmx cluster
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The program could crash without it, so it wasn't optional.

Fixes :issue:`2170`.

Disallowed ascii formats for gmx trjcat
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Since gmx trjcat (deliberately) does not use any .tpr file, the tool
can't handle trajectory formats such as .gro or .pdb where
atom/residue names are needed.

Fixes :issue:`2225`.

Improved grompp missing-parameters error message
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If an interaction entry had parameters but not the function type, then
the error message has been confusing. Note that even when only one
function type is implemented, the field is still required, which makes
for ready extensibility.

Refs :issue:`2144`

Checked for large energy at first step
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Also added step number to fatal error message.

Fixes :issue:`2333`

Disallowed combination of PME-user and verlet cutoff
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixes :issue:`2332`

Avoided confusing message at end of non-dynamical runs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Energy minimization, test-particle insertion, normal-mode analysis,
etc.  are not targets for performance optimization so we will not
write performance reports. This commit fixes an oversight whereby we
would warn a user when the lack of performance report is normal and
expected.

Fixes :issue:`2172`

Changed to require ``-ntmpi`` when setting ``-ntomp`` and using GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With GPUs and thread-MPI, setting only ``gmx mdrun -ntomp`` could lead
to oversubscription of the hardware threads.  Now, with GPUs and
thread-MPI the user is required to set ``-ntmpi`` when using
``-ntomp``. Here we chose that to also require ``-ntmpi`` when the
user specified both ``-nt`` and ``-ntomp``; here we could infer the
number of ranks, but it's safer to ask the user to explicity set
``-ntmpi``.  Note that specifying both ``-ntmpi`` and ``-nt`` has
always worked correctly.

Fixes :issue:`2348`
Highlights
^^^^^^^^^^

|Gromacs| 2018 was released on January 10, 2018. Patch releases may
have been made since then, please use the updated versions!  Here are
some highlights of what you can expect, along with more detail in the
links below!

As always, we've got several useful performance improvements, with or
without GPUs, and all enabled and automated by default. We are
extremely interested in your feedback on how well this worked on your
simulations and hardware. They are:

* PME long-ranged interactions can now run on a single GPU, which
  means many fewer CPU cores are needed for good performance.
* Optimized SIMD support for recent CPU architectures:
  AMD Zen, Intel Skylake-X and Skylake Xeon-SP.

There are some new features available also:

* The AWH (Accelerated Weight Histogram) method is now supported,
  which is an adaptive biasing method used for overcoming free energy
  barriers and calculating free energies (see
  http://dx.doi.org/10.1063/1.4890371).
* A new dual-list dynamic-pruning algorithm for the short-ranged
  interactions, that uses an inner and outer list to permit a longer-lived
  outer list, while doing less work overall and making runs
  less sensitive to the choice of the "nslist" parameter.
* A physical validation suite is added, which runs a series of short
  simulations, to verify the expected statistical properties,
  e.g. of energy distributions between the simulations, as a sensitive
  test that the code correctly samples the expected ensemble.
* Conserved quantities are computed and reported for more integration
  schemes - now including all Berendsen and Parrinello-Rahman schemes.
Removed features
^^^^^^^^^^^^^^^^

Removed hybrid GPU+CPU nonbonded mode
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This mode was not very useful, since it ran the non-local non-bonded
interactions on the CPU. The fraction of non-local interaction is set
by the domain decomposition, so this is not flexible.
Also this mode was not being tested.

QM/MM: removed optimization and transition-state search
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
These functionalities used to only work with old versions of Orca,
had very limited use and will possibly not work any longer now.

Updated application clock handling on Pascal+ GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Starting with Pascal (CC >= 6.0) it is no longer possible to change
application clocks without root privileges. Application
clocks are still reported for Pascal+, but there is no longer
suggestions about changing them.

Removed continuation from :ref:`gmx convert-tpr`
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Removed the obsolete option of :ref:`gmx convert-tpr` to write a tpr
file for continuation using a trajectory and energy file. This is
superseded by checkpointing.
Portability
^^^^^^^^^^^

Enabled compiling CUDA device code with clang
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
clang can be used as a device compiler by setting GMX_CLANG_CUDA=ON. A
CUDA toolkit (>=7.0) is also needed. Note that the resulting runtime
performance is usually worse than that of binaries compiled by the
official NVIDIA CUDA compiler (nvcc).

Increased the oldest cmake, compiler and CUDA versions required
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We now require gcc-4.8.1, clang-3.3 and icc-17.0.1, so we can rely on full
C++11 support. We now also require CUDA-6.5 and CMake-3.4.3.

Added check that CUDA available hardware and compiled code are compatible
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added an early check to detect when the :ref:`gmx mdrun` binary does
not embed code compatible with the GPU device it tries to use nor does
it have PTX that could have been just-in-time compiled.

Additionally, if the user manually sets GMX_CUDA_TARGET_COMPUTE=20 and
no later SM or COMPUTE but runs on >2.0 hardware, we'd be executing
just-in-time-compiled Fermi kernels with incorrect host-side code
assumptions (e.g amount of shared memory allocated or texture type).
This change also prevents such cases.

Fixes :issue:`2273`

Disabled ARM Neon native rsqrt iteration used in short-ranged interactions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixes :issue:`2261`

Avoided FTZ triggering simd test failures
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
For very small arguments on platforms without FMA support, the Intel
compiler's default usage of flush-to-zero for denormal values can lead
to slight deviations. Since this is a range we really don't care
about, and non-FMA platforms are anyway a thing of the past, just
avoid testing a very small range around that threshold for non-FMA
SIMD platforms.

:issue:`2335`

Fixed OpenCL compiles on Mac OS
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Confirmed to work on Mac OS 10.13.2 running on a Macbook Pro with
Radeon Pro 560.

:issue:`2369`

Tested that nvcc/host compiler combination works
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We now compile a trivial CUDA program during a run of CMake to catch
both unsupported nvcc/host compiler version combinations and other
unknown errors.

:issue:`1616`

Added AVX_512 and KNC symbols to FFTW SIMD test
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Otherwise the CMake code might complain loudly about FFTW not being
accelerated on KNC or KNL hosts.

Implemented changes for CMake policy 0068
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
CMake-3.9 introduced a changed behavior for RPATH vs. install_name
options on OS X. This avoids relying on functionality that will be
removed in future CMake versions.

New and improved features
^^^^^^^^^^^^^^^^^^^^^^^^^

Added support for AWH biasing
"""""""""""""""""""""""""""""
The AWH (Accelerated Weight Histogram) method is an adaptive biasing
method used for overcoming free energy barriers and calculating
free energies (see http://dx.doi.org/10.1063/1.4890371). Although
AWH can in general bias any system parameter, this change only
implements biasing of reaction coordinates. The actual force
distribution and coordinate handling is taken care of by the pull
code. AWH interacts with the pull code by registering itself as
the external potential module for the coordinate that should be
AWH biased. The AWH code sets the potential and force for those
coordinates. See the reference manual for full documentation.

It includes a feature to compute the time-integrated force
correlation, also known as the friction tensor (see
e.g. http://dx.doi.org/10.1103/PhysRevLett.108.190602). The friction
tensor defines a metric on the coordinate space and the local volume
element of this metric is a useful measure for determining which
regions need more or less sampling.

Dual pair-list buffer with dynamic pruning
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The |Gromacs| simulation engine uses a new dual pair-list algorithm with
dynamic pruning in cases where the Verlet buffer is determined
automatically (which is the default). This allows further reducing the
frequency of pair search (and domain decomposition) while avoiding
large Verlet buffers and the previously inherent increased
computational cost in the short-ranged nonbonded kernels.  This is
achieved by constructing an "outer" pair-list built infrequently,
which includes many pairs in the list that are outside the cut-off
range for most of the lifetime of the list. Such pairs can be pruned
out very efficiently every few steps and with that building a smaller, "inner"
pair-list with a shorter life-time, and importantly a correspondingly
shorter Verlet buffer (still adhering to the specified tolerance),
which is then used in the nonbonded kernels. Thanks to this,
simulations runs are significantly less sensitive to tuning the search
frequency parameter ("nstlist").
When short-ranged interactions are running on the GPU, the dynamic pruning is overlapped
with the integration on the CPU, so is usually free. This feature
improves all of simulation rate, hardware utilization, and power
consumption.

Added physical validation suite
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
These tests run series of short simulations and verify the expected
statistical properties, e.g. of energy distributions between the
simulations, as a sensitive test that the code correctly samples
the expected ensemble.

To run everything locally (which can take a few hours!) use

::

   cmake -DGMX_PHYSICAL_VALIATION=ON ..
   make
   make check-phys-run

Currently, the script is only running a few systems, checking
convergence of energy conservation in NVE system with decaying
timestep, and the ensembles generated by a few thermostating and
barostating algorithms. Other systems and ensembles covering a broader
combination of settings will be added over time.

Added reporting of conserved quantities for coupling algorithms
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The work that some more coupling algorithms (Berendsen pressure,
Berendsen temperature, and Parrinello-Rahman pressure) applies on the
system is calculated and integrated. Formulae are in the reference
manual.

Added acceleration correction VCM mode
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
New mdp option to remove the center of mass translational velocity and
correct the center of mass position, assuming linear acceleration. This
is useful e.g. for pulling on a group using an absolute reference.

Changed handling of :ref:`gmx mdrun` -gpu_id
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
As more code is able to be offloaded to the GPU, task assignment has
become more complex, and is likely to get more complex still. The
-gpu_id command-line option now merely enables the user to restrict
which of the detected GPUs are available to the automated task
assignment scheme, somewhat like the ``CUDA_VISIBLE_DEVICES`` environment
variable. For the rare cases where full control is needed,
``gmx mdrun -gputasks`` is available and documented in the user guide.

Added log output for equivalent 1x1 pair-list setup
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The |Gromacs| NxM setup can use a shorter pair-list buffer than
other codes' simpler 1x1 scheme, so our log files now report
the equivalent setup, to help people doing performance and
correctness comparisons.

New mdp input for electric fields
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

EW3DC for non-neutral systems
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added the corrections to force and energy according to
Ballenegger, Arnold, and Cerda, J. Chem. Phys. 131, 094107 2009
(http://dx.doi.org/10.1063/1.3216473). Hinted that people
read http://doi.org/10.1021/ct400626b to help make good choices.
Added a warning in grompp for charged systems with Ewald.

Reduce rounding errors in SETTLE
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The parameters for SETTLE are now computed in double precision, which
lowers the systematic error.

Made ``gmx mdrun -pforce`` terminate with non-finite forces
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The :ref:`gmx mdrun` option -pforce used to print non-finite forces,
but would not terminate the run if any were found. Now a fatal error
is issued.
Miscellaneous
^^^^^^^^^^^^^

Updated note in manual on stochastic dynamics integrator
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The comment in the SD section about Berendsen was outdated.
Added a few sentences on equilibration/damping of modes.

Added grompp note for Parrinello-Rahman + position restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This combination can be unstable and is often not desirable, so
grompp now issues a note to suggest alternatives to the user.

Refs :issue:`2330`

Clarified the description of Fmax during energy minimization
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Improved vsite parallel checking
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The vsite struct now stores internally whether it has been configured
with domain decomposition. This allows for internal checks on valid
commrec, which have now been added, and would have prevented :issue:`2257`.

Added partial support for writing masses and partial charges with TNG files
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2188`

Updated TNG to version 1.8.1
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Added data block for atom masses.

Fixes :issue:`2187` and :issue:`2250` and other bugs and warnings.

Added load balance fraction to DLB print
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
DLB can often be based on a small fraction of the total step time,
especially with GPUs. Now this is printed to md.log and stderr.

Added reference for dihedral function in OPLS.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The OPLS four-term dihedral function was not described in the
reference listed earlier, so this was updated. Also updated
the reference to the three term dihedral to an older paper.

Updated many aspects of the documentation
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Imported and updated more material from the wiki. Incorporated
suggestions arising from many tracked issues. Updated user guide,
developer guide, install guide, and reference manual.

Updated mdrun signal help text
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Updated mdrun help text on signal handling for old and recent changes
to the behavior.

Fixes :issue:`2324`

Changed to handle erroneous command line args better
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Some gmx modules need to be able to accept non-option arguments, and
some should not. Introduced enough functionality to support such
behaviour, while giving useful error messages in cases where the
command line is merely missing hyphens (which can happen e.g. when
people copy-paste from inconveniently built PDF files for tutorials).
Increased test coverage of relevant cases.

Removed some useless command-line argument strings from test cases
that never needed them.

Also tested some behaviours of handling string options, and renamed
some test input strings to reflect the intent.

:issue:`2153`

Changed to no longer allow multiple energy groups for GPU runs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Exit with a fatal error instead of only warning, since the latter
leads to writing data for energy groups that is incorrect to the
energy file.

:issue:`1822`

Removed duplications in GMXLIB search paths
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Remove entries that are duplicated, or identical to the default search
path, to avoid e.g.  listing identical force fields multiple times.

:issue:`1928`

Changed to no longer write reference pull group 0 to log
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This is an internal group used for absolute references, which cannot
be set by users, so printing it just leads to confusion.

:issue:`2143`
Improvements to |Gromacs| tools
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Split off the NMR related analyses from :ref:`gmx energy`.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
A new tool :ref:`gmx nmr` is created by straight copying code from
:ref:`gmx energy` to a new tool. The reason is to reduce complexity.

A few cleanups are introduced to pass the valgrind memory test.

Added references the :ref:`gmx nmr` in the manual.

Added selection-enabled :ref:`gmx trajectory`
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
For now, this tool only plots coordinates, velocities, and forces for
selections, so it should provide a full replacement for -ox, -ov, -of,
-com, and -mol from :ref:`gmx traj`.

Decreased memory usage in :ref:`gmx traj` and :ref:`gmx trjconv`
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Made TNG writing work with multiple identical steps
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Introduce a wrapper structure around TNG so we detect and correct for
cases when writing multiple frames with the same step, or non-zero
initial steps to TNG files.  This will avoid frames overwriting each
other, and make sure the time per frame is correct.

:issue:`2189`

Improved frame time/step handling in :ref:`gmx trjconv`
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Store the exact step in PDB/GRO file headers, and be more careful
about not claiming to have time or step information when it was not
available.  This change will avoid some of the problems described in
:issue:`2189`, but it does not yet properly fix the issue in the TNG
library.

:issue:`2189`

Fixed :ref:`gmx trjconv` to always dump at correct time
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Set frame timestep before starting the loop by reading first two
frames and rewinding, and make sure we always write something to the
dump output based on best-guess (if there is at least one input frame
present).

:issue:`1832`

Clarified :ref:`gmx editconf` help text
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
It is possible that users can confuse -c with -center so this
patch makes it clear that -center doesn't do anything unless the
user really wants to shift the center of the system away from the
middle of the box.

Fixes :issue:`2171`

Added option -water tips3p to pdb2gmx.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixes :issue:`2272`

Removed incorrect comment for CHARMM tips3p
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Removed CHARMM tips3p performance warning in :ref:`gmx pdb2gmx` input file,
since the performance loss is negligible with the
:mdp-value:`cutoff-scheme=Verlet`.

Avoided :ref:`gmx grompp` charge warning from merely rounding error
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Even though the :ref:`gmx grompp` total charge check uses double for summation,
there are rounding errors for each charge when charges are stored
in single precision. Now the charge check rounds the net charge of
molecules to integer when the difference is less than the maximum
possible sum of charge rounding errors.

Fixes :issue:`2192`

Improved pdb2gmx for nonstandard residue types
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
If explicit non-blank chain identifiers are set, it will now be a hard
error if the residue types in each chain do not match. For blank chain
ID we still need to allow detection of non-chain parts, but this case
too now provides more explicit output information.

:issue:`2370`

Allowed empty lines in hdb files
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Skip lines that consist only of whitespace. Not a universal solution
for fixing hdb files, but better than the user getting very strange
error messages that don't say anything about whitespace.

:issue:`2028`

Changed to no longer require matching names between rtp and tdb files
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This was only documented in the source. It's a remnant from the days
when all force fields were in the same directory, and no longer
necessary. With this change we will properly match all termini to all
amino acids.

:issue:`2026`
:issue:`2027`

Made duplicate atoms in bondeds an error in :ref:`gmx grompp`
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Having duplicate atom indices in bonded interactions used to be only
a warning. But since in nearly all cases this will lead to issues,
this is now a error, except for angle restraints where it can be
useful so there it is now a note.

:issue:`2141`

Made :ref:`gmx grompp` -r obligatory with position restraints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With position restraints it would often occur that users accidentally
used equilibrated coordinates instead of the original coordinates for
position restraint coordinates due to -r defaulting
to -c. Now -r always need to be supplied with position restraints,
but using the same file name as with -c will reproduce the old
behavior.

Fixed :ref:`gmx msd` when using COM removal and molecules
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Changed order of code to actually assign correct coordinates before
copying the data, and modified data structure size when using COM
removal and individual molecules.

:issue:`2043`

Fixed index error in :ref:`gmx chi`
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
An error in the index construction could lead to segfaults. However,
the actual indices were correct, so it should not have produced any
incorrect results.

:issue:`1814`

Fixed :ref:`gmx grompp` complexity for large exclusion orders
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
To avoid exploding computational complexity for highly connected
molecules with large values for excluded neighbors, avoid adding a
neighbor to the temporary nnb structure if it is already present as a
lower-order neighbor.

:issue:`2260`

Fixed :ref:`gmx density` for non-mass calculations
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We now always use mass and never charge/electron density to center
systems.

:issue:`2230`

Fixed :ref:`gmx check` for tprs with different numbers of atoms
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Fixes :issue:`2279`
Performance improvements
^^^^^^^^^^^^^^^^^^^^^^^^

Implemented support for PME long-ranged interactions on GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
A single GPU can now be used to accelerate the computation of the
long-ranged PME interactions. This feature provides excellent
performance improvements, in particular that only 2-4 CPU cores per
GPU will be about as fast as the 2016 version that needed many more
CPU cores to balance the GPU. Performance on hardware that had good
balance of GPU and CPU also shows minor improvements, and the capacity
for hardware with strong GPUs to run effective simulations is now
greatly improved.

Currently, the GPU used for PME must be either the same GPU as used
for the short-ranged interactions and in the same single rank of the
simulation, or any GPU used from a PME-only rank. mdrun -pme gpu now
requires that PME runs on a GPU, if supported. All CUDA versions and
hardware generations supported by |Gromacs| can run this code path,
including CUDA 9.0 and Volta GPUs. However, not all combinations
of features are supported with PME on GPUs - notably FEP calculations
are not yet available.

The user guide is updated to reflect the new capabilities, and more
documentation will be forthcoming.

Added more SIMD intrinsics support for PME spread and gather
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Achieved speedup on Intel KNL processors of around 11% for PME
spread/gather on typical simulation systems.

Added SIMD intrinsics version of simple update
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
In the simple case of leap-frog without pressure coupling and with at
most one temperature-coupling group, the update of velocities and
coordinates is now implemented with SIMD intrinsics for improved
simulation rate.

Add SIMD intrinsics version of Urey-Bradley angle kernel
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
For steps where energies and shift forces are not required, this kernel
improves performance, which can otherwise be rate limiting in GPU-accelerated
runs, particularly with CHARMM force fields.

Use OpenMP up to 16 threads with AMD Ryzen when automating run setup
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
AMD Ryzen appears to always perform slightly better with OpenMP
than MPI, up to using all 16 threads on the 8-core die.

128-bit AVX2 SIMD for AMD Ryzen
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
While Ryzen supports 256-bit AVX2, the internal units are organized
to execute either a single 256-bit instruction or two 128-bit SIMD
instruction per cycle. Since most of our kernels are slightly
less efficient for wider SIMD, this improves performance by roughly
10%.

Choose faster nbnxn SIMD kernels on AMD Zen
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On AMD Zen, tabulated Ewald kernels are always faster than analytical.
And with AVX2_256 2xNN kernels are faster than 4xN.
These faster choices are now made based on CpuInfo at run time.

Refs :issue:`2328`

Enabled group-scheme SIMD with GMX_SIMD=AVX2_128
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The group-scheme kernels can use AVX instructions from either the
AVX_128_FMA and AVX_256 extensions. But hardware that supports the new
AVX2_128 extensions also supports AVX_256, so we enable such support
for the group-scheme kernels.

Detect AVX-512 FMA units to choose best SIMD
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Recent Intel x86 hardware can have multiple AVX-512 FMA units, and the
number of those units and the way their use interacts with the way the
CPU chooses its clock speed mean that it can be advantageous to avoid
using AVX-512 SIMD support in |Gromacs| if there is only one such
unit.  Because there is no way to query the hardware to count the
number of such units, we run code at CMake and mdrun time to compare
the performance from using such units, and recommend the version that
is best. This may mean that building |Gromacs| on the front-end node
of the cluster might not suit the compute nodes, even when they are
all from the same generation of Intel's hardware.

Speed up nbnxn buffer clearing
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Tweaked conditional in the nonbonded GPU kernels
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
GPU compilers miss an easy optimization of a loop invariant in the
inner-lop conditional. Precomputing part of the conditional together
with using bitwise instead of logical and/or improves performance with
most compilers by up to 5%.

GROMACS 2019.3 release notes
----------------------------

This version was released on June 14, 2019. These release notes
document the changes that have taken place in GROMACS since the
previous 2019.2 version, to fix known issues. It also incorporates all
fixes made in version 2018.7 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix missing interactions with domain decomposition
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When running with domain decomposition, any interactions described by
the rarely-used topology file section
``[ intermolecular_interactions ]`` were ignored. This did not
affect normal non-bonded or intra-molecular interactions.

:issue:`2953`

Fix possible floating point exception during minimization.
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

It was possible that very small forces during minimization could lead to
a crash due to a divide by zero error. Fixed by introducing a check.

:issue:`2917`

Fix segmentation fault when using membrane embedding
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2947`

Allow AWH with pull-geometry 'direction' to be periodic
"""""""""""""""""""""""""""""""""""""""""""""""""""""""

When applying AWH to a pull coordinate with geometry 'direction'
with a AWH interval length of more than 95% of the box size,
the dimension is now made periodic.

:issue:`2946`
       
Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixed residue and molecule indexing in selections
"""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2951`

Fix PQR formatting
""""""""""""""""""""

The formatting was incorrect for some tools that use PQR files.

:issue:`2955`

Fix gmx wham with angle geometries
""""""""""""""""""""""""""""""""""

gmx wham would mix up degree and radian units leading to no overlap
or not-a-number output. **Note**: this fix is not correct, a correct
fix is applied in the next patch release.

:issue:`2609`
:issue:`3094`

Add some information for grompp error with wrong line endings
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Give meaningful error with too large grid in hbond
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When using a grid that is too large :ref:`hbond <gmx hbond>` could try to
allocate enough memory to cause a crash.

:issue:`2962`

Add some information for syntax errors with include delimiters in grompp
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2911`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed wider reference SIMD setups
"""""""""""""""""""""""""""""""""

The reference SIMD builds could use a too small memory alignment,
leading to mdrun exiting with an alignment error

:issue:`2952`

Fixed build failure with Apple Clang
""""""""""""""""""""""""""""""""""""

Builds would fail because of qsort being undefined.

Miscellaneous
^^^^^^^^^^^^^

Removed non-existent mdp option awh1-dim1-period from user guide
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2940`

Add checks for too many interactions during memory allocation
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2932`

GROMACS 2019.1 release notes
----------------------------

This version was released on February 15, 2019. These release notes
document the changes that have taken place in GROMACS since the
initial version 2019, to fix known issues. It also incorporates all
fixes made in version 2018.5 and earlier, which you can find described
in the :ref:`release-notes`.

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix error with 2D/3D dynamic load balancing
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With 2D or 3D domain decomposition with dynamic load balancing,
mdrun would exit with the error "The domain decomposition grid
has shifted too much .." when a cell size was limited.

:issue:`2830`

.. _release-notes-2019-1-gpu:

Fix incorrect LJ repulsion force switching on GPUs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When using a CUDA or OpenCL GPU, the coefficient for the second order
term for the LJ repulsion in the force switching function, called 'A'
in the manual, had the wrong sign. This lead to very small errors in
the forces and the pressure. Note that the dispersion force switching
was correct. The effects of this bug on any physical results seems to
be negligible. Note that force switching is usually only used in
combination with the CHARMM force field.

:issue:`2845`


Fix segmentation fault in mdrun with domain decomposition
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2813`

Fix segmentation fault with energy minimization with the group scheme
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Using energy minimization in combination with the group cutoff scheme
and domain decomposition could lead to a segmentation fault.

:issue:`2813`

Correct free-energy Delta H output with mass lambda's
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When separate lambda parameters were used for perturbed mass
free-energy contributions, these contributions were double counted
in the Delta H output used for BAR calculations. Note that dH/dlambda
was always correct

:issue:`2703`
:issue:`2849`

Prevent mdrun -rerun from writing incorrect free-energy output
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Now mdrun -rerun exits with a fatal error when masses or constraints
are perturbed. Their contributions to Hamiltonian differences and
derivatives were incorrectly set to zero in version 2019.

:issue:`2849`

Fix possible division by zero in enforced-rotation code
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`1431`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix trjconv -ndec
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

This only works for writing .xtc files. The code and documentation now
works correctly with .gro files, which was changed in 2016 release series so that
it would only write fixed-width columns.

:issue:`2824`
:issue:`2037`

Fix using index file groups when .tpr file not supplied
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Selections that use groups from a supplied index file can
again be used even when a .tpr file is not supplied.

:issue:`2847`

Fix tune_pme
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The tool did not work due to a file reading error that is fixed now.

:issue:`2827`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

With MSVC, disabled internal clFFT fallback used for OpenCL support
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

GROMACS requires MSVC 2017, and the GROMACS OpenCL build requires
clFFT. If clFFT is found on the user's system, then all may be well,
but the version of clFFT bundled within GROMACS cannot be built
because only MSVC 2010 is supported by clFFT at this time. A
configure-time fatal error is now issued in this case.

:issue:`2500`

Explicitly require 64-bit platforms for OpenCL
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

A 64-bit OpenCL runtime is required by GROMACS.
All known OpenCL implementations on 64-bit platforms are 64-bit
(and there are no known 32-bit platforms with 64-bit OpenCL),
hence we require a 64-bit platform at configure-time in OpenCL builds.
A known unsupported 32-bit platform is ARMv7.

Miscellaneous
^^^^^^^^^^^^^

Improved docs for applying electric fields
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
GROMACS 2019.6 release notes
----------------------------

This version was released on February 28th, 2020. These release notes
document the changes that have taken place in GROMACS since the
previous 2019.5 version, to fix known issues. It also incorporates all
fixes made in version 2018.8 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Actually fix PME forces with FE without perturbed q/LJ
""""""""""""""""""""""""""""""""""""""""""""""""""""""

PME would incorrectly ignore the mesh forces on perturbed atoms when
no charges or LJ atom types were actually perturbed. Note that this
is a rather uncommon scenario.

:issue:`2640`
:issue:`3359`

Avoid overzealous program abort with orientation restraints
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

It could happen that mdrun would abort on checking orientation
restraints in multiple molecules even though no restraints where
applied to them.

:issue:`3375`

Calculate Coulomb and LJ reciprocal terms in rerun
""""""""""""""""""""""""""""""""""""""""""""""""""

Reruns would not calculate Coulomb and LJ reciprocal terms, leading
to wrong potential energies. This bug only showed up if GROMACS was
compiled without GPU support.

:issue:`3400`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Added check for inconsistent input of distance restraint labels
in gmx disre.

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix compiler errors with Intel compiler
"""""""""""""""""""""""""""""""""""""""

Fix compiler error with Intel compiler 2019 update 5 and 2020 initial release.
Compilation was failing with ``mcpcom: core dumped`` for the file :file:`pullutil.cpp`.

Miscellaneous
^^^^^^^^^^^^^

Avoid cryptic GPU detection errors when devices are unavailable or out of memory
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`3178`
:issue:`3399`

GROMACS 2019.4 release notes
----------------------------

This version was released on October 2nd, 2019. These release notes
document the changes that have taken place in GROMACS since the
previous 2019.3 version, to fix known issues. It also incorporates all
fixes made in version 2018.7 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix incorrect pressure when atoms in CMAP cross a box boundary
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The virial calculation and thus the pressure would be incorrect
when the second and third atom involved in a CHARMM CMAP correction
term would reside in different periodic images. This can happen when
a protein is positioned over a box boundary. Note that the energy
and forces were correct, but sampling was affected when pressure
coupling was applied when a protein crossed a box boundary.

:issue:`2845`
:issue:`2867`

Fix incorrect LJ cut-off on GPU when rvdw < rcoulomb
""""""""""""""""""""""""""""""""""""""""""""""""""""

When rvdw was chosen by the user to be smaller than rcoulomb in the mdp file,
the LJ cut-off would initially be set to the Coulomb cut-off for computing
non-bonded interactions on the GPU. This only affected energy minimization,
mdrun -rerun and the first 2*nstlist steps of a normal MD run, since the correct
LJ cut-off is set when PME tuning (on by default) starts after 2*nstlist steps
(unless PME tuning was disabled with -notunepme).

:issue:`3056`


Fix (unlikely) missing bonded forces with CUDA GPUs and domain decomposition
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Forces could be missing for bonded interactions computed on CUDA GPUs with
domain decomposition when there are non-local bonded interactions, but no
non-local non-bonded interactions between two domains. Note that this is
extremely unlikely to happen, since the distance between the bonded atoms
needs to be larger than the pair-list cut-off distance and there should be no
other non-local atoms within the pair-list cut-off distance.

:issue:`3063`

Fix incorrect reporting of final kinetic energy and temperature
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With the leap-frog integrator, the kinetic energy and temperature reported
for the last step were incorrect when the last step was not divisible by
nstcalcenergy, nsttcouple or nstpcouple.

:issue:`2950`

Fix segmentation fault in grompp and mdrun with cosine COM pulling
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`3023`


Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix grompp not adding angle constraints between constraints
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When using the mdp option constraints=all-angles, angles involving
bonds supplied as constraints in the topology would be removed,
but not replaced by angle constraints.

:issue:`3067`

Fix gmx wham with angle and dihedral geometries
"""""""""""""""""""""""""""""""""""""""""""""""

gmx wham would apply an incorrect radian to degree unit conversion,
leading to no overlap or not-a-number output.

:issue:`2609`
:issue:`3094`

Fix bug in gmx xpm2ps
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The tool would fail when not being provided with a library file to read in.

:issue:`3012`

Fix bug in gmx anaeig
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

An issue was noted when reading a second set
set of eigenvectors that could lead to problems when the number
of eigenvectors was less than the three times the number of atoms.

:issue:`2972`

Fix issue with demux.pl script
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The trajectories could become discontinuous with simulations longer than 100ns
and exchange strides that are not a multiple of 1 ps. This only affected the
post-processing of trajectories generated from replica exchange simulations.

Made gmx disre work with non-consecutively labeled restraints
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2953`

Fixed writing of gro files with index groups
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

An output ``.gro`` file from from e.g. ``gmx editconf -f -n`` would
take the atom names for the output file in order from the atoms in the
input file, rather than in order from the atoms indicated by the
indices in the index file.

:issue:`3107`

Made gmx make_ndx keep chain IDs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Old style structure file reading caused the chain IDs to be overwritten with
default values.

:issue:`3070`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Disable PME OpenCL on Apple
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The Apple OpenCL compilers fail to produce a functional clFFT build.
The OpenCL PME support is therefore disabled on Apple platforms.

:issue:`2941`

Miscellaneous
^^^^^^^^^^^^^

Added AMD Zen 2 detection
^^^^^^^^^^^^^^^^^^^^^^^^^

The AMD Zen 2 architecture is now detected as different from Zen 1
and uses 256-bit wide AVX2 SIMD instructions (GMX_SIMD=AVX2_256) by default. 
Also the non-bonded kernel parameters have been tuned for Zen 2.
This has a significant impact on performance.
GROMACS 2019.2 release notes
----------------------------

This version was released on April 16th, 2019. These release notes
document the changes that have taken place in GROMACS since the
previous 2019.1 version, to fix known issues. It also incorporates all
fixes made in version 2018.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix L-BGFS minimizer
""""""""""""""""""""""""""""""""""""""""""""""""

The minimizer could fail on a number of systems.

:issue:`2641`

Disallow pull geometry direction-periodic with AWH
""""""""""""""""""""""""""""""""""""""""""""""""""

This could lead to incorrect behavior or a cryptic error message.

:issue:`2923`

Fixed mdrun -nsteps option
""""""""""""""""""""""""""

Fixed that the, deprecated, mdrun option -nsteps only allowed extension
of the simulation under certain conditions.

:issue:`2881`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

gmx cluster -clndx indices now correct
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The reported indices of trajectory frames in clusters were
too small by one.

:issue:`2926`

gmx editconf -f in.pdb -o out.pdb again preserves chain IDs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

This had been inadvertently broken and is now fixed.

:issue:`2900`


Tools again accept .tpr files as input
"""""""""""""""""""""""""""""""""""""""

The pdb2gmx, solvate, and insert-molecules tools could no longer
accept input configurations contained in .tpr format files. This
is now fixed.

:issue:`2900`

Fix segmentation fault when preparing simulated annealing inputs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

grompp was unable to prepare tpr files for inputs containing simulated annealing
procedures. The code has been fixed to allow the generation of those files again.

:issue:`2871`
       
Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix error in AVX 512 detection code
"""""""""""""""""""""""""""""""""""

The CMake detection code had a typo that could lead to wrong detection results.

Miscellaneous
^^^^^^^^^^^^^

Added warning with the use of GROMOS force fields
"""""""""""""""""""""""""""""""""""""""""""""""""

grompp now warns when a GROMOS force field is used. The GROMOS force fields
have been parametrized with a physically incorrect multiple-time-stepping
scheme for a twin-range cut-off. When used with a single-range cut-off,
physical properties, such as the density, might be off from the intended values.

:issue:`2884`

Prevented internal build of FFTW with clang and AVX-512 SIMD
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Prevented the internal build of FFTW with clang from attempting to
configure FFTW to compile with AVX-512 support. That SIMD level is not
supported by FFTW with the clang compiler, and compilation fails.

:issue:`2892`

Updated performance guide for recent Intel processors with AVX512 instruction support
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Noted the tradeoffs between CPU frequency and SIMD throughput and advising users to
prefer AVX2 over AVX512 in GPU-offload or highly parallel MPI cases.

Updated release notes for 2019.1
""""""""""""""""""""""""""""""""

A :ref:`fix <release-notes-2019-1-gpu>` made to GPU kernels in 2019.1 was
thought to resolve :issue:`2845` but further investigation suggests that
the real cause is not yet known. 

GROMACS 2019.5 release notes
----------------------------

This version was released on December 23rd, 2019. These release notes
document the changes that have taken place in GROMACS since the
previous 2019.4 version, to fix known issues. It also incorporates all
fixes made in version 2018.8 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix use of uninitialized data on PME only ranks
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When building GPU enabled versions of |Gromacs| with clang as either host only or host
and device side compiler, PME datastructures could be left uninitialized, leading
to the use of random values for LJ PME energies, virial and pressure.

The effect of this bug was that the potential and total energy could
be wrong, but not the Coulomb mesh energy. This didn't affect sampling.
The pressure could also be wrong, which would affect sampling when pressure
coupling is used, but likely the simulation would explode after a few steps.

This doesn't seem to have affected versions of |Gromacs| built
with gcc as the host side compiler.

:issue:`3120`

Fix out of range memory access with free-energy calculations
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With free-energy calculations not using lambda states, an output
buffer would be accessed one element beyond it's allocated size.
We don't expect this to have caused incorrect results, but
a memory checker would complain.

:issue:`3173`

Work around broken Apple Clang compiler in Mac OS Catalina
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
In Mac OS Catalina, the default XCode compilers checks and
enforces stack alignment. This would have been a good idea
if Apple itself did not ship a C library that violates the
stack alignment with AVX instructions are enabled.

:issue:`3199`

Fix error with intermolecular interactions and domain decomposition
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With intermolecular interactions at distances longer than the cutoff
and domain decomposition, mdrun could exit with an error message
about missing interactions.

:issue:`3204`

Fix issues with AWH with pull-geometry 'direction' to be periodic
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Removed fatal error with AWH with periodic pull-geometry 'direction'
when the distance was within 2% of half the box size.
Changed an assertion failure when the AWH interval was larger than
the box size to a fatal error.
Clarified the documentation for pull geometry 'direction-periodic'.

:issue:`2946`

Remove assertion failure with AWH when not using the initial stage
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`3217`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Make histogram output clearer
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Output gave number of events included in histogram bar as *a.u.*,
which was not clear for users.


Fix dihedral angle calculation near 180 degree boundary
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The analysis tools could incorrectly calculate properties of torsion angles and their averages
when close to the -180 or 180 degree boundary.

:issue:`3225`


Remove problematic output of gmx angle tool
"""""""""""""""""""""""""""""""""""""""""""

It could happen that the calculation of the standard deviation
for angles caused a divide by zero error for empty populations.
Because this standard deviation was meaningless, it has been
removed.

:issue:`3206`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Check that libhwloc headers and runtime match
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

It could happen that the libhwloc headers and library detection would
lead to a mismatch at compile or runtime that could cause cryptic
crashes while using mdrun.

:issue:`3200`

Miscellaneous
^^^^^^^^^^^^^

Fix .gro file formatting with large boxes
"""""""""""""""""""""""""""""""""""""""""

The |Gromacs| manual says the box components in the .gro file
format are separated by spaces. But no space was printed when
a box component, except for the first, was 1000 nm or larger
or an off-diagonal component was -100 nm or smaller.
Now at least one space is always printed. Content that was written
in a way that already had at least one space between components
is unchanged. Existing parsers that conform to the documentation
and expect whitespace separation will continue to work in all cases.

:issue:`3176`

Fix duplicate PDB CONECT record output
""""""""""""""""""""""""""""""""""""""

PDB "CONECT" record output was duplicated in some instances. Since |Gromacs| does
not use these anywhere, analysis was not affected. The behavior is now fixed.

:issue:`3206`

Fix performance issue with bonded interactions in wrong GPU stream
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

This could lead to a significant loss in performance.

:issue:`3241`
Removed functionality
^^^^^^^^^^^^^^^^^^^^^

NVML support removed on NVIDIA GPUs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
NVML support (for reporting GPU application clocks  or changing these
for higher throughput) is no longer available. It was only ever supported on
high-end hardware and changing clocks is on recent generations of hardware only
useful when root permissions were available to the user. It may become less useful
as GROMACS evolves, complicated the GROMACS code, and wasn't regularly tested or maintained.
It might return if some of these conditions change.

Support for CUDA compute capability 2.x removed
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The Fermi-era GPUs (cira 2010) are no longer in widespread use, are
not tested in Jenkins, complicated the code, and are no longer
supported.

Contrib directory removed
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This code had not been maintained in years, so likely didn't work, and
has been removed. The git history retains its memory if anybody needs
it.

BlueGene support removed
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
As most of these machines are now retired, and the ports have not been actively
maintained since |Gromacs| 5.1, the support for BlueGene and QPX SIMD has been
removed.

Implicit solvent support removed
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Since |Gromacs|-4.6, the SIMD and multi-threading support has been
mostly broken. Since nobody wants to fix it, the feature has been
removed. Old force field files with parameters for such simulations can still be
read, but the values are ignored.

Removed ``gmx mdrun -multi``
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The implementation of ``gmx mdrun -multidir`` is more reliable and works with more
features. Nobody was willing to maintain the duplicate functionality.
Bugs fixed
^^^^^^^^^^

Fix type bug in trilinic DD code
""""""""""""""""""""""""""""""""""""""""""""""""""

Fix bug with unusual off-diagonal elements communicating too few atoms.

Ensure domains are large enough for atom motion
""""""""""""""""""""""""""""""""""""""""""""""""""

Domain decomposition now makes sure that domains will always be large
enough so that atoms will not move across additional domains.

:issue:`2614`

Velocity Verlet integrators output energy averages from correct steps
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Velocity Verlet integrators would accumulate energies for writing
averages to the energy file when step-1 was a multiple of nstcalcenergy.
This has now been corrected to step being a multiple of nstcalcenergy.
Note that although this (slightly) changes the reported averages,
the averages were not incorrect.

:issue:`2718`

Fix chainsep behaviour of pdb2gmx
""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`2577`

grompp correctly checks nstexpanded against nstcalcenergy
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With expanded ensemble, but without free-energy perturbation, grompp
would not check if nstexpanded was a multiple of nstcalcenergy.
If the latter was not the case, results might have been incorrect.

:issue:`2714`

Issue with do_dssp and unknown residues
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The :ref:`do_dssp <gmx do_dssp>` tool would fail with unknown residues,
as well as have issues on Windows.

:issue:`2599`

Highlights
^^^^^^^^^^

|Gromacs| 2019 was released on December 31st, 2018. Patch releases may
have been made since then, please use the updated versions!  Here are
some highlights of what you can expect, along with more detail in the
links below!

As always, we've got several useful performance improvements, with or
without GPUs, all enabled and automated by default. We are extremely
interested in your feedback on how well this worked on your
simulations and hardware. They are:

* Simulations now automatically run using update groups of atoms whose
  coordinate updates have only intra-group dependencies. These can
  include both constraints and virtual sites. This improves performance
  by eliminating overheads during the update, at no cost.
* Intel integrated GPUs are now supported with OpenCL for offloading
  non-bonded interactions.
* PME long-ranged interactions can now also run on a single AMD GPU
  using OpenCL, which means many fewer CPU cores are needed for good
  performance with such hardware.
Changes anticipated to GROMACS 2019 functionality
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

``gmx mdrun -membed``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The feature for embedding a protein in a membrane will be retained,
but probably in a different form, such as ``gmx membed``.

``gmx mdrun -rerun``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The feature for computing potential energy quantities from a
trajectory will be retained, but probably in a different form, such as
``gmx rerun`` and ``gmx test-particle-insertion``.

Integrator .mdp options will only contain dynamical integrators
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Energy minimization will be accessed in a differt form, perhaps with
``gmx minimize`` and interpret an .mdp field for which minimizer to
use. Normal-mode analysis may be accessed with e.g. ``gmx
normal-modes``. The command-line help for these tools will thenx
be better able to document which functionality is supported when.

Much functionality in ``trjconv``, ``editconf``, ``eneconv`` and ``trjcat``
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The functionality in such tools is being separated to make it
available in composable modules, that we plan to make available as
simpler tools, and eventually via the GROMACS API that is under
development.

``gmx do_dssp`` to be replaced
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This tool is deprecated, because it is problematic for some users to
obtain and install a separate DSSP binary, so we plan to replace the
implementation at some point with a native implementation, likely
based upon xssp, and make it available under a new gmx tool name.

.. _deprecated-functionality:

Functionality deprecated in GROMACS 2019
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generation of virtual sites to replace aromatic rings in standard residues
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3254` These are thought to produce artefacts under some circumstances
(unpublished results), were never well tested, are not widely used,
and we need to simplify pdb2gmx.

``gmx mdrun -gcom``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This feature sometimes overrides the effects of various .mdp settings
in a way that is difficult to understand and report. A user who wants
to do communication between PP ranks less often should choose their
``nst*`` mdp options accordingly.

Benchmarking options only available with ``gmx benchmark``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3255` Options such as ``-confout``, ``-resethway``, ``-resetstep`` are not
intended for use by regular mdrun users, so making them only available
with a dedicated tool is more clear. Also, this permits us to customize
defaults for e.g. writing files at the end of a simulation part in ways
that suit the respective mdrun and benchmark use cases, so ``-confout``
will no longer be required.

``gmx mdrun -nsteps``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3256` The number of simulation steps described by the .tpr file can be
changed with ``gmx convert-tpr``, or altered in .mdp file before the
call to ``gmx grompp``. The convenience of this mdrun option was
outweighted by the doubtful quality of its implementation, no clear
record in the log file, and lack of maintenance.

Functionality deprecated before GROMACS 2019
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
This functionality has been declared as deprecated in previous versions
of |Gromacs|, but has not yet been removed.

The group cutoff scheme
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
All remaining aspects of the group cutoff scheme will be removed, once
a few remaining features (e.g. tabulated interactions, energy-group
exclusions, and vacuum simulations) are available with the Verlet
scheme. Deprecated in GROMACS 5.1

QM/MM support for ORCA, GAMESS and MOPAC
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
These interfaces are untested, and no maintainer has been found for them.
Deprecated in GROMACS 2018.
Portability
^^^^^^^^^^^

Increased the minimum CUDA version required
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We now require CUDA 7.0, whose features help keep the code more
maintainable.

Increased the minimum MSVC version required
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We now require MSVC 2017, so we can rely on full C++11 support and the
highest quality implementations. On this platform, we now also require
CUDA 9.0.

Updated the OpenCL requirement to version 1.2
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
We now require at least OpenCL version 1.2 both for API and kernels. All
currently targeted vendors' libraries do support it, so this is not a
restriction in any way.

Preliminary support for ARM Performance Libraries
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The ARM Performance Libraries can now be used for FFT transforms through
the FFTW compatiblity layer. This can provide performance benefits over using
a vanilla FFTW3 on recent ARMv8 architectures.
New and improved features
^^^^^^^^^^^^^^^^^^^^^^^^^

|Gromacs| build is now more reproducible
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The build system no longer embeds information about who built the
binary and where.  We used to include this information to help
troubleshoot problems and ensure checkpoint continuations are exact
where possible, but this does not seem necessary. This makes the build
closer to ``reproducible by default`` which is useful for projects
that offer distributions of reproducible software, including
|Gromacs|.

Update gmx cluster to write correct PDB files and index files with cluster frames
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:ref:`PDB <pdb>` files from gmx cluster were missing the CRYST header for box information, making
it more difficult than needed to use them with our |Gromacs| tools. Also, the :ref:`index <ndx>`
files needed for :ref:`gmx trjconv` to split up trajectories into frames corresponding
to the clusters were not written. This adds support for writing this :ref:`index <ndx>` file
as well as proper :ref:`PDB <pdb>` files.

Allow using COM of previous step as PBC reference
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Added an option (``pull-pbc-ref-from-prev-step-com``), when pulling, to use
the COM of the group of the previous step, to calculate PBC jumps instead of a
reference atom, which can sometimes move a lot during the simulation.
With this option the PBC reference atom is only used at initialization.
This can be of use when using large pull groups or groups with potentially
large relative movement of atoms.

Transitional external API headers and library
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Library access to |Gromacs| is transitioning to new infrastructure.
gmxapi 0.0.7 provides abstractions for execution environment and simulation work,
as well as development tools for extending MD simulation code without patching
the |Gromacs| source.
Client code may be built against a |Gromacs| installation.
MD plugin code may apply externally calculated forces (see restraint module) or
issue simulation stop signals through session resources available at run time
to registered plugins.
For more project information and use cases,
refer to the tracked :issue:`2585` and to
DOI `10.1093/bioinformatics/bty484 <https://doi.org/10.1093/bioinformatics/bty484>`_.
For a few examples of building on and extending |Gromacs|, refer to the
`Python package <https://github.com/kassonlab/gmxapi>`_ and sample
`restraint plugin <https://github.com/kassonlab/sample_restraint>`_ repository.

Restraint module for gmxapi MD extension code
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Provides functionality that was previously accessed by modifying the "pull" code in the
|Gromacs| source.
Client software may be built against an unmodified |Gromacs| installation.
Separately compiled MD extensions can be registered with the new Restraint
functionality at run time using simulation client code built with the new ``gmxapi`` tools.
(See above.)

Enable output of average pull forces and positions
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Normally the pull module writes instantaneous output of positions and forces, however
now it can write the average of these values over the period since the last output.
This works correctly even if a checkpoint restart intervened. This is enabled using the
new options ``pull-fout-average`` and ``pull-xout-average``.
Miscellaneous
^^^^^^^^^^^^^

grompp discourages use of constraints=all-bonds
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Common force fields, including AMBER, CHARMM and OPLS/aa, are parametrized
with bonds involving hydrogen constrained. Constraining all bonds should
be avoided, for correctness. grompp now issues a note when
constraints=all-bonds is used with these force fields when time steps
are smaller than 2.6 fs and hydrogens are not replaced by virtual sites.
Using constraints=h-bonds will also improve performance.

Documentation changed to reStructuredText
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The complete documentation has been moved to the reStructuredText 
markup format to allow building it together for display as html or as pdf.
Improvements to |Gromacs| tools
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

pdb2gmx writes total charge differently
---------------------------------------

pdb2gmx notes the total charge for each residue in the ``[atoms]``
field of the topology file it produces. The fact that this should
generally be an integer can be used for troubleshooting issues in
system or force field preparation. This printing is now done only once
per residue, rather than for every atom.

nmeig does thermochemistry
---------------------------------------

The nmeig tool that analyzes the Hessian matrix from a normal mode
analysis now generates thermochemical properties like standard
entropy, heat capacity at constant volume, internal thermal energy
and zero-point energy. The analysis is based on the harmonic
approximation that is the same as what is used in quantum chemistry.

Implement writing of LaTeX methods in report-methods
----------------------------------------------------

Added a new tool report-methods to write
a summary of methods used to set up a simulation to an output file
or to standard output.
Performance improvements
^^^^^^^^^^^^^^^^^^^^^^^^

Implemented update groups
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Domain decomposition can now be based on so-called update groups. These
are groups of atoms with dependencies during the update, which can be
constraints and virtual sites. Update groups can typically be used when
only bonds involving hydrogens are constrained and are enabled
automatically when possible. This improves performance by eliminating
MPI and OpenMP communication for constraints and virtual sites.

PME on GPU when running free energy perturbations not involving charges
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
PME can now be run on a GPU when doing free energy perturbations
that do not involve perturbing charges.

PME long-ranged interaction GPU offload now available with OpenCL
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On supported devices from all supported vendors (AMD, Intel, NVIDIA),
it is now possible to offload PME tasks to the GPU using OpenCL. This
works in the same way as the former CUDA offload. A single GPU can
now be used to accelerate the computation of the long-ranged PME
interactions. This feature means that only 2-4 CPU cores per
GPU will be about as fast as the 2018 version that needed many more
CPU cores to balance the GPU. Performance on hardware that had good
balance of GPU and CPU also shows minor improvements, and the capacity
for hardware with strong GPUs to run effective simulations is now
greatly improved.

Intel integrated GPUs are now supported for GPU offload with OpenCL
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On Intel CPUs with integrated GPUs, it is now possible to offload nonbonded tasks
to the GPU the same way as offload is done to other GPU architectures.
This can have performance benefits, in particular on modern desktop and mobile
Intel CPUs this offload can give up to 20% higher simulation performance.

Bonded interactions are now supported for CUDA GPU offload
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Common types of bonded and LJ-14 interactions found can now run on
NVIDIA GPUs with CUDA, with and without domain decomposition.
Interactions with perturbed parameters are not supported.

Added code generation support for NVIDIA Turing GPUs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
With CUDA 10.0 NVIDIA Turing GPUs can be directly targeted by the nvcc
compiler. We now generate the appropriate set of flags for the Turing architecture
by default when using CUDA 10 (or later).
GROMACS 2020.5 release notes
----------------------------

This version was released on January 6th, 2021. These release notes
document the changes that have taken place in GROMACS since the
previous 2020.4 version, to fix known issues. It also incorporates all
fixes made in version 2019.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on redmine, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix mdrun writing zero dH/dlambda and foreign lambda energies before checkpointing
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
 
With free-energy runs with separate-dhdl-file=no and nstdhdl not a multiple of
nstenergy, mdrun would write zeros for dH/dlambda and foreign energies to
the energy file for steps between the last energy frame and the checkpoint.
This would lead to errors in free-energy estimates which could go unnoticed
as values only deviate for a few steps.

:issue:`3763`

Fixed bugs with COM pulling and domain decompostion with weight or >32 ranks
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When using COM pulling and domain decomposition, the results would be
incorrect when using relative weights per atom or when using more than
32 DD MPI ranks. This would usually lead to crashes or obviously wrong
results.

:issue:`3750`

Fix incorrect AWH free-energies when multiple walkers share a bias
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The AWH free-energy output was incorrect when multiple walkers shared
an AWH bias. The error went up quadratically with the free-energy update
interval, as well as with the number of walkers. The error decreases as
update size decreases with time. This meant that with default AWH settings
the error was negligible. With a free-energy update interval of 2 ps,
we observed an error about equal to the statistical error with 32 walkers
for a rather fast reaction coordinate. For slower coordinates the error
will be smaller than the statistical error.

:issue:`3828`

Fixed conserved energy for MTTK
"""""""""""""""""""""""""""""""

When using `pcoupl=MTTK` and `tcoupl=nose-hoover`, the calculated conserved
energy was incorrect due to two errors dating back to GROMACS 4.6 and 2018,
respectively. As a result, all reported conserved energies using this
combination of temperature and pressure coupling algorithms in any GROMACS
version since GROMACS 4.6 are likely to be wrong. Note that these errors did
not impact the dynamics, as the conserved energy is only reported, but never
used in calculations. Also note that this bug only affects this exact
combination of temperature / pressure coupling algorithms.

:issue:`3796`

Fixed conserved energy for Nose-Hoover
""""""""""""""""""""""""""""""""""""""

When using `tcoupl=nose-hoover` and one or more temperature groups with
non-integer number of degrees of freedom, the calculated conserved
energy was incorrect due to an error dating back to GROMACS 2018.
Reported conserved energies using Nose-Hoover temperature coupling and
non-integer number of degrees of freedom since GROMACS 2018 are likely to
be slightly off. Note that this error does not impact the dynamics, as the
conserved energy is only reported, but never used in calculations. Also note
that this will only be noticeable when using small temperature groups or
small systems.

:issue:`3831`

Fixed kinetic energy and temperature reporting for MTTK
"""""""""""""""""""""""""""""""""""""""""""""""""""""""

When using `pcoupl=MTTK` and `tcoupl=nose-hoover`, the reported kinetic
energy and temperature were very slightly off. The integration of the
temperature coupling trailed the reporting by half a time step. Note that
these errors did not impact the dynamics, as the quantities were correctly
integrated and only wrongly reported. Also note that the difference is so
small that it is unlikely to have been significant for any application
except for rigorous algorithm validation. Finally, note that this bug
only affects this exact combination of temperature / pressure coupling
algorithms.

:issue:`3832`

Fix pull error message with angles and dihedrals
""""""""""""""""""""""""""""""""""""""""""""""""

The COM pull code could print incorrect pull group indices when mdrun exited
with an error about a too long pull distance in angle and dihedral geometries.

:issue:`3613`

Fix numerical issues in expanded ensemble
"""""""""""""""""""""""""""""""""""""""""

When performing simulated tempering or expanded ensemble simulations
with changes in the Hamiltonian that were too large, then Monte Carlo
proposals to states that were sufficiently unlikely would underflow,
causing division by zero errors. This was fixed by numerically
hardening the logical flow so that such proposals would be rejected
instead.

:issue:`3304`

Fix incorrect electric field strength with applied electric field
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The electric field generated by the electric field module would be incorrect when
used together with domain decomposition due to an error with indexing the field
to all atoms instead of just those on the current domain.

In overlap regions between domains, which have the thickness of the pairlist
cut-off distance, the electric field would be doubled (or more with 2D or
3D domain decomposition).

To validate if a simulation has been affected by the issue, users should calculate
the actual potential across the simulation box using the Poisson equation.
If this potential agrees with the one provided as the input, a simulation was not affected.

:issue:`3800`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Improve CHARMM support in gmx do_dssp
"""""""""""""""""""""""""""""""""""""

:issue:`3568`

Fix non-funtioning gmx h2order -d option
""""""""""""""""""""""""""""""""""""""""

The gmx h2order tool would always take the normal along the z-axis.

:issue:`3820`

Fix pull group index handling
"""""""""""""""""""""""""""""

The pull code would not validate its index groups correctly, leading
to infinite loops or assertions being triggered at grompp time.

:issue:`3810`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix building on OSX
"""""""""""""""""""

The code wouldn't compile due to a missing include.

:issue:`3730`

Miscellaneous
^^^^^^^^^^^^^
GROMACS 2020.6 release notes
----------------------------

This version was released on March 4th, 2021. These release notes
document the changes that have taken place in GROMACS since the
previous 2020.5 version, to fix known issues.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on redmine, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Cosine acceleration failed to abort if it could not be run
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Cosine acceleration is only compatible with the leap-frog
integrator (:mdp:`integrator = md`). |Gromacs| did, however,
accept input files requesting cosine acceleration for other
integration algorithms, and did report viscosity-related
quantities from these simulations. Since the cosine acceleration
was never applied in these cases, any results obtained from
simulations with enabled cosine acceleration and integrators
other than ``md`` should be regarded as invalid.

:issue:`3903`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix range checking bug in ``gmx covar``
"""""""""""""""""""""""""""""""""""""""

A check was inverted causing range checking to be applied wrong.

:issue:`3902`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^
GROMACS 2020.4 release notes
----------------------------

This version was released on October 6th, 2020. These release notes
document the changes that have taken place in GROMACS since the
previous 2020.3 version, to fix known issues. It also incorporates all
fixes made in version 2019.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on redmine, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Bug fix for the GPU version of LINCS in multiple domain case
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Increase in the maximum number of coupled constraints in the
domain did not trigger memory re-allocation, which is now fixed.
This can happen, e.g. when big molecule enters the domain, previously
occupied by smaller molecules. The bug does not affect the single
domain case.

Fix index handling of N-body virtual sites with domain decomposition
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Incorrect indexing would be used to handle N-body virtual sites in
the domain decomposition code. This would usually lead to crashes
due to illegal or incorrect memory usage.

:issue:`3635`

Fix assertion failure with LJ-PME and dispersion correction
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With vdw-type=PME and dispersion correction, mdrun would exit with
an assertion failure during PME tuning.

:issue:`3677`

Bug fix for FEP calculations with modular simulator and domain decomposition
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
When using the modular simulator, domain decomposition and free energy
calculations with perturbed masses, the simulation would always be
performed using the masses at lambda=0 instead of the actual lambda value.


Added workaround for RDRAND not always returning random numbers on Ryzen
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
On AMD Ryzen 3000 series CPUs, the hardware random number generator (RDRAND)
can behave incorrectly, always returning -1 (0xFFFFFFFF). When this hardware bug
is detected at runtime, |Gromacs| will switch to its software-based pseudo-random
number generator instead.

While many motherboard vendors have been distributing firmware updates that
contain microcode fixes and most motherboards are sold with these factory-installed,
there can still be some systems affected that didn't receive the updates.

In case you ran simulations on one of these systems, in theory all random
number seeding could be affected (see below for algorithms), since it would
mean the same seed is used. Even this should be fine for virtually all individual
simulations since the generated numbers are still random. The most likely case that would
be seriously affected is if you use identical starting conformations and start many
simulations with different random seeds generated automatically (instead of
manually selecting your seeds) - then the Ryzen hardware bug could mean all
your simulations actually get the same generated initial velocities, or the same stochastic
changes, etc. depending which algorithms you are using.

A list of affected algorithms can be found below:

#.  Seeding in `gmx grompp` is affected if no user supplied seed is used (e.g. if ``-1``
    is used to ask |Gromacs| to generate a seed). This can affect Langevin/Stochastic dynamics,
    v-rescale thermostat, anything Monte-Carlo related and the generation of random velocities.
#.  Decision when to exchange replicas during replica exchange simulations.
#.  Simulations using the random components from ``AWH``.
#.  Some analysis and preparation tools might be affected, e.g. free volume calculation,
    ion placement, WHAM, normal mode analysis and PME error estimates.

.. AKA  https://xkcd.com/221/

Diagnosing: to aid detecting the error, run ``gmx mdrun -debug 1`` with |Gromacs| 2020.4 or later,
which will produce a debug log, typically called ``gmx.debug``. This file will contain
the following message if the processor the program ran on is affected:

-   Hardware random number generator (RDRAND) returned -1 (0xFFFFFFFF) twice in
    a row. This may be due to a known bug in AMD Ryzen microcode.
    Will use pseudo-random number generator (PRNG) rather than hardware device.

Earlier releases will fail SeedTest.makeRandomSeed test from unit tests suite on the affected systems.
To check, run ``make check`` in your build folder. You can also find a sample testing code at the link below.

For more information on the issue, please check
`this website <https://arstechnica.com/gadgets/2019/10/how-a-months-old-amd-microcode-bug-destroyed-my-weekend/>`_.

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix default output with gmx trjcat -demux
"""""""""""""""""""""""""""""""""""""""""

Files would not be written when using default file name output.

:issue:`3653`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

CUDA 11.0 supported
"""""""""""""""""""

A build with CUDA 11.0 now configures and passes tests.
Building with CUDA 11.0 means that hardware with CC 3.0 is no longer supported,
while CC 8.0 can now be used.

:issue:`3632`

Fix building with MSVC
""""""""""""""""""""""

The build would fail due to a missing header.

:issue:`3669`

Only check for RDTSCP on x86 platforms
""""""""""""""""""""""""""""""""""""""


Miscellaneous
^^^^^^^^^^^^^

Fix crash of grompp when the whole system is frozen
"""""""""""""""""""""""""""""""""""""""""""""""""""

When the whole system would be frozen, grompp would crash with
a segmentation fault.

:issue:`3683`

Fixes the unexpected change in molecule indexing in output after simulation
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Molecule indices of repeat molecules are now again numbered consecutively as
expected (instead of all ``1``).

:issue:`3575`

Fix ``INTERFACE_INCLUDE_DIRECTORIES`` for ``libgromacs`` CMake target
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:file:`libgromacs.cmake` was malformed, referencing non-existent directories.

:issue:`3592`
GROMACS 2020.1 release notes
----------------------------

This version was released on March 3rd, 2020. These release notes
document the changes that have taken place in GROMACS since the
previous 2020 version, to fix known issues. It also incorporates all
fixes made in version 2019.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix fatal error with mdrun -multidir with more than 1 rank per simulation
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

:issue:`3296`

Fix deadlock in mdrun runs with multiple ranks and separate PME ranks
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When multiple PP ranks as well as separate PME ranks are used, mdrun could
deadlock before starting the PP-PME balancing.

:issue:`3335`

Avoid mdrun assertion failure when running with shells and update on a GPU
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

A check for shells has been added in the mdrun task assignment code,
so that mdrun falls back to CPU or produces a clear error message
when attempting to run with shells and update on a GPU.

:issue:`3303`

Allow large prime factors in the mdrun MPI rank count
"""""""""""""""""""""""""""""""""""""""""""""""""""""

The domain decomposition would refuse to run with large prime factors
in the MPI rank count even when the grid was specified by the user.

:issue:`3336`

Actually fix PME forces with FE without perturbed q/LJ
""""""""""""""""""""""""""""""""""""""""""""""""""""""

PME would incorrectly ignore the mesh forces on perturbed atoms when
no charges or LJ atom types were actually perturbed. Note that this
is a rather uncommon scenario.

:issue:`2640`
:issue:`3359`

Avoid deadlock when checking for missing DD interactions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When missing bonded interactions after domain decomposition were detected,
mdrun was deadlocking instead of exiting with a failure.

:issue:`3373`

Fix checkpoint restarts using Parrinello-Rahman and md-vv
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Checkpoints using Parrinello-Rahman and md-vv (only implemented in
the new modular simulator approach) could not be read.

:issue:`3377`

Avoid overzealous program abort with orientation restraints
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

It could happen that mdrun would abort on checking orientation restraints in multiple
molecules even though no restraints where applied to them.

:issue:`3375`

Add fatal error for mdrun -multidir when simulations sharing state start at different step
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When (re)starting mdrun -multidir for simulations sharing state data
(e.g., replica exchange, AWH with bias sharing or NMR ensemble averaging)
having a different initial step only caused a note to be printed, which
could lead to simulations getting out of sync. Now a fatal error is issued
in this situation.

:issue:`2440`
:issue:`3990`

Correct skewed box using modular simulator without DD
"""""""""""""""""""""""""""""""""""""""""""""""""""""

Using modular simulator without DD, it was not checked whether the box
was getting overly skewed when using pressure control.

:issue:`3383`

Fix NMR restraints using modular simulator
""""""""""""""""""""""""""""""""""""""""""

Using NMR restraints (distance or orientation restraints) under modular simulator
did not work as expected. All orientation restraint simulations would fail with a
segmentation fault, as would distance restraint simulations using time averaging.
All other distance restraint simulations would run correctly, but output to the
energy trajectory would only occur if it coincided with general energy writing
steps.

:issue:`3388`

Avoid integer overflow when using dispersion correction
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

A change in the integer type storing the index meant that the value could overflow
and turn negative, leading to wrong lookup and unphysical values.

:issue:`3391`

Fix too small pairlist buffer on Intel GPUs
"""""""""""""""""""""""""""""""""""""""""""

The pairlist buffer generated for Intel GPUs was slightly too small,
because it assumed a 4x4 atom-cluster pair kernel instead of 4x2.

:issue:`3407`

Fix checkpoint files getting out of sync with simulations sharing data
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When simulations share data, e.g., replica exchange, AWH with bias sharing
or NMR ensemble averaging, MPI barrier have now been added before renaming
the checkpointing files to avoid that checkpoints files from the simulations
can get out of sync. Now in very unlikely cases some checkpoint files might
have temporary names, but all content will be in sync.

:issue:`2440`

Fix simulations using graph and modular simulations
"""""""""""""""""""""""""""""""""""""""""""""""""""

Simulations using modular simulator and a graph object would fail with a
segmentation fault.

:issue:`3389`

Fix center of mass motion removal with frozen atoms
"""""""""""""""""""""""""""""""""""""""""""""""""""

When frozen atoms were part of center of mass motion removal groups,
they would still contribute to the mass of those groups. This meant that
the COM velocity correction was (slightly) too small. Now completely
frozen atoms are removed from COM removal groups by grompp.
When atoms are only frozen along one or two dimensions and part of
a COM removal group, grompp now issues a warning.

:issue:`2553`

Fix temperature calculation when center of mass motion is removed for part of the system
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

In the uncommon case where the center of mass motion is removed for part of the system
but not the whole system, the number of degrees of freedom for the part without
COMM removal would be incorrectly lowered by 3.

:issue:`3406`

Fix possible issue with picking undefined NB kernel types
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The CPU reference implementations for the NB kernels were missing some definitions for specific kernel
types. This only affected installations that have SIMD explicitly turned off, something that is
unlikely to happen in production environments.

:issue:`2728`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Add support for ICC NextGen
"""""""""""""""""""""""""""

Add support for Intel Compiler based on LLVM technology.
To compile GROMACS with this compiler use ``CXX=icpc CXXFLAGS=-qnextgen cmake``.

Document known issues with OpenCL on Volta and Turing
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

:issue:`3125`

Miscellaneous
^^^^^^^^^^^^^

Fix check for modified source files in release tarballs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""
It could happen that modifications to the source tree were not picked
up if they happened after the build directory had been generated.

:issue:`3302`

GROMACS 2020.7 release notes
----------------------------

This version was released on February 3rd, 2022. These release notes
document the changes that have taken place in GROMACS since the
previous 2020.6 version, to fix known issues.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on redmine, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixed bug with GPU LINCS occasionally shifting atoms in wrong direction
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Due to missing blocking synchronizations in the CUDA version of LINCS,
the shared memory was occasionally overwritten with the new data. This
may slightly affect the final coordinates of the shifted atoms.

:issue:`4199`

Fix calculation of restraint potential for large restraint deviations
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The calculation in the code did not follow the description of the potential in the manual
but the potential continued to grow quadratically instead of linearly as it should.

:issue:`4346`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^
GROMACS 2020.3 release notes
----------------------------

This version was released on July 9th, 2020. These release notes
document the changes that have taken place in GROMACS since the
previous 2020.2 version, to fix known issues. It also incorporates all
fixes made in version 2019.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on redmine, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fix incorrect reading of certain older tpr files
""""""""""""""""""""""""""""""""""""""""""""""""

Certain older tpr files could be read incorrectly, usually leading to an exit
with a memory allocation error.

Fix segmentation fault with gmx lie
"""""""""""""""""""""""""""""""""""

The tool would crash due to mismatching sizes of energy terms in the file and F_NRE.

:issue:`3547`

Fix matrix reading in gmx xpm2ps
""""""""""""""""""""""""""""""""

The tool would fail to read a matrix if no second matrix was provided.

:issue:`3551`

Fix uninitialized variable warnings in gmx hbond
""""""""""""""""""""""""""""""""""""""""""""""""

Tool would produce garbage due to using uninitialized memory.

:issue:`3550`

Actually fix gmx do_dssp
""""""""""""""""""""""""

The tool was still broken and gave incorrect results after the previous fix.

:issue:`3444`

Allow configuration of dssp default path
""""""""""""""""""""""""""""""""""""""""

Users can configure the default path for dssp using GMX_DSSP_PROGRAM_PATH.

:issue:`3520`

Avoid segmentation fault in gmx genrestr
""""""""""""""""""""""""""""""""""""""""

The tool could fail when running simple inputs due to memory access errors
caused by accessing free'd memory.

:issue:`3582`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Update MSVC SIMD flags
""""""""""""""""""""""
Newly supported SIMD flags may improve performance on recent x86 running Windows.

Fix error with tinyxml2 linking
"""""""""""""""""""""""""""""""
The signature for linking the external library was wrong.

Miscellaneous
^^^^^^^^^^^^^

Updated message on using GPU with non-dynamical integrator
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The GPU implementation of PME and bonded forces requires dynamical integrator.
The message that informs user why using GPU for PME or bonded forces is not
supported with non-dynamical integrator was made more clear.

GROMACS 2020.2 release notes
----------------------------

This version was released on April 30th, 2020. These release notes
document the changes that have taken place in GROMACS since the
previous 2020.1 version, to fix known issues. It also incorporates all
fixes made in version 2019.6 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Ewald dipole correction incorrect without domain decomposition
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Ewald dipole correction (epsilon-surface != 0) is now disabled when not
using domain decomposition. With domain decomposition, it only works
when each molecule consists of a single update group (e.g. water).
This will be fixed in release-2021.

:issue:`3441`

Expanded ensemble simulations restarted from checkpoints
""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When restarting expanded ensemble simulations from checkpoints, expanded
ensemble would silently refuse to run, and simulations would remain in
their original lambda state.

:issue:`3465`

Fixed free energy calculations with LJ PME
""""""""""""""""""""""""""""""""""""""""""

Fixed an issue that calculated wrong long-range corrections when using
free energy perturbation with ``vdwtype = pme``. This affected forces,
energies, lambda derivatives and foreign lambdas.

:issue:`3470`

The velocities of the center of mass are now removed correctly in case of -update gpu
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When the center of mass motion is removed, the velocities are updated in the CPU memory.
In case of GPU update, they should be copied back to the GPU memory after they were updated
on the CPU. This affected most runs where the velocity of the center of mass has to be removed,
in particular these where this velocity is large in the beginning of the run.

:issue:`3508`

Fix checkpoint restart with non-zero initial step
"""""""""""""""""""""""""""""""""""""""""""""""""

When restarting from the checkpoint, the init-step mdp parameter was ignored while
checking if the simulation is already finished. As a result, this check only worked
properly when init-step was 0 or was not specified.

:issue:`3489`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Time output unit fixes
^^^^^^^^^^^^^^^^^^^^^^

When selecting a time unit of microseconds or larger,
``gmx tool -tu`` now produces the correct string in .xvg and
particularly .xvgr plots

Fix do_dssp
^^^^^^^^^^^

The tool would fail with a segmentation fault.

:issue:`3444`

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Give clearer message about not detecting IBM_VSX support in gcc > 9
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

CMake would fail with a confusing error message.

:issue:`3380`

Miscellaneous
^^^^^^^^^^^^^

Fixed initial DLB state reporting
"""""""""""""""""""""""""""""""""

The initial DLB state was reported incorrectly in the log file when
the either "on" or "auto" value was the chosen at mdrun startup.
Removed functionality
^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Group cut-off scheme
""""""""""""""""""""

The group cut-off scheme has been removed. Several kinds of simulation
that depend on it no longer work.

   * Simulations under vacuum conditions are not supported.
   * User supplied tables for short-range nonbonded interactions are not supported.
   * Switched short-range nonbonded interactions with PME are not supported. 
   * Membrane embedding is deactivated.
   * QMMM is not supported.

:issue:`1852`

Generalized reaction-field
""""""""""""""""""""""""""

This only worked correctly with the group scheme. Note that generalized
reaction-field simulations can still be performed using standard
reaction field and computing the dielectric constant manually.
       
gmx anadock
"""""""""""
The gmx anadock tool was removed since it does not belong in gromacs
(it analyzes AutoDock outputs).

gmx dyndom
""""""""""
The gmx dyndom tool was removed since it does not belong in gromacs
(it analyzes DynDom outputs).

gmx morph
"""""""""
The gmx morph tool was removed since it yields non-physical structures
that can easily be done by a script.

gmx mdrun -gcom
"""""""""""""""

This feature sometimes overrode the effects of various .mdp settings
in a way that was difficult to understand and report. A user who wants
to do communication between PP ranks less often should choose their
``nst*`` mdp options accordingly.
Bugs fixed
^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

gmx mdrun -append now requires that a checkpoint is found
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Previously ``gmx mdrun -append`` would start from the .tpr
configuration (and thus not append) when the checkpoint file was missing.

The Verlet buffer now correctly handles perturbed constraints
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With free-energy calculations with perturbed constraints, the Verlet buffer
could be underestimated when constraint lengths were perturbed. As usually only
very few constraints are perturbed, the effect is very small and much smaller
than the overestimate of the buffer due to approximations, so the results
of most runs with perturbed constraints will not have been affected.

:issue:`4395`
Highlights
^^^^^^^^^^

|Gromacs| 2020 was released on January 1, 2020. Patch releases may
have been made since then, please use the updated versions!  Here are
some highlights of what you can expect, along with more detail in the
links below!

As always, we've got several useful performance improvements, with or
without GPUs, all enabled and automated by default. In addition,
several new features are available for running simulations. We are extremely
interested in your feedback on how well the new release works on your
simulations and hardware. The new features are:

* Density-guided simulations allow "fitting" atoms into three-dimensional
  density maps. 
* Inclusion of gmxapi 0.1, an API and user interface for managing
  complex simulations, data flow, and pluggable molecular dynamics extension code.
* New modular simulator that can be built from individual objects describing different
  calculations happening at each simulation step.
* Parrinello-Rahman pressure coupling is now also available for the md-vv integrator.
* Running almost the entire simulation step on a single CUDA compatible GPU for supported
  types of simulations, including coordinate update and constraint calculation.


.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!
.. _anticipated-changes:

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

The core |Gromacs| team wants to let users and downstream developers
know about impending changes so that disruption is minimized. Do get
in touch if you feel something inappropriate is planned!

Deprecated functionality often remains in |Gromacs| for a year or
more, but this should not be relied upon.

Changes anticipated to |Gromacs| 2020 functionality
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

``gmx mdrun -membed``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The feature for embedding a protein in a membrane will be retained,
but probably in a different form, such as ``gmx membed``.

``gmx mdrun -rerun``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The feature for computing potential energy quantities from a
trajectory will be retained, but probably in a different form, such as
``gmx rerun`` and ``gmx test-particle-insertion``.

Integrator .mdp options will only contain dynamical integrators
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Energy minimization will be accessed in a differt form, perhaps with
``gmx minimize`` and interpret an .mdp field for which minimizer to
use. Normal-mode analysis may be accessed with e.g. ``gmx
normal-modes``. The command-line help for these tools will then
be better able to document which functionality is supported when.

Much functionality in ``trjconv``, ``editconf``, ``eneconv`` and ``trjcat``
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The functionality in such tools is being separated to make it
available in composable modules, that we plan to make available as
simpler tools, and eventually via the GROMACS API that is under
development.

``gmx do_dssp`` to be replaced
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
This tool is deprecated, because it is problematic for some users to
obtain and install a separate DSSP binary, so we plan to replace the
implementation at some point with a native implementation, likely
based upon xssp, and make it available under a new gmx tool name.

Functionality deprecated in |Gromacs| 2020
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Support for 32bit architectures
"""""""""""""""""""""""""""""""
:issue:`3252` There are no current or planned large scale resources using 32bit architectures,
and we have no ability to properly test and evaluate them.

Free-energy soft-core power 48
""""""""""""""""""""""""""""""
:issue:`3253` Free-energy soft-core power 48 is almost never used and is therefore deprecated.

Support for Armv7
"""""""""""""""""
:issue:`2990` There are several issues with current code for the architecture, and we don't
have the resources for support and fix issues related to it. As the architecture has no
large HPC impact it is thus deprecated.

Functionality deprecated in |Gromacs| 2019
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generation of virtual sites to replace aromatic rings in standard residues
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3254` These are thought to produce artefacts under some circumstances
(unpublished results), were never well tested, are not widely used,
and we need to simplify pdb2gmx.

Benchmarking options only available with ``gmx benchmark``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3255` Options such as ``-confout``, ``-resethway``, ``-resetstep`` are not
intended for use by regular mdrun users, so making them only available
with a dedicated tool is more clear. Also, this permits us to customize
defaults for e.g. writing files at the end of a simulation part in ways
that suit the respective mdrun and benchmark use cases, so ``-confout``
will no longer be required.

``gmx mdrun -nsteps``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
:issue:`3256` The number of simulation steps described by the .tpr file can be
changed with ``gmx convert-tpr``, or altered in .mdp file before the
call to ``gmx grompp``. The convenience of this mdrun option was
outweighted by the doubtful quality of its implementation, no clear
record in the log file, and lack of maintenance.
Portability
^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Added support for Hygon Dhyana CPU architecture
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Support for hardware detection and related heuristics has been implemented
for the Hygon Dhyana derived from the first-gen AMD Zen which it shares most
of its architectural details with.

Enabled PME offload support with OpenCL on NVIDIA and Intel GPUs
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Thanks to portability improvements, the previously disabled PME OpenCL offload
is now enabled also on NVIDIA and Intel GPUs.

Fixed building on Solaris with GCC
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
GROMACS now builds on Solaris with GCC (tested on illumos distribution
openindiana, "Hipster" rolling release, using GCC 5, 6, 7, and 8).
New and improved features
^^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Density-guided simulations
""""""""""""""""""""""""""

Users can now apply additional forces from three dimensional reference
densities. These forces can be used to "fit" atoms into the densities by
increasing the similarity of a simulated density to the reference density.

Multiple protocols are available for how to calculate simulated densities
as well as how the similarity between a reference and a simulated density is
evaluated.

Virtual site on the line through two atoms at fixed distance
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

This is use useful for e.g. halogens in the CHARMM force field.

:issue:`2451`

gmxapi Python support
"""""""""""""""""""""

Data flow driven simulation and analysis from Python is now available in a
default |Gromacs| installation when users install the *gmxapi* Python package.
See :ref:`gmxapi`.

New modular simulator
"""""""""""""""""""""

A new approach for how to combine individual calculation steps during a single simulation
step is introduced, with focus on extensibility and modularization. This simulator is the default
now for simulations using velocity-verlet in NVE, NVT (v-rescale thermostat only), NPT (v-rescale
thermostat and Parrinello-Rahman barostat only), or NPH (Parrinello-Rahman barostat only), with or
without free energy perturbation.
Miscellaneous
^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

grompp now warns if macros in mdp "define" field are unused in topology
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Macros defined in the mdp (with e.g. -DPOSRES) now cause a warning
in grompp if they are not encountered while parsing the topology file

:issue:`1975`

Introduced CMake variable GMX_VERSION_STRING_OF_FORK
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
To help users and developers understand which version of |Gromacs| is
being used, anybody providing a forked version of |Gromacs| shall set 
GMX_VERSION_STRING_OF_FORK in the source code (or if necessary when 
running CMake). It will then appear in the log file and users will know
which version and fork of the code produced the result.

Provide checksum to validate release tarballs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Released versions of |Gromacs| will now provide a checksum calculated
from the files participating in building the binaries. When building
|Gromacs| from the tarball, the files will be checksummed again and
compared against the checksum generated during the release build. If the
checksums don't match, the version string is modified to indicate that
the source tree has been modified, and the information is printed in the
log files for the users. If checksumming has not been possible (either due
to missing Python during installation, or because the original checksum file
is missing), this is indicated through a different version string.

:issue:`2128`

Updated physical constants to CODATA 2018
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Reproducibility of computed quantities is easiest to achieve if software
stays up to date with the standards. The values for standard units have thus
been updated to conform with the data available
`here <http://www.codata.org/committees-and-groups/fundamental-physical-constants>`_.

Change grompp warning about decoupling without SD to a note
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The warning that grompp issues when decoupling a molecule
without the use of the SD integrator has been changed to a note,
since there are valid use cases for using normal MD when not
running in the completely decoupled state.

:issue:`2767`

Improvements to |Gromacs| tools
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixed bug in gmx order -calcdist
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
The reference position for the distance calculation was calculated
wrongly.

Improved grompp usability by rejecting more invalid .mdp lines
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Lines like

    ref-t 298
    = 0.1
    =

are now all rejected with a descriptive message, which will help
prevent some kinds of errors in constructing .mdp inputs. Note that an
.mdp parameter name with a missing value is still accepted, and leads
to the default behavior for that parameter.

Added convert-trj
"""""""""""""""""""""""""""""""""""""""
A new tool :ref:`convert-trj <gmx convert-trj>` has been added to allow
users to interchange trajectory formats without having to use legacy :ref:`gmx trjconv`.
Supported actions include the generation of slimmed down output trajectories, as well
as the replacement of particle information in individual frames with data from a structure file.
The new tool allows the usage of command line selections, meaning it is no longer
necessary to write :ref:`index <ndx>` files to select certain atoms.
It is part of the drive to split up the :ref:`trjconv <gmx trjconv>` tool
into smaller parts.

Added extract-cluster
"""""""""""""""""""""""""""""""""""""""

Added a dedicated tool to extract trajectory frames corresponding to different clusters obtained
from :ref:`gmx cluster`. The new :ref:`extract-cluster <gmx extract-cluster>` tool
generates new trajectories that contain only those frames that correspond to the correct cluster.
The corresponding option **-sub** in :ref:`gmx trjconv` has been removed.

Changed behaviour of genion
"""""""""""""""""""""""""""

Functionality of genion was altered to prevent swapping ions for solvent closer
than -rmin from any other non-solvent atom.
This improvement prevents situations where an ion could be placed at the core
of a protein, which would potentially render the folded protein less stable or
may require long equilibration times.
Performance improvements
^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Up to a factor 2.5 speed-up of the non-bonded free-energy kernel
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The non-bonded free-energy kernel is a factor 2.5 faster with non-zero A and B
states and a factor 1.5 with one zero state. This especially improves the run
performance when non-perturbed non-bondeds are offloaded to a GPU. In that case
the PME-mesh calculation now always takes the most CPU time.


Proper dihedrals of Fourier type and improper dihedrals of periodic type are SIMD accelerated
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Avoid configuring the own-FFTW with AVX512 enabled when |Gromacs| does not use AVX512
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Previously if |Gromacs| was configured to use any AVX flavor, the internally built FFTW
would be configured to also contain AVX512 kernels. This could cause performance loss
if the (often noisy) FFTW auto-tuner picks an AVX512 kernel in a run that otherwise 
only uses AVX/AVX2 which could run at higher CPU clocks without AVX512 clock speed limitation.
Now AVX512 is only used for the internal FFTW if |Gromacs| is also configured with
the same SIMD flavor.

Update and constraints can run on a GPU
"""""""""""""""""""""""""""""""""""""""

For standard simulations (see the user guide for more details),
update and constraints can be offloaded to a GPU with CUDA. Thus all compute
intensive parts of a simulation can be offloaded, which provides
better performance when using a fast GPU combined with a slow CPU.
By default, update will run on the CPU, to use GPU in single rank simulations,
one can use new '-update gpu' command line option.
For use with domain decomposition, please see below.

GPU Direct Communications
"""""""""""""""""""""""""

When running on multiple GPUs with CUDA, communication operations can
now be performed directly between GPU memory spaces (automatically
routed, including via NVLink where available). This behaviour is not
yet enabled by default: the new codepaths have been verified by the
standard |Gromacs| regression tests, but (at the time of release) still
lack substantial "real-world" testing. They can be enabled by setting
the following environment variables to any non-NULL value in your
shell: GMX_GPU_DD_COMMS (for halo exchange communications between PP
tasks); GMX_GPU_PME_PP_COMMS (for communications between PME and PP
tasks); GMX_FORCE_UPDATE_DEFAULT_GPU can also be set in
order to combine with the new GPU update feature (above). The
combination of these will (for many common simulations) keep data
resident on the GPU across most timesteps, avoiding expensive data
transfers. Note that these currently require |Gromacs| to be built
with its internal thread-MPI library rather than any external MPI
library, and are limited to a single compute node. We stress that
users should carefully verify results against the default path, and
any reported issues will be gratefully received to help us mature the
software.


Bonded kernels on GPU have been fused
"""""""""""""""""""""""""""""""""""""

Instead of launching one GPU kernel for each listed interaction type there is now one
GPU kernel that handles all listed interactions. This improves the performance when
running bonded calculations on a GPU.

Delay for ramp-up added to PP-PME tuning
""""""""""""""""""""""""""""""""""""""""

Modern CPUs and GPUs can take a few seconds to ramp up their clock speeds.
Therefore the PP-PME load balancing now starts after 5 seconds instead
of after a few MD steps. This avoids sub-optimal performance settings.
.. _older-release-notes:

Release notes for older |Gromacs| versions
==========================================

Unfortunately, resources are finite and many versions of |Gromacs| are
no longer actively maintained. This page records the release notes for
all such versions, so that users can find a record of the changes made
in all major and patch releases of |Gromacs|. Major releases contain
changes to the functionality supported, whereas patch releases contain
only fixes for issues identified in the corresponding major releases.

Where issue numbers are reported in these release notes, more details
can be found at https://gitlab.com/gromacs/gromacs/-/issues at that issue number.

|Gromacs| 5.1 series
-----------------------------------

TODO coming soon
Removed functionality
^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

Bugs fixed
^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

Density-guided simulation normalization
"""""""""""""""""""""""""""""""""""""""

With the ``.mdp`` option ``density-guided-simulation-normalize-densities = yes``
, the reference density and the simulated density values were previously divided
by the sum of their values.

This lead to surprising behavior for reference densities with lots of negative
voxel values: the density started to "repel" the protein structure
instead of attracting it, if the total sum of voxel values was smaller
than zero. The negative normalization constant lead to a sign change in voxel
values.

To avoid this behavior, the reference density is now normalized so that the
sum of *positive* values is unity, ensuring that the normalization constant is
always positive.

Apart from avoiding the unexpected behavior, we expect that this also leads 
to smaller absolute differences between reference density and simulated density,
with some small benefits for numerical stability.

This change affects all simulations where voxel values are negative
(usually this excludes synthetic data) and that are run with
``density-guided-simulation-normalize-densities = yes``, but only has a larger
effect for: first, similarity  measure ``inner-product`` as an effective
force-constant scaling and, second, for all similarity measures where the sum
of all voxel values was negative.   
Highlights
^^^^^^^^^^

|Gromacs| 2023 was released on INSERT DATE HERE. Patch releases may
have been made since then, please use the updated versions!  Here are
some highlights of what you can expect, along with more detail in the
links below!

As always, we've got several useful performance improvements, with or
without GPUs, all enabled and automated by default. In addition,
several new features are available for running simulations. We are extremely
interested in your feedback on how well the new release works on your
simulations and hardware. The new features are:

*

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!
Changes to the API
^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

.. _anticipated-changes:

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

Changes anticipated to |Gromacs| 2023 functionality
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Functionality deprecated in |Gromacs| 2023
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Portability
^^^^^^^^^^^

New and improved features
^^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

Miscellaneous
^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

Improvements to |Gromacs| tools
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

Performance improvements
^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without
   a space between the colon and number!

GROMACS 2022.1 release notes
----------------------------

This version was released on TODO, 2022. These release notes
document the changes that have taken place in GROMACS since the
previous 2022 version, to fix known issues. It also incorporates all
fixes made in version 2021.5 and earlier, which you can find described
in the :ref:`release-notes`.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Fixes where mdrun could behave incorrectly
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fix crash when steering FEP with AWH without PME or with separate PME rank
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

There would be a segfault when deciding whether early PME results are needed.

:issue:`4413`

Fixes for ``gmx`` tools
^^^^^^^^^^^^^^^^^^^^^^^

Fixes that affect portability
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Miscellaneous
^^^^^^^^^^^^^

Removed functionality
^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Removed mdrun-only build configuration
""""""""""""""""""""""""""""""""""""""

The need for the mdrun-only build of |Gromacs| has expired, as it has
the same set of dependencies as regular |Gromacs|. It was deprecated
in GROMACS 2021. Removing it will simplify maintenance, testing,
documentation, installation, and teaching new users.

:issue:`3808`

Removed support for x86 MIC, ARMv7, Sparc64 HPC-ACE, and IBM VMX SIMD
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

These platforms are dead in HPC and so are no longer supported. The
KNL platform is unaffected by this change.

:issue:`3891`

Removed deprecated environment variables
""""""""""""""""""""""""""""""""""""""""

The following environment variables were removed after being deprecated
in favor of better-named alternatives:

* ``GMX_CUDA_NB_ANA_EWALD`` and ``GMX_OCL_NB_ANA_EWALD`` (use ``GMX_GPU_NB_ANA_EWALD``)
* ``GMX_CUDA_NB_TAB_EWALD`` and ``GMX_OCL_NB_TAB_EWALD`` (use ``GMX_GPU_NB_TAB_EWALD``)
* ``GMX_CUDA_NB_EWALD_TWINCUT`` and ``GMX_OCL_NB_EWALD_TWINCUT`` (use ``GMX_GPU_NB_EWALD_TWINCUT``)

:issue:`3803`

Removed the ability for gmx wham to read .pdo files
"""""""""""""""""""""""""""""""""""""""""""""""""""

Files in .pdo format were written by |Gromacs| versions prior to 4.0.
That is so long ago that being able to read them is no longer
relevant, so this capability was deprecated in version 2021. If you do
need to read such files, please use an older version of |Gromacs|.

Removed 32bit support
"""""""""""""""""""""

We deprecated 32bit support in 2020 and have had no way to test it ourselves for a while
before that. Those architectures are no longer relevant in HPC, so we officially no longer
support building |Gromacs| on them.
Bugs fixed
^^^^^^^^^^

Fixed slight inaccuracies when using virtual sites with pressure coupling
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Virtual sites were reconstructed after the system was propagated, but before
scaling due to pressure coupling. For virtual site types which are not a linear
combination of other atoms, this is not completely correct. Since the scaling
due to pressure coupling is very small in healthy simulations, the resulting
inaccuracies are expected to have been extremely minor, and in most cases
undetectable.

:issue:`3866`

Correct dVremain/dl when nstdhdl > nstcalcenergy
""""""""""""""""""""""""""""""""""""""""""""""""

When nstcalcenergy was not a multiple of nstdhdl, incorrect dVremain/dl
terms were written in the energy file. Note that all dH/dl output in
both dhdl.xvg and the energy file, which is used by e.g. gmx bar, was correct.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Removed velocity output for acceleration groups
"""""""""""""""""""""""""""""""""""""""""""""""

The reported velocity in the energy file for acceleration groups was always
zero. Now their velocity is no longer reported in the energy file.

:issue:`1354`

Use correct c0 parameter in Me2PO4 in OPLSAA
""""""""""""""""""""""""""""""""""""""""""""

OPLSAA torsions must sum to 0, but the parameters for Me2PO4 did not do so. Changed the c0
parameter to the correct value.

:issue:`4075`

Allow function type Fourier Dihedral with free energy perturbations
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The Fourier Dihedral (dihedral interaction type 3) could not be used in
free energy perturbation simulations. Under the hood the dihedral parameters
were anyhow converted to Ryckaert-Bellemans parameters, so now the checks
for perturbations are the same for the two functions.

:issue:`2606`

Do not scale coordinates of frozen atoms during Parrinello-Rahman pressure coupling
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When Parrinello-Rahman pressure coupling was used, the box scaling was applied to all the atoms,
causing frozen atoms to shift. The effect is more drastic towards the sides of the box and when the
pressure is changed significantly during the simulations. Now, the frozen atoms will be ignored by
the coupling and atoms with frozen dimensions shall keep such values.

:issue:`3075`

Avoid non-uniform rotation with Test Particle Insertion in anisotropic systems
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With anisotropic systems the random angles would not get a uniform distribution.

:issue:`3558`

Allow free energy calculations with a linear angle potential
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Free energy calculations with a linear angle potential were not
explicitly allowed by grompp.

:issue:`3456`


Fixed progress display in trjconv and trjcat
""""""""""""""""""""""""""""""""""""""""""""

The progress information (frame number and time) shown during trajectory 
operations in trjconv and trjcat is now correctly displayed.

:issue:`4320`

Fixed GROMOS dihedral generation for disulfide bridges
""""""""""""""""""""""""""""""""""""""""""""""""""""""

The pdb2gmx functionality now generates correct dihedrals for disulfide
bridges with the GROMOS force field series.

:issue:`4188`

Fixed energy term naming for periodic improper dihedrals
""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Those used the same name internally as the non-periodic version for printing
to energy files and reading from them. This could cause tools being confused
when trying to compare terms from files where the terms where written in
a different order.

gmx density now always uses relative coordinates
""""""""""""""""""""""""""""""""""""""""""""""""

There is no realistic use case for using absolute coordinates in binning
when the box dimension is changing, so gmx density now always uses
relative coordinates internally. This also avoids issues with output
scaling to the last instead of average box size when users forget
this option, ensures the output is always correct, and gets rid of
occassional segfaults.

:issue:`3830`
Highlights
^^^^^^^^^^

|Gromacs| 2022 was released on February 22st, 2022. Patch releases may
have been made since then, please use the updated versions!  Here are
some highlights of what you can expect, along with more detail in the
links below!

As always, we've got several useful performance improvements, with or
without GPUs, all enabled and automated by default. In addition,
several new features are available for running simulations. We are extremely
interested in your feedback on how well the new release works on your
simulations and hardware. The new features are:

* Free-energy kernels are accelerated using SIMD, which make free-energy
  calculations up to three times as fast when using GPUs
* A new formulation of the soft-cored non-bonded interactions for free-energy calculations allows for a finer control of the alchemical transformation pathways
* New transformation pull coordinate allows arbitrary mathematical transformations of one of more other pull coordinates
* New interface for multi-scale Quantum Mechanics / Molecular Mechanics (QM/MM) simulations with the CP2K quantum 
  chemistry package, supporting periodic boundary conditions.
* grompp performance improvements
* `Cool quotes music playlist <https://open.spotify.com/playlist/4oj41X9tgIAJuLgfWPq6ZX>`_
* Additional features were ported to modular simulator
* Added AMD GPU support with SYCL via hipSYCL_
* More GPU offload features supported with SYCL (PME, GPU update). 
* Improved parallelization with GPU-accelerated runs using CUDA and extended GPU direct communication to support multi-node simulation using CUDA-aware MPI.

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!
Changes to the API
^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Remove physical constant conversion functions
"""""""""""""""""""""""""""""""""""""""""""""

Legacy conversion functions for physical constants from and to the |Gromacs|
representation have been removed as they didn't see any use in the library.


.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Changes anticipated to |Gromacs| 2022 functionality
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Functionality deprecated in |Gromacs| 2022
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

GMX_OPENCL_NB_CLUSTER_SIZE CMake variable deprecated in favor of GMX_GPU_NB_CLUSTER_SIZE
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Both OpenCL and SYCL support different cluster sizes, so GMX_GPU_NB_CLUSTER_SIZE should
be used going forward.

The built-in viewer ``gmx view`` will be removed
""""""""""""""""""""""""""""""""""""""""""""""""

There is little use and no tests of this functionality, so it is not worth attempting to
maintain moving forward.

:issue:`4296`

The analysis tool ``gmx chi`` will be removed
"""""""""""""""""""""""""""""""""""""""""""""

This tool has not been functional for a few years.
Please comment at the linked issue if you have any interest in it.

:issue:`4108`

Guessing masses and atomic radii from atom names is deprecated
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

When atom masses or van-der-Waals radii are needed, we suggest building
a proper GROMACS topology instead of using PDB files directly, even
if the tool supports it.

:issue:`3368`
:issue:`4288`

Portability
^^^^^^^^^^^

Intel classic compiler (icc/icpc) no longer supported
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

We now support the Intel clang-based compiler from oneAPI (icx/icpx)
instead. Please use it, or gcc.

:issue:`3893`

Provisional: Initialize GMX_INSTALL_NBLIB_API and GMXAPI build options from BUILD_SHARED_LIBS
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

CMake options ``GMXAPI`` and ``GMX_INSTALL_NBLIB_API`` produce shared object libraries,
so their default values are now initialized from ``BUILD_SHARED_LIBS``.
Pending movement on :issue:`3605` and related issues, the coupling between these
options is subject to change, but users generally should not need to manually set
``GMXAPI`` and ``GMX_INSTALL_NBLIB_API``.

:issue:`4053`

Updates to pybind11 dependency
""""""""""""""""""""""""""""""

pybind11 is no longer bundled with |Gromacs|.

The gmxapi 0.3 Python package build system relies on PEP 517/518 build requirements to get pybind11 header
dependencies through the Python packaging system. Package managers like ``pip`` will download dependencies
automatically. Package managers that do not automatically fulfill dependencies should still report the missing
dependency to the user.

The ``sample_restraint`` sample project
(bundled in ``python_packaging/sample_restraint``)
still has a primitive CMake-only build procedure.
If you fork a project from this source, you may choose to modernize the build system (similarly to that of
``gmxapi``) or to bundle the pybind11 sources.
Within the GROMACS repository, the ``sample_restraint`` option default is now ``GMXAPI_EXTENSION_DOWNLOAD_PYBIND=ON``.

:issue:`4092`

CMake toolchain file replaced with cache file
"""""""""""""""""""""""""""""""""""""""""""""

The ``gromacs-toolchain.cmake`` file
(previously installed to ``$CMAKE_INSTALL_PREFIX/share/cmake/gromacs/``)
is no longer provided.
Instead a partial CMake cache file is installed to
``$CMAKE_INSTALL_PREFIX/share/cmake/gromacs${SUFFIX}/gromacs-hints.cmake``.

Client software may get CMake hints by configuring with ``-C /path/to/gromacs-hints.cmake``,
instead of forcing a cross-compiling CMake configuration with ``-DCMAKE_TOOLCHAIN_FILE`` or ``--toolchain``.

Client software bundled with GROMACS (the gmxapi Python package) no longer requires the toolchain file.
See :doc:`/gmxapi/userguide/install` for details.

:issue:`4208`

Bundle muparser
"""""""""""""""

|Gromacs| now bundles MuParser version 2.3. It is also possible
to link to an external provided library.
New and improved features
^^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

Hybrid Quantum-Classical simulations (QM/MM) with CP2K interface
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Simulations of chemical reactions pathways can provide an atomistic insight into many 
biological and chemical processes. To perform such kind of modelling in complex systems, 
that includes solvent and/or proteins Multi-scale Quantum Mechanics / Molecular Mechanics 
(QM/MM) approaches are often used. Here we introduce a whole new interface to perform QM/MM 
simulations in fully periodic systems using MDModule that couples |Gromacs| with CP2K 
quantum chemistry package. This enables hybrid simulations of systems in systems 
where chemical reactions occurs. The interface supports most of the simulations techniques 
available in |Gromacs| including energy minimization, classical MD and enhanced sampling methods
such as umbrella sampling and accelerated weight histogram method.

Transformation pull coordinate for mathematical transformations of pull coordinates
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

A new pull coordinate type named transformation has been added. This enables mathematical
transformation of previously defined pull coordinates using a user supplied formula
in a string. This allows for example non-linear transformation of a distance, e.g.
a contact coordinate or (non-)linear combinations of multiple pull coordinates.
This is a powerful tool for defining complex reaction coordinates and it can be combined
with the Accelerated Weight Histogram Method to enhance sampling.

Replica-exchange molecular dynamics simulations with GPU update
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Replica-exchange molecular dynamics now works with GPU update.

A new formulation of soft-core interactions for free energy calculations
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

With this addition Gromacs allows to choose from two schemes to soften
non-bonded interactions during alchemical perturbations:
Beutler *et al.*\ :ref:`100 <refBeutler94>` and Gapsys *et al.*\ :ref:`185 <refGapsys2012>` soft-core functions.

More flexible sharing of biases in AWH
""""""""""""""""""""""""""""""""""""""

With the accelerated weight histogram method, biases can now be shared between
subsets of all simulations, without restrictions. The allows for more flexible
ensemble simulation setups, as well as simpler launches of sets of simulations.

More features implemented in modular simulator
""""""""""""""""""""""""""""""""""""""""""""""

Several features were added to the modular simulator, including all temperature
and pressure coupling algorithms available in the legacy simulator, expanded
ensemble and pull.

Free energy calculations now support all non-perturbed bonded interactions
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Previously |Gromacs| did not permit any usage of a few more special bonded
interactions (restricted angles/dihedrals or combined bending-torsion potentials)
in free energy calculations. These are now allowed, as long as the interaction
itself is not perturbed.

:issue:`3691`

Adapt number of threads to actually permitted hardware
""""""""""""""""""""""""""""""""""""""""""""""""""""""

Previously, |Gromacs| would attempt to start as many threads as there are processors
in the system, and try to pin threads on processing units. This would fail whenever
we are not allowed to use all those processors, e.g. when Slurm only provides part
of a node to a job, or on A64fx where some processors are reserved for the system.
We would also start far too many threads in container environments. As part of
improved hardware detection, we now only detect processors on which we are allowed
to run, and adapt the number of threads whenever there is a cpu limit set, which
will improve performance both for containers and make |Gromacs| do the right thing
when Slurm or other queue systems allocate part of a node.

Enable use of more OpenMP threads
"""""""""""""""""""""""""""""""""
The thread-force-reduction code in |Gromacs| will now allow up to 128 OpenMP
threads by default, and we have changed the internal logic so we just limit
the number of threads rather than refuse to run. This only applies within
each rank; you can use an unlimited number of threads by combining OpenMP
threading with multiple ranks. For large machines with many cores this is
usually faster since the domain decomposition used with multiple ranks is
better adapted to non-uniform memory access hardware.

:issue:`4370`

Centering and symmetrization supported in gmx potential
"""""""""""""""""""""""""""""""""""""""""""""""""""""""
gmx potential now supports the same centering and symmetrization options
as gmx density, which is particularly useful for membranes.

:issue:`3579`
Miscellaneous
^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

grompp no longer modifies nstcomm
"""""""""""""""""""""""""""""""""

grompp will no longer set nstcomm, the interval for center of mass motion
removal, equal to nstcalcenergy when nstcomm < nstcalcenergy.
A note is still printed in that case.

Bonded atom types names can now start with a digit
""""""""""""""""""""""""""""""""""""""""""""""""""

Bonded atom types names in topologies were not allowed to start with a number.
Now all names are supported that contain at least one non-digit character.

:issue:`4120`

grompp now warns when exclusion forces might be missing
"""""""""""""""""""""""""""""""""""""""""""""""""""""""

When using PME, exclusions between non-perturbed,atom pairs should be within
the cut-off distance, otherwise mdrun might not compute grid correction forces
and energies. grompp now computes these distance for the starting structure
and warns when they are beyond 90% of the cut-off distance and generates
an error when they are beyond the cut-off distance.

:issue:`4051`

The AWH cover diameter for angles now has units degrees
"""""""""""""""""""""""""""""""""""""""""""""""""""""""

Using old tpr files that apply AWH to angles or dihedrals and have a non-zero cover
diameter results in an error with the suggestion to regenerate the tpr file.

:issue:`4367`


Core spin-up code is removed
""""""""""""""""""""""""""""""""""""""""""""""""""

Formerly, on non-x86 and non-PowerPC platforms, mdrun ran some
multi-threaded code to try to wake up any cores that the OS might have
powered down. This caused problems on some Arm platforms, and does not
seem to suit a significant number of platforms for use of GROMACS. So
now it is removed.

If required, please manually spin-up the cores with, e.g., ``stress --cpu $(nproc --all)``.

:issue:`4074`

Add documentation for linear angle potential
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Added documentation and reference for the linear angle potential. Also
added please_cite entry, but there is no call to reference it yet.

:issue:`4286`

gmxapi.mdrun guarantees trajectory output
"""""""""""""""""""""""""""""""""""""""""

gmxapi simulations now always run with full-precision trajectory output (``-o``)
in order to guarantee the availability of a usable output trajectory through the
``mdrun.output.trajectory`` result.

:issue:`4285`

gmxapi.mdrun accepts arbitrary runtime arguments
""""""""""""""""""""""""""""""""""""""""""""""""

Arbitrary mdrun arguments can be passed through gmxapi with the new *runtime_args* key word
argument, accepting a dictionary of flags and values.

:issue:`4284`

Improved MPI awareness and task uniqueness for gmxapi Python runner
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Previously, only the Python components in :py:mod:`gmxapi.simulation` reacted to the presence
of an MPI context. This could result in duplicate work or even invalid file access.

:py:func:`gmxapi.commandline_operation` now executes tasks in unique working directories.

For all gmxapi operations, tasks are only launched from one process (per ensemble member).
If `mpi4py <https://mpi4py.readthedocs.io/en/stable/>`__ is available,
the MPI environment is inspected.
If multiple ranks are discovered, the ``ResourceManager`` instances on the various ranks coordinate
to make sure that ``update`` is only called for each member of each task once. Results are
broadcast to all ranks from the ``ResourceManager`` where the work occurred.

These changes merely constitute a bug-fix.
Additional development is needed for more optimal use
of resources and to reduce unnecessary data transfers.

:issue:`3138`

Further discouraged use of Berendsen coupling algorithms
""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Those algorithms have been proven to cause incorrect sampling of their
respective distributions and are mainly provided as a means to provide
backwards compatibility for older simulations. This is why their
use has been further discouraged by changing the current notes about
their use to actual warnings at grompp time.
Improvements to |Gromacs| tools
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

``gmx msd`` has been migrated to the trajectoryanalysis framework
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The tool now uses the |Gromacs| selection syntax. Rather than piping selections via stdin,
selections are now made using the "-sel" option. There is a new option called ``-maxtau``,
which limits maximum time delta between frames to compare for calculating MSDs. This will allow
users who otherwise would run into out-of-memory errors and slow execution with large systems
to restrict sampling to useful tau values.

This migration comes with about a 20% speedup in execution time.

Some rarely used features have yet to be migrated, including:

- The -tensor option is not yet implemented.
- System COM removal with -rmcomm has not yet been implemented.
- B-factor writing using the -pdb option is not yet supported.

A slight behavior change is the removal of the -mw option. ``gmx msd`` with ``-mol`` will
take the MSD of the center-of-mass of of molecules, while no mass-weighting is done
when ``-mol`` is not selected. In previous |Gromacs| versions, ``-mw`` was on by default,
and ``-nomw`` was silently ignored when ``-mol`` was chosen. This change will only cause
different results when performing MSD calculations on a non-homogenous group of particles without
``-mol`` set.

:issue:`2368`

``gmx lie`` now reads energy files from reruns
""""""""""""""""""""""""""""""""""""""""""""""

This tool formerly relied on the presence of a pressure field in the .edr file,
and that field will be missing if the .edr came from a rerun. However it was
never necessary to rely on the presence of the pressure field, so now the
tool just works correctly.

:issue:`4070`

``gmx chi`` no longer needs ``residuetypes.dat`` entries for custom residues
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

The need to add the names of custom residues to ``residuetypes.dat`` has been
removed, because it served no purpose. This makes ``gmx chi`` easier to use.

``gmx wham`` has had minor improvements to its text output
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Reporting about file handling and input-file column contents are easier to
follow.

``gmx do_dssp`` supports DSSP version 4
"""""""""""""""""""""""""""""""""""""""

The newer DSSP version 4 program can be used by ``do_dssp`` by specifying 
option ``-ver 4`` and setting the DSSP environement variable to the ``mkdssp``
executable path (e.g. ``setenv DSSP /opt/dssp/mkdssp``)

:issue:`4129`

``gmx trjconv -dump`` now works reliably
""""""""""""""""""""""""""""""""""""""""

The frame nearest the dump time is now always written, even if the
time is before or after the range present in the trajectory file. To
get the last frame of a trajectory file whose frames are in temporal
order, you can request the dump of any time larger than the time of
any frame in the trajectory, like ``gmx trjconv -dump 9999999``.

:issue:`2873`

``gmx trjconv`` handles selections in TNG files better
""""""""""""""""""""""""""""""""""""""""""""""""""""""

When writing TNG files the whole system was written even if the user requested only a
selection of atoms. Now only the selected atoms should be written. If the selection name
matches a molecule type and the selected atoms are all present in that molecule
then the molecule will be written as expected with the correct molecule count etc.
If the selection only matches some atoms in a molecule or atoms from multiple molecules
then the TNG file will contain a single molecule instance containing all those atoms.

:issue:`2785`

``gmx pdb2gmx`` no longer accepts charged glutamine (QLN) with the OPLS-AA forcefield
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

A torsion angle definition was missing from the (non-standard) charged glutamine
residue. Grompp would use the default torsion angle instead. To avoid silent errors
the charged glutamine residue was removed from the OPLS-AA forcefield.

:issue:`3054`

``gmxapi.commandline_operation`` isolates working directories.
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

Subprocesses launched for wrapped command line operations now run in unique subdirectories. Users
who rely on the *output_files* input and *file* output mapping should not be affected. Users who
rely on assumptions about where wrapped commands are executed will need to adjust their scripts.

The *stderr*, *stdout*, and *file* output members are still the primary
supported means to access command output. Additionally, a new *directory* output gives the
filesystem path that was used for the subprocess.
See :py:func:`gmxapi.commandline_operation` for details.

:issue:`3130`
Performance improvements
^^^^^^^^^^^^^^^^^^^^^^^^

.. Note to developers!
   Please use """"""" to underline the individual entries for fixed issues in the subfolders,
   otherwise the formatting on the webpage is messed up.
   Also, please use the syntax :issue:`number` to reference issues on GitLab, without the
   a space between the colon and number!

GPU direct communication with CUDA-aware MPI
""""""""""""""""""""""""""""""""""""""""""""

Direct GPU communication support has been extended to simulations that use
a CUDA-aware library-MPI when running on NVIDIA GPUs. Detection of CUDA-aware MPI
is performed both at cmake-time and runtime. The feature has been tested
primarily with OpenMPI but any CUDA-aware MPI implementation should be suitable,
and it is also possible to use with the thread-MPI implementation in |Gromacs|.
CUDA-aware MPI support still lacks substantial testing, hence it is included
in the current release as a development feature and should be used with caution.
Hence, even if a suitable MPI is detected, direct communication is not used by
default, but it can be enabled using the GMX_ENABLE_DIRECT_GPU_COMM environment
variable.

:issue:`3960`
:issue:`2915`


Dynamic pairlist generation for energy minimization
"""""""""""""""""""""""""""""""""""""""""""""""""""

With energy minimization, the pairlist, and domain decomposition when running
in parallel, is now performed when at least one atom has moved more than the
half the pairlist buffer size. The pairlist used to be constructed every step.

Nonbonded free-energy kernels use SIMD
""""""""""""""""""""""""""""""""""""""

Free energy calculation performance is improved by making the nonbonded free-energy
kernels SIMD accelerated. On AVX2-256 these kernels are 4 to 8 times as fast.
This should give a noticeable speed-up for most systems, especially if the
perturbed interaction calculations were a bottleneck. This is particularly the
case when using GPUs, where the performance improvement of free-energy runs is
up to a factor of 3.

:issue:`2875`
:issue:`742`

       
PME-PP GPU Direct Communication Pipelining
""""""""""""""""""""""""""""""""""""""""""

For multi-GPU runs with direct PME-PP GPU communication enabled, the
PME rank can now pipeline the coordinate transfers with computation in
the PME Spread and Spline kernel (where the coordinates are
consumed). The data from each transfer is handled separately, allowing
computation and communication to be overlapped. This is expected to
have most benefit on systems where hardware communication interfaces
are shared between multiple GPUs, e.g. PCIe within multi-GPU servers
or Infiniband across multiple nodes.

:issue:`3969`

Domain decomposition with single MPI rank
"""""""""""""""""""""""""""""""""""""""""

When running with a single MPI rank with PME and without GPU, mdrun
will now use the domain decomposition machinery to reorder particles.
This can improve performance, especially for large systems. This
behavior can be controlled with the environment variable
GMX_DD_SINGLE_RANK.

Restricted GPU support with multiple time stepping
""""""""""""""""""""""""""""""""""""""""""""""""""

GPUs can be used in combination with MTS, but for now this is limited
to the setup where only the long-range nonbonded force is applied
in longer timesteps (and computed on the CPU), while all other 
components are are calculated every step (which can be on the GPU).

       
``gmx grompp`` now runs 20-50% faster
"""""""""""""""""""""""""""""""""""""

After a series of improvements, the loops in the parameter- and
atom-lookup code in ``gmx grompp`` have been transformed to
run faster while using simpler, standard code idioms.


PME decomposition support in mixed mode with CUDA and process-MPI
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

PME decomposition is supported now in mixed mode with CUDA backend. 
This is supported only if GROMACS is compiled with external process-MPI 
and underlying MPI implementation is CUDA-aware. This feature lacks substantial testing
and has been disabled by default but can be enabled by setting GMX_GPU_PME_DECOMPOSITION=1 
environment variable.

Performance improvements when running on Ampere-class Nvidia GPUs
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
Improved performance of the short-ranged non-bonded kernels by up to 12%.

:issue:`3872`
.. _special:

Special Topics
==============

This section covers some of the more specialized topics concerning
the use of |Gromacs| for specific scientific problems.

.. toctree::
   :maxdepth: 2

   special/free-energy-implementation
   special/pulling
   special/awh
   special/enforced-rotation
   special/electric-fields
   special/comp-electrophys
   special/free-energy-pmf
   special/remove-fast-dgf
   special/viscosity-calculation
   special/shearing
   special/tabulated-interaction-functions
   special/qmmm
   special/mimic-qmmm
   special/vmd-imd
   special/membrane-embedding
   special/density-guided-simulation.rst


Run parameters and Programs
===========================

Online documentation
--------------------

We install standard UNIX man pages for all the programs. If
you have sourced the ``GMXRC`` script in the |Gromacs| binary directory for
your host they should already be present in your ``MANPATH`` environment
variable, and you should be able to type *e.g.* ``man gmx-grompp``. You can
also use the ``-h`` flag on the command line (e.g. :ref:`gmx grompp <gmx grompp>` ``-h``) to see the
same information, as well as ``gmx help grompp``. The list of all programs
are available from :ref:`gmx help <gmx help>`.

File types
----------

Information about different file types can be found
in :doc:`file-formats`.

|Gromacs| files written in XDR format can be read on any architecture with
|Gromacs| version 1.6 or later if the configuration script found the XDR
libraries on your system. They should always be present on UNIX since
they are necessary for NFS support.

Run Parameters
--------------

The descriptions of :ref:`mdp` parameters can be found at
under the link above both in your local |Gromacs| installation,
or :ref:`here <mdp-general>`.

.. raw:: latex

    \clearpage



Preface and Disclaimer
======================

|Gromacs| - |version|

Contributions from:

Emile Apol, Rossen Apostolov, Paul Bauer, Herman J.C. Berendsen,
Pär Bjelkmar, Christian Blau, Viacheslav Bolnykh, Kevin Boyd,
Aldert van Buuren, Rudi van Drunen, Anton Feenstra, Gerrit Groenhof,
Anca Hamuraru, Vincent Hindriksen, M. Eric Irrgang, Aleksei Iupinov,
Christoph Junghans, Joe Jordan, Dimitrios Karkoulis, Peter Kasson,
Jiri Kraus, Carsten Kutzner, Per Larsson, Justin A. Lemkul,
Viveca Lindahl, Magnus Lundborg, Erik Marklund,Pascal Merz,
Pieter Meulenhoff, Teemu Murtola, Szilárd Páll, Sander Pronk,
Roland Schulz, Michael Shirts, Alexey Shvetsov, Alfons Sijbers,
Peter Tieleman, Teemu Virolainen, Christian Wennberg, Maarten Wolf,
and Artem Zhmurov.

Mark Abraham, Berk Hess, David van der Spoel, and Erik Lindahl.

© 1991 -- 2000:

    Department of Biophysical Chemistry, University of Groningen.
    Nijenborgh 4, 9747 AG Groningen, The Netherlands.

© 2001 -- |thisyear|:

    The |Gromacs| development teams at the Royal Institute of Technology and
    Uppsala University, Sweden.


This manual is not complete and has no pretension to be so due
to lack of time of the contributors -- our first priority is to improve
the software. It is worked on continuously,
which in some cases might mean the information is not entirely correct.

Comments on form and content are welcome, please send them to one of
the mailing lists (see our `webpage`_ or this section on
how to :ref:`contribute <gmx-contribute>`), or open an issue
on our `issue tracker`_. Corrections can also be made in the |Gromacs| git
source repository and uploaded to the |Gromacs| `GitLab`_.

We release an updated version of the manual whenever
we release a new version of the software, so in general 
it is a good idea to use a manual with the same major and
minor release number as your |Gromacs| installation. 

Citation information
--------------------

.. todo:: needs link to ref list

|GMX_MANUAL_DOI_STRING|

However, we prefer that you cite (some of) the |Gromacs|
papers:

* \ :ref:`Bekker et al. (1993) <refBekker93a>`
* \ :ref:`Berendsen et al. (1995) <refBerendsen95a>`
* \ :ref:`Lindahl et al. (2001) <refLindahl2001a>`
* \ :ref:`van der Spoel at al. (2005) <refSpoel2005a>`
* \ :ref:`Hess et al. (2008) <refHess2008b>`
* \ :ref:`Pronk et al. (2013) <refPronk2013>`
* \ :ref:`Pall et al. (2015) <refPall2015>`
* \ :ref:`Abraham et al. (2015) <refAbraham2015>`

when you publish your results. Any future development depends on academic research
grants, since the package is distributed as free software!

|Gromacs| is *Free Software*
----------------------------

The entire |Gromacs| package is available under the GNU Lesser
General Public License (LGPL), version 2.1. This means it's free as in free
speech, not just that you can use it without paying us money.
You can redistribute |Gromacs| and/or modify it under the terms of the LGPL
as published by the Free Software Foundation;
either version 2.1 of the License, or (at your option) any later version.
For details, check the COPYING file in the source code or consult
`this page <http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html>`__.

The |Gromacs| source code and selected set of binary packages are
available on our homepage, `www.gromacs.org <http://www.gromacs.org>`__. Have fun.

.. raw:: latex

    \clearpage
.. _ff:

Interaction function and force fields
=====================================

To accommodate the potential functions used in some popular force fields
(see :ref:`ff`), |Gromacs| offers a choice of functions, both for
non-bonded interaction and for dihedral interactions. They are described
in the appropriate subsections.

The potential functions can be subdivided into three parts

#. *Non-bonded*: Lennard-Jones or Buckingham, and Coulomb or modified
   Coulomb. The non-bonded interactions are computed on the basis of a
   neighbor list (a list of non-bonded atoms within a certain radius),
   in which exclusions are already removed.

#. *Bonded*: covalent bond-stretching, angle-bending, improper
   dihedrals, and proper dihedrals. These are computed on the basis of
   fixed lists.

#. *Restraints*: position restraints, angle restraints, distance
   restraints, orientation restraints and dihedral restraints, all based
   on fixed lists.

#. *Applied Forces*: externally applied forces, see
   chapter :ref:`special`.


.. toctree::
   :maxdepth: 2

   functions/nonbonded-interactions
   functions/bonded-interactions
   functions/restraints
   functions/polarization
   functions/free-energy-interactions
   functions/interaction-methods
   functions/long-range-electrostatics
   functions/long-range-vdw
   functions/force-field


.. _defunits:

Definitions and Units
=====================

Notation
--------

The following conventions for mathematical typesetting are used
throughout this document:

.. |vecex| replace:: :math:`{\mathbf{r}_i}`
.. |lenex| replace:: :math:`r_i`

.. table:: 
    :align: center
    :widths: auto

    +---------------+-------------+---------+
    | Item          | Notation    | Example |
    +===============+=============+=========+
    | Vector        | Bold italic | |vecex| |
    +---------------+-------------+---------+
    | Vector Length | Italic      | |lenex| |
    +---------------+-------------+---------+

We define the *lowercase* subscripts :math:`i`, :math:`j`, :math:`k` and
:math:`l` to denote particles: :math:`\mathbf{r}_i` is the
*position vector* of particle :math:`i`, and using this notation:

.. math:: \begin{aligned}
          \mathbf{r}_{ij}	=	\mathbf{r}_j-\mathbf{r}_i\\
          r_{ij}=	| \mathbf{r}_{ij} | \end{aligned}
          :label: eqnnotation

The force on particle :math:`i` is denoted by
:math:`\mathbf{F}_i` and

.. math:: \mathbf{F}_{ij} = \mbox{force on $i$ exerted by $j$}
          :label: eqbforcenotation

MD units
--------

|Gromacs| uses a consistent set of units that produce values in the
vicinity of unity for most relevant molecular quantities. Let us call
them *MD units*. The basic units in this system are nm, ps, K, electron
charge (e) and atomic mass unit (u), see :numref:`Table %s <table-basicunits>`
The values used in |Gromacs| are
taken from the CODATA Internationally recommended 2010 values of
fundamental physical constants (see `NIST homepage <http://nist.gov>`__). 

.. |tnm| replace:: :math:`\mathrm{nm = }10^{-9}\ m`
.. |tu1| replace:: u (unified atomic mass unit) =
.. |tu2| replace:: :math:`1.660\,538\,921 \times 10^{-27}\ kg`
.. |tti| replace:: :math:`\mathrm{ps = }10^{-12}\ s`
.. |tc1| replace:: *e* = elementary charge =
.. |tc2| replace:: :math:`1.602\,176\,565 \times 10^{-19}\ C`
.. |tte| replace:: K 

.. _table-basicunits:

.. table:: Basic units used in |Gromacs|
    :align: center
    :widths: auto

    +--------------+--------+-------+
    | Quantity     | Symbol | Unit  |
    +==============+========+=======+
    | length       |     r  | |tnm| |
    +--------------+--------+-------+
    | mass         |     m  | |tu1| |
    |              |        | |tu2| |
    +--------------+--------+-------+
    | time         |     t  | |tti| |
    +--------------+--------+-------+
    | charge       |     q  | |tc1| |
    |              |        | |tc2| |
    +--------------+--------+-------+
    | temperature  |     T  | |tte| |
    +--------------+--------+-------+




Consistent
with these units are a set of derived units, given in
:numref:`Table %s <table-derivedunits>`

.. |tse|  replace:: :math:`E,V`
.. |tsf|  replace:: :math:`\mathbf{F}`
.. |tsp|  replace:: :math:`p`
.. |tsv|  replace:: :math:`v`
.. |tsd|  replace:: :math:`\mu`
.. |tsep| replace:: :math:`\Phi`
.. |tsef| replace:: :math:`E`
.. |tdue|   replace:: :math:`\mathrm{kJ~mol}^{-1}`
.. |tduf|   replace:: :math:`\mathrm{kJ~mol}^{-1}~\mathrm{nm}^{-1}`
.. |tdup|   replace:: bar
.. |tduv|   replace:: :math:`\mathrm{nm~ps}^{-1} = 1000\mathrm{~m~s}^{-1}`
.. |tdud|   replace:: :math:`\mathrm{e\ nm}`
.. |tduep1| replace:: :math:`\mathrm{kJ~mol}^{-1}\mathrm{~e}^{-1} =`
.. |tduep2| replace:: :math:`0.010\,364\,269\,19` Volt
.. |tduef1| replace:: :math:`\mathrm{kJ~mol}^{-1}\mathrm{~nm}^{-1}\ \mathrm{e}^{-1} =`
.. |tduef2| replace:: :math:`1.036\,426\,919 \times 10^7\mathrm{~V m}^{-1}`

.. _table-derivedunits:

.. table::
    Derived units. Note that an additional conversion factor of 10\ :math:`^{28}` a.m.u (\ :math:`\approx` 16.6)
    is applied to get bar instead of internal MD units in the energy and
    log files
    :align: center
    :widths: auto

    +--------------------+--------+----------+
    | Quantity           | Symbol | Unit     |
    +====================+========+==========+
    | energy             | |tse|  | |tdue|   |
    +--------------------+--------+----------+
    | Force              | |tsf|  | |tduf|   |
    +--------------------+--------+----------+
    | pressure           | |tsp|  | |tdup|   |
    +--------------------+--------+----------+
    | velocity           | |tsv|  | |tduv|   |
    +--------------------+--------+----------+
    | dipole moment      | |tsd|  | |tdud|   |
    +--------------------+--------+----------+
    | electric potential | |tsep| | |tduep1| |
    |                    |        | |tduep2| |
    +--------------------+--------+----------+
    | electric field     | |tsef| | |tduef1| |
    |                    |        | |tduef2| |
    +--------------------+--------+----------+


The **electric conversion factor**
:math:`f=\frac{1}{4 \pi \varepsilon_o}={138.935\,458}`
:math:`\mathrm{kJ}~\mathrm{mol}^{-1}\mathrm{nm}~\mathrm{ e}^{-2}`.
It relates the mechanical quantities to the electrical quantities as in

.. math:: V = f \frac{q^2}{r} \mbox{\ \ or\ \ } F = f \frac{q^2}{r^2}
          :label: eqnelecconv

Electric potentials :math:`\Phi` and electric fields
:math:`\mathbf{E}` are intermediate quantities in the
calculation of energies and forces. They do not occur inside |Gromacs|. If
they are used in evaluations, there is a choice of equations and related
units. We strongly recommend following the usual practice of including
the factor :math:`f` in expressions that evaluate :math:`\Phi` and
:math:`\mathbf{E}`:

.. math:: \begin{aligned}
          \Phi(\mathbf{r}) = f \sum_j \frac{q_j}{| \mathbf{r}-\mathbf{r}_j | } 	\\
          \mathbf{E}(\mathbf{r}) = f \sum_j q_j \frac{(\mathbf{r}-\mathbf{r}_j)}{| \mathbf{r}-\mathbf{r}_j| ^3}\end{aligned}
          :label: eqnelecfacinclude

With these definitions, :math:`q\Phi` is an energy and
:math:`q\mathbf{E}` is a force. The units are those given
in :numref:`Table %s <table-derivedunits>`
about 10 mV for potential.
Thus, the potential of an electronic charge at a distance of 1 nm equals
:math:`f \approx 140` units :math:`\approx 1.4` V.
(exact value: :math:`1.439\,964\,5` V)

**Note** that these units are mutually consistent; changing any of the
units is likely to produce inconsistencies and is therefore *strongly
discouraged*! In particular: if Å are used instead of nm, the unit of
time changes to 0.1 ps. If :math:`\mathrm{kcal}~\mathrm{mol}^{-1}` (= 4.184
:math:`\mathrm{kJ~mol}^{-1}`) is used instead of :math:`\mathrm{kJ~mol}^{-1}` for energy,
the unit of time becomes 0.488882 ps and the unit of temperature changes
to 4.184 K. But in both cases all electrical energies go wrong, because
they will still be computed in :math:`\mathrm{kJ~mol}^{-1}`, expecting nm as
the unit of length. Although careful rescaling of charges may still
yield consistency, it is clear that such confusions must be rigidly
avoided.

In terms of the MD units, the usual physical constants take on different
values (see :numref:`Table %s <table-consts>`). All quantities are per
mol rather than per molecule. There is no distinction between
Boltzmann’s constant :math:`k` and the gas constant :math:`R`: their
value is :math:`0.008\,314\,462\,1\mathrm{kJ~mol}^{-1} \mathrm{K}^{-1}`.

.. _table-consts:

.. table:: 
    Some Physical Constants
    :align: center
    :widths: auto

    +----------------+----------------------+--------------------------------------------------------------------------+
    | Symbol         | Name                 | Value                                                                    |
    +================+======================+==========================================================================+
    | :math:`N_{AV}` | Avogadro's number    | :math:`6.022\,141\,29\times 10^{23}~\mathrm{mol}^{-1}`                   |
    +----------------+----------------------+--------------------------------------------------------------------------+
    | :math:`R`      | gas constant         | :math:`8.314\,462\,1\times 10^{-3}~\mathrm{kJ~mol}^{-1}~\mathrm{K}^{-1}` |
    +----------------+----------------------+--------------------------------------------------------------------------+
    | :math:`k_B`    | Boltzmann's constant | *idem*                                                                   |
    +----------------+----------------------+--------------------------------------------------------------------------+
    | :math:`h`      | Planck's constant    | :math:`0.399\,031\,271~\mathrm{kJ~mol}^{-1}~\mathrm{ps}`                 |
    +----------------+----------------------+--------------------------------------------------------------------------+
    | :math:`\hbar`  | Dirac's constant     | :math:`0.063\,507\,799\,3~\mathrm{kJ~mol}^{-1}~\mathrm{ps}`              |
    +----------------+----------------------+--------------------------------------------------------------------------+
    | :math:`c`      | velocity of light    | :math:`299\,792.458~\mathrm{nm~ps}^{-1}`                                 |
    +----------------+----------------------+--------------------------------------------------------------------------+



Reduced units
-------------

When simulating Lennard-Jones (LJ) systems, it might be advantageous to
use reduced units (*i.e.*, setting
:math:`\epsilon_{ii}=\sigma_{ii}=m_i=k_B=1` for one type of atoms). This
is possible. When specifying the input in reduced units, the output will
also be in reduced units. The one exception is the *temperature*, which
is expressed in :math:`0.008\,314\,462\,1` reduced units. This is a
consequence of using Boltzmann’s constant in the evaluation of
temperature in the code. Thus not :math:`T`, but :math:`k_BT`, is the
reduced temperature. A |Gromacs| temperature :math:`T=1` means a reduced
temperature of :math:`0.008\ldots` units; if a reduced temperature of 1
is required, the |Gromacs| temperature should be :math:`120.272\,36`.

In :numref:`Table %s <table-reduced>` quantities are given for LJ
potentials:

.. math:: V_{LJ} = 4\epsilon \left[ \left(\frac{\sigma}{r}\right)^{12} - \left(\frac{\sigma}{r}\right)^{6} \right]
          :label: eqnbaseljpotentials

.. _table-reduced:

.. table:: 
    Reduced Lennard-Jones quantities
    :align: center
    :widths: auto

    +-------------+----------------+------------------------------------------+
    | Quantity    | Symbol         | Relation to SI                           |
    +=============+================+==========================================+
    | Length      | r\ :math:`^*`  | r\ :math:`\sigma^{-1}`                   |
    +-------------+----------------+------------------------------------------+
    | Mass        | m\ :math:`^*`  | m M\ :math:`^{-1}`                       |
    +-------------+----------------+------------------------------------------+
    | Time        | t\ :math:`^*`  | t\ :math:`\sigma^{-1}~\sqrt{\epsilon/M}` |
    +-------------+----------------+------------------------------------------+
    | Temperature | T\ :math:`^*`  | k\ :math:`_B\mathrm{T}~\epsilon^{-1}`    |
    +-------------+----------------+------------------------------------------+
    | Energy      | E\ :math:`^*`  | E\ :math:`\epsilon^{-1}`                 |
    +-------------+----------------+------------------------------------------+
    | Force       | F\ :math:`^*`  | F\ :math:`\sigma~\epsilon^{-1}`          |
    +-------------+----------------+------------------------------------------+
    | Pressure    | P\ :math:`^*`  | P\ :math:`\sigma ^3 \epsilon^{-1}`       |
    +-------------+----------------+------------------------------------------+
    | Velocity    | v\ :math:`^*`  | v\ :math:`\sqrt{M/\epsilon}`             |
    +-------------+----------------+------------------------------------------+
    | Density     | :math:`\rho^*` | N\ :math:`\sigma ^3~V^{-1}`              |
    +-------------+----------------+------------------------------------------+




Mixed or Double precision
-------------------------

|Gromacs| can be compiled in either mixed or double precision.
Documentation of previous |Gromacs| versions referred to *single
precision*, but the implementation has made selective use of double
precision for many years. Using single precision for all variables would
lead to a significant reduction in accuracy. Although in *mixed
precision* all state vectors, i.e. particle coordinates, velocities and
forces, are stored in single precision, critical variables are double
precision. A typical example of the latter is the virial, which is a sum
over all forces in the system, which have varying signs. In addition, in
many parts of the code we managed to avoid double precision for
arithmetic, by paying attention to summation order or reorganization of
mathematical expressions. The default configuration uses mixed
precision, but it is easy to turn on double precision by adding the
option ``-DGMX_DOUBLE=on`` to ``cmake``. Double precision will be 20 to 100%
slower than mixed precision depending on the architecture you are
running on. Double precision will use somewhat more memory and run
input, energy and full-precision trajectory files will be almost twice
as large.

The energies in mixed precision are accurate up to the last decimal, the
last one or two decimals of the forces are non-significant. The virial
is less accurate than the forces, since the virial is only one order of
magnitude larger than the size of each element in the sum over all atoms
(sec. :ref:`virial`). In most cases this is not really a problem, since
the fluctuations in the virial can be two orders of magnitude larger
than the average. Using cut-offs for the Coulomb interactions cause
large errors in the energies, forces, and virial. Even when using a
reaction-field or lattice sum method, the errors are larger than, or
comparable to, the errors due to the partial use of single precision.
Since MD is chaotic, trajectories with very similar starting conditions
will diverge rapidly, the divergence is faster in mixed precision than
in double precision.

For most simulations, mixed precision is accurate enough. In some cases
double precision is required to get reasonable results:

-  normal mode analysis, for the conjugate gradient or l-bfgs
   minimization and the calculation and diagonalization of the Hessian

-  long-term energy conservation, especially for large systems

.. raw:: latex

    \clearpage


Some implementation details
===========================

In this chapter we will present some implementation details. This is far
from complete, but we deemed it necessary to clarify some things that
would otherwise be hard to understand.

Single Sum Virial in |Gromacs|
------------------------------

The virial :math:`\Xi` can be written in full tensor form as:

.. math:: \Xi~=~-\frac{1}{2}~\sum_{i < j}^N~\mathbf{r}_{ij}\otimes\mathbf{F}_{ij}
          :label: eqnvirialfulltensorform

where :math:`\otimes` denotes the *direct product* of two vectors. [1]_
When this is computed in the inner loop of an MD program 9
multiplications and 9 additions are needed. [2]_

Here it is shown how it is possible to extract the virial calculation
from the inner loop \ :ref:`177 <refBekker93b>`.

Virial
~~~~~~

In a system with periodic boundary conditions, the periodicity must be
taken into account for the virial:

.. math:: \Xi~=~-\frac{1}{2}~\sum_{i < j}^{N}~\mathbf{r}_{ij}^n\otimes\mathbf{F}_{ij}
          :label: eqnvirialperiodicity

where :math:`\mathbf{r}_{ij}^n` denotes the distance
vector of the *nearest image* of atom :math:`i` from atom :math:`j`. In
this definition we add a *shift vector* :math:`\delta_i` to the position
vector :math:`\mathbf{r}_i` of atom :math:`i`. The
difference vector :math:`\mathbf{r}_{ij}^n` is thus equal
to:

.. math:: \mathbf{r}_{ij}^n~=~\mathbf{r}_i+\delta_i-\mathbf{r}_j
          :label: eqnvirialdiffvector

or in shorthand:

.. math:: \mathbf{r}_{ij}^n~=~\mathbf{r}_i^n-\mathbf{r}_j
          :label: eqnvirialdiffvecshort

In a triclinic system, there are 27 possible images of :math:`i`; when
a truncated octahedron is used, there are 15 possible images.

Virial from non-bonded forces
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Here the derivation for the single sum virial in the *non-bonded force*
routine is given. There are a couple of considerations that are special
to |Gromacs| that we take into account:

-  When calculating short-range interactions, we apply the *minimum
   image convention* and only consider the closest image of each
   neighbor - and in particular we never allow interactions between a
   particle and any of its periodic images. For all the equations below,
   this means :math:`i \neq j`.

-  In general, either the :math:`i` or :math:`j` particle might be
   shifted to a neighbor cell to get the closest interaction (shift
   :math:`\delta_{ij}`). However, with minimum image convention there
   can be at most 27 different shifts for particles in the central cell,
   and for typical (very short-ranged) biomolecular interactions there
   are typically only a few different shifts involved for each particle,
   not to mention that each interaction can only be present for one
   shift.

-  For the |Gromacs| nonbonded interactions we use this to split the
   neighborlist of each :math:`i` particle into multiple separate lists,
   where each list has a constant shift :math:`\delta_i` for the
   :math:`i` partlcle. We can represent this as a sum over shifts (for
   which we use index :math:`s`), with the constraint that each particle
   interaction can only contribute to one of the terms in this sum, and
   the shift is no longer dependent on the :math:`j` particles. For any
   sum that does not contain complex dependence on :math:`s`, this means
   the sum trivially reduces to just the sum over :math:`i` and/or
   :math:`j`.

-  To simplify some of the sums, we replace sums over :math:`j<i` with
   double sums over all particles (remember, :math:`i \neq j`) and
   divide by 2.

Starting from the above definition of the virial, we then get

.. math:: \begin{aligned}
          \Xi
          &~=~&-{\frac{1}{2}}~\sum_{i < j}^{N}~{\mathbf r}^n_{ij} \otimes {\mathbf F}_{ij} \nonumber \\
          &~=~&-{\frac{1}{2}}~\sum_{i < j}^{N}~\left( {\mathbf r}_i + \delta_{ij} - {\mathbf r}_j \right) \otimes {\mathbf F}_{ij} \nonumber \\
          &~=~&-{\frac{1}{4}}~\sum_{i=1}^{N}~\sum_{j=1}^{N}~\left( {\mathbf r}_i + \delta_{ij} - {\mathbf r}_j \right) \otimes {\mathbf F}_{ij} \nonumber \\
          &~=~&-{\frac{1}{4}}~\sum_{i=1}^{N}~\sum_{s}~\sum_{j=1}^{N}~\left( {\mathbf r}_i + \delta_{i,s} - {\mathbf r}_j \right) \otimes {\mathbf F}_{ij,s} \nonumber \\
          &~=~&-{\frac{1}{4}}~\sum_{i=}^{N}~\sum_{s}~\sum_{j=1}^{N}~\left( \left( {\mathbf r}_i + \delta_{i,s} \right) \otimes {\mathbf F}_{ij,s} -{\mathbf r}_j \otimes {\mathbf F}_{ij,s} \right) \nonumber \\
          &~=~&-{\frac{1}{4}}~\sum_{i=1}^{N}~\sum_{s}~\sum_{j=1}^N ~\left( {\mathbf r}_i + \delta_{i,s} \right) \otimes {\mathbf F}_{ij,s} + {\frac{1}{4}}\sum_{i=1}^{N}~\sum_{s}~\sum_{j=1}^{N} {\mathbf r}_j \otimes {\mathbf F}_{ij,s} \nonumber \\
          &~=~&-{\frac{1}{4}}~\sum_{i=1}^{N}~\sum_{s}~\sum_{j=1}^N ~\left( {\mathbf r}_i + \delta_{i,s} \right) \otimes {\mathbf F}_{ij,s} + {\frac{1}{4}}\sum_{i=1}^{N}~\sum_{j=1}^{N} {\mathbf r}_j \otimes {\mathbf F}_{ij} \nonumber \\
          &~=~&-{\frac{1}{4}}~\sum_{s}~\sum_{i=1}^{N}~\left( {\mathbf r}_i + \delta_{i,s} \right) \otimes ~\sum_{j=1}^N {\mathbf F}_{ij,s} + {\frac{1}{4}}\sum_{j=1}^N {\mathbf r}_j \otimes \sum_{i=1}^{N} {\mathbf F}_{ij} \nonumber \\
          &~=~&-{\frac{1}{4}}~\sum_{s}~\sum_{i=1}^{N}~\left( {\mathbf r}_i + \delta_{i,s} \right) \otimes ~\sum_{j=1}^N {\mathbf F}_{ij,s} - {\frac{1}{4}}\sum_{j=1}^N {\mathbf r}_j \otimes \sum_{i=1}^{N} {\mathbf F}_{ji} \nonumber \\
          &~=~&-{\frac{1}{4}}~\sum_{s}~\sum_{i=1}^{N}~\left( {\mathbf r}_i + \delta_{i,s} \right) \otimes {\mathbf F}_{i,s} - {\frac{1}{4}}\sum_{j=1}^N~{\mathbf r}_j \otimes {\mathbf F}_{j}  \nonumber \\
          &~=~&-{\frac{1}{4}}~\left(\sum_{i=1}^{N}~{\mathbf r}_i  \otimes {\mathbf F}_{i} + \sum_{j=1}^N~{\mathbf r}_j \otimes {\mathbf F}_{j} \right) - {\frac{1}{4}}\sum_{s}~\sum_{i=1}^{N} \delta_{i,s} \otimes {\mathbf F}_{i,s}  \nonumber \\
          &~=~&-{\frac{1}{2}}\sum_{i=1}^{N}~{\mathbf r}_i \otimes {\mathbf F}_{i} -{\frac{1}{4}}\sum_{s}~\sum_{i=1}^{N}~\delta_{i,s} \otimes {\mathbf F}_{i,s} \nonumber \\
          &~=~&-{\frac{1}{2}}\sum_{i=1}^{N}~{\mathbf r}_i \otimes {\mathbf F}_{i} -{\frac{1}{4}}\sum_{s}~\delta_{s} \otimes {\mathbf F}_{s} \nonumber \\
          &~=~&\Xi_0 + \Xi_1\end{aligned}
          :label: eqnviriallong

In the second-last stage, we have used the property that each shift
vector itself does not depend on the coordinates of particle :math:`i`,
so it is possible to sum up all forces corresponding to each shift
vector (in the nonbonded kernels), and then just use a sum over the
different shift vectors outside the kernels. We have also used

.. math:: \begin{aligned}
          \mathbf{F}_i&~=~&\sum_{j=1}^N~\mathbf{F}_{ij}					\\
          \mathbf{F}_j&~=~&\sum_{i=1}^N~\mathbf{F}_{ji}\end{aligned}
          :label: eqnvirialtotalforce

which is the total force on :math:`i` with respect to :math:`j`.
Because we use Newton’s Third Law:

.. math:: \mathbf{F}_{ij}~=~-\mathbf{F}_{ji}
          :label: eqnnewtonsthird

we must, in the implementation, double the term containing the shift
:math:`\delta_i`. Similarly, in a few places we have summed the
shift-dependent force over all shifts to come up with the total force
per interaction or particle.

This separates the total virial :math:`\Xi` into a component
:math:`\Xi_0` that is a single sum over particles, and a second
component :math:`\Xi_1` that describes the influence of the particle
shifts, and that is only a sum over the different shift vectors.

The intra-molecular shift (mol-shift)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For the bonded forces and SHAKE it is possible to make a *mol-shift*
list, in which the periodicity is stored. We simple have an array mshift
in which for each atom an index in the shiftvec array is stored.

The algorithm to generate such a list can be derived from graph theory,
considering each particle in a molecule as a bead in a graph, the bonds
as edges.

#. Represent the bonds and atoms as bidirectional graph

#. Make all atoms white

#. Make one of the white atoms black (atom :math:`i`) and put it in the
   central box

#. Make all of the neighbors of :math:`i` that are currently white, gray

#. Pick one of the gray atoms (atom :math:`j`), give it the correct
   periodicity with respect to any of its black neighbors and make it
   black

#. Make all of the neighbors of :math:`j` that are currently white, gray

#. If any gray atom remains, go to [5]

#. If any white atom remains, go to [3]

Using this algorithm we can

-  optimize the bonded force calculation as well as SHAKE

-  calculate the virial from the bonded forces in the single sum method
   again

Find a representation of the bonds as a bidirectional graph.

Virial from Covalent Bonds
~~~~~~~~~~~~~~~~~~~~~~~~~~

Since the covalent bond force gives a contribution to the virial, we
have:

.. math:: \begin{aligned}
          b	&~=~&	\|\mathbf{r}_{ij}^n\|					\\
          V_b	&~=~&	\frac{1}{2} k_b(b-b_0)^2				\\
          \mathbf{F}_i	&~=~&	-\nabla V_b					\\
          	&~=~&	k_b(b-b_0)\frac{\mathbf{r}_{ij}^n}{b}			\\
          \mathbf{F}_j	&~=~&	-\mathbf{F}_i\end{aligned}
          :label: eqncovbondvirial

The virial contribution from the bonds then is:

.. math:: \begin{aligned}
          \Xi_b	&~=~&	-\frac{1}{2}(\mathbf{r}_i^n\otimes\mathbf{F}_i~+~\mathbf{r}_j\otimes\mathbf{F}_j)	\\
          &~=~&	-\frac{1}{2}\mathbf{r}_{ij}^n\otimes\mathbf{F}_i\end{aligned}
          :label: eqncovbondvirialcontri

Virial from SHAKE
~~~~~~~~~~~~~~~~~

An important contribution to the virial comes from shake. Satisfying the
constraints a force **G** that is exerted on the particles “shaken.” If
this force does not come out of the algorithm (as in standard SHAKE) it
can be calculated afterward (when using *leap-frog*) by:

.. math:: \begin{aligned}
          \Delta\mathbf{r}_i&~=~&{\mathbf{r}_i}(t+{\Delta t})-
          [\mathbf{r}_i(t)+{\bf v}_i(t-\frac{{\Delta t}}{2}){\Delta t}+\frac{\mathbf{F}_i}{m_i}{\Delta t}^2]	\\
          {\bf G}_i&~=~&\frac{m_i{\Delta}{\mathbf{r}_i}}{{\Delta t}^2i}\end{aligned}
          :label: eqnshakevirial

This does not help us in the general case. Only when no periodicity is
needed (like in rigid water) this can be used, otherwise we must add the
virial calculation in the inner loop of SHAKE.

When it *is* applicable the virial can be calculated in the single sum
way:

.. math:: \Xi~=~-\frac{1}{2}\sum_i^{N_c}~\mathbf{r}_i\otimes\mathbf{F}_i
          :label: eqnshakevirialsinglesum

where :math:`N_c` is the number of constrained atoms.

Optimizations
-------------

Here we describe some of the algorithmic optimizations used in |Gromacs|,
apart from parallelism.

.. _waterloops:

Inner Loops for Water
~~~~~~~~~~~~~~~~~~~~~

|Gromacs| uses special inner loops to calculate non-bonded interactions
for water molecules with other atoms, and yet another set of loops for
interactions between pairs of water molecules. There highly optimized
loops for two types of water models. For three site models similar to
SPC \ :ref:`80 <refBerendsen81>`, *i.e.*:

#. There are three atoms in the molecule.

#. The whole molecule is a single charge group.

#. The first atom has Lennard-Jones (sec. :ref:`lj`) and Coulomb
   (sec. :ref:`coul`) interactions.

#. Atoms two and three have only Coulomb interactions, and equal
   charges.

These loops also works for the SPC/E \ :ref:`178 <refBerendsen87>` and
TIP3P \ :ref:`128 <refJorgensen83>` water models. And for four site water
models similar to TIP4P \ :ref:`128 <refJorgensen83>`:

#. There are four atoms in the molecule.

#. The whole molecule is a single charge group.

#. The first atom has only Lennard-Jones (sec. :ref:`lj`) interactions.

#. Atoms two and three have only Coulomb (sec. :ref:`coul`) interactions,
   and equal charges.

#. Atom four has only Coulomb interactions.

The benefit of these implementations is that there are more
floating-point operations in a single loop, which implies that some
compilers can schedule the code better. However, it turns out that even
some of the most advanced compilers have problems with scheduling,
implying that manual tweaking is necessary to get optimum performance.
This may include common-sub-expression elimination, or moving code
around.

.. raw:: latex

    \clearpage


.. [1]
   Note that some derivations, an alternative notation
   :math:`\xi_{\mathrm{alt}} = v_{\xi} = p_{\xi}/Q` is used.

.. [2]
   The calculation of Lennard-Jones and Coulomb forces is about 50
   floating point operations.
.. _algorithms:

Algorithms
==========

In this chapter we first give describe some general concepts used in
|Gromacs|: *periodic boundary conditions* (sec. :ref:`pbc`) and the *group
concept* (sec. :ref:`groupconcept`). The MD algorithm is described in
sec. :ref:`MD`: first a global form of the algorithm is given, which is
refined in subsequent subsections. The (simple) EM (Energy Minimization)
algorithm is described in sec. :ref:`EM`. Some other algorithms for
special purpose dynamics are described after this.

A few issues are of general interest. In all cases the *system* must be
defined, consisting of molecules. Molecules again consist of particles
with defined interaction functions. The detailed description of the
*topology* of the molecules and of the *force field* and the calculation
of forces is given in chapter :ref:`ff`. In the present chapter we
describe other aspects of the algorithm, such as pair list generation,
update of velocities and positions, coupling to external temperature and
pressure, conservation of constraints. The *analysis* of the data
generated by an MD simulation is treated in chapter :ref:`analysis`.

.. toctree::
   :maxdepth: 2

   algorithms/periodic-boundary-conditions
   algorithms/group-concept
   algorithms/molecular-dynamics
   algorithms/shell-molecular-dynamics
   algorithms/constraint-algorithms
   algorithms/simulated-annealing
   algorithms/stochastic-dynamics
   algorithms/brownian-dynamics
   algorithms/energy-minimization
   algorithms/normal-mode-analysis
   algorithms/free-energy-calculations
   algorithms/replica-exchange
   algorithms/essential-dynamics
   algorithms/expanded-ensemble
   algorithms/parallelization-domain-decomp


.. _gmx-reference-manual-rst:

****************
Reference Manual
****************

.. highlight:: bash

.. todo:: this needs to be carefully checked that I didn't mess anything up too bad

.. ifconfig:: gmx_image_convert == 'possible'

   This part of the documentation covers implementation details of |Gromacs|.
   
   For quick simulation set-up and short explanations,
   please refer to the :ref:`User guide <user guide>`.
   
   Help with the installation of |Gromacs| can be found in the
   :ref:`Install guide <install guide>`.
   
   If you want to help with developing |Gromacs|, your are most welcome
   to read up on the :ref:`Developer Guide <dev guide>` and continue
   right away with coding for |Gromacs|.

   .. toctree::
      :maxdepth: 2
      
      preface
      introduction
      definitions
      algorithms
      functions
      topologies
      file-formats
      special
      run-parameters
      analysis
      details
      averages
      references


.. ifconfig:: gmx_image_convert == 'impossible'

   The manual could not be properly build because we could not
   convert the images for proper display without Imagemagick.
   The rest of the documentation is still there, but this part here will be missing.

   For quick simulation set-up and short explanations,
   please refer to the :ref:`User guide <user guide>`.

   Help with the installation of |Gromacs| can be found in the
   :ref:`Install guide <install guide>`.

   If you want to help with developing |Gromacs|, your are most welcome
   to read up on the :ref:`Developer Guide <dev guide>` and continue
   right away with coding for |Gromacs|.

   .. toctree::
      :maxdepth: 2

      preface
      introduction
      definitions
      topologies
      file-formats
      run-parameters
      details
      averages
      references

File formats
============

.. todo:: in future patch: update for accuracy, organize better, improve formatting

Summary of file formats
^^^^^^^^^^^^^^^^^^^^^^^

Parameter files
---------------

:ref:`mdp`
    run parameters, input for :ref:`gmx grompp` and :ref:`gmx convert-tpr`

:ref:`m2p`
    input for :ref:`gmx xpm2ps`

.. _gmx-structure-files:

Structure files
---------------

:ref:`gro`
    |Gromacs| format
:ref:`g96`
    GROMOS-96 format
:ref:`pdb`
    brookhaven Protein DataBank format
**Structure+mass(db):** :ref:`tpr`, :ref:`gro`, :ref:`g96`, or :ref:`pdb`
    Structure and mass input for analysis tools.
    When gro or pdb is used approximate masses will be read from the mass database.

Topology files
--------------

:ref:`top`
    system topology (ascii)
:ref:`itp`
    include topology (ascii)
:ref:`rtp`
    residue topology (ascii)
:ref:`ndx`
    index file (ascii)
:ref:`n2t`
    atom naming definition (ascii)
:ref:`atp`
    atom type library (ascii)
:ref:`r2b`
    residue to building block mapping (ascii)
:ref:`arn`
    atom renaming database (ascii)
:ref:`hdb`
    hydrogen atom database (ascii)
:ref:`vsd`
    virtual site database (ascii)
:ref:`tdb`
    termini database (ascii)

Run Input files
---------------

:ref:`tpr`
    system topology, parameters, coordinates and velocities (binary, portable)

Trajectory files
----------------

:ref:`tng`
    Any kind of data (compressed, portable, any precision)
:ref:`trr`
    x, v and f (binary, full precision, portable)
:ref:`xtc`
    x only (compressed, portable, any precision)
:ref:`gro`
    x and v (ascii, any precision)
:ref:`g96`
    x only (ascii, fixed high precision)
:ref:`pdb`
    x only (ascii, reduced precision)
**Formats for full-precision data:**
    :ref:`tng` or :ref:`trr`
**Generic trajectory formats:**
    :ref:`tng`, :ref:`xtc`, :ref:`trr`, :ref:`gro`, :ref:`g96`, or :ref:`pdb`

Energy files
------------

:ref:`ene`
    energies, temperature, pressure, box size, density and virials (binary)
:ref:`edr`
    energies, temperature, pressure, box size, density and virials (binary, portable)
**Generic energy formats:**
    :ref:`edr` or :ref:`ene`

Other files
-----------

:ref:`dat`
    generic, preferred for input
:ref:`edi`
    essential dynamics constraints input for :ref:`gmx mdrun`
:ref:`eps`
    Encapsulated Postscript
:ref:`log`
    log file
:ref:`map`
    colormap input for :ref:`gmx do_dssp`
:ref:`mtx`
    binary matrix data
:ref:`out`
    generic, preferred for output
:ref:`tex`
    LaTeX input
:ref:`xpm`
    ascii matrix data, use :ref:`gmx xpm2ps` to convert to :ref:`eps`
:ref:`xvg`
    xvgr input

File format details
^^^^^^^^^^^^^^^^^^^

.. _atp:

atp
---

The atp file contains general information about atom types, like the atom
number and the mass in atomic mass units.

.. _arn:

arn
---

The arn file allows the renaming of atoms from their force field names to the names
as defined by IUPAC/PDB, to allow easier visualization and identification.

.. _cpt:

cpt
---

The cpt file extension stands for portable checkpoint file.
The complete state of the simulation is stored in the checkpoint file,
including extended thermostat/barostat variables, random number states
and NMR time averaged data.
With domain decomposition also the some decomposition setup information
is stored.

See also :ref:`gmx mdrun`.

.. _dat:

dat
---

Files with the dat file extension contain generic input or output.
As it is not possible
to categorize all data file formats, |Gromacs| has a generic file format called
dat of which no format is given.

.. _dlg:

dlg
---

The dlg file format is used as input for the :ref:`gmx view`
trajectory viewer. These files are not meant to be altered by the end user.

Sample
++++++

::

    grid 39 18 {

    group "Bond Options" 1 1 16 9 {
      radiobuttons { " Thin Bonds"  " Fat Bonds" " Very Fat Bonds" " Spheres" }
            "bonds" "Ok" " F" "help bonds"
    }

    group "Other Options" 18 1 20 13 {
      checkbox " Show Hydrogens"      ""  "" "FALSE" "help opts"
      checkbox " Draw plus for atoms" ""  "" "TRUE"  "help opts"
      checkbox " Show Box"            ""  "" "TRUE"  "help opts"
      checkbox " Remove PBC"          ""  "" "FALSE" "help opts"
      checkbox " Depth Cueing"        ""  "" "TRUE"  "help opts"
      edittext "Skip frames: "        ""  "" "0"     "help opts"
    }

    simple 1 15 37 2 {
      defbutton "Ok" "Ok" "Ok" "Ok" "help bonds"
    }

    }

.. _edi:

edi
---

Files with the edi file extension contain information for :ref:`gmx mdrun`
to run Molecular Dynamics with Essential Dynamics constraints. 
It used to be possible to generate those through the options
provided in the `WHAT IF <http://swift.cmbi.ru.nl/whatif/>`_ program.

.. WEDSAM and ESSDYN seem to have vanished from WhatIf and the web
   These files can be generated by the program <tt>WEDSAM</tt> which uses
   output from the programs in the <tt>ESSDYN</tt> menu of the
   <A HREF="http://www.sander.embl-heidelberg.de/whatif/">WHAT IF</A> program.

.. _edr:

edr
---

The edr file extension stands for portable energy file.
The energies are stored using the xdr protocol.

See also :ref:`gmx energy`.

.. _ene:

ene
---

The ene file extension stands for binary energy file. It holds the
energies as generated during your :ref:`gmx mdrun`.

The file can be transformed to a portable energy file (portable
across hardware platforms), the :ref:`edr` file using the program
:ref:`gmx eneconv`.

See also :ref:`gmx energy`.

.. _eps:

eps
---

The eps file format is not a special |Gromacs| format, but just a
variant of the standard PostScript(tm). A sample eps file as
generated by the :ref:`gmx xpm2ps` program is
included below. It shows the secondary structure of a peptide as a function
of time.

.. image:: plots/plotje.*
   :alt:  hallo

.. _g96:

g96
---

A file with the g96 extension can be a GROMOS-96 initial/final
configuration file or a coordinate trajectory file or a combination of both.
The file is fixed format, all floats are written as 15.9 (files can get huge).
|Gromacs| supports the following data blocks in the given order:

 * Header block:

    - ``TITLE`` (mandatory)

 * Frame blocks:

    - ``TIMESTEP`` (optional)
    - ``POSITION/POSITIONRED`` (mandatory)
    - ``VELOCITY/VELOCITYRED`` (optional)
    - ``BOX`` (optional)

See the GROMOS-96 manual for a complete description of the blocks.

Note that all |Gromacs| programs can read compressed or g-zipped files.

.. _gro:

gro
---

Files with the gro file extension contain a molecular structure in
Gromos87 format. gro files can be used as trajectory by simply
concatenating files. An attempt will be made to read a time value from
the title string in each frame, which should be preceded by
'``t=``', as in the sample below.

A sample piece is included below::

    MD of 2 waters, t= 0.0
        6
        1WATER  OW1    1   0.126   1.624   1.679  0.1227 -0.0580  0.0434
        1WATER  HW2    2   0.190   1.661   1.747  0.8085  0.3191 -0.7791
        1WATER  HW3    3   0.177   1.568   1.613 -0.9045 -2.6469  1.3180
        2WATER  OW1    4   1.275   0.053   0.622  0.2519  0.3140 -0.1734
        2WATER  HW2    5   1.337   0.002   0.680 -1.0641 -1.1349  0.0257
        2WATER  HW3    6   1.326   0.120   0.568  1.9427 -0.8216 -0.0244
       1.82060   1.82060   1.82060

Lines contain the following information (top to bottom):

 * title string (free format string, optional time in ps after '``t=``')
 * number of atoms (free format integer)
 * one line for each atom (fixed format, see below)
 * box vectors (free format, space separated reals), values:
   v1(x) v2(y) v3(z) v1(y) v1(z) v2(x) v2(z) v3(x) v3(y),
   the last 6 values may be omitted (they will be set to zero).
   |Gromacs| only supports boxes with v1(y)=v1(z)=v2(z)=0.

This format is fixed, ie. all columns are in a fixed
position. Optionally (for now only yet with trjconv) you can write gro
files with any number of decimal places, the format will then be
``n+5`` positions with ``n`` decimal places (``n+1``
for velocities) in stead of ``8`` with ``3`` (with
``4`` for velocities). Upon reading, the precision will be
inferred from the distance between the decimal points (which will be
``n+5``). Columns contain the following information (from left to
right):

 * residue number (5 positions, integer)
 * residue name (5 characters)
 * atom name (5 characters)
 * atom number (5 positions, integer)
 * position (in nm, x y z in 3 columns, each 8 positions with 3 decimal places)
 * velocity (in nm/ps (or km/s), x y z in 3 columns, each 8 positions with 4 decimal places)

Note that separate molecules or ions (e.g. water or Cl-) are regarded
as residues.  If you want to write such a file in your own program
without using the |Gromacs| libraries you can use the following formats:

C format
    ``"%5d%-5s%5s%5d%8.3f%8.3f%8.3f%8.4f%8.4f%8.4f"``
Fortran format
    ``(i5,2a5,i5,3f8.3,3f8.4)``
Pascal format
    This is left as an exercise for the user

Note that this is the format for writing, as in the above example
fields may be written without spaces, and therefore can not be read
with the same format statement in C.

.. _hdb:

hdb
---

The hdb file extension stands for hydrogen database
Such a file is needed by :ref:`gmx pdb2gmx`
when building hydrogen atoms that were either originally missing, or that
were removed with ``-ignh``.

.. _itp:

itp
---

The itp file extension stands for include topology. These files are included in
topology files (with the :ref:`top` extension).

.. _log:

log
---

Logfiles are generated by some |Gromacs| programs and are usually in
human-readable format. Use ``more logfile``.

.. _m2p:

m2p
---

The m2p file format contains input options for the
:ref:`gmx xpm2ps` program. All of these options
are very easy to comprehend when you look at the PosScript(tm) output
from :ref:`gmx xpm2ps`.

::

    ; Command line options of xpm2ps override the parameters in this file
    black&white              = no           ; Obsolete
    titlefont                = Times-Roman  ; A PostScript Font
    titlefontsize            = 20           ; Font size (pt)
    legend                   = yes          ; Show the legend
    legendfont               = Times-Roman  ; A PostScript Font
    legendlabel              =              ; Used when there is none in the .xpm
    legend2label             =              ; Used when merging two xpm's
    legendfontsize           = 14           ; Font size (pt)
    xbox                     = 2.0          ; x-size of a matrix element
    ybox                     = 2.0          ; y-size of a matrix element
    matrixspacing            = 20.0         ; Space between 2 matrices
    xoffset                  = 0.0          ; Between matrix and bounding box
    yoffset                  = 0.0          ; Between matrix and bounding box
    x-major                  = 20           ; Major ticks on x axis every .. frames
    x-minor                  = 5            ; Id. Minor ticks
    x-firstmajor             = 0            ; First frame for major tick
    x-majorat0               = no           ; Major tick at first frame
    x-majorticklen           = 8.0          ; x-majorticklength
    x-minorticklen           = 4.0          ; x-minorticklength
    x-label                  =              ; Used when there is none in the .xpm
    x-fontsize               = 16           ; Font size (pt)
    x-font                   = Times-Roman  ; A PostScript Font 
    x-tickfontsize           = 10           ; Font size (pt)
    x-tickfont               = Helvetica    ; A PostScript Font
    y-major                  = 20
    y-minor                  = 5
    y-firstmajor             = 0
    y-majorat0               = no
    y-majorticklen           = 8.0
    y-minorticklen           = 4.0
    y-label                  = 
    y-fontsize               = 16
    y-font                   = Times-Roman
    y-tickfontsize           = 10
    y-tickfont               = Helvetica

.. _map:

map
---

This file maps matrix data to RGB values which is used by the
:ref:`gmx do_dssp` program.

The format of this file is as follow: first line number of elements
in the colormap. Then for each line: The first character is
a code for the secondary structure type.
Then comes a string for use in the legend of the plot and then the
R (red) G (green) and B (blue) values.

In this case the colors are
(in order of appearance): white, red, black, cyan, yellow, blue, magenta, orange.

::

    8
    ~  	Coil		1.0	  1.0	  1.0
    E 	B-Sheet		1.0	  0.0	  0.0
    B 	B-Bridge	0.0	  0.0	  0.0
    S 	Bend		0.0	  0.8	  0.8
    T 	Turn		1.0	  1.0	  0.0
    H 	A-Helix		0.0	  0.0	  1.0
    G 	3-Helix		1.0	  0.0	  1.0
    I 	5-Helix		1.0	  0.6	  0.0

.. _mdp:

mdp
---

See the user guide for a detailed description of the options.

Below is a sample mdp file.
The ordering of the items is not important, but if you enter the same
thing twice, the **last** is used (:ref:`gmx grompp` gives you a note when
overriding values). Dashes and underscores on the left hand side are ignored.

The values of the options are values for a 1 nanosecond
MD run of a protein in a box of water.

**Note:** The parameters chosen (*e.g.,* short-range cutoffs) depend on the
force field being used.

::

    integrator               = md
    dt                       = 0.002
    nsteps                   = 500000

    nstlog                   = 5000
    nstenergy                = 5000
    nstxout-compressed       = 5000

    continuation             = yes
    constraints              = all-bonds
    constraint-algorithm     = lincs

    cutoff-scheme            = Verlet

    coulombtype              = PME
    rcoulomb                 = 1.0
    
    vdwtype                  = Cut-off
    rvdw                     = 1.0
    DispCorr                 = EnerPres

    tcoupl                   = V-rescale
    tc-grps                  = Protein  SOL
    tau-t                    = 0.1      0.1
    ref-t                    = 300      300

    pcoupl                   = Parrinello-Rahman
    tau-p                    = 2.0
    compressibility          = 4.5e-5
    ref-p                    = 1.0

With this input :ref:`gmx grompp` will produce a commented file with the default name
``mdout.mdp``. That file will contain the above options, as well as all other
options not explicitly set, showing their default values.

.. _mtx:

mtx
---

Files with the mtx file extension contain a matrix.
The file format is identical to the :ref:`trr` format.
Currently this file format is only used for hessian matrices,
which are produced with :ref:`gmx mdrun` and read by
:ref:`gmx nmeig`.

.. _ndx:

ndx
---

The |Gromacs| index file (usually called index.ndx) contains some
user definable sets of atoms. The file can be read by
most analysis programs, by the graphics program
(:ref:`gmx view`)
and by the preprocessor (:ref:`gmx grompp`).
Most of these programs create default index groups when no index
file is supplied, so you only need to make an index file when you need special
groups.

First the group name is written between square brackets.
The following atom numbers may be spread out over as many lines as you like.
The atom numbering starts at 1.

An example file is here:

::

    [ Oxygen ]
    1  4  7
    [ Hydrogen ]
    2  3  5  6
    8  9

There are two groups, and total nine atoms. The first group
**Oxygen** has 3 elements.
The second group **Hydrogen** has 6 elements.

An index file generation tool is available:
:ref:`gmx make_ndx`.

.. _n2t:

n2t
---

This |Gromacs| file can be used to perform primitive translations between
atom names found in structure files and the corresponding atom types.
This is mostly useful for using utilities such as :ref:`gmx x2top`, but users
should be aware that the knowledge in this file is extremely limited.

An example file (``share/top/gromos53a5.ff/atomname2type.n2t``) is here:

::

    H       H    0.408  1.008  1  O     0.1
    O       OA  -0.674 15.9994 2  C     0.14 H 0.1               
    C       CH3  0.000 15.035  1  C     0.15         
    C       CH0  0.266 12.011  4  C     0.15 C 0.15     C 0.15     O 0.14

A short description of the file format follows:

* Column 1: Elemental symbol of the atom/first character in the atom name.
* Column 2: The atom type to be assigned.
* Column 3: The charge to be assigned.
* Column 4: The mass of the atom.
* Column 5: The number N of other atoms to which this atom is bonded.
  The number of fields that follow are related to this number;
  for each atom, an elemental symbol and the reference distance for its bond length.
* Columns 6-onward: The elemental symbols and reference bond lengths for N connections
  (column 5) to the atom being assigned parameters (column 1). The reference bond
  lengths have a tolerance of +/- 10% from the value specified in this file. Any bond
  outside this tolerance will not be recognized as being connected to the atom being assigned parameters.

.. _out:

out
---

Files with the out file extension contain generic output. As it is not possible
to categorize all data file formats, |Gromacs| has a generic file format called
out of which no format is given.

.. _pdb:

pdb
---


Files with the :ref:`pdb` extension are molecular
structure files in the protein databank file format.  The protein
databank file format describes the positions of atoms in a molecular
structure. Coordinates are read from the ATOM and HETATM records,
until the file ends or an ENDMDL record is encountered.
|Gromacs| programs can read and write a simulation box in the
CRYST1 entry.
The pdb format can also be used as a trajectory format:
several structures, separated by ENDMDL, can be read from
or written to one file.

Example
+++++++

A pdb file should look like this::

    ATOM      1  H1  LYS     1      14.260   6.590  34.480  1.00  0.00
    ATOM      2  H2  LYS     1      13.760   5.000  34.340  1.00  0.00
    ATOM      3  N   LYS     1      14.090   5.850  33.800  1.00  0.00
    ATOM      4  H3  LYS     1      14.920   5.560  33.270  1.00  0.00
    ...
    ...

.. _rtp:

rtp
---

The rtp file extension stands for residue topology.
Such a file is needed by :ref:`gmx pdb2gmx`
to make a |Gromacs| topology for a protein contained in a :ref:`pdb`
file. The file contains the default interaction type for the 4 bonded
interactions and residue entries, which consist of atoms and
optionally bonds, angles dihedrals and impropers.
Parameters can be added to bonds, angles, dihedrals and impropers,
these parameters override the standard parameters in the :ref:`itp` files.
This should only be used in special cases.
Instead of parameters a string can be added for each bonded interaction,
the string is copied to the :ref:`top` file,
this is used for the GROMOS96 forcefield.

:ref:`gmx pdb2gmx` automatically generates all angles,
this means that the ``[angles]`` field is only
useful for overriding :ref:`itp` parameters.

:ref:`gmx pdb2gmx` automatically generates one proper
dihedral for every rotatable bond, preferably on heavy atoms.
When the ``[dihedrals]`` field is used, no other dihedrals will
be generated for the bonds corresponding to the specified dihedrals.
It is possible to put more than one dihedral on a rotatable bond.

:ref:`gmx pdb2gmx` sets the number exclusions to 3, which
means that interactions between atoms connected by at most 3 bonds are
excluded. Pair interactions are generated for all pairs of atoms which are
separated by 3 bonds (except pairs of hydrogens).
When more interactions need to be excluded, or some pair interactions should
not be generated, an ``[exclusions]`` field can be added, followed by
pairs of atom names on separate lines. All non-bonded and pair interactions
between these atoms will be excluded.

A sample is included below.

::

    [ bondedtypes ]  ; mandatory
    ; bonds  angles  dihedrals  impropers
         1       1          1          2  ; mandatory

    [ GLY ]  ; mandatory

     [ atoms ]  ; mandatory
    ; name  type  charge  chargegroup
         N     N  -0.280     0
         H     H   0.280     0
        CA   CH2   0.000     1
         C     C   0.380     2
         O     O  -0.380     2

     [ bonds ]  ; optional
    ;atom1 atom2      b0      kb
         N     H
         N    CA
        CA     C
         C     O
        -C     N

     [ exclusions ]  ; optional
    ;atom1 atom2

     [ angles ]  ; optional
    ;atom1 atom2 atom3    th0    cth

     [ dihedrals ]  ; optional
    ;atom1 atom2 atom3 atom4   phi0     cp   mult

     [ impropers ]  ; optional
    ;atom1 atom2 atom3 atom4     q0     cq
         N    -C    CA     H
        -C   -CA     N    -O


    [ ZN ]
     [ atoms ]
        ZN    ZN   2.000     0

.. _r2b:

r2b
---

The r2b file translates the residue names for residues that have different names in different
force fields, or have different names depending on their protonation states.

.. _tdb:

tdb
---

tdb files contain the information about amino acid termini that can be placed at the
end of a polypeptide chain.

.. _tex:

tex
---

We use **LaTeX** for *document* processing.
Although the input is not so
user friendly, it has some  advantages over *word* processors.

 * **LaTeX** knows a lot about formatting, probably much more than you.
 * The input is clear, you always know what you are doing
 * It makes anything from letters to a thesis
 * Much more...

.. _tng:

tng
---

Files with the ``.tng`` file extension can contain all kinds of data
related to the trajectory of a simulation. For example, it might
contain coordinates, velocities, forces and/or energies. Various :ref:`mdp`
file options control which of these are written by :ref:`gmx mdrun`, whether data
is written with compression, and how lossy that compression can be.
This file is in portable binary format and can be read with :ref:`gmx dump`.

.. parsed-literal::

   :ref:`gmx dump` -f traj.tng

or if you're not such a fast reader::

   gmx dump -f traj.tng | less

You can also get a quick look in the contents of the file (number of
frames etc.) using:

.. parsed-literal::

   :ref:`gmx check` -f traj.tng

.. _top:

top
---

The top file extension stands for topology. It is an ascii file which is
read by :ref:`gmx grompp` which processes it
and creates a binary topology (:ref:`tpr` file).

A sample file is included below::

    ;
    ; Example topology file
    ;
    [ defaults ]
    ; nbfunc        comb-rule       gen-pairs       fudgeLJ fudgeQQ
      1             1               no              1.0     1.0

    ; The force field files to be included
    #include "rt41c5.itp"

    [ moleculetype ]
    ; name  nrexcl
    Urea         3

    [ atoms ]
    ;   nr    type   resnr  residu    atom    cgnr  charge
         1       C       1    UREA      C1       1   0.683
         2       O       1    UREA      O2       1  -0.683
         3      NT       1    UREA      N3       2  -0.622
         4       H       1    UREA      H4       2   0.346
         5       H       1    UREA      H5       2   0.276
         6      NT       1    UREA      N6       3  -0.622
         7       H       1    UREA      H7       3   0.346
         8       H       1    UREA      H8       3   0.276

    [ bonds ]
    ;  ai    aj funct           c0           c1
        3     4     1 1.000000e-01 3.744680e+05
        3     5     1 1.000000e-01 3.744680e+05
        6     7     1 1.000000e-01 3.744680e+05
        6     8     1 1.000000e-01 3.744680e+05
        1     2     1 1.230000e-01 5.020800e+05
        1     3     1 1.330000e-01 3.765600e+05
        1     6     1 1.330000e-01 3.765600e+05

    [ pairs ]
    ;  ai    aj funct           c0           c1
        2     4     1 0.000000e+00 0.000000e+00
        2     5     1 0.000000e+00 0.000000e+00
        2     7     1 0.000000e+00 0.000000e+00
        2     8     1 0.000000e+00 0.000000e+00
        3     7     1 0.000000e+00 0.000000e+00
        3     8     1 0.000000e+00 0.000000e+00
        4     6     1 0.000000e+00 0.000000e+00
        5     6     1 0.000000e+00 0.000000e+00

    [ angles ]
    ;  ai    aj    ak funct           c0           c1
        1     3     4     1 1.200000e+02 2.928800e+02
        1     3     5     1 1.200000e+02 2.928800e+02
        4     3     5     1 1.200000e+02 3.347200e+02
        1     6     7     1 1.200000e+02 2.928800e+02
        1     6     8     1 1.200000e+02 2.928800e+02
        7     6     8     1 1.200000e+02 3.347200e+02
        2     1     3     1 1.215000e+02 5.020800e+02
        2     1     6     1 1.215000e+02 5.020800e+02
        3     1     6     1 1.170000e+02 5.020800e+02

    [ dihedrals ]
    ;  ai    aj    ak    al funct           c0           c1           c2
        2     1     3     4     1 1.800000e+02 3.347200e+01 2.000000e+00
        6     1     3     4     1 1.800000e+02 3.347200e+01 2.000000e+00
        2     1     3     5     1 1.800000e+02 3.347200e+01 2.000000e+00
        6     1     3     5     1 1.800000e+02 3.347200e+01 2.000000e+00
        2     1     6     7     1 1.800000e+02 3.347200e+01 2.000000e+00
        3     1     6     7     1 1.800000e+02 3.347200e+01 2.000000e+00
        2     1     6     8     1 1.800000e+02 3.347200e+01 2.000000e+00
        3     1     6     8     1 1.800000e+02 3.347200e+01 2.000000e+00

    [ dihedrals ]
    ;  ai    aj    ak    al funct           c0           c1
        3     4     5     1     2 0.000000e+00 1.673600e+02
        6     7     8     1     2 0.000000e+00 1.673600e+02
        1     3     6     2     2 0.000000e+00 1.673600e+02

    ; Include SPC water topology
    #include "spc.itp"

    [ system ]
    Urea in Water

    [ molecules ]
    Urea    1
    SOL     1000

.. _tpr:

tpr
---

The tpr file extension stands for portable binary run input file. This file
contains  the starting structure of your simulation, the molecular topology
and all the simulation parameters. Because this file is in binary format it
cannot be read with a normal editor. To read a portable binary run input
file type:

.. parsed-literal::

   :ref:`gmx dump` -s topol.tpr

or if you're not such a fast reader::

   gmx dump -s topol.tpr | less

You can also compare two tpr files using:

.. parsed-literal::

   :ref:`gmx check` -s1 top1 -s2 top2 | less

.. _trr:

trr
---

Files with the trr file extension contain the trajectory of a simulation.
In this file all the coordinates, velocities, forces and energies are
printed as you told |Gromacs| in your mdp file. This file is in portable binary
format and can be read with :ref:`gmx dump`::

    gmx dump -f traj.trr

or if you're not such a fast reader::

    gmx dump -f traj.trr | less

You can also get a quick look in the contents of the file (number of
frames etc.) using:

.. parsed-literal::

   % :ref:`gmx check` -f traj.trr

.. _vsd:

vsd
---

The vsd file contains the information on how to place virtual sites on a number
of different molecules in a force field.

.. _xdr:

xdr
---

|Gromacs| uses the XDR file format to store things like coordinate files internally.

.. _xpm:

xpm
---

The |Gromacs| xpm file format is compatible with the XPixMap format
and is used for storing matrix data.
Thus |Gromacs| xpm files can be viewed directly with programs like XV.
Alternatively, they can be imported into GIMP and scaled to 300 DPI,
using strong antialiasing for font and graphics.
The first matrix data line in an xpm file corresponds to the last matrix
row.
In addition to the XPixMap format, |Gromacs| xpm files may contain
extra fields. The information in these fields is used when converting
an xpm file to EPS with :ref:`gmx xpm2ps`.
The optional extra field are:

 * Before the ``gv_xpm`` declaration:  ``title``, ``legend``,
   ``x-label``, ``y-label`` and ``type``, all followed by a string.
   The ``legend`` field determines the legend title.
   The ``type`` field must be followed by ``"continuous"`` or
   ``"discrete"``, this determines which type of legend will be drawn in an EPS
   file, the default type is continuous.
 * The xpm colormap entries may be followed by a string, which is a label for
   that color.
 * Between the colormap and the matrix data, the fields ``x-axis`` and/or
   ``y-axis`` may be present followed by the tick-marks for that axis.

The example |Gromacs| xpm file below contains all the extra fields.
The C-comment delimiters and the colon in the extra fields are optional.

::

    /* XPM */
    /* This matrix is generated by g_rms. */
    /* title:   "Backbone RMSD matrix" */
    /* legend:  "RMSD (nm)" */
    /* x-label: "Time (ps)" */
    /* y-label: "Time (ps)" */
    /* type:    "Continuous" */
    static char * gv_xpm[] = {
    "13 13   6 1",
    "A  c #FFFFFF " /* "0" */,
    "B  c #CCCCCC " /* "0.0399" */,
    "C  c #999999 " /* "0.0798" */,
    "D  c #666666 " /* "0.12" */,
    "E  c #333333 " /* "0.16" */,
    "F  c #000000 " /* "0.2" */,
    /* x-axis:  0 40 80 120 160 200 240 280 320 360 400 440 480 */
    /* y-axis:  0 40 80 120 160 200 240 280 320 360 400 440 480 */
    "FEDDDDCCCCCBA",
    "FEDDDCCCCBBAB",
    "FEDDDCCCCBABC",
    "FDDDDCCCCABBC",
    "EDDCCCCBACCCC",
    "EDCCCCBABCCCC",
    "EDCCCBABCCCCC",
    "EDCCBABCCCCCD",
    "EDCCABCCCDDDD",
    "ECCACCCCCDDDD",
    "ECACCCCCDDDDD",
    "DACCDDDDDDEEE",
    "ADEEEEEEEFFFF"

.. _xtc:

xtc
---

The xtc format is a **portable** format for trajectories.
It uses the *xdr* routines for writing and reading
data which was created for the Unix NFS system. The trajectories
are written using a reduced precision algorithm which works
in the following way: the coordinates (in nm) are multiplied by a scale
factor, typically 1000, so that you have coordinates in pm.
These are rounded to integer values. Then several other tricks are
performed, for instance making use of the fact that atoms close
in sequence are usually close in space too (e.g. a water molecule).
To this end, the *xdr* library is extended with a special routine
to write 3-D float coordinates. The routine was originally written
by Frans van Hoesel as part of an Europort project. An updated
version of it can be obtained through `this link <https://github.com/Pappulab/xdrf>`_.

All the data is stored using calls to *xdr* routines.

**int** magic
    A magic number, for the current file version its value is 1995.
**int** natoms
    The number of atoms in the trajectory.
**int** step
    The simulation step.
**float** time
    The simulation time.
**float** box[3][3]
    The computational box which is stored as a set of three basis
    vectors, to allow for triclinic PBC. For a rectangular box the
    box edges are stored on the diagonal of the matrix.
**3dfcoord** x[natoms]
    The coordinates themselves stored in reduced precision.
    Please note that when the number of atoms is smaller than 9
    no reduced precision is used.

Using xtc in your C++ programs
++++++++++++++++++++++++++++++

It is possible to write your own analysis tools to take advantage
of the compressed .xtc format files: see the
``template.cpp`` file in the
``share/gromacs/template`` directory of your installation
for an example and
https://manual.gromacs.org/current/doxygen/html-full/page_analysistemplate.xhtml
for documentation.

To read and write xtc files the following routines are available via ``xtcio.h``::

    /* All functions return 1 if successful, 0 otherwise */

    struct t_fileio* open_xtc(const char* filename, const char* mode);
    /* Open a file for xdr I/O */

    void close_xtc(struct t_fileio* fio);
    /* Close the file for xdr I/O */

    int read_first_xtc(struct t_fileio* fio,
                       int*             natoms,
                       int64_t*         step,
                       real*            time,
                       matrix           box,
                       rvec**           x,
                       real*            prec,
                       gmx_bool*        bOK);
    /* Open xtc file, read xtc file first time, allocate memory for x */

    int read_next_xtc(struct t_fileio* fio, int natoms, int64_t* step, real* time, matrix box, rvec* x, real* prec, gmx_bool* bOK);
    /* Read subsequent frames */

    int write_xtc(struct t_fileio* fio, int natoms, int64_t step, real time, const rvec* box, const rvec* x, real prec);
    /* Write a frame to xtc file */

To use the library function include ``"gromacs/fileio/xtcio.h"``
in your file and link with ``-lgromacs``.

.. _xvg:

xvg
---

Almost all output from |Gromacs| analysis tools is ready as input for
Grace, formerly known as Xmgr. We use Grace, because it is very flexible, and it is also
free software. It produces PostScript(tm) output, which is very suitable
for inclusion in eg. LaTeX documents, but also for other word processors.

A sample Grace session with |Gromacs| data is shown below:

.. image:: plots/xvgr.*
   :alt:  Sample xvg graphic produced using the |Gromacs| tools

.. raw:: latex

    \clearpage


Introduction
============

.. _compchem:

Computational Chemistry and Molecular Modeling
----------------------------------------------

|Gromacs| is an engine to perform molecular dynamics simulations and
energy minimization. These are two of the many techniques that belong to
the realm of computational chemistry and molecular modeling.
*Computational chemistry* is just a name to indicate the use of
computational techniques in chemistry, ranging from quantum mechanics of
molecules to dynamics of large complex molecular aggregates. *Molecular
modeling* indicates the general process of describing complex chemical
systems in terms of a realistic atomic model, with the goal being to
understand and predict macroscopic properties based on detailed
knowledge on an atomic scale. Often, molecular modeling is used to
design new materials, for which the accurate prediction of physical
properties of realistic systems is required.

Macroscopic physical properties can be distinguished by

#. *static equilibrium properties*, such as the binding constant of an
   inhibitor to an enzyme, the average potential energy of a system, or the
   radial distribution function of a liquid, and 

#. *dynamic or non-equilibrium properties*, such as the viscosity of a liquid,
   diffusion processes in membranes, the dynamics of phase changes,
   reaction kinetics, or the dynamics of defects in crystals. 

The choice of
technique depends on the question asked and on the feasibility of the
method to yield reliable results at the present state of the art.
Ideally, the (relativistic) time-dependent Schrödinger equation
describes the properties of molecular systems with high accuracy, but
anything more complex than the equilibrium state of a few atoms cannot
be handled at this *ab initio* level. Thus, approximations are
necessary; the higher the complexity of a system and the longer the time
span of the processes of interest is, the more severe the required
approximations are. At a certain point (reached very much earlier than
one would wish), the *ab initio* approach must be augmented or replaced
by *empirical* parameterization of the model used. Where simulations
based on physical principles of atomic interactions still fail due to
the complexity of the system, molecular modeling is based entirely on a
similarity analysis of known structural and chemical data. The QSAR
methods (Quantitative Structure-Activity Relations) and many
homology-based protein structure predictions belong to the latter
category.

Macroscopic properties are always ensemble averages over a
representative statistical ensemble (either equilibrium or
non-equilibrium) of molecular systems. For molecular modeling, this has
two important consequences:

-  The knowledge of a single structure, even if it is the structure of
   the global energy minimum, is not sufficient. It is necessary to
   generate a representative ensemble at a given temperature, in order
   to compute macroscopic properties. But this is not enough to compute
   thermodynamic equilibrium properties that are based on free energies,
   such as phase equilibria, binding constants, solubilities, relative
   stability of molecular conformations, etc. The computation of free
   energies and thermodynamic potentials requires special extensions of
   molecular simulation techniques.

-  While molecular simulations, in principle, provide atomic details of
   the structures and motions, such details are often not relevant for
   the macroscopic properties of interest. This opens the way to
   simplify the description of interactions and average over irrelevant
   details. The science of statistical mechanics provides the
   theoretical framework for such simplifications. There is a hierarchy
   of methods ranging from considering groups of atoms as one unit,
   describing motion in a reduced number of collective coordinates,
   averaging over solvent molecules with potentials of mean force
   combined with stochastic dynamics :ref:`9 <refGunsteren90>`, to
   *mesoscopic dynamics* describing densities rather than atoms and
   fluxes as response to thermodynamic gradients rather than velocities
   or accelerations as response to forces \ :ref:`10 <refFraaije93>`.

For the generation of a representative equilibrium ensemble two methods
are available: 

#. *Monte Carlo simulations* and

#. *Molecular Dynamics simulations*. 
  
For the generation of non-equilibrium
ensembles and for the analysis of dynamic events, only the second method
is appropriate. While Monte Carlo simulations are more simple than MD
(they do not require the computation of forces), they do not yield
significantly better statistics than MD in a given amount of computer
time. Therefore, MD is the more universal technique. If a starting
configuration is very far from equilibrium, the forces may be
excessively large and the MD simulation may fail. In those cases, a
robust *energy minimization* is required. Another reason to perform an
energy minimization is the removal of all kinetic energy from the
system: if several “snapshots” from dynamic simulations must be
compared, energy minimization reduces the thermal noise in the
structures and potential energies so that they can be compared better.

Molecular Dynamics Simulations
------------------------------

MD simulations solve Newton’s equations of motion for a system of
:math:`N` interacting atoms:

.. math:: m_i \frac{\partial^2 \mathbf{r}_i}{\partial t^2}  = \mathbf{F}_i, \;i=1 \ldots N.
          :label: eqnnewtonslaws

The forces are the negative derivatives of a potential function
:math:`V(\mathbf{r}_1, \mathbf{r}_2, \ldots, \mathbf{r}_N)`:

.. math:: \mathbf{F}_i = - \frac{\partial V}{\partial \mathbf{r}_i}
          :label: eqnmdforces

The equations are solved simultaneously in small time steps. The system
is followed for some time, taking care that the temperature and pressure
remain at the required values, and the coordinates are written to an
output file at regular intervals. The coordinates as a function of time
represent a *trajectory* of the system. After initial changes, the
system will usually reach an *equilibrium state*. By averaging over an
equilibrium trajectory, many macroscopic properties can be extracted
from the output file.

It is useful at this point to consider the limitations of MD
simulations. The user should be aware of those limitations and always
perform checks on known experimental properties to assess the accuracy
of the simulation. We list the approximations below.

**The simulations are classical**

-     Using Newton’s equation of motion automatically implies the use of
      *classical mechanics* to describe the motion of atoms. This is all
      right for most atoms at normal temperatures, but there are
      exceptions. Hydrogen atoms are quite light and the motion of
      protons is sometimes of essential quantum mechanical character.
      For example, a proton may *tunnel* through a potential barrier in
      the course of a transfer over a hydrogen bond. Such processes
      cannot be properly treated by classical dynamics! Helium liquid at
      low temperature is another example where classical mechanics
      breaks down. While helium may not deeply concern us, the high
      frequency vibrations of covalent bonds should make us worry! The
      statistical mechanics of a classical harmonic oscillator differs
      appreciably from that of a real quantum oscillator when the
      resonance frequency :math:`\nu` approximates or exceeds
      :math:`k_BT/h`. Now at room temperature the wavenumber
      :math:`\sigma = 1/\lambda = \nu/c` at which :math:`h
      \nu = k_BT` is approximately 200 cm\ :math:`^{-1}`. Thus, all
      frequencies higher than, say, 100 cm\ :math:`^{-1}` may misbehave
      in classical simulations. This means that practically all bond and
      bond-angle vibrations are suspect, and even hydrogen-bonded
      motions as translational or librational H-bond vibrations are
      beyond the classical limit (see :numref:`Table %s <tab-vibrations>`)
      What can we do? 

.. |H2CX| replace:: H\ :math:`_2`\ CX
.. |OHO1| replace:: O-H\ :math:`\cdots`\ O
.. |INCM| replace:: :math:`\mathrm{cm}~^{-1}`

.. _tab-vibrations:

.. table::
        Typical vibrational frequencies (wavenumbers) in molecules and hydrogen-bonded
        liquids. Compare :math:`kT/h = 200~\mathrm{cm}^{-1}` at 300 K.
        :widths: auto
        :align: center

        +---------------+-------------+------------+
        |               | type of     | wavenumber |
        | type of bond  | vibration   | |INCM|     |
        +===============+=============+============+
        | C-H, O-H, N-H | stretch     | 3000--3500 |
        +---------------+-------------+------------+
        | C=C, C=O      | stretch     | 1700--2000 |
        +---------------+-------------+------------+
        | HOH           | bending     | 1600       |
        +---------------+-------------+------------+
        | C-C           | stretch     | 1400--1600 |
        +---------------+-------------+------------+
        | |H2CX|        | sciss, rock | 1000--1500 |
        +---------------+-------------+------------+
        | CCC           | bending     |  800--1000 |
        +---------------+-------------+------------+
        | |OHO1|        | libration   |  400--700  |
        +---------------+-------------+------------+
        | |OHO1|        | stretch     |   50--200  |
        +---------------+-------------+------------+



-     Well, apart from real quantum-dynamical simulations, we can do one
      of two things:

      (a)   If we perform MD simulations using harmonic oscillators for
            bonds, we should make corrections to the total internal energy
            :math:`U = E_{kin} + E_{pot}` and specific heat :math:`C_V` (and
            to entropy :math:`S` and free energy :math:`A` or :math:`G` if
            those are calculated). The corrections to the energy and specific
            heat of a one-dimensional oscillator with frequency :math:`\nu`
            are: \ :ref:`11 <refMcQuarrie76>`

            .. math:: U^{QM} = U^{cl} +kT \left( {\frac{1}{2}}x - 1 + \frac{x}{e^x-1} \right)
                      :label: eqnmdqmcorr

            .. math:: C_V^{QM} = C_V^{cl} + k \left( \frac{x^2e^x}{(e^x-1)^2} - 1 \right)
                      :label: eqnmdqmcorr2

            where :math:`x=h\nu /kT`. The classical oscillator absorbs too
            much energy (:math:`kT`), while the high-frequency quantum
            oscillator is in its ground state at the zero-point energy level
            of :math:`\frac{1}{2} h\nu`.

      (b)   We can treat the bonds (and bond angles) as
            *constraints* in the equations of
            motion. The rationale behind this is that a quantum oscillator in
            its ground state resembles a constrained bond more closely than a
            classical oscillator. A good practical reason for this choice is
            that the algorithm can use larger time steps when the highest
            frequencies are removed. In practice the time step can be made
            four times as large when bonds are constrained than when they are
            oscillators \ :ref:`12 <refGunsteren77>`. |Gromacs| has this
            option for the bonds and bond angles. The flexibility of the
            latter is rather essential to allow for the realistic motion and
            coverage of configurational space \ :ref:`13 <refGunsteren82>`.

**Electrons are in the ground state**
      In MD we use a *conservative* force field that is a function of
      the positions of atoms only. This means that the electronic
      motions are not considered: the electrons are supposed to adjust
      their dynamics instantly when the atomic positions change (the
      *Born-Oppenheimer*
      approximation), and remain in their ground state. This is really
      all right, almost always. But of course, electron transfer
      processes and electronically excited states can not be treated.
      Neither can chemical reactions be treated properly, but there are
      other reasons to shy away from reactions for the time being.

**Force fields are approximate**
      Force fields
      provide the forces.
      They are not really a part of the simulation method and their
      parameters can be modified by the user as the need arises or
      knowledge improves. But the form of the forces that can be used in
      a particular program is subject to limitations. The force field
      that is incorporated in |Gromacs| is described in Chapter 4. In the
      present version the force field is pair-additive (apart from
      long-range Coulomb forces), it cannot incorporate
      polarizabilities, and it does not contain fine-tuning of bonded
      interactions. This urges the inclusion of some limitations in this
      list below. For the rest it is quite useful and fairly reliable
      for biologically-relevant macromolecules in aqueous solution!

**The force field is pair-additive**
      This means that all *non-bonded* forces result from the sum of
      non-bonded pair interactions. Non pair-additive interactions, the
      most important example of which is interaction through atomic
      polarizability, are represented by *effective pair potentials*.
      Only average non pair-additive contributions are incorporated.
      This also means that the pair interactions are not pure, *i.e.*,
      they are not valid for isolated pairs or for situations that
      differ appreciably from the test systems on which the models were
      parameterized. In fact, the effective pair potentials are not that
      bad in practice. But the omission of polarizability also means
      that electrons in atoms do not provide a dielectric constant as
      they should. For example, real liquid alkanes have a dielectric
      constant of slightly more than 2, which reduce the long-range
      electrostatic interaction between (partial) charges. Thus, the
      simulations will exaggerate the long-range Coulomb terms. Luckily,
      the next item compensates this effect a bit.

**Long-range interactions are cut off**
      In this version, |Gromacs| always uses a
      cut-off
      radius for the Lennard-Jones
      interactions and sometimes for the Coulomb interactions as well.
      The “minimum-image convention” used by |Gromacs| requires that only
      one image of each particle in the periodic boundary conditions is
      considered for a pair interaction, so the cut-off radius cannot
      exceed half the box size. That is still pretty big for large
      systems, and trouble is only expected for systems containing
      charged particles. But then truly bad things can happen, like
      accumulation of charges at the cut-off boundary or very wrong
      energies! For such systems, you should consider using one of the
      implemented long-range electrostatic algorithms, such as
      particle-mesh Ewald \ :ref:`14 <refDarden93>`,
      :ref:`15 <refEssmann95>`.

**Boundary conditions are unnatural**
      Since system size is small (even 10,000 particles is small), a
      cluster of particles will have a lot of unwanted boundary with its
      environment (vacuum). We must avoid this condition if we wish to
      simulate a bulk system. As such, we use periodic boundary
      conditions to avoid real phase boundaries. Since liquids are not
      crystals, something unnatural remains. This item is mentioned last
      because it is the least of the evils. For large systems, the
      errors are small, but for small systems with a lot of internal
      spatial correlation, the periodic boundaries may enhance internal
      correlation. In that case, beware of, and test, the influence of
      system size. This is especially important when using lattice sums
      for long-range electrostatics, since these are known to sometimes
      introduce extra ordering.

Energy Minimization and Search Methods
--------------------------------------

As mentioned in sec. :ref:`Compchem`, in many cases energy minimization
is required. |Gromacs| provides a number of methods for local energy
minimization, as detailed in sec. :ref:`EM`.

The potential energy function of a (macro)molecular system is a very
complex landscape (or *hypersurface*) in a large number of dimensions.
It has one deepest point, the *global minimum* and a very large number
of *local minima*, where all derivatives of the potential energy
function with respect to the coordinates are zero and all second
derivatives are non-negative. The matrix of second derivatives, which is
called the *Hessian matrix*, has non-negative eigenvalues; only the
collective coordinates that correspond to translation and rotation (for
an isolated molecule) have zero eigenvalues. In between the local minima
there are *saddle points*, where the Hessian matrix has only one
negative eigenvalue. These points are the mountain passes through which
the system can migrate from one local minimum to another.

Knowledge of all local minima, including the global one, and of all
saddle points would enable us to describe the relevant structures and
conformations and their free energies, as well as the dynamics of
structural transitions. Unfortunately, the dimensionality of the
configurational space and the number of local minima is so high that it
is impossible to sample the space at a sufficient number of points to
obtain a complete survey. In particular, no minimization method exists
that guarantees the determination of the global minimum in any practical
amount of time. Impractical methods exist, some much faster than
others \ :ref:`16 <refGeman84>`. However, given a starting configuration,
it is possible to find the *nearest local minimum*. “Nearest” in this
context does not always imply “nearest” in a geometrical sense (*i.e.*,
the least sum of square coordinate differences), but means the minimum
that can be reached by systematically moving down the steepest local
gradient. Finding this nearest local minimum is all that |Gromacs| can do
for you, sorry! If you want to find other minima and hope to discover
the global minimum in the process, the best advice is to experiment with
temperature-coupled MD: run your system at a high temperature for a
while and then quench it slowly down to the required temperature; do
this repeatedly! If something as a melting or glass transition
temperature exists, it is wise to stay for some time slightly below that
temperature and cool down slowly according to some clever scheme, a
process called *simulated annealing*. Since no physical truth is
required, you can use your imagination to speed up this process. One
trick that often works is to make hydrogen atoms heavier (mass 10 or
so): although that will slow down the otherwise very rapid motions of
hydrogen atoms, it will hardly influence the slower motions in the
system, while enabling you to increase the time step by a factor of 3 or
4. You can also modify the potential energy function during the search
procedure, *e.g.* by removing barriers (remove dihedral angle functions
or replace repulsive potentials by *soft-core*
potentials \ :ref:`17 <refNilges88>`), but always take care to restore the correct
functions slowly. The best search method that allows rather drastic
structural changes is to allow excursions into four-dimensional
space \ :ref:`18 <refSchaik93>`, but this requires some extra programming
beyond the standard capabilities of |Gromacs|.

Three possible energy minimization methods are:

-  Those that require only function evaluations. Examples are the
   simplex method and its variants. A step is made on the basis of the
   results of previous evaluations. If derivative information is
   available, such methods are inferior to those that use this
   information.

-  Those that use derivative information. Since the partial derivatives
   of the potential energy with respect to all coordinates are known in
   MD programs (these are equal to minus the forces) this class of
   methods is very suitable as modification of MD programs.

-  Those that use second derivative information as well. These methods
   are superior in their convergence properties near the minimum: a
   quadratic potential function is minimized in one step! The problem is
   that for :math:`N` particles a :math:`3N\times 3N` matrix must be
   computed, stored, and inverted. Apart from the extra programming to
   obtain second derivatives, for most systems of interest this is
   beyond the available capacity. There are intermediate methods that
   build up the Hessian matrix on the fly, but they also suffer from
   excessive storage requirements. So |Gromacs| will shy away from this
   class of methods.

The *steepest descent* method, available in |Gromacs|, is of the second
class. It simply takes a step in the direction of the negative gradient
(hence in the direction of the force), without any consideration of the
history built up in previous steps. The step size is adjusted such that
the search is fast, but the motion is always downhill. This is a simple
and sturdy, but somewhat stupid, method: its convergence can be quite
slow, especially in the vicinity of the local minimum! The
faster-converging *conjugate gradient method* (see *e.g.*
:ref:`19 <refZimmerman91>`) uses gradient information from previous steps. In general,
steepest descents will bring you close to the nearest local minimum very
quickly, while conjugate gradients brings you *very* close to the local
minimum, but performs worse far away from the minimum. |Gromacs| also
supports the L-BFGS minimizer, which is mostly comparable to *conjugate
gradient method*, but in some cases converges faster.

.. raw:: latex

    \clearpage


.. _analysis:

Analysis
========

In this chapter different ways of analyzing your trajectory are
described. The names of the corresponding analysis programs are given.
Specific information on the in- and output of these programs can be
found in the tool documentation :ref:`here <gmx-cmdline>`.
The output files are often
produced as finished Grace/Xmgr graphs.

First, in sec. :ref:`usinggroups`, the group concept in analysis is
explained. :ref:`selections` explains a newer concept of dynamic
selections, which is currently supported by a few tools. Then, the
different analysis tools are presented.

.. toctree::
   :maxdepth: 2

   analysis/using-groups
   analysis/looking-at-trajectory
   analysis/general-properties
   analysis/radial-distribution-function
   analysis/correlation-function
   analysis/curve-fitting
   analysis/mean-square-displacement
   analysis/bond-angle-dihedral
   analysis/radius-of-gyration
   analysis/rmsd
   analysis/covariance-analysis
   analysis/dihedral-pca
   analysis/hydrogen-bonds
   analysis/protein-related
   analysis/interface-related


Topologies
==========

|Gromacs| must know on which atoms and combinations of atoms the various
contributions to the potential functions (see chapter :ref:`ff`) must act.
It must also know what parameters must be applied to the various
functions. All this is described in the *topology* file :ref:`top`, which
lists the *constant attributes* of each atom. There are many more atom
types than elements, but only atom types present in biological systems
are parameterized in the force field, plus some metals, ions and
silicon. The bonded and special interactions are determined by fixed
lists that are included in the topology file. Certain non-bonded
interactions must be excluded (first and second neighbors), as these are
already treated in bonded interactions. In addition, there are *dynamic
attributes* of atoms - their positions, velocities and forces. These do
not strictly belong to the molecular topology, and are stored in the
coordinate file :ref:`gro` (positions and velocities), or
trajectory file :ref:`trr` (positions, velocities, forces).

This chapter describes the setup of the topology file, the :ref:`top` file and
the database files: what the parameters stand for and how/where to
change them if needed. First, all file formats are explained. Section
:ref:`fffiles` describes the organization of the files in each force
field.

**Note:** if you construct your own topologies, we encourage you to
upload them to our topology archive at our `webpage`_! Just imagine how thankful
you’d have been if your topology had been available there before you
started. The same goes for new force fields or modified versions of the
standard force fields - contribute them to the force field archive!

.. _homepage: `webpage`_

.. toctree::
   :maxdepth: 2

   topologies/particle-type
   topologies/parameter-files
   topologies/molecule-definition
   topologies/constraint-algorithm-section
   topologies/pdb2gmx-input-files
   topologies/topology-file-formats
   topologies/force-field-organization


Averages and fluctuations
=========================

Formulae for averaging
----------------------

**Note:** this section was taken from ref \ :ref:`179 <refGunsteren94a>`.

When analyzing a MD trajectory averages :math:`\left<x\right>` and
fluctuations

.. math::  \left<(\Delta x)^2\right>^{{\frac{1}{2}}} ~=~ \left<[x-\left<x\right>]^2\right>^{{\frac{1}{2}}}
           :label: eqnvar0

of a quantity :math:`x` are to be computed. The variance
:math:`\sigma_x` of a series of N\ :math:`_x` values, {:math:`x_i`}, can
be computed from

.. math:: \sigma_x~=~ \sum_{i=1}^{N_x} x_i^2 ~-~  \frac{1}{N_x}\left(\sum_{i=1}^{N_x}x_i\right)^2
          :label: eqnvar1

Unfortunately this formula is numerically not very accurate, especially
when :math:`\sigma_x^{{\frac{1}{2}}}` is small compared to the values of
:math:`x_i`. The following (equivalent) expression is numerically more
accurate

.. math:: \sigma_x ~=~ \sum_{i=1}^{N_x} [x_i  - \left<x\right>]^2
          :label: eqnvar1equivalent

with

.. math:: \left<x\right> ~=~ \frac{1}{N_x} \sum_{i=1}^{N_x} x_i
          :label: eqnvar2

Using :eq:`eqns. %s <eqnvar1>` and
:eq:`%s <eqnvar2>` one has to go through the series of
:math:`x_i` values twice, once to determine :math:`\left<x\right>` and
again to compute :math:`\sigma_x`, whereas
:eq:`eqn. %s <eqnvar0>` requires only one sequential scan of
the series {:math:`x_i`}. However, one may cast
:eq:`eqn. %s <eqnvar1>` in another form, containing partial
sums, which allows for a sequential update algorithm. Define the partial
sum

.. math:: X_{n,m} ~=~ \sum_{i=n}^{m} x_i
          :label: eqnpartialsum

and the partial variance

.. math::  \sigma_{n,m} ~=~ \sum_{i=n}^{m}  \left[x_i - \frac{X_{n,m}}{m-n+1}\right]^2  
           :label: eqnsigma

It can be shown that

.. math::  X_{n,m+k} ~=~  X_{n,m} + X_{m+1,m+k}         
           :label: eqnXpartial

and

.. math:: \begin{aligned}
          \sigma_{n,m+k} &=& \sigma_{n,m} + \sigma_{m+1,m+k} + \left[~\frac {X_{n,m}}{m-n+1} - \frac{X_{n,m+k}}{m+k-n+1}~\right]^2~* \nonumber\\
          && ~\frac{(m-n+1)(m+k-n+1)}{k}
          \end{aligned}
          :label: eqnvarpartial

For :math:`n=1` one finds

.. math:: \sigma_{1,m+k} ~=~ \sigma_{1,m} + \sigma_{m+1,m+k}~+~
          \left[~\frac{X_{1,m}}{m} - \frac{X_{1,m+k}}{m+k}~\right]^2~ \frac{m(m+k)}{k}
          :label: eqnsig1

and for :math:`n=1` and :math:`k=1`
:eq:`eqn. %s <eqnvarpartial>` becomes

.. math:: \begin{aligned}
          \sigma_{1,m+1}  &=& \sigma_{1,m} + 
          \left[\frac{X_{1,m}}{m} - \frac{X_{1,m+1}}{m+1}\right]^2 m(m+1)\\
          &=& \sigma_{1,m} + 
          \frac {[~X_{1,m} - m x_{m+1}~]^2}{m(m+1)}
          \end{aligned}
          :label: eqnsimplevar0

where we have used the relation

.. math:: X_{1,m+1} ~=~  X_{1,m} + x_{m+1}                       
          :label: eqnsimplevar1

Using formulae :eq:`eqn. %s <eqnsimplevar0>` and
:eq:`eqn. %s <eqnsimplevar1>` the average

.. math:: \left<x\right> ~=~ \frac{X_{1,N_x}}{N_x}
          :label: eqnfinalaverage

and the fluctuation

.. math:: \left<(\Delta x)^2\right>^{{\frac{1}{2}}} = \left[\frac {\sigma_{1,N_x}}{N_x}\right]^{{\frac{1}{2}}}
          :label: eqnfinalfluctuation

can be obtained by one sweep through the data.

Implementation
--------------

In |Gromacs| the instantaneous energies :math:`E(m)` are stored in the
:ref:`energy file <edr>`, along with the values of :math:`\sigma_{1,m}` and
:math:`X_{1,m}`. Although the steps are counted from 0, for the energy
and fluctuations steps are counted from 1. This means that the equations
presented here are the ones that are implemented. We give somewhat
lengthy derivations in this section to simplify checking of code and
equations later on.

Part of a Simulation
~~~~~~~~~~~~~~~~~~~~

It is not uncommon to perform a simulation where the first part, *e.g.*
100 ps, is taken as equilibration. However, the averages and
fluctuations as printed in the :ref:`log file <log>` are computed over the whole
simulation. The equilibration time, which is now part of the simulation,
may in such a case invalidate the averages and fluctuations, because
these numbers are now dominated by the initial drift towards
equilibrium.

Using :eq:`eqns. %s <eqnXpartial>` and
:eq:`%s <eqnvarpartial>` the average and standard deviation
over part of the trajectory can be computed as:

.. math:: \begin{aligned}
          X_{m+1,m+k}     &=& X_{1,m+k} - X_{1,m}                 \\
          \sigma_{m+1,m+k} &=& \sigma_{1,m+k}-\sigma_{1,m} - \left[~\frac{X_{1,m}}{m} - \frac{X_{1,m+k}}{m+k}~\right]^{2}~ \frac{m(m+k)}{k}\end{aligned}
          :label: eqnaveragesimpart

or, more generally (with :math:`p \geq 1` and :math:`q \geq p`):

.. math:: \begin{aligned}
          X_{p,q}         &=&     X_{1,q} - X_{1,p-1}     \\
          \sigma_{p,q}    &=&     \sigma_{1,q}-\sigma_{1,p-1} - \left[~\frac{X_{1,p-1}}{p-1} - \frac{X_{1,q}}{q}~\right]^{2}~ \frac{(p-1)q}{q-p+1}\end{aligned}
          :label: eqnaveragesimpartgeneral

**Note** that implementation of this is not entirely trivial, since
energies are not stored every time step of the simulation. We therefore
have to construct :math:`X_{1,p-1}` and :math:`\sigma_{1,p-1}` from the
information at time :math:`p` using :eq:`eqns. %s <eqnsimplevar0>` and
:eq:`%s <eqnsimplevar1>`:

.. math:: \begin{aligned}
          X_{1,p-1}       &=&     X_{1,p} - x_p   \\
          \sigma_{1,p-1}  &=&     \sigma_{1,p} -  \frac {[~X_{1,p-1} - (p-1) x_{p}~]^2}{(p-1)p}\end{aligned}
          :label: eqnfinalaveragesimpartnote

Combining two simulations
~~~~~~~~~~~~~~~~~~~~~~~~~

Another frequently occurring problem is, that the fluctuations of two
simulations must be combined. Consider the following example: we have
two simulations (A) of :math:`n` and (B) of :math:`m` steps, in which
the second simulation is a continuation of the first. However, the
second simulation starts numbering from 1 instead of from :math:`n+1`.
For the partial sum this is no problem, we have to add :math:`X_{1,n}^A`
from run A:

.. math::  X_{1,n+m}^{AB} ~=~ X_{1,n}^A + X_{1,m}^B
           :label: eqnpscomb

When we want to compute the partial variance from the two components we
have to make a correction :math:`\Delta\sigma`:

.. math:: \sigma_{1,n+m}^{AB} ~=~ \sigma_{1,n}^A + \sigma_{1,m}^B +\Delta\sigma
          :label: eqnscombcorr

if we define :math:`x_i^{AB}` as the combined and renumbered set of
data points we can write:

.. math:: \sigma_{1,n+m}^{AB} ~=~ \sum_{i=1}^{n+m}  \left[x_i^{AB} - \frac{X_{1,n+m}^{AB}}{n+m}\right]^2
          :label: eqnpscombpoints

and thus

.. math:: \sum_{i=1}^{n+m}  \left[x_i^{AB} - \frac{X_{1,n+m}^{AB}}{n+m}\right]^2  ~=~
          \sum_{i=1}^{n}  \left[x_i^{A} - \frac{X_{1,n}^{A}}{n}\right]^2  +
          \sum_{i=1}^{m}  \left[x_i^{B} - \frac{X_{1,m}^{B}}{m}\right]^2  +\Delta\sigma
          :label: eqnpscombresult

or

.. math:: \begin{aligned}
          \sum_{i=1}^{n+m}  \left[(x_i^{AB})^2 - 2 x_i^{AB}\frac{X^{AB}_{1,n+m}}{n+m} + \left(\frac{X^{AB}_{1,n+m}}{n+m}\right)^2  \right] &-& \nonumber \\
          \sum_{i=1}^{n}  \left[(x_i^{A})^2 - 2 x_i^{A}\frac{X^A_{1,n}}{n} + \left(\frac{X^A_{1,n}}{n}\right)^2  \right] &-& \nonumber \\
          \sum_{i=1}^{m}  \left[(x_i^{B})^2 - 2 x_i^{B}\frac{X^B_{1,m}}{m} + \left(\frac{X^B_{1,m}}{m}\right)^2  \right] &=& \Delta\sigma\end{aligned}
          :label: eqnpscombresult2

all the :math:`x_i^2` terms drop out, and the terms independent of the
summation counter :math:`i` can be simplified:

.. math:: \begin{aligned}
          \frac{\left(X^{AB}_{1,n+m}\right)^2}{n+m} \,-\, 
          \frac{\left(X^A_{1,n}\right)^2}{n} \,-\, 
          \frac{\left(X^B_{1,m}\right)^2}{m} &-& \nonumber \\
          2\,\frac{X^{AB}_{1,n+m}}{n+m}\sum_{i=1}^{n+m}x_i^{AB} \,+\,
          2\,\frac{X^{A}_{1,n}}{n}\sum_{i=1}^{n}x_i^{A} \,+\,
          2\,\frac{X^{B}_{1,m}}{m}\sum_{i=1}^{m}x_i^{B} &=& \Delta\sigma\end{aligned}
          :label: eqnpscombsimp

we recognize the three partial sums on the second line and use
:eq:`eqn. %s <eqnpscomb>` to obtain:

.. math:: \Delta\sigma ~=~ \frac{\left(mX^A_{1,n} - nX^B_{1,m}\right)^2}{nm(n+m)}
          :label: eqnpscombused

if we check this by inserting :math:`m=1` we get back
:eq:`eqn. %s <eqnsimplevar0>`

Summing energy terms
~~~~~~~~~~~~~~~~~~~~

The :ref:`gmx energy <gmx energy>` program
can also sum energy terms into one, *e.g.* potential + kinetic = total.
For the partial averages this is again easy if we have :math:`S` energy
components :math:`s`:

.. math::  X_{m,n}^S ~=~ \sum_{i=m}^n \sum_{s=1}^S x_i^s ~=~ \sum_{s=1}^S \sum_{i=m}^n x_i^s ~=~ \sum_{s=1}^S X_{m,n}^s
           :label: eqnsumterms

For the fluctuations it is less trivial again, considering for example
that the fluctuation in potential and kinetic energy should cancel.
Nevertheless we can try the same approach as before by writing:

.. math:: \sigma_{m,n}^S ~=~ \sum_{s=1}^S \sigma_{m,n}^s + \Delta\sigma
          :label: eqnsigmatermsfluct

if we fill in :eq:`eqn. %s <eqnsigma>`:

.. math:: \sum_{i=m}^n \left[\left(\sum_{s=1}^S x_i^s\right) - \frac{X_{m,n}^S}{m-n+1}\right]^2 ~=~
          \sum_{s=1}^S \sum_{i=m}^n \left[\left(x_i^s\right) - \frac{X_{m,n}^s}{m-n+1}\right]^2 + \Delta\sigma
          :label: eqnsigmaterms

which we can expand to:

.. math:: \begin{aligned}
          &~&\sum_{i=m}^n \left[\sum_{s=1}^S (x_i^s)^2 + \left(\frac{X_{m,n}^S}{m-n+1}\right)^2 -2\left(\frac{X_{m,n}^S}{m-n+1}\sum_{s=1}^S x_i^s + \sum_{s=1}^S \sum_{s'=s+1}^S x_i^s x_i^{s'} \right)\right]    \nonumber \\
          &-&\sum_{s=1}^S \sum_{i=m}^n \left[(x_i^s)^2 - 2\,\frac{X_{m,n}^s}{m-n+1}\,x_i^s + \left(\frac{X_{m,n}^s}{m-n+1}\right)^2\right] ~=~\Delta\sigma \end{aligned}
          :label: eqnsimtermsexpanded

the terms with :math:`(x_i^s)^2` cancel, so that we can simplify to:

.. math:: \begin{aligned}
          &~&\frac{\left(X_{m,n}^S\right)^2}{m-n+1} -2 \frac{X_{m,n}^S}{m-n+1}\sum_{i=m}^n\sum_{s=1}^S x_i^s -2\sum_{i=m}^n\sum_{s=1}^S \sum_{s'=s+1}^S x_i^s x_i^{s'}\, -        \nonumber \\
          &~&\sum_{s=1}^S \sum_{i=m}^n \left[- 2\,\frac{X_{m,n}^s}{m-n+1}\,x_i^s + \left(\frac{X_{m,n}^s}{m-n+1}\right)^2\right] ~=~\Delta\sigma \end{aligned}
          :label: eqnsigmatermssimplefied

or

.. math:: -\frac{\left(X_{m,n}^S\right)^2}{m-n+1}  -2\sum_{i=m}^n\sum_{s=1}^S \sum_{s'=s+1}^S x_i^s x_i^{s'}\, +  \sum_{s=1}^S \frac{\left(X_{m,n}^s\right)^2}{m-n+1}  ~=~\Delta\sigma
           :label: eqnsigmatermsalternative

If we now expand the first term using
:eq:`eqn. %s <eqnsumterms>` we obtain:

.. math:: -\frac{\left(\sum_{s=1}^SX_{m,n}^s\right)^2}{m-n+1}  -2\sum_{i=m}^n\sum_{s=1}^S \sum_{s'=s+1}^S x_i^s x_i^{s'}\, +      \sum_{s=1}^S \frac{\left(X_{m,n}^s\right)^2}{m-n+1}  ~=~\Delta\sigma
          :label: eqnsigmatermsfirstexpand

which we can reformulate to:

.. math:: -2\left[\sum_{s=1}^S \sum_{s'=s+1}^S X_{m,n}^s X_{m,n}^{s'}\,+\sum_{i=m}^n\sum_{s=1}^S \sum_{s'=s+1}^S x_i^s x_i^{s'}\right] ~=~\Delta\sigma
          :label: eqnsigmatermsreformed

or

.. math:: -2\left[\sum_{s=1}^S X_{m,n}^s \sum_{s'=s+1}^S X_{m,n}^{s'}\,+\,\sum_{s=1}^S \sum_{i=m}^nx_i^s \sum_{s'=s+1}^S x_i^{s'}\right] ~=~\Delta\sigma
          :label: eqnsigmatermsreformedalternative

which gives

.. math:: -2\sum_{s=1}^S \left[X_{m,n}^s \sum_{s'=s+1}^S \sum_{i=m}^n x_i^{s'}\,+\,\sum_{i=m}^n x_i^s \sum_{s'=s+1}^S x_i^{s'}\right] ~=~\Delta\sigma
          :label: eqnsigmatermsfinal

Since we need all data points :math:`i` to evaluate this, in general
this is not possible. We can then make an estimate of
:math:`\sigma_{m,n}^S` using only the data points that are available
using the left hand side of :eq:`eqn. %s <eqnsigmaterms>`.
While the average can be computed using all time steps in the
simulation, the accuracy of the fluctuations is thus limited by the
frequency with which energies are saved. Since this can be easily done
with a program such as ``xmgr`` this is not
built-in in |Gromacs|.

.. raw:: latex

    \clearpage


Bibliography
============



.. raw:: html

   <div id="refs" class="references">

.. raw:: html

   <div id="ref-Bekker93a">

.. _refBekker93a:

:sup:`1` H. Bekker, H.J.C. Berendsen, E.J. Dijkstra, S. Achterop, R. van
Drunen, D. van der Spoel, A. Sijbers, and H. Keegstra *et al.*, "Gromacs: A parallel computer for molecular dynamics simulations";
pp. 252–256 in *Physics computing 92*. Edited by R.A. de Groot and J.
Nadrchal. World Scientific, Singapore, 1993.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Berendsen95a">

.. _refBerendsen95a:

:sup:`2` H.J.C. Berendsen, D. van der Spoel, and R. van Drunen,
"GROMACS: A message-passing parallel molecular dynamics implementation,"
*Comp. Phys. Comm.*, **91** 43–56 (1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Lindahl2001a">

.. _refLindahl2001a:

:sup:`3` E. Lindahl, B. Hess, and D. van der Spoel, "GROMACS 3.0: A
package for molecular simulation and trajectory analysis," *J. Mol.
Mod.*, **7** 306–317 (2001).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Spoel2005a">

.. _refSpoel2005a:

:sup:`4` D. van der Spoel, E. Lindahl, B. Hess, G. Groenhof, A.E. Mark,
and H.J.C. Berendsen, "GROMACS: Fast, Flexible and Free," *J. Comp.
Chem.*, **26** 1701–1718 (2005).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hess2008b">

.. _refHess2008b:

:sup:`5` B. Hess, C. Kutzner, D. van der Spoel, and E. Lindahl, "GROMACS
4: Algorithms for Highly Efficient, Load-Balanced, and Scalable
Molecular Simulation," *J. Chem. Theory Comput.*, **4** [3] 435–447
(2008).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Pronk2013">

.. _refPronk2013:

:sup:`6` S. Pronk, S. Páll, R. Schulz, P. Larsson, P. Bjelkmar, R.
Apostolov, M.R. Shirts, and J.C. Smith *et al.*, "GROMACS 4.5: A
high-throughput and highly parallel open source molecular simulation
toolkit," *Bioinformatics*, **29** [7] 845–854 (2013).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Pall2015">

.. _refPall2015:

:sup:`7` S. Páll, M.J. Abraham, C. Kutzner, B. Hess, and E. Lindahl,
"Tackling exascale software challenges in molecular dynamics simulations
with GROMACS"; pp. 3–27 in *Solving software challenges for exascale*.
Edited by S. Markidis and E. Laure. Springer International Publishing
Switzerland, London, 2015.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Abraham2015">

.. _refAbraham2015:

:sup:`8` M.J. Abraham, T. Murtola, R. Schulz, S. Páll, J.C. Smith, B.
Hess, and E. Lindahl, "GROMACS: High performance molecular simulations
through multi-level parallelism from laptops to supercomputers,"
*SoftwareX*, **1–2** 19–25 (2015).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Gunsteren90">

.. _refGunsteren90:

:sup:`9` W.F. van Gunsteren and H.J.C. Berendsen, "Computer simulation
of molecular dynamics: Methodology, applications, and perspectives in
chemistry," *Angew. Chem. Int. Ed. Engl.*, **29** 992–1023 (1990).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Fraaije93">

.. _refFraaije93:

:sup:`10` J.G.E.M. Fraaije, "Dynamic density functional theory for
microphase separation kinetics of block copolymer melts," *J. Chem.
Phys.*, **99** 9202–9212 (1993).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-McQuarrie76">

.. _refMcQuarrie76:

:sup:`11` D.A. McQuarrie, *Statistical mechanics*. Harper & Row, New
York, 1976.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Gunsteren77">

.. _refGunsteren77:

:sup:`12` W.F. van Gunsteren and H.J.C. Berendsen, "Algorithms for
macromolecular dynamics and constraint dynamics," *Mol. Phys.*, **34**
1311–1327 (1977).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Gunsteren82">

.. _refGunsteren82:

:sup:`13` W.F. van Gunsteren and M. Karplus, "Effect of constraints on
the dynamics of macromolecules," *Macromolecules*, **15** 1528–1544
(1982).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Darden93">

.. _refDarden93:

:sup:`14` T. Darden, D. York, and L. Pedersen, "Particle mesh Ewald: An
N\ :math:`\bullet`\ log(N) method for Ewald sums in large systems," *J.
Chem. Phys.*, **98** 10089–10092 (1993).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Essmann95">

.. _refEssmann95:

:sup:`15` U. Essmann, L. Perera, M.L. Berkowitz, T. Darden, H. Lee, and
L.G. Pedersen, "A smooth particle mesh ewald potential," *J. Chem.
Phys.*, **103** 8577–8592 (1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Geman84">

.. _refGeman84:

:sup:`16` S. Geman and D. Geman, "Stochastic relaxation, Gibbs
distributions and the Bayesian restoration of images," *IEEE Trans.
Patt. Anal. Mach. Int.*, **6** 721 (1984).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Nilges88">

.. _refNilges88:

:sup:`17` M. Nilges, G.M. Clore, and A.M. Gronenborn, "Determination of
three-dimensional structures of proteins from interproton distance data
by dynamical simulated annealing from a random array of atoms," *FEBS
Lett.*, **239** 129–136 (1988).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Schaik93">

.. _refSchaik93:

:sup:`18` R.C. van Schaik, H.J.C. Berendsen, A.E. Torda, and W.F. van
Gunsteren, "A structure refinement method based on molecular dynamics in
4 spatial dimensions," *J. Mol. Biol.*, **234** 751–762 (1993).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Zimmerman91">

.. _refZimmerman91:

:sup:`19` K. Zimmerman, "All purpose molecular mechanics simulator and
energy minimizer," *J. Comp. Chem.*, **12** 310–319 (1991).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Adams79">

.. _refAdams79:

:sup:`20` D.J. Adams, E.M. Adams, and G.J. Hills, "The computer
simulation of polar liquids," *Mol. Phys.*, **38** 387–400 (1979).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Bekker95">

.. _refBekker95:

:sup:`21` H. Bekker, E.J. Dijkstra, M.K.R. Renardus, and H.J.C.
Berendsen, "An efficient, box shape independent non-bonded force and
virial algorithm for molecular dynamics," *Mol. Sim.*, **14** 137–152
(1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hockney74">

.. _refHockney74:

:sup:`22` R.W. Hockney, S.P. Goel, and J. Eastwood, "Quiet High
Resolution Computer Models of a Plasma," *J. Comp. Phys.*, **14**
148–158 (1974).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Verlet67">

.. _refVerlet67:

:sup:`23` L. Verlet., "Computer experiments on classical fluids. I.
Thermodynamical properties of Lennard-Jones molecules," *Phys. Rev.*,
**159** 98–103 (1967).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Berendsen86b">

.. _refBerendsen86b:

:sup:`24` H.J.C. Berendsen and W.F. van Gunsteren, "Practical algorithms
for dynamics simulations"; in 1986.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Swope82">

.. _refSwope82:

:sup:`25` W.C. Swope, H.C. Andersen, P.H. Berens, and K.R. Wilson, "A
computer-simulation method for the calculation of equilibrium-constants
for the formation of physical clusters of molecules: Application to
small water clusters," *J. Chem. Phys.*, **76** 637–649 (1982).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Berendsen84">

.. _refBerendsen84:

:sup:`26` H.J.C. Berendsen, J.P.M. Postma, A. DiNola, and J.R. Haak,
"Molecular dynamics with coupling to an external bath," *J. Chem.
Phys.*, **81** 3684–3690 (1984).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Andersen80">

.. _refAndersen80:

:sup:`27` H.C. Andersen, "Molecular dynamics simulations at constant
pressure and/or temperature," *J. Chem. Phys.*, **72** 2384 (1980).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Nose84">

.. _refNose84:

:sup:`28` S. Nosé, "A molecular dynamics method for simulations in the
canonical ensemble," *Mol. Phys.*, **52** 255–268 (1984).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hoover85">

.. _refHoover85:

:sup:`29` W.G. Hoover, "Canonical dynamics: Equilibrium phase-space
distributions," *Phys. Rev. **A***, **31** 1695–1697 (1985).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Bussi2007a">

.. _refBussi2007a:

:sup:`30` G. Bussi, D. Donadio, and M. Parrinello, "Canonical sampling
through velocity rescaling," *J. Chem. Phys.*, **126** 014101 (2007).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Berendsen91">

.. _refBerendsen91:

:sup:`31` H.J.C. Berendsen, "Transport properties computed by linear
response through weak coupling to a bath"; pp. 139–155 in *Computer
simulations in material science*. Edited by M. Meyer and V. Pontikis.
Kluwer, 1991.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Basconi2013">

.. _refBasconi2013:

:sup:`32` J.E. Basconi and M.R. Shirts, "Effects of temperature control
algorithms on transport properties and kinetics in molecular dynamics
simulations," *J. Chem. Theory Comput.*, **9** [7] 2887–2899 (2013).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Cooke2008">

.. _refCooke2008:

:sup:`33` B. Cooke and S.J. Schmidler, "Preserving the Boltzmann
ensemble in replica-exchange molecular dynamics," *J. Chem. Phys.*,
**129** 164112 (2008).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Martyna1992">

.. _refMartyna1992:

:sup:`34` G.J. Martyna, M.L. Klein, and M.E. Tuckerman, "Nosé-Hoover
chains: The canonical ensemble via continuous dynamics," *J. Chem.
Phys.*, **97** 2635–2643 (1992).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Martyna1996">

.. _refMartyna1996:

:sup:`35` G.J. Martyna, M.E. Tuckerman, D.J. Tobias, and M.L. Klein,
"Explicit reversible integrators for extended systems dynamics," *Mol.
Phys.*, **87** 1117–1157 (1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Holian95">

.. _refHolian95:

:sup:`36` B.L. Holian, A.F. Voter, and R. Ravelo, "Thermostatted
molecular dynamics: How to avoid the Toda demon hidden in Nosé-Hoover
dynamics," *Phys. Rev. E*, **52** [3] 2338–2347 (1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Eastwood2010">

.. _refEastwood2010:

:sup:`37` M.P. Eastwood, K.A. Stafford, R.A. Lippert, M.Ø. Jensen, P.
Maragakis, C. Predescu, R.O. Dror, and D.E. Shaw, "Equipartition and the
calculation of temperature in biomolecular simulations," *J. Chem.
Theory Comput.*, **ASAP** DOI: 10.1021/ct9002916 (2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Parrinello81">

.. _refParrinello81:

:sup:`38` M. Parrinello and A. Rahman, "Polymorphic transitions in
single crystals: A new molecular dynamics method," *J. Appl. Phys.*,
**52** 7182–7190 (1981).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Nose83">

.. _refNose83:

:sup:`39` S. Nosé and M.L. Klein, "Constant pressure molecular dynamics
for molecular systems," *Mol. Phys.*, **50** 1055–1076 (1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Liu2015">

.. _refLiu2015:

:sup:`40` G. Liu, "Dynamical equations for the period vectors in a
periodic system under constant external stress," *Can. J. Phys.*, **93**
974–978 (2015).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Tuckerman2006">

.. _refTuckerman2006:

:sup:`41` M.E. Tuckerman, J. Alejandre, R. López-Rendón, A.L. Jochim,
and G.J. Martyna, "A Liouville-operator derived measure-preserving
integrator for molecular dynamics simulations in the isothermal-isobaric
ensemble," *J. Phys. A.*, **59** 5629–5651 (2006).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Yu2010">

.. _refYu2010:

:sup:`42` T.-Q. Yu, J. Alejandre, R. Lopez-Rendon, G.J. Martyna, and
M.E. Tuckerman, "Measure-preserving integrators for molecular dynamics
in the isothermal-isobaric ensemble derived from the liouville
operator," *Chem. Phys.*, **370** 294–305 (2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Dick58">

.. _refDick58:

:sup:`43` B.G. Dick and A.W. Overhauser, "Theory of the dielectric
constants of alkali halide crystals," *Phys. Rev.*, **112** 90–103
(1958).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Jordan95">

.. _refJordan95:

:sup:`44` P.C. Jordan, P.J. van Maaren, J. Mavri, D. van der Spoel, and
H.J.C. Berendsen, "Towards phase transferable potential functions:
Methodology and application to nitrogen," *J. Chem. Phys.*, **103**
2272–2285 (1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Maaren2001a">

.. _refMaaren2001a:

:sup:`45` P.J. van Maaren and D. van der Spoel, "Molecular dynamics
simulations of a water with a novel shell-model potential," *J. Phys.
Chem. B.*, **105** 2618–2626 (2001).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Ryckaert77">

.. _refRyckaert77:

:sup:`46` J.P. Ryckaert, G. Ciccotti, and H.J.C. Berendsen, "Numerical
integration of the cartesian equations of motion of a system with
constraints; molecular dynamics of n-alkanes," *J. Comp. Phys.*, **23**
327–341 (1977).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Miyamoto92">

.. _refMiyamoto92:

:sup:`47` S. Miyamoto and P.A. Kollman, "SETTLE: An analytical version
of the SHAKE and RATTLE algorithms for rigid water models," *J. Comp.
Chem.*, **13** 952–962 (1992).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Andersen1983a">

.. _refAndersen1983a:

:sup:`48` H.C. Andersen, "RATTLE: A ‘Velocity’ version of the SHAKE
algorithm for molecular dynamics calculations," *J. Comp. Phys.*, **52**
24–34 (1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hess97">

.. _refHess97:

:sup:`49` B. Hess, H. Bekker, H.J.C. Berendsen, and J.G.E.M. Fraaije,
"LINCS: A linear constraint solver for molecular simulations," *J. Comp.
Chem.*, **18** 1463–1472 (1997).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hess2008a">

.. _refHess2008a:

:sup:`50` B. Hess, "P-LINCS: A parallel linear constraint solver for
molecular simulation," *J. Chem. Theory Comput.*, **4** 116–122 (2007).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Goga2012">

.. _refGoga2012:

:sup:`51` N. Goga, A.J. Rzepiela, A.H. de Vries, S.J. Marrink, and
H.J.C. Berendsen, "Efficient algorithms for Langevin and DPD dynamics,"
*J. Chem. Theory Comput.*, **8** 3637–3649 (2012).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Byrd95a">

.. _refByrd95a:

:sup:`52` R.H. Byrd, P. Lu, and J. Nocedal, "A limited memory algorithm
for bound constrained optimization," *SIAM J. Scientif. Statistic.
Comput.*, **16** 1190–1208 (1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Zhu97a">

.. _refZhu97a:

:sup:`53` C. Zhu, R.H. Byrd, and J. Nocedal, "L-BFGS-B: Algorithm 778:
L-BFGS-B, FORTRAN routines for large scale bound constrained
optimization," *ACM Trans. Math. Softw.*, **23** 550–560 (1997).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Levitt83">

.. _refLevitt83:

:sup:`54` M. Levitt, C. Sander, and P.S. Stern, "The normal modes of a
protein: Native bovine pancreatic trypsin inhibitor," *Int. J. Quant.
Chem: Quant. Biol. Symp.*, **10** 181–199 (1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Go83">

.. _refGo83:

:sup:`55` N. G\ :math:`\bar{\rm o}`, T. Noguti, and T. Nishikawa,
"Dynamics of a small globular protein in terms of low-frequency
vibrational modes," *Proc. Natl. Acad. Sci. USA*, **80** 3696–3700
(1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-BBrooks83b">

.. _refBBrooks83b:

:sup:`56` B. Brooks and M. Karplus, "Harmonic dynamics of proteins:
Normal modes and fluctuations in bovine pancreatic trypsin inhibitor,"
*Proc. Natl. Acad. Sci. USA*, **80** 6571–6575 (1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hayward95b">

.. _refHayward95b:

:sup:`57` S. Hayward and N. G\ :math:`\bar{\rm o}`, "Collective variable
description of native protein dynamics," *Annu. Rev. Phys. Chem.*,
**46** 223–250 (1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Bennett1976">

.. _refBennett1976:

:sup:`58` C.H. Bennett, "Efficient Estimation of Free Energy Differences
from Monte Carlo Data," *J. Comp. Phys.*, **22** 245–268 (1976).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Shirts2008">

.. _refShirts2008:

:sup:`59` M.R. Shirts and J.D. Chodera, "Statistically optimal analysis
of multiple equilibrium simulations," *J. Chem. Phys.*, **129** 124105
(2008).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hukushima96a">

.. _refHukushima96a:

:sup:`60` K. Hukushima and K. Nemoto, "Exchange Monte Carlo Method and
Application to Spin Glass Simulations," *J. Phys. Soc. Jpn.*, **65**
1604–1608 (1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Sugita99">

.. _refSugita99:

:sup:`61` Y. Sugita and Y. Okamoto, "Replica-exchange molecular dynamics
method for protein folding," *Chem. Phys. Lett.*, **314** 141–151
(1999).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Seibert2005a">

.. _refSeibert2005a:

:sup:`62` M. Seibert, A. Patriksson, B. Hess, and D. van der Spoel,
"Reproducible polypeptide folding and structure prediction using
molecular dynamics simulations," *J. Mol. Biol.*, **354** 173–183
(2005).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Okabe2001a">

.. _refOkabe2001a:

:sup:`63` T. Okabe, M. Kawata, Y. Okamoto, and M. Mikami,
"Replica-exchange Monte Carlo method for the isobaric-isothermal
ensemble," *Chem. Phys. Lett.*, **335** 435–439 (2001).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Chodera2011">

.. _refChodera2011:

:sup:`64` J.D. Chodera and M.R. Shirts, "Replica exchange and expanded
ensemble simulations as gibbs sampling: Simple improvements for enhanced
mixing," *J. Chem. Phys.*, **135** 194110 (2011).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Degroot96a">

.. _refDegroot96a:

:sup:`65` B.L. de Groot, A. Amadei, D.M.F. van Aalten, and H.J.C.
Berendsen, "Towards an exhaustive sampling of the configurational spaces
of the two forms of the peptide hormone guanylin," *J. Biomol. Str.
Dyn.*, **13** [5] 741–751 (1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Degroot96b">

.. _refDegroot96b:

:sup:`66` B.L. de Groot, A. Amadei, R.M. Scheek, N.A.J. van Nuland, and
H.J.C. Berendsen, "An extended sampling of the configurational space of
HPr from *E. coli*," *PROTEINS: Struct. Funct. Gen.*, **26** 314–322
(1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Lange2006a">

.. _refLange2006a:

:sup:`67` O.E. Lange, L.V. Schafer, and H. Grubmuller, "Flooding in
GROMACS: Accelerated barrier crossings in molecular dynamics," *J. Comp.
Chem.*, **27** 1693–1702 (2006).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Lyubartsev1992">

.. _refLyubartsev1992:

:sup:`68` A.P. Lyubartsev, A.A. Martsinovski, S.V. Shevkunov, and P.N.
Vorontsov-Velyaminov, "New approach to Monte Carlo calculation of the
free energy: Method of expanded ensembles," *J. Chem. Phys.*, **96**
1776–1783 (1992).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Liem1991">

.. _refLiem1991:

:sup:`69` S.Y. Liem, D. Brown, and J.H.R. Clarke, "Molecular dynamics
simulations on distributed memory machines," *Comput. Phys. Commun.*,
**67** [2] 261–267 (1991).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Shaw2006">

.. _refShaw2006:

:sup:`70` K.J. Bowers, R.O. Dror, and D.E. Shaw, "The midpoint method
for parallelization of particle simulations," *J. Chem. Phys.*, **124**
[18] 184109–184109 (2006).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Spoel2006a">

.. _refSpoel2006a:

:sup:`72` D. van der Spoel and P.J. van Maaren, "The origin of layer
structure artifacts in simulations of liquid water," *J. Chem. Theory
Comput.*, **2** 1–11 (2006).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Ohmine1988">

.. _refOhmine1988:

:sup:`73` I. Ohmine, H. Tanaka, and P.G. Wolynes, "Large local energy
fluctuations in water. II. Cooperative motions and fluctuations," *J.
Chem. Phys.*, **89** 5852–5860 (1988).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Kitchen1990">

.. _refKitchen1990:

:sup:`74` D.B. Kitchen, F. Hirata, J.D. Westbrook, R. Levy, D. Kofke,
and M. Yarmush, "Conserving energy during molecular dynamics simulations
of water, proteins, and proteins in water," *J. Comp. Chem.*, **11**
1169–1180 (1990).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Guenot1993">

.. _refGuenot1993:

:sup:`75` J. Guenot and P.A. Kollman, "Conformational and energetic
effects of truncating nonbonded interactions in an aqueous protein
dynamics simulation," *J. Comp. Chem.*, **14** 295–311 (1993).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Steinbach1994">

.. _refSteinbach1994:

:sup:`76` P.J. Steinbach and B.R. Brooks, "New spherical-cutoff methods
for long-range forces in macromolecular simulation," *J. Comp. Chem.*,
**15** 667–683 (1994).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-gromos96">

.. _refgromos96:

:sup:`77` W.F. van Gunsteren, S.R. Billeter, A.A. Eising, P.H.
Hünenberger, P. Krüger, A.E. Mark, W.R.P. Scott, and I.G. Tironi,
*Biomolecular simulation: The GROMOS96 manual and user guide*.
Hochschulverlag AG an der ETH Zürich, Zürich, Switzerland, 1996.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-biomos">

.. _refbiomos:

:sup:`78` W.F. van Gunsteren and H.J.C. Berendsen, *Gromos-87 manual*.
Biomos BV, Nijenborgh 4, 9747 AG Groningen, The Netherlands, 1987.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Morse29">

.. _refMorse29:

:sup:`79` P.M. Morse, "Diatomic molecules according to the wave
mechanics. II. vibrational levels." *Phys. Rev.*, **34** 57–64 (1929).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Berendsen81">

.. _refBerendsen81:

:sup:`80` H.J.C. Berendsen, J.P.M. Postma, W.F. van Gunsteren, and J.
Hermans, "Interaction models for water in relation to protein
hydration"; pp. 331–342 in *Intermolecular forces*. Edited by B.
Pullman. D. Reidel Publishing Company, Dordrecht, 1981.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Ferguson95">

.. _refFerguson95:

:sup:`81` D.M. Ferguson, "Parametrization and evaluation of a flexible
water model," *J. Comp. Chem.*, **16** 501–511 (1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Warner72">

.. _refWarner72:

:sup:`82` H.R. Warner Jr., "Kinetic theory and rheology of dilute
suspensions of finitely extendible dumbbells," *Ind. Eng. Chem.
Fundam.*, **11** [3] 379–387 (1972).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-MonicaGoga2013">

.. _refMonicaGoga2013:

:sup:`83` M. Bulacu, N. Goga, W. Zhao, G. Rossi, L. Monticelli, X.
Periole, D. Tieleman, and S. Marrink, "Improved angle potentials for
coarse-grained molecular dynamics simulations," *J. Chem. Phys.*,
**123** [11] (2005).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-BBrooks83">

.. _refBBrooks83:

:sup:`84` B.R. Brooks, R.E. Bruccoleri, B.D. Olafson, D.J. States, S.
Swaminathan, and M. Karplus, "CHARMM: A program for macromolecular
energy, minimization, and dynamics calculation," *J. Comp. Chem.*, **4**
187–217 (1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Lawrence2003b">

.. _refLawrence2003b:

:sup:`85` C.P. Lawrence and J.L. Skinner, "Flexible TIP4P model for
molecular dynamics simulation of liquid water," *Chem. Phys. Lett.*,
**372** 842–847 (2003).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Jorgensen1996">

.. _refJorgensen1996:

:sup:`86` W.L. Jorgensen, D.S. Maxwell, and J. Tirado-Rives,
"Development and testing of the oPLS all-atom force field on
conformational energetics and properties of organic liquids," *J. Am.
Chem. Soc.*, **118** 11225–11236 (1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Robertson2015a">

.. _refRobertson2015a:

:sup:`87` M.J. Robertson, J. Tirado-Rives, and W.L. Jorgensen, "Improved
peptide and protein torsional energetics with the oPLS-aA force field,"
*J. Chem. Theory Comput.*, **11** 3499–3509 (2015).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-BulacuGiessen2005">

.. _refBulacuGiessen2005:

:sup:`88` M. Bulacu and E. van der Giessen, "Effect of bending and
torsion rigidity on self-diffusion in polymer melts: A
molecular-dynamics study," *JCTC*, **9** [8] 3282–3292 (2013).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-ScottScheragator1966">

.. _refScottScheragator1966:

:sup:`89` R.A. Scott and H. Scheraga, "Conformational analysis of
macromolecules," *J. Chem. Phys.*, **44** 3054–3069 (1966).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-PaulingBond">

.. _refPaulingBond:

:sup:`90` L. Pauling, *The nature of chemical bond*. Cornell University
Press, Ithaca; New York, 1960.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Torda89">

.. _refTorda89:

:sup:`91` A.E. Torda, R.M. Scheek, and W.F. van Gunsteren,
"Time-dependent distance restraints in molecular dynamics simulations,"
*Chem. Phys. Lett.*, **157** 289–294 (1989).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hess2003">

.. _refHess2003:

:sup:`92` B. Hess and R.M. Scheek, "Orientation restraints in molecular
dynamics simulations using time and ensemble averaging," *J. Magn.
Reson.*, **164** 19–27 (2003).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Lopes2013a">

.. _refLopes2013a:

:sup:`93` P.E.M. Lopes, J. Huang, J. Shim, Y. Luo, H. Li, B. Roux, and
J. MacKerell Alexander D., "Polarizable force field for peptides and
proteins based on the classical drude oscillator," *J. Chem. Theory
Comput*, **9** 5430–5449 (2013).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-HYu2010">

.. _refHYu2010:

:sup:`94` H. Yu, T.W. Whitfield, E. Harder, G. Lamoureux, I. Vorobyov,
V.M. Anisimov, A.D. MacKerell, Jr., and B. Roux, "Simulating Monovalent
and Divalent Ions in Aqueous Solution Using a Drude Polarizable Force
Field," *J. Chem. Theory Comput.*, **6** 774–786 (2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Thole81">

.. _refThole81:

:sup:`95` B.T. Thole, "Molecular polarizabilities with a modified dipole
interaction," *Chem. Phys.*, **59** 341–345 (1981).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Lamoureux2003a">

.. _refLamoureux2003a:

:sup:`96` G. Lamoureux and B. Roux, "Modeling induced polarization with
classical drude oscillators: Theory and molecular dynamics simulation
algorithm," *J. Chem. Phys.*, **119** 3025–3039 (2003).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Lamoureux2003b">

.. _refLamoureux2003b:

:sup:`97` G. Lamoureux, A.D. MacKerell, and B. Roux, "A simple
polarizable model of water based on classical drude oscillators," *J.
Chem. Phys.*, **119** 5185–5197 (2003).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Noskov2005a">

.. _refNoskov2005a:

:sup:`98` S.Y. Noskov, G. Lamoureux, and B. Roux, "Molecular dynamics
study of hydration in ethanol-water mixtures using a polarizable force
field," *J. Phys. Chem. B.*, **109** 6705–6713 (2005).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Gunsteren98a">

.. _refGunsteren98a:

:sup:`99` W.F. van Gunsteren and A.E. Mark, "Validation of molecular
dynamics simulations," *J. Chem. Phys.*, **108** 6109–6116 (1998).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Beutler94">

.. _refBeutler94:

:sup:`100` T.C. Beutler, A.E. Mark, R.C. van Schaik, P.R. Greber, and
W.F. van Gunsteren, "Avoiding singularities and numerical instabilities
in free energy calculations based on molecular simulations," *Chem.
Phys. Lett.*, **222** 529–539 (1994).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Jorgensen88">

.. _refJorgensen88:

:sup:`103` W.L. Jorgensen and J. Tirado-Rives, "The OPLS potential
functions for proteins. energy minimizations for crystals of cyclic
peptides and crambin," *J. Am. Chem. Soc.*, **110** 1657–1666 (1988).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Berendsen84b">

.. _refBerendsen84b:

:sup:`104` H.J.C. Berendsen and W.F. van Gunsteren, "Molecular dynamics
simulations: Techniques and approaches"; pp. 475–500 in *Molecular
liquids-dynamics and interactions*. Edited by A.J.B. et al. Reidel,
Dordrecht, The Netherlands, 1984.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Ewald21">

.. _refEwald21:

:sup:`105` P.P. Ewald, "Die Berechnung optischer und elektrostatischer
Gitterpotentiale," *Ann. Phys.*, **64** 253–287 (1921).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hockney81">

.. _refHockney81:

:sup:`106` R.W. Hockney and J.W. Eastwood, *Computer simulation using
particles*. McGraw-Hill, New York, 1981.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Ballenegger2012">

.. _refBallenegger2012:

:sup:`107` V. Ballenegger, J.J. Cerdà, and C. Holm, "How to convert SPME
to P3M: Influence functions and error estimates," *J. Chem. Theory
Comput.*, **8** [3] 936–947 (2012).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Allen87">

.. _refAllen87:

:sup:`108` M.P. Allen and D.J. Tildesley, *Computer simulations of
liquids*. Oxford Science Publications, Oxford, 1987.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Wennberg13">

.. _refWennberg13:

:sup:`109` C.L. Wennberg, T. Murtola, B. Hess, and E. Lindahl,
"Lennard-Jones Lattice Summation in Bilayer Simulations Has Critical
Effects on Surface Tension and Lipid Properties," *J. Chem. Theory
Comput.*, **9** 3527–3537 (2013).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Oostenbrink2004">

.. _refOostenbrink2004:

:sup:`110` C. Oostenbrink, A. Villa, A.E. Mark, and W.F. Van Gunsteren,
"A biomolecular force field based on the free enthalpy of hydration and
solvation: The GROMOS force-field parameter sets 53A5 and 53A6,"
*Journal of Computational Chemistry*, **25** [13] 1656–1676 (2004).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Cornell1995">

.. _refCornell1995:

:sup:`111` W.D. Cornell, P. Cieplak, C.I. Bayly, I.R. Gould, K.R. Merz
Jr., D.M. Ferguson, D.C. Spellmeyer, and T. Fox *et al.*, "A Second
Generation Force Field for the Simulation of Proteins, Nucleic Acids,
and Organic Molecules," *J. Am. Chem. Soc.*, **117** [19] 5179–5197
(1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Kollman1996">

.. _refKollman1996:

:sup:`112` P.A. Kollman, "Advances and Continuing Challenges in
Achieving Realistic and Predictive Simulations of the Properties of
Organic and Biological Molecules," *Acc. Chem. Res.*, **29** [10]
461–469 (1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Wang2000">

.. _refWang2000:

:sup:`113` J. Wang, P. Cieplak, and P.A. Kollman, "How Well Does a
Restrained Electrostatic Potential (RESP) Model Perform in Calculating
Conformational Energies of Organic and Biological Molecules?" *J. Comp.
Chem.*, **21** [12] 1049–1074 (2000).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hornak2006">

.. _refHornak2006:

:sup:`114` V. Hornak, R. Abel, A. Okur, B. Strockbine, A. Roitberg, and
C. Simmerling, "Comparison of Multiple Amber Force Fields and
Development of Improved Protein Backbone Parameters," *PROTEINS: Struct.
Funct. Gen.*, **65** 712–725 (2006).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Lindorff2010">

.. _refLindorff2010:

:sup:`115` K. Lindorff-Larsen, S. Piana, K. Palmo, P. Maragakis, J.L.
Klepeis, R.O. Dorr, and D.E. Shaw, "Improved side-chain torsion
potentials for the AMBER ff99SB protein force field," *PROTEINS: Struct.
Funct. Gen.*, **78** 1950–1958 (2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Duan2003">

.. _refDuan2003:

:sup:`116` Y. Duan, C. Wu, S. Chowdhury, M.C. Lee, G. Xiong, W. Zhang,
R. Yang, and P. Cieplak *et al.*, "A Point-Charge Force Field for
Molecular Mechanics Simulations of Proteins Based on Condensed-Phase
Quantum Mechanical Calculations," *J. Comp. Chem.*, **24** [16]
1999–2012 (2003).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Garcia2002">

.. _refGarcia2002:

:sup:`117` A.E. García and K.Y. Sanbonmatsu, "\ :math:`\alpha`-Helical
stabilization by side chain shielding of backbone hydrogen bonds,"
*Proc. Natl. Acad. Sci. USA*, **99** [5] 2782–2787 (2002).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-mackerell04">

.. _refmackerell04:

:sup:`118` J. MacKerell A. D., M. Feig, and C.L. Brooks III, "Extending
the treatment of backbone energetics in protein force fields:
Limitations of gas-phase quantum mechanics in reproducing protein
conformational distributions in molecular dynamics simulations," *J.
Comp. Chem.*, **25** [11] 1400–15 (2004).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-mackerell98">

.. _refmackerell98:

:sup:`119` A.D. MacKerell, D. Bashford, Bellott, R.L. Dunbrack, J.D.
Evanseck, M.J. Field, S. Fischer, and J. Gao *et al.*, "All-atom
empirical potential for molecular modeling and dynamics studies of
proteins," *J. Phys. Chem. B.*, **102** [18] 3586–3616 (1998).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-feller00">

.. _reffeller00:

:sup:`120` S.E. Feller and A.D. MacKerell, "An improved empirical
potential energy function for molecular simulations of phospholipids,"
*J. Phys. Chem. B.*, **104** [31] 7510–7515 (2000).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-foloppe00">

.. _reffoloppe00:

:sup:`121` N. Foloppe and A.D. MacKerell, "All-atom empirical force
field for nucleic acids: I. Parameter optimization based on small
molecule and condensed phase macromolecular target data," *J. Comp.
Chem.*, **21** [2] 86–104 (2000).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Mac2000">

.. _refMac2000:

:sup:`122` A.D. MacKerell and N.K. Banavali, "All-atom empirical force
field for nucleic acids: II. application to molecular dynamics
simulations of DNA and RNA in solution," *J. Comp. Chem.*, **21** [2]
105–120 (2000).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Larsson10">

.. _refLarsson10:

:sup:`123` P. Larsson and E. Lindahl, "A High-Performance
Parallel-Generalized Born Implementation Enabled by Tabulated
Interaction Rescaling," *J. Comp. Chem.*, **31** [14] 2593–2600 (2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Bjelkmar10">

.. _refBjelkmar10:

:sup:`124` P. Bjelkmar, P. Larsson, M.A. Cuendet, B. Hess, and E.
Lindahl, "Implementation of the CHARMM force field in GROMACS: Analysis
of protein stability effects from correction maps, virtual interaction
sites, and water models," *J. Chem. Theory Comput.*, **6** 459–466
(2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-kohlmeyer2016">

.. _refkohlmeyer2016:

:sup:`125` A. Kohlmeyer and J. Vermaas, *TopoTools: Release 1.6 with
CHARMM export in topogromacs*, (2016).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-bereau12">

.. _refbereau12:

:sup:`126` T. Bereau, Z.-J. Wang, and M. Deserno, *Solvent-free
coarse-grained model for unbiased high-resolution protein-lipid
interactions*, (n.d.).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-wang_jpcb10">

.. _refwang_jpcb10:

:sup:`127` Z.-J. Wang and M. Deserno, "A systematically coarse-grained
solvent-free model for quantitative phospholipid bilayer simulations,"
*J. Phys. Chem. B.*, **114** [34] 11207–11220 (2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Jorgensen83">

.. _refJorgensen83:

:sup:`128` W.L. Jorgensen, J. Chandrasekhar, J.D. Madura, R.W. Impey,
and M.L. Klein, "Comparison of simple potential functions for simulating
liquid water," *J. Chem. Phys.*, **79** 926–935 (1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-iupac70">

.. _refiupac70:

:sup:`129` IUPAC-IUB Commission on Biochemical Nomenclature,
"Abbreviations and Symbols for the Description of the Conformation of
Polypeptide Chains. Tentative Rules (1969)," *Biochemistry*, **9**
3471–3478 (1970).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Mahoney2000a">

.. _refMahoney2000a:

:sup:`130` M.W. Mahoney and W.L. Jorgensen, "A five-site model for
liquid water and the reproduction of the density anomaly by rigid,
nonpolarizable potential functions," *J. Chem. Phys.*, **112** 8910–8922
(2000).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Ryckaert78">

.. _refRyckaert78:

:sup:`131` J.P. Ryckaert and A. Bellemans, "Molecular dynamics of liquid
alkanes," *Far. Disc. Chem. Soc.*, **66** 95–106 (1978).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Loof92">

.. _refLoof92:

:sup:`132` H. de Loof, L. Nilsson, and R. Rigler, "Molecular dynamics
simulations of galanin in aqueous and nonaqueous solution," *J. Am.
Chem. Soc.*, **114** 4028–4035 (1992).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Buuren93a">

.. _refBuuren93a:

:sup:`133` A.R. van Buuren and H.J.C. Berendsen, "Molecular Dynamics
simulation of the stability of a 22 residue alpha-helix in water and 30%
trifluoroethanol," *Biopolymers*, **33** 1159–1166 (1993).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-RMNeumann1980a">

.. _refRMNeumann1980a:

:sup:`134` R.M. Neumann, "Entropic approach to Brownian Movement," *Am.
J. Phys.*, **48** 354–357 (1980).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Jarzynski1997a">

.. _refJarzynski1997a:

:sup:`135` C. Jarzynski, "Nonequilibrium equality for free energy
differences," *Phys. Rev. Lett.*, **78** [14] 2690–2693 ().

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Engin2010a">

.. _refEngin2010a:

:sup:`136` M.S. O. Engin A. Villa and B. Hess, "Driving forces for
adsorption of amphiphilic peptides to air-water interface," *J. Phys.
Chem. B.*, (2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-lindahl2014accelerated">

.. _reflindahl2014accelerated:

:sup:`137` V. Lindahl, J. Lidmar, and B. Hess, "Accelerated weight
histogram method for exploring free energy landscapes," *The Journal of
chemical physics*, **141** [4] 044110 (2014).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-wang2001efficient">

.. _refwang2001efficient:

:sup:`138` F. Wang and D. Landau, "Efficient, multiple-range random walk
algorithm to calculate the density of states," *Physical review
letters*, **86** [10] 2050 (2001).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-huber1994local">

.. _refhuber1994local:

:sup:`139` T. Huber, A.E. Torda, and W.F. van Gunsteren, "Local
elevation: A method for improving the searching properties of molecular
dynamics simulation," *Journal of computer-aided molecular design*,
**8** [6] 695–708 (1994).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-laio2002escaping">

.. _reflaio2002escaping:

:sup:`140` A. Laio and M. Parrinello, "Escaping free-energy minima,"
*Proceedings of the National Academy of Sciences*, **99** [20]
12562–12566 (2002).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-belardinelli2007fast">

.. _refbelardinelli2007fast:

:sup:`141` R. Belardinelli and V. Pereyra, "Fast algorithm to calculate
density of states," *Physical Review E*, **75** [4] 046701 (2007).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-barducci2008well">

.. _refbarducci2008well:

:sup:`142` A. Barducci, G. Bussi, and M. Parrinello, "Well-tempered
metadynamics: A smoothly converging and tunable free-energy method,"
*Physical review letters*, **100** [2] 020603 (2008).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-lindahl2017sequence">

.. _reflindahl2017sequence:

:sup:`143` V. Lindahl, A. Villa, and B. Hess, "Sequence dependency of
canonical base pair opening in the dNA double helix," *PLoS
computational biology*, **13** [4] e1005463 (2017).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-sivak2012thermodynamic">

.. _refsivak2012thermodynamic:

:sup:`144` D.A. Sivak and G.E. Crooks, "Thermodynamic metrics and
optimal paths," *Physical review letters*, **108** [19] 190602 (2012).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Kutzner2011">

.. _refKutzner2011:

:sup:`145` C. Kutzner, J. Czub, and H. Grubmüller, "Keep it flexible:
Driving macromolecular rotary motions in atomistic simulations with
GROMACS," *J. Chem. Theory Comput.*, **7** 1381–1393 (2011).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Caleman2008a">

.. _refCaleman2008a:

:sup:`146` C. Caleman and D. van der Spoel, "Picosecond Melting of Ice
by an Infrared Laser Pulse - A simulation study," *Angew. Chem., Int.
Ed. Engl.*, **47** 1417–1420 (2008).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Kutzner2011b">

.. _refKutzner2011b:

:sup:`147` C. Kutzner, H. Grubmüller, B.L. de Groot, and U. Zachariae,
"Computational electrophysiology: The molecular dynamics of ion channel
permeation and selectivity in atomistic detail," *Biophys. J.*, **101**
809–817 (2011).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-feenstra99">

.. _reffeenstra99:

:sup:`148` K.A. Feenstra, B. Hess, and H.J.C. Berendsen, "Improving
efficiency of large time-scale molecular dynamics simulations of
hydrogen-rich systems," *J. Comp. Chem.*, **20** 786–798 (1999).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hess2002a">

.. _refHess2002a:

:sup:`149` B. Hess, "Determining the shear viscosity of model liquids
from molecular dynamics," *J. Chem. Phys.*, **116** 209–217 (2002).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-mopac">

.. _refmopac:

:sup:`150` M.J.S. Dewar, "Development and status of MINDO/3 and MNDO,"
*J. Mol. Struct.*, **100** 41 (1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-gamess-uk">

.. _refgamess-uk:

:sup:`151` M.F. Guest, R.J. Harrison, J.H. van Lenthe, and L.C.H. van
Corler, "Computational chemistry on the FPS-X64 scientific computers -
Experience on single- and multi-processor systems," *Theor. Chim. Act.*,
**71** 117 (1987).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-g03">

.. _refg03:

:sup:`152` M.J. Frisch, G.W. Trucks, H.B. Schlegel, G.E. Scuseria, M.A.
Robb, J.R. Cheeseman, J.A. Montgomery Jr., and T. Vreven *et al.*,
*Gaussian 03, Revision C.02*, (n.d.).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Car85a">

.. _refCar85a:

:sup:`153` R. Car and M. Parrinello, "Unified approach for molecular
dynamics and density-functional theory," *Phys. Rev. Lett.*, **55**
2471–2474 (1985).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Field90a">

.. _refField90a:

:sup:`154` M. Field, P.A. Bash, and M. Karplus, "A combined quantum
mechanical and molecular mechanical potential for molecular dynamics
simulation," *J. Comp. Chem.*, **11** 700 (1990).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Maseras96a">

.. _refMaseras96a:

:sup:`155` F. Maseras and K. Morokuma, "IMOMM: A New Ab Initio +
Molecular Mechanics Geometry Optimization Scheme of Equilibrium
Structures and Transition States," *J. Comp. Chem.*, **16** 1170–1179
(1995).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Svensson96a">

.. _refSvensson96a:

:sup:`156` M. Svensson, S. Humbel, R.D.J. Froes, T. Matsubara, S.
Sieber, and K. Morokuma, "ONIOM a multilayered integrated MO + MM method
for geometry optimizations and single point energy predictions. a test
for Diels-Alder reactions and Pt(P(t-Bu)3)2 + H2 oxidative addition,"
*J. Phys. Chem.*, **100** 19357 (1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Yesylevskyy2007">

.. _refYesylevskyy2007:

:sup:`157` S. Yesylevskyy, "ProtSqueeze: Simple and effective automated
tool for setting up membrane protein simulations," *J. Chem. Inf.
Model.*, **47** 1986–1994 (2007).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Wolf2010">

.. _refWolf2010:

:sup:`158` M. Wolf, M. Hoefling, C. Aponte-Santamaría, H. Grubmüller,
and G. Groenhof, "g\_membed: Efficient insertion of a membrane protein
into an equilibrated lipid bilayer with minimal perturbation," *J. Comp.
Chem.*, **31** 2169–2174 (2010).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Spoel97a">

.. _refSpoel97a:

:sup:`159` D. van der Spoel and H.J.C. Berendsen, "Molecular dynamics
simulations of Leu-enkephalin in water and DMSO," *Biophys. J.*, **72**
2032–2041 (1997).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-PSmith93c">

.. _refPSmith93c:

:sup:`160` P.E. Smith and W.F. van Gunsteren, "The Viscosity of SPC and
SPC/E Water," *Chem. Phys. Lett.*, **215** 315–318 (1993).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Balasubramanian96">

.. _refBalasubramanian96:

:sup:`161` S. Balasubramanian, C.J. Mundy, and M.L. Klein, "Shear
viscosity of polar fluids: Molecular dynamics calculations of water,"
*J. Chem. Phys.*, **105** 11190–11195 (1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-lmfit">

.. _reflmfit:

:sup:`162` J. Wuttke, *Lmfit*, (2013).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Steen-Saethre2014a">

.. _refSteen-Saethre2014a:

:sup:`163` B. Steen-Sæthre, A.C. Hoffmann, and D. van der Spoel, "Order
parameters and algorithmic approaches for detection and demarcation of
interfaces in hydrate-fluid and ice-fluid systems," *J. Chem. Theor.
Comput.*, **10** 5606–5615 (2014).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Palmer1994a">

.. _refPalmer1994a:

:sup:`164` B.J. Palmer, "Transverse-current autocorrelation-function
calculations of the shear viscosity for molecular liquids." *Phys. Rev.
E*, **49** 359–366 (1994).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Wensink2003a">

.. _refWensink2003a:

:sup:`165` E.J.W. Wensink, A.C. Hoffmann, P.J. van Maaren, and D. van
der Spoel, "Dynamic properties of water/alcohol mixtures studied by
computer simulation," *J. Chem. Phys.*, **119** 7308–7317 (2003).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Guo2002b">

.. _refGuo2002b:

:sup:`166` G.-J. Guo, Y.-G. Zhang, K. Refson, and Y.-J. Zhao, "Viscosity
and stress autocorrelation function in supercooled water: A molecular
dynamics study," *Mol. Phys.*, **100** 2617–2627 (2002).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Fanourgakis2012a">

.. _refFanourgakis2012a:

:sup:`167` G.S. Fanourgakis, J.S. Medina, and R. Prosmiti, "Determining
the bulk viscosity of rigid water models," *J. Phys. Chem. A*, **116**
2564–2570 (2012).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Spoel96b">

.. _refSpoel96b:

:sup:`168` D. van der Spoel, H.J. Vogel, and H.J.C. Berendsen,
"Molecular dynamics simulations of N-terminal peptides from a nucleotide
binding protein," *PROTEINS: Struct. Funct. Gen.*, **24** 450–466
(1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Amadei93">

.. _refAmadei93:

:sup:`169` A. Amadei, A.B.M. Linssen, and H.J.C. Berendsen, "Essential
dynamics of proteins," *PROTEINS: Struct. Funct. Gen.*, **17** 412–425
(1993).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hess2002b">

.. _refHess2002b:

:sup:`170` B. Hess, "Convergence of sampling in protein simulations,"
*Phys. Rev. **E***, **65** 031910 (2002).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Hess2000">

.. _refHess2000:

:sup:`171` B. Hess, "Similarities between principal components of
protein dynamics and random diffusion," *Phys. Rev. **E***, **62**
8438–8448 (2000).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Mu2005a">

.. _refMu2005a:

:sup:`172` Y. Mu, P.H. Nguyen, and G. Stock, "Energy landscape of a
small peptide revelaed by dihedral angle principal component analysis,"
*PROTEINS: Struct. Funct. Gen.*, **58** 45–52 (2005).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Spoel2006b">

.. _refSpoel2006b:

:sup:`173` D. van der Spoel, P.J. van Maaren, P. Larsson, and N.
Timneanu, "Thermodynamics of hydrogen bonding in hydrophilic and
hydrophobic media," *J. Phys. Chem. B.*, **110** 4393–4398 (2006).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Luzar96b">

.. _refLuzar96b:

:sup:`174` A. Luzar and D. Chandler, "Hydrogen-bond kinetics in liquid
water," *Nature*, **379** 55–57 (1996).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Luzar2000a">

.. _refLuzar2000a:

:sup:`175` A. Luzar, "Resolving the hydrogen bond dynamics conundrum,"
*J. Chem. Phys.*, **113** 10663–10675 (2000).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Kabsch83">

.. _refKabsch83:

:sup:`176` W. Kabsch and C. Sander, "Dictionary of protein secondary
structure: Pattern recognition of hydrogen-bonded and geometrical
features," *Biopolymers*, **22** 2577–2637 (1983).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Bekker93b">

.. _refBekker93b:

:sup:`177` H. Bekker, H.J.C. Berendsen, E.J. Dijkstra, S. Achterop, R.
v. Drunen, D. v. d. Spoel, A. Sijbers, and H. Keegstra
*et al.*, "Gromacs Method of Virial Calculation Using a Single Sum"; pp.
257–261 in *Physics computing 92*. Edited by R.A. de Groot and J.
Nadrchal. World Scientific, Singapore, 1993.

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Berendsen87">

.. _refBerendsen87:

:sup:`178` H.J.C. Berendsen, J.R. Grigera, and T.P. Straatsma, "The
missing term in effective pair potentials," *J. Phys. Chem.*, **91**
6269–6271 (1987).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Gunsteren94a">

.. _refGunsteren94a:

:sup:`179` W.F. van Gunsteren and H.J.C. Berendsen, *Molecular dynamics
of simple systems*, (1994).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-RoethlisbergerQMMM">

.. _refRoethlisbergerQMMM:

:sup:`180` A. Laio, J. VandeVondele, U. Rothlisberger, *A Hamiltonian
electrostatic coupling scheme for hybrid Car-Parrinello
molecular dynamics simulations*, (2002).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-GroenhofEwaldArtefact">

.. _refGroenhofEwaldArtefact:

:sup:`181` Hub, J. S., de Groot, B. L., Grubmüller, H., Groenhof, G.,
"Quantifying artifacts in Ewald simulations of inhomogeneous systems with a net charge,"
*J. Chem. Theory Comput.*, **10**, 381–390 (2014).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-PallPairInteractions">

.. _refPallPairInteractions:

:sup:`182` Páll, S., Hess, B.,
"A flexible algorithm for calculating pair interactions on SIMD architectures,"
*Comput. Phys. Commun.*, **183**, 2641–2650 (2013).

.. raw:: html

   </div>


.. raw:: html

   <div id="ref-Orzechowski2019">

.. _refOrzechowski2008:

:sup:`182` Orzechowski M, Tama F., "Flexible fitting of high-resolution x-ray 
structures into cryoelectron microscopy maps using biased molecular dynamics simulations",
*Biophysical journal*, *95*, 5692–705, (2008).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Igaev2019">

.. _refIgaev2019:

:sup:`183` Igaev, M., Kutzner, C., Bock, L. V., Vaiana, A. C., & Grubmüller, H.,
"Automated cryo-EM structure refinement using correlation-driven molecular dynamics", *eLife*, **8**, e43542 (2019).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Bernetti2020">

.. _refBernetti2020:

:sup:`184` Bernetti, M. and Bussi G.,
"Pressure control using stochastic cell rescaling", *J. Chem. Phys.*, **153**, 114107 (2020).

.. raw:: html

   </div>

  <div id="ref-Lidmar2012">

.. _refLidmar2012:

:sup:`185` Lidmar J.,
"Improving the efficiency of extended ensemble simulations: The accelerated weight histogram method", *Phys. Rev. E*, **85**, 0256708 (2012).

.. raw:: html

   </div>

   <div id="ref-Lindahl2018">

.. _refLindahl2018:

:sup:`186` Lindahl V., Lidmar J. and Hess B.,
"Riemann metric approach to optimal sampling of multidimensional free-energy landscapes", *Phys. Rev. E*, **98**, 023312 (2018).

.. raw:: html

   </div>

   <div id="ref-LundBorg2021">

.. _refLundborg2021:

:sup:`187` Lundborg M., Lidmar J. and Hess B.,
"The accelerated weight histogram method for alchemical free energy calculations", *J. Chem. Phys.*, **154**, 204103 (2021).

.. raw:: html

   </div>

   <div id="refcp2k2020">

.. _refcp2k2020:

:sup:`188` Kühne T., Iannuzzi M., Del Ben M. and Hutter J. *et al.*,
"CP2K: An electronic structure and molecular dynamics software package - Quickstep: Efficient and accurate electronic structure calculations",
*J. Chem. Phys.*, **152**, 194103 (2020).

.. raw:: html

   </div>

   <div id="refLaino2005">

.. _refLaino2005:

:sup:`189` Laino T., Mohamed F., Laio A. and Parrinello M.,
"An Efficient Real Space Multigrid QM/MM Electrostatic Coupling", *J. Chem. Theory Comput.*, **1**, 1176 (2005).

.. raw:: html

   </div>

.. raw:: html

   <div id="ref-Gapsys2012">

.. _refGapsys2012:

:sup:`185` V. Gapsys, D. Seeliger, and B.L. de Groot, 
"New Soft-Core Potential Function for Molecular Dynamics Based Alchemical Free Energy Calculations", *J. Chem. Theor. Comput.*, **8** 2373-2382 (2012).

.. raw:: html

   </div>


   <div id="refSpoel2020">

.. _refSpoel2020:
   
:sup:`190` D. van der Spoel, H. Henschel, P. J. van Maaren, M. M. Ghahremanpour , and L. T. Costa, "A potential for molecular simulation of compounds with linear moieties", *J. Chem. Phys.*, **153** 084503 (2020).

.. raw:: html

   </div>

   <div id="refTuckerman92">

.. _refTuckerman92:

:sup:`191` M. Tuckerman, B. J. Berne, and G. J. Martyna, "Reversible multiple time scale molecular dynamics", *J. Chem. Phys.*, **97** 1990 (1992).

.. raw:: html

   </div>

General properties
------------------

| :ref:`gmx energy <gmx energy>`, :ref:`gmx traj <gmx traj>`
| To analyze some or all *energies* and other properties, such as *total
  pressure*, *pressure tensor*, *density*, *box-volume* and *box-sizes*,
  use the program :ref:`gmx energy <gmx energy>`. A choice can be made from a
  list a set of energies, like potential, kinetic or total energy, or
  individual contributions, like Lennard-Jones or dihedral energies.

The *center-of-mass velocity*, defined as

.. math:: {\bf v}_{com} = {1 \over M} \sum_{i=1}^N m_i {\bf v}_i
          :label: eqncomvelocity

with :math:`M = \sum_{i=1}^N m_i` the total mass of the system, can be
monitored in time by the program :ref:`gmx traj <gmx traj>` ``-com -ov``. It is however
recommended to remove the center-of-mass velocity every step (see
chapter :ref:`algorithms`)!
Dihedral principal component analysis
-------------------------------------

| :ref:`gmx angle <gmx angle>`, :ref:`gmx covar <gmx covar>`, 
  :ref:`gmx anaeig <gmx anaeig>`
| Principal component analysis can be performed in dihedral
  space \ :ref:`172 <refMu2005a>` using |Gromacs|. You start by defining the
  dihedral angles of interest in an index file, either using
  :ref:`gmx mk_angndx <gmx mk_angndx>` or otherwise. Then you use the
  :ref:`gmx angle <gmx angle>` program with the ``-or`` flag to
  produce a new :ref:`trr` file containing the cosine and sine
  of each dihedral angle in two coordinates, respectively. That is, in
  the :ref:`trr` file you will have a series of numbers
  corresponding to: cos(\ :math:`\phi_1`), sin(\ :math:`\phi_1`),
  cos(\ :math:`\phi_2`), sin(\ :math:`\phi_2`), ...,
  cos(\ :math:`\phi_n`), sin(\ :math:`\phi_n`), and the array is padded
  with zeros, if necessary. Then you can use this :ref:`trr`
  file as input for the :ref:`gmx covar <gmx covar>` program and perform
  principal component analysis as usual. For this to work you will need
  to generate a reference file (:ref:`tpr`,
  :ref:`gro`, :ref:`pdb` etc.) containing the same
  number of “atoms” as the new :ref:`trr` file, that is for
  :math:`n` dihedrals you need 2\ :math:`n`/3 atoms (rounded up if not
  an integer number). You should use the ``-nofit`` option
  for :ref:`gmx covar <gmx covar>` since the coordinates in the dummy
  reference file do not correspond in any way to the information in the
  :ref:`trr` file. Analysis of the results is done using
  :ref:`gmx anaeig <gmx anaeig>`.
.. _msd:

Mean Square Displacement
------------------------

| :ref:`gmx msd <gmx msd>`
| To determine the self diffusion
  coefficient :math:`D_A` of
  particles of type :math:`A`, one can use the Einstein
  relation :ref:`108 <refAllen87>`:

  .. math:: \lim_{t \rightarrow \infty} \langle
            \|{\bf r}_i(t) - {\bf r}_i(0)\|^2 \rangle_{i \in A} ~=~ 6 D_A t
            :label: eqnmsd

| This *mean square displacement* and :math:`D_A` are calculated by the
  program :ref:`gmx msd <gmx msd>`. Normally
  an index file containing atom numbers is used and the MSD is averaged
  over these atoms. For molecules consisting of more than one atom,
  :math:`{\bf r}_i` can be taken as the center of mass positions of the
  molecules. In that case, you should use an index file with molecule
  numbers. The results will be nearly identical to averaging over atoms,
  however. The :ref:`gmx msd <gmx msd>` program can also be used for
  calculating diffusion in one or two dimensions. This is useful for
  studying lateral diffusion on interfaces.

An example of the mean square displacement of SPC water is given in
:numref:`Fig. %s <fig-msdwater>`.

.. _fig-msdwater:

.. figure:: plots/msdwater.*
    :width: 8.00000cm

    Mean Square Displacement of SPC-water.


Interface-related items
-----------------------

| :ref:`gmx order <gmx order>`, :ref:`gmx density <gmx density>`, 
  :ref:`gmx potential <gmx potential>`, :ref:`gmx traj <gmx traj>`
| When simulating molecules with long carbon tails, it can be
  interesting to calculate their average orientation. There are several
  flavors of order parameters, most of which are related. The program
  :ref:`gmx order <gmx order>` can calculate
  order parameters using the equation:

.. math:: S_{z} = \frac{3}{2}\langle {\cos^2{\theta_z}} \rangle - \frac{1}{2}
          :label: eqnSgr

where :math:`\theta_z` is the angle between the :math:`z`-axis of the
simulation box and the molecular axis under consideration. The latter is
defined as the vector from C\ :math:`_{n-1}` to C\ :math:`_{n+1}`. The
parameters :math:`S_x` and :math:`S_y` are defined in the same way. The
brackets imply averaging over time and molecules. Order parameters can
vary between 1 (full order along the interface normal) and :math:`-1/2`
(full order perpendicular to the normal), with a value of zero in the
case of isotropic orientation.

The program can do two things for you. It can calculate the order
parameter for each CH\ :math:`_2` segment separately, for any of three
axes, or it can divide the box in slices and calculate the average value
of the order parameter per segment in one slice. The first method gives
an idea of the ordering of a molecule from head to tail, the second
method gives an idea of the ordering as function of the box length.

The electrostatic potential (:math:`\psi`) across the interface can be
computed from a trajectory by evaluating the double integral of the
charge density (:math:`\rho(z)`):

.. math:: \psi(z) - \psi(-\infty) = - \int_{-\infty}^z dz' \int_{-\infty}^{z'} \rho(z'')dz''/ \epsilon_0 
          :label: eqnelpotgr

where the position :math:`z=-\infty` is far enough in the bulk phase
such that the field is zero. With this method, it is possible to “split”
the total potential into separate contributions from lipid and water
molecules. The program :ref:`gmx potential <gmx potential>` divides the box in slices and sums
all charges of the atoms in each slice. It then integrates this charge
density to give the electric field, which is in turn integrated to give
the potential. Charge density, electric field, and potential are written
to xvgr input files.

The program :ref:`gmx traj <gmx traj>` is a very simple analysis program. All it does is
print the coordinates, velocities, or forces of selected atoms. It can
also calculate the center of mass of one or more molecules and print the
coordinates of the center of mass to three files. By itself, this is
probably not a very useful analysis, but having the coordinates of
selected molecules or atoms can be very handy for further analysis, not
only in interfacial systems.

The program :ref:`gmx density <gmx density>`
calculates the mass density of groups and gives a plot of the density
against a box axis. This is useful for looking at the distribution of
groups or atoms across the interface.

.. raw:: latex

    \clearpage


Looking at your trajectory
--------------------------

.. _fig-ngmxdump:

.. figure:: plots/ngmxdump.*
   :width: 8.00000cm

   The window of :ref:`gmx view <gmx view>` showing a box of water.

| :ref:`gmx view <gmx view>`
| Before analyzing your trajectory it is often informative to look at
  your trajectory first. |Gromacs| comes with a simple trajectory viewer
  :ref:`gmx view <gmx view>`; the advantage
  with this one is that it does not require OpenGL, which usually isn’t
  present on *e.g.* supercomputers. It is also possible to generate a
  hard-copy in Encapsulated Postscript format (see
  :numref:`Fig. %s <fig-ngmxdump>`). If you want a faster and more
  fancy viewer there are several programs that can read the |Gromacs|
  trajectory formats – have a look at our `webpage`_ for updated links.

Correlation functions
---------------------

Theory of correlation functions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The theory of correlation functions is well established \ :ref:`108 <refAllen87>`.
We describe here the implementation of the various
correlation function flavors in the |Gromacs| code. The definition of the
autocorrelation function (ACF) :math:`C_f(t)` for a property
:math:`f(t)` is:

.. math:: C_f(t)  ~=~     \left\langle f(\xi) f(\xi+t)\right\rangle_{\xi}
          :label: eqncorr

where the notation on the right hand side indicates averaging over
:math:`\xi`, *i.e.* over time origins. It is also possible to compute
cross-correlation function from two properties :math:`f(t)` and
:math:`g(t)`:

.. math:: C_{fg}(t) ~=~   \left\langle f(\xi) g(\xi+t)\right\rangle_{\xi}
          :label: eqncrosscorr

however, in |Gromacs| there is no standard mechanism to do this
(**note:** you can use the ``xmgr`` program to compute cross correlations).
The integral of the correlation function over time is the correlation
time :math:`\tau_f`:

.. math:: \tau_f  ~=~     \int_0^{\infty} C_f(t) {\rm d} t
          :label: eqncorrtime

In practice, correlation functions are calculated based on data points
with discrete time intervals :math:`\Delta`\ t, so that the ACF from an
MD simulation is:

.. math:: C_f(j\Delta t)  ~=~     \frac{1}{N-j}\sum_{i=0}^{N-1-j} f(i\Delta t) f((i+j)\Delta t)
          :label: eqncorrmd

where :math:`N` is the number of available time frames for the
calculation. The resulting ACF is obviously only available at time
points with the same interval :math:`\Delta`\ t. Since, for many
applications, it is necessary to know the short time behavior of the ACF
(*e.g.* the first 10 ps) this often means that we have to save the data
with intervals much shorter than the time scale of interest. Another
implication of :eq:`eqn. %s <eqncorrmd>` is that in principle we can not compute
all points of the ACF with the same accuracy, since we have :math:`N-1`
data points for :math:`C_f(\Delta t)` but only 1 for
:math:`C_f((N-1)\Delta t)`. However, if we decide to compute only an ACF
of length :math:`M\Delta t`, where :math:`M \leq N/2` we can compute all
points with the same statistical accuracy:

.. math:: C_f(j\Delta t)  ~=~ \frac{1}{M}\sum_{i=0}^{N-1-M} f(i\Delta t)f((i+j)\Delta t)
          :label: eqncorrstataccuracy

Here of course :math:`j < M`. :math:`M` is sometimes referred to as the
time lag of the correlation function. When we decide to do this, we
intentionally do not use all the available points for very short time
intervals (:math:`j << M`), but it makes it easier to interpret the
results. Another aspect that may not be neglected when computing ACFs
from simulation is that usually the time origins :math:`\xi`
(:eq:`eqn. %s <eqncorr>`) are not statistically independent, which may introduce
a bias in the results. This can be tested using a block-averaging
procedure, where only time origins with a spacing at least the length of
the time lag are included, *e.g.* using :math:`k` time origins with
spacing of :math:`M\Delta t` (where :math:`kM \leq N`):

.. math:: C_f(j\Delta t)  ~=~ \frac{1}{k}\sum_{i=0}^{k-1} f(iM\Delta t)f((iM+j)\Delta t)
          :label: eqncorrblockaveraging

However, one needs very long simulations to get good accuracy this way,
because there are many fewer points that contribute to the ACF.

Using FFT for computation of the ACF
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The computational cost for calculating an ACF according to
:eq:`eqn. %s <eqncorrmd>` is proportional to :math:`N^2`, which is considerable.
However, this can be improved by using fast Fourier transforms to do the
convolution \ :ref:`108 <refAllen87>`.

Special forms of the ACF
~~~~~~~~~~~~~~~~~~~~~~~~

There are some important varieties on the ACF, *e.g.* the ACF of a
vector :math:`\mathbf{p}`:

.. math:: C_{\mathbf{p}}(t) ~=~       \int_0^{\infty} P_n(\cos\angle\left(\mathbf{p}(\xi),\mathbf{p}(\xi+t)\right) {\rm d} \xi
          :label: eqncorrleg

where :math:`P_n(x)` is the :math:`n^{th}` order Legendre
polynomial. [1]_ Such correlation times can actually be obtained
experimentally using *e.g.* NMR or other relaxation experiments. |Gromacs|
can compute correlations using the 1\ :math:`^{st}` and 2\ :math:`^{nd}`
order Legendre polynomial (:eq:`eqn. %s <eqncorrleg>`). This can also be used
for rotational autocorrelation (:ref:`gmx rotacf`) and dipole autocorrelation
(:ref:`gmx dipoles <gmx dipoles>`).

In order to study torsion angle dynamics, we define a dihedral
autocorrelation function as \ :ref:`159 <refSpoel97a>`:

.. math:: C(t)    ~=~     \left\langle \cos(\theta(\tau)-\theta(\tau+t))\right\rangle_{\tau}
          :label: eqncoenk

**Note** that this is not a product of two functions as is generally
used for correlation functions, but it may be rewritten as the sum of
two products:

.. math:: C(t)    ~=~     \left\langle\cos(\theta(\tau))\cos(\theta(\tau+t))\,+\,\sin(\theta(\tau))\sin(\theta(\tau+t))\right\rangle_{\tau}
          :label: eqncot

Some Applications
~~~~~~~~~~~~~~~~~

The program :ref:`gmx velacc <gmx velacc>`
calculates the *velocity autocorrelation function*.

.. math:: C_{\mathbf{v}} (\tau) ~=~ \langle {\mathbf{v}}_i(\tau) \cdot {\mathbf{v}}_i(0) \rangle_{i \in A}
          :label: eqnvelocityautocorr

The self diffusion coefficient can be calculated using the Green-Kubo
relation \ :ref:`108 <refAllen87>`:

.. math:: D_A ~=~ {1\over 3} \int_0^{\infty} \langle {\bf v}_i(t) \cdot {\bf v}_i(0) \rangle_{i \in A} \; dt
          :label: eqndiffcoeff

which is just the integral of the velocity autocorrelation function.
There is a widely-held belief that the velocity ACF converges faster
than the mean square displacement (sec. :ref:`msd`), which can also be
used for the computation of diffusion constants. However, Allen &
Tildesley \ :ref:`108 <refAllen87>` warn us that the long-time
contribution to the velocity ACF can not be ignored, so care must be
taken.

Another important quantity is the dipole correlation time. The *dipole
correlation function* for particles of type :math:`A` is calculated as
follows by :ref:`gmx dipoles <gmx dipoles>`:

.. math:: C_{\mu} (\tau) ~=~
          \langle {\bf \mu}_i(\tau) \cdot {\bf \mu}_i(0) \rangle_{i \in A}
          :label: eqndipolecorrfunc

with :math:`{\bf \mu}_i = \sum_{j \in i} {\bf r}_j q_j`. The dipole
correlation time can be computed using :eq:`eqn. %s <eqncorrtime>`. 
For some applications
see (**???**).

The viscosity of a liquid can be related to the correlation time of the
Pressure tensor
:math:`\mathbf{P}` :ref:`160 <refPSmith93c>`,
:ref:`161 <refBalasubramanian96>`. :ref:`gmx energy` can compute the viscosity,
but this is not very accurate \ :ref:`149 <refHess2002a>`, and actually
the values do not converge.


.. [1]
   :math:`P_0(x) = 1`, :math:`P_1(x) = x`, :math:`P_2(x) = (3x^2-1)/2`

.. _covanal:

Covariance analysis
-------------------

Covariance analysis, also called principal component analysis or
essential dynamics :ref:`169 <refAmadei93>`\ , can find
correlated motions. It uses the covariance matrix :math:`C` of the
atomic coordinates:

.. math:: C_{ij} = \left \langle 
          M_{ii}^{\frac{1}{2}} (x_i - \langle x_i \rangle)
          M_{jj}^{\frac{1}{2}}  (x_j - \langle x_j \rangle)
          \right \rangle
          :label: eqncovmatrixcoord

where :math:`M` is a diagonal matrix containing the masses of the atoms
(mass-weighted analysis) or the unit matrix (non-mass weighted
analysis). :math:`C` is a symmetric :math:`3N \times 3N` matrix, which
can be diagonalized with an orthonormal transformation matrix :math:`R`:

.. math:: R^T C R = \mbox{diag}(\lambda_1,\lambda_2,\ldots,\lambda_{3N})
          ~~~~\mbox{where}~~\lambda_1 \geq \lambda_2 \geq \ldots \geq \lambda_{3N}
          :label: eqnorthnormtransformmatrix

The columns of :math:`R` are the eigenvectors, also called principal or
essential modes. :math:`R` defines a transformation to a new coordinate
system. The trajectory can be projected on the principal modes to give
the principal components :math:`p_i(t)`:

.. math:: {\bf p}(t) = R^T M^{\frac{1}{2}} ({\bf x}(t) - \langle {\bf x} \rangle)
          :label: eqnprinccomponents

The eigenvalue :math:`\lambda_i` is the mean square fluctuation of
principal component :math:`i`. The first few principal modes often
describe collective, global motions in the system. The trajectory can be
filtered along one (or more) principal modes. For one principal mode
:math:`i` this goes as follows:

.. math:: {\bf x}^f(t) =
          \langle {\bf x} \rangle + M^{-\frac{1}{2}} R_{ * i} \, p_i(t)
          :label: eqnprincmodei

When the analysis is performed on a macromolecule, one often wants to
remove the overall rotation and translation to look at the internal
motion only. This can be achieved by least square fitting to a reference
structure. Care has to be taken that the reference structure is
representative for the ensemble, since the choice of reference structure
influences the covariance matrix.

One should always check if the principal modes are well defined. If the
first principal component resembles a half cosine and the second
resembles a full cosine, you might be filtering noise (see below). A
good way to check the relevance of the first few principal modes is to
calculate the overlap of the sampling between the first and second half
of the simulation. **Note** that this can only be done when the same
reference structure is used for the two halves.

A good measure for the overlap has been defined in \ :ref:`170 <refHess2002b>`. The
elements of the covariance matrix are proportional to the square of the
displacement, so we need to take the square root of the matrix to
examine the extent of sampling. The square root can be calculated from
the eigenvalues :math:`\lambda_i` and the eigenvectors, which are the
columns of the rotation matrix :math:`R`. For a symmetric and
diagonally-dominant matrix :math:`A` of size :math:`3N \times 3N` the
square root can be calculated as:

.. math:: A^\frac{1}{2} = 
          R \, \mbox{diag}(\lambda_1^\frac{1}{2},\lambda_2^\frac{1}{2},\ldots,\lambda_{3N}^\frac{1}{2}) \, R^T
          :label: eqnmatrixsquareroot

It can be verified easily that the product of this matrix with itself
gives :math:`A`. Now we can define a difference :math:`d` between
covariance matrices :math:`A` and :math:`B` as follows:

.. math:: \begin{aligned}
          d(A,B) & = & \sqrt{\mbox{tr}\left(\left(A^\frac{1}{2} - B^\frac{1}{2}\right)^2\right)
          }
          \\ & = &
          \sqrt{\mbox{tr}\left(A + B - 2 A^\frac{1}{2} B^\frac{1}{2}\right)}
          \\ & = &
          \left( \sum_{i=1}^N \left( \lambda_i^A + \lambda_i^B \right)
          - 2 \sum_{i=1}^N \sum_{j=1}^N \sqrt{\lambda_i^A \lambda_j^B}
          \left(R_i^A \cdot R_j^B\right)^2 \right)^\frac{1}{2}\end{aligned}
          :label: eqnmatrixdiff

where tr is the trace of a matrix. We can now define the overlap
:math:`s` as:

.. math:: s(A,B) = 1 - \frac{d(A,B)}{\sqrt{\mbox{tr}A + \mbox{tr} B}}
          :label: eqnmatrixoverlap

The overlap is 1 if and only if matrices :math:`A` and :math:`B` are
identical. It is 0 when the sampled subspaces are completely orthogonal.

A commonly-used measure is the subspace overlap of the first few
eigenvectors of covariance matrices. The overlap of the subspace spanned
by :math:`m` orthonormal vectors :math:`{\bf w}_1,\ldots,{\bf w}_m` with
a reference subspace spanned by :math:`n` orthonormal vectors
:math:`{\bf v}_1,\ldots,{\bf v}_n` can be quantified as follows:

.. math:: \mbox{overlap}({\bf v},{\bf w}) =
          \frac{1}{n} \sum_{i=1}^n \sum_{j=1}^m ({\bf v}_i \cdot {\bf w}_j)^2
          :label: eqnsubspaceoverlap

The overlap will increase with increasing :math:`m` and will be 1 when
set :math:`{\bf v}` is a subspace of set :math:`{\bf w}`. The
disadvantage of this method is that it does not take the eigenvalues
into account. All eigenvectors are weighted equally, and when degenerate
subspaces are present (equal eigenvalues), the calculated overlap will
be too low.

Another useful check is the cosine content. It has been proven that the
the principal components of random diffusion are cosines with the number
of periods equal to half the principal component
index \ :ref:`170 <refHess2002b>`, :ref:`171 <refHess2000>`.
The eigenvalues are proportional to the index to the power
:math:`-2`. The cosine content is defined as:

.. math:: \frac{2}{T}
          \left( \int_0^T \cos\left(\frac{i \pi t}{T}\right) \, p_i(t) \mbox{d} t \right)^2
          \left( \int_0^T p_i^2(t) \mbox{d} t \right)^{-1}
          :label: eqneigenvaluecosine

When the cosine content of the first few principal components is close
to 1, the largest fluctuations are not connected with the potential, but
with random diffusion.

The covariance matrix is built and diagonalized by
:ref:`gmx covar <gmx covar>`. The principal components and
overlap (and many more things) can be plotted and analyzed with
:ref:`gmx anaeig <gmx anaeig>`. The cosine
content can be calculated with
:ref:`gmx analyze <gmx analyze>`.
Protein-related items
---------------------

| :ref:`gmx do_dssp <gmx do_dssp>`, :ref:`gmx rama <gmx rama>`,
  :ref:`gmx wheel <gmx wheel>`
| To analyze structural changes of a protein, you can calculate the
  radius of gyration or the minimum residue distances over time (see
  sec. :ref:`rg`), or calculate the RMSD (sec. :ref:`rmsd`).

You can also look at the changing of *secondary structure elements*
during your run. For this, you can use the program 
:ref:`gmx do_dssp <gmx do_dssp>`, which is an interface for the
commercial program ``DSSP``  :ref:`176 <refKabsch83>`. For
further information, see the ``DSSP`` manual. A typical
output plot of :ref:`gmx do_dssp <gmx do_dssp>` is given in
:numref:`Fig. %s <fig-dssp>`.

.. _fig-dssp: 

.. figure:: plots/dssp.*
   :width: 12.00000cm

   Analysis of the secondary structure elements of a peptide in time.

One other important analysis of proteins is the so-called *Ramachandran
plot*. This is the projection of the structure on the two dihedral
angles :math:`\phi` and :math:`\psi` of the protein backbone, see
:numref:`Fig. %s <fig-phipsi>`: 

.. _fig-phipsi:

.. figure:: plots/phipsi.*
   :width: 8.00000cm

   Definition of the dihedral angles :math:`\phi` and :math:`\psi` of
   the protein backbone.

To evaluate this Ramachandran plot you can use the program
:ref:`gmx rama <gmx rama>`. A typical output
is given in :numref:`Fig. %s <fig-rama>`.

.. _fig-rama:

.. figure:: plots/rama.* 
    :width: 15.00000cm

    Ramachandran plot of a small protein.

When studying :math:`\alpha`-helices it is useful to have a *helical
wheel* projection of your peptide, to see whether a peptide is
amphipathic. This can be done using the :ref:`gmx wheel <gmx wheel>`
program. Two examples are plotted in
:numref:`Fig. %s <fig-hprwheel>`.

.. _fig-hprwheel:

.. figure:: plots/hpr-wheel.*
   :width: 10.00000cm

   Helical wheel projection of the N-terminal helix of HPr.

.. _rmsd:

Root mean square deviations in structure
----------------------------------------

| :ref:`gmx rms <gmx rms>`, :ref:`gmx rmsdist <gmx rmsdist>`
| The *root mean square deviation* (:math:`RMSD`) of certain atoms in a
  molecule with respect to a reference structure can be calculated with
  the program :ref:`gmx rms <gmx rms>` by least-square fitting the structure to the
  reference structure (:math:`t_2 = 0`) and subsequently calculating the
  :math:`RMSD` (:eq:`eqn. %s <eqnrmsd>`).

  .. math:: RMSD(t_1,t_2) ~=~ \left[\frac{1}{M} \sum_{i=1}^N m_i \|{\bf r}_i(t_1)-{\bf r}_i(t_2)\|^2 \right]^{\frac{1}{2}}
            :label: eqnrmsd

| where :math:`M = \sum_{i=1}^N m_i` and :math:`{\bf r}_i(t)` is the
  position of atom :math:`i` at time :math:`t`. **Note** that fitting
  does not have to use the same atoms as the calculation of the
  :math:`RMSD`; *e.g.* a protein is usually fitted on the backbone atoms
  (N, C\ :math:`_{\alpha}`, C), but the :math:`RMSD` can be computed of the
  backbone or of the whole protein.

Instead of comparing the structures to the initial structure at time
:math:`t=0` (so for example a crystal structure), one can also calculate
:eq:`eqn. %s <eqnrmsd>` with a structure at time :math:`t_2=t_1-\tau`. This
gives some insight in the mobility as a function of :math:`\tau`. A
matrix can also be made with the :math:`RMSD` as a function of
:math:`t_1` and :math:`t_2`, which gives a nice graphical interpretation
of a trajectory. If there are transitions in a trajectory, they will
clearly show up in such a matrix.

Alternatively the :math:`RMSD` can be computed using a fit-free method
with the program :ref:`gmx rmsdist <gmx rmsdist>`:

.. math:: RMSD(t) ~=~     \left[\frac{1}{N^2}\sum_{i=1}^N \sum_{j=1}^N    \|{\bf r}_{ij}(t)-{\bf r}_{ij}(0)\|^2\right]^{\frac{1}{2}}
          :label: eqnrmsdff

where the *distance* **r**\ :math:`_{ij}` between atoms at time
:math:`t` is compared with the distance between the same atoms at time
:math:`0`.
.. _usinggroups:

Using Groups
------------

| In chapter :ref:`algorithms`, it was explained how *groups of atoms* can
  be used in :ref:`mdrun <gmx mdrun>` (see sec. :ref:`groupconcept`). In most analysis
  programs, groups of atoms must also be chosen. Most programs can
  generate several default index groups, but groups can always be read
  from an index file. Let’s consider the example of a simulation of a
  binary mixture of components A and B. When we want to calculate the
  radial distribution function (RDF) :math:`g_{AB}(r)` of A with respect
  to B, we have to calculate:

  .. math:: 4\pi r^2 g_{AB}(r)      ~=~     V~\sum_{i \in A}^{N_A} \sum_{j \in B}^{N_B} P(r)
            :label: eqnanalysisrdf

| where :math:`V` is the volume and :math:`P(r)` is the probability of
  finding a B atom at distance :math:`r` from an A atom.

By having the user define the *atom numbers* for groups A and B in a
simple file, we can calculate this :math:`g_{AB}` in the most general
way, without having to make any assumptions in the RDF program about the
type of particles.

Groups can therefore consist of a series of *atom numbers*, but in some
cases also of *molecule numbers*. It is also possible to specify a
series of angles by *triples* of *atom numbers*, dihedrals by
*quadruples* of *atom numbers* and bonds or vectors (in a molecule) by
*pairs* of *atom numbers*. When appropriate the type of index file will
be specified for the following analysis programs. To help creating such
:ref:`index file <ndx>` ``index.ndx``), there are a couple of programs to generate
them, using either your input configuration or the topology. To generate
an index file consisting of a series of *atom numbers* (as in the
example of :math:`g_{AB}`), use :ref:`gmx make_ndx`
or :ref:`gmx select`. To generate an index file with
angles or dihedrals, use :ref:`gmx mk_angndx`. Of course you can also
make them by hand. The general format is presented here:

::

    [ Oxygen ]
       1       4       7

    [ Hydrogen ]
       2       3       5       6
       8       9

First, the group name is written between square brackets. The following
atom numbers may be spread out over as many lines as you like. The atom
numbering starts at 1.

Each tool that can use groups will offer the available alternatives for
the user to choose. That choice can be made with the number of the
group, or its name. In fact, the first few letters of the group name
will suffice if that will distinguish the group from all others. There
are ways to use Unix shell features to choose group names on the command
line, rather than interactively. Consult our `webpage`_ for suggestions.

.. _defaultgroups:

Default Groups
~~~~~~~~~~~~~~

When no index file is supplied to analysis tools or
:ref:`grompp <gmx grompp>`, a number of default
groups are generated to choose from:

``System``
    | all atoms in the system

``Protein``
    | all protein atoms

``Protein-H``
    | protein atoms excluding hydrogens

``C-alpha``
    | C\ :math:`_{\alpha}` atoms

``Backbone``
    | protein backbone atoms; N, C\ :math:`_{\alpha}` and C

``MainChain``
    | protein main chain atoms: N, C\ :math:`_{\alpha}`, C and O,
      including oxygens in C-terminus

``MainChain+Cb``
    | protein main chain atoms including C\ :math:`_{\beta}`

``MainChain+H``
    | protein main chain atoms including backbone amide hydrogens and
      hydrogens on the N-terminus

``SideChain``
    | protein side chain atoms; that is all atoms except N,
      C\ :math:`_{\alpha}`, C, O, backbone amide hydrogens, oxygens in
      C-terminus and hydrogens on the N-terminus

``SideChain-H``
    | protein side chain atoms excluding all hydrogens

``Prot-Masses``
    | protein atoms excluding dummy masses (as used in virtual site
      constructions of NH\ :math:`_3` groups and tryptophan
      side-chains), see also sec. :ref:`vsitetop`; this group is only
      included when it differs from the ``Protein`` group

``Non-Protein``
    | all non-protein atoms

``DNA``
    | all DNA atoms

``RNA``
    | all RNA atoms

``Water``
    | water molecules (names like ``SOL``, ``WAT``, ``HOH``, etc.) See
      ``residuetypes.dat`` for a full listing

``non-Water``
    | anything not covered by the ``Water`` group

``Ion``
    | any name matching an Ion entry in
      ``residuetypes.dat``

``Water_and_Ions``
    | combination of the ``Water`` and ``Ions``
      groups

``molecule_name``
    | for all residues/molecules which are not recognized as protein,
      DNA, or RNA; one group per residue/molecule name is generated

``Other``
    | all atoms which are neither protein, DNA, nor RNA.

Empty groups will not be generated. Most of the groups only contain
protein atoms. An atom is considered a protein atom if its residue name
is listed in the
``residuetypes.dat``
file and is listed as a “Protein” entry. The process for determinding
DNA, RNA, etc. is analogous. If you need to modify these
classifications, then you can copy the file from the library directory
into your working directory and edit the local copy.

.. _selections:

Selections
~~~~~~~~~~

| :ref:`gmx select <gmx select>`
| Currently, a few analysis tools support an extended concept of
  *(dynamic) selections*. There are three
  main differences to traditional index groups:

-  The selections are specified as text instead of reading fixed atom
   indices from a file, using a syntax similar to VMD. The text can be
   entered interactively, provided on the command line, or from a file.

-  The selections are not restricted to atoms, but can also specify that
   the analysis is to be performed on, e.g., center-of-mass positions of
   a group of atoms. Some tools may not support selections that do not
   evaluate to single atoms, e.g., if they require information that is
   available only for single atoms, like atom names or types.

-  The selections can be dynamic, i.e., evaluate to different atoms for
   different trajectory frames. This allows analyzing only a subset of
   the system that satisfies some geometric criteria.

As an example of a simple selection, ``resname ABC`` and
``within 2 of resname DEF`` selects all atoms in residues named ABC that are
within 2nm of any atom in a residue named DEF.

Tools that accept selections can also use traditional index files
similarly to older tools: it is possible to give an :ref:`ndx`
file to the tool, and directly select a group from the index file as a
selection, either by group number or by group name. The index groups can
also be used as a part of a more complicated selection.

To get started, you can run :ref:`gmx select <gmx select>` with a single
structure, and use the interactive prompt to try out different
selections. The tool provides, among others, output options
``-on`` and ``-ofpdb`` to write out the selected
atoms to an index file and to a :ref:`pdb` file, respectively.
This does not allow testing selections that evaluate to center-of-mass
positions, but other selections can be tested and the result examined.

The detailed syntax and the individual keywords that can be used in
selections can be accessed by typing ``help`` in the
interactive prompt of any selection-enabled tool, as well as with
:ref:`gmx help <gmx help>` selections. The help is divided into subtopics
that can be accessed with, e.g., ``help syntax``/
:ref:`gmx help <gmx help>` ``selections syntax``. Some individual selection
keywords have extended help as well, which can be accessed with, e.g.,
``help keywords`` within.

The interactive prompt does not currently provide much editing
capabilities. If you need them, you can run the program under
``rlwrap``.

For tools that do not yet support the selection syntax, you can use
:ref:`gmx select <gmx select>` -on to generate static index groups to pass
to the tool. However, this only allows for a small subset (only the
first bullet from the above list) of the flexibility that fully
selection-aware tools offer.

It is also possible to write your own analysis tools to take advantage
of the flexibility of these selections: see the
``template.cpp`` file in the
``share/gromacs/template`` directory of your installation
for an example and
https://manual.gromacs.org/current/doxygen/html-full/page_analysistemplate.xhtml
for documentation.
Hydrogen bonds
--------------

| :ref:`gmx hbond <gmx hbond>`
| The program :ref:`gmx hbond <gmx hbond>`
  analyzes the *hydrogen bonds* (H-bonds) between all possible donors D
  and acceptors A. To determine if an H-bond exists, a geometrical
  criterion is used, see also :numref:`Fig. %s <fig-hbond>`:

  .. math:: \begin{array}{rclcl}
            r       & \leq  & r_{HB}        & = & 0.35~\mbox{nm}    \\
            \alpha  & \leq  & \alpha_{HB}   & = & 30^o              \\
            \end{array}
            :label: eqnhbondgeomtric

.. _fig-hbond:

.. figure:: plots/hbond.*
   :width: 7.50000cm

   Geometrical Hydrogen bond criterion.

The value of :math:`r_{HB} = 0.35 \mathrm{nm}` corresponds to the first minimum
of the RDF of SPC water (see also :numref:`Fig. %s <fig-hbondinsert>`).

The program :ref:`gmx hbond <gmx hbond>` analyzes all hydrogen bonds
existing between two groups of atoms (which must be either identical or
non-overlapping) or in specified donor-hydrogen-acceptor triplets, in
the following ways:

.. _fig-hbondinsert:

.. figure:: plots/hbond-insert.*
    :width: 7.50000cm

    Insertion of water into an H-bond. (1) Normal H-bond between two
    residues. (2) H-bonding bridge via a water molecule.

-  Donor-Acceptor distance (:math:`r`) distribution of all H-bonds

-  Hydrogen-Donor-Acceptor angle (:math:`\alpha`) distribution of all
   H-bonds

-  The total number of H-bonds in each time frame

-  The number of H-bonds in time between residues, divided into groups
   :math:`n`-:math:`n`\ +\ :math:`i` where :math:`n` and
   :math:`n`\ +\ :math:`i` stand for residue numbers and :math:`i` goes
   from 0 to 6. The group for :math:`i=6` also includes all H-bonds for
   :math:`i>6`. These groups include the
   :math:`n`-:math:`n`\ +\ :math:`3`, :math:`n`-:math:`n`\ +\ :math:`4`
   and :math:`n`-:math:`n`\ +\ :math:`5` H-bonds, which provide a
   measure for the formation of :math:`\alpha`-helices or
   :math:`\beta`-turns or strands.

-  The lifetime of the H-bonds is calculated from the average over all
   autocorrelation functions of the existence functions (either 0 or 1)
   of all H-bonds:

   .. math:: C(\tau) ~=~ \langle s_i(t)~s_i (t + \tau) \rangle
             :label: eqnhbcorr

-  with :math:`s_i(t) = \{0,1\}` for H-bond :math:`i` at time
   :math:`t`. The integral of :math:`C(\tau)` gives a rough estimate of
   the average H-bond lifetime :math:`\tau_{HB}`:

   .. math::  \tau_{HB} ~=~ \int_{0}^{\infty} C(\tau) d\tau
              :label: eqnhblife

-  Both the integral and the complete autocorrelation function
   :math:`C(\tau)` will be output, so that more sophisticated analysis
   (*e.g.* using multi-exponential fits) can be used to get better
   estimates for :math:`\tau_{HB}`. A more complete analysis is given in
   ref. \ :ref:`173 <refSpoel2006b>`; one of the more fancy option is the Luzar
   and Chandler analysis of hydrogen bond kinetics \ :ref:`174 <refLuzar96b>`, :ref:`175 <refLuzar2000a>`.

-  An H-bond existence map can be generated of dimensions
   *# H-bonds*\ :math:`\times`\ *# frames*. The ordering is identical to
   the index file (see below), but reversed, meaning that the last
   triplet in the index file corresponds to the first row of the
   existence map.

-  Index groups are output containing the analyzed groups, all
   donor-hydrogen atom pairs and acceptor atoms in these groups,
   donor-hydrogen-acceptor triplets involved in hydrogen bonds between
   the analyzed groups and all solvent atoms involved in insertion.
Radial distribution functions
-----------------------------

| :ref:`gmx rdf <gmx rdf>`
| The *radial distribution function* (RDF) or pair correlation function
  :math:`g_{AB}(r)` between particles of type :math:`A` and :math:`B` is
  defined in the following way:

.. math:: \begin{array}{rcl}
          g_{AB}(r)&=&    {\displaystyle \frac{\langle \rho_B(r) \rangle}{\langle\rho_B\rangle_{local}}}         \\
                   &=&    {\displaystyle \frac{1}{\langle\rho_B\rangle_{local}}}{\displaystyle \frac{1}{N_A}}
                          \sum_{i \in A}^{N_A} \sum_{j \in B}^{N_B} 
                          {\displaystyle \frac{\delta( r_{ij} - r )}{4 \pi r^2}}         \\
          \end{array}
          :label: eqnrdfdefine

with :math:`\langle\rho_B(r)\rangle` the particle density of type
:math:`B` at a distance :math:`r` around particles :math:`A`, and
:math:`\langle\rho_B\rangle_{local}` the particle density of type
:math:`B` averaged over all spheres around particles :math:`A` with
radius :math:`r_{max}` (see :numref:`Fig. %s <fig-rdfex>` C).

.. _fig-rdfex:

.. figure:: plots/rdf.*
    :width: 7.00000cm

    Definition of slices in :ref:`gmx rdf <gmx rdf>`: A. :math:`g_{AB}(r)`.
    B. :math:`g_{AB}(r,\theta)`. The slices are colored gray. C.
    Normalization :math:`\langle\rho_B\rangle_{local}`. D. Normalization
    :math:`\langle\rho_B\rangle_{local,\:\theta }`. Normalization volumes
    are colored gray.

Usually the value of :math:`r_{max}` is half of the box length. The
averaging is also performed in time. In practice the analysis program
:ref:`gmx rdf <gmx rdf>` divides the system
into spherical slices (from :math:`r` to :math:`r+dr`, see
:numref:`Fig. %s <fig-rdfex>` A) and makes a histogram in stead of
the :math:`\delta`-function. An example of the RDF of oxygen-oxygen in
SPC water \ :ref:`80 <refBerendsen81>` is given in :numref:`Fig. %s <fig-rdf>`

.. _fig-rdf:

.. figure:: plots/rdfO-O.*
    :width: 8.00000cm

    :math:`g_{OO}(r)` for Oxygen-Oxygen of SPC-water.

With :ref:`gmx rdf <gmx rdf>` it is also possible to calculate an angle
dependent rdf :math:`g_{AB}(r,\theta)`, where the angle :math:`\theta`
is defined with respect to a certain laboratory axis :math:`{\bf e}`,
see :numref:`Fig. %s <fig-rdfex>` B.

.. math:: g_{AB}(r,\theta) = {1 \over \langle\rho_B\rangle_{local,\:\theta }} 
          {1 \over N_A} \sum_{i \in A}^{N_A} \sum_{j \in B}^{N_B} {\delta( r_{ij} - r ) 
          \delta(\theta_{ij} -\theta) \over 2 \pi r^2 sin(\theta)}
          :label: eqnrdfangleaxis1

.. math:: cos(\theta_{ij}) = {{\bf r}_{ij} \cdot {\bf e} \over \|r_{ij}\| \;\| e\| }
          :label: eqnrdfangleaxis2

This :math:`g_{AB}(r,\theta)` is useful for analyzing anisotropic
systems. **Note** that in this case the normalization
:math:`\langle\rho_B\rangle_{local,\:\theta}` is the average density in
all angle slices from :math:`\theta` to :math:`\theta + d\theta` up to
:math:`r_{max}`, so angle dependent, see :numref:`Fig. %s <fig-rdfex>` D.
.. _bad:

Bonds/distances, angles and dihedrals
-------------------------------------

| :ref:`gmx distance <gmx distance>`, :ref:`gmx angle <gmx angle>`, 
  :ref:`gmx gangle <gmx gangle>`
| To monitor specific *bonds* in your modules, or more generally
  distances between points, the program 
  :ref:`gmx distance <gmx distance>` can calculate distances as a
  function of time, as well as the distribution of the distance. With a
  traditional index file, the groups should consist of pairs of atom
  numbers, for example:

::

    [ bonds_1 ]
     1     2
     3     4
     9    10

    [ bonds_2 ]
    12    13

Selections are also supported, with first two positions defining the
first distance, second pair of positions defining the second distance
and so on. You can calculate the distances between CA and CB atoms in
all your residues (assuming that every residue either has both atoms, or
neither) using a selection such as:

::

    name CA CB

The selections also allow more generic distances to be computed. For
example, to compute the distances between centers of mass of two
residues, you can use:

::

    com of resname AAA plus com of resname BBB

The program :ref:`gmx angle <gmx angle>`
calculates the distribution of *angles* and *dihedrals* in time. It also
gives the average angle or dihedral. The index file consists of triplets
or quadruples of atom numbers:

::

    [ angles ]
     1     2     3
     2     3     4
     3     4     5

    [ dihedrals ]
     1     2     3     4
     2     3     5     5

For the dihedral angles you can use either the “biochemical convention”
(:math:`\phi = 0 \equiv cis`) or “polymer convention”
(:math:`\phi = 0 \equiv trans`), see
:numref:`Fig. %s <fig-dihdef>`.

.. _fig-dihdef:

.. figure:: plots/dih-def.*
    :width: 5.00000cm

    Dihedral conventions: A. “Biochemical convention”. B. “Polymer
    convention”.

The program :ref:`gmx gangle <gmx gangle>`
provides a selection-enabled version to compute angles. This tool can
also compute angles and dihedrals, but does not support all the options
of :ref:`gmx angle <gmx angle>`, such as autocorrelation or other time
series analyses. In addition, it supports angles between two vectors, a
vector and a plane, two planes (defined by 2 or 3 points, respectively),
a vector/plane and the :math:`z` axis, or a vector/plane and the normal
of a sphere (determined by a single position). Also the angle between a
vector/plane compared to its position in the first frame is supported.
For planes, :ref:`gmx gangle <gmx gangle>`
uses the normal vector perpendicular to the plane. See
:numref:`Fig. %s <fig-sgangle>` A, B, C) for the definitions.

.. _fig-sgangle:

.. figure:: plots/sgangle.*
    :width: 10.00000cm

    Angle options of :ref:`gmx gangle <gmx gangle>`: A. Angle between two
    vectors. B. Angle between two planes. C. Angle between a vector and the
    :math:`z` axis. D. Angle between a vector and the normal of a sphere.
    Also other combinations are supported: planes and vectors can be used
    interchangeably.


Curve fitting in |Gromacs|
--------------------------

Sum of exponential functions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Sometimes it is useful to fit a curve to an analytical function, for
example in the case of autocorrelation functions with noisy tails.
|Gromacs| is not a general purpose curve-fitting tool however and
therefore |Gromacs| only supports a limited number of functions.
:numref:`Table %s <table-fitfn>`  lists the available options with the corresponding
command-line options. The underlying routines for fitting use the
Levenberg-Marquardt algorithm as implemented in the lmfit package \ :ref:`162 <reflmfit>`
(a bare-bones version of which is included in |Gromacs| in which an
option for error-weighted fitting was implemented).

.. |exp|  replace:: :math:`e^{-t/{a_0}}`                                                       
.. |aexp| replace:: :math:`a_1e^{-t/{a_0}}`                                                    
.. |exp2| replace:: :math:`a_1e^{-t/{a_0}}+(1-a_1)e^{-t/{a_2}}`                                
.. |exp5| replace:: :math:`a_1e^{-t/{a_0}}+a_3e^{-t/{a_2}}+a_4`                                
.. |exp7| replace:: :math:`a_1e^{-t/{a_0}}+a_3e^{-t/{a_2}}+a_5e^{-t/{a_4}}+a_6`                
.. |exp9| replace:: :math:`a_1e^{-t/{a_0}}+a_3e^{-t/{a_2}}+a_5e^{-t/{a_4}}+a_7e^{-t/{a_6}}+a_8`
.. |nexp2| replace:: :math:`a_2\ge a_0\ge 0`               
.. |nexp5| replace:: :math:`a_2\ge a_0\ge 0`               
.. |nexp7| replace:: :math:`a_4\ge a_2\ge a_0 \ge0`        
.. |nexp9| replace:: :math:`a_6\ge a_4\ge a_2\ge a_0\ge 0` 

.. _table-fitfn:

.. table:: Overview of fitting functions supported in (most) analysis tools 
    that compute autocorrelation functions. The **Note** column describes 
    properties of the output parameters.
    :align: center
    :widths: auto

    +-------------+------------------------------+---------------------+
    | Command     | Functional form :math:`f(t)` | Note                |
    | line option |                              |                     |
    +=============+==============================+=====================+
    | exp         | |exp|                        |                     |
    +-------------+------------------------------+---------------------+
    | aexp        | |aexp|                       |                     |
    +-------------+------------------------------+---------------------+
    | exp_exp     | |exp2|                       | |nexp2|             |
    +-------------+------------------------------+---------------------+
    | exp5        | |exp5|                       | |nexp5|             |
    +-------------+------------------------------+---------------------+
    | exp7        | |exp7|                       | |nexp7|             |
    +-------------+------------------------------+---------------------+
    | exp9        | |exp9|                       | |nexp9|             |
    +-------------+------------------------------+---------------------+


Error estimation
~~~~~~~~~~~~~~~~

Under the hood |Gromacs| implements some more fitting functions, namely a
function to estimate the error in time-correlated data due to Hess \ :ref:`149 <refHess2002a>`:

.. math:: \varepsilon^2(t) =
          2 \alpha\tau_1\left(1+\frac{\tau_1}{t}\left(e^{-t/\tau_1}-1\right)\right)
                + 2 (1-\alpha)\tau_2\left(1+\frac{\tau_2}{t}\left(e^{-t/\tau_2}-1\right)\right)
          :label: eqntimecorrerror

where :math:`\tau_1` and :math:`\tau_2` are time constants (with
:math:`\tau_2 \ge \tau_1`) and :math:`\alpha` usually is close to 1 (in
the fitting procedure it is enforced that :math:`0\leq\alpha\leq 1`).
This is used in :ref:`gmx analyze <gmx analyze>` for error estimation using

.. math:: \lim_{t\rightarrow\infty}\varepsilon(t) = \sigma\sqrt{\frac{2(\alpha\tau_1+(1-\alpha)\tau_2)}{T}}
          :label: eqnanalyzeerrorest

where :math:`\sigma` is the standard deviation of the data set and
:math:`T` is the total simulation time \ :ref:`149 <refHess2002a>`.

Interphase boundary demarcation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In order to determine the position and width of an interface,
Steen-Sæthre *et al.* fitted a density profile to the following function

.. math:: f(x) ~=~ \frac{a_0+a_1}{2} - \frac{a_0-a_1}{2}{\rm
          erf}\left(\frac{x-a_2}{a_3^2}\right)
          :label: eqndesprofilefunc

where :math:`a_0` and :math:`a_1` are densities of different phases,
:math:`x` is the coordinate normal to the interface, :math:`a_2` is the
position of the interface and :math:`a_3` is the width of the
interface \ :ref:`163 <refSteen-Saethre2014a>`. This is implemented
in :ref:`gmx densorder <gmx densorder>`.

Transverse current autocorrelation function
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In order to establish the transverse current autocorrelation function
(useful for computing viscosity  \ :ref:`164 <refPalmer1994a>`) the following function is
fitted:

.. math:: f(x) ~=~ e^{-\nu}\left({\rm cosh}(\omega\nu)+\frac{{\rm
          sinh}(\omega\nu)}{\omega}\right)
          :label: eqntransverseautocorrfunc

with :math:`\nu = x/(2a_0)` and :math:`\omega = \sqrt{1-a_1}`. This is
implemented in :ref:`gmx tcaf <gmx tcaf>`.

Viscosity estimation from pressure autocorrelation function
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The viscosity is a notoriously difficult property to extract from
simulations \ :ref:`149 <refHess2002a>`, :ref:`165 <refWensink2003a>`. It is *in principle*
possible to determine it by integrating the pressure autocorrelation
function \ :ref:`160 <refPSmith93c>`, however this is often hampered by
the noisy tail of the ACF. A workaround to this is fitting the ACF to
the following function \ :ref:`166 <refGuo2002b>`:

.. math:: f(t)/f(0) = (1-C) {\rm cos}(\omega t) e^{-(t/\tau_f)^{\beta_f}} + C
          e^{-(t/\tau_s)^{\beta_s}}
          :label: eqnviscestpressureautocorr

where :math:`\omega` is the frequency of rapid pressure oscillations
(mainly due to bonded forces in molecular simulations), :math:`\tau_f`
and :math:`\beta_f` are the time constant and exponent of fast
relaxation in a stretched-exponential approximation, :math:`\tau_s` and
:math:`\beta_s` are constants for slow relaxation and :math:`C` is the
pre-factor that determines the weight between fast and slow relaxation.
After a fit, the integral of the function :math:`f(t)` is used to
compute the viscosity:

.. math:: \eta = \frac{V}{k_B T}\int_0^{\infty} f(t) dt
          :label: eqncompviscosity

This equation has been applied to computing the bulk and shear
viscosity using different elements from the pressure tensor \ :ref:`167 <refFanourgakis2012a>`.
.. _rg:

Radius of gyration and distances
--------------------------------

| :ref:`gmx gyrate <gmx gyrate>`, :ref:`gmx distance <gmx distance>`, 
  :ref:`gmx mindist <gmx mindist>`, :ref:`gmx mdmat <gmx mdmat>`,
  :ref:`gmx pairdist <gmx pairdist>`, :ref:`gmx xpm2ps <gmx xpm2ps>`
| To have a rough measure for the compactness of a structure, you can
  calculate the *radius of gyration* with the program
  :ref:`gmx gyrate <gmx gyrate>` as follows:

  .. math:: R_g ~=~ \left({\frac{\sum_i \|{\bf r}_i\|^2 m_i}{\sum_i m_i}}\right)^{{\frac{1}{2}}}
            :label: eqnrg

| where :math:`m_i` is the mass of atom :math:`i` and :math:`{\bf r}_i`
  the position of atom :math:`i` with respect to the center of mass of
  the molecule. It is especially useful to characterize polymer
  solutions and proteins. The program will also provide the radius of
  gyration around the coordinate axis (or, optionally, principal axes)
  by only summing the radii components orthogonal to each axis, for
  instance

  .. math:: R_{g,x} ~=~ \left({\frac{\sum_i \left( r_{i,y}^2 + r_{i,z}^2 \right) m_i}{\sum_i m_i}}\right)^{{\frac{1}{2}}}
            :label: eqnrgaxis

Sometimes it is interesting to plot the *distance* between two atoms, or
the *minimum* distance between two groups of atoms (*e.g.*: protein
side-chains in a salt bridge). To calculate these distances between
certain groups there are several possibilities:

*   The *distance between the geometrical centers* of two groups can be
    calculated with the program :ref:`gmx distance <gmx distance>`, as explained in
    sec. :ref:`bad`.

*   The *minimum distance* between two groups of atoms during time can
    be calculated with the program :ref:`gmx mindist <gmx mindist>`. It also calculates the
    *number of contacts* between these groups within a certain radius
    :math:`r_{max}`.

*   :ref:`gmx pairdist <gmx pairdist>` is a selection-enabled version of :ref:`gmx mindist <gmx mindist>`.

*   To monitor the *minimum distances between amino acid residues*
    within a (protein) molecule, you can use the program :ref:`gmx mdmat <gmx mdmat>`. This
    minimum distance between two residues A\ :math:`_i` and
    A\ :math:`_j` is defined as the smallest distance between any pair
    of atoms (i :math:`\in` A\ :math:`_i`, j :math:`\in` A\ :math:`_j`).
    The output is a symmetrical matrix of smallest distances between all
    residues. To visualize this matrix, you can use a program such as
    ``xv``. If you want to view the axes and legend or if you want to print
    the matrix, you can convert it with :ref:`xpm2ps <gmx xpm2ps>` into a Postscript
    :numref:`Fig. %s <fig-distm>`. 

.. _fig-distm:

.. figure:: plots/distm.*
       :width: 6.50000cm

       A minimum distance matrix for a
       peptide \ :ref:`168 <refSpoel96b>`.

*   Plotting these matrices for different time-frames, one can analyze
    changes in the structure, and *e.g.* forming of salt bridges.


Long Range Van der Waals interactions
-------------------------------------

Dispersion correction
~~~~~~~~~~~~~~~~~~~~~

In this section, we derive long-range corrections due to the use of a
cut-off for Lennard-Jones or Buckingham interactions. We assume that the
cut-off is so long that the repulsion term can safely be neglected, and
therefore only the dispersion term is taken into account. Due to the
nature of the dispersion interaction (we are truncating a potential
proportional to :math:`-r^{-6}`), energy and pressure corrections are
both negative. While the energy correction is usually small, it may be
important for free energy calculations where differences between two
different Hamiltonians are considered. In contrast, the pressure
correction is very large and can not be neglected under any
circumstances where a correct pressure is required, especially for any
NPT simulations. Although it is, in principle, possible to parameterize
a force field such that the pressure is close to the desired
experimental value without correction, such a method makes the
parameterization dependent on the cut-off and is therefore undesirable.

.. _ecorr:

Energy
^^^^^^

The long-range contribution of the dispersion interaction to the virial
can be derived analytically, if we assume a homogeneous system beyond
the cut-off distance :math:`r_c`. The dispersion energy between two
particles is written as:

.. math:: V({r_{ij}}) ~=~- C_6\,{r_{ij}}^{-6}
          :label: eqnlrljEdisp

and the corresponding force is:

.. math:: \mathbf{F}_{ij} ~=~- 6\,C_6\,r_{ij}^{-8}\mathbf{r}_{ij}
          :label: eqnlrljFdisp

In a periodic system it is not easy to calculate the full potentials,
so usually a cut-off is applied, which can be abrupt or smooth. We will
call the potential and force with cut-off :math:`V_c` and
:math:`\mathbf{F}_c`. The long-range contribution to the
dispersion energy in a system with :math:`N` particles and particle
density :math:`\rho` = :math:`N/V` is:

.. math:: V_{lr} ~=~ {\frac{1}{2}}N \rho\int_0^{\infty}   4\pi r^2 g(r) \left( V(r) -V_c(r) \right) {{{\rm d}r}}
          :label: eqnenercorr

We will integrate this for the shift function, which is the most
general form of van der Waals interaction available in |Gromacs|. The
shift function has a constant difference :math:`S` from 0 to :math:`r_1`
and is 0 beyond the cut-off distance :math:`r_c`. We can integrate
:eq:`eqn. %s <eqnenercorr>`, assuming that the density in the sphere within
:math:`r_1` is equal to the global density and the radial distribution
function :math:`g(r)` is 1 beyond :math:`r_1`:

.. math:: \begin{aligned}
          V_{lr}  &=& {\frac{1}{2}}N \left(
            \rho\int_0^{r_1}  4\pi r^2 g(r) \, C_6 \,S\,{{{\rm d}r}}
          + \rho\int_{r_1}^{r_c}  4\pi r^2 \left( V(r) -V_c(r) \right) {{{\rm d}r}}
          + \rho\int_{r_c}^{\infty}  4\pi r^2 V(r) \, {{{\rm d}r}}
          \right) \\
          & = & {\frac{1}{2}}N \left(\left(\frac{4}{3}\pi \rho r_1^{3} - 1\right) C_6 \,S
          + \rho\int_{r_1}^{r_c} 4\pi r^2 \left( V(r) -V_c(r) \right) {{{\rm d}r}}
          -\frac{4}{3} \pi N \rho\, C_6\,r_c^{-3}
          \right)\end{aligned}
          :label: eqnlrljshift

where the term :math:`-1` corrects for the self-interaction. For a
plain cut-off we only need to assume that :math:`g(r)` is 1 beyond
:math:`r_c` and the correction reduces to \ :ref:`108 <refAllen87>`:

.. math:: \begin{aligned}
          V_{lr} & = & -\frac{2}{3} \pi N \rho\, C_6\,r_c^{-3}\end{aligned}
          :label: eqnlrljcorrreduced

If we consider, for example, a box of pure water, simulated with a
cut-off of 0.9 nm and a density of 1 g cm\ :math:`^{-3}` this correction
is :math:`-0.75` kJ mol\ :math:`^{-1}` per molecule.

For a homogeneous mixture we need to define an *average dispersion constant*:

.. math:: {\left< C_6 \right>}= \frac{2}{N(N-1)}\sum_i^N\sum_{j>i}^N C_6(i,j)\\
          :label: eqnavcsix

In |Gromacs|, excluded pairs of atoms do not contribute to the average.

In the case of inhomogeneous simulation systems, *e.g.* a system with a
lipid interface, the energy correction can be applied if
:math:`{\left< C_6 \right>}` for both components is comparable.

.. _virial:

Virial and pressure
^^^^^^^^^^^^^^^^^^^

The scalar virial of the system due to the dispersion interaction
between two particles :math:`i` and :math:`j` is given by:

.. math:: \Xi~=~-{\frac{1}{2}} \mathbf{r}_{ij} \cdot \mathbf{F}_{ij} ~=~ 3\,C_6\,r_{ij}^{-6}
          :label: eqnlrljdispvirial

The pressure is given by:

.. math:: P~=~\frac{2}{3\,V}\left(E_{kin} - \Xi\right)
          :label: eqnlrljpressure

The long-range correction to the virial is given by:

.. math:: \Xi_{lr} ~=~ {\frac{1}{2}}N \rho \int_0^{\infty} 4\pi r^2 g(r) (\Xi -\Xi_c) \,{{\rm d}r}
          :label: eqnlrljcorrvirial

We can again integrate the long-range contribution to the virial
assuming :math:`g(r)` is 1 beyond :math:`r_1`:

.. math:: \begin{aligned}
          \Xi_{lr}&=&	{\frac{1}{2}}N \rho \left(
              \int_{r_1}^{r_c}  4 \pi r^2 (\Xi -\Xi_c)  \,{{\rm d}r}+ \int_{r_c}^{\infty} 4 \pi r^2 3\,C_6\,{r_{ij}}^{-6}\,  {{\rm d}r}\right)	\nonumber\\
                  &=&     {\frac{1}{2}}N \rho \left(
              \int_{r_1}^{r_c} 4 \pi r^2 (\Xi -\Xi_c) \, {{\rm d}r}+ 4 \pi C_6 \, r_c^{-3} \right)\end{aligned}
          :label: eqnlrljvirialcontrib

For a plain cut-off the correction to the pressure
is \ :ref:`108 <refAllen87>`:

.. math:: P_{lr}~=~-\frac{4}{3} \pi C_6\, \rho^2 r_c^{-3}
          :label: eqnlrljpressurecorr

Using the same example of a water box, the correction to the virial is
0.75 kJ mol\ :math:`^{-1}` per molecule, the corresponding correction to
the pressure for SPC water is approximately :math:`-280` bar.

For homogeneous mixtures, we can again use the average dispersion
constant :math:`{\left< C_6 \right>}` (:eq:`eqn. %s <eqnavcsix>`):

.. math:: P_{lr}~=~-\frac{4}{3} \pi {\left< C_6 \right>}\rho^2 r_c^{-3}
          :label: eqnpcorr

For inhomogeneous systems, :eq:`eqn. %s <eqnpcorr>` can be applied under the
same restriction as holds for the energy (see sec. :ref:`ecorr`).

Lennard-Jones PME
~~~~~~~~~~~~~~~~~

In order to treat systems, using Lennard-Jones potentials, that are
non-homogeneous outside of the cut-off distance, we can instead use the
Particle-mesh Ewald method as discussed for electrostatics above. In
this case the modified Ewald equations become

.. math:: \begin{aligned}
          V &=& V_{\mathrm{dir}} + V_{\mathrm{rec}} + V_{0} \\[0.5ex]
          V_{\mathrm{dir}} &=& -\frac{1}{2} \sum_{i,j}^{N}
          \sum_{n_x}\sum_{n_y}
          \sum_{n_{z}*} \frac{C^{ij}_6 g(\beta {r}_{ij,{\bf n}})}{{r_{ij,{\bf n}}}^6}
          \end{aligned}
          :label: eqnljpmerealspace

.. math:: \begin{aligned} 
          V_{\mathrm{rec}} &=& \frac{{\pi}^{\frac{3}{2}} \beta^{3}}{2V} \sum_{m_x}\sum_{m_y}\sum_{m_{z}*}
          f(\pi | {\mathbf m} | /\beta) \times \sum_{i,j}^{N} C^{ij}_6 {\mathrm{exp}}\left[-2\pi i {\bf m}\cdot({\bf r_i}-{\bf r_j})\right] \\[0.5ex]
          V_{0} &=& -\frac{\beta^{6}}{12}\sum_{i}^{N} C^{ii}_6\end{aligned}
          :label: eqnljpmerealspace2

where :math:`{\bf m}=(m_x,m_y,m_z)`, :math:`\beta` is the parameter
determining the weight between direct and reciprocal space, and
:math:`{C^{ij}_6}` is the combined dispersion parameter for particle
:math:`i` and :math:`j`. The star indicates that terms with
:math:`i = j` should be omitted when :math:`((n_x,n_y,n_z)=(0,0,0))`,
and :math:`{\bf r}_{ij,{\bf n}}` is the real distance between the
particles. Following the derivation by
Essmann \ :ref:`15 <refEssmann95>`, the functions :math:`f` and :math:`g`
introduced above are defined as

.. math:: \begin{aligned}
          f(x)&=&1/3\left[(1-2x^2){\mathrm{exp}}(-x^2) + 2{x^3}\sqrt{\pi}\,{\mathrm{erfc}}(x) \right] \\
          g(x)&=&{\mathrm{exp}}(-x^2)(1+x^2+\frac{x^4}{2}).\end{aligned}
          :label: eqnljpmerealdistance

The above methodology works fine as long as the dispersion parameters
can be combined geometrically (:eq:`eqn. %s <eqncomb>`) in the same way as the
charges for electrostatics

.. math:: C^{ij}_{6,\mathrm{geom}} = \left(C^{ii}_6 \, C^{jj}_6\right)^{1/2}
          :label: eqnljpmegeom

For Lorentz-Berthelot combination rules (:eq:`eqn. %s <eqnlorentzberthelot>`),
the reciprocal part of this sum has to be calculated seven times due to
the splitting of the dispersion parameter according to

.. math:: C^{ij}_{6,\mathrm{L-B}} = (\sigma_i+\sigma_j)^6=\sum_{n=0}^{6} P_{n}\sigma_{i}^{n}\sigma_{j}^{(6-n)},
          :label: eqnljpmelorenztberthelot

for :math:`P_{n}` the Pascal triangle coefficients. This introduces a
non-negligible cost to the reciprocal part, requiring seven separate
FFTs, and therefore this has been the limiting factor in previous
attempts to implement LJ-PME. A solution to this problem is to use
geometrical combination rules in order to calculate an approximate
interaction parameter for the reciprocal part of the potential, yielding
a total interaction of

.. math:: \begin{aligned}
          V(r<r_c) & = & \underbrace{C^{\mathrm{dir}}_6 g(\beta r) r^{-6}}_{\mathrm{Direct \  space}} + \underbrace{C^\mathrm{recip}_{6,\mathrm{geom}} [1 - g(\beta r)] r^{-6}}_{\mathrm{Reciprocal \  space}} \nonumber \\
          &=& C^\mathrm{recip}_{6,\mathrm{geom}}r^{-6} + \left(C^{\mathrm{dir}}_6-C^\mathrm{recip}_{6,\mathrm{geom}}\right)g(\beta r)r^{-6} \\
          V(r>r_c) & = & \underbrace{C^\mathrm{recip}_{6,\mathrm{geom}} [1 - g(\beta r)] r^{-6}}_{\mathrm{Reciprocal \  space}}.\end{aligned}
          :label: eqnpmearith

This will preserve a well-defined Hamiltonian and significantly
increase the performance of the simulations. The approximation does
introduce some errors, but since the difference is located in the
interactions calculated in reciprocal space, the effect will be very
small compared to the total interaction energy. In a simulation of a
lipid bilayer, using a cut-off of 1.0 nm, the relative error in total
dispersion energy was below 0.5%. A more thorough discussion of this can
be found in :ref:`109 <refWennberg13>`.

In |Gromacs| we now perform the proper calculation of this interaction by
subtracting, from the direct-space interactions, the contribution made
by the approximate potential that is used in the reciprocal part

.. math:: V_\mathrm{dir} = C^{\mathrm{dir}}_6 r^{-6} - C^\mathrm{recip}_6 [1 - g(\beta r)] r^{-6}.
          :label: eqnljpmedirectspace

This potential will reduce to the expression in
:eq:`eqn. %s <eqnljpmerealspace>` when
:math:`C^{\mathrm{dir}}_6 = C^\mathrm{recip}_6`, and the total
interaction is given by

.. math:: \begin{aligned}
          \nonumber V(r<r_c) &=& \underbrace{C^{\mathrm{dir}}_6 r^{-6} - C^\mathrm{recip}_6 [1 - g(\beta r)] r^{-6}}_{\mathrm{Direct \  space}} + \underbrace{C^\mathrm{recip}_6 [1 - g(\beta r)] r^{-6}}_{\mathrm{Reciprocal \  space}} \\ 
          &=&C^{\mathrm{dir}}_6 r^{-6}
          \end{aligned}
          :label: eqnljpmecorr2

.. math:: \begin{aligned} 
          V(r>r_c) &=& C^\mathrm{recip}_6 [1 - g(\beta r)] r^{-6}.\end{aligned}
          :label: eqnljpmecorr3

For the case when :math:`C^{\mathrm{dir}}_6 \neq C^\mathrm{recip}_6`
this will retain an unmodified LJ force up to the cut-off, and the error
is an order of magnitude smaller than in simulations where the
direct-space interactions do not account for the approximation used in
reciprocal space. When using a VdW interaction modifier of
potential-shift, the constant

.. math:: \left(-C^{\mathrm{dir}}_6 + C^\mathrm{recip}_6 [1 - g(\beta r_c)]\right) r_c^{-6}
          :label: eqnljpmeconstant

is added to :eq:`eqn. %s <eqnljpmecorr2>` in order to ensure that the potential
is continuous at the cutoff. Note that, in the same way as
:eq:`eqn. %s <eqnljpmedirectspace>`, this degenerates into the expected
:math:`-C_6g(\beta r_c)r^{-6}_c` when :math:`C^{\mathrm{dir}}_6 =
C^\mathrm{recip}_6`. In addition to this, a long-range dispersion
correction can be applied to correct for the approximation using a
combination rule in reciprocal space. This correction assumes, as for
the cut-off LJ potential, a uniform particle distribution. But since the
error of the combination rule approximation is very small this
long-range correction is not necessary in most cases. Also note that
this homogenous correction does not correct the surface tension, which
is an inhomogeneous property.

Using LJ-PME
^^^^^^^^^^^^

As an example for using Particle-mesh Ewald summation for Lennard-Jones
interactions in |Gromacs|, specify the following lines in your :ref:`mdp` file:

::

    vdwtype          = PME
    rvdw             = 0.9
    vdw-modifier     = Potential-Shift
    rlist            = 0.9
    rcoulomb         = 0.9
    fourierspacing   = 0.12
    pme-order        = 4
    ewald-rtol-lj    = 0.001
    lj-pme-comb-rule = geometric

The same Fourier grid and interpolation order are used if both LJ-PME
and electrostatic PME are active, so the settings for
``fourierspacing`` and ``pme-order`` are common
to both. ``ewald-rtol-lj`` controls the splitting between
direct and reciprocal space in the same way as
``ewald-rtol``. In addition to this, the combination rule to
be used in reciprocal space is determined by
``lj-pme-comb-rule``. If the current force field uses
Lorentz-Berthelot combination rules, it is possible to set
``lj-pme-comb-rule = geometric`` in order to gain a
significant increase in performance for a small loss in accuracy. The
details of this approximation can be found in the section above.

Note that the use of a complete long-range dispersion correction means
that as with Coulomb PME, ``rvdw`` is now a free parameter
in the method, rather than being necessarily restricted by the
force-field parameterization scheme. Thus it is now possible to optimize
the cutoff, spacing, order and tolerance terms for accuracy and best
performance.

Naturally, the use of LJ-PME rather than LJ cut-off adds computation and
communication done for the reciprocal-space part, so for best
performance in balancing the load of parallel simulations using PME-only
ranks, more such ranks should be used. It may be possible to improve
upon the automatic load-balancing used by :ref:`mdrun <gmx mdrun>`.
Polarization
------------

Polarization can be treated by |Gromacs| by attaching shell (Drude)
particles to atoms and/or virtual sites. The energy of the shell
particle is then minimized at each time step in order to remain on the
Born-Oppenheimer surface.

Simple polarization
~~~~~~~~~~~~~~~~~~~

This is implemented as a harmonic potential with equilibrium distance 0.
The input given in the topology file is the polarizability
:math:`\alpha` (in |Gromacs| units) as follows:

::

    [ polarization ]
    ; Atom i  j  type  alpha
    1         2  1     0.001

in this case the polarizability volume is 0.001 nm\ :math:`^3` (or 1
Å\ :math:`^3`). In order to compute the harmonic force constant
:math:`k_{cs}` (where :math:`cs` stands for core-shell), the following
is used \ :ref:`45 <refMaaren2001a>`:

.. math:: k_{cs} ~=~ \frac{q_s^2}{\alpha}
          :label: eqnsimplepol

where :math:`q_s` is the charge on the shell particle.

Anharmonic polarization
~~~~~~~~~~~~~~~~~~~~~~~

For the development of the Drude force field by Roux and
McKerell \ :ref:`93 <refLopes2013a>` it was found that some particles can
overpolarize and this was fixed by introducing a higher order term in
the polarization energy:

.. math:: \begin{aligned}
          V_{pol} ~=& \frac{k_{cs}}{2} r_{cs}^2 & r_{cs} \le \delta \\
                      =& \frac{k_{cs}}{2} r_{cs}^2 + k_{hyp} (r_{cs}-\delta)^4 & r_{cs} > \delta\end{aligned}
          :label: eqnanharmpol

where :math:`\delta` is a user-defined constant that is set to 0.02 nm
for anions in the Drude force field \ :ref:`94 <refHYu2010>`. Since this
original introduction it has also been used in other atom
types \ :ref:`93 <refLopes2013a>`.

::

    [ polarization ]
    ;Atom i j    type   alpha (nm^3)    delta  khyp
    1       2       2       0.001786     0.02  16.736e8

The above force constant :math:`k_{hyp}` corresponds to
4\ :math:`\cdot`\ 10\ :math:`^8` kcal/mol/nm\ :math:`^4`, hence the
strange number.

Water polarization
~~~~~~~~~~~~~~~~~~

A special potential for water that allows anisotropic polarization of a
single shell particle \ :ref:`45 <refMaaren2001a>`.

Thole polarization
~~~~~~~~~~~~~~~~~~

Based on early work by Thole :ref:`95 <refThole81>`, Roux and coworkers
have implemented potentials for molecules like
ethanol \ :ref:`96 <refLamoureux2003a>`, :ref:`98 <refNoskov2005a>`.
Within such molecules, there are intra-molecular interactions between
shell particles, however these must be screened because full Coulomb
would be too strong. The potential between two shell particles :math:`i`
and :math:`j` is:

.. math:: V_{thole} ~=~ \frac{q_i q_j}{r_{ij}}\left[1-\left(1+\frac{{\bar{r}_{ij}}}{2}\right){\rm exp}^{-{\bar{r}_{ij}}}\right]
          :label: eqntholepol

**Note** that there is a sign error in Equation 1 of Noskov
*et al.*  :ref:`98 <refNoskov2005a>`:

.. math:: {\bar{r}_{ij}}~=~ a\frac{r_{ij}}{(\alpha_i \alpha_j)^{1/6}}
          :label: eqntholsignerror

where :math:`a` is a magic (dimensionless) constant, usually chosen to
be 2.6 \ :ref:`98 <refNoskov2005a>`; :math:`\alpha_i` and
:math:`\alpha_j` are the polarizabilities of the respective shell
particles.
Methods
-------

Exclusions and 1-4 Interactions.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Atoms within a molecule that are close by in the chain, *i.e.* atoms
that are covalently bonded, or linked by one or two atoms are called
*first neighbors, second neighbors* and *third neighbors*, respectively
(see :numref:`Fig. %s <fig-chain>`). Since the interactions of atom **i** with atoms
**i+1** and **i+2** are mainly quantum mechanical, they can not be
modeled by a Lennard-Jones potential. Instead it is assumed that these
interactions are adequately modeled by a harmonic bond term or
constraint (**i, i+1**) and a harmonic angle term (**i, i+2**). The
first and second neighbors (atoms **i+1** and **i+2**) are therefore
*excluded* from the Lennard-Jones interaction list of atom **i**; atoms
**i+1** and **i+2** are called *exclusions* of atom **i**.

.. _fig-chain:

.. figure:: plots/chain.*
   :width: 8.00000cm

   Atoms along an alkane chain.

For third neighbors, the normal Lennard-Jones repulsion is sometimes
still too strong, which means that when applied to a molecule, the
molecule would deform or break due to the internal strain. This is
especially the case for carbon-carbon interactions in a
*cis*-conformation (*e.g.* *cis*-butane). Therefore, for some of these
interactions, the Lennard-Jones repulsion has been reduced in the GROMOS
force field, which is implemented by keeping a separate list of 1-4 and
normal Lennard-Jones parameters. In other force fields, such as
OPLS \ :ref:`103 <refJorgensen88>`, the standard Lennard-Jones
parameters are reduced by a factor of two, but in that case also the
dispersion (r\ :math:`^{-6}`) and the Coulomb interaction are scaled.
|Gromacs| can use either of these methods.

Charge Groups
~~~~~~~~~~~~~

In principle, the force calculation in MD is an :math:`O(N^2)` problem.
Therefore, we apply a cut-off for non-bonded force (NBF) calculations;
only the particles within a certain distance of each other are
interacting. This reduces the cost to :math:`O(N)` (typically
:math:`100N` to :math:`200N`) of the NBF. It also introduces an error,
which is, in most cases, acceptable, except when applying the cut-off
implies the creation of charges, in which case you should consider using
the lattice sum methods provided by |Gromacs|.

Consider a water molecule interacting with another atom. If we would
apply a plain cut-off on an atom-atom basis we might include the
atom-oxygen interaction (with a charge of :math:`-0.82`) without the
compensating charge of the protons, and as a result, induce a large
dipole moment over the system. Therefore, we have to keep groups of
atoms with total charge 0 together. These groups are called *charge
groups*. Note that with a proper treatment of long-range electrostatics
(e.g. particle-mesh Ewald (sec. :ref:`pme`), keeping charge groups
together is not required.

Treatment of Cut-offs in the group scheme
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

|Gromacs| is quite flexible in treating cut-offs, which implies there can
be quite a number of parameters to set. These parameters are set in the
input file for grompp. There are two sort of parameters that affect the
cut-off interactions; you can select which type of interaction to use in
each case, and which cut-offs should be used in the neighbor searching.

For both Coulomb and van der Waals interactions there are interaction
type selectors (termed vdwtype and coulombtype) and two parameters, for
a total of six non-bonded interaction parameters. See the User Guide for
a complete description of these parameters.

In the group cut-off scheme, all of the interaction functions in
:numref:`Table %s <tab-funcparm>` require that neighbor searching be done with a
radius at least as large as the :math:`r_c` specified for the functional
form, because of the use of charge groups. The extra radius is typically
of the order of 0.25 nm (roughly the largest distance between two atoms
in a charge group plus the distance a charge group can diffuse within
neighbor list updates).

.. |CPCOP| replace:: :math:`r_c`, :math:`{\varepsilon}_{r}`
.. |CRFP|  replace:: :math:`r_c`, :math:`{\varepsilon}_{rf}`
.. |CSHFP| replace:: :math:`r_1`, :math:`r_c`, :math:`{\varepsilon}_{r}`
.. |CSWFP| replace:: :math:`r_1`, :math:`r_c`, :math:`{\varepsilon}_{r}`
.. |VPCOP| replace:: :math:`r_c`
.. |VSHFP| replace:: :math:`r_1`, :math:`r_c`
.. |VSWFP| replace:: :math:`r_1`, :math:`r_c`

.. _tab-funcparm:

.. table:: Parameters for the different functional forms of the
           non-bonded interactions.

           +----------------------------+------------+
           | Type                       | Parameters |
           +=========+==================+============+
           | Coulomb | Plain cut-off    | |CPCOP|    |
           |         +------------------+------------+
           |         | Reaction field   | |CRFP|     |
           |         +------------------+------------+
           |         | Shift function   | |CSHFP|    |
           |         +------------------+------------+ 
           |         | Switch function  | |CSWFP|    | 
           +---------+------------------+------------+
           | VdW     | Plain cut-off    | |VPCOP|    |
           |         +------------------+------------+ 
           |         | Shift function   | |VSHFP|    |
           |         +------------------+------------+ 
           |         | Switch function  | |VSWFP|    | 
           +---------+------------------+------------+

.. _virtualsites:

Virtual interaction sites
-------------------------

Virtual interaction sites (called dummy atoms in
|Gromacs| versions before 3.3) can be used in |Gromacs| in a number of ways.
We write the position of the virtual site :math:`\mathbf{r}_s` as a function
of the positions of other particles
:math:`\mathbf{r}`\ :math:`_i`: :math:`\mathbf{r}_s =
f(\mathbf{r}_1..\mathbf{r}_n)`. The virtual site, which may carry charge or be
involved in other interactions, can now be used in the force
calculation. The force acting on the virtual site must be redistributed
over the particles with mass in a consistent way. A good way to do this
can be found in ref. \ :ref:`104 <refBerendsen84b>`. We can write the
potential energy as:

.. math:: V = V(\mathbf{r}_s,\mathbf{r}_1,\ldots,\mathbf{r}_n) = V^*(\mathbf{r}_1,\ldots,\mathbf{r}_n)
          :label: eqnvsiteepot

The force on the particle :math:`i` is then:

.. math:: \mathbf{F}_i = -\frac{\partial V^*}{\partial \mathbf{r}_i} 
          = -\frac{\partial V}{\partial \mathbf{r}_i} - 
             \frac{\partial V}{\partial \mathbf{r}_s} 
             \frac{\partial \mathbf{r}_s}{\partial \mathbf{r}_i}
          = \mathbf{F}_i^{direct} + \mathbf{F}_i
          :label: eqnvsiteforce

The first term is the normal force. The second term is the force on
particle :math:`i` due to the virtual site, which can be written in
tensor notation:

.. math::  \mathbf{F}_i = \left[\begin{array}{ccc}
           {\displaystyle\frac{\partial x_s}{\partial x_i}} & {\displaystyle\frac{\partial y_s}{\partial x_i}} & {\displaystyle\frac{\partial z_s}{\partial x_i}} \\[1ex]
           {\displaystyle\frac{\partial x_s}{\partial y_i}} & {\displaystyle\frac{\partial y_s}{\partial y_i}} & {\displaystyle\frac{\partial z_s}{\partial y_i}} \\[1ex]
           {\displaystyle\frac{\partial x_s}{\partial z_i}} & {\displaystyle\frac{\partial y_s}{\partial z_i}} & {\displaystyle\frac{\partial z_s}{\partial z_i}} \end{array}\right]\mathbf{F}_{s}
           :label: eqnfvsite

where :math:`\mathbf{F}_{s}` is the force on the virtual site and
:math:`x_s`, :math:`y_s` and :math:`z_s` are the coordinates of the
virtual site. In this way, the total force and the total torque are
conserved \ :ref:`104 <refBerendsen84b>`.

The computation of the virial (:eq:`eqn. %s <eqnXi>`) is non-trivial when
virtual sites are used. Since the virial involves a summation over all
the atoms (rather than virtual sites), the forces must be redistributed
from the virtual sites to the atoms (using  :eq:`eqn. %s <eqnfvsite>`) *before*
computation of the virial. In some special cases where the forces on the
atoms can be written as a linear combination of the forces on the
virtual sites (types 2 and 3 below) there is no difference between
computing the virial before and after the redistribution of forces.
However, in the general case redistribution should be done first.

.. _fig-vsites:

.. figure:: plots/dummies.*
   :width: 15.00000cm

   The seven different types of virtual site construction. The
   constructing atoms are shown as black circles, the virtual sites in
   gray.

There are six ways to construct virtual sites from surrounding atoms in
|Gromacs|, which we classify by the number of constructing atoms. **Note**
that all site types mentioned can be constructed from types 3fd
(normalized, in-plane) and 3out (non-normalized, out of plane). However,
the amount of computation involved increases sharply along this list, so
we strongly recommended using the first adequate virtual site type that
will be sufficient for a certain purpose. :numref:`Fig. %s <fig-vsites>` depicts 6 of
the available virtual site constructions. The conceptually simplest
construction types are linear combinations:

.. math:: \mathbf{r}_s = \sum_{i=1}^N w_i \, \mathbf{r}_i
          :label: eqnvsitelincomb

The force is then redistributed using the same weights:

.. math:: \mathbf{F}_i = w_i \, \mathbf{F}_{s}
          :label: eqnvsitelincombforce

The types of virtual sites supported in |Gromacs| are given in the list
below. Constructing atoms in virtual sites can be virtual sites
themselves, but only if they are higher in the list, i.e. virtual sites
can be constructed from “particles” that are simpler virtual sites. The
virtual site velocities are reported, but not used in the integration
of the virtual site positions.

On top of an atom
~~~~~~~~~~~~~~~~~

-  This allows giving an atom multiple atom types and
   with that also assigned multiple, different bonded interactions. This
   can especially be of use in free-energy calculations.

-  The coordinates of the virtual site equal that of the constructing atom:

   .. math:: \mathbf{r}_s ~=~ \mathbf{r}_i
             :label: eqnvsite1

-  The force is moved to the constructing atom:

   .. math:: \mathbf{F}_i ~=~ \mathbf{F}_{s}
             :label: eqnvsite1force

-  The velocity of the virtual site equals that of the constructing atom:

   .. math:: \mathbf{v}_s ~=~ \mathbf{v}_i
             :label: eqnvsite1vel

As a linear combination of two atoms (:numref:`Fig. %s <fig-vsites>` 2)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  The weights are calculated as

   .. math:: w_i = 1 - a ~,~~ w_j = a
             :label: eqnvsitelin2atom

-  In this case the virtual site is on the line through atoms :math:`i`
   and :math:`j`.

-  The velocity of the virtual site is a linear combination of the
   velocities of the constructing atoms

On the line through two atoms, with a fixed distance (:numref:`Fig. %s <fig-vsites>` 2fd)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  The position is calculated as:

   .. math:: \mathbf{r}_s ~=~ \mathbf{r}_i + a \frac{ \mathbf{r}_{ij} }
                                                  { | \mathbf{r}_{ij} | }
             :label: eqnvsite2fdatom

-  In this case the virtual site is on the line through the other two
   particles at a distance of :math:`|a|` from :math:`i`. The force on
   particles :math:`i` and :math:`j` due to the force on the virtual site
   can be computed as:

   .. math:: \begin{array}{lcr}
                     \mathbf{F}_i &=& \displaystyle \mathbf{F}_{s} - \gamma ( \mathbf{F}_{is} - \mathbf{p} ) \\[1ex]
                     \mathbf{F}_j &=& \displaystyle \gamma (\mathbf{F}_{s} - \mathbf{p})      \\[1ex]
                     \end{array}
                     ~\mbox{ where }~
                     \begin{array}{c}
             \displaystyle \gamma = \frac{a}{ | \mathbf{r}_{ij} | } \\[2ex]
             \displaystyle \mathbf{p} = \frac{ \mathbf{r}_{is} \cdot \mathbf{F}_{s} }
                                   { \mathbf{r}_{is} \cdot \mathbf{r}_{is} } \mathbf{r}_{is}
             \end{array}
             :label: eqnvsite2fdforce

-  The velocity is calculated as:

   .. math:: \mathbf{v}_{s} = \mathbf{v}_{i} + \frac{a}{|\mathbf{r}_{ij}|}
                                 \left(\mathbf{v}_{ij} - \mathbf{r}_{ij}
                                    \frac{\mathbf{v}_{ij}\cdot\mathbf{r}_{ij}}
                                         {|\mathbf{r}_{ij}|^2}\right)
             :label: eqnvsite2fdatomvel

As a linear combination of three atoms (:numref:`Fig. %s <fig-vsites>` 3)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  The weights are calculated as:

   .. math:: w_i = 1 - a - b ~,~~ w_j = a ~,~~ w_k = b
             :label: eqnvsitelin3atom

-  In this case the virtual site is in the plane of the other three
   particles.

In the plane of three atoms, with a fixed distance (:numref:`Fig. %s <fig-vsites>` 3fd)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  The position is calculated as:

   .. math:: \mathbf{r}_s ~=~ \mathbf{r}_i + b \frac{ \mathbf{r}_{ijk} } { | \mathbf{r}_{ijk} | }
             ~\mbox{ where }~
             \mathbf{r}_{ijk} ~=~ \mathbf{r}_{ij} + a \mathbf{r}_{jk}
             :label: eqnvsiteplane3atom

-  In this case the virtual site is in the plane of the other three
   particles at a distance of :math:`|b|` from :math:`i`. The force on
   particles :math:`i`, :math:`j` and :math:`k` due to the force on the
   virtual site can be computed as:

   .. math:: \begin{array}{lcr}
                     \mathbf{F}_i &=& \displaystyle \mathbf{F}_{s} - \gamma ( \mathbf{F}_{is} - \mathbf{p} ) \\[1ex]
                     \mathbf{F}_j &=& \displaystyle (1-a)\gamma (\mathbf{F}_{s} - \mathbf{p})      \\[1ex]
                     \mathbf{F}_k &=& \displaystyle a \gamma (\mathbf{F}_{s} - \mathbf{p})         \\
                     \end{array}
                     ~\mbox{ where }~
                     \begin{array}{c}
             \displaystyle \gamma = \frac{b}{ | \mathbf{r}_{ij} + a \mathbf{r}_{jk} | } \\[2ex]
             \displaystyle \mathbf{p} = \frac{ \mathbf{r}_{is} \cdot \mathbf{F}_{s} }
                                   { \mathbf{r}_{is} \cdot \mathbf{r}_{is} } \mathbf{r}_{is}
             \end{array}
             :label: eqnvsiteplane3atomforce

-  The velocity is calculated as:

   .. math:: \mathbf{v}_{s} ~=~ \mathbf{v}_{i} +
                                \frac{b}{|\mathbf{r}_{ijk}|}
                                \left(\dot{\mathbf{r}}_{ijk} -
                                \mathbf{r}_{ijk}\frac{\dot{\mathbf{r}}_{ijk}\cdot\mathbf{r}_{ijk}}
                                                     {|\mathbf{r}_{ijk}|^2}\right)
             :label: eqnvsiteplane3atomvel

In the plane of three atoms, with a fixed angle and distance (:numref:`Fig. %s <fig-vsites>` 3fad)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  The position is calculated as:

   .. math:: \mathbf{r}_s ~=~ \mathbf{r}_i +
             d \cos \theta \frac{\mathbf{r}_{ij}}{ | \mathbf{r}_{ij} | } +
             d \sin \theta \frac{\mathbf{r}_\perp}{ | \mathbf{r}_\perp | }
             ~\mbox{ where }~
             \mathbf{r}_\perp ~=~ \mathbf{r}_{jk} - 
             \frac{ \mathbf{r}_{ij} \cdot \mathbf{r}_{jk} }
             { \mathbf{r}_{ij} \cdot \mathbf{r}_{ij} }
             \mathbf{r}_{ij}
             :label: eqnvsite2fadF

-  In this case the virtual site is in the plane of the other three
   particles at a distance of :math:`|d|` from :math:`i` at an angle of
   :math:`\alpha` with :math:`\mathbf{r}_{ij}`. Atom
   :math:`k` defines the plane and the direction of the angle. **Note**
   that in this case :math:`b` and :math:`\alpha` must be specified,
   instead of :math:`a` and :math:`b` (see also sec. :ref:`vsitetop`).
   The force on particles :math:`i`, :math:`j` and :math:`k` due to the
   force on the virtual site can be computed as (with
   :math:`\mathbf{r}_\perp` as defined in
   :eq:`eqn. %s <eqnvsite2fadF>`):

   .. math:: \begin{array}{c}
                     \begin{array}{lclllll}
                     \mathbf{F}_i &=& \mathbf{F}_{s} &-& 
                             \dfrac{d \cos \theta}{ | \mathbf{r}_{ij} | } \mathbf{F}_1 &+&
                             \dfrac{d \sin \theta}{ | \mathbf{r}_\perp | } \left( 
                             \dfrac{ \mathbf{r}_{ij} \cdot \mathbf{r}_{jk} }
                                  { \mathbf{r}_{ij} \cdot \mathbf{r}_{ij} } \mathbf{F}_2     +
                             \mathbf{F}_3 \right)                                \\[3ex]
                     \mathbf{F}_j &=& &&
                             \dfrac{d \cos \theta}{ | \mathbf{r}_{ij} | } \mathbf{F}_1 &-&
                             \dfrac{d \sin \theta}{ | \mathbf{r}_\perp | } \left(
                              \mathbf{F}_2 + 
                              \dfrac{ \mathbf{r}_{ij} \cdot \mathbf{r}_{jk} }
                                     { \mathbf{r}_{ij} \cdot \mathbf{r}_{ij} } \mathbf{F}_2 +
                             \mathbf{F}_3 \right)                                \\[3ex]
                     \mathbf{F}_k &=& && &&
                             \dfrac{d \sin \theta}{ | \mathbf{r}_\perp | } \mathbf{F}_2  \\[3ex]
                     \end{array}                                             \\[5ex]
                     ~\mbox{where }~
                     \mathbf{F}_1 = \mathbf{F}_{s} -
                               \dfrac{ \mathbf{r}_{ij} \cdot \mathbf{F}_{s} }
                                     { \mathbf{r}_{ij} \cdot \mathbf{r}_{ij} } \mathbf{r}_{ij}
                     ~\mbox{, }~
                     \mathbf{F}_2 = \mathbf{F}_1 -
                               \dfrac{ \mathbf{r}_\perp \cdot \mathbf{F}_{s} }
                                     { \mathbf{r}_\perp \cdot \mathbf{r}_\perp } \mathbf{r}_\perp
                     ~\mbox{and }~
                     \mathbf{F}_3 = \dfrac{ \mathbf{r}_{ij} \cdot \mathbf{F}_{s} }
                                      { \mathbf{r}_{ij} \cdot \mathbf{r}_{ij} } \mathbf{r}_\perp
             \end{array}
             :label: eqnvsite2fadFforce

-  The velocity is calculated as:

   .. math:: \mathbf{v}_{s} &= \mathbf{v}_{i} + d\cos\theta\ \frac{\delta}{\delta t}\frac{\mathbf{r}_{ij}}{|\mathbf{r}_{ij}|} +
                               d\sin\theta\ \frac{\delta}{\delta t}\frac{\mathbf{r}_{\perp}}{|\mathbf{r}_{\perp}|} \\
             ~\mbox{where}~&\\
             \frac{\delta}{\delta t}\frac{\mathbf{r}_{ij}}{|\mathbf{r}_{ij}|} &=
                 \frac{1}{|\mathbf{r}_{ij}|}\left(\mathbf{v}_{ij} - \mathbf{r}_{ij}
                 \frac{\mathbf{v}_{ij}\cdot\mathbf{r}_{ij}}{|\mathbf{r}_{ij}|^2}\right)\\
             \frac{\delta}{\delta t}\frac{\mathbf{r}_{\perp}}{|\mathbf{r}_{\perp}|} &=
                 \frac{1}{|\mathbf{r}_{\perp}|}
                 \left(\dot{\mathbf{r}}_{\perp} - \mathbf{r}_{\perp}\frac{\dot{\mathbf{r}}_{\perp}\cdot\mathbf{r}_{\perp}}{|\mathbf{r}_{\perp}|^2}\right)\\
             \dot{\mathbf{r}}_\perp &= \mathbf{v}_{jk} - \mathbf{r}_{ij}
                 \frac{|\mathbf{r}_{ij}|^2(\mathbf{v}_{ij}\cdot\mathbf{r}_{jk} + \mathbf{r}_{ij}\cdot\mathbf{v}_{jk}) -
                 (\mathbf{r}_{ij}\cdot\mathbf{r}_{jk})(2\mathbf{r}_{ij}\cdot\mathbf{v}_{ij})} {|\mathbf{r}_{ij}|^4} -
                 \frac{\mathbf{r}_{ij}\cdot\mathbf{r}_{jk}}{|\mathbf{r}_{ij}|^2}\ \mathbf{v}_{ij}
             :label: eqnvsite2fadvel

As a non-linear combination of three atoms, out of plane (:numref:`Fig. %s <fig-vsites>` 3out)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  The position is calculated as:

   .. math:: \mathbf{r}_s ~=~ \mathbf{r}_i + a \mathbf{r}_{ij} + b \mathbf{r}_{ik} +
                              c (\mathbf{r}_{ij} \times \mathbf{r}_{ik})
             :label: eqnvsitenonlin3atom

-  This enables the construction of virtual sites out of the plane of
   the other atoms. The force on particles :math:`i,j` and :math:`k` due
   to the force on the virtual site can be computed as:

   .. math:: \begin{array}{lcl}
             \mathbf{F}_j &=& \left[\begin{array}{ccc}
              a              &  -c\,z_{ik}   & c\,y_{ik}     \\[0.5ex]
              c\,z_{ik}      &   a           & -c\,x_{ik}    \\[0.5ex]
             -c\,y_{ik}      &   c\,x_{ik}   & a
             \end{array}\right]\mathbf{F}_{s}                                 \\
             \mathbf{F}_k &=& \left[\begin{array}{ccc}
              b              &   c\,z_{ij}   & -c\,y_{ij}    \\[0.5ex]
             -c\,z_{ij}      &   b           & c\,x_{ij}     \\[0.5ex]
              c\,y_{ij}      &  -c\,x_{ij}   & b
             \end{array}\right]\mathbf{F}_{s}                                 \\
             \mathbf{F}_i &=& \mathbf{F}_{s} - \mathbf{F}_j - \mathbf{F}_k
             \end{array}
             :label: eqnvsitenonlin3atomforce

-  The velocity is calculated as:

   .. math:: \mathbf{v}_{s} ~=~ \mathbf{v}_{i} + \frac{c}{|\mathbf{r}_{m}|}\left(\dot{\mathbf{r}}_{m} -
                 \mathbf{r}_{m} \frac{\dot{\mathbf{r}}_{m}\cdot\mathbf{r}_{m}}{|\mathbf{r}_{m}|^2}\right)
             :label: eqnvsitenonlin3atomvel

From four atoms, with a fixed distance, see separate :numref:`Fig. %s <fig-vsite4fdn>`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-  This construction is a bit complex,
   in particular since the previous type (4fd) could be unstable which
   forced us to introduce a more elaborate construction:

.. _fig-vsite4fdn:

.. figure:: plots/vsite-4fdn.*
      :width: 5.00000cm

      The new 4fdn virtual site construction, which is stable even when
      all constructing atoms are in the same plane.

-  The position is calculated as

      .. math::   \begin{aligned}
                  \mathbf{r}_{ja} &=& a\, \mathbf{r}_{ik} - \mathbf{r}_{ij} = a\, (\mathbf{x}_k - \mathbf{x}_i) - (\mathbf{x}_j - \mathbf{x}_i) \nonumber \\
                  \mathbf{r}_{jb} &=& b\, \mathbf{r}_{il} - \mathbf{r}_{ij} = b\, (\mathbf{x}_l - \mathbf{x}_i) - (\mathbf{x}_j - \mathbf{x}_i) \nonumber \\
                  \mathbf{r}_m &=& \mathbf{r}_{ja} \times \mathbf{r}_{jb} \nonumber \\
                  \mathbf{r}_s &=& \mathbf{r}_i + c \frac{\mathbf{r}_m}{ | \mathbf{r}_m | }
                  \end{aligned}
                  :label: eqnvsite

-   The velocity is calculated as:

   .. math:: \mathbf{v}_{s} = \mathbf{v}_{i} + \frac{c}{|\mathbf{r}_{m}|}\left(\dot{\mathbf{r}}_{m} - \mathbf{r}_{m} \frac{\dot{\mathbf{r}}_{m}\cdot\mathbf{r}_{m}}{|\mathbf{r}_{m}|^2}\right)\\
             ~\mbox{where}~&\\
             \dot{\mathbf{r}}_{m} &= \dot{\mathbf{r}}_{ja} \times \mathbf{r}_{jb} + \mathbf{r}_{ja} \times \dot{\mathbf{r}}_{jb}
             :label: eqnvsitevel

-  In this case the virtual site is at a distance of :math:`|c|` from
   :math:`i`, while :math:`a` and :math:`b` are parameters. **Note**
   that the vectors :math:`\mathbf{r}_{ik}` and :math:`\mathbf{r}_{ij}`
   are not normalized to save floating-point operations. The force on
   particles :math:`i`, :math:`j`, :math:`k` and :math:`l` due to the
   force on the virtual site are computed through chain rule derivatives
   of the construction expression. This is exact and conserves energy,
   but it does lead to relatively lengthy expressions that we do not
   include here (over 200 floating-point operations). The interested
   reader can look at the source code in ``vsite.c``. Fortunately, this
   vsite type is normally only used for chiral centers such as
   :math:`C_{\alpha}` atoms in proteins.

   The new 4fdn construct is identified with a ‘type’ value of 2 in the
   topology. The earlier 4fd type is still supported internally (‘type’
   value 1), but it should not be used for new simulations. All current
   |Gromacs| tools will automatically generate type 4fdn instead.

A linear combination of :math:`N` atoms with relative weights :math:`a_i`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  The weight for atom :math:`i` is:

   .. math:: w_i = a_i \left(\sum_{j=1}^N a_j \right)^{-1}
             :label: eqnvsiterelweight

-   There are three options for setting the weights:

   -  center of geometry: equal weights

   -  center of mass: :math:`a_i` is the mass of atom :math:`i`; when in
      free-energy simulations the mass of the atom is changed, only the
      mass of the A-state is used for the weight

   -  center of weights: :math:`a_i` is defined by the user

Bonded interactions
-------------------

Bonded interactions are based on a fixed list of atoms. They are not
exclusively pair interactions, but include 3- and 4-body interactions as
well. There are *bond stretching* (2-body), *bond angle* (3-body), and
*dihedral angle* (4-body) interactions. A special type of dihedral
interaction (called *improper dihedral*) is used to force atoms to
remain in a plane or to prevent transition to a configuration of
opposite chirality (a mirror image).

.. _bondpot:

Bond stretching
~~~~~~~~~~~~~~~

.. _harmonicbond:

Harmonic potential
^^^^^^^^^^^^^^^^^^

The bond stretching between two covalently bonded atoms :math:`i` and
:math:`j` is represented by a harmonic potential:

.. _fig-bstretch1:

.. figure:: plots/bstretch.*
   :width: 7.00000cm

   Principle of bond stretching (left), and the bond stretching
   potential (right).

.. math:: V_b~({r_{ij}}) = {\frac{1}{2}}k^b_{ij}({r_{ij}}-b_{ij})^2
          :label: eqnharmbondstretch

See also :numref:`Fig. %s <fig-bstretch1>`, with the force given by:

.. math:: \mathbf{F}_i(\mathbf{r}_{ij}) = k^b_{ij}({r_{ij}}-b_{ij}) {\frac{{\mathbf{r}_{ij}}}{{r_{ij}}}}
          :label: eqnharmbondstretchforce

.. _g96bond:

Fourth power potential
^^^^^^^^^^^^^^^^^^^^^^

In the GROMOS-96 force field \ :ref:`77 <refgromos96>`, the covalent bond
potential is, for reasons of computational efficiency, written as:

.. math:: V_b~({r_{ij}}) = \frac{1}{4}k^b_{ij}\left({r_{ij}}^2-b_{ij}^2\right)^2
          :label: eqng96bond

The corresponding force is:

.. math:: \mathbf{F}_i(\mathbf{r}_{ij}) = k^b_{ij}({r_{ij}}^2-b_{ij}^2)~\mathbf{r}_ij
          :label: eqng96bondforce

The force constants for this form of the potential are related to the
usual harmonic force constant :math:`k^{b,\mathrm{harm}}`
(sec. :ref:`bondpot`) as

.. math:: 2 k^b b_{ij}^2 = k^{b,\mathrm{harm}}
          :label: eqn96harmrelation

The force constants are mostly derived from the harmonic ones used in
GROMOS-87 :ref:`78 <refbiomos>`. Although this form is
computationally more efficient (because no square root has to be
evaluated), it is conceptually more complex. One particular disadvantage
is that since the form is not harmonic, the average energy of a single
bond is not equal to :math:`{\frac{1}{2}}kT` as it is for the normal
harmonic potential.

.. _morsebond:

Morse potential bond stretching
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For some systems that require an anharmonic bond stretching potential,
the Morse potential \ :ref:`79 <refMorse29>` between two atoms *i* and *j* is
available in |Gromacs|. This potential differs from the harmonic potential
in that it has an asymmetric potential well and a zero force at infinite
distance. The functional form is:

.. math:: \displaystyle V_{morse} (r_{ij}) = D_{ij} [1 - \exp(-\beta_{ij}(r_{ij}-b_{ij}))]^2,
          :label: eqnmorsebond

See also :numref:`Fig. %s <fig-morse>`, and the corresponding force is:

.. math:: \begin{array}{rcl}
          \displaystyle {\bf F}_{morse} ({\bf r}_{ij})&=&2 D_{ij} \beta_{ij} \exp(-\beta_{ij}(r_{ij}-b_{ij})) * \\
          \displaystyle \: & \: &[1 - \exp(-\beta_{ij}(r_{ij}-b_{ij}))] \frac{\displaystyle {\bf r}_{ij}}{\displaystyle r_{ij}},
          \end{array}
          :label: eqnmorsebondforce

where :math:`\displaystyle D_{ij}`  is the depth of the well in
kJ/mol, :math:`\displaystyle \beta_{ij}` defines the steepness of the
well (in nm\ :math:`^{-1}`), and :math:`\displaystyle b_{ij}` is the
equilibrium distance in nm. The steepness parameter
:math:`\displaystyle \beta_{ij}` can be expressed in terms of the reduced mass of the atoms *i* and
*j*, the fundamental vibration frequency :math:`\displaystyle\omega_{ij}` and the well depth :math:`\displaystyle D_{ij}`:

.. math:: \displaystyle \beta_{ij}= \omega_{ij} \sqrt{\frac{\mu_{ij}}{2 D_{ij}}}
          :label: eqnmorsefreq

and because :math:`\displaystyle \omega = \sqrt{k/\mu}`, one can
rewrite :math:`\displaystyle \beta_{ij}` in terms of the harmonic
force constant :math:`\displaystyle k_{ij}`:

.. math:: \displaystyle \beta_{ij}= \sqrt{\frac{k_{ij}}{2 D_{ij}}}
          :label: eqnbetaij

For small deviations :math:`\displaystyle (r_{ij}-b_{ij})`, one can
approximate the :math:`\displaystyle \exp`-term to first-order using a
Taylor expansion:

.. math:: \displaystyle \exp(-x) \approx 1-x
          :label: eqnexpminx

and substituting :eq:`eqn. %s <eqnbetaij>` and :eq:`eqn. %s <eqnexpminx>` in the
functional form:

.. math:: \begin{array}{rcl}
          \displaystyle V_{morse} (r_{ij})&=&D_{ij} [1 - \exp(-\beta_{ij}(r_{ij}-b_{ij}))]^2\\
          \displaystyle \:&=&D_{ij} [1 - (1 -\sqrt{\frac{k_{ij}}{2 D_{ij}}}(r_{ij}-b_{ij}))]^2\\
          \displaystyle \:&=&\frac{1}{2} k_{ij} (r_{ij}-b_{ij}))^2
          \end{array}
          :label: eqnharmfrommorse

we recover the harmonic bond stretching potential.

.. _fig-morse:

.. figure:: plots/f-morse.*
   :width: 7.00000cm

   The Morse potential well, with bond length 0.15 nm.

Cubic bond stretching potential
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Another anharmonic bond stretching potential that is slightly simpler
than the Morse potential adds a cubic term in the distance to the simple
harmonic form:

.. math:: V_b~({r_{ij}}) = k^b_{ij}({r_{ij}}-b_{ij})^2 + k^b_{ij}k^{cub}_{ij}({r_{ij}}-b_{ij})^3
          :label: eqncubicbond

A flexible water model (based on the SPC water model \ :ref:`80 <refBerendsen81>`)
including a cubic bond stretching potential for the O-H bond was
developed by Ferguson \ :ref:`81 <refFerguson95>`. This model was found to yield a
reasonable infrared spectrum. The Ferguson water model is available in
the |Gromacs| library (``flexwat-ferguson.itp``). It should be noted that the
potential is asymmetric: overstretching leads to infinitely low
energies. The integration timestep is therefore limited to 1 fs.

The force corresponding to this potential is:

.. math:: \mathbf{F}_i(\mathbf{r}_{ij}) = 2k^b_{ij}({r_{ij}}-b_{ij})~{\frac{{\mathbf{r}_{ij}}}{{r_{ij}}}}+ 3k^b_{ij}k^{cub}_{ij}({r_{ij}}-b_{ij})^2~{\frac{{\mathbf{r}_{ij}}}{{r_{ij}}}}
          :label: eqncubicbondforce

FENE bond stretching potential
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In coarse-grained polymer simulations the beads are often connected by a
FENE (finitely extensible nonlinear elastic) potential \ :ref:`82 <refWarner72>`:

.. math:: V_{\mbox{FENE}}({r_{ij}}) =
          -{\frac{1}{2}}k^b_{ij} b^2_{ij} \log\left(1 - \frac{{r_{ij}}^2}{b^2_{ij}}\right)
          :label: eqnfenebond

The potential looks complicated, but the expression for the force is
simpler:

.. math:: F_{\mbox{FENE}}(\mathbf{r}_{ij}) =
          -k^b_{ij} \left(1 - \frac{{r_{ij}}^2}{b^2_{ij}}\right)^{-1} \mathbf{r}_{ij}
          :label: eqnfenebondforce

At short distances the potential asymptotically goes to a harmonic
potential with force constant :math:`k^b`, while it diverges at distance
:math:`b`.

.. _harmonicangle:

Harmonic angle potential
~~~~~~~~~~~~~~~~~~~~~~~~

The bond-angle vibration between a triplet of atoms :math:`i` -
:math:`j` - :math:`k` is also represented by a harmonic potential on the
angle :math:`{\theta_{ijk}}`

.. _fig-angle:

.. figure:: plots/angle.*
   :width: 7.00000cm

   Principle of angle vibration (left) and the bond angle potential.

.. math:: V_a({\theta_{ijk}}) = {\frac{1}{2}}k^{\theta}_{ijk}({\theta_{ijk}}-{\theta_{ijk}}^0)^2
          :label: eqnharmangle

As the bond-angle vibration is represented by a harmonic potential, the
form is the same as the bond stretching
(:numref:`Fig. %s <fig-bstretch1>`).

The force equations are given by the chain rule:

.. math:: \begin{array}{l}
          \mathbf{F}_i    ~=~ -\displaystyle\frac{d V_a({\theta_{ijk}})}{d \mathbf{r}_i}   \\
          \mathbf{F}_k    ~=~ -\displaystyle\frac{d V_a({\theta_{ijk}})}{d \mathbf{r}_k}   \\
          \mathbf{F}_j    ~=~ -\mathbf{F}_i-\mathbf{F}_k
          \end{array}
          ~ \mbox{ ~ where ~ } ~
           {\theta_{ijk}}= \arccos \frac{(\mathbf{r}_{ij} \cdot \mathbf{r}_{kj})}{r_{ij}r_{kj}}
          :label: eqnharmangleforce

The numbering :math:`i,j,k` is in sequence of covalently bonded atoms.
Atom :math:`j` is in the middle; atoms :math:`i` and :math:`k` are at
the ends (see :numref:`Fig. %s <fig-angle>`). **Note** that in the input in topology
files, angles are given in degrees and force constants in
kJ/mol/rad\ :math:`^2`.

.. _g96angle:

Cosine based angle potential
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the GROMOS-96 force field a simplified function is used to represent
angle vibrations:

.. math:: V_a({\theta_{ijk}}) = {\frac{1}{2}}k^{\theta}_{ijk}\left(\cos({\theta_{ijk}}) - \cos({\theta_{ijk}}^0)\right)^2
          :label: eqnG96angle

where

.. math:: \cos({\theta_{ijk}}) = \frac{\mathbf{r}_{ij}\cdot\mathbf{r}_{kj}}{{r_{ij}}r_{kj}}
          :label: eqnG96anglecos

The corresponding force can be derived by partial differentiation with
respect to the atomic positions. The force constants in this function
are related to the force constants in the harmonic form
:math:`k^{\theta,\mathrm{harm}}` (:ref:`harmonicangle`) by:

.. math:: k^{\theta} \sin^2({\theta_{ijk}}^0) = k^{\theta,\mathrm{harm}}
          :label: eqnG96angleFC

In the GROMOS-96 manual there is a much more complicated conversion
formula which is temperature dependent. The formulas are equivalent at 0
K and the differences at 300 K are on the order of 0.1 to 0.2%. **Note**
that in the input in topology files, angles are given in degrees and
force constants in kJ/mol.

.. _reb:

Restricted bending potential
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The restricted bending (ReB) potential \ :ref:`83 <refMonicaGoga2013>` prevents the
bending angle :math:`\theta` from reaching the :math:`180^{\circ}`
value. In this way, the numerical instabilities due to the calculation
of the torsion angle and potential are eliminated when performing
coarse-grained molecular dynamics simulations.

To systematically hinder the bending angles from reaching the
:math:`180^{\circ}` value, the bending potential :eq:`eqn %s <eqnG96angle>` is
divided by a :math:`\sin^2\theta` factor:

.. math:: V_{\rm ReB}(\theta_i) = \frac{1}{2} k_{\theta} \frac{(\cos\theta_i - \cos\theta_0)^2}{\sin^2\theta_i}.
          :label: eqnReB

:numref:`Figure %s <fig-ReB>` shows the comparison between the ReB potential,
:eq:`%s <eqnReB>`, and the standard one :eq:`%s <eqnG96angle>`.

.. _fig-ReB:

.. figure:: plots/fig-02.*
   :width: 10.00000cm

   Bending angle potentials: cosine harmonic (solid black line), angle
   harmonic (dashed black line) and restricted bending (red) with the
   same bending constant :math:`k_{\theta}=85` kJ mol\ :math:`^{-1}` and
   equilibrium angle :math:`\theta_0=130^{\circ}`. The orange line
   represents the sum of a cosine harmonic (:math:`k =50` kJ
   mol\ :math:`^{-1}`) with a restricted bending (:math:`k =25` kJ
   mol\ :math:`^{-1}`) potential, both with
   :math:`\theta_0=130^{\circ}`.

The wall of the ReB potential is very repulsive in the region close to
:math:`180^{\circ}` and, as a result, the bending angles are kept within
a safe interval, far from instabilities. The power :math:`2` of
:math:`\sin\theta_i` in the denominator has been chosen to guarantee
this behavior and allows an elegant differentiation:

.. math:: F_{\rm ReB}(\theta_i) = \frac{2k_{\theta}}{\sin^4\theta_i}(\cos\theta_i - \cos\theta_0) (1 - \cos\theta_i\cos\theta_0) \frac{\partial \cos\theta_i}{\partial \vec r_{k}}.
          :label: eqdiffReB

Due to its construction, the restricted bending potential cannot be
used for equilibrium :math:`\theta_0` values too close to
:math:`0^{\circ}` or :math:`180^{\circ}` (from experience, at least
:math:`10^{\circ}` difference is recommended). It is very important
that, in the starting configuration, all the bending angles have to be
in the safe interval to avoid initial instabilities. This bending
potential can be used in combination with any form of torsion potential.
It will always prevent three consecutive particles from becoming
collinear and, as a result, any torsion potential will remain free of
singularities. It can be also added to a standard bending potential to
affect the angle around :math:`180^{\circ}`, but to keep its original
form around the minimum (see the orange curve in :numref:`Fig. %s <fig-ReB>`).

Urey-Bradley potential
~~~~~~~~~~~~~~~~~~~~~~

The Urey-Bradley bond-angle vibration between a triplet of atoms
:math:`i` - :math:`j` - :math:`k` is represented by a harmonic potential
on the angle :math:`{\theta_{ijk}}` and a harmonic correction term on
the distance between the atoms :math:`i` and :math:`k`. Although this
can be easily written as a simple sum of two terms, it is convenient to
have it as a single entry in the topology file and in the output as a
separate energy term. It is used mainly in the CHARMm force
field \ :ref:`84 <refBBrooks83>`. The energy is given by:

.. math:: V_a({\theta_{ijk}}) = {\frac{1}{2}}k^{\theta}_{ijk}({\theta_{ijk}}-{\theta_{ijk}}^0)^2 + {\frac{1}{2}}k^{UB}_{ijk}(r_{ik}-r_{ik}^0)^2
          :label: eqnUBAngle

The force equations can be deduced from sections :ref:`harmonicbond`
and :ref:`harmonicangle`.

Linear Angle potential
~~~~~~~~~~~~~~~~~~~~~~

The linear angle potential was designed especially for linear compounds
such as nitriles and for carbon dioxide \ :ref:`190 <refSpoel2020>`. 
It avoids the calculation of the angle per se, since the angle force
is not well-defined if the angle is 180 degrees. Rather, it computes the
deviation of a central atom in a triplet *i,j,k* from a reference position

.. math:: \mathbf{x}_j^0 = a \mathbf{x}_i + (1-a) \mathbf{x}_k

where a is defined by the bond-length *i-j* and *j-k*, in a symmetric
molecule such as carbon dioxide *a = 1/2*. If the compound has different
bond lengths :math:`b_{ij}` and :math:`b_{jk}` respectivey, we instead have

.. math:: a = \frac{b_{jk}}{b_{ij}+b_{jk}}.

If the order of atoms is changed to *k,j,i*, *a* needs to be 
replaced by *1-a*. The energy is now given by

.. math:: V_{lin} = \frac{k_{lin}}{2}\left(\mathbf{x}_j - \mathbf{x}_j^0\right)^2

with :math:`k_{lin}` the force constant. For examples, and a derivation of the forces from the energy function, see ref. \ :ref:`190 <refSpoel2020>`. 

Bond-Bond cross term
~~~~~~~~~~~~~~~~~~~~

The bond-bond cross term for three particles :math:`i, j, k` forming
bonds :math:`i-j` and :math:`k-j` is given
by \ :ref:`85 <refLawrence2003b>`:

.. math:: V_{rr'} ~=~ k_{rr'} \left(\left|\mathbf{r}_{i}-\mathbf{r}_j\right|-r_{1e}\right) \left(\left|\mathbf{r}_{k}-\mathbf{r}_j\right|-r_{2e}\right)
          :label: eqncrossbb

where :math:`k_{rr'}` is the force constant, and :math:`r_{1e}` and
:math:`r_{2e}` are the equilibrium bond lengths of the :math:`i-j` and
:math:`k-j` bonds respectively. The force associated with this potential
on particle :math:`i` is:

.. math:: \mathbf{F}_{i} = -k_{rr'}\left(\left|\mathbf{r}_{k}-\mathbf{r}_j\right|-r_{2e}\right)\frac{\mathbf{r}_i-\mathbf{r}_j}{\left|\mathbf{r}_{i}-\mathbf{r}_j\right|}
          :label: eqncrossbbforce

The force on atom :math:`k` can be obtained by swapping :math:`i` and
:math:`k` in the above equation. Finally, the force on atom :math:`j`
follows from the fact that the sum of internal forces should be zero:
:math:`\mathbf{F}_j = -\mathbf{F}_i-\mathbf{F}_k`.

Bond-Angle cross term
~~~~~~~~~~~~~~~~~~~~~

The bond-angle cross term for three particles :math:`i, j, k` forming
bonds :math:`i-j` and :math:`k-j` is given
by \ :ref:`85 <refLawrence2003b>`:

.. math:: V_{r\theta} ~=~ k_{r\theta} \left(\left|\mathbf{r}_{i}-\mathbf{r}_k\right|-r_{3e} \right) \left(\left|\mathbf{r}_{i}-\mathbf{r}_j\right|-r_{1e} + \left|\mathbf{r}_{k}-\mathbf{r}_j\right|-r_{2e}\right)
          :label: eqncrossba

where :math:`k_{r\theta}` is the force constant, :math:`r_{3e}` is the
:math:`i-k` distance, and the other constants are the same as in
:eq:`Equation %s <eqncrossbb>`. The force associated with the potential on atom
:math:`i` is:

.. math:: \mathbf{F}_{i} ~=~ -k_{r\theta}
          \left[
          \left(
          \left| \mathbf{r}_{i} - \mathbf{r}_{k}\right|
          -r_{3e}\right)
          \frac{
                \mathbf{r}_{i}-\mathbf{r}_j}
                { \left| \mathbf{r}_{i}-\mathbf{r}_{j}\right| 
                }
          + \left(
            \left| \mathbf{r}_{i}-\mathbf{r}_{j}\right|
          -r_{1e}
          + \left| \mathbf{r}_{k}-\mathbf{r}_{j}\right|
          -r_{2e}\right)
          \frac{
                \mathbf{r}_{i}-\mathbf{r}_{k}}
                {\left| \mathbf{r}_{i}-\mathbf{r}_{k}\right|
                }
          \right]
          :label: eqncrossbaforce

Quartic angle potential
~~~~~~~~~~~~~~~~~~~~~~~

For special purposes there is an angle potential that uses a fourth
order polynomial:

.. math:: V_q({\theta_{ijk}}) ~=~ \sum_{n=0}^5 C_n ({\theta_{ijk}}-{\theta_{ijk}}^0)^n
          :label: eqnquarticangle

.. _imp:

Improper dihedrals
~~~~~~~~~~~~~~~~~~

Improper dihedrals are meant to keep planar groups (*e.g.* aromatic
rings) planar, or to prevent molecules from flipping over to their
mirror images, see :numref:`Fig. %s <fig-imp>`.

.. _fig-imp:

.. figure:: plots/ring-imp.*
        :width: 4.00000cm

        Principle of improper dihedral angles. Out of plane bending for rings.
        The improper dihedral angle :math:`\xi` is defined as the angle between
        planes (i,j,k) and (j,k,l).

.. figure:: plots/subst-im.*
        :width: 3.00000cm

.. figure:: plots/tetra-im.*
        :width: 3.00000cm

        Principle of improper dihedral angles. Out of tetrahedral angle.
        The improper dihedral angle :math:`\xi` is defined
        as the angle between planes (i,j,k) and (j,k,l).

Improper dihedrals: harmonic type
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The simplest improper dihedral potential is a harmonic potential; it is
plotted in :numref:`Fig. %s <fig-imps>`.

.. math:: V_{id}(\xi_{ijkl}) = {\frac{1}{2}}k_{\xi}(\xi_{ijkl}-\xi_0)^2
          :label: eqnharmimpdihedral

Since the potential is harmonic it is discontinuous, but since the
discontinuity is chosen at 180\ :math:`^\circ` distance from
:math:`\xi_0` this will never cause problems. **Note** that in the input
in topology files, angles are given in degrees and force constants in
kJ/mol/rad\ :math:`^2`.

.. _fig-imps:

.. figure:: plots/f-imps.*
   :width: 10.00000cm

   Improper dihedral potential.

Improper dihedrals: periodic type
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This potential is identical to the periodic proper dihedral (see below).
There is a separate dihedral type for this (type 4) only to be able to
distinguish improper from proper dihedrals in the parameter section and
the output.

Proper dihedrals
~~~~~~~~~~~~~~~~

For the normal dihedral interaction there is a choice of either the
GROMOS periodic function or a function based on expansion in powers of
:math:`\cos \phi` (the so-called Ryckaert-Bellemans potential). This
choice has consequences for the inclusion of special interactions
between the first and the fourth atom of the dihedral quadruple. With
the periodic GROMOS potential a special 1-4 LJ-interaction must be
included; with the Ryckaert-Bellemans potential *for alkanes* the 1-4
interactions must be excluded from the non-bonded list. **Note:**
Ryckaert-Bellemans potentials are also used in *e.g.* the OPLS force
field in combination with 1-4 interactions. You should therefore not
modify topologies generated by :ref:`pdb2gmx <gmx pdb2gmx>` in this case.

Proper dihedrals: periodic type
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Proper dihedral angles are defined according to the IUPAC/IUB
convention, where :math:`\phi` is the angle between the :math:`ijk` and
the :math:`jkl` planes, with **zero** corresponding to the *cis*
configuration (:math:`i` and :math:`l` on the same side). There are two
dihedral function types in |Gromacs| topology files. There is the standard
type 1 which behaves like any other bonded interactions. For certain
force fields, type 9 is useful. Type 9 allows multiple potential
functions to be applied automatically to a single dihedral in the
``[ dihedral ]`` section when multiple parameters are
defined for the same atomtypes in the ``[ dihedraltypes ]``
section.

.. _fig-pdihf:

.. figure:: plots/f-dih.*
   :width: 7.00000cm

   Principle of proper dihedral angle (left, in *trans* form) and the
   dihedral angle potential (right).

.. math:: V_d(\phi_{ijkl}) = k_{\phi}(1 + \cos(n \phi - \phi_s))
          :label: eqnperiodicpropdihedral

Proper dihedrals: Ryckaert-Bellemans function
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

| For alkanes, the following proper dihedral potential is often used
  (see :numref:`Fig. %s <fig-rbdih>`):

  .. math:: V_{rb}(\phi_{ijkl}) = \sum_{n=0}^5 C_n( \cos(\psi ))^n,
            :label: eqnRBproperdihedral

|  where :math:`\psi = \phi - 180^\circ`.
| **Note:** A conversion from one convention to another can be achieved
  by multiplying every coefficient :math:`\displaystyle C_n` by
  :math:`\displaystyle (-1)^n`.

An example of constants for :math:`C` is given in :numref:`Table %s <tab-crb>`.

.. _tab-crb:

.. table:: 
    Constants for Ryckaert-Bellemans potential (\ :math:`\mathrm{kJ mol}^{-1}`).
    :widths: auto
    :align: center

    +-------------+-------+-------------+--------+-------------+-------+
    | :math:`C_0` | 9.28  | :math:`C_2` | -13.12 | :math:`C_4` | 26.24 |
    +-------------+-------+-------------+--------+-------------+-------+
    | :math:`C_1` | 12.16 | :math:`C_3` | -3.06  | :math:`C_5` | -31.5 |
    +-------------+-------+-------------+--------+-------------+-------+


.. _fig-rbdih:

.. figure:: plots/f-rbs.*
   :width: 8.00000cm

   Ryckaert-Bellemans dihedral potential.

(**Note:** The use of this potential implies exclusion of LJ
interactions between the first and the last atom of the dihedral, and
:math:`\psi` is defined according to the “polymer convention”
(:math:`\psi_{trans}=0`).)

| The RB dihedral function can also be used to include Fourier dihedrals
  (see below):

  .. math:: V_{rb} (\phi_{ijkl}) ~=~ \frac{1}{2} \left[F_1(1+\cos(\phi)) + F_2(
            1-\cos(2\phi)) + F_3(1+\cos(3\phi)) + F_4(1-\cos(4\phi))\right]
            :label: eqnRBproperdihedralFourier

| Because of the equalities :math:`\cos(2\phi) = 2\cos^2(\phi) - 1`,
  :math:`\cos(3\phi) = 4\cos^3(\phi) - 3\cos(\phi)` and
  :math:`\cos(4\phi) = 8\cos^4(\phi) - 8\cos^2(\phi) + 1` one can
  translate the OPLS parameters to Ryckaert-Bellemans parameters as
  follows:

  .. math:: \displaystyle
            \begin{array}{rcl}
            \displaystyle C_0&=&F_2 + \frac{1}{2} (F_1 + F_3)\\
            \displaystyle C_1&=&\frac{1}{2} (- F_1 + 3 \, F_3)\\
            \displaystyle C_2&=& -F_2 + 4 \, F_4\\
            \displaystyle C_3&=&-2 \, F_3\\
            \displaystyle C_4&=&-4 \, F_4\\
            \displaystyle C_5&=&0
            \end{array}
            :label: eqnoplsRBconversion

| with OPLS parameters in protein convention and RB parameters in
  polymer convention (this yields a minus sign for the odd powers of
  cos\ :math:`(\phi)`).
| **Note:** Mind the conversion from **kcal mol**\ :math:`^{-1}` for
  literature OPLS and RB parameters to **kJ mol**\ :math:`^{-1}` in
  |Gromacs|.

Proper dihedrals: Fourier function
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

| The OPLS potential function is given as the first three
   :ref:`86 <refJorgensen1996>` or four \ :ref:`87 <refRobertson2015a>`
  cosine terms of a Fourier series. In |Gromacs| the four term function is
  implemented:

  .. math:: V_{F} (\phi_{ijkl}) ~=~ \frac{1}{2} \left[C_1(1+\cos(\phi)) + C_2(
            1-\cos(2\phi)) + C_3(1+\cos(3\phi)) + C_4(1-\cos(4\phi))\right],
            :label: eqnfourierproperdihedral

| Internally, |Gromacs| uses the Ryckaert-Bellemans code to compute
  Fourier dihedrals (see above), because this is more efficient.
| **Note:** Mind the conversion from *k*\ cal mol\ :math:`^{-1}` for
  literature OPLS parameters to **kJ mol**\ :math:`^{-1}` in |Gromacs|.

Proper dihedrals: Restricted torsion potential
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In a manner very similar to the restricted bending potential (see
:ref:`ReB`), a restricted torsion/dihedral potential is introduced:

.. math:: V_{\rm ReT}(\phi_i) = \frac{1}{2} k_{\phi} \frac{(\cos\phi_i - \cos\phi_0)^2}{\sin^2\phi_i}
          :label: eqnReT

with the advantages of being a function of :math:`\cos\phi` (no
problems taking the derivative of :math:`\sin\phi`) and of keeping the
torsion angle at only one minimum value. In this case, the factor
:math:`\sin^2\phi` does not allow the dihedral angle to move from the
[:math:`-180^{\circ}`:0] to [0::math:`180^{\circ}`] interval, i.e. it
cannot have maxima both at :math:`-\phi_0` and :math:`+\phi_0` maxima,
but only one of them. For this reason, all the dihedral angles of the
starting configuration should have their values in the desired angles
interval and the equilibrium :math:`\phi_0` value should not be too
close to the interval limits (as for the restricted bending potential,
described in :ref:`ReB`, at least :math:`10^{\circ}` difference is
recommended).

Proper dihedrals: Combined bending-torsion potential
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When the four particles forming the dihedral angle become collinear
(this situation will never happen in atomistic simulations, but it can
occur in coarse-grained simulations) the calculation of the torsion
angle and potential leads to numerical instabilities. One way to avoid
this is to use the restricted bending potential (see :ref:`ReB`) that
prevents the dihedral from reaching the :math:`180^{\circ}` value.

Another way is to disregard any effects of the dihedral becoming
ill-defined, keeping the dihedral force and potential calculation
continuous in entire angle range by coupling the torsion potential (in a
cosine form) with the bending potentials of the adjacent bending angles
in a unique expression:

.. math:: V_{\rm CBT}(\theta_{i-1}, \theta_i, \phi_i) = k_{\phi} \sin^3\theta_{i-1} \sin^3\theta_{i} \sum_{n=0}^4 { a_n \cos^n\phi_i}.
          :label: eqnCBT

This combined bending-torsion (CBT) potential has been proposed
by \ :ref:`88 <refBulacuGiessen2005>` for polymer melt simulations and is
extensively described in \ :ref:`83 <refMonicaGoga2013>`.

This potential has two main advantages:

-  it does not only depend on the dihedral angle :math:`\phi_i` (between
   the :math:`i-2`, :math:`i-1`, :math:`i` and :math:`i+1` beads) but
   also on the bending angles :math:`\theta_{i-1}` and :math:`\theta_i`
   defined from three adjacent beads (:math:`i-2`, :math:`i-1` and
   :math:`i`, and :math:`i-1`, :math:`i` and :math:`i+1`, respectively).
   The two :math:`\sin^3\theta` pre-factors, tentatively suggested
   by \ :ref:`89 <refScottScheragator1966>` and theoretically discussed by
   \ :ref:`90 <refPaulingBond>`, cancel the torsion potential and force when either of the two
   bending angles approaches the value of :math:`180^\circ`.

-  its dependence on :math:`\phi_i` is expressed through a polynomial in
   :math:`\cos\phi_i` that avoids the singularities in
   :math:`\phi=0^\circ` or :math:`180^\circ` in calculating the
   torsional force.

These two properties make the CBT potential well-behaved for MD
simulations with weak constraints on the bending angles or even for
steered / non-equilibrium MD in which the bending and torsion angles
suffer major modifications. When using the CBT potential, the bending
potentials for the adjacent :math:`\theta_{i-1}` and :math:`\theta_i`
may have any form. It is also possible to leave out the two angle
bending terms (:math:`\theta_{i-1}` and :math:`\theta_{i}`) completely.
:numref:`Fig. %s <fig-CBT>` illustrates the difference between a torsion potential
with and without the :math:`\sin^{3}\theta` factors (blue and gray
curves, respectively).

.. _fig-CBT:

.. figure:: plots/fig-04.*
   :width: 10.00000cm

   Blue: surface plot of the combined bending-torsion potential
   (:eq:`%s <eqnCBT>` with :math:`k = 10` kJ mol\ :math:`^{-1}`,
   :math:`a_0=2.41`, :math:`a_1=-2.95`, :math:`a_2=0.36`,
   :math:`a_3=1.33`) when, for simplicity, the bending angles behave the
   same (:math:`\theta_1=\theta_2=\theta`). Gray: the same torsion
   potential without the :math:`\sin^{3}\theta` terms
   (Ryckaert-Bellemans type). :math:`\phi` is the dihedral angle.

Additionally, the derivative of :math:`V_{CBT}` with respect to the
Cartesian variables is straightforward:

.. math:: \frac{\partial V_{\rm CBT}(\theta_{i-1},\theta_i,\phi_i)} {\partial \vec r_{l}} = \frac{\partial V_{\rm CBT}}{\partial \theta_{i-1}} \frac{\partial \theta_{i-1}}{\partial \vec r_{l}} +
          \frac{\partial V_{\rm CBT}}{\partial \theta_{i  }} \frac{\partial \theta_{i  }}{\partial \vec r_{l}} +
          \frac{\partial V_{\rm CBT}}{\partial \phi_{i    }} \frac{\partial \phi_{i    }}{\partial \vec r_{l}}
          :label: eqnforcecbt

The CBT is based on a cosine form without multiplicity, so it can only
be symmetrical around :math:`0^{\circ}`. To obtain an asymmetrical
dihedral angle distribution (e.g. only one maximum in
[:math:`-180^{\circ}`::math:`180^{\circ}`] interval), a standard torsion
potential such as harmonic angle or periodic cosine potentials should be
used instead of a CBT potential. However, these two forms have the
inconveniences of the force derivation (:math:`1/\sin\phi`) and of the
alignment of beads (:math:`\theta_i` or
:math:`\theta_{i-1} = 0^{\circ}, 180^{\circ}`). Coupling such
non-\ :math:`\cos\phi` potentials with :math:`\sin^3\theta` factors does
not improve simulation stability since there are cases in which
:math:`\theta` and :math:`\phi` are simultaneously :math:`180^{\circ}`.
The integration at this step would be possible (due to the cancelling of
the torsion potential) but the next step would be singular
(:math:`\theta` is not :math:`180^{\circ}` and :math:`\phi` is very
close to :math:`180^{\circ}`).

Tabulated bonded interaction functions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

| For full flexibility, any functional shape can be used for bonds,
  angles and dihedrals through user-supplied tabulated functions. The
  functional shapes are:

  .. math:: \begin{aligned}
            V_b(r_{ij})      &=& k \, f^b_n(r_{ij}) \\
            V_a({\theta_{ijk}})       &=& k \, f^a_n({\theta_{ijk}}) \\
            V_d(\phi_{ijkl}) &=& k \, f^d_n(\phi_{ijkl})\end{aligned}
            :label: eqntabuöatedbond

| where :math:`k` is a force constant in units of energy and :math:`f`
  is a cubic spline function; for details see :ref:`cubicspline`. For
  each interaction, the force constant :math:`k` and the table number
  :math:`n` are specified in the topology. There are two different types
  of bonds, one that generates exclusions (type 8) and one that does not
  (type 9). For details see :numref:`Table %s <tab-topfile2>`. The table files are
  supplied to the :ref:`mdrun <gmx mdrun>` program. After the table file name an
  underscore, the letter “b” for bonds, “a” for angles or “d” for
  dihedrals and the table number must be appended. For example, a
  tabulated bond with :math:`n=0` can be read from the file
  table\_b0.xvg. Multiple tables can be supplied simply by adding files
  with different values of :math:`n`, and are applied to the appropriate
  bonds, as specified in the topology (:numref:`Table %s <tab-topfile2>`). The format
  for the table files is three fixed-format columns of any suitable
  width. These columns must contain :math:`x`, :math:`f(x)`,
  :math:`-f'(x)`, and the values of :math:`x` should be uniformly
  spaced. Requirements for entries in the topology are given
  in :numref:`Table %s <tab-topfile2>`. The setup of the tables is as follows:
| **bonds**: :math:`x` is the distance in nm. For distances beyond the
  table length, :ref:`mdrun <gmx mdrun>` will quit with an error message.
| **angles**: :math:`x` is the angle in degrees. The table should go
  from 0 up to and including 180 degrees; the derivative is taken in
  degrees.
| **dihedrals**: :math:`x` is the dihedral angle in degrees. The table
  should go from -180 up to and including 180 degrees; the IUPAC/IUB
  convention is used, *i.e.* zero is cis, the derivative is taken in
  degrees.
Force field
-----------

A force field is built up from two distinct components:

-  The set of equations (called the *potential functions*) used to
   generate the potential energies and their derivatives, the forces.
   These are described in detail in the previous chapter.

-  The parameters used in this set of equations. These are not given in
   this manual, but in the data files corresponding to your |Gromacs|
   distribution.

Within one set of equations various sets of parameters can be used. Care
must be taken that the combination of equations and parameters form a
consistent set. It is in general dangerous to make *ad hoc* changes in a
subset of parameters, because the various contributions to the total
force are usually interdependent. This means in principle that every
change should be documented, verified by comparison to experimental data
and published in a peer-reviewed journal before it can be used.

|Gromacs| |version| includes several force fields, and
additional ones are available on the website. If you do not know which
one to select we recommend GROMOS-96 for united-atom setups and
OPLS-AA/L for all-atom parameters. That said, we describe the available
options in some detail.

All-hydrogen force field
~~~~~~~~~~~~~~~~~~~~~~~~

The GROMOS-87-based all-hydrogen force field is almost identical to the
normal GROMOS-87 force field, since the extra hydrogens have no
Lennard-Jones interaction and zero charge. The only differences are in
the bond angle and improper dihedral angle terms. This force field is
only useful when you need the exact hydrogen positions, for instance for
distance restraints derived from NMR measurements. When citing this
force field please read the previous paragraph.

GROMOS-96
~~~~~~~~~

|Gromacs| supports the GROMOS-96 force fields \ :ref:`77 <refgromos96>`. All
parameters for the 43A1, 43A2 (development, improved alkane dihedrals),
45A3, 53A5, and 53A6 parameter sets are included. All standard building
blocks are included and topologies can be built automatically by
:ref:`pdb2gmx <gmx pdb2gmx>`.

The GROMOS-96 force field is a further development of the GROMOS-87
force field. It has improvements over the GROMOS-87 force field for
proteins and small molecules. **Note** that the sugar parameters present
in 53A6 do correspond to those published in 2004\ :ref:`110 <refOostenbrink2004>`,
which are different from those present in 45A4, which is not
included in |Gromacs| at this time. The 45A4 parameter set corresponds to
a later revision of these parameters. The GROMOS-96 force field is not,
however, recommended for use with long alkanes and lipids. The GROMOS-96
force field differs from the GROMOS-87 force field in a few respects:

-  the force field parameters

-  the parameters for the bonded interactions are not linked to atom
   types

-  a fourth power bond stretching potential (:ref:`G96bond`)

-  an angle potential based on the cosine of the angle
   (:ref:`G96angle`)

There are two differences in implementation between |Gromacs| and
GROMOS-96 which can lead to slightly different results when simulating
the same system with both packages:

-  in GROMOS-96 neighbor searching for solvents is performed on the
   first atom of the solvent molecule. This is not implemented in
   |Gromacs|, but the difference with searching by centers of charge
   groups is very small

-  the virial in GROMOS-96 is molecule-based. This is not implemented in
   |Gromacs|, which uses atomic virials

The GROMOS-96 force field was parameterized with a Lennard-Jones cut-off
of 1.4 nm, so be sure to use a Lennard-Jones cut-off
(``rvdw``) of at least 1.4. A larger cut-off is possible
because the Lennard-Jones potential and forces are almost zero beyond
1.4 nm.

GROMOS-96 files
^^^^^^^^^^^^^^^

|Gromacs| can read and write GROMOS-96 coordinate and trajectory files.
These files should have the extension :ref:`g96`. Such a file
can be a GROMOS-96 initial/final configuration file, a coordinate
trajectory file, or a combination of both. The file is fixed format; all
floats are written as 15.9, and as such, files can get huge. |Gromacs|
supports the following data blocks in the given order:

-  Header block:

   ::

       TITLE (mandatory)

-  Frame blocks:

   ::

       TIMESTEP (optional)
       POSITION/POSITIONRED (mandatory)
       VELOCITY/VELOCITYRED (optional)
       BOX (optional)

See the GROMOS-96 manual \ :ref:`77 <refgromos96>` for a complete
description of the blocks. **Note** that all |Gromacs| programs can read
compressed (.Z) or gzipped (.gz) files.

OPLS/AA
~~~~~~~

AMBER
~~~~~

|Gromacs| provides native support for the following AMBER force fields:

-  AMBER94 \ :ref:`111 <refCornell1995>`

-  AMBER96 \ :ref:`112 <refKollman1996>`

-  AMBER99 \ :ref:`113 <refWang2000>`

-  AMBER99SB \ :ref:`114 <refHornak2006>`

-  AMBER99SB-ILDN \ :ref:`115 <refLindorff2010>`

-  AMBER03 \ :ref:`116 <refDuan2003>`

-  AMBERGS \ :ref:`117 <refGarcia2002>`

.. _charmmff:

CHARMM
~~~~~~

|Gromacs| supports the CHARMM force field for
proteins \ :ref:`118 <refmackerell04>`, :ref:`119 <refmackerell98>`,
lipids \ :ref:`120 <reffeller00>` and nucleic
acids \ :ref:`121 <reffoloppe00>`, :ref:`122 <refMac2000>`. The protein
parameters (and to some extent
the lipid and nucleic acid parameters) were thoroughly tested – both by
comparing potential energies between the port and the standard parameter
set in the CHARMM molecular simulation package, as well by how the
protein force field behaves together with |Gromacs|-specific techniques
such as virtual sites (enabling long time steps) recently
implemented \ :ref:`123 <refLarsson10>` – and the details and results are
presented in the paper by Bjelkmar et al. \ :ref:`124 <refBjelkmar10>`.
The nucleic acid parameters, as well as the ones for HEME, were
converted and tested by Michel Cuendet.

When selecting the CHARMM force field in
:ref:`pdb2gmx <gmx pdb2gmx>` the default option
is to use CMAP (for torsional correction map).
To exclude CMAP, use ``-nocmap``. The basic form of the CMAP
term implemented in |Gromacs| is a function of the :math:`\phi` and
:math:`\psi` backbone torsion angles. This term is defined in the
``rtp`` file by a ``[ cmap ]`` statement at the
end of each residue supporting CMAP. The following five atom names
define the two torsional angles. Atoms 1-4 define :math:`\phi`, and
atoms 2-5 define :math:`\psi`. The corresponding atom types are then
matched to the correct CMAP type in the ``cmap.itp`` file
that contains the correction maps.

A port of the CHARMM36 force field for use with |Gromacs| is also
available at `the MacKerell lab webpage <http://mackerell.umaryland.edu/charmm_ff.shtml#gromacs>`_.

For branched polymers or other topologies not supported by
:ref:`pdb2gmx <gmx pdb2gmx>`, it is possible to
use TopoTools \ :ref:`125 <refkohlmeyer2016>` to generate a |Gromacs| top
file.

.. _cgforcefields:

Coarse-grained force fields
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Coarse-graining is a systematic way of reducing the
number of degrees of freedom representing a system of interest. To
achieve this, typically whole groups of atoms are represented by single
beads and the coarse-grained force fields describes their effective
interactions. Depending on the choice of parameterization, the
functional form of such an interaction can be complicated and often
tabulated potentials are used.

Coarse-grained models are designed to reproduce certain properties of a
reference system. This can be either a full atomistic model or even
experimental data. Depending on the properties to reproduce there are
different methods to derive such force fields. An incomplete list of
methods is given below:

-  Conserving free energies

   -  Simplex method

   -  MARTINI force field (see next section)

-  Conserving distributions (like the radial distribution function),
   so-called structure-based coarse-graining

   -  (iterative) Boltzmann inversion

   -  Inverse Monte Carlo

-  Conversing forces

   -  Force matching

Note that coarse-grained potentials are state dependent (e.g.
temperature, density,...) and should be re-parametrized depending on the
system of interest and the simulation conditions. This can for example
be done using the Versatile Object-oriented Toolkit for Coarse-Graining
Applications (VOTCA) (**???**). The package was designed to assists in
systematic coarse-graining, provides implementations for most of the
algorithms mentioned above and has a well tested interface to |Gromacs|.
It is available as open source and further information can be found at
`www.votca.org <http://www.votca.org>`_.

MARTINI
~~~~~~~

The MARTINI force field is a coarse-grain parameter set that allows for
the construction of many systems, including proteins and membranes.

PLUM
~~~~

The PLUM force field :ref:`126 <refbereau12>` is an example of a solvent-free
protein-membrane model for which the membrane was derived from
structure-based coarse-graining \ :ref:`127 <refwang_jpcb10>`. A |Gromacs|
implementation can be found at
`code.google.com/p/plumx <http://code.google.com/p/plumx/>`__.

Restraints
----------

Special potentials are used for imposing restraints on the motion of the
system, either to avoid disastrous deviations, or to include knowledge
from experimental data. In either case they are not really part of the
force field and the reliability of the parameters is not important. The
potential forms, as implemented in |Gromacs|, are mentioned just for the
sake of completeness. Restraints and constraints refer to quite
different algorithms in |Gromacs|.

.. _positionrestraint:

Position restraints
~~~~~~~~~~~~~~~~~~~

These are used to restrain particles to fixed reference positions
:math:`\mathbf{R}_i`. They can be used during
equilibration in order to avoid drastic rearrangements of critical parts
(*e.g.* to restrain motion in a protein that is subjected to large
solvent forces when the solvent is not yet equilibrated). Another
application is the restraining of particles in a shell around a region
that is simulated in detail, while the shell is only approximated
because it lacks proper interaction from missing particles outside the
shell. Restraining will then maintain the integrity of the inner part.
For spherical shells, it is a wise procedure to make the force constant
depend on the radius, increasing from zero at the inner boundary to a
large value at the outer boundary. This feature has not, however, been
implemented in |Gromacs|.

The following form is used:

.. math:: V_{pr}(\mathbf{r}_i) = {\frac{1}{2}}k_{pr}|\mathbf{r}_i-\mathbf{R}_i|^2
          :label: eqnposrestform

The potential is plotted in :numref:`Fig. %s <fig-positionrestraint>`.

.. _fig-positionrestraint:

.. figure:: plots/f-pr.*
   :width: 8.00000cm

   Position restraint potential.

The potential form can be rewritten without loss of generality as:

.. math:: V_{pr}(\mathbf{r}_i) = {\frac{1}{2}} \left[ k_{pr}^x (x_i-X_i)^2 ~{\hat{\bf x}} + k_{pr}^y (y_i-Y_i)^2 ~{\hat{\bf y}} + k_{pr}^z (z_i-Z_i)^2 ~{\hat{\bf z}}\right]
         :label: eqnposrestgeneral

Now the forces are:

.. math:: \begin{array}{rcl}
          F_i^x &=& -k_{pr}^x~(x_i - X_i) \\
          F_i^y &=& -k_{pr}^y~(y_i - Y_i) \\
          F_i^z &=& -k_{pr}^z~(z_i - Z_i)
          \end{array}
          :label: eqnposrestforce

Using three different force constants the position restraints can be
turned on or off in each spatial dimension; this means that atoms can be
harmonically restrained to a plane or a line. Position restraints are
applied to a special fixed list of atoms. Such a list is usually
generated by the :ref:`pdb2gmx <gmx pdb2gmx>` program.

.. _reference-manual-position-restraints:

Note that position restraints make the potential dependent on absolute
coordinates in space. Therefore, in general the pressure (and virial)
is not well defined, as the pressure is the derivative of the free-energy
of the system with respect to the volume. When the reference coordinates
are scaled along with the system, which can be selected with the mdp option
:mdp-value:`refcoord-scaling=all`, the pressure and virial are well defined.

Flat-bottomed position restraints
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Flat-bottomed position restraints can be used to restrain particles to
part of the simulation volume. No force acts on the restrained particle
within the flat-bottomed region of the potential, however a harmonic
force acts to move the particle to the flat-bottomed region if it is
outside it. It is possible to apply normal and flat-bottomed position
restraints on the same particle (however, only with the same reference
position :math:`\mathbf{R}_i`). The following general
potential is used (:numref:`Figure %s <fig-fbposres>` A):

.. math:: V_\mathrm{fb}(\mathbf{r}_i) = \frac{1}{2}k_\mathrm{fb} [d_g(\mathbf{r}_i;\mathbf{R}_i) - r_\mathrm{fb}]^2\,H[d_g(\mathbf{r}_i;\mathbf{R}_i) - r_\mathrm{fb}],
          :label: eqnflatbottomposrest

where :math:`\mathbf{R}_i` is the reference position,
:math:`r_\mathrm{fb}` is the distance from the center with a flat
potential, :math:`k_\mathrm{fb}` the force constant, and :math:`H` is
the Heaviside step function. The distance
:math:`d_g(\mathbf{r}_i;\mathbf{R}_i)` from
the reference position depends on the geometry :math:`g` of the
flat-bottomed potential.

.. _fig-fbposres:

.. figure:: plots/fbposres.*
   :width: 10.00000cm

   Flat-bottomed position restraint potential. (A) Not inverted, (B)
   inverted.

| The following geometries for the flat-bottomed potential are
  supported:

| **Sphere** (:math:`g =1`): The
  particle is kept in a sphere of given radius. The force acts towards
  the center of the sphere. The following distance calculation is used:

  .. math:: d_g(\mathbf{r}_i;\mathbf{R}_i) = | \mathbf{r}_i-\mathbf{R}_i |
            :label: eqnfbsphereposrest

| **Cylinder** (:math:`g=6,7,8`): The particle is kept in a cylinder of
  given radius parallel to the :math:`x` (:math:`g=6`), :math:`y`
  (:math:`g=7`), or :math:`z`-axis (:math:`g=8`). For backwards
  compatibility, setting :math:`g=2` is mapped to :math:`g=8` in the
  code so that old :ref:`tpr` files and topologies work. The
  force from the flat-bottomed potential acts towards the axis of the
  cylinder. The component of the force parallel to the cylinder axis is
  zero. For a cylinder aligned along the :math:`z`-axis:

  .. math:: d_g(\mathbf{r}_i;\mathbf{R}_i) = \sqrt{ (x_i-X_i)^2 + (y_i - Y_i)^2 }
            :label: eqnfbcylinderposrest

| **Layer** (:math:`g=3,4,5`): The particle is kept in a layer defined
  by the thickness and the normal of the layer. The layer normal can be
  parallel to the :math:`x`, :math:`y`, or :math:`z`-axis. The force
  acts parallel to the layer normal.

  .. math:: d_g(\mathbf{r}_i;\mathbf{R}_i) = |x_i-X_i|, \;\;\;\mbox{or}\;\;\; 
            d_g(\mathbf{r}_i;\mathbf{R}_i) = |y_i-Y_i|, \;\;\;\mbox{or}\;\;\; 
            d_g(\mathbf{r}_i;\mathbf{R}_i) = |z_i-Z_i|.
            :label: eqnfblayerposrest

It is possible to apply multiple independent flat-bottomed position
restraints of different geometry on one particle. For example, applying
a cylinder and a layer in :math:`z` keeps a particle within a disk.
Applying three layers in :math:`x`, :math:`y`, and :math:`z` keeps the
particle within a cuboid.

In addition, it is possible to invert the restrained region with the
unrestrained region, leading to a potential that acts to keep the
particle *outside* of the volume defined by
:math:`\mathbf{R}_i`, :math:`g`, and
:math:`r_\mathrm{fb}`. That feature is switched on by defining a
negative :math:`r_\mathrm{fb}` in the topology. The following potential
is used (:numref:`Figure %s <fig-fbposres>` B):

.. math:: V_\mathrm{fb}^{\mathrm{inv}}(\mathbf{r}_i) = \frac{1}{2}k_\mathrm{fb}
          [d_g(\mathbf{r}_i;\mathbf{R}_i) - | r_\mathrm{fb} | ]^2\,
          H[ -(d_g(\mathbf{r}_i;\mathbf{R}_i) - | r_\mathrm{fb} | )].
          :label: eqninvertrest

Angle restraints
~~~~~~~~~~~~~~~~

These are used to restrain the angle between two pairs of particles or
between one pair of particles and the :math:`z`-axis. The functional
form is similar to that of a proper dihedral. For two pairs of atoms:

.. math:: V_{ar}(\mathbf{r}_i,\mathbf{r}_j,\mathbf{r}_k,\mathbf{r}_l)
                  = k_{ar}(1 - \cos(n (\theta - \theta_0))
                  )
          ,~~~~\mbox{where}~~
          \theta = \arccos\left(\frac{\mathbf{r}_j -\mathbf{r}_i}{\|\mathbf{r}_j -\mathbf{r}_i\|}
          \cdot \frac{\mathbf{r}_l -\mathbf{r}_k}{\|\mathbf{r}_l -\mathbf{r}_k\|} \right)
          :label: eqnanglerest

For one pair of atoms and the :math:`z`-axis:

.. math:: V_{ar}(\mathbf{r}_i,\mathbf{r}_j) = k_{ar}(1 - \cos(n (\theta - \theta_0))
                  )
          ,~~~~\mbox{where}~~
          \theta = \arccos\left(\frac{\mathbf{r}_j -\mathbf{r}_i}{\|\mathbf{r}_j -\mathbf{r}_i\|}
          \cdot \left( \begin{array}{c} 0 \\ 0 \\ 1 \\ \end{array} \right) \right)
          :label: eqnanglerestzaxis

A multiplicity (:math:`n`) of 2 is useful when you do not want to
distinguish between parallel and anti-parallel vectors. The equilibrium
angle :math:`\theta` should be between 0 and 180 degrees for
multiplicity 1 and between 0 and 90 degrees for multiplicity 2.

.. _dihedralrestraint:

Dihedral restraints
~~~~~~~~~~~~~~~~~~~

These are used to restrain the dihedral angle :math:`\phi` defined by
four particles as in an improper dihedral (sec. :ref:`imp`) but with a
slightly modified potential. Using:

.. math:: \phi' = \left(\phi-\phi_0\right) ~{\rm MOD}~ 2\pi
          :label: eqndphi

where :math:`\phi_0` is the reference angle, the potential is defined
as:

.. math:: V_{dihr}(\phi') ~=~ \left\{
          \begin{array}{lcllll}
          {\frac{1}{2}}k_{dihr}(\phi'-\Delta\phi)^2      
                          &\mbox{for}&     \|\phi'\| & >   & \Delta\phi       \\[1.5ex]
          0               &\mbox{for}&     \|\phi'\| & \le & \Delta\phi       \\[1.5ex]
          \end{array}\right.
          :label: eqndihre

where :math:`\Delta\phi` is a user defined angle and :math:`k_{dihr}`
is the force constant. **Note** that in the input in topology files,
angles are given in degrees and force constants in
kJ/mol/rad\ :math:`^2`.

.. _distancerestraint:

Distance restraints
~~~~~~~~~~~~~~~~~~~

Distance restraints add a penalty to the potential when the distance
between specified pairs of atoms exceeds a threshold value. They are
normally used to impose experimental restraints from, for instance,
experiments in nuclear magnetic resonance (NMR), on the motion of the
system. Thus, MD can be used for structure refinement using NMR data. In
|Gromacs| there are three ways to impose restraints on pairs of atoms:

-  Simple harmonic restraints: use ``[ bonds ]`` type 6 (see sec. :ref:`excl`).

-  Piecewise linear/harmonic restraints: ``[ bonds ]`` type
   10.

-  Complex NMR distance restraints, optionally with pair, time and/or
   ensemble averaging.

The last two options will be detailed now.

The potential form for distance restraints is quadratic below a
specified lower bound and between two specified upper bounds, and linear
beyond the largest bound (see :numref:`Fig. %s <fig-dist>`).

.. math:: V_{dr}(r_{ij}) ~=~ \left\{
          \begin{array}{lcllllll}
          {\frac{1}{2}}k_{dr}(r_{ij}-r_0)^2      
                          &\mbox{for}&     &     & r_{ij} & < & r_0       \\[1.5ex]
          0               &\mbox{for}& r_0 & \le & r_{ij} & < & r_1       \\[1.5ex]
          {\frac{1}{2}}k_{dr}(r_{ij}-r_1)^2      
                          &\mbox{for}& r_1 & \le & r_{ij} & < & r_2       \\[1.5ex]
          {\frac{1}{2}}k_{dr}(r_2-r_1)(2r_{ij}-r_2-r_1)  
                          &\mbox{for}& r_2 & \le & r_{ij} &   &
          \end{array}\right.
          :label: eqndisre

.. _fig-dist:

.. figure:: plots/f-dr.*
   :width: 8.00000cm

   Distance Restraint potential.

The forces are

.. math:: \mathbf{F}_i~=~ \left\{
          \begin{array}{lcllllll}
          -k_{dr}(r_{ij}-r_0)\frac{\mathbf{r}_{ij}}{r_{ij}} 
                          &\mbox{for}&     &     & r_{ij} & < & r_0       \\[1.5ex]
          0               &\mbox{for}& r_0 & \le & r_{ij} & < & r_1       \\[1.5ex]
          -k_{dr}(r_{ij}-r_1)\frac{\mathbf{r}_{ij}}{r_{ij}} 
                          &\mbox{for}& r_1 & \le & r_{ij} & < & r_2       \\[1.5ex]
          -k_{dr}(r_2-r_1)\frac{\mathbf{r}_{ij}}{r_{ij}}    
                          &\mbox{for}& r_2 & \le & r_{ij} &   &
          \end{array} \right.
          :label: eqndisreforce

For restraints not derived from NMR data, this functionality will
usually suffice and a section of ``[ bonds ]`` type 10 can be used to apply individual
restraints between pairs of atoms, see :ref:`topfile`. For applying
restraints derived from NMR measurements, more complex functionality
might be required, which is provided through the ``[ distance_restraints ]`` section and is
described below.

Time averaging
^^^^^^^^^^^^^^

Distance restraints based on instantaneous distances can potentially
reduce the fluctuations in a molecule significantly. This problem can be
overcome by restraining to a *time averaged*
distance \ :ref:`91 <refTorda89>`. The forces with time averaging are:

.. math:: \mathbf{F}_i~=~ \left\{
          \begin{array}{lcllllll}
          -k^a_{dr}(\bar{r}_{ij}-r_0)\frac{\mathbf{r}_{ij}}{r_{ij}}   
                          &\mbox{for}&     &     & \bar{r}_{ij} & < & r_0 \\[1.5ex]
          0               &\mbox{for}& r_0 & \le & \bar{r}_{ij} & < & r_1 \\[1.5ex]
          -k^a_{dr}(\bar{r}_{ij}-r_1)\frac{\mathbf{r}_{ij}}{r_{ij}}   
                          &\mbox{for}& r_1 & \le & \bar{r}_{ij} & < & r_2 \\[1.5ex]
          -k^a_{dr}(r_2-r_1)\frac{\mathbf{r}_{ij}}{r_{ij}}    
                          &\mbox{for}& r_2 & \le & \bar{r}_{ij} &   &
          \end{array} \right.
          :label: eqntimeaveragerest

where :math:`\bar{r}_{ij}` is given by an exponential running average
with decay time :math:`\tau`:

.. math:: \bar{r}_{ij} ~=~ < r_{ij}^{-3} >^{-1/3}
          :label: eqnrav

The force constant :math:`k^a_{dr}` is switched on slowly to compensate
for the lack of history at the beginning of the simulation:

.. math:: k^a_{dr} = k_{dr} \left(1-\exp\left(-\frac{t}{\tau}\right)\right)
          :label: eqnforceconstantswitch

Because of the time averaging, we can no longer speak of a distance
restraint potential.

This way an atom can satisfy two incompatible distance restraints *on
average* by moving between two positions. An example would be an amino
acid side-chain that is rotating around its :math:`\chi` dihedral angle,
thereby coming close to various other groups. Such a mobile side chain
can give rise to multiple NOEs that can not be fulfilled by a single
structure.

The computation of the time averaged distance in the
:ref:`mdrun <gmx mdrun>` program is done in the following fashion:

.. math:: \begin{array}{rcl}
          \overline{r^{-3}}_{ij}(0)       &=& r_{ij}(0)^{-3}      \\
          \overline{r^{-3}}_{ij}(t)       &=& \overline{r^{-3}}_{ij}(t-\Delta t)~\exp{\left(-\frac{\Delta t}{\tau}\right)} + r_{ij}(t)^{-3}\left[1-\exp{\left(-\frac{\Delta t}{\tau}\right)}\right]
          \end{array}
          :label: eqnravdisre

When a pair is within the bounds, it can still feel a force because the
time averaged distance can still be beyond a bound. To prevent the
protons from being pulled too close together, a mixed approach can be
used. In this approach, the penalty is zero when the instantaneous
distance is within the bounds, otherwise the violation is the square
root of the product of the instantaneous violation and the time averaged
violation:

.. math:: \mathbf{F}_i~=~ \left\{
          \begin{array}{lclll}
          k^a_{dr}\sqrt{(r_{ij}-r_0)(\bar{r}_{ij}-r_0)}\frac{\mathbf{r}_{ij}}{r_{ij}}   
              & \mbox{for} & r_{ij} < r_0 & \mbox{and} & \bar{r}_{ij} < r_0 \\[1.5ex]
          -k^a _{dr} \,
            \mbox{min}\left(\sqrt{(r_{ij}-r_1)(\bar{r}_{ij}-r_1)},r_2-r_1\right)
            \frac{\mathbf{r}_{ij}}{r_{ij}}   
              & \mbox{for} & r_{ij} > r_1 & \mbox{and} & \bar{r}_{ij} > r_1 \\[1.5ex]
          0               &\mbox{otherwise}
          \end{array} \right.
          :label: eqntimeaverageviolation

Averaging over multiple pairs
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Sometimes it is unclear from experimental data which atom pair gives
rise to a single NOE, in other occasions it can be obvious that more
than one pair contributes due to the symmetry of the system, *e.g.* a
methyl group with three protons. For such a group, it is not possible to
distinguish between the protons, therefore they should all be taken into
account when calculating the distance between this methyl group and
another proton (or group of protons). Due to the physical nature of
magnetic resonance, the intensity of the NOE signal is inversely
proportional to the sixth power of the inter-atomic distance. Thus, when
combining atom pairs, a fixed list of :math:`N` restraints may be taken
together, where the apparent “distance” is given by:

.. math:: r_N(t) = \left [\sum_{n=1}^{N} \bar{r}_{n}(t)^{-6} \right]^{-1/6}
          :label: eqnrsix

where we use :math:`r_{ij}` or :eq:`eqn. %s <eqnrav>` for the
:math:`\bar{r}_{n}`. The :math:`r_N` of the instantaneous and
time-averaged distances can be combined to do a mixed restraining, as
indicated above. As more pairs of protons contribute to the same NOE
signal, the intensity will increase, and the summed “distance” will be
shorter than any of its components due to the reciprocal summation.

There are two options for distributing the forces over the atom pairs.
In the conservative option, the force is defined as the derivative of
the restraint potential with respect to the coordinates. This results in
a conservative potential when time averaging is not used. The force
distribution over the pairs is proportional to :math:`r^{-6}`. This
means that a close pair feels a much larger force than a distant pair,
which might lead to a molecule that is “too rigid.” The other option is
an equal force distribution. In this case each pair feels :math:`1/N` of
the derivative of the restraint potential with respect to :math:`r_N`.
The advantage of this method is that more conformations might be
sampled, but the non-conservative nature of the forces can lead to local
heating of the protons.

It is also possible to use *ensemble averaging* using multiple (protein)
molecules. In this case the bounds should be lowered as in:

.. math:: \begin{array}{rcl}
          r_1     &~=~&   r_1 * M^{-1/6}  \\
          r_2     &~=~&   r_2 * M^{-1/6}
          \end{array}
          :label: eqnrestforceensembleaverage

where :math:`M` is the number of molecules. The |Gromacs| preprocessor
:ref:`grompp <gmx grompp>` can do this automatically when the appropriate
option is given. The resulting “distance” is then used to calculate the
scalar force according to:

.. math:: \mathbf{F}_i~=~\left\{
          \begin{array}{rcl}
          ~& 0 \hspace{4cm}  & r_{N} < r_1         \\
           & k_{dr}(r_{N}-r_1)\frac{\mathbf{r}_{ij}}{r_{ij}} & r_1 \le r_{N} < r_2 \\
           & k_{dr}(r_2-r_1)\frac{\mathbf{r}_{ij}}{r_{ij}}    & r_{N} \ge r_2 
          \end{array} \right.
          :label: eqnrestscalarforce

where :math:`i` and :math:`j` denote the atoms of all the pairs that
contribute to the NOE signal.

Using distance restraints
^^^^^^^^^^^^^^^^^^^^^^^^^

A list of distance restrains based on NOE data can be added to a
molecule definition in your topology file, like in the following
example:

::

    [ distance_restraints ]
    ; ai   aj   type   index   type'      low     up1     up2     fac
    10     16      1       0       1      0.0     0.3     0.4     1.0
    10     28      1       1       1      0.0     0.3     0.4     1.0
    10     46      1       1       1      0.0     0.3     0.4     1.0
    16     22      1       2       1      0.0     0.3     0.4     2.5
    16     34      1       3       1      0.0     0.5     0.6     1.0

In this example a number of features can be found. In columns ai and aj
you find the atom numbers of the particles to be restrained. The type
column should always be 1. As explained in  :ref:`distancerestraint`,
multiple distances can contribute to a single NOE signal. In the
topology this can be set using the index column. In our example, the
restraints 10-28 and 10-46 both have index 1, therefore they are treated
simultaneously. An extra requirement for treating restraints together is
that the restraints must be on successive lines, without any other
intervening restraint. The type’ column will usually be 1, but can be
set to 2 to obtain a distance restraint that will never be time- and
ensemble-averaged; this can be useful for restraining hydrogen bonds.
The columns ``low``, ``up1``, and
``up2`` hold the values of :math:`r_0`, :math:`r_1`, and
:math:`r_2` from  :eq:`eqn. %s <eqndisre>`. In some cases it
can be useful to have different force constants for some restraints;
this is controlled by the column ``fac``. The force constant
in the parameter file is multiplied by the value in the column
``fac`` for each restraint. Information for each restraint
is stored in the energy file and can be processed and plotted with
:ref:`gmx nmr`.

Orientation restraints
~~~~~~~~~~~~~~~~~~~~~~

This section describes how orientations between vectors, as measured in
certain NMR experiments, can be calculated and restrained in MD
simulations. The presented refinement methodology and a comparison of
results with and without time and ensemble averaging have been
published \ :ref:`92 <refHess2003>`.

Theory
^^^^^^

In an NMR experiment, orientations of vectors can be measured when a
molecule does not tumble completely isotropically in the solvent. Two
examples of such orientation measurements are residual dipolar couplings
(between two nuclei) or chemical shift anisotropies. An observable for a
vector :math:`\mathbf{r}_i` can be written as follows:

.. math:: \delta_i = \frac{2}{3} \mbox{tr}({{\mathbf S}}{{\mathbf D}}_i)
          :label: eqnorrestvector

where :math:`{{\mathbf S}}` is the dimensionless order tensor of the
molecule. The tensor :math:`{{\mathbf D}}_i` is given by:

.. math:: {{\mathbf D}}_i = \frac{c_i}{\|\mathbf{r}_i\|^\alpha} \left(
          \begin{array}{lll}
          3 x x - 1 & 3 x y     & 3 x z     \\
          3 x y     & 3 y y - 1 & 3 y z     \\
          3 x z     & 3 y z     & 3 z z - 1 \\
          \end{array} \right)
          :label: eqnorientdef

.. math:: \mbox{with:} \quad 
          x=\frac{r_{i,x}}{\|\mathbf{r}_i\|}, \quad
          y=\frac{r_{i,y}}{\|\mathbf{r}_i\|}, \quad 
          z=\frac{r_{i,z}}{\|\mathbf{r}_i\|}
          :label: eqnorientdef2

For a dipolar coupling :math:`\mathbf{r}_i` is the vector
connecting the two nuclei, :math:`\alpha=3` and the constant :math:`c_i`
is given by:

.. math:: c_i = \frac{\mu_0}{4\pi} \gamma_1^i \gamma_2^i \frac{\hbar}{4\pi}
          :label: eqnorrestconstant

where :math:`\gamma_1^i` and :math:`\gamma_2^i` are the gyromagnetic
ratios of the two nuclei.

The order tensor is symmetric and has trace zero. Using a rotation
matrix :math:`{\mathbf T}` it can be transformed into the following
form:

.. math:: {\mathbf T}^T {{\mathbf S}}{\mathbf T} = s \left( \begin{array}{ccc}
          -\frac{1}{2}(1-\eta) & 0                    & 0 \\
          0                    & -\frac{1}{2}(1+\eta) & 0 \\
          0                    & 0                    & 1
          \end{array} \right)
          :label: eqnorresttensor

where :math:`-1 \leq s \leq 1` and :math:`0 \leq \eta \leq 1`.
:math:`s` is called the order parameter and :math:`\eta` the asymmetry
of the order tensor :math:`{{\mathbf S}}`. When the molecule tumbles
isotropically in the solvent, :math:`s` is zero, and no orientational
effects can be observed because all :math:`\delta_i` are zero.

Calculating orientations in a simulation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For reasons which are explained below, the :math:`{{\mathbf D}}`
matrices are calculated which respect to a reference orientation of the
molecule. The orientation is defined by a rotation matrix
:math:`{{\mathbf R}}`, which is needed to least-squares fit the current
coordinates of a selected set of atoms onto a reference conformation.
The reference conformation is the starting conformation of the
simulation. In case of ensemble averaging, which will be treated later,
the structure is taken from the first subsystem. The calculated
:math:`{{\mathbf D}}_i^c` matrix is given by:

.. math:: {{\mathbf D}}_i^c(t) = {{\mathbf R}}(t) {{\mathbf D}}_i(t) {{\mathbf R}}^T(t)
          :label: eqnDrot

The calculated orientation for vector :math:`i` is given by:

.. math:: \delta^c_i(t) = \frac{2}{3} \mbox{tr}({{\mathbf S}}(t){{\mathbf D}}_i^c(t))
          :label: eqnDrotvector

The order tensor :math:`{{\mathbf S}}(t)` is usually unknown. A
reasonable choice for the order tensor is the tensor which minimizes the
(weighted) mean square difference between the calculated and the
observed orientations:

.. math:: MSD(t) = \left(\sum_{i=1}^N w_i\right)^{-1} \sum_{i=1}^N w_i (\delta_i^c (t) -\delta_i^{exp})^2
          :label: eqnSmsd

To properly combine different types of measurements, the unit of
:math:`w_i` should be such that all terms are dimensionless. This means
the unit of :math:`w_i` is the unit of :math:`\delta_i` to the power
:math:`-2`. **Note** that scaling all :math:`w_i` with a constant factor
does not influence the order tensor.

Time averaging
^^^^^^^^^^^^^^

Since the tensors :math:`{{\mathbf D}}_i` fluctuate rapidly in time,
much faster than can be observed in an experiment, they should be
averaged over time in the simulation. However, in a simulation the time
and the number of copies of a molecule are limited. Usually one can not
obtain a converged average of the :math:`{{\mathbf D}}_i` tensors over
all orientations of the molecule. If one assumes that the average
orientations of the :math:`\mathbf{r}_i` vectors within
the molecule converge much faster than the tumbling time of the
molecule, the tensor can be averaged in an axis system that rotates with
the molecule, as expressed by :eq:`equation %s <eqnDrot>`). The time-averaged
tensors are calculated using an exponentially decaying memory function:

.. math:: {{\mathbf D}}^a_i(t) = \frac{\displaystyle
          \int_{u=t_0}^t {{\mathbf D}}^c_i(u) \exp\left(-\frac{t-u}{\tau}\right)\mbox{d} u
          }{\displaystyle
          \int_{u=t_0}^t \exp\left(-\frac{t-u}{\tau}\right)\mbox{d} u
          }
          :label: eqnorresttimeaverage

Assuming that the order tensor :math:`{{\mathbf S}}` fluctuates slower
than the :math:`{{\mathbf D}}_i`, the time-averaged orientation can be
calculated as:

.. math:: \delta_i^a(t) = \frac{2}{3} \mbox{tr}({{\mathbf S}}(t) {{\mathbf D}}_i^a(t))
          :label: eqnorresttimeaveorient

where the order tensor :math:`{{\mathbf S}}(t)` is calculated using
expression :eq:`%s <eqnSmsd>` with :math:`\delta_i^c(t)` replaced by
:math:`\delta_i^a(t)`.

Restraining
^^^^^^^^^^^

The simulated structure can be restrained by applying a force
proportional to the difference between the calculated and the
experimental orientations. When no time averaging is applied, a proper
potential can be defined as:

.. math:: V = \frac{1}{2} k \sum_{i=1}^N w_i (\delta_i^c (t) -\delta_i^{exp})^2
          :label: eqnorrestsimrest

where the unit of :math:`k` is the unit of energy. Thus the effective
force constant for restraint :math:`i` is :math:`k w_i`. The forces are
given by minus the gradient of :math:`V`. The force
:math:`\mathbf{F}\!_i` working on vector
:math:`\mathbf{r}_i` is:

.. math:: \begin{aligned}
          \mathbf{F}\!_i(t) 
          & = & - \frac{\mbox{d} V}{\mbox{d}\mathbf{r}_i} \\
          & = & -k w_i (\delta_i^c (t) -\delta_i^{exp}) \frac{\mbox{d} \delta_i (t)}{\mbox{d}\mathbf{r}_i} \\
          & = & -k w_i (\delta_i^c (t) -\delta_i^{exp})
          \frac{2 c_i}{\|\mathbf{r}\|^{2+\alpha}} \left(2 {{\mathbf R}}^T {{\mathbf S}}{{\mathbf R}}\mathbf{r}_i - \frac{2+\alpha}{\|\mathbf{r}\|^2} \mbox{tr}({{\mathbf R}}^T {{\mathbf S}}{{\mathbf R}}\mathbf{r}_i \mathbf{r}_i^T) \mathbf{r}_i \right)\end{aligned}
          :label: eqnorrestsimrestforce

Ensemble averaging
^^^^^^^^^^^^^^^^^^

Ensemble averaging can be applied by simulating a system of :math:`M`
subsystems that each contain an identical set of orientation restraints.
The systems only interact via the orientation restraint potential which
is defined as:

.. math:: V = M \frac{1}{2} k \sum_{i=1}^N w_i 
          \langle \delta_i^c (t) -\delta_i^{exp} \rangle^2
          :label: eqnorrestensembleave

The force on vector :math:`\mathbf{r}_{i,m}` in subsystem
:math:`m` is given by:

.. math:: \mathbf{F}\!_{i,m}(t) = - \frac{\mbox{d} V}{\mbox{d}\mathbf{r}_{i,m}} =
          -k w_i \langle \delta_i^c (t) -\delta_i^{exp} \rangle \frac{\mbox{d} \delta_{i,m}^c (t)}{\mbox{d}\mathbf{r}_{i,m}}
          :label: eqnorrestensaveforce 

Time averaging
^^^^^^^^^^^^^^

When using time averaging it is not possible to define a potential. We
can still define a quantity that gives a rough idea of the energy stored
in the restraints:

.. math:: V = M \frac{1}{2} k^a \sum_{i=1}^N w_i 
          \langle \delta_i^a (t) -\delta_i^{exp} \rangle^2
          :label: eqntimeavepot

The force constant :math:`k_a` is switched on slowly to compensate for
the lack of history at times close to :math:`t_0`. It is exactly
proportional to the amount of average that has been accumulated:

.. math:: k^a =
          k \, \frac{1}{\tau}\int_{u=t_0}^t \exp\left(-\frac{t-u}{\tau}\right)\mbox{d} u
          :label: eqntimeaveforceswitch

What really matters is the definition of the force. It is chosen to be
proportional to the square root of the product of the time-averaged and
the instantaneous deviation. Using only the time-averaged deviation
induces large oscillations. The force is given by:

.. math:: \mathbf{F}\!_{i,m}(t) =
          \left\{ \begin{array}{ll}
          0 & \quad \mbox{for} \quad a\, b \leq 0 \\
          \displaystyle
          k^a w_i \frac{a}{|a|} \sqrt{a\, b} \, \frac{\mbox{d} \delta_{i,m}^c (t)}{\mbox{d}\mathbf{r}_{i,m}}
          & \quad \mbox{for} \quad a\, b > 0 
          \end{array}
          \right.
          :label: eqntimeaveforce

.. math:: \begin{aligned}
          a &=& \langle \delta_i^a (t) -\delta_i^{exp} \rangle \\
          b &=& \langle \delta_i^c (t) -\delta_i^{exp} \rangle\end{aligned}
          :label: eqntimeaveforce2

Using orientation restraints
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Orientation restraints can be added to a molecule definition in the
topology file in the section ``[ orientation_restraints ]``.
Here we give an example section containing five N-H residual dipolar
coupling restraints:

::

    [ orientation_restraints ]
    ; ai   aj  type  exp.  label  alpha    const.     obs.   weight
    ;                                Hz      nm^3       Hz    Hz^-2
      31   32     1     1      3      3     6.083    -6.73      1.0
      43   44     1     1      4      3     6.083    -7.87      1.0
      55   56     1     1      5      3     6.083    -7.13      1.0
      65   66     1     1      6      3     6.083    -2.57      1.0
      73   74     1     1      7      3     6.083    -2.10      1.0

The unit of the observable is Hz, but one can choose any other unit. In
columns ``ai`` and ``aj`` you find the atom numbers of the particles to be
restrained. The ``type`` column should always be 1. The ``exp.`` column denotes
the experiment number, starting at 1. For each experiment a separate
order tensor :math:`{{\mathbf S}}` is optimized. The label should be a
unique number larger than zero for each restraint. The ``alpha`` column
contains the power :math:`\alpha` that is used in
:eq:`equation %s <eqnorientdef>`) to calculate the orientation. The ``const.`` column
contains the constant :math:`c_i` used in the same equation. The
constant should have the unit of the observable times
nm\ :math:`^\alpha`. The column ``obs.`` contains the observable, in any
unit you like. The last column contains the weights :math:`w_i`; the
unit should be the inverse of the square of the unit of the observable.

Some parameters for orientation restraints can be specified in the
:ref:`grompp <gmx grompp>` :ref:`mdp` file, for a study of the effect of different
force constants and averaging times and ensemble averaging see \ :ref:`92 <refHess2003>`.
Information for each restraint is stored in the energy
file and can be processed and plotted with :ref:`gmx nmr`.

.. raw:: latex

    \clearpage


Non-bonded interactions
-----------------------

Non-bonded interactions in |Gromacs| are pair-additive:

.. math:: V(\mathbf{r}_1,\ldots \mathbf{r}_N) = \sum_{i<j}V_{ij}(\mathbf{r}_{ij});
          :label: eqnnbinteractions1

.. math:: \mathbf{F}_i = -\sum_j \frac{dV_{ij}(r_{ij})}{dr_{ij}} \frac{\mathbf{r}_{ij}}{r_{ij}}
          :label: eqnnbinteractions2

Since the potential only depends on the scalar distance, interactions
will be centro-symmetric, i.e. the vectorial partial force on particle
:math:`i` from the pairwise interaction :math:`V_{ij}(r_{ij})` has the
opposite direction of the partial force on particle :math:`j`. For
efficiency reasons, interactions are calculated by loops over
interactions and updating both partial forces rather than summing one
complete nonbonded force at a time. The non-bonded interactions contain
a repulsion term, a dispersion term, and a Coulomb term. The repulsion
and dispersion term are combined in either the Lennard-Jones (or 6-12
interaction), or the Buckingham (or exp-6 potential). In addition,
(partially) charged atoms act through the Coulomb term.

.. _lj:

The Lennard-Jones interaction
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The Lennard-Jones potential :math:`V_{LJ}` between two atoms equals:

.. math:: V_{LJ}({r_{ij}}) =  \frac{C_{ij}^{(12)}}{{r_{ij}}^{12}} -
                              \frac{C_{ij}^{(6)}}{{r_{ij}}^6}
          :label: eqnnblj

See also :numref:`Fig. %s <fig-lj>` The parameters :math:`C^{(12)}_{ij}` and
:math:`C^{(6)}_{ij}` depend on pairs of *atom types*; consequently they
are taken from a matrix of LJ-parameters. In the Verlet cut-off scheme,
the potential is shifted by a constant such that it is zero at the
cut-off distance.

.. _fig-lj:

.. figure:: plots/f-lj.*
   :width: 8.00000cm

   The Lennard-Jones interaction.

The force derived from this potential is:

.. math:: \mathbf{F}_i(\mathbf{r}_{ij}) = -\left( 12~\frac{C_{ij}^{(12)}}{{r_{ij}}^{13}} -
                                    6~\frac{C_{ij}^{(6)}}{{r_{ij}}^7} \right) {\frac{{\mathbf{r}_{ij}}}{{r_{ij}}}}
          :label: eqnljforce

The LJ potential may also be written in the following form:

.. math:: V_{LJ}(\mathbf{r}_{ij}) = 4\epsilon_{ij}\left(\left(\frac{\sigma_{ij}} {{r_{ij}}}\right)^{12}
          - \left(\frac{\sigma_{ij}}{{r_{ij}}}\right)^{6} \right)
          :label: eqnsigeps

In constructing the parameter matrix for the non-bonded LJ-parameters,
two types of combination rules can be used within |Gromacs|, only
geometric averages (type 1 in the input section of the force-field
file):

.. math:: \begin{array}{rcl}
          C_{ij}^{(6)}    &=& \left({C_{ii}^{(6)} \, C_{jj}^{(6)}}\right)^{1/2}    \\
          C_{ij}^{(12)}   &=& \left({C_{ii}^{(12)} \, C_{jj}^{(12)}}\right)^{1/2}
          \end{array}
          :label: eqncomb

or, alternatively the Lorentz-Berthelot rules can be used. An
arithmetic average is used to calculate :math:`\sigma_{ij}`, while a
geometric average is used to calculate :math:`\epsilon_{ij}` (type 2):

.. math:: \begin{array}{rcl}
          \sigma_{ij}   &=& \frac{1}{ 2}(\sigma_{ii} + \sigma_{jj})        \\
          \epsilon_{ij} &=& \left({\epsilon_{ii} \, \epsilon_{jj}}\right)^{1/2}
          \end{array}
          :label: eqnlorentzberthelot

finally an geometric average for both parameters can be used (type 3):

.. math:: \begin{array}{rcl}
          \sigma_{ij}   &=& \left({\sigma_{ii} \, \sigma_{jj}}\right)^{1/2}        \\
          \epsilon_{ij} &=& \left({\epsilon_{ii} \, \epsilon_{jj}}\right)^{1/2}
          \end{array}
          :label: eqnnbgeometricaverage

This last rule is used by the OPLS force field.

Buckingham potential
~~~~~~~~~~~~~~~~~~~~

The Buckingham potential has a more flexible and realistic repulsion
term than the Lennard-Jones interaction, but is also more expensive to
compute. The potential form is:

.. math:: V_{bh}({r_{ij}}) = A_{ij} \exp(-B_{ij} {r_{ij}}) -
                             \frac{C_{ij}}{{r_{ij}}^6}
          :label: eqnnbbuckingham

.. _fig-bham:

.. figure:: plots/f-bham.*
   :width: 8.00000cm

   The Buckingham interaction.

See also :numref:`Fig. %s <fig-bham>`. The force derived from this is:

.. math:: \mathbf{F}_i({r_{ij}}) = \left[ A_{ij}B_{ij}\exp(-B_{ij} {r_{ij}}) -
                                   6\frac{C_{ij}}{{r_{ij}}^7} \right] {\frac{{\mathbf{r}_{ij}}}{{r_{ij}}}}
          :label: eqnnbbuckinghamforce

.. _coul:

Coulomb interaction
~~~~~~~~~~~~~~~~~~~

The Coulomb interaction between two charge particles is given by:

.. math:: V_c({r_{ij}}) = f \frac{q_i q_j}{{\varepsilon_r}{r_{ij}}}
          :label: eqnvcoul

See also :numref:`Fig. %s <fig-coul>`, where
:math:`f = \frac{1}{4\pi \varepsilon_0} = {138.935\,458}` (see chapter :ref:`defunits`)

.. _fig-coul:

.. figure:: plots/vcrf.*
   :width: 8.00000cm

   The Coulomb interaction (for particles with equal signed charge) with
   and without reaction field. In the latter case
   :math:`{\varepsilon_r}` was 1, :math:`{\varepsilon_{rf}}` was 78, and
   :math:`r_c` was 0.9 nm. The dot-dashed line is the same as the dashed
   line, except for a constant.

The force derived from this potential is:

.. math:: \mathbf{F}_i(\mathbf{r}_{ij}) = -f \frac{q_i q_j}{{\varepsilon_r}{r_{ij}}^2}{\frac{{\mathbf{r}_{ij}}}{{r_{ij}}}}
          :label: eqnfcoul

A plain Coulomb interaction should only be used without cut-off or when
all pairs fall within the cut-off, since there is an abrupt, large
change in the force at the cut-off. In case you do want to use a
cut-off, the potential can be shifted by a constant to make the
potential the integral of the force. With the group cut-off scheme, this
shift is only applied to non-excluded pairs. With the Verlet cut-off
scheme, the shift is also applied to excluded pairs and self
interactions, which makes the potential equivalent to a reaction field
with :math:`{\varepsilon_{rf}}=1` (see below).

In |Gromacs| the relative dielectric constant :math:`{\varepsilon_r}` may
be set in the in the input for :ref:`grompp <gmx grompp>`.

.. _coulrf:

Coulomb interaction with reaction field
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The Coulomb interaction can be modified for homogeneous systems by
assuming a constant dielectric environment beyond the cut-off
:math:`r_c` with a dielectric constant of :math:`{\varepsilon_{rf}}`.
The interaction then reads:

.. math:: V_{crf} ~=~
          f \frac{q_i q_j}{{\varepsilon_r}{r_{ij}}}\left[1+\frac{{\varepsilon_{rf}}-{\varepsilon_r}}{2{\varepsilon_{rf}}+{\varepsilon_r}}
          \,\frac{{r_{ij}}^3}{r_c^3}\right]
          - f\frac{q_i q_j}{{\varepsilon_r}r_c}\,\frac{3{\varepsilon_{rf}}}{2{\varepsilon_{rf}}+{\varepsilon_r}}
          :label: eqnvcrf

in which the constant expression on the right makes the potential zero
at the cut-off :math:`r_c`. For charged cut-off spheres this corresponds
to neutralization with a homogeneous background charge. We can rewrite
:eq:`eqn. %s <eqnvcrf>` for simplicity as

.. math:: V_{crf} ~=~     f \frac{q_i q_j}{{\varepsilon_r}}\left[\frac{1}{{r_{ij}}} + k_{rf}~ {r_{ij}}^2 -c_{rf}\right]
          :label: eqnvcrfrewrite

with

.. math:: \begin{aligned}
          k_{rf}  &=&     \frac{1}{r_c^3}\,\frac{{\varepsilon_{rf}}-{\varepsilon_r}}{(2{\varepsilon_{rf}}+{\varepsilon_r})}
          \end{aligned}
          :label: eqnkrf

.. math:: \begin{aligned}
          c_{rf}  &=&     \frac{1}{r_c}+k_{rf}\,r_c^2 ~=~ \frac{1}{r_c}\,\frac{3{\varepsilon_{rf}}}{(2{\varepsilon_{rf}}+{\varepsilon_r})}
          \end{aligned}
          :label: eqncrf

For large :math:`{\varepsilon_{rf}}` the :math:`k_{rf}` goes to
:math:`r_c^{-3}/2`, while for :math:`{\varepsilon_{rf}}` =
:math:`{\varepsilon_r}` the correction vanishes. In :numref:`Fig. %s <fig-coul>` the
modified interaction is plotted, and it is clear that the derivative
with respect to :math:`{r_{ij}}` (= -force) goes to zero at the cut-off
distance. The force derived from this potential reads:

.. math:: \mathbf{F}_i(\mathbf{r}_{ij}) = -f \frac{q_i q_j}{{\varepsilon_r}}\left[\frac{1}{{r_{ij}}^2} - 2 k_{rf}{r_{ij}}\right]{\frac{{\mathbf{r}_{ij}}}{{r_{ij}}}}
          :label: eqnfcrf

The reaction-field correction should also be applied to all excluded
atoms pairs, including self pairs, in which case the normal Coulomb term
in :eq:`eqns. %s <eqnvcrf>` and :eq:`%s <eqnfcrf>` is absent.

.. _modnbint:

Modified non-bonded interactions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In |Gromacs|, the non-bonded potentials can be modified by a shift
function, also called a force-switch function, since it switches the
force to zero at the cut-off. The purpose of this is to replace the
truncated forces by forces that are continuous and have continuous
derivatives at the cut-off radius. With such forces the time integration
produces smaller errors. But note that for Lennard-Jones interactions
these errors are usually smaller than other errors, such as integration
errors at the repulsive part of the potential. For Coulomb interactions
we advise against using a shifted potential and for use of a reaction
field or a proper long-range method such as PME.

There is *no* fundamental difference between a switch function (which
multiplies the potential with a function) and a shift function (which
adds a function to the force or potential) \ :ref:`72 <refSpoel2006a>`. The
switch function is a special case of the shift function, which we apply
to the *force function* :math:`F(r)`, related to the electrostatic or
van der Waals force acting on particle :math:`i` by particle :math:`j`
as:

.. math:: \mathbf{F}_i = c \, F(r_{ij}) \frac{\mathbf{r}_{ij}}{r_{ij}}
          :label: eqnswitch

For pure Coulomb or Lennard-Jones interactions
:math:`F(r) = F_\alpha(r) = \alpha \, r^{-(\alpha+1)}`. The switched
force :math:`F_s(r)` can generally be written as:

.. math::  \begin{array}{rcl}
           F_s(r)~=&~F_\alpha(r)   & r < r_1               \\
           F_s(r)~=&~F_\alpha(r)+S(r)      & r_1 \le r < r_c       \\
           F_s(r)~=&~0             & r_c \le r     
           \end{array}
           :label: eqnswitchforce

When :math:`r_1=0` this is a traditional shift function, otherwise it
acts as a switch function. The corresponding shifted potential function
then reads:

.. math:: V_s(r) =  \int^{\infty}_r~F_s(x)\, dx
          :label: eqnswitchpotential

The |Gromacs| **force switch** function :math:`S_F(r)` should be smooth at
the boundaries, therefore the following boundary conditions are imposed
on the switch function:

.. math:: \begin{array}{rcl}
          S_F(r_1)          &=&0            \\
          S_F'(r_1)         &=&0            \\
          S_F(r_c)          &=&-F_\alpha(r_c)       \\
          S_F'(r_c)         &=&-F_\alpha'(r_c)
          \end{array}
          :label: eqnswitchforcefunction

A 3\ :math:`^{rd}` degree polynomial of the form

.. math:: S_F(r) = A(r-r_1)^2 + B(r-r_1)^3
          :label: eqnswitchforcepoly

fulfills these requirements. The constants A and B are given by the
boundary condition at :math:`r_c`:

.. math:: \begin{array}{rcl}
          A &~=~& -\alpha \, \displaystyle
                  \frac{(\alpha+4)r_c~-~(\alpha+1)r_1} {r_c^{\alpha+2}~(r_c-r_1)^2} \\
          B &~=~& \alpha \, \displaystyle
                  \frac{(\alpha+3)r_c~-~(\alpha+1)r_1}{r_c^{\alpha+2}~(r_c-r_1)^3}
          \end{array}
          :label: eqnforceswitchboundary

Thus the total force function is:

.. math:: F_s(r) = \frac{\alpha}{r^{\alpha+1}} + A(r-r_1)^2 + B(r-r_1)^3
          :label: eqnswitchfinalforce

and the potential function reads:

.. math:: V_s(r) = \frac{1}{r^\alpha} - \frac{A}{3} (r-r_1)^3 - \frac{B}{4} (r-r_1)^4 - C
          :label: eqnswitchfinalpotential

where

.. math:: C =  \frac{1}{r_c^\alpha} - \frac{A}{3} (r_c-r_1)^3 - \frac{B}{4} (r_c-r_1)^4
          :label: eqnswitchpotentialexp

The |Gromacs| **potential-switch** function :math:`S_V(r)` scales the
potential between :math:`r_1` and :math:`r_c`, and has similar boundary
conditions, intended to produce smoothly-varying potential and forces:

.. math:: \begin{array}{rcl}
          S_V(r_1)          &=&1 \\
          S_V'(r_1)         &=&0 \\
          S_V''(r_1)        &=&0 \\
          S_V(r_c)          &=&0 \\
          S_V'(r_c)         &=&0 \\
          S_V''(r_c)        &=&0
          \end{array}
          :label: eqnpotentialswitch

The fifth-degree polynomial that has these properties is

.. math:: S_V(r; r_1, r_c) = 1 - 10\left(\frac{r-r_1}{r_c-r_1}\right)^3 + 15\left(\frac{r-r_1}{r_c-r_1}\right)^4 - 6\left(\frac{r-r_1}{r_c-r_1}\right)^5
          :label: eqn5polynomal

This implementation is found in several other simulation
packages,\ :ref:`73 <refOhmine1988>`\ :ref:`75 <refGuenot1993>` but
differs from that in CHARMM.\ :ref:`76 <refSteinbach1994>` Switching the
potential leads to artificially large forces in the switching region,
therefore it is not recommended to switch Coulomb interactions using
this function,\ :ref:`72 <refSpoel2006a>` but switching Lennard-Jones
interactions using this function produces acceptable results.

Modified short-range interactions with Ewald summation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When Ewald summation or particle-mesh Ewald is used to calculate the
long-range interactions, the short-range Coulomb potential must also be
modified. Here the potential is switched to (nearly) zero at the
cut-off, instead of the force. In this case the short range potential is
given by:

.. math:: V(r) = f \frac{\mbox{erfc}(\beta r_{ij})}{r_{ij}} q_i q_j,
          :label: eqnewaldsrmod

where :math:`\beta` is a parameter that determines the relative weight
between the direct space sum and the reciprocal space sum and
erfc\ :math:`(x)` is the complementary error function. For further
details on long-range electrostatics, see sec. :ref:`lrelstat`.
.. _feia:

Free energy interactions
------------------------

This section describes the :math:`\lambda`-dependence of the potentials
used for free energy calculations (see sec. :ref:`fecalc`). All common
types of potentials and constraints can be interpolated smoothly from
state A (:math:`\lambda=0`) to state B (:math:`\lambda=1`) and vice
versa. All bonded interactions are interpolated by linear interpolation
of the interaction parameters. Non-bonded interactions can be
interpolated linearly or via soft-core interactions.

Starting in |Gromacs| 4.6, :math:`\lambda` is a vector, allowing different
components of the free energy transformation to be carried out at
different rates. Coulomb, Lennard-Jones, bonded, and restraint terms can
all be controlled independently, as described in the
:ref:`mdp` options.

Harmonic potentials
~~~~~~~~~~~~~~~~~~~

The example given here is for the bond potential, which is harmonic in
|Gromacs|. However, these equations apply to the angle potential and the
improper dihedral potential as well.

.. math:: \begin{aligned}
          V_b     &=&{\frac{1}{2}}\left[{(1-{\lambda})}k_b^A + 
                          {\lambda}k_b^B\right] \left[b - {(1-{\lambda})}b_0^A - {\lambda}b_0^B\right]^2  \\
          {\frac{\partial V_b}{\partial {\lambda}}}&=&{\frac{1}{2}}(k_b^B-k_b^A)
                          \left[b - {(1-{\lambda})}b_0^A + {\lambda}b_0^B\right]^2 + 
          		\nonumber\\
                  & & \phantom{{\frac{1}{2}}}(b_0^A-b_0^B) \left[b - {(1-{\lambda})}b_0^A -{\lambda}b_0^B\right]
          		\left[{(1-{\lambda})}k_b^A + {\lambda}k_b^B \right]\end{aligned}
          :label: eqnfepharmpot

GROMOS-96 bonds and angles
~~~~~~~~~~~~~~~~~~~~~~~~~~

Fourth-power bond stretching and cosine-based angle potentials are
interpolated by linear interpolation of the force constant and the
equilibrium position. Formulas are not given here.

Proper dihedrals
~~~~~~~~~~~~~~~~

For the proper dihedrals, the equations are somewhat more complicated:

.. math:: \begin{aligned}
          V_d     &=&\left[{(1-{\lambda})}k_d^A + {\lambda}k_d^B \right]
                  \left( 1+ \cos\left[n_{\phi} \phi - 
          		    {(1-{\lambda})}\phi_s^A - {\lambda}\phi_s^B
          		    \right]\right)\\
          {\frac{\partial V_d}{\partial {\lambda}}}&=&(k_d^B-k_d^A) 
                   \left( 1+ \cos
          		 \left[
          		    n_{\phi} \phi- {(1-{\lambda})}\phi_s^A - {\lambda}\phi_s^B
          		 \right]
          	 \right) +
          	 \nonumber\\
                  &&(\phi_s^B - \phi_s^A) \left[{(1-{\lambda})}k_d^A - {\lambda}k_d^B\right] 
                  \sin\left[  n_{\phi}\phi - {(1-{\lambda})}\phi_s^A - {\lambda}\phi_s^B \right]\end{aligned}
          :label: eqnfeppropdihedral

**Note:** that the multiplicity :math:`n_{\phi}` can not be
parameterized because the function should remain periodic on the
interval :math:`[0,2\pi]`.

Tabulated bonded interactions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For tabulated bonded interactions only the force constant can
interpolated:

.. math:: \begin{aligned}
                V  &=& ({(1-{\lambda})}k^A + {\lambda}k^B) \, f \\
          {\frac{\partial V}{\partial {\lambda}}} &=& (k^B - k^A) \, f\end{aligned}
          :label: eqnfeptabbonded

Coulomb interaction
~~~~~~~~~~~~~~~~~~~

The Coulomb interaction between two particles of which the charge varies
with :math:`{\lambda}` is:

.. math:: \begin{aligned}
          V_c &=& \frac{f}{{\varepsilon_{rf}}{r_{ij}}}\left[{(1-{\lambda})}q_i^A q_j^A + {\lambda}\, q_i^B q_j^B\right] \\
          {\frac{\partial V_c}{\partial {\lambda}}}&=& \frac{f}{{\varepsilon_{rf}}{r_{ij}}}\left[- q_i^A q_j^A + q_i^B q_j^B\right]\end{aligned}
          :label: eqnfepcoloumb

where :math:`f = \frac{1}{4\pi \varepsilon_0} = {138.935\,458}` (see
chapter :ref:`defunits`).

Coulomb interaction with reaction field
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The Coulomb interaction including a reaction field, between two
particles of which the charge varies with :math:`{\lambda}` is:

.. math:: \begin{aligned}
          V_c     &=& f\left[\frac{1}{{r_{ij}}} + k_{rf}~ {r_{ij}}^2 -c_{rf}\right]
          \left[{(1-{\lambda})}q_i^A q_j^A + {\lambda}\, q_i^B q_j^B\right] \\
          {\frac{\partial V_c}{\partial {\lambda}}}&=& f\left[\frac{1}{{r_{ij}}} + k_{rf}~ {r_{ij}}^2 -c_{rf}\right]
          \left[- q_i^A q_j^A + q_i^B q_j^B\right]
          \end{aligned}
          :label: eqdVcoulombdlambda

**Note** that the constants :math:`k_{rf}` and :math:`c_{rf}` are
defined using the dielectric constant :math:`{\varepsilon_{rf}}` of the
medium (see sec. :ref:`coulrf`).

Lennard-Jones interaction
~~~~~~~~~~~~~~~~~~~~~~~~~

For the Lennard-Jones interaction between two particles of which the
*atom type* varies with :math:`{\lambda}` we can write:

.. math:: \begin{aligned}
          V_{LJ}  &=&     \frac{{(1-{\lambda})}C_{12}^A + {\lambda}\, C_{12}^B}{{r_{ij}}^{12}} -
          \frac{{(1-{\lambda})}C_6^A + {\lambda}\, C_6^B}{{r_{ij}}^6}   \\
          {\frac{\partial V_{LJ}}{\partial {\lambda}}}&=&\frac{C_{12}^B - C_{12}^A}{{r_{ij}}^{12}} -
          \frac{C_6^B - C_6^A}{{r_{ij}}^6}
          \end{aligned}
          :label: eqdVljdlambda

It should be noted that it is also possible to express a pathway from
state A to state B using :math:`\sigma` and :math:`\epsilon` (see
:eq:`eqn. %s <eqnsigeps>`). It may seem to make sense physically to vary the
force field parameters :math:`\sigma` and :math:`\epsilon` rather than
the derived parameters :math:`C_{12}` and :math:`C_{6}`. However, the
difference between the pathways in parameter space is not large, and the
free energy itself does not depend on the pathway, so we use the simple
formulation presented above.

Kinetic Energy
~~~~~~~~~~~~~~

When the mass of a particle changes, there is also a contribution of the
kinetic energy to the free energy (note that we can not write the
momentum :math:`\mathbf{p}` as
m :math:`\mathbf{v}`, since that would result in the
sign of :math:`{\frac{\partial E_k}{\partial {\lambda}}}` being
incorrect \ :ref:`99 <refGunsteren98a>`):

.. math:: \begin{aligned}
          E_k      &=&     {\frac{1}{2}}\frac{\mathbf{p}^2}{{(1-{\lambda})}m^A + {\lambda}m^B}        \\
          {\frac{\partial E_k}{\partial {\lambda}}}&=&    -{\frac{1}{2}}\frac{\mathbf{p}^2(m^B-m^A)}{({(1-{\lambda})}m^A + {\lambda}m^B)^2}\end{aligned}
          :label: eqnfepekin

after taking the derivative, we *can* insert
:math:`\mathbf{p}` = m :math:`\mathbf{v}`, such that:

.. math:: {\frac{\partial E_k}{\partial {\lambda}}}~=~    -{\frac{1}{2}}\mathbf{v}^2(m^B-m^A)
          :label: eqnfepekinderivative

Constraints
~~~~~~~~~~~

The constraints are formally part of the Hamiltonian, and therefore they
give a contribution to the free energy. In |Gromacs| this can be
calculated using the LINCS or the SHAKE algorithm. If we have
:math:`k = 1 \ldots K` constraint equations :math:`g_k` for LINCS, then

.. math:: g_k     =       | \mathbf{r}_{k} | - d_{k}
          :label: eqnfepconstr

where :math:`\mathbf{r}_k` is the displacement vector
between two particles and :math:`d_k` is the constraint distance between
the two particles. We can express the fact that the constraint distance
has a :math:`{\lambda}` dependency by

.. math:: d_k     =       {(1-{\lambda})}d_{k}^A + {\lambda}d_k^B
          :label: eqnfepconstrdistdep

Thus the :math:`{\lambda}`-dependent constraint equation is

.. math:: g_k     =       | \mathbf{r}_{k} | - \left({(1-{\lambda})}d_{k}^A + {\lambda}d_k^B\right).
          :label: eqnfepconstrlambda

The (zero) contribution :math:`G` to the Hamiltonian from the
constraints (using Lagrange multipliers :math:`\lambda_k`, which are
logically distinct from the free-energy :math:`{\lambda}`) is

.. math:: \begin{aligned}
          G           &=&     \sum^K_k \lambda_k g_k    \\
          {\frac{\partial G}{\partial {\lambda}}}    &=&     \frac{\partial G}{\partial d_k} {\frac{\partial d_k}{\partial {\lambda}}} \\
                      &=&     - \sum^K_k \lambda_k \left(d_k^B-d_k^A\right)\end{aligned}
          :label: eqnconstrfreeenergy

For SHAKE, the constraint equations are

.. math:: g_k     =       \mathbf{r}_{k}^2 - d_{k}^2
          :label: eqnfepshakeconstr

with :math:`d_k` as before, so

.. math:: \begin{aligned}
          {\frac{\partial G}{\partial {\lambda}}}    &=&     -2 \sum^K_k \lambda_k \left(d_k^B-d_k^A\right)\end{aligned}
          :label: eqnfepshakeconstr2

Soft-core interactions: Beutler *et al.*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. _fig-softcore:

.. figure:: plots/softcore.*
   :height: 6.00000cm

   Soft-core interactions at :math:`{\lambda}=0.5`, with :math:`p=2` and
   :math:`C_6^A=C_{12}^A=C_6^B=C_{12}^B=1`.

In a free-energy calculation where particles grow out of nothing, or
particles disappear, using the simple linear interpolation of the
Lennard-Jones and Coulomb potentials as described in
:eq:`Equations %s <eqdVljdlambda>` and :eq:`%s <eqdVcoulombdlambda>` may lead to poor
convergence. When the particles have nearly disappeared, or are close to
appearing (at :math:`{\lambda}` close to 0 or 1), the interaction energy
will be weak enough for particles to get very close to each other,
leading to large fluctuations in the measured values of
:math:`\partial V/\partial {\lambda}` (which, because of the simple
linear interpolation, depends on the potentials at both the endpoints of
:math:`{\lambda}`).

To circumvent these problems, the singularities in the potentials need
to be removed. This can be done by modifying the regular Lennard-Jones
and Coulomb potentials with “soft-core” potentials that limit the
energies and forces involved at :math:`{\lambda}` values between 0 and
1, but not *at* :math:`{\lambda}=0` or 1.

In |Gromacs| the soft-core potentials :math:`V_{sc}` are shifted versions
of the regular potentials, so that the singularity in the potential and
its derivatives at :math:`r=0` is never reached. This formulation was
introduced by Beutler *et al.*\ :ref:`100 <refBeutler94>`:

.. math:: \begin{aligned}
          V_{sc}(r) &=& {(1-{\lambda})}V^A(r_A) + {\lambda}V^B(r_B)
              \\
          r_A &=& \left(\alpha \sigma_A^6 {\lambda}^p + r^6 \right)^\frac{1}{6}
              \\
          r_B &=& \left(\alpha \sigma_B^6 {(1-{\lambda})}^p + r^6 \right)^\frac{1}{6}\end{aligned}
          :label: eqnfepsoftcore

where :math:`V^A` and :math:`V^B` are the normal “hard core” Van der
Waals or electrostatic potentials in state A (:math:`{\lambda}=0`) and
state B (:math:`{\lambda}=1`) respectively, :math:`\alpha` is the
soft-core parameter (set with ``sc_alpha`` in the
:ref:`mdp` file), :math:`p` is the soft-core :math:`{\lambda}`
power (set with ``sc_power``), :math:`\sigma` is the radius
of the interaction, which is :math:`(C_{12}/C_6)^{1/6}` or an input
parameter (``sc_sigma``) when :math:`C_6` or :math:`C_{12}`
is zero. Beutler *et al.*\ :ref:`100 <refBeutler94>` probed various
combinations of the :math:`r` power values for the Lennard-Jones
and Coulombic interactions. |Gromacs| uses :math:`r^6` for both,
van der Waals and electrostatic interactions.

For intermediate :math:`{\lambda}`, :math:`r_A` and :math:`r_B` alter
the interactions very little for :math:`r > \alpha^{1/6} \sigma` and
quickly switch the soft-core interaction to an almost constant value for
smaller :math:`r` (:numref:`Fig. %s <fig-softcore>`). The force is:

.. math:: F_{sc}(r) = -\frac{\partial V_{sc}(r)}{\partial r} =
           {(1-{\lambda})}F^A(r_A) \left(\frac{r}{r_A}\right)^5 +
          {\lambda}F^B(r_B) \left(\frac{r}{r_B}\right)^5
          :label: eqnfepsoftcoreforce

where :math:`F^A` and :math:`F^B` are the “hard core” forces. The
contribution to the derivative of the free energy is:

.. math:: \begin{aligned}
          {\frac{\partial V_{sc}(r)}{\partial {\lambda}}} & = &
           V^B(r_B) -V^A(r_A)  + 
          	{(1-{\lambda})}\frac{\partial V^A(r_A)}{\partial r_A}
          		   \frac{\partial r_A}{\partial {\lambda}} + 
          	{\lambda}\frac{\partial V^B(r_B)}{\partial r_B}
          		   \frac{\partial r_B}{\partial {\lambda}}
          \nonumber\\
          &=&
           V^B(r_B) -V^A(r_A)  + \nonumber \\
           & &
           \frac{p \alpha}{6}
                 \left[ {\lambda}F^B(r_B) r^{-5}_B \sigma_B^6 {(1-{\lambda})}^{p-1} -
          	       {(1-{\lambda})}F^A(r_A) r^{-5}_A \sigma_A^6 {\lambda}^{p-1} \right]\end{aligned}
          :label: eqnfepsoftcorederivative

The original GROMOS Lennard-Jones soft-core
function\ :ref:`100 <refBeutler94>` uses :math:`p=2`, but :math:`p=1` gives a smoother
:math:`\partial H/\partial{\lambda}` curve. Another issue that should be
considered is the soft-core effect of hydrogens without Lennard-Jones
interaction. Their soft-core :math:`\sigma` is set with
``sc_sigma`` in the :ref:`mdp` file. These
hydrogens produce peaks in :math:`\partial H/\partial{\lambda}` at
:math:`{\lambda}` is 0 and/or 1 for :math:`p=1` and close to 0 and/or 1
with :math:`p=2`. Lowering ``sc_sigma``
will decrease this effect, but it will also increase the interactions
with hydrogens relative to the other interactions in the soft-core
state.

When soft-core potentials are selected (by setting
``sc_alpha >0``), and the Coulomb and Lennard-Jones
potentials are turned on or off sequentially, then the Coulombic
interaction is turned off linearly, rather than using soft-core
interactions, which should be less statistically noisy in most cases.
This behavior can be overwritten by using the :ref:`mdp` option
``sc-coul`` to ``yes``. Note that the
``sc-coul`` is only taken into account when lambda states
are used, not with ``couple-lambda0``  /
``couple-lambda1``, and you can still turn off soft-core
interactions by setting ``sc-alpha=0``. Additionally, the
soft-core interaction potential is only applied when either the A or B
state has zero interaction potential. If both A and B states have
nonzero interaction potential, default linear scaling described above is
used. When both Coulombic and Lennard-Jones interactions are turned off
simultaneously, a soft-core potential is used, and a hydrogen is being
introduced or deleted, the sigma is set to ``sc-sigma-min``,
which itself defaults to ``sc-sigma-default``.


Soft-core interactions: Gapsys *et al.*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In this section we describe the functional form and parameters for 
the soft-cored non-bonded interactions using the formalism by Gapsys *et al.*\ :ref:`185 <refGapsys2012>`.

The Gapsys *et al.* soft-core is formulated to act on the level of van der Waals and electrostatic forces:
the non-bonded interactions are linearized at a point defined as, :math:`r_{scLJ}` or :math:`r_{scQ}`, respectively.
The linearization point depends on the state of the system as controlled by the :math:`\lambda` parameter and 
two parameters :math:`\alpha_Q` (set with ``sc-gapsys-scale-linpoint-q``) and :math:`\alpha_{LJ}` (set with ``sc-gapsys-scale-linpoint-lj``).
The dependence on :math:`\lambda` guarantees that the end-states are properly represented by their hard-core potentials.
:numref:`Fig. %s <fig-gapsyssc>` illustrates the behaviour of the linearization point, forces and integrated potential energies with respect
to the parameters :math:`\alpha_Q` and :math:`\alpha_{LJ}`. The optimal choices of the parameter values have been systematically explored in :ref:`185 <refGapsys2012>`. These recommended values are set by default when ``sc-function=gapsys`` is selected: ``sc-gapsys-scale-linpoint-q=0.3`` and ``sc-gapsys-scale-linpoint-lj=0.85``.

.. _fig-gapsyssc:

.. figure:: plots/gapsys-sc.*
        :width: 15.0cm

        Illustration of the soft-core parameter influence on the linearization point (top row), 
        forces (middle row) and energies (bottom row)
        for van der Waals (left column) and electrostatic interactions (right column).
        The case of two interacting atoms is considered.
        In state A both atoms have charges of 0.5 and :math:`\sigma=0.3` nm, :math:`\epsilon=0.5` kJ/mol.
        In state B all the non-bonded interactions are set to zero.
        The parameter :math:`\lambda` is set to 0.5 and electrostatic interaction cutoff is 1 nm.

The parameter :math:`\alpha_{LJ}` is a unitless scaling factor in the range :math:`[0,1)`.
It scales the position of the point from which the van der Waals force will be linearized.
The linearization of the force is allowed in the range :math:`[0,F_{min}^{LJ})`,
where setting :math:`\alpha_{LJ}=0` results in a standard hard-core van der Waals interaction.
Setting :math:`\alpha_{LJ}` closer to 1 brings the force linearization point towards 
the minimum in the Lennard-Jones force curve (:math:`F_{min}^{LJ}`).
This construct allows retaining the repulsion between two particles with non-zero C12 parameter at any :math:`\lambda` value.

The parameter :math:`\alpha_{Q}` has a unit of :math:`\frac{nm}{e^2}` and is defined in the range :math:`[0,\inf)`.
It scales the position of the point from which the Coulombic force will be linearized.
Even though in theory :math:`\alpha_{Q}` can be set to an arbitrarily large value,
algorithmically the linearization point for the force is bound in the range :math:`[0,F_{rcoul}^{Q})`,
where setting :math:`\alpha_{Q}=0` results in a standard hard-core Coulombic interaction.
Setting :math:`\alpha_{Q}` to a larger value softens the Coulombic force.

In all the notations below, for simplicity, the distance between two atoms :math:`i` and :math:`j` is noted as :math:`r`, i.e. :math:`r=r_{ij}`.

Forces: van der Waals interactions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. math:: \begin{aligned}
          \mathbf{F}_{ij}^{LJ}(\mathbf{r})=\begin{cases}
          (\frac{12C_{ij}^{(12)}}{r^{13}} - \frac{6C_{ij}^{(6)}}{r^7})\frac{\mathbf{r}}{r}, & \mbox{if } \mbox{ $r \geq r_{scLJ}$} 
          \\
          \frac{d\mathbf{F}_{ij}^{LJ}}{dr}_{r=r_{scLJ}}r + \mathbf{F}_{ij}^{LJ}(r_{scLJ}), & \mbox{if } \mbox{ $r<r_{scLJ}$}
          \end{cases}\end{aligned}
          :label: eqvdwforces

where the switching point between the soft and hard-core Lennard-Jones forces
:math:`r_{scLJ} = \alpha_{LJ}(\frac{26}{7}\sigma^6\lambda)^{\frac{1}{6}}` for state A, and
:math:`r_{scLJ} = \alpha_{LJ}(\frac{26}{7}\sigma^6(1-\lambda))^{\frac{1}{6}}` for state B.
In analogy to the Beutler *et al.* soft core version, :math:`\sigma` is the radius of the interaction, which is :math:`(C_{12}/C_6)^{1/6}`
or an input parameter (set with ``sc-sigma-LJ-gapsys``) when C6 or C12 is zero. The default value for this parameter is ``sc-sigma-LJ-gapsys=0.3``.

Explicit expression:

.. math:: \begin{aligned}
          \mathbf{F}_{LJ}(\mathbf{r})=\begin{cases}
          \left(\frac{12C^{(12)}}{r^{13}} - \frac{6C^{(6)}}{r^7}\right)\frac{\mathbf{r}}{r}, & \mbox{if } \mbox{ $r \geq r_{scLJ}$} 
          \\
          \left(-\frac{156C^{(12)}}{r_{scLJ}^{14}} + \frac{42C^{(6)}}{r_{scLJ}^{8}}\right)\mathbf{r} + \frac{168C^{(12)}}{r_{scLJ}^{13}} - \frac{48C^{(6)}}{r_{scLJ}^{7}}, & \mbox{if } \mbox{ $r<r_{scLJ}$}
          \end{cases}\end{aligned}
          :label: eqvdwforcesexpl

Forces: Coulomb interactions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. math:: \begin{aligned}
          \mathbf{F}_{ij}^{Q}(\mathbf{r})=\begin{cases}
          \frac{q_{i}q_{j}}{4{\pi}{\varepsilon_0}{\varepsilon_r}r^{2}}\frac{\mathbf{r}}{r}, & \mbox{if } \mbox{ $r \geq r_{scQ} < r_{cutoffQ}$} 
          \\
          \frac{d\mathbf{F}_{ij}^{Q}}{dr}_{r=r_{scQ}}r + \mathbf{F}_{ij}^{Q}(r_{scQ}), & \mbox{if } \mbox{ $r<r_{scQ} < r_{cutoffQ}$}
          \\
          \frac{d\mathbf{F}_{ij}^{Q}}{dr}_{r=r_{cutoffQ}}r + \mathbf{F}_{ij}^{Q}(r_{cutoffQ}), & \mbox{if } \mbox{ $r < r^{scQ} \geq r_{cutoffQ}$} 
          \end{cases}\end{aligned}
          :label: eqqforces

where the switching point :math:`r^{sc}` between the soft and hard-core electrostatic forces is 
:math:`r_{scQ} = \alpha_Q(1+|q_iq_j|)\lambda^{\frac{1}{6}}` for state A, and
:math:`r_{scQ} = \alpha_Q(1+|q_iq_j|)(1-\lambda)^{\frac{1}{6}}` for state B.
The :math:`\lambda` dependence of the linearization point for both van der Waals and Coulombic interactions is of the same power :math:`1/6`.

Explicit expression:

.. math:: \begin{aligned}
          \mathbf{F}_{Q}(\mathbf{r})=\begin{cases}
          \frac{q_iq_j}{4{\pi}{\varepsilon_0}{\varepsilon_r}r^{2}}\frac{\mathbf{r}}{r}, & \mbox{if } \mbox{ $r \geq r_{scQ} < r_{cutoffQ}$} 
          \\
          \frac{1}{4{\pi}{\varepsilon_0}{\varepsilon_r}}\big( -\frac{2q_{i}q_{j}}{r_{sc}^3}\mathbf{r} + \frac{3q_iq_j}{r_{sc}^2} \big), & \mbox{if } \mbox{ $r<r_{scQ} < r_{cutoffQ}$}
          \\
          \frac{1}{4{\pi}{\varepsilon_0}{\varepsilon_r}}\big( -\frac{2q_{i}q_{j}}{r_{cutoffQ}^3}\mathbf{r} + \frac{3q_iq_j}{r_{cutoffQ}^2} \big), & \mbox{if } \mbox{ $r < r_{scQ} \geq r_{cutoffQ}$}                        \end{cases}\end{aligned}
          :label: eqqforcesexpl

Energies: van der Waals interactions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Explicition definition of energies:

.. math:: \begin{aligned}
          V_{LJ}(r)=\begin{cases}
          \frac{C^{(12)}}{r^{12}} - \frac{C^{(6)}}{r^6}, & \mbox{if } \mbox{ $r \geq r_{scLJ}$} 
          \\
          \left(\frac{78C^{(12)}}{r_{scLJ}^{14}} - \frac{21C^{(6)}}{r_{scLJ}^{8}}\right)r^2 - \left(\frac{168C^{(12)}}{r_{scLJ}^{13}} - \frac{48C^{(12)}}{r_{scLJ}^{7}}\right)r
          + \frac{91C^{(12)}}{r_{scLJ}^{12}} - \frac{28C^{(6)}}{r_{scLJ}^{6}}, & \mbox{if } \mbox{ $r<r_{scLJ}$}
          \end{cases}\end{aligned}
          :label: eqvdwener

Energies: Coulomb interactions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. math:: \begin{aligned}
          V_{Q}(r)=\begin{cases}
          \frac{q_{i}q_{j}}{4{\pi}{\varepsilon_0}{\varepsilon_r}r}, & \mbox{if } \mbox{ $r \geq r_{scQ} < r_{cutoffQ}$}
          \\
          \frac{q_{i}q_{j}}{r_{scQ}^3}r^2 - \frac{3q_iq_j}{r_{scQ}^2}r + \frac{3q_iq_j}{r_{scQ}}, & \mbox{if } \mbox{ $r<r_{scQ} < r_{cutoffQ}$}
          \\
          \frac{q_{i}q_{j}}{r_{cutoffQ}^3}r^2 - \frac{3q_iq_j}{r_{cutoffQ}^2}r + \frac{3q_iq_j}{r_{cutoffQ}}, & \mbox{if } \mbox{ $r < r_{scQ} \geq r_{cutoffQ}$}                
          \end{cases}\end{aligned}
          :label: eqqener

:math:`\partial H / \partial \lambda`: van der Waals interactions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Here we provide the explicit expressions of :math:`\partial H/ \partial \lambda` for Lennard-Jones potential, when :math:`r<r_{scLJ}`.
For simplicity, in the expression below we use the notation :math:`r_{scLJ_A}=r_{scA}` and :math:`r_{scLJ_B}=r_{scB}`.

.. math:: \begin{aligned}
          \frac{\partial{H}}{\partial{\lambda}} &= V_{LJ}^B(r) - V_{LJ}^A(r) + (1-\lambda)\frac{\partial{V_{LJ}^A(r)}}{\partial{\lambda}} + \lambda\frac{\partial{V_{LJ}^B(r)}}{\partial{\lambda}} \\
          & =  \left(\frac{78C^{(12)}_B}{r_{scB}^{14}} - \frac{21C^{(6)}_B}{r_{scB}^{8}}\right)r^2 - \left(\frac{168C^{(12)}_B}{r_{scB}^{13}} - \frac{48C^{(12)}_B}{r_{scB}^{7}}\right)r
          + \frac{91C^{(12)}_B}{r_{scB}^{12}} - \frac{28C^{(6)}_B}{r_{scB}^{6}} \\
          & -  \left[\left(\frac{78C^{(12)}_A}{r_{scA}^{14}} - \frac{21C^{(6)}_A}{r_{scA}^{8}}\right)r^2 - \left(\frac{168C^{(12)}_A}{r_{scA}^{13}} - \frac{48C^{(12)}_A}{r_{scA}^{7}}\right)r
          + \frac{91C^{(12)}_A}{r_{scA}^{12}} - \frac{28C^{(6)}_A}{r_{scA}^{6}} \right]\\
          & +  \frac{14(\lambda-1)}{\lambda}\left[\left(\frac{13C^{(12)}_A}{r_{scA}^{14}} - \frac{2C^{(6)}_A}{r_{scA}^{8}}\right)r^2
          - \left(\frac{26C^{(12)}_A}{r_{scA}^{13}} - \frac{4C^{(6)}_A}{r_{scA}^{7}}\right)r
          + \frac{13C^{(12)}_A}{r_{scA}^{12}} - \frac{2C^{(6)}_A}{r_{scA}^{6}}\right] \\
          & +  \frac{14\lambda}{1-\lambda}\left[\left(\frac{13C^{(12)}_B}{r_{scB}^{14}} - \frac{2C^{(6)}_B}{r_{scB}^{8}}\right)r^2
          - \left(\frac{26C^{(12)}_B}{r_{scB}^{13}} - \frac{4C^{(6)}_B}{r_{scB}^{7}}\right)r
          + \frac{13C^{(12)}_B}{r_{scB}^{12}} - \frac{2C^{(6)}_B}{r_{scB}^{6}}\right] \end{aligned}
          :label: eqvdwdhdl

:math:`\partial H/ \partial \lambda` for Lennard-Jones potential, when :math:`r \geq r_{scLJ}` is calculated as a standard hard-core
contribution to :math:`\partial H/ \partial \lambda`: :math:`\frac{\partial{H}}{\partial{\lambda}} = V_{LJ}^B(r) - V_{LJ}^A(r)`.

:math:`\partial H/ \partial \lambda` for Coulomb interactions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Here we provide the explicit expressions of :math:`\partial H/ \partial \lambda` for Coulomb potential, when :math:`r<r_{scQ}<r_{cutoffQ}`.
For simplicity, in the expression below we use the notation :math:`r_{scQ_A}=r_{scA}` and :math:`r_{scQ_B}=r_{scB}`.

.. math:: \begin{aligned}
          \frac{\partial{H}}{\partial{\lambda}} &= V_Q^B(r) - V_Q^A(r) + (1-\lambda)\frac{\partial{V_Q^A(r)}}{\partial{\lambda}} + \lambda\frac{\partial{V_Q^B(r)}}{\partial{\lambda}} \\
          & =  \frac{q_{i}^Bq_{j}^B}{r_{scB}^3}r^2 - \frac{3q_i^Bq_j^B}{r_{scB}^2}r + \frac{3q^B_iq_j^B}{r_{scB}} \\
          & -  \left[\frac{q_{i}^Aq_{j}^A}{r_{scA}^3}r^2 - \frac{3q_i^Aq_j^A}{r_{scA}^2}r + \frac{3q^A_iq_j^A}{r_{scA}}\right] \\
          & +  \frac{\lambda-1}{2\lambda}\left[\frac{q_i^Aq_j^A}{r_{scA}^3}r^2 - \frac{2q_i^Aq_j^A}{r_{scA}^2}r + \frac{q_i^Aq_j^A}{r_{scA}}\right] \\
          & +  \frac{\lambda}{2(1-\lambda)}\left[\frac{q_i^Bq_j^B}{r_{scB}^3}r^2 - \frac{2q_i^Bq_j^B}{r_{scB}^2}r + \frac{q_i^Bq_j^B}{r_{scB}}\right] \end{aligned}
          :label: eqqdhdl

:math:`\partial H/ \partial \lambda` for Coulomb potential, when :math:`r < r_{scQ} \geq r_{cutoffQ}` is calculated using the same expression above
by setting :math:`r_{scA}=r_{cutoffQ}` and :math:`r_{scB}=r_{cutoffQ}`.

:math:`\partial H/ \partial \lambda` for Coulomb potential, when :math:`r \geq r_{scQ} < r_{cutoffQ}` is calculated as a standard hard-core
contribution to :math:`\partial H/ \partial \lambda`: :math:`\frac{\partial{H}}{\partial{\lambda}} = V_{Q}^B(r) - V_{Q}^A(r)`.



.. _lrelstat:   

Long Range Electrostatics
-------------------------

Ewald summation
~~~~~~~~~~~~~~~

The total electrostatic energy of :math:`N` particles and their periodic
images is given by

.. math:: V=\frac{f}{2}\sum_{n_x}\sum_{n_y}
          \sum_{n_{z}*} \sum_{i}^{N} \sum_{j}^{N}
          \frac{q_i q_j}{{\bf r}_{ij,{\bf n}}}.
          :label: eqntotalcoulomb

:math:`(n_x,n_y,n_z)={\bf n}` is the box index vector, and the star
indicates that terms with :math:`i=j` should be omitted when
:math:`(n_x,n_y,n_z)=(0,0,0)`. The distance :math:`{\bf r}_{ij,{\bf n}}`
is the real distance between the charges and not the minimum-image. This
sum is conditionally convergent, but very slow.

Ewald summation was first introduced as a method to calculate long-range
interactions of the periodic images in crystals \ :ref:`105 <refEwald21>`. The idea
is to convert the single slowly-converging sum :eq:`eqn. %s <eqntotalcoulomb>`
into two quickly-converging terms and a constant term:

.. math:: \begin{aligned}
          V &=& V_{\mathrm{dir}} + V_{\mathrm{rec}} + V_{0} \\[0.5ex]
          V_{\mathrm{dir}} &=& \frac{f}{2} \sum_{i,j}^{N}
          \sum_{n_x}\sum_{n_y}
          \sum_{n_{z}*} q_i q_j \frac{\mbox{erfc}(\beta {r}_{ij,{\bf n}} )}{{r}_{ij,{\bf n}}} \\[0.5ex]
          V_{\mathrm{rec}} &=& \frac{f}{2 \pi V} \sum_{i,j}^{N} q_i q_j
          \sum_{m_x}\sum_{m_y}
          \sum_{m_{z}*} \frac{\exp{\left( -(\pi {\bf m}/\beta)^2 + 2 \pi i
                {\bf m} \cdot ({\bf r}_i - {\bf r}_j)\right)}}{{\bf m}^2} \\[0.5ex]
          V_{0} &=& -\frac{f \beta}{\sqrt{\pi}}\sum_{i}^{N} q_i^2,\end{aligned}
          :label: eqntotalcoloumbseparate

where :math:`\beta` is a parameter that determines the relative weight
of the direct and reciprocal sums and :math:`{\bf m}=(m_x,m_y,m_z)`. In
this way we can use a short cut-off (of the order of :math:`1`  nm) in
the direct space sum and a short cut-off in the reciprocal space sum
(*e.g.* 10 wave vectors in each direction). Unfortunately, the
computational cost of the reciprocal part of the sum increases as
:math:`N^2` (or :math:`N^{3/2}` with a slightly better algorithm) and it
is therefore not realistic for use in large systems.

Using Ewald
^^^^^^^^^^^

Don’t use Ewald unless you are absolutely sure this is what you want -
for almost all cases the PME method below will perform much better. If
you still want to employ classical Ewald summation enter this in your
:ref:`mdp` file, if the side of your box is about :math:`3`  nm:

::

    coulombtype     = Ewald
    rvdw            = 0.9
    rlist           = 0.9
    rcoulomb        = 0.9
    fourierspacing  = 0.6
    ewald-rtol      = 1e-5

The ratio of the box dimensions and the fourierspacing parameter
determines the highest magnitude of wave vectors :math:`m_x,m_y,m_z` to
use in each direction. With a 3-nm cubic box this example would use
:math:`11` wave vectors (from :math:`-5` to :math:`5`) in each
direction. The ``ewald-rtol`` parameter is the relative strength of the
electrostatic interaction at the cut-off. Decreasing this gives you a
more accurate direct sum, but a less accurate reciprocal sum.

.. _pme:

PME
~~~

Particle-mesh Ewald is a method proposed by Tom
Darden \ :ref:`14 <refDarden93>` to improve the performance of the reciprocal sum.
Instead of directly summing wave vectors, the charges are assigned to a
grid using interpolation. The implementation in |Gromacs| uses cardinal
B-spline interpolation \ :ref:`15 <refEssmann95>`, which is referred to as
smooth PME (SPME). The grid is then Fourier transformed with a 3D FFT
algorithm and the reciprocal energy term obtained by a single sum over
the grid in k-space.

The potential at the grid points is calculated by inverse
transformation, and by using the interpolation factors we get the forces
on each atom.

The PME algorithm scales as :math:`N \log(N)`, and is substantially
faster than ordinary Ewald summation on medium to large systems. On very
small systems it might still be better to use Ewald to avoid the
overhead in setting up grids and transforms. For the parallelization of
PME see the section on MPMD PME (:ref:`mpmdpme`).

With the Verlet cut-off scheme, the PME direct space potential is
shifted by a constant such that the potential is zero at the cut-off.
This shift is small and since the net system charge is close to zero,
the total shift is very small, unlike in the case of the Lennard-Jones
potential where all shifts add up. We apply the shift anyhow, such that
the potential is the exact integral of the force.

Using PME
^^^^^^^^^

As an example for using Particle-mesh Ewald summation in |Gromacs|,
specify the following lines in your :ref:`mdp` file:

::

    coulombtype     = PME
    rvdw            = 0.9
    rlist           = 0.9
    rcoulomb        = 0.9
    fourierspacing  = 0.12
    pme-order       = 4
    ewald-rtol      = 1e-5

In this case the ``fourierspacing`` parameter determines the
maximum spacing for the FFT grid (i.e. minimum number of grid points),
and ``pme-order`` controls the interpolation order. Using
fourth-order (cubic) interpolation and this spacing should give
electrostatic energies accurate to about :math:`5\cdot10^{-3}`. Since
the Lennard-Jones energies are not this accurate it might even be
possible to increase this spacing slightly.

Pressure scaling works with PME, but be aware of the fact that
anisotropic scaling can introduce artificial ordering in some systems.

P3M-AD
~~~~~~

The Particle-Particle
Particle-Mesh
methods of Hockney & Eastwood can also be applied in |Gromacs| for the
treatment of long range electrostatic
interactions \ :ref:`106 <refHockney81>`. Although the P3M method was the first efficient long-range
electrostatics method for molecular simulation, the smooth PME (SPME)
method has largely replaced P3M as the method of choice in atomistic
simulations. One performance disadvantage of the original P3M method was
that it required 3 3D-FFT back transforms to obtain the forces on the
particles. But this is not required for P3M and the forces can be
derived through analytical differentiation of the potential, as done in
PME. The resulting method is termed P3M-AD. The only remaining
difference between P3M-AD and PME is the optimization of the lattice
Green influence function for error minimization that P3M uses. However,
in 2012 it has been shown that the SPME influence function can be
modified to obtain P3M \ :ref:`107 <refBallenegger2012>`. This means
that the advantage of error minimization in P3M-AD can be used at the
same computational cost and with the same code as PME, just by adding a
few lines to modify the influence function. However, at optimal
parameter setting the effect of error minimization in P3M-AD is less
than 10%. P3M-AD does show large accuracy gains with interlaced (also
known as staggered) grids, but that is not supported in |Gromacs| (yet).

P3M is used in |Gromacs| with exactly the same options as used with PME by
selecting the electrostatics type:

::

    coulombtype     = P3M-AD

Optimizing Fourier transforms and PME calculations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

It is recommended to optimize the parameters for calculation of
electrostatic interaction such as PME grid dimensions and cut-off radii.
This is particularly relevant to do before launching long production
runs.

:ref:`gmx mdrun` will automatically do a lot of PME
optimization, and |Gromacs| also includes a special tool,
:ref:`gmx tune_pme`, which automates the process of selecting
the optimal number of PME-only ranks.
Viscosity calculation
---------------------

The shear viscosity is a property of liquids that can be determined
easily by experiment. It is useful for parameterizing a force field
because it is a kinetic property, while most other properties which are
used for parameterization are thermodynamic. The viscosity is also an
important property, since it influences the rates of conformational
changes of molecules solvated in the liquid.

The viscosity can be calculated from an equilibrium simulation using an
Einstein relation:

.. math::  \eta = \frac{1}{2}\frac{V}{k_B T} \lim_{t \rightarrow \infty}
           \frac{\mbox{d}}{\mbox{d} t} \left\langle 
           \left( \int_{t_0}^{{t_0}+t} P_{xz}(t') \mbox{d} t' \right)^2
           \right\rangle_{t_0}
           :label: eqneinsteinrelation

This can be done with :ref:`gmx energy <gmx energy>`. This method converges
very slowly \ :ref:`149 <refHess2002a>`, and as such a nanosecond simulation might not
be long enough for an accurate determination of the viscosity. The
result is very dependent on the treatment of the electrostatics. Using a
(short) cut-off results in large noise on the off-diagonal pressure
elements, which can increase the calculated viscosity by an order of
magnitude.

|Gromacs| also has a non-equilibrium method for determining the
viscosity \ :ref:`149 <refHess2002a>`. This makes use of the fact that energy, which is
fed into system by external forces, is dissipated through viscous
friction. The generated heat is removed by coupling to a heat bath. For
a Newtonian liquid adding a small force will result in a velocity
gradient according to the following equation:

.. math:: a_x(z) + \frac{\eta}{\rho} \frac{\partial^2 v_x(z)}{\partial z^2} = 0
          :label: eqnviscositygradiant

Here we have applied an acceleration :math:`a_x(z)` in the
:math:`x`-direction, which is a function of the :math:`z`-coordinate. In
|Gromacs| the acceleration profile is:

.. math:: a_x(z) = A \cos\left(\frac{2\pi z}{l_z}\right)
          :label: eqnviscosityacceleration

where :math:`l_z` is the height of the box. The generated velocity
profile is:

.. math:: v_x(z) = V \cos\left(\frac{2\pi z}{l_z}\right)
          :label: eqnviscosityprofile1

.. math:: V = A \frac{\rho}{\eta}\left(\frac{l_z}{2\pi}\right)^2
          :label: eqnviscosityprofile2

The viscosity can be calculated from :math:`A` and :math:`V`:

.. math:: \eta = \frac{A}{V}\rho \left(\frac{l_z}{2\pi}\right)^2
          :label: eqnvisc

In the simulation :math:`V` is defined as:

.. math:: V = \frac{\displaystyle \sum_{i=1}^N m_i v_{i,x} 2 \cos\left(\frac{2\pi z}{l_z}\right)}
          {\displaystyle \sum_{i=1}^N m_i}
          :label: eqnsimulationviscosity

The generated velocity profile is not coupled to the heat bath.
Moreover, the velocity profile is excluded from the kinetic energy. One
would like :math:`V` to be as large as possible to get good statistics.
However, the shear rate should not be so high that the system gets too
far from equilibrium. The maximum shear rate occurs where the cosine is
zero, the rate being:

.. math:: \mbox{sh}_{\max} =  \max_z \left| \frac{\partial v_x(z)}{\partial z} \right|
          = A \frac{\rho}{\eta} \frac{l_z}{2\pi}
          :label: eqnshearrate

For a simulation with: :math:`\eta=10^{-3}`
[kgm\ :math:`^{-1}`\ s\ :math:`^{-1}`],
:math:`\rho=10^3`\ [kgm\ :math:`^{-3}`] and :math:`l_z=2\pi`\ [nm],
:math:`\mbox{sh}_{\max}=1`\ [psnm\ :math:`^{-1}`] :math:`A`. This shear
rate should be smaller than one over the longest correlation time in the
system. For most liquids, this will be the rotation correlation time,
which is around 10 ps. In this case, :math:`A` should be smaller than
0.1[nmps\ :math:`^{-2}`]. When the shear rate is too high, the observed
viscosity will be too low. Because :math:`V` is proportional to the
square of the box height, the optimal box is elongated in the
:math:`z`-direction. In general, a simulation length of 100 ps is enough
to obtain an accurate value for the viscosity.

The heat generated by the viscous friction is removed by coupling to a
heat bath. Because this coupling is not instantaneous the real
temperature of the liquid will be slightly lower than the observed
temperature. Berendsen derived this temperature
shift \ :ref:`31 <refBerendsen91>`, which can be written in terms of the
shear rate as:

.. math:: T_s = \frac{\eta\,\tau}{2 \rho\,C_v} \mbox{sh}_{\max}^2
          :label: eqnberendsentempshift

where :math:`\tau` is the coupling time for the Berendsen thermostat
and :math:`C_v` is the heat capacity. Using the values of the example
above, :math:`\tau=10^{-13}` [s] and :math:`C_v=2 \cdot 10^3`\ [J
kg\ :math:`^{-1}`\ K\ :math:`^{-1}`], we get:
:math:`T_s=25`\ [Kps\ :math:`^{-2}`]sh\ :math:`_{\max}^2`. When we want
the shear rate to be smaller than :math:`1/10`\ [ps\ :math:`^{-1}`],
:math:`T_s` is smaller than 0.25[K], which is negligible.

**Note** that the system has to build up the velocity profile when
starting from an equilibrium state. This build-up time is of the order
of the correlation time of the liquid.

Two quantities are written to the energy file, along with their averages
and fluctuations: :math:`V` and :math:`1/\eta`, as obtained from
(:eq:`%s <eqnvisc>`).

Tabulated interaction functions
-------------------------------

.. _cubicspline:

Cubic splines for potentials
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In some of the inner loops of |Gromacs|, look-up tables are used for
computation of potential and forces. The tables are interpolated using a
cubic spline algorithm. There are separate tables for electrostatic,
dispersion, and repulsion interactions, but for the sake of caching
performance these have been combined into a single array. The cubic
spline interpolation for :math:`x_i \leq x < x_{i+1}` looks like this:

.. math::  V_s(x) = A_0 + A_1 \,\epsilon + A_2 \,\epsilon^2 + A_3 \,\epsilon^3
           :label: eqnspline

where the table spacing :math:`h` and fraction :math:`\epsilon` are
given by:

.. math::  \begin{aligned}
           h	&=&	x_{i+1} - x_i	\\
           \epsilon&=&	(x - x_i)/h\end{aligned}
           :label: eqntablespaceing

so that :math:`0 \le \epsilon < 1`. From this, we can calculate the
derivative in order to determine the forces:

.. math::  -V_s'(x) ~=~ 
           -\frac{{\rm d}V_s(x)}{{\rm d}\epsilon}\frac{{\rm d}\epsilon}{{\rm d}x} ~=~
           -(A_1 + 2 A_2 \,\epsilon + 3 A_3 \,\epsilon^2)/h
           :label: eqntablederivative

The four coefficients are determined from the four conditions that
:math:`V_s` and :math:`-V_s'` at both ends of each interval should match
the exact potential :math:`V` and force :math:`-V'`. This results in the
following errors for each interval:

.. math:: \begin{aligned}
          | V_s  - V  | _{max} &=& V'''' \frac{h^4}{384} + O(h^5) \\
          | V_s' - V' | _{max} &=& V'''' \frac{h^3}{72\sqrt{3}} + O(h^4) \\
          | V_s''- V''| _{max} &=& V'''' \frac{h^2}{12}  + O(h^3)\end{aligned}
          :label: eqntableerrors

V and V’ are continuous, while V” is the first discontinuous
derivative. The number of points per nanometer is 500 and 2000 for
mixed- and double-precision versions of |Gromacs|, respectively. This
means that the errors in the potential and force will usually be smaller
than the mixed precision accuracy.

|Gromacs| stores :math:`A_0`, :math:`A_1`, :math:`A_2` and :math:`A_3`.
The force routines get a table with these four parameters and a scaling
factor :math:`s` that is equal to the number of points per nm. (**Note**
that :math:`h` is :math:`s^{-1}`). The algorithm goes a little something
like this:

#. Calculate distance vector
   (:math:`\mathbf{r}_{ij}`) and distance
   r\ :math:`_{ij}`

#. Multiply r\ :math:`_{ij}` by :math:`s` and truncate to an integer
   value :math:`n_0` to get a table index

#. Calculate fractional component (:math:`\epsilon` =
   :math:`s`\ r\ :math:`_{ij} - n_0`) and :math:`\epsilon^2`

#. Do the interpolation to calculate the potential :math:`V` and the
   scalar force :math:`f`

#. Calculate the vector force :math:`\mathbf{F}` by
   multiplying :math:`f` with
   :math:`\mathbf{r}_{ij}`

**Note** that table look-up is significantly *slower* than computation
of the most simple Lennard-Jones and Coulomb interaction. However, it is
much faster than the shifted Coulomb function used in conjunction with
the PPPM method. Finally, it is much easier to modify a table for the
potential (and get a graphical representation of it) than to modify the
inner loops of the MD program.

User-specified potential functions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

You can also use your own potential functions without editing the
|Gromacs| code. The potential function should be according to the
following equation

.. math:: V(r_{ij}) ~=~ \frac{q_i q_j}{4 \pi\epsilon_0} f(r_{ij}) + C_6 \,g(r_{ij}) + C_{12} \,h(r_{ij})
          :label: eqnuserpotfunction

where :math:`f`, :math:`g`, and :math:`h` are user defined functions.
**Note** that if :math:`g(r)` represents a normal dispersion
interaction, :math:`g(r)` should be :math:`<` 0. C\ :math:`_6`,
C\ :math:`_{12}` and the charges are read from the topology. Also note
that combination rules are only supported for Lennard-Jones and
Buckingham, and that your tables should match the parameters in the
binary topology.

When you add the following lines in your :ref:`mdp` file:

::

    rlist           = 1.0
    coulombtype     = User
    rcoulomb        = 1.0
    vdwtype         = User
    rvdw            = 1.0

:ref:`mdrun <gmx mdrun>` will read a single non-bonded table file, or
multiple when ``energygrp-table`` is set (see below). The
name of the file(s) can be set with the :ref:`mdrun <gmx mdrun>` option
``-table``. The table file should contain seven columns of
table look-up data in the order: :math:`x`, :math:`f(x)`,
:math:`-f'(x)`, :math:`g(x)`, :math:`-g'(x)`, :math:`h(x)`,
:math:`-h'(x)`. The :math:`x` should run from 0 to :math:`r_c+1` (the
value of ``table_extension`` can be changed in the :ref:`mdp` file). You can
choose the spacing you like; for the standard tables |Gromacs| uses a
spacing of 0.002 and 0.0005 nm when you run in mixed and double
precision, respectively. In this context, :math:`r_c` denotes the
maximum of the two cut-offs ``rvdw`` and ``rcoulomb`` (see above). These
variables need not be the same (and need not be 1.0 either). Some
functions used for potentials contain a singularity at :math:`x = 0`,
but since atoms are normally not closer to each other than 0.1 nm, the
function value at :math:`x = 0` is not important. Finally, it is also
possible to combine a standard Coulomb with a modified LJ potential (or
vice versa). One then specifies *e.g.* ``coulombtype = Cut-off`` or
``coulombtype = PME``, combined with ``vdwtype = User``. The table file must
always contain the 7 columns however, and meaningful data (i.e. not
zeroes) must be entered in all columns. A number of pre-built table
files can be found in the ``GMXLIB`` directory for 6-8, 6-9, 6-10, 6-11, and
6-12 Lennard-Jones potentials combined with a normal Coulomb.

If you want to have different functional forms between different groups
of atoms, this can be set through energy groups. Different tables can be
used for non-bonded interactions between different energy groups pairs
through the :ref:`mdp` option ``energygrp-table`` (see details in the User Guide).
Atoms that should interact with a different potential should be put into
different energy groups. Between group pairs which are not listed in
``energygrp-table``, the normal user tables will be used. This makes it easy
to use a different functional form between a few types of atoms.
.. _dgimplement:

Free energy implementation
--------------------------

For free energy calculations, there are two things that must be
specified; the end states, and the pathway connecting the end states.
The end states can be specified in two ways. The most straightforward is
through the specification of end states in the topology file. Most
potential forms support both an :math:`A` state and a :math:`B` state.
Whenever both states are specified, the :math:`A` state corresponds
to the initial free energy state, and the :math:`B` state corresponds to
the final state.

In some cases, the end state can also be defined in some cases without
altering the topology, solely through the :ref:`mdp` file,
through the use of the
``couple-moltype``,
``couple-lambda0``,
``couple-lambda1``, and ``couple-intramol`` :ref:`mdp`
keywords. Any molecule type selected in ``couple-moltype``
will automatically have a :math:`B` state implicitly constructed (and
the :math:`A` state redefined) according to the
``couple-lambda`` keywords. ``couple-lambda0``
and ``couple-lambda1`` define the non-bonded parameters that
are present in the :math:`A` state (``couple-lambda0``) and
the :math:`B` state (``couple-lambda1``). The choices are
``q``,
``vdw``, and ``vdw-q``; these indicate the Coulombic, van der Waals, or
both parameters that are turned on in the respective state.

Once the end states are defined, then the path between the end states
has to be defined. This path is defined solely in the .mdp file.
Starting in 4.6, :math:`\lambda` is a vector of components, with
Coulombic, van der Waals, bonded, restraint, and mass components all
able to be adjusted independently. This makes it possible to turn off
the Coulombic term linearly, and then the van der Waals using soft core,
all in the same simulation. This is especially useful for replica
exchange or expanded ensemble simulations, where it is important to
sample all the way from interacting to non-interacting states in the
same simulation to improve sampling.

``fep-lambdas`` is the default array of :math:`\lambda`
values ranging from 0 to 1. All of the other lambda arrays use the
values in this array if they are not specified. The previous behavior,
where the pathway is controlled by a single :math:`\lambda` variable,
can be preserved by using only ``fep-lambdas`` to define the
pathway.


.. _figlambdaval:

.. figure:: plots/lambda-values.*
   :width: 12.00000cm

   Separate :math:`\lambda` values for Coulomb, van-der-Waals and restraint interactions.

:numref:`Fig. %s <figlambdaval>` shows an example of different lambda arrays.
There, first the Coulombic terms are reduced, then
the van der Waals terms, changing bonded at the same time rate as the
van der Waals, but changing the restraints throughout the first
two-thirds of the simulation. The corresponding :math:`\lambda`
vector is given here:

::

    coul-lambdas           = 0.0 0.2 0.5 1.0 1.0 1.0 1.0 1.0 1.0 1.0
    vdw-lambdas            = 0.0 0.0 0.0 0.0 0.4 0.5 0.6 0.7 0.8 1.0
    bonded-lambdas         = 0.0 0.0 0.0 0.0 0.4 0.5 0.6 0.7 0.8 1.0
    restraint-lambdas      = 0.0 0.0 0.1 0.2 0.3 0.5 0.7 1.0 1.0 1.0

This is also equivalent to:

::

    fep-lambdas            = 0.0 0.0 0.0 0.0 0.4 0.5 0.6 0.7 0.8 1.0
    coul-lambdas           = 0.0 0.2 0.5 1.0 1.0 1.0 1.0 1.0 1.0 1.0
    restraint-lambdas      = 0.0 0.0 0.1 0.2 0.3 0.5 0.7 1.0 1.0 1.0

The ``fep-lambda`` array, in this case, is being used as the
default to fill in the bonded and van der Waals :math:`\lambda` arrays.
Usually, it’s best to fill in all arrays explicitly, just to make sure
things are properly assigned.

If you want to turn on only restraints going from :math:`A` to
:math:`B`, then it would be:

::

    restraint-lambdas      = 0.0 0.1 0.2 0.4 0.6 1.0

and all of the other components of the :math:`\lambda` vector would be
left in the :math:`A` state.

To compute free energies with a vector :math:`\lambda` using
thermodynamic integration, then the TI equation becomes vector equation:

.. math:: \Delta F = \int \langle \nabla H \rangle \cdot d\vec{\lambda}
          :label: eqnfepti

or for finite differences:

.. math:: \Delta F \approx \int \sum \langle \nabla H \rangle \cdot \Delta\lambda
          :label: eqnfepfinitediff

The external `pymbar script <https://SimTK.org/home/pymbar>`_
can compute this integral automatically
from the |Gromacs| ``dhdl.xvg`` output.

Potential of mean force
-----------------------

A potential of mean force (PMF) is a potential that is obtained by
integrating the mean force from an ensemble of configurations. In
|Gromacs|, there are several different methods to calculate the mean
force. Each method has its limitations, which are listed below.

-  **pull code:** between the centers of mass of molecules or groups of
   molecules.

-  **AWH code:** currently acts on coordinates provided by the pull
   code or the free-energy lambda parameter.

-  **free-energy code with harmonic bonds or constraints:** between
   single atoms.

-  **free-energy code with position restraints:** changing the
   conformation of a relatively immobile group of atoms.

-  **pull code in limited cases:** between groups of atoms that are part
   of a larger molecule for which the bonds are constrained with SHAKE
   or LINCS. If the pull group if relatively large, the pull code can be
   used.

The pull and free-energy code a described in more detail in the
following two sections.

Entropic effects
^^^^^^^^^^^^^^^^

When a distance between two atoms or the centers of mass of two groups
is constrained or restrained, there will be a purely entropic
contribution to the PMF due to the rotation of the two
groups \ :ref:`134 <refRMNeumann1980a>`. For a system of two
non-interacting masses the potential of mean force is:

.. math:: V_{pmf}(r) = -(n_c - 1) k_B T \log(r)
          :label: eqnfepentropy

where :math:`n_c` is the number of dimensions in which the constraint
works (i.e. :math:`n_c=3` for a normal constraint and :math:`n_c=1` when
only the :math:`z`-direction is constrained). Whether one needs to
correct for this contribution depends on what the PMF should represent.
When one wants to pull a substrate into a protein, this entropic term
indeed contributes to the work to get the substrate into the protein.
But when calculating a PMF between two solutes in a solvent, for the
purpose of simulating without solvent, the entropic contribution should
be removed. **Note** that this term can be significant; when at 300K the
distance is halved, the contribution is 3.5 kJ mol\ :math:`^{-1}`.
.. _compel:

Computational Electrophysiology
-------------------------------

The Computational Electrophysiology (CompEL) protocol
:ref:`147 <refKutzner2011b>` allows the simulation of ion flux through membrane channels,
driven by transmembrane potentials or ion concentration gradients. Just
as in real cells, CompEL establishes transmembrane potentials by
sustaining a small imbalance of charges :math:`\Delta q` across the
membrane, which gives rise to a potential difference :math:`\Delta U`
according to the membrane capacitance:

.. math:: \Delta U = \Delta q / C_{membrane}
          :label: eqnmembcap

The transmembrane electric field and concentration gradients are
controlled by :ref:`mdp` options, which allow the user to set
reference counts for the ions on either side of the membrane. If a
difference between the actual and the reference numbers persists over a
certain time span, specified by the user, a number of ion/water pairs
are exchanged between the compartments until the reference numbers are
restored. Alongside the calculation of channel conductance and ion
selectivity, CompEL simulations also enable determination of the channel
reversal potential, an important characteristic obtained in
electrophysiology experiments.

In a CompEL setup, the simulation system is divided into two
compartments **A** and **B** with independent ion concentrations. This
is best achieved by using double bilayer systems with a copy (or copies)
of the channel/pore of interest in each bilayer
(:numref:`Fig. %s <fig-compelsetup>` A, B). If the channel axes
point in the same direction, channel flux is observed simultaneously at
positive and negative potentials in this way, which is for instance
important for studying channel rectification.

.. _fig-compelsetup:

.. figure:: plots/compelsetup.*
   :width: 13.50000cm

   Typical double-membrane setup for CompEL simulations (A, B).
   Ion/water molecule exchanges will be performed as needed between the
   two light blue volumes around the dotted black lines (A). Plot (C)
   shows the potential difference :math:`\Delta U` resulting from the
   selected charge imbalance :math:`\Delta q_{ref}` between the
   compartments.

The potential difference :math:`\Delta U` across the membrane is easily
calculated with the :ref:`gmx potential <gmx potential>` utility. By this, the potential drop
along :math:`z` or the pore axis is exactly known in each time interval
of the simulation (:numref:`Fig. %s <fig-compelsetup>` C). Type and number of ions
:math:`n_i` of charge :math:`q_i`, traversing the channel in the
simulation, are written to the swapions.xvg output file, from which the
average channel conductance :math:`G` in each interval :math:`\Delta t`
is determined by:

.. math:: G = \frac{\sum_{i} n_{i}q_{i}}{\Delta t \, \Delta U} \, .
          :label: eqnchannelcond

The ion selectivity is calculated as the number flux ratio of different
species. Best results are obtained by averaging these values over
several overlapping time intervals.

The calculation of reversal potentials is best achieved using a small
set of simulations in which a given transmembrane concentration gradient
is complemented with small ion imbalances of varying magnitude. For
example, if one compartment contains 1M salt and the other 0.1M, and
given charge neutrality otherwise, a set of simulations with
:math:`\Delta q = 0\,e`, :math:`\Delta q = 2\,e`,
:math:`\Delta q = 4\,e` could be used. Fitting a straight line through
the current-voltage relationship of all obtained :math:`I`-:math:`U`
pairs near zero current will then yield :math:`U_{rev}`.

Usage
^^^^^

The following :ref:`mdp` options control the CompEL protocol:

::

    swapcoords     = Z        ; Swap positions: no, X, Y, Z
    swap-frequency = 100      ; Swap attempt frequency

Choose ``Z`` if your membrane is in the :math:`xy`-plane
(:numref:`Fig. %s <fig-compelsetup>`). Ions will be exchanged
between compartments depending on their :math:`z`-positions alone.
``swap-frequency`` determines how often a swap attempt will
be made. This step requires that the positions of the split groups, the
ions, and possibly the solvent molecules are communicated between the
parallel processes, so if chosen too small it can decrease the
simulation performance. The ``Position swapping`` entry in
the cycle and time accounting table at the end of the
``md.log`` file summarizes the amount of runtime spent in
the swap module.

::

    split-group0   = channel0 ; Defines compartment boundary
    split-group1   = channel1 ; Defines other compartment boundary
    massw-split0   = no       ; use mass-weighted center?
    massw-split1   = no

``split-group0`` and ``split-group1`` are two
index groups that define the boundaries between the two compartments,
which are usually the centers of the channels. If
``massw-split0`` or ``massw-split1`` are set to
``yes``, the center of mass of each index group is used as
boundary, here in :math:`z`-direction. Otherwise, the geometrical
centers will be used (:math:`\times` in
:numref:`Fig. %s <fig-compelsetup>` A). If, such as here, a membrane
channel is selected as split group, the center of the channel will
define the dividing plane between the compartments (dashed horizontal
lines). All index groups must be defined in the index file.

If, to restore the requested ion counts, an ion from one compartment has
to be exchanged with a water molecule from the other compartment, then
those molecules are swapped which have the largest distance to the
compartment-defining boundaries (dashed horizontal lines). Depending on
the ion concentration, this effectively results in exchanges of
molecules between the light blue volumes. If a channel is very
asymmetric in :math:`z`-direction and would extend into one of the swap
volumes, one can offset the swap exchange plane with the
``bulk-offset`` parameter. A value of 0.0 means no offset
:math:`b`, values :math:`-1.0 < b < 0` move the swap exchange plane
closer to the lower, values :math:`0 < b < 1.0` closer to the upper
membrane. :numref:`Fig. %s <fig-compelsetup>` A (left) depicts that
for the **A** compartment.

::

    solvent-group  = SOL      ; Group containing the solvent molecules
    iontypes       = 3        ; Number of different ion types to control
    iontype0-name  = NA       ; Group name of the ion type
    iontype0-in-A  = 51       ; Reference count of ions of type 0 in A
    iontype0-in-B  = 35       ; Reference count of ions of type 0 in B
    iontype1-name  = K
    iontype1-in-A  = 10
    iontype1-in-B  = 38
    iontype2-name  = CL
    iontype2-in-A  = -1
    iontype2-in-B  = -1

The group name of solvent molecules acting as exchange partners for the
ions has to be set with ``solvent-group``. The number of
different ionic species under control of the CompEL protocol is given by
the ``iontypes`` parameter, while
``iontype0-name`` gives the name of the index group
containing the atoms of this ionic species. The reference number of ions
of this type can be set with the ``iontype0-in-A`` and
``iontype0-in-B`` options for compartments **A** and **B**,
respectively. Obviously, the sum of ``iontype0-in-A`` and
``iontype0-in-B`` needs to equal the number of ions in the
group defined by ``iontype0-name``. A reference number of
``-1`` means: use the number of ions as found at the
beginning of the simulation as the reference value.

::

    coupl-steps    = 10       ; Average over these many swap steps
    threshold      = 1        ; Do not swap if < threshold

If ``coupl-steps`` is set to 1, then the momentary ion
distribution determines whether ions are exchanged.
``coupl-steps > 1`` will use the time-average of ion
distributions over the selected number of attempt steps instead. This
can be useful, for example, when ions diffuse near compartment
boundaries, which would lead to numerous unproductive ion exchanges. A
``threshold`` of 1 means that a swap is performed if the
average ion count in a compartment differs by at least 1 from the
requested values. Higher thresholds will lead to toleration of larger
differences. Ions are exchanged until the requested number :math:`\pm`
the threshold is reached.

::

    cyl0-r         = 5.0      ; Split cylinder 0 radius (nm)
    cyl0-up        = 0.75     ; Split cylinder 0 upper extension (nm)
    cyl0-down      = 0.75     ; Split cylinder 0 lower extension (nm)
    cyl1-r         = 5.0      ; same for other channel
    cyl1-up        = 0.75
    cyl1-down      = 0.75

The cylinder options are used to define virtual geometric cylinders
around the channel’s pore to track how many ions of which type have
passed each channel. Ions will be counted as having traveled through a
channel according to the definition of the channel’s cylinder radius,
upper and lower extension, relative to the location of the respective
split group. This will not affect the actual flux or exchange, but will
provide you with the ion permeation numbers across each of the channels.
Note that an ion can only be counted as passing through a particular
channel if it is detected *within* the defined split cylinder in a swap
step. If ``swap-frequency`` is chosen too high, a particular
ion may be detected in compartment **A** in one swap step, and in
compartment **B** in the following swap step, so it will be unclear
through which of the channels it has passed.

A double-layered system for CompEL simulations can be easily prepared by
duplicating an existing membrane/channel MD system in the direction of
the membrane normal (typically :math:`z`) with 
:ref:`gmx editconf` ``-translate 0 0 <l_z>``, where ``l_z`` is the box
length in that direction. If you have already defined index groups for
the channel for the single-layered system, :ref:`gmx make_ndx`
``-n index.ndx -twin`` will provide you with the groups for the
double-layered system.

To suppress large fluctuations of the membranes along the swap
direction, it may be useful to apply a harmonic potential (acting only
in the swap dimension) between each of the two channel and/or bilayer
centers using umbrella pulling (see section :ref:`pull`).

Multimeric channels
^^^^^^^^^^^^^^^^^^^

If a split group consists of more than one molecule, the correct PBC
image of all molecules with respect to each other has to be chosen such
that the channel center can be correctly determined. |Gromacs| assumes
that the starting structure in the :ref:`tpr` file has the
correct PBC representation. Set the following environment variable to
check whether that is the case:

-  ``GMX_COMPELDUMP``: output the starting structure after
   it has been made whole to :ref:`pdb` file.
.. _fepmf:

Calculating a PMF using the free-energy code
--------------------------------------------

The free-energy coupling-parameter approach (see sec. :ref:`fecalc`)
provides several ways to calculate potentials of mean force. A potential
of mean force between two atoms can be calculated by connecting them
with a harmonic potential or a constraint. For this purpose there are
special potentials that avoid the generation of extra exclusions,
see sec. :ref:`excl`. When the position of the minimum or the constraint
length is 1 nm more in state B than in state A, the restraint or
constraint force is given by :math:`\partial H/\partial \lambda`. The
distance between the atoms can be changed as a function of
:math:`\lambda` and time by setting delta-lambda in the :ref:`mdp` file. The
results should be identical (although not numerically due to the
different implementations) to the results of the pull code with umbrella
sampling and constraint pulling. Unlike the pull code, the free energy
code can also handle atoms that are connected by constraints.

Potentials of mean force can also be calculated using position
restraints. With position restraints, atoms can be linked to a position
in space with a harmonic potential (see :ref:`positionrestraint`).
These positions can be made a function of the coupling parameter
:math:`\lambda`. The positions for the A and the B states are supplied
to :ref:`grompp <gmx grompp>` with the ``-r`` and ``-rb`` options, respectively. One could use this
approach to do targeted MD; note that we do not encourage the use of
targeted MD for proteins. A protein can be forced from one conformation
to another by using these conformations as position restraint
coordinates for state A and B. One can then slowly change
:math:`\lambda` from 0 to 1. The main drawback of this approach is that
the conformational freedom of the protein is severely limited by the
position restraints, independent of the change from state A to B. Also,
the protein is forced from state A to B in an almost straight line,
whereas the real pathway might be very different. An example of a more
fruitful application is a solid system or a liquid confined between
walls where one wants to measure the force required to change the
separation between the boundaries or walls. Because the boundaries (or
walls) already need to be fixed, the position restraints do not limit
the system in its sampling.
Shear simulations
-----------------

A common type of non-equilibrium simulations in fluid dynamics and rheology are
shearing simulations. These are non-equilibrium simulations where work is
performed on the simulation system to achieve a shear flow. This can be used
to compute viscosities and friction and to study the effect of shear stress on conformations.
In |Gromacs| there are four different ways to achieve shear flow.

Groups of atoms can be given a constant acceleration, which is effectively
a mass-weighted force. This will cause such groups to move with respect to
the rest of the system. Care needs to be taken to control the velocity of
the center of mass of the system. Normal center of mass motion removal
can not be used, as that would affect the flow in the system.

As |Gromacs| supports general triclinic unit-cell shapes, the unit cell can
be deformed to set up a shear flow. This can be achieved either by deforming
the unit cell directly using the ``deform`` option in the :ref:`mdp` file,
or this can be driven by applying an off-diagonal stress through pressure
coupling. In the former case, one can measure the viscosity through
the stress, in the latter case through measuring the shear rate.

For measuring the viscosity of simple liquids one can use a cosine-shaped
acceleration profile, which can be specified using the ``cos-acceleration``
option in the :ref:`mdp` file. As the unit-cell does not deform, this
avoids some complications of the other methods. The viscosity is computed
on the fly and reported in the energy file.

And finally, there is the case where one wants to study the effect of walls
on the flow. In particular, structured walls are of interest, consisting
of atoms that can be of any kind. In this case one wants to have walls
on two sides of the system, typically in the xy-plane close to z=0 and
the box height. The flow is then driven by moving the walls at constant
speed by using a constant force. A constant force can be achieved by
use of acceleration groups, but that will not allow position restraining
atoms in the walls along the direction of the shear, which is needed
for some types of walls. For the case of walls where (part of) the atoms
are position restrained, a constant speed can be set by using
the free-energy lambda-coupling code. To achieve this, you need to supply
a second, B-state, position restraint file with the ``-r`` option
of :ref:`gmx grompp`. If you shift the coordinates in this file by 1 nm
in the direction of shear, you can set the speed of the walls with the
``delta-lambda`` option in the :ref:`mdp` file. Note that this makes
lambda increase proportionally with simulation time. There is no limit
on magnitude of lambda and periodic shifts of walls are handled
correctly. When the position restraint coordinates are shifted by 1 nm,
the force on the walls is given directly by :math:`dV/d\lambda`.

A Couette flow is a popular setup in experiments. Unfortunately this is
difficult to achieve in simulations. The best would be to, as in experiment,
apply a pressure difference over (part of) the simulation box. But that
is not easy to set up. One can accelerate all liquid atoms, but this does
not guarantee that atoms that interact directly with the wall experience
the same forces as they would in an experiment. A slightly better setup
would be accelerating only the atoms in the middle of the flow,
but spatially defined acceleration groups are currently not supported
in |Gromacs|.
Embedding proteins into the membranes
-------------------------------------

|Gromacs| is capable of inserting the protein into pre-equilibrated lipid
bilayers with minimal perturbation of the lipids using the method, which
was initially described as a ProtSqueeze technique, \ :ref:`157 <refYesylevskyy2007>`
and later implemented as g_membed tool \ :ref:`158 <refWolf2010>`. Currently the
functionality of g_membed is available in mdrun as described in the
user guide.

This method works by first artificially shrinking the protein in the
:math:`xy`-plane, then it removes lipids that overlap with that much
smaller core. Then the protein atoms are gradually resized back to their
initial configuration, using normal dynamics for the rest of the system,
so the lipids adapt to the protein. Further lipids are removed as
required.

.. raw:: latex

    \clearpage


Non-equilibrium pulling
-----------------------

When the distance between two groups is changed continuously, work is
applied to the system, which means that the system is no longer in
equilibrium. Although in the limit of very slow pulling the system is
again in equilibrium, for many systems this limit is not reachable
within reasonable computational time. However, one can use the Jarzynski
relation \ :ref:`135 <refJarzynski1997a>` to obtain the equilibrium free-energy difference
:math:`\Delta G` between two distances from many non-equilibrium
simulations:

.. math:: \Delta G_{AB} = -k_BT \log \left\langle e^{-\beta W_{AB}} \right\rangle_A
          :label: eqJarz

where :math:`W_{AB}` is the work performed to force the system along
one path from state A to B, the angular bracket denotes averaging over a
canonical ensemble of the initial state A and :math:`\beta=1/k_B T`.

.. _pull:

Collective variables: the pull code
-----------------------------------

The pull code applies forces or constraints on
collective variables (sometimes referred to as reaction coordinates). The basic collective pull coordinates are
a distance, angle and dihedral angle between centers of mass of groups
atoms, the so-called "pull groups". More complex collective variables
can be defined using :ref:`transformationcoord`.
A pull group can be part of one or more pull coordinates.
Furthermore, a coordinate can also operate on a
single group and an absolute reference position in space. The distance
between a pair of groups can be determined in 1, 2 or 3 dimensions, or
can be along a user-defined vector. The reference distance can be
constant or can change linearly with time. Normally all atoms are
weighted by their mass, but an additional weighting factor can also be
used.

.. _fig-pull:

.. figure:: plots/pull.*
   :width: 6.00000cm

   Schematic picture of pulling a lipid out of a lipid bilayer with
   umbrella pulling. :math:`V_{rup}` is the velocity at which the spring
   is retracted, :math:`Z_{link}` is the atom to which the spring is
   attached and :math:`Z_{spring}` is the location of the spring.

Several different pull types, i.e. ways to apply the pull force, are
supported, and in all cases the reference distance can be constant or
linearly changing with time.

#. **Umbrella pulling** A harmonic potential is applied between the
   centers of mass of two groups. Thus, the force is proportional to the
   displacement.

#. **Constraint pulling** The distance between the centers of mass of
   two groups is constrained. The constraint force can be written to a
   file. This method uses the SHAKE algorithm but only needs 1 iteration
   to be exact if only two groups are constrained.

#. **Constant force pulling** A constant force is applied between the
   centers of mass of two groups. Thus, the potential is linear. In this
   case there is no reference distance of pull rate.

#. **Flat bottom pulling** Like umbrella pulling, but the potential and
   force are zero for coordinate values below
   (``pull-coord?-type = flat-bottom``) or above
   (``pull-coord?-type = flat-bottom-high``) a reference
   value. This is useful for restraining e.g. the distance between two
   molecules to a certain region.

#. **External potential** This takes the potential acting on the reaction
   coordinate from another module. Current only the Accelerated Weight
   Histogram method (see sec. :doc:`awh`) is supported, which provides
   adaptive biasing of pull coordinates.

In addition, there are different types of reaction coordinates,
so-called pull geometries. These are set with the :ref:`mdp`
option ``pull-coord?-geometry``.

Definition of the center of mass
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In |Gromacs|, there are three ways to define the center of mass of a
group. The standard way is a “plain” center of mass, possibly with
additional weighting factors. With periodic boundary conditions it is no
longer possible to uniquely define the center of mass of a group of
atoms. Therefore, a reference atom is used. For determining the center
of mass, for all other atoms in the group, the closest periodic image to
the reference atom is used. This uniquely defines the center of mass. By
default, the middle (determined by the order in the topology) atom is
used as a reference atom, but the user can also select any other atom if
it would be closer to center of the group.

When there are large pull groups, such as a
lipid bilayer, ``pull-pbc-ref-prev-step-com`` can be used to avoid potential
large movements of the center of mass in case that atoms in the pull group
move so much that the reference atom is too far from the intended center of mass.
With this option enabled the center of mass from the previous step is used,
instead of the position of the reference atom, to determine the reference position.
The position of the reference atom is still used for the first step. For large pull
groups it is important to select a reference atom that is close to the intended
center of mass, i.e. do not use ``pull-group?-pbcatom = 0``.

For a layered system, for instance a lipid bilayer, it may be of
interest to calculate the PMF of a lipid as function of its distance
from the whole bilayer. The whole bilayer can be taken as reference
group in that case, but it might also be of interest to define the
reaction coordinate for the PMF more locally. The :ref:`mdp`
option ``pull-coord?-geometry = cylinder`` does not use all
the atoms of the reference group, but instead dynamically only those
within a cylinder with radius ``pull-cylinder-r`` around the
pull vector going through the pull group. This only works for distances
defined in one dimension, and the cylinder is oriented with its long
axis along this one dimension. To avoid jumps in the pull force,
contributions of atoms are weighted as a function of distance (in
addition to the mass weighting), for atom :math:`i`:

.. math:: \begin{aligned}
          w_i(r_i < r_\mathrm{cyl}) & = &
          1-2 \left(\frac{r_i}{r_\mathrm{cyl}}\right)^2 + \left(\frac{r_i}{r_\mathrm{cyl}}\right)^4 \\
          w_i(r_i \geq r_\mathrm{cyl}) & = & 0\end{aligned}
          :label: eqnpulldistmassweight

Note that the radial dependence on the weight causes a radial force on
both cylinder group and the other pull group:

.. math:: \begin{aligned}
          F^\mathrm{radial}_i(r_i < r_\mathrm{cyl}) & = &
          F^\mathrm{pull} a_i \frac{1}{\sum_i w_i}\frac{4}{r_\mathrm{cyl}^4} r_i (r_i^2 - r_\mathrm{cyl}^2) \\
          F^\mathrm{radial}_i(r_i \geq r_\mathrm{cyl}) & = & 0\end{aligned}
          :label: eqnpulldistmassweightradialforce

where :math:`F^\mathrm{pull}` is the pull force working between the groups
and :math:`a_i` is the axial distance of atom :math:`i` to the center of
mass of the cylinder group. This is an undesirable,
but unavoidable effect. To minimize this effect, the cylinder radius
should be chosen sufficiently large. The effective mass is 0.47 times
that of a cylinder with uniform weights and equal to the mass of uniform
cylinder of 0.79 times the radius.

.. _fig-pullref:

.. figure:: plots/pullref.*
   :width: 6.00000cm

   Comparison of a plain center of mass reference group versus a
   cylinder reference group applied to interface systems. C is the
   reference group. The circles represent the center of mass of two
   groups plus the reference group, :math:`d_c` is the reference
   distance.

For a group of molecules in a periodic system, a plain reference group
might not be well-defined. An example is a water slab that is connected
periodically in :math:`x` and :math:`y`, but has two liquid-vapor
interfaces along :math:`z`. In such a setup, water molecules can
evaporate from the liquid and they will move through the vapor, through
the periodic boundary, to the other interface. Such a system is
inherently periodic and there is no proper way of defining a “plain”
center of mass along :math:`z`. A proper solution is to using a cosine
shaped weighting profile for all atoms in the reference group. The
profile is a cosine with a single period in the unit cell. Its phase is
optimized to give the maximum sum of weights, including mass weighting.
This provides a unique and continuous reference position that is nearly
identical to the plain center of mass position in case all atoms are all
within a half of the unit-cell length. See ref :ref:`136 <refEngin2010a>`
for details.

When relative weights :math:`w_i` are used during the calculations,
either by supplying weights in the input or due to cylinder geometry or
due to cosine weighting, the weights need to be scaled to conserve
momentum:

.. math:: w'_i = w_i
          \left. \sum_{j=1}^N w_j \, m_j \right/ \sum_{j=1}^N w_j^2 \, m_j
          :label: eqnpullmassscale

where :math:`m_j` is the mass of atom :math:`j` of the group. The mass
of the group, required for calculating the constraint force, is:

.. math:: M = \sum_{i=1}^N w'_i \, m_i
          :label: eqnpullconstraint

The definition of the weighted center of mass is:

.. math:: \mathbf{r}_{com} = \left. \sum_{i=1}^N w'_i \, m_i \, \mathbf{r}_i \right/ M
          :label: eqnpullcom

From the centers of mass the AFM, constraint, or umbrella force
:math:`\mathbf{F}_{\!com}` on each group can be
calculated. The force on the center of mass of a group is redistributed
to the atoms as follows:

.. math:: \mathbf{F}_{\!i} = \frac{w'_i \, m_i}{M} \, \mathbf{F}_{\!com}
          :label: eqnpullcomforce

Definition of the pull direction
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The most common setup is to pull along the direction of the vector
containing the two pull groups, this is selected with
``pull-coord?-geometry = distance``. You might want to pull
along a certain vector instead, which is selected with
``pull-coord?-geometry = direction``. But this can cause
unwanted torque forces in the system, unless you pull against a
reference group with (nearly) fixed orientation, e.g. a membrane protein
embedded in a membrane along x/y while pulling along z. If your
reference group does not have a fixed orientation, you should probably
use ``pull-coord?-geometry = direction-relative``, see
:numref:`Fig. %s <fig-pulldirrel>`. Since the potential now depends
on the coordinates of two additional groups defining the orientation,
the torque forces will work on these two groups.

.. _fig-pulldirrel:

.. figure:: plots/pulldirrel.*
   :width: 5.00000cm

   The pull setup for geometry ``direction-relative``. The
   “normal” pull groups are 1 and 2. Groups 3 and 4 define the pull
   direction and thus the direction of the normal pull forces (red).
   This leads to reaction forces (blue) on groups 3 and 4, which are
   perpendicular to the pull direction. Their magnitude is given by the
   “normal” pull force times the ratio of :math:`d_p` and the distance
   between groups 3 and 4.

Definition of the angle and dihedral pull geometries
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Four pull groups are required for ``pull-coord?-geometry =
angle``. In the same way as for geometries with two groups, each
consecutive pair of groups :math:`i` and :math:`i+1` define a vector
connecting the COMs of groups :math:`i` and :math:`i+1`. The angle is
defined as the angle between the two resulting vectors. E.g., the
:ref:`mdp` option ``pull-coord?-groups = 1 2 2 4``
defines the angle between the vector from the COM of group 1 to the COM
of group 2 and the vector from the COM of group 2 to the COM of group 4.
The angle takes values in the closed interval [0, 180] deg. For
``pull-coord?-geometry = angle-axis`` the angle is defined
with respect to a reference axis given by
``pull-coord?-vec`` and only two groups need to be given.
The dihedral geometry requires six pull groups. These pair up in the
same way as described above and so define three vectors. The dihedral
angle is defined as the angle between the two planes spanned by the two
first and the two last vectors. Equivalently, the dihedral angle can be
seen as the angle between the first and the third vector when these
vectors are projected onto a plane normal to the second vector (the axis
vector). As an example, consider a dihedral angle involving four groups:
1, 5, 8 and 9. Here, the :ref:`mdp` option
``pull-coord?-groups = 8 1 1 5 5 9`` specifies the three
vectors that define the dihedral angle: the first vector is the COM
distance vector from group 8 to 1, the second vector is the COM distance
vector from group 1 to 5, and the third vector is the COM distance
vector from group 5 to 9. The dihedral angle takes values in the
interval (-180, 180] deg and has periodic boundaries.

.. _transformationcoord:

The transformation pull coordinate
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The transformation pull coordinate is a "meta" pull coordinate that can
be used to define more complex collective variables.
It can transform one or more other pull coordinates using an arbitrary
mathematical expression. This is a powerful tool for generating
complex collective variables.
A simple example is a contact coordinate using a non-linear transformation
of a distance. More complex examples are a (non-)linear combination of
two or more pull coordinates or a sum of contacts.

Typically, the force constant for pull coordinate(s) the transformation
coordinates acts on should be zero. This avoids
unintended addition of direct forces on the pull coordinate(s)
to the indirect forces from the transition pull coordinate. This is not
a requirement, but having both a direct and indirect, from the tranformation
coordinate, force working on them is almost never desirable.
If the transformation is a linear combination of multiple distances,
it is useful to normalize the coefficients
such that the transformation coordinate also has units of nanometer.
That makes both the choice of the force constant and the interpretation easier.

Here are two examples of pull sections of the :ref:`mdp` input that use
a tranformation coordinate setups. The first is a contact reaction coordinate
that is 1 at contact and 0 at larger distances:

::

   pull                     = yes
   pull-ngroups             = 2
   pull-ncoords             = 2

   pull-group1-name         = groupA
   pull-group2-name         = groupB

   pull-coord1-type         = umbrella
   pull-coord1-geometry     = distance
   pull-coord1-groups       = 1 2
   pull-coord1-dim          = Y Y Y
   pull-coord1-k            = 0      ; avoid forces working directly on this distance

   pull-coord2-type         = umbrella
   pull-coord2-geometry     = transformation
   pull-coord2-expression   = 1/(1 + exp(50*(x1 - 1.8*0.3)))  ; x1 refers to the value of coord1
   pull-coord2-init         = 1      ; this restrains the distance to having the contact
   pull-coord2-k            = 100

The second example is an average of two distances:

::

   pull                     = yes
   pull-ngroups             = 4
   pull-ncoords             = 3

   pull-group1-name         = groupA
   pull-group2-name         = groupB
   pull-group3-name         = groupC
   pull-group4-name         = groupD

   pull-coord1-type         = umbrella
   pull-coord1-geometry     = distance
   pull-coord1-groups       = 1 2
   pull-coord1-dim          = Y Y Y
   pull-coord1-k            = 0      ; avoid forces working directly on this distance

   pull-coord2-type         = umbrella
   pull-coord2-geometry     = distance
   pull-coord2-groups       = 3 4
   pull-coord2-dim          = Y Y Y
   pull-coord2-k            = 0      ; avoid forces working directly on this distance

   pull-coord3-type         = umbrella
   pull-coord3-geometry     = transformation
   pull-coord3-expression   = 0.5*(x1 + x2)  ; x1 and x2 refer to the value of coord1 and coord2
   pull-coord3-init         = 0.8    ; restrains the average distance to 0.8 nm
   pull-coord3-k            = 1000


Limitations
^^^^^^^^^^^

There is one theoretical limitation: strictly speaking, constraint
forces can only be calculated between groups that are not connected by
constraints to the rest of the system. If a group contains part of a
molecule of which the bond lengths are constrained, the pull constraint
and LINCS or SHAKE bond constraint algorithms should be iterated
simultaneously. This is not done in |Gromacs|. This means that for
simulations with ``constraints = all-bonds`` in the :ref:`mdp` file pulling is,
strictly speaking, limited to whole molecules or groups of molecules. In
some cases this limitation can be avoided by using the free energy code,
see sec. :ref:`fepmf`. In practice, the errors caused by not iterating
the two constraint algorithms can be negligible when the pull group
consists of a large amount of atoms and/or the pull force is small. In
such cases, the constraint correction displacement of the pull group is
small compared to the bond lengths.
.. _mimic:

MiMiC Hybrid Quantum Mechanical/Molecular Mechanical simulations
----------------------------------------------------------------

This section describes the coupling to a novel QM/MM interface.
The Multiscale Modeling in Computational Chemistry (MiMiC) interface
combines |Gromacs| with the `CPMD QM code <http://cpmd.org/>`__.
To find information about other QM/MM implementations in
|Gromacs| please refer to the section :ref:`qmmm`.
Within a QM/MM approach, typically a small part of the system
(e.g. active site of an enzyme where a chemical reaction can take place)
is treated at the QM level of theory (as we cannot neglect electronic
degrees of freedom while describing some processes e.g.  chemical
reactions), while the rest of the system (remainder of the
protein, solvent, etc.) is described by the classical forcefield (MM).

Overview
^^^^^^^^
MiMiC implements the  QM/MM coupling scheme developed by the group
of Prof. U. Roethlisberger described in
\ :ref:`180 <refRoethlisbergerQMMM>`. This additive
scheme uses electrostatic embedding of the classical system within
the quantum Hamiltonian. The total QM/MM energy is calculated as
a sum of subsystem contributions:

   .. math::

      E_{tot} = E_{QM}+E_{MM}+E_{QM/MM}

The QM contribution is computed by CPMD, while the MM part is
processed by |Gromacs| and the cross terms are treated by the
MiMiC interface. Cross terms, i.e. the terms involving simultaneously
atoms from the QM region and atoms from the MM region consist of
both bonded and non-bonded interactions. 

The bonded interactions are taken from the forcefield used to
describe the MM part. Whenever there is a chemical bond crossing
the QM/MM boundary additional care has to be taken to handle this
situation correctly. Otherwise the QM atom involved in the cut bond
is left with an unsaturated electronic orbital leading to
unphysical system behaviour. Therefore, the dangling bond has to be capped
with another QM atom. There are two different options available
in CPMD for bond capping:

#. Hydrogen capping - the simplest approach is to cap the bond with a
   hydrogen atom, constraining its relative position
   
#. Link atom pseudo-potential - this strategy uses an ad-hoc pseudo-potential
   developed to cap the bond. This pseudo-potential would represent the real
   atom and, thus, will not require the bond constraint.
   
As in standard forcefields, the non-bonded contributions to :math:`E_{QM/MM}`
can be separated into van der Waals and electrostatic contributions.
The first contribution is again taken from the MM forcefield. The second
part of non-bonded interactions is handled by MiMiC within the
electrostatic embedding approach. This adds additional terms to the
Hamiltonian of the system:

   .. math::

      E_{QM/MM}^{es} = -\sum_a^{N_{mm}}Q_a\int\rho(\mathbf{r})\frac{r_{c,a}^4 
      - |\mathbf{R_a} - \mathbf{r}|^4}{r_{c,a}^5 - |\mathbf{R_a} - \mathbf{r}|^5}d\mathbf{r} 
      + \sum_a^{N_{mm}}\sum_n^{N_{qm}}Q_aZ_n
      \frac{r_{c,a}^4 - |\mathbf{R_a} - \mathbf{R_n}|^4}
      {r_{c,a}^5 - |\mathbf{R_a} - \mathbf{R_n}|^5}

where :math:`N_{mm}` is a number of MM atoms :math:`N_{qm}`, is the number of QM atoms
and :math:`r_{c,a}` is the covalent radius of the MM atoms. The first
term above corresponds to the damped Coulomb interaction between the
eletronic density :math:`\rho(\mathbf{r})` of the QM region and the MM
atoms. The damping is needed due to the fact that CPMD uses a plane-wave
basis set to expand the electronic wavefunction. Unlike localized
basis sets, plane waves are delocalized and this may give a rise to
the so-called electron spill-out problem: positively charged MM atoms
may artificially overpolarize the electronic cloud due to the absence
of quantum mechanical effects (e.g. Pauli repusion) that would normally
prevent it (in a fully quantum system). This functional form of the
damped Coulomb potential from the equation above was introduced in
\ :ref:`180 <refRoethlisbergerQMMM>`.

Since computing the integrals in the first term above can be computational
extremely expensive, MiMiC also implements hierarchical electrostatic
embedding scheme in order to mitigate the enormous computational effort
needed to compute :math:`N_{mm}` integrals over the electronic grid.
Within this scheme the MM atoms are grouped into two shells according
to the distance from the QM region: the short-ranged and long-ranged one.
For the MM atoms in the short-ranged shell the QM/MM interactions are
calculated using the equation above. In contrast to that, the interactions
involving MM atoms from the long-ranged shell are computed using
the multipolar expansion of the QM electrostatic potential.
More details about it can be found in \ :ref:`180 <refRoethlisbergerQMMM>`.


Application coupling model
^^^^^^^^^^^^^^^^^^^^^^^^^^

Unlike the majority of QM/MM interfaces, MiMiC uses a loose coupling between
partner codes. This means that instead of compiling both codes into a
single binary MiMiC builds separate executables for CPMD and |Gromacs|.
The user will then prepare the input for both codes and run them simultaneously.
Each of the codes is running using a separate pool of MPI processes and 
communicate the necessary data (e.g. coordinates, energies and forces) 
through MPI client-server mechanism. Within MiMiC framework CPMD acts 
as a server and |Gromacs| becomes the client.

Software prerequisites
^^^^^^^^^^^^^^^^^^^^^^

#. |Gromacs| version 2019+. Newer major releases may support multiple versions of
   MiMiC.
#. CPMD version 4.1+.

Usage
^^^^^

After :ref:`installing with MiMiC`, to run a MiMiC QM/MM simulation
one needs to:

#. Get and compile CPMD with MiMiC support.
#. Do a normal classical equilibration with |Gromacs|.
#. Create an index group representing QM atoms within |Gromacs|.
   Keep in mind that this group should also include link atoms
   bound to atoms in the QM region, as they have to be treated
   at quantum level.
#. Prepare input for CPMD and |Gromacs| according to the recommendations
   below.
#. Run both CPMD and |Gromacs| as two independent instances within
   a single batch job.

Preparing the input file for |Gromacs|
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
In order to setup the :ref:`mdp` file for a MiMiC simulation one needs
to add two options:

#. :mdp-value:`integrator=mimic` to enable MiMiC workflow within GROMACS.
#. ``QMMM-grps=<name_of_qm_index_group>`` to indicate all the atoms
   that are going to be handled by CPMD.

Since CPMD is going to perform the MD integration, only :ref:`mdp`
options relating to force calculation and output are active.

After setting up the :ref:`mdp` file one can run :ref:`grompp <gmx
grompp>` as usual. :ref:`grompp <gmx grompp>` will set the charges of
all the QM atoms to zero to avoid double-counting of Coulomb
interactions. Moreover, it will update non-bonded exclusion lists to
exclude LJ interactions between QM atoms (since they will be described
by CPMD). Finally, it will remove bonds between QM atoms (if
present). We recommend to output the preprocessed topology file using
``gmx grompp -pp <preprocessed_topology_file>`` as it will help to
prepare the input for CPMD in an automated way.

Preparing the input file for CPMD
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
This section will only describe the MiMiC-related input in CPMD - for the
configuration of a DFT-related options - please refer to the `CPMD manual
<https://www.cpmd.org/wordpress/CPMD/getFile.php?file=manual.pdf>`__.
After preparing the input for GROMACS and having obtained the
preprocessed topology file, simply run the Python
preprocessor script provided within the MiMiC distribution to obtain
MiMiC-related part of the CPMD input file. The usage of the script is simple:

::

    prepare-qmmm.py <index_file> <gro_file> <preprocessed_topology_file> <qm_group_name>

Be advised that for MiMiC it is crucial that the forcefield contains the data about
the element number of each atom type! If it does not provide it, the preprocessor
will fail with the error:

::

    It looks like the forcefield that you are using has no information about the element number.
    The element number is needed to run QM/MM simulations.

Given all the relevant information the script will print the part of the CPMD
input that is related to MiMiC. Here is the sample output with the short
descriptions of keywords that can be found in this part of CPMD input:

::

    &MIMIC
    PATHS
    1
    <some_absolute_path>
    BOX
    35.77988547402689 35.77988547402689 35.77988547402689
    OVERLAPS
    3
    2 13 1 1
    2 14 1 2
    2 15 1 3
    &END
    
    &ATOMS
    O
    1
    17.23430225802002 17.76342557295923 18.576007806615877
    H
    2
    18.557110545368047 19.086233860307257 18.727185896598506
    17.57445296048094 16.705178943080806 17.06422690678956
    &END
    Suggested QM box size [12.661165036045407, 13.71941166592383, 13.00131573850633]

``&MIMIC`` section contains MiMiC settings:

    ``PATHS`` indicates number of MM client codes involved in the simulation
    and the absolute path to each of their respective folder. Keep in mind
    that this path has to point to the folder, where |Gromacs| is going to
    be run -- otherwise it will cause a deadlock in CPMD! The next line
    contains the number of MM codes (1 in this case) and next :math:`N`
    lines contain paths to their respective working directories
    
    ``BOX`` indicates the size of the whole simulation box in Bohr in
    an ``X Y Z`` format

    ``OVERLAPS`` - sets the number and IDs of atoms within |Gromacs| that are going to be 
    treated by CPMD. The format is the following:

    ::

        <code_id> <atom_id_in_code> <host_code_id> <atom_id_in_that_code>
    
    CPMD host code id is always ID 1. Therefore, in a QM/MM simulation
    |Gromacs| will have code ID 2.

    (OPTIONAL) ``LONG-RANGE COUPLING`` - enables the faster multipole coupling for
    atoms located at a certain distance from the QM box

    (OPTIONAL) ``CUTOFF DISTANCE`` - the next line contains the cutoff for
    explicit Coulomb coupling  (20 Bohr by default if ``LONG-RANGE COUPLING``
    is present)

    (OPTIONAL) ``MULTIPOLE ORDER`` - The next line will contain the order at which
    the multipolar expansion will be truncated (default 2, maximum 20).

The ``&ATOMS`` section of CPMD input file contains all the QM atoms
within the system and has a default CPMD formatting. Please refer
to the `CPMD manual
<http://www.cpmd.org/downloadable-files/no-authentication/manual_v4_0_1.pdf>`__
to adjust it to your needs(one will need to set the correct pseudo-potential
for each atom species).

Finally, the preprocessor suggests the size of the QM box where the electronic
density is going to be contained. The suggested value is not final
- further adjustment by user may be required.

Running a MiMiC QM/MM simulation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In order to run the simulation, one will need to run both |Gromacs| and CPMD within one job.
This is easily done within the vast majority of queueing systems. For example in
case of SLURM queue system one can use two job steps within one job. Here is
the example job script running a 242-node slurm job, allocating 2 nodes to |Gromacs|
and 240 nodes to CPMD (both codes are launched in the same folder):

::

    #!/bin/bash -x
    #SBATCH --nodes=242
    #SBATCH --output=mpi-out.%j
    #SBATCH --error=mpi-err.%j
    #SBATCH --time=00:25:00
    #SBATCH --partition=batch
    
    # *** start of job script ***

    srun -N2 --ntasks-per-node=6 --cpus-per-task=4 -r0 gmx_mpi_d mdrun -deffnm mimic -ntomp 4 &
    srun -N240 --ntasks-per-node=6 --cpus-per-task=4 -r2 cpmd.x benchmark.inp <path_to_pp_folder> > benchmark-240-4.out &
    wait


Known Issues
^^^^^^^^^^^^

OpenMPI prior to version 3.x.x has a bug preventing the usage of MiMiC
completely - please use newer versions or other MPI distributions.

With IntelMPI communication between CPMD and |Gromacs| may result
in a deadlock in some situations. If it happens, setting an
IntelMPI-related environment variable may help:

::

    export FI_OFI_RXM_USE_SRX=1
.. _awh:

Adaptive biasing with AWH
-------------------------

The accelerated weight histogram method :ref:`185 <refLidmar2012>`
:ref:`137 <reflindahl2014accelerated>` calculates the PMF along a reaction coordinate by adding
an adaptively determined biasing potential. AWH flattens free energy
barriers along the reaction coordinate by applying a history-dependent
potential to the system that “fills up” free energy minima. This is
similar in spirit to other adaptive biasing potential methods, e.g. the
Wang-Landau \ :ref:`138 <refwang2001efficient>`, local
elevation \ :ref:`139 <refhuber1994local>` and
metadynamics \ :ref:`140 <reflaio2002escaping>` methods.
The initial sampling stage of AWH makes the method robust against the
choice of input parameters. Furthermore, the target distribution along
the reaction coordinate may be chosen freely.

Basics of the method
^^^^^^^^^^^^^^^^^^^^

Rather than biasing the reaction coordinate :math:`\xi(x)` directly, AWH
acts on a *reference coordinate* :math:`\lambda`. The fundamentals of the
method is based on the connection between atom coordinates and :math:`\lambda` and
is established through the extended ensemble \ :ref:`68 <refLyubartsev1992>`,

.. math:: P(x,\lambda) = \frac{1}{\mathcal{Z}}e^{g(\lambda) - Q(\xi(x),\lambda) - V(x)},
          :label: eqawhpxlambda

where :math:`g(\lambda)` is a bias function (a free variable) and
:math:`V(x)` is the unbiased potential energy of the system. The
distribution along :math:`\lambda` can be tuned to be any predefined
*target distribution* :math:`\rho(\lambda)` (often chosen to be flat) by
choosing :math:`g(\lambda)` wisely. This is evident from

.. math:: P(\lambda) = \int P(x,\lambda)  dx = 
          \frac{1}{\mathcal{Z}}e^{g(\lambda)} \int e^{- Q(\xi(x),\lambda) - V(x)}  dx 
          \equiv \frac{1}{\mathcal{Z}}e^{g(\lambda) - F(\lambda)},
          :label: eqawhplambda

where :math:`F(\lambda)` is the free energy

.. math:: F(\lambda) = -\ln \int e^{- Q(\xi(x),\lambda) - V(x)}  dx.
          :label: eqawhflambda

The reaction coordinate :math:`\xi(x)` is commonly coupled to
:math:`\lambda` with a harmonic potential

.. math:: Q(\xi,\lambda) = \frac{1}{2} \beta k (\xi - \lambda)^2,
          :label: eqnawhbasic

so that for large force constants :math:`k`,
:math:`\xi \approx \lambda`. Note the use of dimensionless energies for
compatibility with previously published work. Units of energy are
obtained by multiplication with :math:`k_BT=1/\beta`. In the simulation,
:math:`\lambda` samples the user-defined sampling interval :math:`I`.

Being the convolution of the PMF with the Gaussian defined by the
harmonic potential, :math:`F(\lambda)` is a smoothened version of the
PMF. :eq:`Eq. %s <eqawhplambda>` shows that in order to obtain
:math:`P(\lambda)=\rho(\lambda)`, :math:`F(\lambda)` needs to be
determined accurately. Thus, AWH adaptively calculates
:math:`F(\lambda)` and simultaneously converges :math:`P(\lambda)`
toward :math:`\rho(\lambda)`.

It is also possible to directly control the :math:`\lambda` state
of, e.g., alchemical free energy perturbations :ref:`187 <reflundborg2021>`. In that case there is no harmonic
potential and :math:`\lambda` changes in discrete steps along the reaction coordinate
depending on the biased free energy difference between the :math:`\lambda` states.
N.b., it is not yet possible to use AWH in combination with perturbed masses or
constraints.

For a multidimensional reaction coordinate :math:`\xi`, the sampling
interval is the Cartesian product :math:`I=\Pi_{\mu} I_{\mu}` (a rectangular
domain).

The free energy update
^^^^^^^^^^^^^^^^^^^^^^

AWH is initialized with an estimate of the free energy
:math:`F_0(\lambda)`. At regular time intervals this estimate is updated
using data collected in between the updates. At update :math:`n`, the
applied bias :math:`g_n(\lambda)` is a function of the current free
energy estimate :math:`F_n(\lambda)` and target distribution
:math:`\rho_n(\lambda)`,

.. math:: g_n(\lambda) = \ln \rho_n(\lambda) +F_n(\lambda),
          :label: eqawhgrhofrelation

which is consistent with :eq:`Eq. %s <eqawhplambda>`. Note that also the
target distribution may be updated during the simulation (see examples
in section :ref:`awhtargets`). Substituting this choice of :math:`g=g_n`
back into :eq:`Eq. %s <eqawhplambda>` yields the simple free energy update

.. math:: \Delta F_n(\lambda) 
          = F(\lambda) - F_n(\lambda) 
          = -\ln\frac{P_n(\lambda)}{\rho_n(\lambda)},
          :label: eqawhdfnaive

which would yield a better estimate :math:`F_{n+1} = F_n + \Delta F_n`,
assuming :math:`P_n(\lambda)` can be measured accurately. AWH estimates
:math:`P_n(\lambda)` by regularly calculating the conditional
distribution

.. math:: \omega_n(\lambda|x) \equiv P_n(\lambda|x) = \frac{e^{g_n(\lambda) - Q(\xi(x), \lambda)}}{\sum_{\lambda'} e^{g_n(\lambda') - Q(\xi(x),\lambda')}}.
          :label: eqawhomega

Accumulating these probability weights yields
:math:`\sum_t \omega(\lambda|x(t)) \sim P_n(\lambda)`, where
:math:`\int P_n(\lambda|x) P_n(x) dx = P_n(\lambda)` has been used. The
:math:`\omega_n(\lambda|x)` weights are thus the samples of the AWH
method. With the limited amount of sampling one has in practice, update
scheme :eq:`%s <eqawhdfnaive>` yields very noisy results. AWH instead applies a
free energy update that has the same form but which can be applied
repeatedly with limited and localized sampling,

.. math:: \Delta F_n = -\ln \frac{W_n(\lambda) + \sum_t \omega_n(\lambda|x(t))}{W_n(\lambda) + \sum_t\rho_n(\lambda)) }.
          :label: eqnawhsampling

Here :math:`W_n(\lambda)` is the *reference weight histogram*
representing prior sampling. The update for :math:`W(\lambda)`,
disregarding the initial stage (see section :ref:`awhinitialstage`), is

.. math:: W_{n+1}(\lambda) = W_n(\lambda) + \sum_t\rho_n(\lambda).
          :label: eqawhwupdate

Thus, the weight histogram equals the targeted, “ideal” history of
samples. There are two important things to note about the free energy
update. First, sampling is driven away from oversampled, currently local
regions. For such :math:`\lambda` values,
:math:`\omega_n(\lambda) > \rho_n(\lambda)` and
:math:`\Delta F_n(\lambda) < 0`, which by :eq:`Eq. %s <eqawhgrhofrelation>`
implies :math:`\Delta g_n(\lambda) < 0` (assuming
:math:`\Delta \rho_n \equiv 0`). Thus, the probability to sample
:math:`\lambda` decreases after the update (see :eq:`Eq. %s <eqawhplambda>`).
Secondly, the normalization of the histogram
:math:`N_n=\sum_\lambda W_n(\lambda)`, determines the update size
:math:`| \Delta F(\lambda) |`. For instance, for a single sample
:math:`\omega(\lambda|x)`, and using a harmonic potential
(:see :eq:`Eq. %s <eqnawhbasic>`),
the shape of the update is approximately a
Gaussian function of width :math:`\sigma=1/\sqrt{\beta k}` and height
:math:`\propto 1/N_n` :ref:`137 <reflindahl2014accelerated>`,

.. math:: | \Delta F_n(\lambda) | \propto \frac{1}{N_n} e^{-\frac{1}{2} \beta k (\xi(x) - \lambda)^2}.
          :label: eqawhdfsize

When directly controlling the lambda state of the system, the shape of
the update is instead

.. math:: | \Delta F_n(\lambda) | \propto \frac{1}{N_n} P_n(\lambda | x).
          :label: eqawhdfsizelambda

Therefore, in both cases, as samples accumulate in :math:`W(\lambda)` and
:math:`N_n` grows, the updates get smaller, allowing for the free energy to
converge.

Note that quantity of interest to the user is not :math:`F(\lambda)` but
the PMF :math:`\Phi(\xi)`. :math:`\Phi(\xi)` is extracted by reweighting
samples :math:`\xi(t)` on the fly \ :ref:`137 <reflindahl2014accelerated>` (see
also section :ref:`awhreweight`) and will converge at the same rate as
:math:`F(\lambda)`, see :numref:`Fig. %s <fig-awhbiasevolution1>`. The PMF will be
written to output (see section :ref:`awhusage`).

Applying the bias to the system
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The bias potential can be applied to the system in two ways. Either by
applying a harmonic potential centered at :math:`\lambda(t)`, which is
sampled using (rejection-free) Monte-Carlo sampling from the conditional
distribution :math:`\omega_n(\lambda | x(t)) = P_n(\lambda | x(t))`, see
:eq:`Eq. %s <eqawhomega>`. This is also called Gibbs sampling or independence
sampling. Alternatively, and by default in the code, the following
*convolved bias potential* can be applied,

.. math:: U_n(\xi) = -\ln \int e^{ g_n(\lambda) -Q(\xi,\lambda)} d \lambda.
          :label: eqawhbiaspotential

These two approaches are equivalent in the sense that they give rise to
the same biased probabilities :math:`P_n(x)`
(cf. :eq:`%s <eqawhpxlambda>`) while the dynamics are clearly
different in the two cases. This choice does not affect the internals of
the AWH algorithm, only what force and potential AWH returns to the MD
engine.

Along a bias dimension directly controlling the
:math:`\lambda` state of the system, such as when controlling free energy
perturbations, the Monte-Carlo sampling alternative is always used, even if
a convolved bias potential is chosen to be used along the other dimensions
(if there are more than one).


.. _fig-awhbiasevolution1:

.. figure:: plots/awh-traj.*
        :width: 8.0cm

        AWH evolution in time for a Brownian particle in a double-well
        potential. The reaction coordinate :math:`\xi(t)` traverses the sampling
        interval multiple times in the initial stage before exiting and entering
        the final stage. In the final stage, the dynamics of
        :math:`\xi` becomes increasingly diffusive.

.. _fig-awhbiasevolution2:

.. figure:: plots/awh-invN.*
        :width: 8.0cm

        In the final stage, the dynamics of
        :math:`\xi` becomes increasingly diffusive. The times of covering are
        shown as :math:`\times`-markers of different colors. At these times the
        free energy update size :math:`\sim 1/N`, where :math:`N` is the size of
        the weight histogram, is decreased by scaling :math:`N` by a factor of
        :math:`\gamma=3`.

.. _fig-awhbiasevolution3:

.. figure:: plots/awh-sampleweights.*
        :width: 8.0cm

        In the final stage, :math:`N` grows at the
        sampling rate and thus :math:`1/N\sim1/t`. The exit from the final stage
        is determined on the fly by ensuring that the effective sample weight
        :math:`s` of data collected in the final stage exceeds that of initial
        stage data (note that :math:`\ln s(t)` is plotted).

.. _fig-awhbiasevolution4:

.. figure:: plots/awh-pmfs.*
        :width: 8.0cm

        An estimate of the PMF is also extracted from the simulation (bottom
        right), which after exiting the initial stage should estimate global
        free energy differences fairly accurately.

.. _awhinitialstage:

The initial stage
~~~~~~~~~~~~~~~~~

Initially, when the bias potential is far from optimal, samples will be
highly correlated. In such cases, letting :math:`W(\lambda)` accumulate
samples as prescribed by :eq:`Eq. %s <eqawhwupdate>`, entails
a too rapid decay of the free energy update size. This motivates
splitting the simulation into an *initial stage* where the weight
histogram grows according to a more restrictive and robust protocol, and
a *final stage* where the weight histogram grows linearly at the
sampling rate (:eq:`Eq. %s <eqawhwupdate>`). The AWH initial
stage takes inspiration from the well-known Wang-Landau algorithm \ :ref:`138 <refwang2001efficient>`,
although there are differences in the details.

In the initial stage the update size is kept constant (by keeping
:math:`N_n` constant) until a transition across the sampling interval
has been detected, a “covering”. For the definition of a covering, see
:eq:`Eq. %s <eqawhcovering>` below. After a covering has
occurred, :math:`N_n` is scaled up by a constant “growth factor”
:math:`\gamma`, chosen heuristically as :math:`\gamma=3`. Thus, in the
initial stage :math:`N_n` is set dynamically as
:math:`N_{n} = \gamma^{m} N_0`, where :math:`m` is the number of
coverings. Since the update size scales as :math:`1/N` (
:eq:`Eq. %s <eqawhdfsize>`) this leads to a close to
exponential decay of the update size in the initial stage, see
:numref:`Fig. %s <fig-awhbiasevolution1>`.

The update size directly determines the rate of change of
:math:`F_n(\lambda)` and hence, from
:eq:`Eq. %s <eqawhgrhofrelation>`, also the rate of change of
the bias funcion :math:`g_n(\lambda)` Thus initially, when :math:`N_n`
is kept small and updates large, the system will be driven along the
reaction coordinate by the constantly fluctuating bias. If :math:`N_0`
is set small enough, the first transition will typically be fast because
of the large update size and will quickly give a first rough estimate of
the free energy. The second transition, using :math:`N_1=\gamma N_0`
refines this estimate further. Thus, rather than very carefully filling
free energy minima using a small initial update size, the sampling
interval is sweeped back-and-forth multiple times, using a wide range of
update sizes, see :numref:`Fig. %s <fig-awhbiasevolution1>`. This
way, the initial stage also makes AWH robust against the choice of
:math:`N_0`.

The covering criterion
^^^^^^^^^^^^^^^^^^^^^^

In the general case of a multidimensional reaction coordinate
:math:`\lambda=(\lambda_{\mu})`, the sampling interval :math:`I` is
considered covered when all dimensions have been covered. A dimension
:math:`d` is covered if all points :math:`\lambda_{\mu}` in the
one-dimensional sampling interval :math:`I_{\mu}` have been “visited”.
Finally, a point :math:`\lambda_{\mu} \in I_{\mu}` has been visited if there is
at least one point :math:`\lambda^*\in I` with
:math:`\lambda^*_{\mu} = \lambda_{\mu}` that since the last covering has
accumulated probability weight corresponding to the peak of a
multidimensional Gaussian distribution

.. math:: \Delta W(\lambda^*)
          \ge w_{\mathrm{peak}}
          \equiv \prod_{\mu} \frac{\Delta \lambda_{\mu}}{\sqrt{2\pi}\sigma_k}.
          :label: eqawhcovering

Here, :math:`\Delta \lambda_{\mu}` is the point spacing of the discretized
:math:`I_{\mu}` and :math:`\sigma_k=1/\sqrt{\beta k_{\mu}}` (where :math:`k_{\mu}`
is the force constant) is the Gaussian width.

Exit from the initial stage
^^^^^^^^^^^^^^^^^^^^^^^^^^^

For longer times, when major free energy barriers have largely been
flattened by the converging bias potential, the histogram
:math:`W(\lambda)` should grow at the actual sampling rate and the
initial stage needs to be exited \ :ref:`141 <refbelardinelli2007fast>`.
There are multiple reasonable (heuristic) ways of determining when this
transition should take place. One option is to postulate that the number
of samples in the weight histogram :math:`N_n` should never exceed the
actual number of collected samples, and exit the initial stage when this
condition breaks \ :ref:`137 <reflindahl2014accelerated>`. In the initial stage,
:math:`N` grows close to exponentially while the collected number of
samples grows linearly, so an exit will surely occur eventually. Here we
instead apply an exit criterion based on the observation that
“artifically” keeping :math:`N` constant while continuing to collect
samples corresponds to scaling down the relative weight of old samples
relative to new ones. Similarly, the subsequent scaling up of :math:`N`
by a factor :math:`\gamma` corresponds to scaling up the weight of old
data. Briefly, the exit criterion is devised such that the weight of a
sample collected *after* the initial stage is always larger or equal to
the weight of a sample collected *during* the initial stage, see
:numref:`Fig. %s <fig-awhbiasevolution1>`. This is consistent with
scaling down early, noisy data.

The initial stage exit criterion will now be described in detail. We
start out at the beginning of a covering stage, so that :math:`N` has
just been scaled by :math:`\gamma` and is now kept constant. Thus, the
first sample of this stage has the weight :math:`s= 1/\gamma` relative
to the last sample of the previous covering stage. We assume that
:math:`\Delta N` samples are collected and added to :math:`W` for each
update . To keep :math:`N` constant, :math:`W` needs to be scaled down
by a factor :math:`N/(N + \Delta N)` after every update. Equivalently,
this means that new data is scaled up relative to old data by the
inverse factor. Thus, after :math:`\Delta n` updates a new sample has
the relative weight
:math:`s=(1/\gamma) [(N_n + \Delta N)/N_n]^{\Delta n}`. Now assume
covering occurs at this time. To continue to the next covering stage,
:math:`N` should be scaled by :math:`\gamma`, which corresponds to again
multiplying :math:`s` by :math:`1/\gamma`. If at this point
:math:`s \ge \gamma`, then after rescaling :math:`s \ge 1`; i.e. overall
the relative weight of a new sample relative to an old sample is still
growing fast. If on the contrary :math:`s < \gamma`, and this defines
the exit from the initial stage, then the initial stage is over and from
now :math:`N` simply grows at the sampling rate (see
:eq:`Eq. %s <eqawhwupdate>`). To really ensure that
:math:`s\ge 1` holds before exiting, so that samples after the exit have
at least the sample weight of older samples, the last covering stage is
extended by a sufficient number of updates.

.. _awhtargets:

Choice of target distribution
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The target distribution :math:`\rho(\lambda)` is traditionally chosen to
be uniform

.. math:: \rho_{\mathrm{const}}(\lambda) = \mathrm{const.}
          :label: eqnawhuniformdist

This choice exactly flattens :math:`F(\lambda)` in user-defined
sampling interval :math:`I`. Generally,
:math:`\rho(\lambda)=0, \lambda\notin I`. In certain cases other choices
may be preferable. For instance, in the multidimensional case the
rectangular sampling interval is likely to contain regions of very high
free energy, e.g. where atoms are clashing. To exclude such regions,
:math:`\rho(\lambda)` can specified by the following function of the
free energy

.. math:: \rho_{\mathrm{cut}}(\lambda) \propto \frac{1}{1+ e^{F(\lambda) - F_{\mathrm{cut}}}},
          :label: eqawhrhocut
    

where :math:`F_{\mathrm{cut}}` is a free energy cutoff (relative to
:math:`\min_\lambda F(\lambda)`). Thus, regions of the sampling interval
where :math:`F(\lambda) > F_{\mathrm{cut}}` will be exponentially
suppressed (in a smooth fashion). Alternatively, very high free energy
regions could be avoided while still flattening more moderate free
energy barriers by targeting a Boltzmann distribution corresponding to
scaling :math:`\beta=1/k_BT` by a factor :math:`0<s_\beta<1`,

.. math:: \rho_{\mathrm{Boltz}}(\lambda) \propto e^{-s_\beta F(\lambda)},
          :label: eqawhrhoboltz

The parameter :math:`s_\beta` determines to what degree the free energy
landscape is flattened; the lower :math:`s_\beta`, the flatter. Note
that both :math:`\rho_{\mathrm{cut}}(\lambda)` and
:math:`\rho_{\mathrm{Boltz}}(\lambda)` depend on :math:`F(\lambda)`,
which needs to be substituted by the current best estimate
:math:`F_n(\lambda)`. Thus, the target distribution is also updated
(consistently with :eq:`Eq. %s <eqawhgrhofrelation>`).

There is in fact an alternative approach to obtaining
:math:`\rho_{\mathrm{Boltz}}(\lambda)` as the limiting target
distribution in AWH, which is particular in the way the weight histogram
:math:`W(\lambda)` and the target distribution :math:`\rho` are updated
and coupled to each other. This yields an evolution of the bias
potential which is very similar to that of well-tempered
metadynamics \ :ref:`142 <refbarducci2008well>`,
see \ :ref:`137 <reflindahl2014accelerated>` for details. Because of the popularity and
success of well-tempered metadynamics, this is a special case worth
considering. In this case :math:`\rho` is a function of the reference
weight histogram

.. math:: \rho_{\mathrm{Boltz,loc}}(\lambda) \propto W(\lambda), 
          :label: eqnawhweighthistogram

and the update of the weight histogram is modified (cf.
:eq:`Eq. %s <eqawhwupdate>`)

.. math:: W_{n+1}(\lambda) =  W_{n}(\lambda) + s_{\beta}\sum_t \omega(\lambda | x(t)).
          :label: eqnawhupdateweighthist

Thus, here the weight histogram equals the real history of samples, but
scaled by :math:`s_\beta`. This target distribution is called *local*
Boltzmann since :math:`W` is only modified locally, where sampling has
taken place. We see that when :math:`s_\beta \approx 0` the histogram
essentially does not grow and the size of the free energy update will
stay at a constant value (as in the original formulation of
metadynamics). Thus, the free energy estimate will not converge, but
continue to fluctuate around the correct value. This illustrates the
inherent coupling between the convergence and choice of target
distribution for this special choice of target. Furthermore note that
when using :math:`\rho=\rho_{\mathrm{Boltz,loc}}` there is no initial
stage (section :ref:`awhinitialstage`). The rescaling of the weight
histogram applied in the initial stage is a global operation, which is
incompatible :math:`\rho_{\mathrm{Boltz,loc}}` only depending locally on
the sampling history.

Lastly, the target distribution can be modulated by arbitrary
probability weights

.. math:: \rho(\lambda) = \rho_0(\lambda) w_{\mathrm{user}}(\lambda).
          :label: eqnawhpropweigth

where :math:`w_{\mathrm{user}}(\lambda)` is provided by user data and
in principle :math:`\rho_0(\lambda)` can be any of the target
distributions mentioned above.

Multiple independent or sharing biases
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Multiple independent bias potentials may be applied within one
simulation. This only makes sense if the biased coordinates
:math:`\xi^{(1)}`, :math:`\xi^{(2)}`, :math:`\ldots` evolve essentially
independently from one another. A typical example of this would be when
applying an independent bias to each monomer of a protein. Furthermore,
multiple AWH simulations can be launched in parallel, each with a (set
of) indepedendent biases.

If the defined sampling interval is large relative to the diffusion time
of the reaction coordinate, traversing the sampling interval multiple
times as is required by the initial stage
(section :ref:`awhinitialstage`) may take an infeasible mount of
simulation time. In these cases it could be advantageous to parallelize
the work and have a group of multiple “walkers” :math:`\xi^{(i)}(t)`
share a single bias potential. This can be achieved by collecting
samples from all :math:`\xi^{(i)}` of the same sharing group into a
single histogram and update a common free energy estimate. Samples can
be shared between walkers within the simulation and/or between multiple
simulations. However, currently only sharing between simulations is
supported in the code while all biases within a simulation are
independent.

Note that when attempting to shorten the simulation time by using
bias-sharing walkers, care must be taken to ensure the simulations are
still long enough to properly explore and equilibrate all regions of the
sampling interval. To begin, the walkers in a group should be
decorrelated and distributed approximately according to the target
distribution before starting to refine the free energy. This can be
achieved e.g. by “equilibrating” the shared weight histogram before
letting it grow; for instance, :math:`W(\lambda)/N\approx \rho(\lambda)`
with some tolerance.

Furthermore, the “covering” or transition criterion of the initial stage
should to be generalized to detect when the sampling interval has been
collectively traversed. One alternative is to just use the same
criterion as for a single walker (but now with more samples), see
:eq:`Eq. %s <eqawhcovering>`. However, in contrast to the
single walker case this does not ensure that any real transitions across
the sampling interval has taken place; in principle all walkers could be
sampling only very locally and still cover the whole interval. Just as
with a standard umbrella sampling procedure, the free energy may appear
to be converged while in reality simulations sampling closeby
:math:`\lambda` values are sampling disconnected regions of phase space.
A stricter criterion, which helps avoid such issues, is to require that
before a simulation marks a point :math:`\lambda_{\mu}` along dimension
:math:`\mu` as visited, and shares this with the other walkers, also all
points within a certain diameter :math:`D_{\mathrm{cover}}` should have
been visited (i.e. fulfill :eq:`Eq. %s <eqawhcovering>`).
Increasing :math:`D_{\mathrm{cover}}` increases robustness, but may slow
down convergence. For the maximum value of :math:`D_{\mathrm{cover}}`,
equal to the length of the sampling interval, the sampling interval is
considered covered when at least one walker has independently traversed
the sampling interval.

In practice biases are shared by setting :mdp:`awh-share-multisim` to true
and :mdp:`awh1-share-group` (for bias 1) to a non-zero value. Here, bias 1
will be shared between simulations that have the same share group value.
Sharing can be different for bias 1, 2, etc. (although there are
few use cases where this is useful). Technically there are no restrictions
on sharing, apart from that biases that are shared need to have the same
number of grid points and the update intervals should match.
Note that biases can not be shared within a simulation.
The latter could be useful, especially for multimeric proteins, but this
is more difficult to implement.

.. _awhreweight:

Reweighting and combining biased data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Often one may want to, post-simulation, calculate the unbiased PMF
:math:`\Phi(u)` of another variable :math:`u(x)`. :math:`\Phi(u)` can be
estimated using :math:`\xi`-biased data by reweighting (“unbiasing”) the
trajectory using the bias potential :math:`U_{n(t)}`, see
:eq:`Eq. %s <eqawhbiaspotential>`. Essentially, one bins the
biased data along :math:`u` and removes the effect of :math:`U_{n(t)}`
by dividing the weight of samples :math:`u(t)` by
:math:`e^{-U_{n(t)}(\xi(t))}`,

.. math:: \hat{\Phi}(u)  = -\ln 
          \sum_t 1_u(u(t))e^{U_{n(t)}(\xi(t)} \mathcal{Z}_{n(t)}.
          :label: eqawhunbias

Here the indicator function :math:`1_u` denotes the binning procedure:
:math:`1_u(u') = 1` if :math:`u'` falls into the bin labeled by
:math:`u` and :math:`0` otherwise. The normalization factor
:math:`\mathcal{Z}_n = \int e^{-\Phi(\xi) - U_{n}(\xi)}d \xi` is the
partition function of the extended ensemble. As can be seen
:math:`\mathcal{Z}_n` depends on :math:`\Phi(\xi)`, the PMF of the
(biased) reaction coordinate :math:`\xi` (which is calculated and
written to file by the AWH simulation). It is advisable to use only
final stage data in the reweighting procedure due to the rapid change of
the bias potential during the initial stage. If one would include
initial stage data, one should use the sample weights that are inferred
by the repeated rescaling of the histogram in the initial stage, for the
sake of consistency. Initial stage samples would then in any case be
heavily scaled down relative to final stage samples. Note that
:eq:`Eq. %s <eqawhunbias>` can also be used to combine data
from multiple simulations (by adding another sum also over the
trajectory set). Furthermore, when multiple independent AWH biases have
generated a set of PMF estimates :math:`\{\hat{\Phi}^{(i)}(\xi)\}`, a
combined best estimate :math:`\hat{\Phi}(\xi)` can be obtained by
applying self-consistent exponential averaging. More details on this
procedure and a derivation of :eq:`Eq. %s <eqawhunbias>`
(using slightly different notation) can be found in :ref:`143 <reflindahl2017sequence>`.

.. _awhfriction:

The friction metric
~~~~~~~~~~~~~~~~~~~

During the AWH simulation, the following time-integrated force
correlation function is calculated,

.. math:: \eta_{\mu\nu}(\lambda) =
          \beta
          \int_0^\infty
          \frac{
          \left<{\delta \mathcal{F}_{\mu}(x(t),\lambda)
          \delta \mathcal{F}_\nu(x(0),\lambda)
          \omega(\lambda|x(t)) \omega(\lambda|x(0))}\right>}
          {\left<{\omega^2(\lambda | x)}\right>}
          dt.
          :label: eqawhmetric

Here
:math:`\mathcal F_\mu(x,\lambda) = k_\mu (\xi_\mu(x) - \lambda_\mu)` is
the force along dimension :math:`\mu` from an harmonic potential
centered at :math:`\lambda` and
:math:`\delta \mathcal F_{\mu}(x,\lambda) = \mathcal F_{\mu}(x,\lambda) - \left<{\mathcal F_\mu(x,\lambda)}\right>`
is the deviation of the force. The factors :math:`\omega(\lambda|x(t))`,
see :eq:`Eq %s <eqawhomega>`, reweight the samples.
:math:`\eta_{\mu\nu}(\lambda)` is a friction
tensor :ref:`186 <reflindahl2018>` and :ref:`144 <refsivak2012thermodynamic>`. Its matrix elements are inversely proportional to local
diffusion coefficients. A measure of sampling (in)efficiency at each
:math:`\lambda` is given by

.. math:: \eta^{\frac{1}{2}}(\lambda) = \sqrt{\det\eta_{\mu\nu}(\lambda)}.
          :label: eqawhsqrtmetric

A large value of :math:`\eta^{\frac{1}{2}}(\lambda)` indicates slow
dynamics and long correlation times, which may require more sampling.

.. _awhusage:

Usage
~~~~~

AWH stores data in the energy file (:ref:`edr`) with a frequency set by the
user. The data – the PMF, the convolved bias, distributions of the
:math:`\lambda` and :math:`\xi` coordinates, etc. – can be extracted
after the simulation using the :ref:`gmx awh` tool. Furthermore, the trajectory
of the reaction coordinate :math:`\xi(t)` is printed to the pull output
file :math:`{\tt pullx.xvg}`. The log file (:ref:`log`) also contains
information; check for messages starting with “awh”, they will tell you
about covering and potential sampling issues.

Setting the initial update size
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The initial value of the weight histogram size :math:`N` sets the
initial update size (and the rate of change of the bias). When :math:`N`
is kept constant, like in the initial stage, the average variance of the
free energy scales as :math:`\varepsilon^2 \sim 1/(ND)`
:ref:`137 <reflindahl2014accelerated>`, for a simple model system with constant diffusion
:math:`D` along the reaction coordinate. This provides a ballpark
estimate used by AWH to initialize :math:`N` in terms of more meaningful
quantities

.. math:: \frac{1}{N_0} = \frac{1}{N_0(\varepsilon_0, D)} = \frac{1}{\Delta
	  t_\mathrm{sample}} \max_d \frac{L_d^2}{2D_d} \varepsilon_0^2
          :label: eqawhn0

where :math:`L_d` is the length of the interval and :math:`D_d` is
the diffusion constant along dimension :math:`d` of the AWH bias.
For one dimension, :math:`L^2/2D` is the average time to diffuse
over a distance of :math:`L`. We then takes the maximum crossing
time over all dimensions involved in the bias.
Essentially, this formula tells us that a slower system (small :math:`D`)
requires more samples (larger :math:`N^0`) to attain the same level of
accuracy (:math:`\varepsilon_0`) at a given sampling rate. Conversely,
for a system of given diffusion, how to choose the initial biasing rate
depends on how good the initial accuracy is. Both the initial error
:math:`\varepsilon_0` and the diffusion :math:`D` only need to be
roughly estimated or guessed. In the typical case, one would only tweak
the :math:`D` parameter, and use a default value for
:math:`\varepsilon_0`. For good convergence, :math:`D` should be chosen
as large as possible (while maintaining a stable system) giving large
initial bias updates and fast initial transitions. Choosing :math:`D`
too small can lead to slow initial convergence. It may be a good idea to
run a short trial simulation and after the first covering check the
maximum free energy difference of the PMF estimate. If this is much
larger than the expected magnitude of the free energy barriers that
should be crossed, then the system is probably being pulled too hard and
:math:`D` should be decreased. An accurate estimate of the diffusion
can be obtaining from an AWH simulation with the :ref:`gmx awh` tool.
:math:`\varepsilon_0` on the other hand, should be a rough estimate
of the initial error.

Tips for efficient sampling
^^^^^^^^^^^^^^^^^^^^^^^^^^^

The force constant :math:`k` should be larger than the curvature of the
PMF landscape. If this is not the case, the distributions of the
reaction coordinate :math:`\xi` and the reference coordinate
:math:`\lambda`, will differ significantly and warnings will be printed
in the log file. One can choose :math:`k` as large as the time step
supports. This will neccessarily increase the number of points of the
discretized sampling interval :math:`I`. In general however, it should
not affect the performance of the simulation noticeably because the AWH
update is implemented such that only sampled points are accessed at free
energy update time.

As with any method, the choice of reaction coordinate(s) is critical. If
a single reaction coordinate does not suffice, identifying a second
reaction coordinate and sampling the two-dimensional landscape may help.
In this case, using a target distribution with a free energy cutoff (see
:eq:`Eq. %s <eqawhrhocut>`) might be required to avoid
sampling uninteresting regions of very high free energy. Obtaining
accurate free energies for reaction coordinates of much higher
dimensionality than 3 or possibly 4 is generally not feasible.

Monitoring the transition rate of :math:`\xi(t)`, across the sampling
interval is also advisable. For reliable statistics (e.g. when
reweighting the trajectory as described in section :ref:`awhreweight`),
one would generally want to observe at least a few transitions after
having exited the initial stage. Furthermore, if the dynamics of the
reaction coordinate suddenly changes, this may be a sign of e.g. a
reaction coordinate problem.

Difficult regions of sampling may also be detected by calculating the
friction tensor :math:`\eta_{\mu\nu}(\lambda)` in the sampling interval,
see section :ref:`awhfriction`. :math:`\eta_{\mu\nu}(\lambda)` as well
as the sampling efficiency measure :math:`\eta^{\frac{1}{2}}(\lambda)`
(:eq:`Eq. %s <eqawhsqrtmetric>`) are written to the energy file and can be
extracted with :ref:`gmx awh`. A high peak in
:math:`\eta^{\frac{1}{2}}(\lambda)` indicates that this region requires
longer time to sample properly.

.. this really does not belong here in my opinion

Using VMD plug-ins for trajectory file I/O
------------------------------------------

|Gromacs|
tools are able to use the plug-ins found in an existing installation of
`VMD`_ in order to read and write
trajectory files in formats that are not native to |Gromacs|. You will be
able to supply an AMBER DCD-format trajectory filename directly to
|Gromacs| tools, for example.

This requires a VMD installation not older than version 1.8, that your
system provides the dlopen function so that programs can determine at
run time what plug-ins exist, and that you build shared libraries when
building |Gromacs|. CMake will find the vmd executable in your path, and
from it, or the environment variable ``VMDDIR`` at
configuration or run time, locate the plug-ins. Alternatively, the
``VMD_PLUGIN_PATH`` can be used at run time to specify a
path where these plug-ins can be found. Note that these plug-ins are in
a binary format, and that format must match the architecture of the
machine attempting to use them.

Interactive Molecular Dynamics
------------------------------

|Gromacs| supports the interactive molecular dynamics (IMD) protocol as
implemented by `VMD`_ to control
a running simulation in NAMD. IMD allows to monitor a running |Gromacs|
simulation from a VMD client. In addition, the user can interact with
the simulation by pulling on atoms, residues or fragments with a mouse
or a force-feedback device. Additional information about the |Gromacs|
implementation and an exemplary |Gromacs| IMD system can be found `on this
homepage <http://www.mpibpc.mpg.de/grubmueller/interactivemd>`__.

Simulation input preparation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The |Gromacs| implementation allows transmission and interaction with a
part of the running simulation only, e.g. in cases where no water
molecules should be transmitted or pulled. The group is specified via
the :ref:`mdp` option ``IMD-group``. When
``IMD-group`` is empty, the IMD protocol is disabled and
cannot be enabled via the switches in :ref:`mdrun <gmx mdrun>`. To interact
with the entire system, ``IMD-group`` can be set to
``System``. When using :ref:`grompp <gmx grompp>`, a
:ref:`gro` file to be used as VMD input is written out
(``-imd`` switch of :ref:`grompp <gmx grompp>`).

Starting the simulation
^^^^^^^^^^^^^^^^^^^^^^^

Communication between VMD and |Gromacs| is achieved via TCP sockets and
thus enables controlling an :ref:`mdrun <gmx mdrun>` running locally or on
a remote cluster. The port for the connection can be specified with the
``-imdport`` switch of :ref:`mdrun <gmx mdrun>`, 8888 is the
default. If a port number of 0 or smaller is provided, |Gromacs|
automatically assigns a free port to use with IMD.

Every :math:`N` steps, the :ref:`mdrun <gmx mdrun>` client receives the
applied forces from VMD and sends the new positions to the client. VMD
permits increasing or decreasing the communication frequency
interactively. By default, the simulation starts and runs even if no IMD
client is connected. This behavior is changed by the
``-imdwait`` switch of :ref:`mdrun <gmx mdrun>`. After startup
and whenever the client has disconnected, the integration stops until
reconnection of the client. When the ``-imdterm`` switch is
used, the simulation can be terminated by pressing the stop button in
VMD. This is disabled by default. Finally, to allow interacting with the
simulation (i.e. pulling from VMD) the ``-imdpull`` switch
has to be used. Therefore, a simulation can only be monitored but not
influenced from the VMD client when none of ``-imdwait``,
``-imdterm`` or ``-imdpull`` are set. However,
since the IMD protocol requires no authentication, it is not advisable
to run simulations on a host directly reachable from an insecure
environment. Secure shell forwarding of TCP can be used to connect to
running simulations not directly reachable from the interacting host.
Note that the IMD command line switches of :ref:`mdrun <gmx mdrun>` are
hidden by default and show up in the help text only with
:ref:`gmx mdrun` ``-h -hidden``.

Connecting from VMD
^^^^^^^^^^^^^^^^^^^

In VMD, first the structure corresponding to the IMD group has to be
loaded (*File* :math:`\rightarrow` *New Molecule*). Then the IMD
connection window has to be used (*Extensions* :math:`\rightarrow`
*Simulation* :math:`\rightarrow` *IMD Connect (NAMD)*). In the IMD
connection window, hostname and port have to be specified and followed
by pressing *Connect*. *Detach Sim* allows disconnecting without
terminating the simulation, while *Stop Sim* ends the simulation on the
next neighbor searching step (if allowed by ``-imdterm``).

The timestep transfer rate allows adjusting the communication frequency
between simulation and IMD client. Setting the keep rate loads every
:math:`N^\mathrm{th}` frame into VMD instead of discarding them when a
new one is received. The displayed energies are in SI units in contrast
to energies displayed from NAMD simulations.s
.. _electric fields:

Electric fields
---------------

A pulsed and oscillating electric field can be applied according to:

.. math:: E(t) = E_0 \exp\left[-\frac{(t-t_0)^2}{2\sigma^2}\right]\cos\left[\omega (t-t_0)\right]
          :label: eq-efield

where :math:`E_0` is the field strength, the angular frequency
:math:`\omega = 2\pi c/\lambda`, :math:`t_0` is the time
at of the peak in the field strength and :math:`\sigma` is the width of
the pulse. Special cases occur when :math:`\sigma` = 0 (non-pulsed
field) and for :math:`\omega` is 0 (static field). See
:mdp:`electric-field-x` for more details.

This simulated laser-pulse was applied to simulations of melting
ice \ :ref:`146 <refCaleman2008a>`. A pulsed electric field may look ike
:numref:`Fig. %s <fig-field>`. In the supporting information of that paper the impact
of an applied electric field on a system under periodic boundary
conditions is analyzed. It is described that the effective electric
field under PBC is larger than the applied field, by a factor depending
on the size of the box and the dielectric properties of molecules in the
box. For a system with static dielectric properties this factor can be
corrected for. But for a system where the dielectric varies over time,
for example a membrane protein with a pore that opens and closes during
the simulation, this way of applying an electric field is not useful.
In such cases one can use the computational electrophysiology protocol
described in the next section (sec. :ref:`compel`).

.. _fig-field:

.. figure:: plots/field.*
   :width: 8.00000cm

   A simulated laser pulse in |Gromacs|.

Electric fields are applied when the following options are specified in
the :ref:`grompp <gmx grompp>` :ref:`mdp` file. You specify, in order, :math:`E_0`,
:math:`\omega`, :math:`t_0` and :math:`\sigma`:

::

    electric-field-x = 0.04 0       0     0

yields a static field with :math:`E_0` = 0.04 V/nm in the X-direction.
In contrast,

::

    electric-field-x = 2.0  150     5     0

yields an oscillating electric field with :math:`E_0` = 2 V/nm,
:math:`\omega` = 150/ps and :math:`t_0` = 5 ps. Finally

::

    electric-field-x = 2.0  150     5     1

yields an pulsed-oscillating electric field with :math:`E_0` = 2 V/nm,
:math:`\omega` = 150/ps and :math:`t_0` = 5 ps and :math:`\sigma` = 1
ps. Read more in ref. \ :ref:`146 <refCaleman2008a>`. Note that the input file
format is changed from the undocumented older version. A figure like
:numref:`Fig. %s <fig-field>` may be produced by passing the
``-field`` option to :ref:`gmx mdrun`.
.. _density-guided-simulation:

Applying forces from three-dimensional densities
------------------------------------------------

In density-guided simulations, additional forces are applied to atoms that depend
on the gradient of similarity between a simulated density and a reference density.

By applying these forces protein structures can be made to "fit" densities
from, e.g., cryo electron-microscopy. The implemented approach extends the ones
described in \ :ref:`182 <refOrzechowski2008>`, and \ :ref:`183 <refIgaev2019>`.

Overview
^^^^^^^^

The forces that are applied depend on:

 * The forward model that describes how atom positions are translated into a
   simulated density, :math:`\rho^{\mathrm{sim}}\!(\mathbf{r})`.
 * The similarity measure that describes how close the simulated density is to
   the reference density, :math:`\rho^{\mathrm{ref}}`, :math:`S[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}\!(\mathbf{r})]`.
 * The scaling of these forces by a force constant, :math:`k`.

The resulting effective potential energy is

.. math:: U = U_{\mathrm{forcefield}}(\mathbf{r}) - k S[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}\!(\mathbf{r})]\,\mathrm{.}
          :label: eqndensone

The corresponding density based forces that are added during the simulation are

.. math:: \mathbf{F}_{\mathrm{density}} = k \nabla_{\mathbf{r}} S[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}\!(\mathbf{r})]\,\mathrm{.}
          :label: eqndenstwo

This derivative decomposes into a similarity measure derivative and a simulated
density model derivative, summed over all density voxels :math:`\mathbf{v}`

.. math:: \mathbf{F}_{\mathrm{density}} = k \sum_{\mathbf{v}}\partial_{\rho_{\mathbf{v}}^{\mathrm{sim}}} S[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}] \cdot \nabla_{\mathbf{r}} \rho_{\mathbf{v}}^{\mathrm{sim}}\!(\mathbf{r})\,\mathrm{.}
          :label: eqndensthree

Thus density-guided simulation force calculations are based on computing a
simulated density and its derivative with respect to the atom positions, as
well as a density-density derivative between the simulated and the reference
density.

Usage
^^^^^

Density-guided simulations are controlled by setting ``.mdp`` options and
providing a reference density map as a file additional to the ``.tpr``.

All options that are related to density-guided simulations are prefixed with
``density-guided-simulation``.

Setting ``density-guided-simulation-active = yes`` will trigger density-guided
simulations with default parameters that will cause atoms to move into the
reference density.

The simulated density and its force contribution
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Atoms are spread onto the regular three-dimensional lattice of the reference
density. For spreading the atoms onto the grid, the discrete Gauss transform is
used. The simulated density from atoms at positions :math:`\mathbf{r_i}` at a
voxel with coordinates :math:`\mathbf{v}` is

.. math:: \rho_{\mathbf{v}} = \sum_i A_i \frac{1}{\sqrt{2\pi}^3\sigma^3} \exp[-\frac{(\mathbf{r_i}-\mathbf{v})^2}{2 \sigma^2}]\,\mathrm{.}
          :label: eqndensfour

Where :math:`A_i` is an amplitude that is determined per atom type and may be
the atom mass, partial charge, or unity for all atoms.

The width of the Gaussian spreading function is determined by :math:`\sigma`.
It is not recommended to use a spreading width that is smaller than the
grid spacing of the reference density.

The factor for the density force is then

.. math:: \nabla_{r} \rho_{\mathbf{v}}^{\mathrm{sim}}\!(\mathbf{r}) = \sum_{i} - A_i \frac{(\mathbf{r_i}-\mathbf{v})}{\sigma} \frac{1}{\sqrt{2\pi}^3\sigma^3} \exp[-\frac{(\mathbf{r_i}-\mathbf{v})^2}{2 \sigma^2}]\,\mathrm{.}
          :label: eqndensfive

The density similarity measure and its force contribution
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

There are multiple valid similarity measures between the reference density and
the simulated density, each motivated by the experimental source of the
reference density data. For the density-guided simulations in |Gromacs|, the following
measures are provided:

The inner product of the simulated density,

.. math:: S_{\mathrm{inner-product}}[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}] =
                \frac{1}{N_\mathrm{voxel}}\sum_{v=1}^{N_\mathrm{voxel}} \rho^{\mathrm{ref}}_v \rho^{\mathrm{sim}}_v\,\mathrm{.}
        :label: eqndenssix

The negative relative entropy between two densities,

.. math:: S_{\mathrm{relative-entropy}}[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}] =
           \sum_{v=1, \rho^{\mathrm{ref}}>0, \rho^{\mathrm{sim}}>0}^{N_\mathrm{voxel}} \rho^\mathrm{ref} [\log(\rho^\mathrm{sim}_v)-\log(\rho^\mathrm{ref}_v)]\,\mathrm{.}
        :label: eqndensseven

The cross correlation between two densities,

.. math:: S_{\mathrm{cross-correlation}}[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}] =
           \frac{\sum_{v}\left((\rho_v^{\mathrm{ref}} - \bar{\rho}^{\mathrm{ref}})(\rho_v^{\mathrm{sim}} - \bar{\rho}^{\mathrm{sim}})\right)}
           {\sqrt{\sum_v(\rho_v^{\mathrm{ref}} - \bar{\rho}^{\mathrm{ref}})^2 \sum_v(\rho_v^{\mathrm{sim}} - \bar{\rho}^{\mathrm{sim}})^2}}\mathrm{.}
        :label: eqndenscrosscorr
     

Declaring regions to fit
^^^^^^^^^^^^^^^^^^^^^^^^

A subset of atoms may be chosen when pre-processing the simulation to which the
density-guided simulation forces are applied. Only these atoms generate the
simulated density that is compared to the reference density.

Performance
^^^^^^^^^^^

The following factors affect the performance of density-guided simulations

 * Number of atoms in the density-guided simulation group, :math:`N_{\mathrm{atoms}}`.
 * Spreading range in multiples of Gaussian width, :math:`N_{\mathrm{\sigma}}`.
 * The ratio of spreading width to the input density grid spacing, :math:`r_{\mathrm{\sigma}}`.
 * The number of voxels of the input density, :math:`N_{\mathrm{voxel}}`.
 * Frequency of force calculations, :math:`N_{\mathrm{force}}`.
 * The communication cost when using multiple ranks, that is reflected in a constant :math:`c_{\mathrm{comm}}`.

The overall cost of the density-guided simulation is approximately proportional to

.. math:: \frac{1}{N_{\mathrm{force}}} \left[N_{\mathrm{atoms}}\left(N_{\mathrm{\sigma}}r_{\mathrm{\sigma}}\right)^3 + c_{\mathrm{comm}}N_{\mathrm{voxel}}\right]\,\mathrm{.}
          :label: eqndenseight

Applying force every N-th step
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The cost of applying forces every integration step is reduced when applying the
density-guided simulation forces only every :math:`N` steps. The applied force
is scaled by :math:`N` to approximate the same effective Hamiltonian as when
applying the forces every step, while maintaining time-reversibility and energy
conservation. Note that for this setting, the energy output frequency must be a
multiple of :math:`N`.

The maximal time-step should not exceed the fastest oscillation period of any
atom within the map potential divided by :math:`\pi`. This oscillation period
depends on the choice of reference density, the similarity measure and the force
constant and is thus hard to estimate directly. It has been observed to be
in the order of picoseconds for typical cryo electron-microscopy data, resulting
in a `density-guided-simulation-nst` setting in the order of 100.

Combining density-guided simulations with pressure coupling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Note that the contribution of forces from density-guided simulations to the
system virial are not accounted for. The size of the effect on the
pressure-coupling algorithm grows with the total summed density-guided simulation
force, as well as the angular momentum introduced by forces from density-guided
simulations. To minimize this effect, align your structure to the density before
running a pressure-coupled simulation.

Additionally, applying force every N-th steps does not work with the current
implementation of infrequent evaluation of pressure coupling and the constraint
virial.

Periodic boundary condition treatment
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Of all periodic images only the one closest to the center of the density map
is considered.

The reference density map format
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Reference input for the densities are given in mrc format according to the
"EMDB Map Distribution Format Description Version 1.01 (c) emdatabank.org 2014".
Closely related formats like ``ccp4`` and ``map`` might work.

Be aware that different visualization software handles map formats differently.
During simulations, reference densities are interpreted as visualised by ``VMD``.

Output
^^^^^^

The energy output file will contain an additional "Density-fitting" term.
This is the energy that is added to the system from the density-guided simulations.
The lower the energy, the higher the similarity between simulated and reference
density.

Adaptive force constant scaling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To enable a steady increase in similarity between reference and simulated
density while using as little force as possible, adaptive force scaling
decreases the force constant when similarity increases and vice versa. To avoid
large fluctuations in the force constant, change in similarity is measured
with an exponential moving average that smoothens the time series of similarity
measures with a time constant :math:`tau` that is given in ps. If the exponential
moving average similarity increases, the force constant is scaled down by
dividing by :math:`1+\delta t_{\mathrm{density}}/tau`, where
:math:`\delta t_{\mathrm{density}}` is the time between density guided simulation steps.
Conversely, if similarity between reference and simulated density is decreasing,
the force constant is increased by multiplying by :math:`1+2\delta t_{\mathrm{density}}/tau`.
Note that adaptive force scaling does not conserve energy and will ultimately lead to very high
forces when similarity cannot be increased further.

Mapping input structure to density data with affine transformations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
To align input structure and density data, a transformation matrix
:math:`\mathbf{A}` and shift vector :math:`\mathbf{v_{\mathrm{shift}}}` may be
defined that transform the input structure atom coordinates before evaluating
density-guided-simulation energies and forces, so that 

.. math:: U = U_{\mathrm{forcefield}}(\mathbf{r}) - k S[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}\!(\mathbf{A} \mathbf{r}+\mathbf{v}_{\mathrm{shift}})]\,\mathrm{.}
          :label: eqndensnine

.. math:: \mathbf{F}_{\mathrm{density}} = k \nabla_{\mathbf{r}} S[\rho^{\mathrm{ref}},\rho^{\mathrm{sim}}\!(\mathbf{A} \mathbf{r}+\mathbf{v}_{\mathrm{shift}})]\,\mathrm{.}
          :label: eqndensten

Affine transformations may be used, amongst other things, to perform

 * rotations, e.g., around the z-axis by an angle :math:`\theta` by using :math:`A=\begin{pmatrix} \cos \theta & -\sin \theta & 0 \\ \sin \theta & \cos \theta & 0 \\ 0 & 0 & 1 \end{pmatrix}`.
 * projection, e.g., onto the z-axis by using :math:`A=\begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix}`. This allows density-guided simulations to be steered by a density-profile along this axis.
 * scaling the structure against the density by a factor :math:`s` by using :math:`A=\begin{pmatrix} s & 0 & 0 \\ 0 & s & 0 \\ 0 & 0 & s \end{pmatrix}`. This proves useful when, e.g., voxel-sizes in cryo-EM densities have to be adjusted.
 * and arbitrary combinations of these by matrix multiplications (note that matrix multiplications are not commutative).

Future developments
^^^^^^^^^^^^^^^^^^^

Further similarity measures might be added in the future, along with different
methods to determine atom amplitudes. More automation in choosing a force constant
as well as alignment of the input density map to the structure might be provided.
Enforced Rotation
-----------------

This module can be used to enforce the rotation of a group of atoms, as
*e.g.* a protein subunit. There are a variety of rotation potentials,
among them complex ones that allow flexible adaptations of both the
rotated subunit as well as the local rotation axis during the
simulation. An example application can be found in ref.
:ref:`145 <refKutzner2011>`.

.. _fig-rotation:

.. figure:: plots/rotation.*
   :width: 13.00000cm

   Comparison of fixed and flexible axis rotation. A:
   Rotating the sketched shape inside the white tubular cavity can
   create artifacts when a fixed rotation axis (dashed) is used. More
   realistically, the shape would revolve like a flexible pipe-cleaner
   (dotted) inside the bearing (gray). B: Fixed rotation
   around an axis :math:`\mathbf{v}` with a pivot point
   specified by the vector :math:`\mathbf{u}`.
   C: Subdividing the rotating fragment into slabs with
   separate rotation axes (:math:`\uparrow`) and pivot points
   (:math:`\bullet`) for each slab allows for flexibility. The distance
   between two slabs with indices :math:`n` and :math:`n+1` is
   :math:`\Delta x`.

.. _fig-equipotential:

.. figure:: plots/equipotential.*
   :width: 13.00000cm

   Selection of different rotation potentials and definition of
   notation. All four potentials :math:`V` (color coded) are shown for a
   single atom at position :math:`\mathbf{x}_j(t)`.
   A: Isotropic potential :math:`V^\mathrm{iso}`,
   B: radial motion potential :math:`V^\mathrm{rm}` and
   flexible potential :math:`V^\mathrm{flex}`, C–D: radial
   motion2 potential :math:`V^\mathrm{rm2}` and flexible2 potential
   :math:`V^\mathrm{flex2}` for :math:`\epsilon'\mathrm{ = }0\mathrm{ nm}^2`
   (C) and :math:`\epsilon'\mathrm{ = }0.01\mathrm{nm}^2`
   (D). The rotation axis is perpendicular to the plane
   and marked by :math:`\otimes`. The light gray contours indicate
   Boltzmann factors :math:`e^{-V/(k_B T)}` in the
   :math:`\mathbf{x}_j`-plane for :math:`T=300`\ K and
   :math:`k\mathrm{ = }200\mathrm{kJ}/(\mathrm{mol }\cdot\mathrm{nm}^2)`. The green
   arrow shows the direction of the force
   :math:`\mathbf{F}_{\!j}` acting on atom :math:`j`; the
   blue dashed line indicates the motion of the reference position.

Fixed Axis Rotation
^^^^^^^^^^^^^^^^^^^

Stationary Axis with an Isotropic Potential
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the fixed axis approach (see :numref:`Fig. %s B <fig-rotation>`),
torque on a group of :math:`N` atoms with positions
:math:`\mathbf{x}_i` (denoted “rotation group”) is applied
by rotating a reference set of atomic positions – usually their initial
positions :math:`\mathbf{y}_i^0` – at a constant angular
velocity :math:`\omega` around an axis defined by a direction vector
:math:`\hat{\mathbf{v}}` and a pivot point
:math:`\mathbf{u}`. To that aim, each atom with
position :math:`\mathbf{x}_i` is attracted by a “virtual
spring” potential to its moving reference position
:math:`\mathbf{y}_i = \mathbf{\Omega}(t) (\mathbf{y}_i^0 - \mathbf{u})`,
where :math:`\mathbf{\Omega}(t)` is a matrix that describes the rotation
around the axis. In the simplest case, the “springs” are described by a
harmonic potential,

.. math:: V^\mathrm{iso} = \frac{k}{2} \sum_{i=1}^{N} w_i \left[ \mathbf{\Omega}(t)
          (\mathbf{y}_i^0 - \mathbf{u}) - (\mathbf{x}_i - \mathbf{u})  \right]^2
          :label: eqnpotiso

with optional mass-weighted prefactors :math:`w_i = N \, m_i/M` with
total mass :math:`M = \sum_{i=1}^N m_i`. The rotation matrix
:math:`\mathbf{\Omega}(t)` is

.. math:: \mathbf{\Omega}(t) =  
          \left(   
          \begin{array}{ccc}
          \cos\omega t + v_x^2{\,\xi\,}& v_x v_y{\,\xi\,}- v_z\sin\omega t  & v_x v_z{\,\xi\,}+ v_y\sin\omega t\\
          v_x v_y{\,\xi\,}+ v_z\sin\omega t  & \cos\omega t + v_y^2{\,\xi\,}& v_y v_z{\,\xi\,}- v_x\sin\omega t\\
          v_x v_z{\,\xi\,}- v_y\sin\omega t  & v_y v_z{\,\xi\,}+ v_x\sin\omega t  & \cos\omega t + v_z^2{\,\xi\,}\\
          \end{array}
          \right)
          :label: eqnrotmat

where :math:`v_x`, :math:`v_y`, and :math:`v_z` are the components of
the normalized rotation vector :math:`\hat{\mathbf{v}}`,
and :math:`{\,\xi\,}:= 1-\cos(\omega t)`. As illustrated in
:numref:`Fig.  %s A <fig-equipotential>` for a single atom :math:`j`,
the rotation matrix :math:`\mathbf{\Omega}(t)` operates on the initial
reference positions
:math:`\mathbf{y}_j^0 = \mathbf{x}_j(t_0)`
of atom :math:`j` at :math:`t=t_0`. At a later time :math:`t`, the
reference position has rotated away from its initial place (along the
blue dashed line), resulting in the force

.. math:: \mathbf{F}_{\!j}^\mathrm{iso} 
          = -\nabla_{\!j} \, V^\mathrm{iso} 
          = k \, w_j \left[
          \mathbf{\Omega}(t) (\mathbf{y}_j^0 - \mathbf{u}) - (\mathbf{x}_j - \mathbf{u} ) \right]
          :label: eqnforcefixed

which is directed towards the reference position.

Pivot-Free Isotropic Potential
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Instead of a fixed pivot vector :math:`\mathbf{u}` this
potential uses the center of mass :math:`\mathbf{x}_c` of
the rotation group as pivot for the rotation axis,

.. math:: \mathbf{x}_c   = \frac{1}{M} \sum_{i=1}^N m_i \mathbf{x}_i 
          \mbox{and}
          \mathbf{y}_c^0 = \frac{1}{M} \sum_{i=1}^N m_i \mathbf{y}_i^0 \ ,
          :label: eqncom

which yields the “pivot-free” isotropic potential

.. math:: V^\mathrm{iso-pf} = \frac{k}{2} \sum_{i=1}^{N} w_i \left[ \mathbf{\Omega}(t)
          (\mathbf{y}_i^0 - \mathbf{y}_c^0) - (\mathbf{x}_i - \mathbf{x}_c) \right]^2 ,
          :label: eqnpotisopf

with forces

.. math:: \mathbf{F}_{\!j}^\mathrm{iso-pf} = k \, w_j 
          \left[ 
          \mathbf{\Omega}(t) ( \mathbf{y}_j^0 - \mathbf{y}_c^0) 
                           - ( \mathbf{x}_j   - \mathbf{x}_c )
          \right] .
          :label: eqnforceisopf

Without mass-weighting, the pivot :math:`\mathbf{x}_c` is
the geometrical center of the group.

Parallel Motion Potential Variant
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The forces generated by the isotropic potentials
(eqns. :eq:`%s <eqnpotiso>` and :eq:`%s <eqnpotisopf>`) also contain components parallel to the
rotation axis and thereby restrain motions along the axis of either the
whole rotation group (in case of :math:`V^\mathrm{iso}`) or within the
rotation group, in case of :math:`V^\mathrm{iso-pf}`.
        
For cases where unrestrained motion along the axis is preferred, we have implemented a
“parallel motion” variant by eliminating all components parallel to the
rotation axis for the potential. This is achieved by projecting the
distance vectors between reference and actual positions

.. math:: \mathbf{r}_i = \mathbf{\Omega}(t) (\mathbf{y}_i^0 - \mathbf{u}) - (\mathbf{x}_i - \mathbf{u})
          :label: eqnrotdistvectors

onto the plane perpendicular to the rotation vector,

.. math:: \mathbf{r}_i^\perp :=  \mathbf{r}_i - (\mathbf{r}_i \cdot \hat{\mathbf{v}})\hat{\mathbf{v}}
          :label: eqnproject

yielding

.. math:: \begin{aligned}
          \nonumber
          V^\mathrm{pm} &=& \frac{k}{2} \sum_{i=1}^{N} w_i ( \mathbf{r}_i^\perp )^2 \\
                  &=& \frac{k}{2} \sum_{i=1}^{N} w_i
           \left\lbrace
           \mathbf{\Omega}(t)
             (\mathbf{y}_i^0 - \mathbf{u}) - (\mathbf{x}_i - \mathbf{u})  \right. \nonumber \\
          && \left. - \left\lbrace
          \left[ \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{u}) - (\mathbf{x}_i - \mathbf{u}) \right] \cdot\hat{\mathbf{v}}
            \right\rbrace\hat{\mathbf{v}} \right\rbrace^2
          \end{aligned}
          :label: eqnpotpm

and similarly

.. math:: \mathbf{F}_{\!j}^\mathrm{pm} = k \, w_j \, \mathbf{r}_j^\perp
          :label: eqnforcepm

Pivot-Free Parallel Motion Potential
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Replacing in eqn. :eq:`%s <eqnpotpm>` the fixed pivot
:math:`\mathbf{u}` by the center of mass
:math:`\mathbf{x_c}` yields the pivot-free variant of the
parallel motion potential. With

.. math:: \mathbf{s}_i = \mathbf{\Omega}(t) (\mathbf{y}_i^0 - \mathbf{y}_c^0) - (\mathbf{x}_i - \mathbf{x}_c)
          :label: eqnparrallelpotential

the respective potential and forces are

.. math:: \begin{aligned}
          V^\mathrm{pm-pf} &=& \frac{k}{2} \sum_{i=1}^{N} w_i ( \mathbf{s}_i^\perp )^2 \end{aligned}
          :label: eqnpotpmpf

.. math:: \begin{aligned}
          \mathbf{F}_{\!j}^\mathrm{pm-pf} &=& k \, w_j \, \mathbf{s}_j^\perp
          \end{aligned}
          :label: eqnforcepmpf

Radial Motion Potential
^^^^^^^^^^^^^^^^^^^^^^^

In the above variants, the minimum of the rotation potential is either a
single point at the reference position
:math:`\mathbf{y}_i` (for the isotropic potentials) or a
single line through :math:`\mathbf{y}_i` parallel to the
rotation axis (for the parallel motion potentials). As a result, radial
forces restrict radial motions of the atoms. The two subsequent types of
rotation potentials, :math:`V^\mathrm{rm}` and :math:`V^\mathrm{rm2}`, drastically
reduce or even eliminate this effect. The first variant, :math:`V^\mathrm{rm}`
(:numref:`Fig. %s B <fig-equipotential>`), eliminates all force
components parallel to the vector connecting the reference atom and the
rotation axis,

.. math:: V^\mathrm{rm} = \frac{k}{2} \sum_{i=1}^{N} w_i \left[
          \mathbf{p}_i
          \cdot(\mathbf{x}_i - \mathbf{u}) \right]^2 ,
          :label: eqnpotrm

with

.. math::   \mathbf{p}_i := 
            \frac{\hat{\mathbf{v}}\times \mathbf{\Omega}(t) (\mathbf{y}_i^0 - \mathbf{u})} {\| \hat{\mathbf{v}}\times \mathbf{\Omega}(t) (\mathbf{y}_i^0 - \mathbf{u})\|} \ .
            :label: eqnpotrmpart2

This variant depends only on the distance
:math:`\mathbf{p}_i \cdot (\mathbf{x}_i -
\mathbf{u})` of atom :math:`i` from the plane spanned by
:math:`\hat{\mathbf{v}}` and
:math:`\mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{u})`.
The resulting force is

.. math:: \mathbf{F}_{\!j}^\mathrm{rm} =
           -k \, w_j \left[ \mathbf{p}_j\cdot(\mathbf{x}_j - \mathbf{u}) \right] \,\mathbf{p}_j \,  .
          :label: eqnpotrmforce

Pivot-Free Radial Motion Potential
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Proceeding similar to the pivot-free isotropic potential yields a
pivot-free version of the above potential. With

.. math:: \mathbf{q}_i := 
          \frac{\hat{\mathbf{v}}\times \mathbf{\Omega}(t) (\mathbf{y}_i^0 - \mathbf{y}_c^0)} {\| \hat{\mathbf{v}}\times \mathbf{\Omega}(t) (\mathbf{y}_i^0 - \mathbf{y}_c^0)\|} \, ,
          :label: eqnpotrmpfpart1

the potential and force for the pivot-free variant of the radial motion
potential read

.. math:: \begin{aligned}
          V^\mathrm{rm-pf} & = & \frac{k}{2} \sum_{i=1}^{N} w_i \left[
          \mathbf{q}_i
          \cdot(\mathbf{x}_i - \mathbf{x}_c)
          \right]^2 \, , \end{aligned}
          :label: eqnpotrmpf

.. math:: \begin{aligned}       
          \mathbf{F}_{\!j}^\mathrm{rm-pf} & = &
           -k \, w_j \left[ \mathbf{q}_j\cdot(\mathbf{x}_j - \mathbf{x}_c) \right] \,\mathbf{q}_j 
           + k   \frac{m_j}{M} \sum_{i=1}^{N} w_i \left[
           \mathbf{q}_i\cdot(\mathbf{x}_i - \mathbf{x}_c) \right]\,\mathbf{q}_i \, .
          \end{aligned}
          :label: eqnpotrmpfforce

Radial Motion 2 Alternative Potential
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

As seen in :numref:`Fig. %s B <fig-equipotential>`, the force
resulting from :math:`V^\mathrm{rm}` still contains a small, second-order
radial component. In most cases, this perturbation is tolerable; if not,
the following alternative, :math:`V^\mathrm{rm2}`, fully eliminates the
radial contribution to the force, as depicted in
:numref:`Fig. %s C <fig-equipotential>`,

.. math:: V^\mathrm{rm2} = 
          \frac{k}{2} \sum_{i=1}^{N} w_i\, 
          \frac{\left[ (\hat{\mathbf{v}} \times ( \mathbf{x}_i - \mathbf{u} ))
          \cdot \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{u}) \right]^2}
          {\| \hat{\mathbf{v}} \times (\mathbf{x}_i - \mathbf{u}) \|^2 +
          \epsilon'} \, ,
          :label: eqnpotrm2

where a small parameter :math:`\epsilon'` has been introduced to avoid
singularities. For :math:`\epsilon'\mathrm{ = }0\mathrm{nm}^2`, the
equipotential planes are spanned by :math:`\mathbf{x}_i -
\mathbf{u}` and :math:`\hat{\mathbf{v}}`,
yielding a force perpendicular to
:math:`\mathbf{x}_i - \mathbf{u}`, thus not
contracting or expanding structural parts that moved away from or toward
the rotation axis.

Choosing a small positive :math:`\epsilon'` (*e.g.*,
:math:`\epsilon'\mathrm{ = }0.01\mathrm{nm}^2`,
:numref:`Fig. %s D <fig-equipotential>`) in the denominator of
eqn. :eq:`%s <eqnpotrm2>` yields a well-defined potential and
continuous forces also close to the rotation axis, which is not the case
for :math:`\epsilon'\mathrm{ = }0\mathrm{nm}^2`
(:numref:`Fig. %s C <fig-equipotential>`). With

.. math:: \begin{aligned}
          \mathbf{r}_i & := & \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{u})\\
          \mathbf{s}_i & := & \frac{\hat{\mathbf{v}} \times (\mathbf{x}_i -
          \mathbf{u} ) }{ \| \hat{\mathbf{v}} \times (\mathbf{x}_i - \mathbf{u})
          \| } \equiv \; \Psi_{i} \;\; {\hat{\mathbf{v}} \times
          (\mathbf{x}_i-\mathbf{u} ) }\\
          \Psi_i^{*}   & := & \frac{1}{ \| \hat{\mathbf{v}} \times
          (\mathbf{x}_i-\mathbf{u}) \|^2 + \epsilon'}\end{aligned}
          :label: eqnpotrm2forcepart1

the force on atom :math:`j` reads

.. math:: \mathbf{F}_{\!j}^\mathrm{rm2}  = 
          - k\; 
          \left\lbrace w_j\;
          (\mathbf{s}_j\cdot\mathbf{r}_{\!j})\;
          \left[ \frac{\Psi_{\!j}^*   }{\Psi_{\!j}  }  \mathbf{r}_{\!j} 
               - \frac{\Psi_{\!j}^{ * 2}}{\Psi_{\!j}^3}
               (\mathbf{s}_j\cdot\mathbf{r}_{\!j})\mathbf{s}_j \right]
          \right\rbrace \times \hat{\mathbf{v}} .
          :label: eqnpotrm2force

Pivot-Free Radial Motion 2 Potential
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The pivot-free variant of the above potential is

.. math:: V{^\mathrm{rm2-pf}}= 
          \frac{k}{2} \sum_{i=1}^{N} w_i\, 
          \frac{\left[ (\hat{\mathbf{v}} \times ( \mathbf{x}_i - \mathbf{x}_c ))
          \cdot \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{y}_c) \right]^2}
          {\| \hat{\mathbf{v}} \times (\mathbf{x}_i - \mathbf{x}_c) \|^2 +
          \epsilon'} \, .
          :label: eqnpotrm2pf

With

.. math:: \begin{aligned}
          \mathbf{r}_i & := & \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{y}_c)\\
          \mathbf{s}_i & := & \frac{\hat{\mathbf{v}} \times (\mathbf{x}_i -
          \mathbf{x}_c ) }{ \| \hat{\mathbf{v}} \times (\mathbf{x}_i - \mathbf{x}_c)
          \| } \equiv \; \Psi_{i} \;\; {\hat{\mathbf{v}} \times
          (\mathbf{x}_i-\mathbf{x}_c ) }\\ \Psi_i^{*}   & := & \frac{1}{ \| \hat{\mathbf{v}} \times
          (\mathbf{x}_i-\mathbf{x}_c) \|^2 + \epsilon'}\end{aligned}
          :label: eqnpotrm2pfpart2

the force on atom :math:`j` reads

.. math:: \begin{aligned}
          \nonumber
          \mathbf{F}_{\!j}{^\mathrm{rm2-pf}}& = &
          - k\; 
          \left\lbrace w_j\;
          (\mathbf{s}_j\cdot\mathbf{r}_{\!j})\;
          \left[ \frac{\Psi_{\!j}^*   }{\Psi_{\!j}  } \mathbf{r}_{\!j} 
               - \frac{\Psi_{\!j}^{ * 2}}{\Psi_{\!j}^3}
               (\mathbf{s}_j\cdot\mathbf{r}_{\!j})\mathbf{s}_j \right]
          \right\rbrace \times \hat{\mathbf{v}}\\
               & &
          + k\;\frac{m_j}{M} \left\lbrace \sum_{i=1}^{N}
          w_i\;(\mathbf{s}_i\cdot\mathbf{r}_i) \; 
          \left[ \frac{\Psi_i^*   }{\Psi_i  }  \mathbf{r}_i
               - \frac{\Psi_i^{ * 2}}{\Psi_i^3} (\mathbf{s}_i\cdot\mathbf{r}_i )\;
               \mathbf{s}_i \right] \right\rbrace \times \hat{\mathbf{v}} \, .
          \end{aligned}
          :label: eqnpotrm2pfforce

Flexible Axis Rotation
~~~~~~~~~~~~~~~~~~~~~~

As sketched in :numref:`Fig. %s <fig-rotation>` A–B, the rigid body
behavior of the fixed axis rotation scheme is a drawback for many
applications. In particular, deformations of the rotation group are
suppressed when the equilibrium atom positions directly depend on the
reference positions. To avoid this limitation,
eqns. :eq:`%s <eqnpotrmpf>` and :eq:`%s <eqnpotrm2pf>`
will now be generalized towards a “flexible axis” as sketched in
:numref:`Fig. %s C <fig-rotation>`. This will be achieved by
subdividing the rotation group into a set of equidistant slabs
perpendicular to the rotation vector, and by applying a separate
rotation potential to each of these slabs.
:numref:`Fig. %s C <fig-rotation>` shows the midplanes of the slabs
as dotted straight lines and the centers as thick black dots.

To avoid discontinuities in the potential and in the forces, we define
“soft slabs” by weighing the contributions of each slab :math:`n` to the
total potential function :math:`V^\mathrm{flex}` by a Gaussian function

.. math:: g_n(\mathbf{x}_i) = \Gamma \ \mbox{exp} \left(
          -\frac{\beta_n^2(\mathbf{x}_i)}{2\sigma^2}  \right) ,
          :label: eqngaussian

centered at the midplane of the :math:`n`\ th slab. Here :math:`\sigma`
is the width of the Gaussian function, :math:`\Delta x` the distance
between adjacent slabs, and

.. math:: \beta_n(\mathbf{x}_i) := \mathbf{x}_i \cdot \hat{\mathbf{v}} - n \, \Delta x \, .
          :label: eqngaussianpart2

.. _fig-gaussian:

.. figure:: plots/gaussians.*
   :width: 6.50000cm

   Gaussian functions :math:`g_n` centered at :math:`n \, \Delta x` for
   a slab distance :math:`\Delta x = 1.5` nm and :math:`n \geq -2`.
   Gaussian function :math:`g_0` is highlighted in bold; the dashed line
   depicts the sum of the shown Gaussian functions.

A most convenient choice is :math:`\sigma = 0.7 \Delta x` and

.. math:: 1/\Gamma = \sum_{n \in Z}
          \mbox{exp}
          \left(-\frac{(n - \frac{1}{4})^2}{2\cdot 0.7^2}\right)
          \approx 1.75464 \, ,
          :label: eqngaussianpart3

which yields a nearly constant sum, essentially independent of
:math:`\mathbf{x}_i` (dashed line in
:numref:`Fig. %s <fig-gaussian>`), *i.e.*,

.. math:: \sum_{n \in Z} g_n(\mathbf{x}_i) =  1 + \epsilon(\mathbf{x}_i) \, ,
          :label: eqnnormal

with
:math:`| \epsilon(\mathbf{x}_i) | < 1.3\cdot 10^{-4}`.
This choice also implies that the individual contributions to the force
from the slabs add up to unity such that no further normalization is
required.

To each slab center :math:`\mathbf{x}_c^n`, all atoms
contribute by their Gaussian-weighted (optionally also mass-weighted)
position vectors
:math:`g_n(\mathbf{x}_i) \, \mathbf{x}_i`.
The instantaneous slab centers :math:`\mathbf{x}_c^n` are
calculated from the current positions
:math:`\mathbf{x}_i`,

.. math::  \mathbf{x}_c^n =
           \frac{\sum_{i=1}^N g_n(\mathbf{x}_i) \, m_i \, \mathbf{x}_i}
                {\sum_{i=1}^N g_n(\mathbf{x}_i) \, m_i} \, ,\\
           :label: eqndefx0 

while the reference centers :math:`\mathbf{y}_c^n` are
calculated from the reference positions
:math:`\mathbf{y}_i^0`,

.. math:: \mathbf{y}_c^n =
          \frac{\sum_{i=1}^N g_n(\mathbf{y}_i^0) \, m_i \, \mathbf{y}_i^0}
               {\sum_{i=1}^N g_n(\mathbf{y}_i^0) \, m_i} \, .
          :label: eqndefy0

Due to the rapid decay of :math:`g_n`, each slab will essentially
involve contributions from atoms located within :math:`\approx
3\Delta x` from the slab center only.

Flexible Axis Potential
^^^^^^^^^^^^^^^^^^^^^^^

We consider two flexible axis variants. For the first variant, the slab
segmentation procedure with Gaussian weighting is applied to the radial
motion potential
(eqn. :eq:`%s <eqnpotrmpf>` / :numref:`Fig. %s B <fig-equipotential>`),
yielding as the contribution of slab :math:`n`

.. math::  V^n = 
           \frac{k}{2} \sum_{i=1}^{N} w_i \, g_n(\mathbf{x}_i) 
           \left[
           \mathbf{q}_i^n
           \cdot
            (\mathbf{x}_i - \mathbf{x}_c^n) 
           \right]^2  ,
           :label: eqnflexpot

and a total potential function

.. math:: V^\mathrm{flex} = \sum_n V^n \, .
          :label: eqnpotflex

Note that the global center of mass :math:`\mathbf{x}_c`
used in eqn. :eq:`%s <eqnpotrmpf>` is now replaced by
:math:`\mathbf{x}_c^n`, the center of mass of the slab.
With

.. math:: \begin{aligned}
          \mathbf{q}_i^n & := & \frac{\hat{\mathbf{v}} \times
          \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{y}_c^n) }{ \| \hat{\mathbf{v}}
          \times \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{y}_c^n) \| } \\
          b_i^n         & := & \mathbf{q}_i^n \cdot (\mathbf{x}_i - \mathbf{x}_c^n) \, ,\end{aligned}
          :label: eqnflexpotpart2

the resulting force on atom :math:`j` reads

.. math:: \begin{aligned}
          \nonumber\hspace{-15mm}
          \mathbf{F}_{\!j}^\mathrm{flex} &=&
          - \, k \, w_j \sum_n g_n(\mathbf{x}_j) \, b_j^n \left\lbrace  \mathbf{q}_j^n -
          b_j^n \frac{\beta_n(\mathbf{x}_j)}{2\sigma^2} \hat{\mathbf{v}} \right\rbrace \\ & &
          + \, k \, m_j \sum_n \frac{g_n(\mathbf{x}_j)}{\sum_h g_n(\mathbf{x}_h)}
          \sum_{i=1}^{N} w_i \, g_n(\mathbf{x}_i) \, b_i^n \left\lbrace 
          \mathbf{q}_i^n -\frac{\beta_n(\mathbf{x}_j)}{\sigma^2}
          \left[ \mathbf{q}_i^n \cdot (\mathbf{x}_j - \mathbf{x}_c^n )\right]
          \hat{\mathbf{v}} \right\rbrace .
          \end{aligned}
          :label: eqnpotflexforce

Note that for :math:`V^\mathrm{flex}`, as defined, the slabs are fixed in
space and so are the reference centers
:math:`\mathbf{y}_c^n`. If during the simulation the
rotation group moves too far in :math:`\mathbf{v}`
direction, it may enter a region where – due to the lack of nearby
reference positions – no reference slab centers are defined, rendering
the potential evaluation impossible. We therefore have included a
slightly modified version of this potential that avoids this problem by
attaching the midplane of slab :math:`n=0` to the center of mass of the
rotation group, yielding slabs that move with the rotation group. This
is achieved by subtracting the center of mass
:math:`\mathbf{x}_c` of the group from the positions,

.. math:: \tilde{\mathbf{x}}_i = \mathbf{x}_i - \mathbf{x}_c \, , \mbox{\ \ \ and \ \ } 
          \tilde{\mathbf{y}}_i^0 = \mathbf{y}_i^0 - \mathbf{y}_c^0 \, ,
          :label: eqntrafo

such that

.. math:: \begin{aligned}
          V^\mathrm{flex-t} 
            & = & \frac{k}{2} \sum_n \sum_{i=1}^{N} w_i \, g_n(\tilde{\mathbf{x}}_i)
            \left[ \frac{\hat{\mathbf{v}} \times \mathbf{\Omega}(t)(\tilde{\mathbf{y}}_i^0
            - \tilde{\mathbf{y}}_c^n) }{ \| \hat{\mathbf{v}} \times
          \mathbf{\Omega}(t)(\tilde{\mathbf{y}}_i^0 -
          \tilde{\mathbf{y}}_c^n) \| }
          \cdot
           (\tilde{\mathbf{x}}_i - \tilde{\mathbf{x}}_c^n) 
          \right]^2 .
          \end{aligned}
          :label: eqnpotflext

To simplify the force derivation, and for efficiency reasons, we here
assume :math:`\mathbf{x}_c` to be constant, and thus
:math:`\partial \mathbf{x}_c / \partial x =
\partial \mathbf{x}_c / \partial y = \partial \mathbf{x}_c / \partial z = 0`.
The resulting force error is small (of order :math:`O(1/N)` or
:math:`O(m_j/M)` if mass-weighting is applied) and can therefore be
tolerated. With this assumption, the forces :math:`\mathbf{F}^\mathrm{flex-t}`
have the same form as eqn. :eq:`%s <eqnpotflexforce>`.

Flexible Axis 2 Alternative Potential
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In this second variant, slab segmentation is applied to
:math:`V^\mathrm{rm2}` (eqn. :eq:`%s <eqnpotrm2pf>`), resulting in
a flexible axis potential without radial force contributions
(:numref:`Fig. %s C <fig-equipotential>`),

.. math::   V{^\mathrm{flex2}}= 
            \frac{k}{2} \sum_{i=1}^{N} \sum_n w_i\,g_n(\mathbf{x}_i) 
            \frac{\left[ (\hat{\mathbf{v}} \times ( \mathbf{x}_i - \mathbf{x}_c^n ))
            \cdot \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{y}_c^n) \right]^2}
            {\| \hat{\mathbf{v}} \times (\mathbf{x}_i - \mathbf{x}_c^n) \|^2 +
            \epsilon'}
            :label: eqnpotflex2

With

.. math:: \begin{aligned}
          \mathbf{r}_i^n & := & \mathbf{\Omega}(t)(\mathbf{y}_i^0 - \mathbf{y}_c^n)\\
          \mathbf{s}_i^n & := & \frac{\hat{\mathbf{v}} \times (\mathbf{x}_i -
          \mathbf{x}_c^n ) }{ \| \hat{\mathbf{v}} \times (\mathbf{x}_i - \mathbf{x}_c^n)
          \| } \equiv \; \psi_{i} \;\; {\hat{\mathbf{v}} \times (\mathbf{x}_i-\mathbf{x}_c^n ) }\\
          \psi_i^{*}     & := & \frac{1}{ \| \hat{\mathbf{v}} \times (\mathbf{x}_i-\mathbf{x}_c^n) \|^2 + \epsilon'}\\
          W_j^n          & := & \frac{g_n(\mathbf{x}_j)\,m_j}{\sum_h g_n(\mathbf{x}_h)\,m_h}\\
          \mathbf{S}^n   & := & 
          \sum_{i=1}^{N} w_i\;g_n(\mathbf{x}_i)
          \; (\mathbf{s}_i^n\cdot\mathbf{r}_i^n)
          \left[ \frac{\psi_i^*   }{\psi_i  }  \mathbf{r}_i^n
               - \frac{\psi_i^{ * 2}}{\psi_i^3} (\mathbf{s}_i^n\cdot\mathbf{r}_i^n )\;
               \mathbf{s}_i^n \right] 
          \end{aligned}
          :label: eqnSn

the force on atom :math:`j` reads

.. math:: \begin{aligned}
          \nonumber
          \mathbf{F}_{\!j}{^\mathrm{flex2}}& = &
          - k\; 
          \left\lbrace \sum_n w_j\;g_n(\mathbf{x}_j)\;
          (\mathbf{s}_j^n\cdot\mathbf{r}_{\!j}^n)\;
          \left[ \frac{\psi_j^*   }{\psi_j  }  \mathbf{r}_{\!j}^n 
               - \frac{\psi_j^{ * 2}}{\psi_j^3} (\mathbf{s}_j^n\cdot\mathbf{r}_{\!j}^n)\;
               \mathbf{s}_{\!j}^n \right] \right\rbrace \times \hat{\mathbf{v}} \\
          \nonumber
          & &
          + k \left\lbrace \sum_n W_{\!j}^n \, \mathbf{S}^n \right\rbrace \times
          \hat{\mathbf{v}}
          - k \left\lbrace \sum_n W_{\!j}^n \; \frac{\beta_n(\mathbf{x}_j)}{\sigma^2} \frac{1}{\psi_j}\;\; 
          \mathbf{s}_j^n \cdot 
          \mathbf{S}^n \right\rbrace \hat{\mathbf{v}}\\ 
          & & 
          + \frac{k}{2} \left\lbrace \sum_n w_j\;g_n(\mathbf{x}_j)
          \frac{\beta_n(\mathbf{x}_j)}{\sigma^2} 
          \frac{\psi_j^*}{\psi_j^2}( \mathbf{s}_j^n \cdot \mathbf{r}_{\!j}^n )^2 \right\rbrace
          \hat{\mathbf{v}} .
          \end{aligned}
          :label: eqnpotflex2force

Applying transformation :eq:`%s <eqntrafo>` yields a
“translation-tolerant” version of the flexible2 potential,
:math:`V{^\mathrm{flex2 - t}}`. Again, assuming that
:math:`\partial \mathbf{x}_c / \partial x`,
:math:`\partial \mathbf{x}_c /
\partial y`, :math:`\partial \mathbf{x}_c / \partial z`
are small, the resulting equations for :math:`V{^\mathrm{flex2 - t}}`
and :math:`\mathbf{F}{^\mathrm{flex2 - t}}` are similar
to those of :math:`V^\mathrm{flex2}` and
:math:`\mathbf{F}^\mathrm{flex2}`.

Usage
~~~~~

To apply enforced rotation, the particles :math:`i` that are to be
subjected to one of the rotation potentials are defined via index groups
``rot-group0``, ``rot-group1``, etc., in the
:ref:`mdp` input file. The reference positions
:math:`\mathbf{y}_i^0` are read from a special
:ref:`trr` file provided to :ref:`grompp <gmx grompp>`. If no such
file is found, :math:`\mathbf{x}_i(t=0)` are used as
reference positions and written to :ref:`trr` such that they
can be used for subsequent setups. All parameters of the potentials such
as :math:`k`, :math:`\epsilon'`, etc.
(:numref:`Table %s <tab-vars>`) are provided as :ref:`mdp`
parameters; ``rot-type`` selects the type of the potential.
The option ``rot-massw`` allows to choose whether or not to
use mass-weighted averaging. For the flexible potentials, a cutoff value
:math:`g_n^\mathrm{min}` (typically :math:`g_n^\mathrm{min}=0.001`)
makes sure that only significant contributions to :math:`V` and
:math:`\mathbf{F}` are evaluated, *i.e.* terms with
:math:`g_n(\mathbf{x}) < g_n^\mathrm{min}` are omitted.
:numref:`Table %s <tab-quantities>` summarizes observables that are
written to additional output files and which are described below.

.. |ROTISO| replace:: V\ :math:`^\mathrm{iso}`
.. |ROTISOPF| replace:: V\ :math:`^\mathrm{iso-pf}`
.. |ROTPM| replace:: V\ :math:`^\mathrm{pm}`
.. |ROTPMPF| replace:: V\ :math:`^\mathrm{pm-pf}`
.. |ROTRM| replace:: V\ :math:`^\mathrm{rm}`
.. |ROTRMPF| replace:: V\ :math:`^\mathrm{rm-pf}`
.. |ROTRM2| replace:: V\ :math:`^\mathrm{rm2}`
.. |ROTRM2PF| replace:: V\ :math:`^\mathrm{rm2-pf}`
.. |ROTFL| replace:: V\ :math:`^\mathrm{flex}`
.. |ROTFLT| replace:: V\ :math:`^\mathrm{flex-t}`
.. |ROTFL2| replace:: V\ :math:`^\mathrm{flex2}`
.. |ROTFLT2| replace:: V\ :math:`^\mathrm{flex2-t}`
.. |KUNIT| replace:: :math:`\frac{\mathrm{kJ}}{\mathrm{mol} \cdot \mathrm{nm}^2}`
.. |BFX| replace:: **x**
.. |KMA| replace:: :math:`k`
.. |VECV| replace:: :math:`\hat{\mathbf{v}}`
.. |VECU| replace:: :math:`\mathbf{u}`
.. |OMEG| replace:: :math:`\omega`
.. |EPSP| replace:: :math:`{\epsilon}'`
.. |DELX| replace:: :math:`{\Delta}x`
.. |GMIN| replace:: :math:`g_n^\mathrm{min}`
.. |CIPS| replace:: :math:`^\circ`\ /ps
.. |NM2| replace:: nm\ :math:`^2`
.. |REF1| replace:: \ :eq:`eqnpotiso`
.. |REF2| replace:: \ :eq:`eqnpotisopf`
.. |REF3| replace:: \ :eq:`eqnpotpm`
.. |REF4| replace:: \ :eq:`eqnpotpmpf`
.. |REF5| replace:: \ :eq:`eqnpotrm`
.. |REF6| replace:: \ :eq:`eqnpotrmpf`
.. |REF7| replace:: \ :eq:`eqnpotrm2`
.. |REF8| replace:: \ :eq:`eqnpotrm2pf`
.. |REF9| replace:: \ :eq:`eqnpotflex`
.. |REF10| replace:: \ :eq:`eqnpotflext`
.. |REF11| replace:: \ :eq:`eqnpotflex2`

.. _tab-vars:

.. table:: Parameters used by the various rotation potentials.
           |BFX| indicate which parameter is actually used for a given potential
           :widths: auto
           :align: center

           +------------------------------------------+---------+--------+--------+--------+--------+-----------+-----------+
           | parameter                                | |KMA|   | |VECV| | |VECU| | |OMEG| | |EPSP| | |DELX|    | |GMIN|    |
           +------------------------------------------+---------+--------+--------+--------+--------+-----------+-----------+
           | :ref:`mdp` input variable name           | k       | vec    | pivot  | rate   | eps    | slab-dist | min-gauss |
           +------------------------------------------+---------+--------+--------+--------+--------+-----------+-----------+
           | unit                                     | |KUNIT| | ``-``  | nm     | |CIPS| | |NM2|  | nm        | ``-``     |
           +================================+=========+=========+========+========+========+========+===========+===========+
           | fixed axis potentials:         | eqn.                                                                          |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | isotropic         | |ROTISO|   | |REF1|  | |BFX|   | |BFX|  | |BFX|  | |BFX|  | ``-``  | ``-``     | ``-``     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | --- pivot-free    | |ROTISOPF| | |REF2|  | |BFX|   | |BFX|  | ``-``  | |BFX|  | ``-``  | ``-``     | ``-``     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | parallel motion   | |ROTPM|    | |REF3|  | |BFX|   | |BFX|  | |BFX|  | |BFX|  | ``-``  | ``-``     | ``-``     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | --- pivot-free    | |ROTPMPF|  | |REF4|  | |BFX|   | |BFX|  | ``-``  | |BFX|  | ``-``  | ``-``     | ``-``     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | radial motion     | |ROTRM|    | |REF5|  | |BFX|   | |BFX|  | |BFX|  | |BFX|  | ``-``  | ``-``     | ``-``     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | --- pivot-free    | |ROTRMPF|  | |REF6|  | |BFX|   | |BFX|  | ``-``  | |BFX|  | ``-``  | ``-``     | ``-``     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | radial motion 2   | |ROTRM2|   | |REF7|  | |BFX|   | |BFX|  | |BFX|  | |BFX|  | |BFX|  | ``-``     | ``-``     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | --- pivot-free    | |ROTRM2PF| | |REF8|  | |BFX|   | |BFX|  | ``-``  | |BFX|  | |BFX|  | ``-``     | ``-``     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | flexible axis potentials:      | eqn.                                                                          | 
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | flexible          | |ROTFL|    | |REF9|  | |BFX|   | |BFX|  | ``-``  | |BFX|  | ``-``  | |BFX|     | |BFX|     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | --- transl. tol   | |ROTFLT|   | |REF10| | |BFX|   | |BFX|  | ``-``  | |BFX|  | ``-``  | |BFX|     | |BFX|     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | flexible 2        | |ROTFL2|   | |REF11| | |BFX|   | |BFX|  | ``-``  | |BFX|  | |BFX|  | |BFX|     | |BFX|     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+
           | --- transl. tol   | |ROTFLT2|  | ``-``   | |BFX|   | |BFX|  | ``-``  | |BFX|  | |BFX|  | |BFX|     | |BFX|     |
           +-------------------+------------+---------+---------+--------+--------+--------+--------+-----------+-----------+


| 

.. |VT|      replace:: :math:`V(t)`
.. |THET|    replace:: :math:`\theta_{	\mathrm{ref}}(t)`
.. |THETAV|  replace:: :math:`\theta_{\mathrm{av}}(t)`
.. |THETFIT| replace:: :math:`\theta_{\mathrm{fit}}(t)`, :math:`\theta_{\mathrm{fit}}(t,n)`
.. |YVEC|    replace:: :math:`\mathbf{y}_{0}(n)`, :math:`\mathbf{x}_{0}(t,n)`
.. |TAUT|    replace:: :math:`\tau(t)`
.. |TAUTN|   replace:: :math:`\tau(t,n)`
.. |REFT|  replace:: :numref:`see Table %s <tab-vars>`
.. |REFEQ| replace:: :math:`\theta_{\mathrm{ref}}(t)=\omega t`
.. |REF12| replace:: \ :eq:`eqnavangle`
.. |REF13| replace:: \ :eq:`eqnrmsdfit`
.. |REF14| replace:: \ :eq:`eqndefx0`\ ,\ :eq:`eqndefy0`
.. |REF15| replace:: \ :eq:`eqntorque` 

.. _tab-quantities:

.. table:: Quantities recorded in output files during enforced rotation simulations.
           All slab-wise data is written every ``nstsout`` steps, other rotation data every ``nstrout`` steps.
           :widths: auto
           :align: center

           +------------+---------+------------+--------------------+-------+----------+
           | quantity   | unit    | equation   | output file        | fixed | flexible |
           +============+=========+============+====================+=======+==========+
           | |VT|       | kJ/mol  | |REFT|     | ``rotation``       | |BFX| | |BFX|    |
           +------------+---------+------------+--------------------+-------+----------+
           | |THET|     | degrees | |REFEQ|    | ``rotation``       | |BFX| | |BFX|    |
           +------------+---------+------------+--------------------+-------+----------+
           | |THETAV|   | degrees | |REF12|    | ``rotation``       | |BFX| | ``-``    |
           +------------+---------+------------+--------------------+-------+----------+
           | |THETFIT|  | degrees | |REF13|    | ``rotangles``      | ``-`` | |BFX|    |
           +------------+---------+------------+--------------------+-------+----------+
           | |YVEC|     | nm      | |REF14|    | ``rotslabs``       | ``-`` | |BFX|    |
           +------------+---------+------------+--------------------+-------+----------+
           | |TAUT|     | kJ/mol  | |REF15|    | ``rotation``       | |BFX| | ``-``    |
           +------------+---------+------------+--------------------+-------+----------+
           | |TAUTN|    | kJ/mol  | |REF15|    | ``rottorque``      | ``-`` | |BFX|    |
           +------------+---------+------------+--------------------+-------+----------+




Angle of Rotation Groups: Fixed Axis
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For fixed axis rotation, the average angle :math:`\theta_\mathrm{av}(t)`
of the group relative to the reference group is determined via the
distance-weighted angular deviation of all rotation group atoms from
their reference positions,

.. math::  \theta_\mathrm{av} = \left. \sum_{i=1}^{N} r_i \ \theta_i \right/ \sum_{i=1}^N r_i \ .
           :label: eqnavangle

Here, :math:`r_i` is the distance of the reference position to the
rotation axis, and the difference angles :math:`\theta_i` are determined
from the atomic positions, projected onto a plane perpendicular to the
rotation axis through pivot point :math:`\mathbf{u}` (see
eqn. :eq:`%s <eqnproject>` for the definition of
:math:`\perp`),

.. math:: \cos \theta_i = 
          \frac{(\mathbf{y}_i-\mathbf{u})^\perp \cdot (\mathbf{x}_i-\mathbf{u})^\perp}
               { \| (\mathbf{y}_i-\mathbf{u})^\perp \cdot (\mathbf{x}_i-\mathbf{u})^\perp
               \| } \ .
          :label: eqnavanglepart2

The sign of :math:`\theta_\mathrm{av}` is chosen such that
:math:`\theta_\mathrm{av} > 0` if the actual structure rotates ahead of
the reference.

Angle of Rotation Groups: Flexible Axis
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For flexible axis rotation, two outputs are provided, the angle of the
entire rotation group, and separate angles for the segments in the
slabs. The angle of the entire rotation group is determined by an RMSD
fit of :math:`\mathbf{x}_i` to the reference positions
:math:`\mathbf{y}_i^0` at :math:`t=0`, yielding
:math:`\theta_\mathrm{fit}` as the angle by which the reference has to
be rotated around :math:`\hat{\mathbf{v}}` for the optimal
fit,

.. math::  \mathrm{RMSD} \big( \mathbf{x}_i,\ \mathbf{\Omega}(\theta_\mathrm{fit})
           \mathbf{y}_i^0 \big) \stackrel{!}{=} \mathrm{min} \, .
           :label: eqnrmsdfit

To determine the local angle for each slab :math:`n`, both reference
and actual positions are weighted with the Gaussian function of slab
:math:`n`, and :math:`\theta_\mathrm{fit}(t,n)` is calculated as in
eqn. :eq:`%s <eqnrmsdfit>` from the Gaussian-weighted
positions.

For all angles, the :ref:`mdp` input option
``rot-fit-method`` controls whether a normal RMSD fit is
performed or whether for the fit each position
:math:`\mathbf{x}_i` is put at the same distance to the
rotation axis as its reference counterpart
:math:`\mathbf{y}_i^0`. In the latter case, the RMSD
measures only angular differences, not radial ones.

Angle Determination by Searching the Energy Minimum
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Alternatively, for ``rot-fit-method = potential``, the angle
of the rotation group is determined as the angle for which the rotation
potential energy is minimal. Therefore, the used rotation potential is
additionally evaluated for a set of angles around the current reference
angle. In this case, the ``rotangles.log`` output file
contains the values of the rotation potential at the chosen set of
angles, while ``rotation.xvg`` lists the angle with minimal
potential energy.

Torque
^^^^^^

The torque :math:`\mathbf{\tau}(t)` exerted by the
rotation potential is calculated for fixed axis rotation via

.. math:: \mathbf{\tau}(t) = \sum_{i=1}^{N} \mathbf{r}_i(t) \times \mathbf{f}_{\!i}^\perp(t) ,
          :label: eqntorque

where :math:`\mathbf{r}_i(t)` is the distance vector from
the rotation axis to :math:`\mathbf{x}_i(t)` and
:math:`\mathbf{f}_{\!i}^\perp(t)` is the force component
perpendicular to :math:`\mathbf{r}_i(t)` and
:math:`\hat{\mathbf{v}}`. For flexible axis rotation,
torques :math:`\mathbf{\tau}_{\!n}` are calculated for
each slab using the local rotation axis of the slab and the
Gaussian-weighted positions.
.. _rmfast:

Removing fastest degrees of freedom
-----------------------------------

The maximum time step in MD simulations is limited by the smallest
oscillation period that can be found in the simulated system.
Bond-stretching vibrations are in their quantum-mechanical ground state
and are therefore better represented by a constraint instead of a
harmonic potential.

For the remaining degrees of freedom, the shortest oscillation period
(as measured from a simulation) is 13 fs for bond-angle vibrations
involving hydrogen atoms. Taking as a guideline that with a Verlet
(leap-frog) integration scheme a minimum of 5 numerical integration
steps should be performed per period of a harmonic oscillation in order
to integrate it with reasonable accuracy, the maximum time step will be
about 3 fs. Disregarding these very fast oscillations of period 13 fs,
the next shortest periods are around 20 fs, which will allow a maximum
time step of about 4 fs.

Removing the bond-angle degrees of freedom from hydrogen atoms can best
be done by defining them as virtual interaction sites instead of normal
atoms. Whereas a normal atom is connected to the molecule with bonds,
angles and dihedrals, a virtual site’s position is calculated from the
position of three nearby heavy atoms in a predefined manner (see also
sec. :ref:`virtualsites`). For the hydrogens in water and in hydroxyl,
sulfhydryl, or amine groups, no degrees of freedom can be removed,
because rotational freedom should be preserved. The only other option
available to slow down these motions is to increase the mass of the
hydrogen atoms at the expense of the mass of the connected heavy atom.
This will increase the moment of inertia of the water molecules and the
hydroxyl, sulfhydryl, or amine groups, without affecting the equilibrium
properties of the system and without affecting the dynamical properties
too much. These constructions will shortly be described in
sec. :ref:`vsitehydro` and have previously been described in full
detail \ :ref:`148 <reffeenstra99>`.

Using both virtual sites and modified masses, the next bottleneck is
likely to be formed by the improper dihedrals (which are used to
preserve planarity or chirality of molecular groups) and the peptide
dihedrals. The peptide dihedral cannot be changed without affecting the
physical behavior of the protein. The improper dihedrals that preserve
planarity mostly deal with aromatic residues. Bonds, angles, and
dihedrals in these residues can also be replaced with somewhat elaborate
virtual site constructions.

All modifications described in this section can be performed using the
|Gromacs| topology building tool :ref:`pdb2gmx <gmx pdb2gmx>`. Separate options exist to
increase hydrogen masses, virtualize all hydrogen atoms, or also
virtualize the aromatic rings in standard residues. **Note** that when all hydrogen atoms
are virtualized, those inside the aromatic residues will be virtualized
as well, *i.e.* hydrogens in the aromatic residues are treated
differently depending on the treatment of the aromatic residues. Note
further that the virtualization of aromatic rings is deprecated.

Parameters for the virtual site constructions for the hydrogen atoms are
inferred from the force-field parameters (*vis*. bond lengths and
angles) directly by :ref:`grompp <gmx grompp>` while processing the topology file. The
constructions for the aromatic residues are based on the bond lengths
and angles for the geometry as described in the force fields, but these
parameters are hard-coded into :ref:`pdb2gmx <gmx pdb2gmx>` due to the complex nature of the
construction needed for a whole aromatic group.

.. _vsitehydro:

Hydrogen bond-angle vibrations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Construction of virtual sites
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. _fig-vsitehydro:

.. figure:: plots/dumtypes.*
   :width: 11.00000cm

   The different types of virtual site constructions used for hydrogen
   atoms. The atoms used in the construction of the virtual site(s) are
   depicted as black circles, virtual sites as gray ones. Hydrogens are
   smaller than heavy atoms. A: fixed bond angle, note
   that here the hydrogen is not a virtual site; B: in
   the plane of three atoms, with fixed distance; C: in
   the plane of three atoms, with fixed angle and distance;
   D: construction for amine groups
   (-NH\ :math:`_2` or -NH\ :math:`_3^+`),
   see text for details.

The goal of defining hydrogen atoms as virtual sites is to remove all
high-frequency degrees of freedom from them. In some cases, not all
degrees of freedom of a hydrogen atom should be removed, *e.g.* in the
case of hydroxyl or amine groups the rotational freedom of the hydrogen
atom(s) should be preserved. Care should be taken that no unwanted
correlations are introduced by the construction of virtual sites, *e.g.*
bond-angle vibration between the constructing atoms could translate into
hydrogen bond-length vibration. Additionally, since virtual sites are by
definition massless, in order to preserve total system mass, the mass of
each hydrogen atom that is treated as virtual site should be added to
the bonded heavy atom.

Taking into account these considerations, the hydrogen atoms in a
protein naturally fall into several categories, each requiring a
different approach (see also :numref:`Fig. %s <fig-vsitehydro>`).

-  *hydroxyl (-OH) or sulfhydryl (-SH) hydrogen:* 
   The only internal degree of freedom in a hydroxyl group
   that can be constrained is the bending of the C-O-H
   angle. This angle is fixed by defining an additional bond of
   appropriate length, see :numref:`Fig. %s A<fig-vsitehydro>`.
   Doing so removes the high-frequency angle bending, but leaves the
   dihedral rotational freedom. The same goes for a sulfhydryl group.
   **Note** that in these cases the hydrogen is not treated as a virtual
   site.

-  *single amine or amide (-NH-) and aromatic hydrogens
   (-CH-):* 
   The position of these hydrogens cannot be
   constructed from a linear combination of bond vectors, because of the
   flexibility of the angle between the heavy atoms. Instead, the
   hydrogen atom is positioned at a fixed distance from the bonded heavy
   atom on a line going through the bonded heavy atom and a point on the
   line through both second bonded atoms, see
   :numref:`Fig. %s B<fig-vsitehydro>`.

-  *planar amine (-NH*:math:`_2`) *hydrogens:* The method
   used for the single amide hydrogen is not well suited for planar
   amine groups, because no suitable two heavy atoms can be found to
   define the direction of the hydrogen atoms. Instead, the hydrogen is
   constructed at a fixed distance from the nitrogen atom, with a fixed
   angle to the carbon atom, in the plane defined by one of the other
   heavy atoms, see :numref:`Fig. %s C<fig-vsitehydro>`.

-  *amine group (umbrella -NH*:math:`_2` *or
   -NH*:math:`_3^+`)* hydrogens:* Amine hydrogens with
   rotational freedom cannot be constructed as virtual sites from the
   heavy atoms they are connected to, since this would result in loss of
   the rotational freedom of the amine group. To preserve the rotational
   freedom while removing the hydrogen bond-angle degrees of freedom,
   two “dummy masses” are constructed with the same total mass, moment
   of inertia (for rotation around the C-N bond) and
   center of mass as the amine group. These dummy masses have no
   interaction with any other atom, except for the fact that they are
   connected to the carbon and to each other, resulting in a rigid
   triangle. From these three particles, the positions of the nitrogen
   and hydrogen atoms are constructed as linear combinations of the two
   carbon-mass vectors and their outer product, resulting in an amine
   group with rotational freedom intact, but without other internal
   degrees of freedom. See :numref:`Fig. %s D<fig-vsitehydro>`.

.. figure:: plots/dumaro.*
   :width: 15.00000cm

   The different types of virtual site constructions used for aromatic
   residues. The atoms used in the construction of the virtual site(s)
   are depicted as black circles, virtual sites as gray ones. Hydrogens
   are smaller than heavy atoms. A: phenylalanine;
   B: tyrosine (note that the hydroxyl hydrogen is *not*
   a virtual site); C: tryptophan; D:
   histidine.

Out-of-plane vibrations in aromatic groups
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The planar arrangements in the side chains of the aromatic residues
lends itself perfectly to a virtual-site construction, giving a
perfectly planar group without the inherently unstable constraints that
are necessary to keep normal atoms in a plane. The basic approach is to
define three atoms or dummy masses with constraints between them to fix
the geometry and create the rest of the atoms as simple virtual sites
type (see sec. :ref:`virtualsites`) from these three. Each of the
aromatic residues require a different approach:

-  *Phenylalanine:* C\ :math:`_\gamma`,
   C\ :math:`_{{\epsilon}1}`, and
   C\ :math:`_{{\epsilon}2}` are kept as normal atoms,
   but with each a mass of one third the total mass of the phenyl group.
   See :numref:`Fig. %s A<fig-vsitehydro>`.

-  *Tyrosine:* The ring is treated identically to the phenylalanine
   ring. Additionally, constraints are defined between
   C\ :math:`_{{\epsilon}1}`,
   C\ :math:`_{{\epsilon}2}`, and
   O\ :math:`_{\eta}`. The original improper dihedral
   angles will keep both triangles (one for the ring and one with
   O\ :math:`_{\eta}`) in a plane, but due to the larger
   moments of inertia this construction will be much more stable. The
   bond-angle in the hydroxyl group will be constrained by a constraint
   between C\ :math:`_\gamma` and
   H\ :math:`_{\eta}`. **Note** that the hydrogen is not
   treated as a virtual site. See
   :numref:`Fig. %s B<fig-vsitehydro>`.

-  *Tryptophan:* C\ :math:`_\beta` is kept as a normal
   atom and two dummy masses are created at the center of mass of each
   of the rings, each with a mass equal to the total mass of the
   respective ring (C\ :math:`_{{\delta}2}` and
   C\ :math:`_{{\epsilon}2}` are each counted half for
   each ring). This keeps the overall center of mass and the moment of
   inertia almost (but not quite) equal to what it was. See
   :numref:`Fig. %s C<fig-vsitehydro>`.

-  *Histidine:* C\ :math:`_\gamma`,
   C\ :math:`_{{\epsilon}1}` and
   N\ :math:`_{{\epsilon}2}` are kept as normal atoms,
   but with masses redistributed such that the center of mass of the
   ring is preserved. See :numref:`Fig. %s D<fig-vsitehydro>`.
.. _qmmm:

Hybrid Quantum-Classical simulations (QM/MM) with CP2K interface
----------------------------------------------------------------

In a molecular mechanics (MM) force field, the influence of electrons is
expressed by empirical parameters that are assigned on the basis of
experimental data, or on the basis of results from high-level quantum
chemistry calculations. These are valid for the ground state of a given
covalent structure, and the MM approximation is usually sufficiently
accurate for ground-state processes in which the overall connectivity
between the atoms in the system remains unchanged. However, for
processes in which the connectivity does change, such as chemical
reactions, or processes that involve multiple electronic states, such as
photochemical conversions, electrons can no longer be ignored, and a
quantum mechanical description is required for at least those parts of
the system in which the reaction takes place.

One approach to the simulation of chemical reactions in solution, or in
enzymes, is to use a combination of quantum mechanics (QM) and molecular
mechanics (MM). The reacting parts of the system are treated quantum
mechanically, with the remainder being modeled using the force field.
The current version of |Gromacs| provides an interface to the popular
Quantum Chemistry package CP2K :ref:`188 <refcp2k2020>`.

Overview
^^^^^^^^

|Gromacs| interactions between the QM and the MM subsystems are handled using
the GEEP approach as described by Laino et al. :ref:`189 <refLaino2005>`. 
This method of evaluating interactions between the QM and MM subsystems 
is a variant of the "electrostatic embedding" scheme. The electrostatic 
interactions between the electrons of the QM region and the MM atoms 
and between the QM nuclei and the MM atoms are explicitly included into
the Hamiltonian for the QM subsystem:

   .. math::

      H^{QM/MM} =
      H^{QM}_e-\sum_i^n\sum_J^M\frac{e^2Q_J}{4\pi\epsilon_0r_{iJ}}+\sum_A^N\sum_J^M\frac{e^2Z_AQ_J}{e\pi\epsilon_0R_{AJ}},

where :math:`n` and :math:`N` are the number of electrons and nuclei
in the QM region, respectively, and :math:`M` is the number of
charged MM atoms. The first term on the right hand side is the
original electronic Hamiltonian of an isolated QM system. The first
of the double sums is the total electrostatic interaction between the
QM electrons and the MM atoms. The total electrostatic interaction of
the QM nuclei with the MM atoms is given by the second double sum. 
An important advantage of using the CP2K/GEEP combination is that it allows
evaluation of forces for both QM-QM and QM-MM interactions,
in the case of systems with periodic boundary conditions (PBC).
To avoid double accounting for electrostatic interactions and LJ,
classical MM charge on the QM atoms are zeroed out as well as LJ
interactions between QM-QM atoms are excluded. It should be noted that 
LJ interactions between QM-MM atoms are kept and still calculated by |Gromacs|.
Bonded interactions between QM and MM atoms are described at the MM
level by the appropriate force-field terms. All bonds,
consisting of 2 QM atoms, angles and settles containing 2 or 3 QM atoms, 
dihedrals containing 3 or 4 QM atoms are excluded from the forcefield
evaluation. Broken chemical bonds between QM and MM subsystems needs to be capped
in the QM calculation. This is done within CP2K by adding a hydrogen atom to 
complete the valence of the QM region. The force on this atom, which is present 
in the QM region only, is distributed over the two atoms of the bond. 
The cap atom is usually referred to as a link atom. Within the interface 
all described topology modifications are performed automatically during :ref:`gmx grompp` pre-processing.

Software prerequisites
^^^^^^^^^^^^^^^^^^^^^^

CP2K version 8.1 (or later) should be linked into |Gromacs| as libcp2k.
For a specific installation instructions please follow the :ref:`installing with CP2K` guide.

Limitations in simulation techniques
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The QM/MM interface limits simulations in two ways.
First, no topology modifications are possible during the simulations in the QM region.
Second, interface completely ignores "B" state parameters in the topology, making
double topology setups impossible, e.g. free-energy perturbation simulations (:ref:`dgimplement`).

In addition it should be noted that the contribution of forces from QM/MM to the system 
virial are not accounted for. The size of the effect on the pressure-coupling algorithm 
grows with the total summed force due to QM-MM interactions and might produce artifacts 
in simulations with the NPT ensemble.

Usage
^^^^^

QM/MM simulations with CP2K interface are controlled by setting :ref:`mdp` file options and,
in some cases, providing an additional input file for :ref:`gmx grompp` with the ``-qmi``
command-line option. All options that are related to QM/MM simulations with CP2K 
are prefixed with ``qmmm-cp2k``.

Setting :mdp-value:`qmmm-cp2k-active=true` will trigger a QM/MM simulation using the whole
system as QM part and default parameters for all other options.

Choosing atoms for QM calculation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The QM part of your system is chosen with a name that corresponds to an atom group
in the index file of |Gromacs| to the :mdp:`qmmm-cp2k-qmgroup` option in :ref:`mdp` file.
The typical QM part should consist of atoms that are interesting from the chemical point of view,
i.e. part of the system where reaction happens. To make computation of the
QM part feasible, it should be small and
as compact as possible in a space. DFT simulations often scale as 3rd order of 
the number of atoms in the QM part. This means increasing number of atoms in the QM part 
by a factor of 2 will slow down the simulation by a factor of 8.

In addition user should provide total charge of your QM subsystem with
:mdp:`qmmm-cp2k-qmcharge` option and spin-state (multiplicity) with :mdp:`qmmm-cp2k-qmmultiplicity`
option.

Supported QM methods
^^^^^^^^^^^^^^^^^^^^

The QM method is chosen with :mdp:`qmmm-cp2k-qmmethod` in the :ref:`mdp` file.
Currently the following QM methods are supported:

#. :mdp-value:`qmmm-cp2k-qmmethod=PBE` - DFT using PBE functional and DZVP-MOLOPT basis set.
#. :mdp-value:`qmmm-cp2k-qmmethod=BLYP` - DFT using BLYP functional and DZVP-MOLOPT basis set.

That list will be updated with a new methods once they are tested and included into the
interface.

Providing your own CP2K input file
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In addition it is possible to use custom external CP2K input file with 
:mdp-value:`qmmm-cp2k-qmmethod=INPUT` and providing file with 
:ref:`gmx grompp` with ``-qmi`` option. The external file will be incorporated into the
:ref:`tpr` file of the simulation and are subject to the following restrictions:

#. ``RUN_TYPE`` option in the CP2K input should be equal to ``ENERGY_FORCE``.
#. ``CHARGE`` option should be present.
#. ``MULTIPILICTY`` option should be present.
#. ``COORD_FILE_NAME`` option should be present pointing towards :ref:`pdb` file. 
#. Both ``CHARGE_EXTENDED TRUE`` and ``COORD_FILE_FORMAT PDB`` options should be present.
#. Incremental includes (``@INCLUDE`` directive) are not allowed in the CP2K input file . 

Changing names of CP2K files
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

During :ref:`gmx mdrun` simulation additional files will be produced with ``.inp``, ``.out`` and
``.pdb``. They contain CP2K input, CP2K output and :ref:`pdb` file with point charges of MM atoms
in the extended beta field. By default all CP2K related files names will be deduced from :ref:`tpr` 
simulation file name by adding ``_cp2k`` suffix. In order to change it manually 
:mdp:`qmmm-cp2k-qmfilenames` option should be used.

Output
^^^^^^

The energy output file will contain an additional "Quantum En." term.
This is the energy that is added to the system from the QM/MM interactions.
In addition, a file containing CP2K output will appear in the simulation directory 
with the ``.out`` extension.

Future developments
^^^^^^^^^^^^^^^^^^^

support of additional DFT methods will be added in the future, as well as semi-empirical and 
DFTB description of the QM subsystem will be allowed. Support of the multiple 
time-stepping approach to speed-up simulation will be added. Excited state simulations
will be implemented with TD-DFT description of the wavefunction.
Stochastic Dynamics
-------------------

Stochastic or velocity Langevin dynamics adds a friction and a noise
term to Newton’s equations of motion, as

.. math::  m_i {{\mbox{d}}^2 \mathbf{r}_i \over {\mbox{d}}t^2} =
   - m_i \gamma_i {{\mbox{d}}\mathbf{r}_i \over {\mbox{d}}t} + \mathbf{F}_i(\mathbf{r}) + {\stackrel{\circ}{\mathbf{r}}}_i,
   :label: eqnSDeq

where :math:`\gamma_i` is the friction constant :math:`[1/\mbox{ps}]`
and :math:`{\stackrel{\circ}{\mathbf{r}}}_i\!\!(t)` is a
noise process with
:math:`\langle {\stackrel{\circ}{r}}_i\!\!(t) {\stackrel{\circ}{r}}_j\!\!(t+s) \rangle = 2 m_i \gamma_i k_B T \delta(s) \delta_{ij}`. When :math:`1/\gamma_i`
is large compared to the time scales present in the system, one could
see stochastic dynamics as molecular dynamics with stochastic
temperature-coupling. But any processes that take longer than
:math:`1/\gamma_i`, e.g. hydrodynamics, will be dampened. Since each
degree of freedom is coupled independently to a heat bath, equilibration
of fast modes occurs rapidly. For simulating a system in vacuum there is
the additional advantage that there is no accumulation of errors for the
overall translational and rotational degrees of freedom. When
:math:`1/\gamma_i` is small compared to the time scales present in the
system, the dynamics will be completely different from MD, but the
sampling is still correct.

In |Gromacs| there is one simple and efficient implementation. Its
accuracy is equivalent to the normal MD leap-frog and Velocity Verlet
integrator. It is nearly identical to the common way of discretizing the
Langevin equation, but the friction and velocity term are applied in an
impulse fashion \ :ref:`51 <refGoga2012>`. It can be described as:

.. math::  \begin{aligned}
   \mathbf{v}'  &~=~&   \mathbf{v}(t-{{\frac{1}{2}}{{\Delta t}}}) + \frac{1}{m}\mathbf{F}(t){{\Delta t}}\\
   \Delta\mathbf{v}     &~=~&   -\alpha \, \mathbf{v}'(t+{{\frac{1}{2}}{{\Delta t}}}) + \sqrt{\frac{k_B T}{m}(1 - \alpha^2)} \, {\mathbf{r}^G}_i \\
   \mathbf{r}(t+{{\Delta t}})   &~=~&   \mathbf{r}(t)+\left(\mathbf{v}' +\frac{1}{2}\Delta \mathbf{v}\right){{\Delta t}}
  \end{aligned}
  :label: eqnsd1int

.. math:: \begin{aligned}
   \mathbf{v}(t+{{\frac{1}{2}}{{\Delta t}}})  &~=~&   \mathbf{v}' + \Delta \mathbf{v} \\
   \alpha &~=~& 1 - e^{-\gamma {{\Delta t}}}\end{aligned}
   :label: eqnsd1xupd

where :math:`{\mathbf{r}^G}_i` is Gaussian distributed
noise with :math:`\mu = 0`, :math:`\sigma = 1`. The velocity is first
updated a full time step without friction and noise to get
:math:`\mathbf{v}'`, identical to the normal update in
leap-frog. The friction and noise are then applied as an impulse at step
:math:`t+{{\Delta t}}`. The advantage of this scheme is that the
velocity-dependent terms act at the full time step, which makes the
correct integration of forces that depend on both coordinates and
velocities, such as constraints and dissipative particle dynamics (DPD,
not implented yet), straightforward. With constraints, the coordinate
update :eq:`eqn. %s <eqnsd1xupd>` is split into a normal leap-frog update
and a :math:`\Delta \mathbf{v}`. After both of these
updates the constraints are applied to coordinates and velocities.

When using SD as a thermostat, an appropriate value for :math:`\gamma`
is e.g. 0.5 ps\ :math:`^{-1}`, since this results in a friction that is
lower than the internal friction of water, while it still provides
efficient thermostatting.
Normal-Mode Analysis
--------------------

Normal-mode analysis \ :ref:`54 <refLevitt83>`\ :ref:`56 <refBBrooks83b>`
can be performed using |Gromacs|, by diagonalization of the
mass-weighted Hessian :math:`H`:

.. math:: \begin{aligned}
          R^T M^{-1/2} H M^{-1/2} R   &=& \mbox{diag}(\lambda_1,\ldots,\lambda_{3N})
          \\
          \lambda_i &=& (2 \pi \omega_i)^2\end{aligned}
          :label: eqnNMA

where :math:`M` contains the atomic masses, :math:`R` is a matrix that
contains the eigenvectors as columns, :math:`\lambda_i` are the
eigenvalues and :math:`\omega_i` are the corresponding frequencies.

First the Hessian matrix, which is a :math:`3N \times 3N` matrix where
:math:`N` is the number of atoms, needs to be calculated:

.. math:: \begin{aligned}
          H_{ij}  &=&     \frac{\partial^2 V}{\partial x_i \partial x_j}\end{aligned}
          :label: eqnNMAhessian

where :math:`x_i` and :math:`x_j` denote the atomic x, y or z
coordinates. In practice, this equation is not used, but the Hessian is
calculated numerically from the force as:

.. math:: \begin{aligned}
          H_{ij} &=& -
            \frac{f_i({\bf x}+h{\bf e}_j) - f_i({\bf x}-h{\bf e}_j)}{2h}
          \\
          f_i     &=& - \frac{\partial V}{\partial x_i}\end{aligned}
          :label: eqnNMAhessianfromforce

where :math:`{\bf e}_j` is the unit vector in direction :math:`j`. It
should be noted that for a usual normal-mode calculation, it is
necessary to completely minimize the energy prior to computation of the
Hessian. The tolerance required depends on the type of system, but a
rough indication is 0.001 kJ mol\ :math:`^{-1}`. Minimization should be
done with conjugate gradients or L-BFGS in double precision.

A number of |Gromacs| programs are involved in these calculations. First,
the energy should be minimized using :ref:`mdrun <gmx mdrun>`. Then,
:ref:`mdrun <gmx mdrun>` computes the Hessian. **Note** that for generating
the run input file, one should use the minimized conformation from the
full precision trajectory file, as the structure file is not accurate
enough. :ref:`gmx nmeig` does the
diagonalization and the sorting of the normal modes according to their
frequencies. Both :ref:`mdrun <gmx mdrun>` and :ref:`gmx nmeig` should be run in double precision.
The normal modes can be analyzed with the program :ref:`gmx anaeig`. Ensembles
of structures at any temperature and for any subset of normal modes can
be generated with :ref:`gmx nmens`. An overview of normal-mode analysis and the
related principal component analysis (see sec. :ref:`covanal`) can be
found in \ :ref:`57 <refHayward95b>`.
Replica exchange
----------------

Replica exchange molecular dynamics (REMD) is a method that can be used
to speed up the sampling of any type of simulation, especially if
conformations are separated by relatively high energy barriers. It
involves simulating multiple replicas of the same system at different
temperatures and randomly exchanging the complete state of two replicas
at regular intervals with the probability:

.. math:: P(1 \leftrightarrow 2)=\min\left(1,\exp\left[
          \left(\frac{1}{k_B T_1} - \frac{1}{k_B T_2}\right)(U_1 - U_2)
          \right] \right)
          :label: eqnREX

where :math:`T_1` and :math:`T_2` are the reference temperatures and
:math:`U_1` and :math:`U_2` are the instantaneous potential energies of
replicas 1 and 2 respectively. After exchange the velocities are scaled
by :math:`(T_1/T_2)^{\pm0.5}` and a neighbor search is performed the
next step. This combines the fast sampling and frequent barrier-crossing
of the highest temperature with correct Boltzmann sampling at all the
different temperatures \ :ref:`60 <refHukushima96a>`,
:ref:`61 <refSugita99>`. We only attempt exchanges for neighboring temperatures as the
probability decreases very rapidly with the temperature difference. One
should not attempt exchanges for all possible pairs in one step. If, for
instance, replicas 1 and 2 would exchange, the chance of exchange for
replicas 2 and 3 not only depends on the energies of replicas 2 and 3,
but also on the energy of replica 1. In |Gromacs| this is solved by
attempting exchange for all *odd* pairs on *odd* attempts and for all
*even* pairs on *even* attempts. If we have four replicas: 0, 1, 2 and
3, ordered in temperature and we attempt exchange every 1000 steps,
pairs 0-1 and 2-3 will be tried at steps 1000, 3000 etc. and pair 1-2 at
steps 2000, 4000 etc.

How should one choose the temperatures? The energy difference can be
written as:

.. math:: U_1 - U_2 =  N_{df} \frac{c}{2} k_B (T_1 - T_2)
          :label: eqnREXEdiff

where :math:`N_{df}` is the total number of degrees of freedom of one
replica and :math:`c` is 1 for harmonic potentials and around 2 for
protein/water systems. If :math:`T_2 = (1+\epsilon) T_1` the probability
becomes:

.. math:: P(1 \leftrightarrow 2)
            = \exp\left( -\frac{\epsilon^2 c\,N_{df}}{2 (1+\epsilon)} \right)
          \approx \exp\left(-\epsilon^2 \frac{c}{2} N_{df} \right)
          :label: eqnREXprob

Thus for a probability of :math:`e^{-2}\approx 0.135` one obtains
:math:`\epsilon \approx 2/\sqrt{c\,N_{df}}`. With all bonds constrained
one has :math:`N_{df} \approx 2\, N_{atoms}` and thus for :math:`c` = 2
one should choose :math:`\epsilon` as :math:`1/\sqrt{N_{atoms}}`.
However there is one problem when using pressure coupling. The density
at higher temperatures will decrease, leading to higher energy
\ :ref:`62 <refSeibert2005a>`, which should be taken into account. The |Gromacs| website
features a so-called ``REMD calculator``, that lets you type in the
temperature range and the number of atoms, and based on that proposes a
set of temperatures.

An extension to the REMD for the isobaric-isothermal ensemble was
proposed by Okabe et al. :ref:`63 <refOkabe2001a>`. In this work the
exchange probability is modified to:

.. math:: P(1 \leftrightarrow 2)=\min\left(1,\exp\left[
          \left(\frac{1}{k_B T_1} - \frac{1}{k_B T_2}\right)(U_1 - U_2) +
          \left(\frac{P_1}{k_B T_1} - \frac{P_2}{k_B T_2}\right)\left(V_1-V_2\right)
          \right] \right)
          :label: eqnREXexchangeprob

where :math:`P_1` and :math:`P_2` are the respective reference
pressures and :math:`V_1` and :math:`V_2` are the respective
instantaneous volumes in the simulations. In most cases the differences
in volume are so small that the second term is negligible. It only plays
a role when the difference between :math:`P_1` and :math:`P_2` is large
or in phase transitions.

Hamiltonian replica exchange is also supported in |Gromacs|. In
Hamiltonian replica exchange, each replica has a different Hamiltonian,
defined by the free energy pathway specified for the simulation. The
exchange probability to maintain the correct ensemble probabilities is:

.. math:: P(1 \leftrightarrow 2)=\min\left(1,\exp\left[
          \left(\frac{1}{k_B T_1} - \frac{1}{k_B T_2}\right)((U_1(x_2) - U_1(x_1)) + (U_2(x_1) - U_2(x_2)))
          \right]\right)
          :label: eqnREXcorrectensemble

The separate Hamiltonians are defined by the free energy functionality
of |Gromacs|, with swaps made between the different values of
:math:`\lambda` defined in the mdp file.

Hamiltonian and temperature replica exchange can also be performed
simultaneously, using the acceptance criteria:

.. math:: P(1 \leftrightarrow 2)=\min\left(1,\exp\left[
          \left(\frac{1}{k_B T_1} - \frac{1}{k_B T_2}\right)(\frac{U_1(x_2) - U_1(x_1)}{k_B T_1} + \frac{U_2(x_1) - U_2(x_2)}{k_B T_2})
          \right] \right)
          :label: eqnREXacceptance

Gibbs sampling replica exchange has also been implemented in
|Gromacs| :ref:`64 <refChodera2011>`. In Gibbs sampling replica exchange,
all possible pairs are tested for exchange, allowing swaps between
replicas that are not neighbors.

Gibbs sampling replica exchange requires no additional potential energy
calculations. However there is an additional communication cost in Gibbs
sampling replica exchange, as for some permutations, more than one round
of swaps must take place. In some cases, this extra communication cost
might affect the efficiency.

All replica exchange variants are options of the :ref:`mdrun <gmx mdrun>` program. It will
only work when MPI is installed, due to the inherent parallelism in the
algorithm. For efficiency each replica can run on a separate rank. See
the manual page of :ref:`mdrun <gmx mdrun>` on how to use these multinode features.
Brownian Dynamics
-----------------

In the limit of high friction, stochastic dynamics reduces to Brownian
dynamics, also called position Langevin dynamics. This applies to
over-damped systems, *i.e.* systems in which the inertia effects are
negligible. The equation is

.. math:: {{\mbox{d}}\mathbf{r}_i \over {\mbox{d}}t} = \frac{1}{\gamma_i} \mathbf{F}_i(\mathbf{r}) + {\stackrel{\circ}{\mathbf{r}}}_i
          :label: eqnbrowniandyn

where :math:`\gamma_i` is the friction coefficient
:math:`[\mbox{amu/ps}]` and
:math:`{\stackrel{\circ}{\mathbf{r}}}_i\!\!(t)` is a noise
process with
:math:`\langle {\stackrel{\circ}{r}}_i\!\!(t) {\stackrel{\circ}{r}}_j\!\!(t+s) \rangle = 2 \delta(s) \delta_{ij} k_B T / \gamma_i`.
In |Gromacs| the equations are integrated with a simple, explicit scheme

.. math:: \mathbf{r}_i(t+\Delta t) = \mathbf{r}_i(t) +
          {\Delta t \over \gamma_i} \mathbf{F}_i(\mathbf{r}(t)) 
          + \sqrt{2 k_B T {\Delta t \over \gamma_i}}\, {\mathbf{r}^G}_i,
          :label: eqnbrowniandynint

where :math:`{\mathbf{r}^G}_i` is Gaussian distributed
noise with :math:`\mu = 0`, :math:`\sigma = 1`. The friction
coefficients :math:`\gamma_i` can be chosen the same for all particles
or as :math:`\gamma_i = m_i\,\gamma_i`, where the friction constants
:math:`\gamma_i` can be different for different groups of atoms. Because
the system is assumed to be over-damped, large timesteps can be used.
LINCS should be used for the constraints since SHAKE will not converge
for large atomic displacements. BD is an option of the :ref:`mdrun <gmx mdrun>` program.
Simulated Annealing
-------------------

The well known simulated annealing (SA) protocol is supported in
|Gromacs|, and you can even couple multiple groups of atoms separately
with an arbitrary number of reference temperatures that change during
the simulation. The annealing is implemented by simply changing the
current reference temperature for each group in the temperature
coupling, so the actual relaxation and coupling properties depends on
the type of thermostat you use and how hard you are coupling it. Since
we are changing the reference temperature it is important to remember
that the system will NOT instantaneously reach this value - you need to
allow for the inherent relaxation time in the coupling algorithm too. If
you are changing the annealing reference temperature faster than the
temperature relaxation you will probably end up with a crash when the
difference becomes too large.

The annealing protocol is specified as a series of corresponding times
and reference temperatures for each group, and you can also choose
whether you only want a single sequence (after which the temperature
will be coupled to the last reference value), or if the annealing should
be periodic and restart at the first reference point once the sequence
is completed. You can mix and match both types of annealing and
non-annealed groups in your simulation.
.. _fecalc:

Free energy calculations
------------------------

Slow-growth methods
~~~~~~~~~~~~~~~~~~~

Free energy calculations can be performed in |Gromacs| using a number of
methods, including “slow-growth.” An example problem might be
calculating the difference in free energy of binding of an inhibitor
**I** to an enzyme **E** and to a mutated enzyme
**E**\ :math:`^{\prime}`. It is not feasible with computer simulations
to perform a docking calculation for such a large complex, or even
releasing the inhibitor from the enzyme in a reasonable amount of
computer time with reasonable accuracy. However, if we consider the free
energy cycle in :numref:`Fig. %s A<fig-free1>` we can write:

.. math:: \Delta G_1 - \Delta G_2 =       \Delta G_3 - \Delta G_4
   :label: eqnddg

If we are interested in the left-hand term we can equally well compute
the right-hand term.

.. _fig-free1:

.. figure:: plots/free1.*
            :width: 6.00000cm

            Free energy cycles. **A:** to calculate :math:`\Delta G_{12}`, the free
            energy difference between the binding of inhibitor **I** to enzymes
            **E** respectively **E**\ :math:`^{\prime}`. 

.. _fig-free2:

.. figure:: plots/free2.*
            :width: 6.00000cm

            Free energy cycles. **B:** to calculate
            :math:`\Delta G_{12}`, the free energy difference for binding of
            inhibitors **I** respectively **I**\ :math:`^{\prime}` to enzyme
            **E**.

If we want to compute the difference in free energy of binding of two
inhibitors **I** and **I**\ :math:`^{\prime}` to an enzyme **E**
(:numref:`Fig. %s <fig-free2>`) we can again use
:eq:`eqn. %s <eqnddg>` to compute the desired property.

Free energy differences between two molecular species can be calculated
in |Gromacs| using the “slow-growth” method. Such free energy differences
between different molecular species are physically meaningless, but they
can be used to obtain meaningful quantities employing a thermodynamic
cycle. The method requires a simulation during which the Hamiltonian of
the system changes slowly from that describing one system (A) to that
describing the other system (B). The change must be so slow that the
system remains in equilibrium during the process; if that requirement is
fulfilled, the change is reversible and a slow-growth simulation from B
to A will yield the same results (but with a different sign) as a
slow-growth simulation from A to B. This is a useful check, but the user
should be aware of the danger that equality of forward and backward
growth results does not guarantee correctness of the results.

The required modification of the Hamiltonian :math:`H` is realized by
making :math:`H` a function of a *coupling parameter* :math:`\lambda:
H=H(p,q;\lambda)` in such a way that :math:`\lambda=0` describes system
A and :math:`\lambda=1` describes system B:

.. math:: H(p,q;0)=H{^{\mathrm{A}}}(p,q);~~~~ H(p,q;1)=H{^{\mathrm{B}}}(p,q).
          :label: eqnddgHamiltonian

In |Gromacs|, the functional form of the :math:`\lambda`-dependence is
different for the various force-field contributions and is described in
section sec. :ref:`feia`.

The Helmholtz free energy :math:`A` is related to the partition function
:math:`Q` of an :math:`N,V,T` ensemble, which is assumed to be the
equilibrium ensemble generated by a MD simulation at constant volume and
temperature. The generally more useful Gibbs free energy :math:`G` is
related to the partition function :math:`\Delta` of an :math:`N,p,T`
ensemble, which is assumed to be the equilibrium ensemble generated by a
MD simulation at constant pressure and temperature:

.. math:: \begin{aligned}
           A(\lambda) &=&  -k_BT \ln Q \\
           Q &=& c \int\!\!\int \exp[-\beta H(p,q;\lambda)]\,dp\,dq \\
           G(\lambda) &=&  -k_BT \ln \Delta \\
           \Delta &=& c \int\!\!\int\!\!\int \exp[-\beta H(p,q;\lambda) -\beta
          pV]\,dp\,dq\,dV \\
          G &=& A + pV, \end{aligned}
          :label: eqnddgGibs

where :math:`\beta = 1/(k_BT)` and :math:`c = (N! h^{3N})^{-1}`. These
integrals over phase space cannot be evaluated from a simulation, but it
is possible to evaluate the derivative with respect to :math:`\lambda`
as an ensemble average:

.. math:: \frac{dA}{d\lambda} =  \frac{\int\!\!\int (\partial H/ \partial
          \lambda) \exp[-\beta H(p,q;\lambda)]\,dp\,dq}{\int\!\!\int \exp[-\beta
          H(p,q;\lambda)]\,dp\,dq} = 
          \left\langle \frac{\partial H}{\partial \lambda} \right\rangle_{NVT;\lambda},
          :label: eqnddgensembleave

with a similar relation for :math:`dG/d\lambda` in the :math:`N,p,T`
ensemble. The difference in free energy between A and B can be found by
integrating the derivative over :math:`\lambda`:

.. math::  \begin{aligned}
           A{^{\mathrm{B}}}(V,T)-A{^{\mathrm{A}}}(V,T) &=& \int_0^1 \left\langle \frac{\partial
           H}{\partial \lambda} \right\rangle_{NVT;\lambda} \,d\lambda 
           \end{aligned}
           :label: eqdelA

.. math:: \begin{aligned}
          G{^{\mathrm{B}}}(p,T)-G{^{\mathrm{A}}}(p,T) &=& \int_0^1 \left\langle \frac{\partial
          H}{\partial \lambda} \right\rangle_{NpT;\lambda} \,d\lambda.
          \end{aligned}
          :label: eqdelG

If one wishes to evaluate
:math:`G{^{\mathrm{B}}}(p,T)-G{^{\mathrm{A}}}(p,T)`, the natural choice
is a constant-pressure simulation. However, this quantity can also be
obtained from a slow-growth simulation at constant volume, starting with
system A at pressure :math:`p` and volume :math:`V` and ending with
system B at pressure :math:`p_B`, by applying the following small (but,
in principle, exact) correction:

.. math:: G{^{\mathrm{B}}}(p)-G{^{\mathrm{A}}}(p) =
          A{^{\mathrm{B}}}(V)-A{^{\mathrm{A}}}(V) - \int_p^{p{^{\mathrm{B}}}}[V{^{\mathrm{B}}}(p')-V]\,dp'
          :label: eqnddgpresscorr

Here we omitted the constant :math:`T` from the notation. This
correction is roughly equal to
:math:`-\frac{1}{2} (p{^{\mathrm{B}}}-p)\Delta V=(\Delta V)^2/(2
\kappa V)`, where :math:`\Delta V` is the volume change at :math:`p` and
:math:`\kappa` is the isothermal compressibility. This is usually small;
for example, the growth of a water molecule from nothing in a bath of
1000 water molecules at constant volume would produce an additional
pressure of as much as 22 bar, but a correction to the Helmholtz free
energy of just -1 kJ mol\ :math:`^{-1}`. In Cartesian coordinates, the
kinetic energy term in the Hamiltonian depends only on the momenta, and
can be separately integrated and, in fact, removed from the equations.
When masses do not change, there is no contribution from the kinetic
energy at all; otherwise the integrated contribution to the free energy
is :math:`-\frac{3}{2} k_BT \ln
(m{^{\mathrm{B}}}/m{^{\mathrm{A}}})`. **Note** that this is only true in
the absence of constraints.

Thermodynamic integration
~~~~~~~~~~~~~~~~~~~~~~~~~

|Gromacs| offers the possibility to integrate :eq:`eq. %s <eqdelA>` or eq.
:eq:`%s <eqdelG>` in one simulation over the full range from A to B. However, if
the change is large and insufficient sampling can be expected, the user
may prefer to determine the value of :math:`\langle
dG/d\lambda \rangle` accurately at a number of well-chosen intermediate
values of :math:`\lambda`. This can easily be done by setting the
stepsize ``delta_lambda`` to zero. Each simulation can be equilibrated
first, and a proper error estimate can be made for each value of
:math:`dG/d\lambda` from the fluctuation of :math:`\partial H/\partial
\lambda`. The total free energy change is then determined afterward by
an appropriate numerical integration procedure.

|Gromacs| now also supports the use of Bennett’s Acceptance Ratio
\ :ref:`58 <refBennett1976>` for calculating values of :math:`\Delta`\ G for transformations
from state A to state B using the program :ref:`gmx bar`. The same data can
also be used to calculate free energies using MBAR \ :ref:`59 <refShirts2008>`,
though the analysis currently requires external tools from the
external `pymbar package <https://SimTK.org/home/pymbar>`_.

The :math:`\lambda`-dependence for the force-field contributions is
described in detail in section sec. :ref:`feia`.
.. _groupconcept:

The group concept
-----------------

The |Gromacs| MD and analysis programs use user-defined *groups* of atoms
to perform certain actions on. The maximum number of groups is 256, but
each atom can only belong to six different groups, one each of the
following:

temperature-coupling group
    The temperature coupling parameters (reference temperature, time
    constant, number of degrees of freedom, see :ref:`update`) can be
    defined for each T-coupling group separately. For example, in a
    solvated macromolecule the solvent (that tends to generate more
    heating by force and integration errors) can be coupled with a
    shorter time constant to a bath than is a macromolecule, or a
    surface can be kept cooler than an adsorbing molecule. Many
    different T-coupling groups may be defined. See also center of mass
    groups below.

freeze group

    Atoms that belong to a freeze group are kept stationary in the
    dynamics. This is useful during equilibration, *e.g.* to avoid badly
    placed solvent molecules giving unreasonable kicks to protein atoms,
    although the same effect can also be obtained by putting a
    restraining potential on the atoms that must be protected. The
    freeze option can be used, if desired, on just one or two
    coordinates of an atom, thereby freezing the atoms in a plane or on
    a line. When an atom is partially frozen, constraints will still be
    able to move it, even in a frozen direction. A fully frozen atom can
    not be moved by constraints. Many freeze groups can be defined.
    Frozen coordinates are unaffected by pressure scaling; in some cases
    this can produce unwanted results, particularly when constraints are
    also used (in this case you will get very large pressures).
    Accordingly, it is recommended to avoid combining freeze groups with
    constraints and pressure coupling. For the sake of equilibration it
    could suffice to start with freezing in a constant volume
    simulation, and afterward use position restraints in conjunction
    with constant pressure.

accelerate group

    On each atom in an “accelerate group” an acceleration
    :math:`\mathbf{a}^g` is imposed. This is equivalent to
    a mass-weighted external force. This feature makes it possible to
    drive the system into a non-equilibrium state to compute,
    for example, transport properties.

energy-monitor group

    Mutual interactions between all energy-monitor groups are compiled
    during the simulation. This is done separately for Lennard-Jones and
    Coulomb terms. In principle up to 256 groups could be defined, but
    that would lead to 256\ :math:`\times`\ 256 items! Better use this
    concept sparingly.

    All non-bonded interactions between pairs of energy-monitor groups
    can be excluded (see details in the User Guide). Pairs of particles
    from excluded pairs of energy-monitor groups are not put into the
    pair list. This can result in a significant speedup for simulations
    where interactions within or between parts of the system are not
    required.

center of mass group

    In |Gromacs|, the center of mass (COM) motion can be removed, for
    either the complete system or for groups of atoms. The latter is
    useful, *e.g.* for systems where there is limited friction (*e.g.*
    gas systems) to prevent center of mass motion to occur. It makes
    sense to use the same groups for temperature coupling and center of
    mass motion removal.

Compressed position output group

    In order to further reduce the size of the compressed trajectory
    file (:ref:`xtc` or :ref:`tng`), it is possible to
    store only a subset of all particles. All x-compression groups that
    are specified are saved, the rest are not. If no such groups are
    specified, than all atoms are saved to the compressed trajectory
    file.

The use of groups in |Gromacs| tools is described in
sec. :ref:`usinggroups`.
.. _em:

Energy Minimization
-------------------

Energy minimization in |Gromacs| can be done using steepest descent,
conjugate gradients, or l-bfgs (limited-memory
Broyden-Fletcher-Goldfarb-Shanno quasi-Newtonian minimizer...we prefer
the abbreviation). EM is just an option of the :ref:`mdrun <gmx mdrun>` program.

Steepest Descent
~~~~~~~~~~~~~~~~

Although steepest descent is certainly not the most efficient algorithm
for searching, it is robust and easy to implement.

We define the vector :math:`\mathbf{r}` as the vector of
all :math:`3N` coordinates. Initially a maximum displacement :math:`h_0`
(*e.g.* 0.01 nm) must be given.

First the forces :math:`\mathbf{F}` and potential energy
are calculated. New positions are calculated by

  .. math:: \mathbf{r}_{n+1} =  \mathbf{r}_n + \frac{\mathbf{F}_n}{\max (|\mathbf{F}_n|)} h_n,
            :label: eqnEMpos

where :math:`h_n` is the maximum displacement and
:math:`\mathbf{F}_n` is the force, or the negative
gradient of the potential :math:`V`. The notation :math:`\max
(|\mathbf{F}_n|)` means the largest scalar force on any
atom. The forces and energy are again computed for the new positions

| If (:math:`V_{n+1} < V_n`) the new positions are accepted and
  :math:`h_{n+1} = 1.2
  h_n`.
| If (:math:`V_{n+1} \geq V_n`) the new positions are rejected and
  :math:`h_n = 0.2 h_n`.

The algorithm stops when either a user-specified number of force
evaluations has been performed (*e.g.* 100), or when the maximum of the
absolute values of the force (gradient) components is smaller than a
specified value :math:`\epsilon`. Since force truncation produces some
noise in the energy evaluation, the stopping criterion should not be
made too tight to avoid endless iterations. A reasonable value for
:math:`\epsilon` can be estimated from the root mean square force
:math:`f` a harmonic oscillator would exhibit at a temperature
:math:`T`. This value is

.. math:: f = 2 \pi \nu \sqrt{ 2mkT},
          :label: eqnEMharmosc

where :math:`\nu` is the oscillator frequency, :math:`m` the (reduced)
mass, and :math:`k` Boltzmann’s constant. For a weak oscillator with a
wave number of 100 cm\ :math:`^{-1}` and a mass of 10 atomic units, at a
temperature of 1 K, :math:`f=7.7` kJ mol\ :math:`^{-1}` nm\ :math:`^{-1}`.
A value for :math:`\epsilon` between 1 and 10 is acceptable.

Conjugate Gradient
~~~~~~~~~~~~~~~~~~

Conjugate gradient is slower than steepest descent in the early stages
of the minimization, but becomes more efficient closer to the energy
minimum. The parameters and stop criterion are the same as for steepest
descent. In |Gromacs| conjugate gradient can not be used with constraints,
including the SETTLE algorithm for water \ :ref:`47 <refMiyamoto92>`, as
this has not been implemented. If water is present it must be of a
flexible model, which can be specified in the :ref:`mdp` file
by ``define = -DFLEXIBLE``.

This is not really a restriction, since the accuracy of conjugate
gradient is only required for minimization prior to a normal-mode
analysis, which cannot be performed with constraints. For most other
purposes steepest descent is efficient enough.

L-BFGS
~~~~~~

The original BFGS algorithm works by successively creating better
approximations of the inverse Hessian matrix, and moving the system to
the currently estimated minimum. The memory requirements for this are
proportional to the square of the number of particles, so it is not
practical for large systems like biomolecules. Instead, we use the
L-BFGS algorithm of Nocedal  \ :ref:`52 <refByrd95a>`,
:ref:`53 <refZhu97a>`, which approximates the inverse Hessian by a fixed number
of corrections from previous steps. This sliding-window technique is
almost as efficient as the original method, but the memory requirements
are much lower - proportional to the number of particles multiplied with
the correction steps. In practice we have found it to converge faster
than conjugate gradients, but due to the correction steps it is not yet
parallelized. It is also noteworthy that switched or shifted
interactions usually improve the convergence, since sharp cut-offs mean
the potential function at the current coordinates is slightly different
from the previous steps used to build the inverse Hessian approximation.
Essential Dynamics sampling
---------------------------

The results from Essential Dynamics (see sec. :ref:`covanal`) of a
protein can be used to guide MD simulations. The idea is that from an
initial MD simulation (or from other sources) a definition of the
collective fluctuations with largest amplitude is obtained. The position
along one or more of these collective modes can be constrained in a
(second) MD simulation in a number of ways for several purposes. For
example, the position along a certain mode may be kept fixed to monitor
the average force (free-energy gradient) on that coordinate in that
position. Another application is to enhance sampling efficiency with
respect to usual MD :ref:`65 <refDegroot96a>`, :ref:`66 <refDegroot96b>`.
In this case, the system is
encouraged to sample its available configuration space more
systematically than in a diffusion-like path that proteins usually take.

Another possibility to enhance sampling is flooding. Here a flooding
potential is added to certain (collective) degrees of freedom to expel
the system out of a region of phase space :ref:`67 <refLange2006a>`.

The procedure for essential dynamics sampling or flooding is as follows.
First, the eigenvectors and eigenvalues need to be determined using
covariance analysis (:ref:`gmx covar`) or normal-mode analysis (:ref:`gmx nmeig`).
Then, this information is fed into :ref:`make_edi <gmx make_edi>`, which has many options for
selecting vectors and setting parameters, see ``gmx make_edi -h``. The
generated :ref:`edi` input file is then passed to :ref:`mdrun <gmx mdrun>`.
Shell molecular dynamics
------------------------

|Gromacs| can simulate polarizability using the shell model of Dick and
Overhauser \ :ref:`43 <refDick58>`. In such models a shell particle
representing the electronic degrees of freedom is attached to a nucleus
by a spring. The potential energy is minimized with respect to the shell
position at every step of the simulation (see below). Successful
applications of shell models in |Gromacs| have been published for
:math:`N_2` :ref:`44 <refJordan95>` and water\ :ref:`45 <refMaaren2001a>`.

Optimization of the shell positions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The force :math:`\mathbf{F}`\ :math:`_S` on a shell
particle :math:`S` can be decomposed into two components

.. math:: \mathbf{F}_S ~=~ \mathbf{F}_{bond} + \mathbf{F}_{nb}
          :label: eqnshellforcedecomp

where :math:`\mathbf{F}_{bond}` denotes the
component representing the polarization energy, usually represented by a
harmonic potential and :math:`\mathbf{F}_{nb}` is the sum of Coulomb
and van der Waals interactions. If we assume that
:math:`\mathbf{F}_{nb}` is almost constant we
can analytically derive the optimal position of the shell, i.e. where
:math:`\mathbf{F}_S` = 0. If we have the shell S connected to atom A we have

.. math:: \mathbf{F}_{bond} ~=~ k_b \left( \mathbf{x}_S - \mathbf{x}_A\right).
          :label: eqnshell

In an iterative solver, we have positions :math:`\mathbf{x}_S(n)` where :math:`n` is
the iteration count. We now have at iteration :math:`n`

.. math:: \mathbf{F}_{nb} ~=~ \mathbf{F}_S - k_b \left( \mathbf{x}_S(n) - \mathbf{x}_A\right)
          :label: eqnshellsolv

and the optimal position for the shells :math:`x_S(n+1)` thus follows from

.. math:: \mathbf{F}_S - k_b \left( \mathbf{x}_S(n) - \mathbf{x}_A\right) + k_b \left( \mathbf{x}_S(n+1) - \mathbf{x}_A\right) = 0
          :label: eqnshelloptpos

if we write

.. math:: \Delta \mathbf{x}_S = \mathbf{x}_S(n+1) - \mathbf{x}_S(n)
          :label: eqnshelloptpos2

we finally obtain

.. math:: \Delta \mathbf{x}_S = \mathbf{F}_S/k_b
          :label: eqnshelloptpos3

which then yields the algorithm to compute the next trial in the
optimization of shell positions

.. math:: \mathbf{x}_S(n+1) ~=~ \mathbf{x}_S(n) + \mathbf{F}_S/k_b.
          :label: eqnshelloptpos4

.. _pbc:

Periodic boundary conditions
----------------------------

.. _fig-pbc:

.. figure:: plots/pbctric.*
   :width: 9.00000cm

   Periodic boundary conditions in two dimensions.

The classical way to minimize edge effects in a finite system is to
apply *periodic boundary conditions*. The atoms of the system to be
simulated are put into a space-filling box, which is surrounded by
translated copies of itself (:numref:`Fig. %s <fig-pbc>`). Thus
there are no boundaries of the system; the artifact caused by unwanted
boundaries in an isolated cluster is now replaced by the artifact of
periodic conditions. If the system is crystalline, such boundary
conditions are desired (although motions are naturally restricted to
periodic motions with wavelengths fitting into the box). If one wishes
to simulate non-periodic systems, such as liquids or solutions, the
periodicity by itself causes errors. The errors can be evaluated by
comparing various system sizes; they are expected to be less severe than
the errors resulting from an unnatural boundary with vacuum.

There are several possible shapes for space-filling unit cells. Some,
like the *rhombic dodecahedron* and the *truncated octahedron* :ref:`20 <refAdams79>` are closer to being a sphere than a cube is, and
are therefore better suited to the study of an approximately spherical
macromolecule in solution, since fewer solvent molecules are required to
fill the box given a minimum distance between macromolecular images. At
the same time, rhombic dodecahedra and truncated octahedra are special
cases of *triclinic* unit cells; the most general space-filling unit
cells that comprise all possible space-filling shapes \ :ref:`21 <refBekker95>`.
For this reason, |Gromacs| is based on the triclinic unit cell.

|Gromacs| uses periodic boundary conditions, combined with the 
*minimum image convention*: only one – the nearest – image of each particle is
considered for short-range non-bonded interaction terms. For long-range
electrostatic interactions this is not always accurate enough, and
|Gromacs| therefore also incorporates lattice sum methods such as Ewald
Sum, PME and PPPM.

|Gromacs| supports triclinic boxes of any shape. The simulation box (unit
cell) is defined by the 3 box vectors :math:`{\bf a}`,\ :math:`{\bf b}`
and :math:`{\bf c}`. The box vectors must satisfy the following
conditions:

.. math:: a_y = a_z = b_z = 0
          :label: eqnboxrot

.. math:: a_x>0,~~~~b_y>0,~~~~c_z>0
          :label: eqnboxshift

.. math:: |b_x| \leq \frac{1}{2} \, a_x,~~~~
          |c_x| \leq \frac{1}{2} \, a_x,~~~~
          |c_y| \leq \frac{1}{2} \, b_y
          :label: eqnboxshift2

Equations :eq:`%s <eqnboxrot>` can always be satisfied by
rotating the box. Inequalities (:eq:`%s <eqnboxshift>`) and
(:eq:`%s <eqnboxshift2>`) can always be satisfied by adding
and subtracting box vectors.

Even when simulating using a triclinic box, |Gromacs| always keeps the
particles in a brick-shaped volume for efficiency, as illustrated in
:numref:`Fig. %s <fig-pbc>` for a 2-dimensional system. Therefore,
from the output trajectory it might seem that the simulation was done in
a rectangular box. The program :ref:`trjconv <gmx trjconv>` can be used to
convert the trajectory to a different unit-cell representation.

It is also possible to simulate without periodic boundary conditions,
but it is usually more efficient to simulate an isolated cluster of
molecules in a large periodic box, since fast grid searching can only be
used in a periodic system.

.. _fig-boxshapes:

.. figure:: plots/rhododec.*
        :width: 5.00000cm

        A rhombic dodecahedron (arbitrary orientation).


.. figure:: plots/truncoct.*
        :width: 5.00000cm

        A truncated octahedron (arbitrary orientation).

Some useful box types
~~~~~~~~~~~~~~~~~~~~~

.. |mathd| replace:: :math:`d`
.. |mathd3| replace:: :math:`d^{3}`
.. |mathd23| replace:: :math:`\frac{1}{2}\sqrt{2}~d^{3}`
.. |mathd70| replace:: :math:`0.707~d^{3}`
.. |mathd43| replace:: :math:`\frac{4}{9}\sqrt{3}~d^{3}`
.. |mathd77| replace:: :math:`0.770~d^{3}`
.. |math12d| replace:: :math:`\frac{1}{2}~d`
.. |math13d| replace:: :math:`\frac{1}{3}~d`
.. |math13dn| replace:: :math:`-\frac{1}{3}~d`
.. |math12s2| replace:: :math:`\frac{1}{2}\sqrt{2}~d`
.. |math12s3| replace:: :math:`\frac{1}{2}\sqrt{3}~d`
.. |math16s3| replace:: :math:`\frac{1}{6}\sqrt{3}~d`
.. |math13s6| replace:: :math:`\frac{1}{3}\sqrt{6}~d`
.. |math23s2| replace:: :math:`\frac{2}{3}\sqrt{2}~d`
.. |math13s2| replace:: :math:`\frac{1}{3}\sqrt{2}~d`
.. |angbc| replace:: :math:`\angle` **bc** 
.. |angac| replace:: :math:`\angle` **ac** 
.. |angab| replace:: :math:`\angle` **ab** 
.. |90deg| replace:: :math:`90^\circ`
.. |60deg| replace:: :math:`60^\circ`
.. |71deg| replace:: :math:`71.53^\circ`
.. |109deg| replace:: :math:`109.47^\circ`

.. _table-boxtypes:

.. table:: Overview over different box types
    :align: center
    :widths: auto

    +-------------+-----------+-----------+-----------------------------------+------------------------------+
    | box type    | image     | box       | box vectors                       | box vector angles            | 
    |             |           |           +---------+------------+------------+---------+----------+---------+
    |             | distance  | volume    | **a**   | **b**      | **c**      | |angbc| | |angac|  | |angab| |
    +=============+===========+===========+=========+============+============+=========+==========+=========+
    |             |           |           | |mathd| |   0        |   0        |         |          |         |
    |             |           |           +---------+------------+------------+         |          |         |
    | cubic       | |mathd|   | |mathd3|  |   0     | |mathd|    |   0        | |90deg| | |90deg|  | |90deg| |
    |             |           |           +---------+------------+------------+         |          |         |
    |             |           |           |   0     |   0        | |mathd|    |         |          |         |
    +-------------+-----------+-----------+---------+------------+------------+---------+----------+---------+
    | rhombic     |           | |mathd23| | |mathd| | 0          | |math12d|  |         |          |         |
    |             |           |           +---------+------------+------------+         |          |         |
    | dodcahdron  | |mathd|   | |mathd70| | 0       | |mathd|    | |math12d|  | |60deg| | |60deg|  | |60deg| |
    |             |           |           +---------+------------+------------+         |          |         |
    | (xy-square) |           |           | 0       | 0          | |math12s2| |         |          |         |
    +-------------+-----------+-----------+---------+------------+------------+---------+----------+---------+
    | rhombic     |           | |mathd23| | |mathd| | |math12d|  | |math12d|  |         |          |         |
    |             |           |           +---------+------------+------------+         |          |         |
    | dodcahdron  | |mathd|   | |mathd70| | 0       | |math12s3| | |math16s3| | |60deg| | |60deg|  | |60deg| |
    |             |           |           +---------+------------+------------+         |          |         |
    | (xy-        |           |           | 0       | 0          | |math13s6| |         |          |         |
    | hexagon)    |           |           |         |            |            |         |          |         |
    +-------------+-----------+-----------+---------+------------+------------+---------+----------+---------+
    | truncated   |           | |mathd43| | |mathd| | |math13d|  | |math13dn| |         |          |         |
    |             |           |           +---------+------------+------------+         |          |         |
    | octahedron  | |mathd|   | |mathd77| | 0       | |math23s2| | |math13s2| | |71deg| | |109deg| | |71deg| |
    |             |           |           +---------+------------+------------+         |          |         |
    |             |           |           | 0       | 0          | |math13s6| |         |          |         |
    +-------------+-----------+-----------+---------+------------+------------+---------+----------+---------+

The three most useful box types for simulations of solvated systems are
described in :numref:`Table %s <table-boxtypes>`. The rhombic
dodecahedron (:numref:`Fig. %s <fig-boxshapes>`) is the smallest and
most regular space-filling unit cell. Each of the 12 image cells is at
the same distance. The volume is 71% of the volume of a cube having the
same image distance. This saves about 29% of CPU-time when simulating a
spherical or flexible molecule in solvent. There are two different
orientations of a rhombic dodecahedron that satisfy equations
:eq:`%s <eqnboxrot>`, :eq:`%s <eqnboxshift>` and
:eq:`%s <eqnboxshift2>`. The program :ref:`editconf <gmx editconf>`
produces the orientation which has a square intersection with the
xy-plane. This orientation was chosen because the first two box vectors
coincide with the x and y-axis, which is easier to comprehend. The other
orientation can be useful for simulations of membrane proteins. In this
case the cross-section with the xy-plane is a hexagon, which has an area
which is 14% smaller than the area of a square with the same image
distance. The height of the box (:math:`c_z`) should be changed to
obtain an optimal spacing. This box shape not only saves CPU time, it
also results in a more uniform arrangement of the proteins.

Cut-off restrictions
~~~~~~~~~~~~~~~~~~~~

The minimum image convention implies that the cut-off radius used to
truncate non-bonded interactions may not exceed half the shortest box
vector:

.. math:: R_c < {\frac{1}{2}}\min(\|{\bf a}\|,\|{\bf b}\|,\|{\bf c}\|),
          :label: eqnphysicalrc

because otherwise more than one image would be within the cut-off
distance of the force. When a macromolecule, such as a protein, is
studied in solution, this restriction alone is not sufficient: in
principle, a single solvent molecule should not be able to ‘see’ both
sides of the macromolecule. This means that the length of each box
vector must exceed the length of the macromolecule in the direction of
that edge *plus* two times the cut-off radius :math:`R_c`. It is,
however, common to compromise in this respect, and make the solvent
layer somewhat smaller in order to reduce the computational cost. For
efficiency reasons the cut-off with triclinic boxes is more restricted.
For grid search the extra restriction is weak:

.. math:: R_c < \min(a_x,b_y,c_z)
         :label: eqngridrc
   

For simple search the extra restriction is stronger:

.. math:: R_c < {\frac{1}{2}}\min(a_x,b_y,c_z)
          :label: eqnsimplerc

Each unit cell (cubic, rectangular or triclinic) is surrounded by 26
translated images. A particular image can therefore always be identified
by an index pointing to one of 27 *translation vectors* and constructed
by applying a translation with the indexed vector (see :ref:`forces`).
Restriction :eq:`%s <eqngridrc>` ensures that only 26 images need to be
considered.
Constraint algorithms
---------------------

Constraints can be imposed in |Gromacs| using LINCS (default) or the
traditional SHAKE method.


.. _shake:

SHAKE
~~~~~

The SHAKE \ :ref:`46 <refRyckaert77>` algorithm changes a
set of unconstrained coordinates :math:`\mathbf{r}^{'}` to
a set of coordinates :math:`\mathbf{r}''` that fulfill a
list of distance constraints, using a set :math:`\mathbf{r}` reference, as

.. math:: {\rm SHAKE}(\mathbf{r}^{'} \rightarrow \mathbf{r}'';\, \mathbf{r})
          :label: eqnshakebase

This action is consistent with solving a set of Lagrange multipliers in
the constrained equations of motion. SHAKE needs a *relative tolerance*;
it will continue until all constraints are satisfied within that
relative tolerance. An error message is given if SHAKE cannot reset the
coordinates because the deviation is too large, or if a given number of
iterations is surpassed.

Assume the equations of motion must fulfill :math:`K` holonomic
constraints, expressed as

.. math:: \sigma_k(\mathbf{r}_1 \ldots \mathbf{r}_N) = 0; \;\; k=1 \ldots K.
          :label: eqnshakemotconstr

For example, :math:`(\mathbf{r}_1 - \mathbf{r}_2)^2 - b^2 = 0`.
Then the forces are defined as

.. math:: - \frac{\partial}{\partial \mathbf{r}_i} \left( V + \sum_{k=1}^K \lambda_k
          \sigma_k \right),
          :label: eqnshakeforce

where :math:`\lambda_k` are Lagrange multipliers which must be solved
to fulfill the constraint equations. The second part of this sum
determines the *constraint forces* :math:`\mathbf{G}_i`, defined by

.. math:: \mathbf{G}_i = -\sum_{k=1}^K \lambda_k \frac{\partial \sigma_k}{\partial
          \mathbf{r}_i}
          :label: eqnshakeconstrforces

The displacement due to the constraint forces in the leap-frog or
Verlet algorithm is equal to :math:`(\mathbf{G}_i/m_i)({{\Delta t}})^2`. Solving the
Lagrange multipliers (and hence the displacements) requires the solution
of a set of coupled equations of the second degree. These are solved
iteratively by SHAKE. :ref:`settle` 

.. _settle:

SETTLE
~~~~~~

For the special case of rigid
water molecules, that often make up more than 80% of the simulation
system we have implemented the SETTLE algorithm \ :ref:`47 <refMiyamoto92>`
(sec. :ref:`constraintalg`). The implementation of SETTLE in |Gromacs|
is a slight modification of the original algorithm, in that it completely
avoids the calculation of the center of mass of the water molecule.
Apart from saving a few operations, the main gain of this is a reduction
in rouding errors. For large coordinates, the floating pointing precision of constrained
distances is reduced, which leads to an energy drift which usually depends
quadratically on the coordinate. For SETTLE this dependence is now linear, which enables
accurate integration of systems in single precision up to 1000 nm in size.
But note that the drift due to SHAKE and LINCS still has a quadratic
dependence, which limits the size of systems with normal constraints
in single precision to 100 to 200 nm.

For velocity Verlet, an additional round of constraining must be done,
to constrain the velocities of the second velocity half step, removing
any component of the velocity parallel to the bond vector. This step is
called RATTLE, and is covered in more detail in the original Andersen
paper \ :ref:`48 <refAndersen1983a>`.

LINCS
~~~~~

.. _lincs:

The LINCS algorithm
^^^^^^^^^^^^^^^^^^^

LINCS is an algorithm that resets bonds to their correct lengths after
an unconstrained update \ :ref:`49 <refHess97>`. The method is non-iterative,
as it always uses two steps. Although LINCS is based on matrices, no
matrix-matrix multiplications are needed. The method is more stable and
faster than SHAKE, but it can only be used with bond constraints and
isolated angle constraints, such as the proton angle in OH. Because of
its stability, LINCS is especially useful for Brownian dynamics. LINCS
has two parameters, which are explained in the subsection parameters.
The parallel version of LINCS, P-LINCS, is described in subsection
:ref:`plincs`.

The LINCS formulas
^^^^^^^^^^^^^^^^^^

We consider a system of :math:`N` particles, with positions given by a
:math:`3N` vector :math:`\mathbf{r}(t)`. For molecular
dynamics the equations of motion are given by Newton’s Law

.. math:: {{\mbox{d}}^2 \mathbf{r} \over {\mbox{d}}t^2} = {{\mathbf{M}}^{-1}}\mathbf{F},
          :label: eqnc1

where :math:`\mathbf{F}` is the :math:`3N` force vector
and :math:`{\mathbf{M}}` is a :math:`3N \times 3N`
diagonal matrix, containing the masses of the particles. The system is
constrained by :math:`K` time-independent constraint equations

.. math:: g_i(\mathbf{r}) = | \mathbf{r}_{i_1}-\mathbf{r}_{i_2} | - d_i = 0 ~~~~~~i=1,\ldots,K.
          :label: eqnc2

In a numerical integration scheme, LINCS is applied after an
unconstrained update, just like SHAKE. The algorithm works in two steps
(see figure :numref:`Fig. %s <fig-lincs>`). In the first step, the
projections of the new bonds on the old bonds are set to zero. In the
second step, a correction is applied for the lengthening of the bonds
due to rotation. The numerics for the first step and the second step are
very similar. A complete derivation of the algorithm can be found in
:ref:`49 <refHess97>`. Only a short description of the first step is given
here.

.. _fig-lincs:

.. figure:: plots/lincs.*
   :height: 5.00000cm

   The three position updates needed for one time step. The dashed
   line is the old bond of length :math:`d`, the solid lines are the new
   bonds. :math:`l=d \cos \theta` and :math:`p=(2 d^2 - l^2)^{1 \over 2}`.

A new notation is introduced for the gradient matrix of the constraint
equations which appears on the right hand side of this equation:

.. math::  B_{hi} = {{\partial}g_h \over {\partial}r_i}
           :label: eqnc3

Notice that :math:`{\mathbf{B}}` is a :math:`K \times 3N`
matrix, it contains the directions of the constraints. The following
equation shows how the new constrained coordinates
:math:`\mathbf{r}_{n+1}` are related to the unconstrained
coordinates :math:`\mathbf{r}_{n+1}^{unc}` by

.. math::  \begin{array}{c}
           \mathbf{r}_{n+1}=(\mathbf{I}-\mathbf{T}_n \mathbf{B}_n) \mathbf{r}_{n+1}^{unc} + {\mathbf{T}}_n \mathbf{d}=  
           \\[2mm]
           \mathbf{r}_{n+1}^{unc} - 
           {{\mathbf{M}}^{-1}}\mathbf{B}_n ({\mathbf{B}}_n {{\mathbf{M}}^{-1}}{\mathbf{B}}_n^T)^{-1} ({\mathbf{B}}_n \mathbf{r}_{n+1}^{unc} - \mathbf{d}) 
           \end{array}
           :label: eqnm0

where

.. math:: {\mathbf{T}}= {{\mathbf{M}}^{-1}}{\mathbf{B}}^T ({\mathbf{B}}{{\mathbf{M}}^{-1}}{\mathbf{B}}^T)^{-1}
          :label: eqnnm01

The derivation of this equation from :eq:`eqns. %s <eqnc1>` and
:eq:`%s <eqnc2>` can be found in :ref:`49 <refHess97>`.

This first step does not set the real bond lengths to the prescribed
lengths, but the projection of the new bonds onto the old directions of
the bonds. To correct for the rotation of bond :math:`i`, the projection
of the bond, :math:`p_i`, on the old direction is set to

.. math::  p_i=\sqrt{2 d_i^2 - l_i^2},
           :label: eqnm1a

where :math:`l_i` is the bond length after the first projection. The
corrected positions are

.. math::  \mathbf{r}_{n+1}^*=(\mathbf{I}-\mathbf{T}_n \mathbf{B}_n)\mathbf{r}_{n+1} + {\mathbf{T}}_n \mathbf{p}.
           :label: eqnm1b

This correction for rotational effects is actually an iterative
process, but during MD only one iteration is applied. The relative
constraint deviation after this procedure will be less than 0.0001 for
every constraint. In energy minimization, this might not be accurate
enough, so the number of iterations is equal to the order of the
expansion (see below).

Half of the CPU time goes to inverting the constraint coupling matrix
:math:`{\mathbf{B}}_n {{\mathbf{M}}^{-1}}{\mathbf{B}}_n^T`,
which has to be done every time step. This :math:`K \times K` matrix has
:math:`1/m_{i_1} + 1/m_{i_2}` on the diagonal. The off-diagonal elements
are only non-zero when two bonds are connected, then the element is
:math:`\cos \phi /m_c`, where :math:`m_c` is the mass of the atom
connecting the two bonds and :math:`\phi` is the angle between the
bonds.

The matrix :math:`\mathbf{T}` is inverted through a power
expansion. A :math:`K \times K` matrix :math:`\mathbf{S}`
is introduced which is the inverse square root of the diagonal of
:math:`\mathbf{B}_n {{\mathbf{M}}^{-1}}{\mathbf{B}}_n^T`.
This matrix is used to convert the diagonal elements of the coupling
matrix to one:

.. math:: \begin{array}{c}
          ({\mathbf{B}}_n {{\mathbf{M}}^{-1}}{\mathbf{B}}_n^T)^{-1}
          = {\mathbf{S}}{\mathbf{S}}^{-1} ({\mathbf{B}}_n {{\mathbf{M}}^{-1}}{\mathbf{B}}_n^T)^{-1} {\mathbf{S}}^{-1} {\mathbf{S}}\\[2mm]
          = {\mathbf{S}}({\mathbf{S}}{\mathbf{B}}_n {{\mathbf{M}}^{-1}}{\mathbf{B}}_n^T {\mathbf{S}})^{-1} {\mathbf{S}}=
          {\mathbf{S}}(\mathbf{I} - \mathbf{A}_n)^{-1} {\mathbf{S}}\end{array}
          :label: eqnm2

The matrix :math:`\mathbf{A}_n` is symmetric and sparse
and has zeros on the diagonal. Thus a simple trick can be used to
calculate the inverse:

.. math:: (\mathbf{I}-\mathbf{A}_n)^{-1}= 
          \mathbf{I} + \mathbf{A}_n + \mathbf{A}_n^2 + \mathbf{A}_n^3 + \ldots
          :label: eqnm3

This inversion method is only valid if the absolute values of all the
eigenvalues of :math:`\mathbf{A}_n` are smaller than one.
In molecules with only bond constraints, the connectivity is so low that
this will always be true, even if ring structures are present. Problems
can arise in angle-constrained molecules. By constraining angles with
additional distance constraints, multiple small ring structures are
introduced. This gives a high connectivity, leading to large
eigenvalues. Therefore LINCS should NOT be used with coupled
angle-constraints.

For molecules with all bonds constrained the eigenvalues of :math:`A`
are around 0.4. This means that with each additional order in the
expansion :eq:`eqn. %s <eqnm3>` the deviations decrease by a factor 0.4. But for
relatively isolated triangles of constraints the largest eigenvalue is
around 0.7. Such triangles can occur when removing hydrogen angle
vibrations with an additional angle constraint in alcohol groups or when
constraining water molecules with LINCS, for instance with flexible
constraints. The constraints in such triangles converge twice as slow as
the other constraints. Therefore, starting with |Gromacs| 4, additional
terms are added to the expansion for such triangles

.. math:: (\mathbf{I}-\mathbf{A}_n)^{-1} \approx
          \mathbf{I} + \mathbf{A}_n + \ldots + \mathbf{A}_n^{N_i} +
          \left(\mathbf{A}^*_n + \ldots + {\mathbf{A}_n^*}^{N_i} \right) \mathbf{A}_n^{N_i}
          :label: eqnm3ang

where :math:`N_i` is the normal order of the expansion and
:math:`\mathbf{A}^*` only contains the elements of
:math:`\mathbf{A}` that couple constraints within rigid
triangles, all other elements are zero. In this manner, the accuracy of
angle constraints comes close to that of the other constraints, while
the series of matrix vector multiplications required for determining the
expansion only needs to be extended for a few constraint couplings. This
procedure is described in the P-LINCS paper\ :ref:`50 <refHess2008a>`.

The LINCS Parameters
^^^^^^^^^^^^^^^^^^^^

The accuracy of LINCS depends on the number of matrices used in the
expansion :eq:`eqn. %s <eqnm3>`. For MD calculations a fourth order expansion is
enough. For Brownian dynamics with large time steps an eighth order
expansion may be necessary. The order is a parameter in the :ref:`mdp` file.
The implementation of LINCS is done in such a way that the algorithm
will never crash. Even when it is impossible to to reset the constraints
LINCS will generate a conformation which fulfills the constraints as
well as possible. However, LINCS will generate a warning when in one
step a bond rotates over more than a predefined angle. This angle is set
by the user in the :ref:`mdp` file.
Expanded Ensemble
-----------------

In an expanded ensemble simulation \ :ref:`68 <refLyubartsev1992>`, both the
coordinates and the thermodynamic ensemble are treated as configuration
variables that can be sampled over. The probability of any given state
can be written as:

.. math:: P(\vec{x},k) \propto \exp\left(-\beta_k U_k + g_k\right),
          :label: eqnexpandensemble

where :math:`\beta_k = \frac{1}{k_B T_k}` is the :math:`\beta`
corresponding to the :math:`k`\ th thermodynamic state, and :math:`g_k`
is a user-specified weight factor corresponding to the :math:`k`\ th
state. This space is therefore a *mixed*, *generalized*, or *expanded*
ensemble which samples from multiple thermodynamic ensembles
simultaneously. :math:`g_k` is chosen to give a specific weighting of
each subensemble in the expanded ensemble, and can either be fixed, or
determined by an iterative procedure. The set of :math:`g_k` is
frequently chosen to give each thermodynamic ensemble equal probability,
in which case :math:`g_k` is equal to the free energy in non-dimensional
units, but they can be set to arbitrary values as desired. Several
different algorithms can be used to equilibrate these weights, described
in the mdp option listings.

In |Gromacs|, this space is sampled by alternating sampling in the
:math:`k` and :math:`\vec{x}` directions. Sampling in the
:math:`\vec{x}` direction is done by standard molecular dynamics
sampling; sampling between the different thermodynamics states is done
by Monte Carlo, with several different Monte Carlo moves supported. The
:math:`k` states can be defined by different temperatures, or choices of
the free energy :math:`\lambda` variable, or both. Expanded ensemble
simulations thus represent a serialization of the replica exchange
formalism, allowing a single simulation to explore many thermodynamic
states.
.. _md:

Molecular Dynamics
------------------

.. _gmx-md-scheme:

**THE GLOBAL MD ALGORITHM**

--------------

| 
| **1. Input initial conditions**
| Potential interaction :math:`V` as a function of atom positions
| Positions :math:`\mathbf{r}` of all atoms in the system
| Velocities :math:`\mathbf{v}` of all atoms in the system
| :math:`\Downarrow`

--------------

| 
| **repeat 2,3,4** for the required number of steps:

--------------

| 
| **2. Compute forces**
| The force on any atom
| :math:`\mathbf{F}_i = - \displaystyle\frac{\partial V}{\partial \mathbf{r}_i}`
| is computed by calculating the force between non-bonded atom pairs:
| :math:`\mathbf{F}_i = \sum_j \mathbf{F}_{ij}`
| plus the forces due to bonded interactions (which may depend on 1, 2,
  3, or 4 atoms), plus restraining and/or external forces.
| The potential and kinetic energies and the pressure tensor may be
  computed.
| :math:`\Downarrow`
| **3. Update configuration**
| The movement of the atoms is simulated by numerically solving Newton’s
  equations of motion
| :math:`\displaystyle \frac {{\mbox{d}}^2\mathbf{r}_i}{{\mbox{d}}t^2} = \frac{\mathbf{F}_i}{m_i}`
| or
| :math:`\displaystyle   \frac{{\mbox{d}}\mathbf{r}_i}{{\mbox{d}}t} = \mathbf{v}_i ; \;\;   \frac{{\mbox{d}}\mathbf{v}_i}{{\mbox{d}}t} = \frac{\mathbf{F}_i}{m_i}` 
| :math:`\Downarrow`
| **4.** if required: **Output step**
| write positions, velocities, energies, temperature, pressure, etc.

A global flow scheme for MD is given above.
Each MD or EM run requires as input
a set of initial coordinates and – optionally – initial velocities of
all particles involved. This chapter does not describe how these are
obtained; for the setup of an actual MD run check the :ref:`user guide`
in Sections :ref:`gmx-sysprep` and :ref:`gmx-getting-started`.

Initial conditions
~~~~~~~~~~~~~~~~~~

Topology and force field
^^^^^^^^^^^^^^^^^^^^^^^^

The system topology, including a description of the force field, must be
read in. Force fields and topologies are described in chapter :ref:`ff`
and :ref:`top`, respectively. All this information is static; it is never
modified during the run.

Coordinates and velocities
^^^^^^^^^^^^^^^^^^^^^^^^^^

.. _fig-maxwell:

.. figure:: plots/maxwell.*
   :width: 8.00000cm

   A Maxwell-Boltzmann velocity distribution, generated from
   random numbers.

Then, before a run starts, the box size and the coordinates and
velocities of all particles are required. The box size and shape is
determined by three vectors (nine numbers)
:math:`\mathbf{b}_1, \mathbf{b}_2, \mathbf{b}_3`,
which represent the three basis vectors of the periodic box.

If the run starts at :math:`t=t_0`, the coordinates at :math:`t=t_0`
must be known. The *leap-frog algorithm*, the default algorithm used to
update the time step with :math:`{{\Delta t}}` (see :ref:`update`),
also requires that the velocities at
:math:`t=t_0 - {{\frac{1}{2}}{{\Delta t}}}` are known. If velocities are
not available, the program can generate initial atomic velocities
:math:`v_i, i=1\ldots 3N` with a Maxwell-Boltzmann distribution
(:numref:`Fig. %s <fig-maxwell>`) at a given absolute temperature
:math:`T`:

.. math:: p(v_i) = \sqrt{\frac{m_i}{2 \pi kT}}\exp\left(-\frac{m_i v_i^2}{2kT}\right)
          :label: eqnmaxwellboltzman

where :math:`k` is Boltzmann’s constant (see chapter :ref:`defunits`). To
accomplish this, normally distributed random numbers are generated by
adding twelve random numbers :math:`R_k` in the range
:math:`0 \le R_k < 1` and subtracting 6.0 from their sum. The result is
then multiplied by the standard deviation of the velocity distribution
:math:`\sqrt{kT/m_i}`. Since the resulting total energy will not
correspond exactly to the required temperature :math:`T`, a correction
is made: first the center-of-mass motion is removed and then all
velocities are scaled so that the total energy corresponds exactly to
:math:`T` (see :eq:`eqn. %s <eqnET>`).

Center-of-mass motion
^^^^^^^^^^^^^^^^^^^^^

The center-of-mass velocity is normally set to zero at every step; there
is (usually) no net external force acting on the system and the
center-of-mass velocity should remain constant. In practice, however,
the update algorithm introduces a very slow change in the center-of-mass
velocity, and therefore in the total kinetic energy of the system –
especially when temperature coupling is used. If such changes are not
quenched, an appreciable center-of-mass motion can develop in long runs,
and the temperature will be significantly misinterpreted. Something
similar may happen due to overall rotational motion, but only when an
isolated cluster is simulated. In periodic systems with filled boxes,
the overall rotational motion is coupled to other degrees of freedom and
does not cause such problems.

Neighbor searching
~~~~~~~~~~~~~~~~~~

As mentioned in chapter :ref:`ff`, internal forces are either generated
from fixed (static) lists, or from dynamic lists. The latter consist of
non-bonded interactions between any pair of particles. When calculating
the non-bonded forces, it is convenient to have all particles in a
rectangular box. As shown in :numref:`Fig. %s <fig-pbc>`, it is possible to transform
a triclinic box into a rectangular box. The output coordinates are
always in a rectangular box, even when a dodecahedron or triclinic box
was used for the simulation. :eq:`Equation %s <eqnboxrot>` ensures that we can
reset particles in a rectangular box by first shifting them with box
vector :math:`{\bf c}`, then with :math:`{\bf b}` and finally with
:math:`{\bf a}`. Equations :eq:`%s <eqnboxshift2>`,
:eq:`%s <eqnphysicalrc>` and :eq:`%s <eqngridrc>`
ensure that we can find the 14 nearest triclinic images within a linear
combination that does not involve multiples of box vectors.

Pair lists generation
^^^^^^^^^^^^^^^^^^^^^

The non-bonded pair forces need to be calculated only for those pairs
:math:`i,j` for which the distance :math:`r_{ij}` between :math:`i` and
the nearest image of :math:`j` is less than a given cut-off radius
:math:`R_c`. Some of the particle pairs that fulfill this criterion are
excluded, when their interaction is already fully accounted for by
bonded interactions. But for most electrostatic treatments, correction
forces also need to be computed for such excluded atom pairs.
|Gromacs| employs a *pair list* that contains those
particle pairs for which non-bonded forces must be calculated. The pair
list contains particles :math:`i`, a displacement vector for particle
:math:`i`, and all particles :math:`j` that are within ``rlist`` of this
particular image of particle :math:`i`. The list is updated every
``nstlist`` steps.

To make the pair list, all atom pairs that are within the pair list
cut-off distance need to be found and stored in a list. Note that
such a list generally does not store all neighbors for each atom,
since each atom pair should appear only once in the list. This
searching, usually called neighbor search (NS) or pair search, involves
periodic boundary conditions and determining the *image* (see
sec. :ref:`pbc`). The search algorithm employed in |Gromacs| is :math:`O(N)`.

As pair searching is an expensive operation, a generated pair list
is retained for a certain number of integration steps.
A buffer is needed to account for relative displacements
of atoms over the steps where a fixed pair list is retained.
|Gromacs| uses a buffered pair list by default. It also
uses clusters of particles, but these are not static as in the old charge group
scheme. Rather, the clusters are defined spatially and consist of 4 or 8
particles, which is convenient for stream computing, using e.g. SSE, AVX
or CUDA on GPUs. At neighbor search steps, a pair list is created with a
Verlet buffer, i.e. the pair-list cut-off is larger than the interaction
cut-off. In the non-bonded kernels, interactions are only computed when
a particle pair is within the cut-off distance at that particular time
step. This ensures that as particles move between pair search steps,
forces between nearly all particles within the cut-off distance are
calculated. We say *nearly* all particles, because |Gromacs| uses a fixed
pair list update frequency for efficiency. A particle-pair, whose
distance was outside the cut-off, could possibly move enough during this
fixed number of steps that its distance is now within the cut-off. This
small chance results in a small energy drift, and the size of the chance
depends on the temperature. When temperature coupling is used, the
buffer size can be determined automatically, given a certain tolerance
on the energy drift. The default tolerance is 0.005 kJ/mol/ns per
particle, but in practice the energy drift is usually an order of
magnitude smaller. Note that in single precision for normal atomistic
simulations constraints cause a drift somewhere around 0.0001 kJ/mol/ns
per particle, so it doesn't make sense to go much lower than that.

The pair list is implemented in a very efficient fashion
based on clusters of particles. The simplest example is a cluster size
of 4 particles. The pair list is then constructed based on cluster
pairs. The cluster-pair search is much faster searching based on
particle pairs, because :math:`4 \times 4 = 16` particle pairs are put
in the list at once. The non-bonded force calculation kernel can then
calculate many particle-pair interactions at once, which maps nicely to
SIMD or SIMT units on modern hardware, which can perform multiple
floating operations at once. These non-bonded kernels are much faster
than the kernels used in the group scheme for most types of systems,
particularly on newer hardware. For further information on algorithmic
and implementation details of the Verlet cut-off scheme and the NxM
kernels, as well as detailed performance analysis, please consult the
following article: :ref:`182 <refPallPairInteractions>`.

Additionally, when the list buffer is determined automatically as
described below, we also apply dynamic pair list pruning. The pair list
can be constructed infrequently, but that can lead to a lot of pairs in
the list that are outside the cut-off range for all or most of the life
time of this pair list. Such pairs can be pruned out by applying a
cluster-pair kernel that only determines which clusters are in range.
Because of the way the non-bonded data is regularized in |Gromacs|, this
kernel is an order of magnitude faster than the search and the
interaction kernel. On the GPU this pruning is overlapped with the
integration on the CPU, so it is free in most cases. Therefore we can
prune every 4-10 integration steps with little overhead and
significantly reduce the number of cluster pairs in the interaction
kernel. This procedure is applied automatically, unless the user set the
pair-list buffer size manually.

Energy drift and pair-list buffering
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For a canonical (NVT) ensemble, the average energy error caused by
diffusion of :math:`j` particles from outside the pair-list cut-off
:math:`r_\ell` to inside the interaction cut-off :math:`r_c` over the
lifetime of the list can be determined from the atomic displacements and
the shape of the potential at the cut-off. The displacement distribution
along one dimension for a freely moving particle with mass :math:`m`
over time :math:`t` at temperature :math:`T` is a Gaussian :math:`G(x)`
of zero mean and variance :math:`\sigma^2 = t^2 k_B T/m`. For the
distance between two particles, the variance changes to
:math:`\sigma^2 = \sigma_{12}^2 =
t^2 k_B T(1/m_1+1/m_2)`. Note that in practice particles usually
interact with (bump into) other particles over time :math:`t` and
therefore the real displacement distribution is much narrower. Given a
non-bonded interaction cut-off distance of :math:`r_c` and a pair-list
cut-off :math:`r_\ell=r_c+r_b` for :math:`r_b` the Verlet buffer size,
we can then write the average energy error after time :math:`t` for all
missing pair interactions between a single :math:`i` particle of type 1
surrounded by all :math:`j` particles that are of type 2 with number
density :math:`\rho_2`, when the inter-particle distance changes from
:math:`r_0` to :math:`r_t`, as:

.. math:: \langle \Delta V \rangle =
          \int_{0}^{r_c} \int_{r_\ell}^\infty 4 \pi r_0^2 \rho_2 V(r_t) G\!\left(\frac{r_t-r_0}{\sigma}\right) d r_0\, d r_t
          :label: eqnverletbufenergy

To evaluate this analytically, we need to make some approximations.
First we replace :math:`V(r_t)` by a Taylor expansion around
:math:`r_c`, then we can move the lower bound of the integral over
:math:`r_0` to :math:`-\infty` which will simplify the result:

.. math:: \begin{aligned}
          \langle \Delta V \rangle &\approx&
          \int_{-\infty}^{r_c} \int_{r_\ell}^\infty 4 \pi r_0^2 \rho_2 \Big[ V'(r_c) (r_t - r_c) +
          \nonumber\\
          & &
          \phantom{\int_{-\infty}^{r_c} \int_{r_\ell}^\infty 4 \pi r_0^2 \rho_2 \Big[}
          V''(r_c)\frac{1}{2}(r_t - r_c)^2 +
          \nonumber\\
          & &
          \phantom{\int_{-\infty}^{r_c} \int_{r_\ell}^\infty 4 \pi r_0^2 \rho_2 \Big[}
            V'''(r_c)\frac{1}{6}(r_t - r_c)^3 +
            \nonumber\\
          & &
          \phantom{\int_{-\infty}^{r_c} \int_{r_\ell}^\infty 4 \pi r_0^2 \rho_2 \Big[}
            O \! \left((r_t - r_c)^4 \right)\Big] G\!\left(\frac{r_t-r_0}{\sigma}\right) d r_0 \, d r_t\end{aligned}
          :label: eqnverletaylor

Replacing the factor :math:`r_0^2` by :math:`(r_\ell + \sigma)^2`,
which results in a slight overestimate, allows us to calculate the
integrals analytically:

.. math:: \begin{aligned}
          \langle \Delta V \rangle \!
          &\approx&
          4 \pi (r_\ell+\sigma)^2 \rho_2
          \int_{-\infty}^{r_c} \int_{r_\ell}^\infty \Big[ V'(r_c) (r_t - r_c) +
          \nonumber\\
          & &
          \phantom{4 \pi (r_\ell+\sigma)^2 \rho_2 \int_{-\infty}^{r_c} \int_{r_\ell}^\infty \Big[}
          V''(r_c)\frac{1}{2}(r_t - r_c)^2 +
          \nonumber\\
          & &
          \phantom{4 \pi (r_\ell+\sigma)^2 \rho_2 \int_{-\infty}^{r_c} \int_{r_\ell}^\infty \Big[}
          V'''(r_c)\frac{1}{6}(r_t - r_c)^3 \Big] G\!\left(\frac{r_t-r_0}{\sigma}\right)
          d r_0 \, d r_t\\
          &=&
          4 \pi (r_\ell+\sigma)^2 \rho_2 \bigg\{
          \frac{1}{2}V'(r_c)\left[r_b \sigma G\!\left(\frac{r_b}{\sigma}\right) - (r_b^2+\sigma^2)E\!\left(\frac{r_b}{\sigma}\right) \right] +
          \nonumber\\
          & &
          \phantom{4 \pi (r_\ell+\sigma)^2 \rho_2 \bigg\{ }
          \frac{1}{6}V''(r_c)\left[ \sigma(r_b^2+2\sigma^2) G\!\left(\frac{r_b}{\sigma}\right) - r_b(r_b^2+3\sigma^2 ) E\!\left(\frac{r_b}{\sigma}\right) \right] +
          \nonumber\\
          & &
          \phantom{4 \pi (r_\ell+\sigma)^2 \rho_2 \bigg\{ }
          \frac{1}{24}V'''(r_c)\bigg[ r_b\sigma(r_b^2+5\sigma^2) G\!\left(\frac{r_b}{\sigma}\right)
          \nonumber\\
          & &
          \phantom{4 \pi (r_\ell+\sigma)^2 \rho_2 \bigg\{ \frac{1}{24}V'''(r_c)\bigg[ }
           - (r_b^4+6r_b^2\sigma^2+3\sigma^4 ) E\!\left(\frac{r_b}{\sigma}\right) \bigg]
          \bigg\}\end{aligned}
          :label: eqnverletanalytical

where :math:`G(x)` is a Gaussian distribution with 0 mean and unit
variance and :math:`E(x)=\frac{1}{2}\mathrm{erfc}(x/\sqrt{2})`. We
always want to achieve small energy error, so :math:`\sigma` will be
small compared to both :math:`r_c` and :math:`r_\ell`, thus the
approximations in the equations above are good, since the Gaussian
distribution decays rapidly. The energy error needs to be averaged over
all particle pair types and weighted with the particle counts. In
|Gromacs| we don’t allow cancellation of error between pair types, so we
average the absolute values. To obtain the average energy error per unit
time, it needs to be divided by the neighbor-list life time
:math:`t = ({\tt nstlist} - 1)\times{\tt dt}`. The function can not be
inverted analytically, so we use bisection to obtain the buffer size
:math:`r_b` for a target drift. Again we note that in practice the error
we usually be much smaller than this estimate, as in the condensed phase
particle displacements will be much smaller than for freely moving
particles, which is the assumption used here.

When (bond) constraints are present, some particles will have fewer
degrees of freedom. This will reduce the energy errors. For simplicity,
we only consider one constraint per particle, the heaviest particle in
case a particle is involved in multiple constraints. This simplification
overestimates the displacement. The motion of a constrained particle is
a superposition of the 3D motion of the center of mass of both particles
and a 2D rotation around the center of mass. The displacement in an
arbitrary direction of a particle with 2 degrees of freedom is not
Gaussian, but rather follows the complementary error function:

.. math:: \frac{\sqrt{\pi}}{2\sqrt{2}\sigma}\,\mathrm{erfc}\left(\frac{|r|}{\sqrt{2}\,\sigma}\right)
          :label: eqn2Ddisp

where :math:`\sigma^2` is again :math:`t^2 k_B T/m`. This distribution
can no longer be integrated analytically to obtain the energy error. But
we can generate a tight upper bound using a scaled and shifted Gaussian
distribution (not shown). This Gaussian distribution can then be used to
calculate the energy error as described above. The rotation displacement
around the center of mass can not be more than the length of the arm. To
take this into account, we scale :math:`\sigma` in
:eq:`eqn. %s <eqn2Ddisp>` (details not presented here) to
obtain an overestimate of the real displacement. This latter effect
significantly reduces the buffer size for longer neighborlist lifetimes
in e.g. water, as constrained hydrogens are by far the fastest
particles, but they can not move further than 0.1 nm from the heavy atom
they are connected to.

There is one important implementation detail that reduces the energy
errors caused by the finite Verlet buffer list size. The derivation
above assumes a particle pair-list. However, the |Gromacs| implementation
uses a cluster pair-list for efficiency. The pair list consists of pairs
of clusters of 4 particles in most cases, also called a
:math:`4 \times 4` list, but the list can also be :math:`4 \times 8`
(GPU CUDA kernels and AVX 256-bit single precision kernels) or
:math:`4 \times 2` (SSE double-precision kernels). This means that the
pair-list is effectively much larger than the corresponding
:math:`1 \times 1` list. Thus slightly beyond the pair-list cut-off
there will still be a large fraction of particle pairs present in the
list. This fraction can be determined in a simulation and accurately
estimated under some reasonable assumptions. The fraction decreases with
increasing pair-list range, meaning that a smaller buffer can be used.
For typical all-atom simulations with a cut-off of 0.9 nm this fraction
is around 0.9, which gives a reduction in the energy errors of a factor
of 10. This reduction is taken into account during the automatic Verlet
buffer calculation and results in a smaller buffer size.

.. _fig-verletdrift:

.. figure:: plots/verlet-drift.*
   :width: 9.00000cm

   Energy drift per atom for an SPC/E water system at 300K with a
   time step of 2 fs and a pair-list update period of 10 steps
   (pair-list life time: 18 fs). PME was used with
   ``ewald-rtol`` set to 10\ :math:`^{-5}`; this parameter
   affects the shape of the potential at the cut-off. Error estimates
   due to finite Verlet buffer size are shown for a :math:`1 \times 1`
   atom pair list and :math:`4 \times 4` atom pair list without and with
   (dashed line) cancellation of positive and negative errors. Real
   energy drift is shown for simulations using double- and
   mixed-precision settings. Rounding errors in the SETTLE constraint
   algorithm from the use of single precision causes the drift to become
   negative at large buffer size. Note that at zero buffer size, the
   real drift is small because positive (H-H) and negative (O-H) energy
   errors cancel.

In :numref:`Fig. %s <fig-verletdrift>` one can see that for small
buffer sizes the drift of the total energy is much smaller than the pair
energy error tolerance, due to cancellation of errors. For larger buffer
size, the error estimate is a factor of 6 higher than drift of the total
energy, or alternatively the buffer estimate is 0.024 nm too large. This
is because the protons don’t move freely over 18 fs, but rather vibrate.

Cut-off artifacts and switched interactions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

By default, the pair potentials are shifted to be zero at the cut-off,
which makes the potential the integral of the force. However, there can
still be energy drift when the forces are non-zero at the cut-off. This
effect is extremely small and often not noticeable, as other integration
errors (e.g. from constraints) may dominate. To completely avoid cut-off
artifacts, the non-bonded forces can be switched exactly to zero at some
distance smaller than the neighbor list cut-off (there are several ways
to do this in |Gromacs|, see sec. :ref:`modnbint`). One then has a
buffer with the size equal to the neighbor list cut-off less the longest
interaction cut-off.

Simple search
^^^^^^^^^^^^^

Due to :eq:`eqns. %s <eqnboxrot>` and
:eq:`%s <eqnsimplerc>`, the vector
:math:`{\mathbf{r}_{ij}}` connecting images within the
cut-off :math:`R_c` can be found by constructing:

.. math:: \begin{aligned}
          \mathbf{r}'''   & = & \mathbf{r}_j-\mathbf{r}_i \\
          \mathbf{r}''    & = & \mathbf{r}''' - \mathbf{c}*\mathrm{round}(r'''_z/c_z) \\
          \mathbf{r}'     & = & \mathbf{r}'' - \mathbf{b}*\mathrm{round}(r''_y/b_y) \\
          \mathbf{r}_{ij} & = & \mathbf{r}' - \mathbf{a}*\mathrm{round}(r'_x/a_x)
          \end{aligned}
          :label: eqnsearchvec

When distances between two particles in a triclinic box are needed that
do not obey :eq:`eqn. %s <eqnboxrot>`, many shifts of
combinations of box vectors need to be considered to find the nearest
image.

.. _fig-grid:

.. figure:: plots/nstric.*
   :width: 8.00000cm

   Grid search in two dimensions. The arrows are the box vectors.

Grid search
^^^^^^^^^^^

The grid search is schematically depicted in
:numref:`Fig. %s <fig-grid>`. All particles are put on the NS grid,
with the smallest spacing :math:`\ge` :math:`R_c/2` in each of the
directions. In the direction of each box vector, a particle :math:`i`
has three images. For each direction the image may be -1,0 or 1,
corresponding to a translation over -1, 0 or +1 box vector. We do not
search the surrounding NS grid cells for neighbors of :math:`i` and then
calculate the image, but rather construct the images first and then
search neighbors corresponding to that image of :math:`i`. As
:numref:`Fig. %s <fig-grid>` shows, some grid cells may be searched
more than once for different images of :math:`i`. This is not a problem,
since, due to the minimum image convention, at most one image will “see”
the :math:`j`-particle. For every particle, fewer than 125 (5\ :math:`^3`)
neighboring cells are searched. Therefore, the algorithm scales linearly
with the number of particles. Although the prefactor is large, the
scaling behavior makes the algorithm far superior over the standard
:math:`O(N^2)` algorithm when there are more than a few hundred
particles. The grid search is equally fast for rectangular and triclinic
boxes. Thus for most protein and peptide simulations the rhombic
dodecahedron will be the preferred box shape.

.. _chargegroup:

Charge groups
^^^^^^^^^^^^^

Charge groups were originally introduced to reduce cut-off artifacts of
Coulomb interactions. This concept has been superseded by exact atomistic
cut-off treatments. For historical reasons charge groups are still
defined in the atoms section for each moleculetype in the topology,
but they are no longer used.

.. _forces:

Compute forces
~~~~~~~~~~~~~~

Potential energy
^^^^^^^^^^^^^^^^

When forces are computed, the potential energy of each interaction term
is computed as well. The total potential energy is summed for various
contributions, such as Lennard-Jones, Coulomb, and bonded terms. It is
also possible to compute these contributions for *energy-monitor groups*
of atoms that are separately defined (see sec. :ref:`groupconcept`).

Kinetic energy and temperature
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The temperature is given by the total kinetic energy of the
:math:`N`-particle system:

.. math:: E_{kin} = {\frac{1}{2}}\sum_{i=1}^N m_i v_i^2
          :label: eqntempEkin

From this the absolute temperature :math:`T` can be computed using:

.. math::  {\frac{1}{2}}N_{\mathrm{df}} kT = E_{\mathrm{kin}}
           :label: eqnET

where :math:`k` is Boltzmann’s constant and :math:`N_{df}` is the
number of degrees of freedom which can be computed from:

.. math:: N_{\mathrm{df}}  ~=~     3 N - N_c - N_{\mathrm{com}}
          :label: eqndofcoupling

Here :math:`N_c` is the number of *constraints* imposed on the system.
When performing molecular dynamics :math:`N_{\mathrm{com}}=3` additional
degrees of freedom must be removed, because the three center-of-mass
velocities are constants of the motion, which are usually set to zero.
When simulating in vacuo, the rotation around the center of mass can
also be removed, in this case :math:`N_{\mathrm{com}}=6`. When more than
one temperature-coupling group is used, the number of degrees of freedom
for group :math:`i` is:

.. math:: N^i_{\mathrm{df}}  ~=~  (3 N^i - N^i_c) \frac{3 N - N_c - N_{\mathrm{com}}}{3 N - N_c}
          :label: eqndofonecouplgroup

The kinetic energy can also be written as a tensor, which is necessary
for pressure calculation in a triclinic system, or systems where shear
forces are imposed:

.. math:: {\bf E}_{\mathrm{kin}} = {\frac{1}{2}}\sum_i^N m_i {\mathbf{v}_i}\otimes {\mathbf{v}_i}
          :label: eqnEkintensor

Pressure and virial
^^^^^^^^^^^^^^^^^^^

The pressure tensor **P** is calculated from the difference between
kinetic energy :math:`E_{\mathrm{kin}}` and the virial
:math:`{\bf \Xi}`:

.. math:: {\bf P} = \frac{2}{V} ({\bf E}_{\mathrm{kin}}-{\bf \Xi})
          :label: eqnP

where :math:`V` is the volume of the computational box. The scalar
pressure :math:`P`, which can be used for pressure coupling in the case
of isotropic systems, is computed as:

.. math:: P       = {\rm trace}({\bf P})/3

The virial :math:`{\bf \Xi}` tensor is defined as:

.. math:: {\bf \Xi} = -{\frac{1}{2}}\sum_{i<j} \mathbf{r}_{ij} \otimes \mathbf{F}_{ij}
          :label: eqnXi

The |Gromacs| implementation of the virial computation is described in
sec. :ref:`virial`

.. _update:

The leap-frog integrator
~~~~~~~~~~~~~~~~~~~~~~~~

.. _fig-leapfrog:

.. figure:: plots/leapfrog.*
   :width: 8.00000cm

   The Leap-Frog integration method. The algorithm is called Leap-Frog
   because :math:`\mathbf{r}` and
   :math:`\mathbf{v}` are leaping like frogs over each
   other’s backs.

The default MD integrator in |Gromacs| is the so-called *leap-frog*
algorithm \ :ref:`22 <refHockney74>` for the integration of the
equations of motion. When extremely accurate integration with
temperature and/or pressure coupling is required, the velocity Verlet
integrators are also present and may be preferable (see
:ref:`vverlet`). The leap-frog algorithm uses positions
:math:`\mathbf{r}` at time :math:`t` and velocities
:math:`\mathbf{v}` at time
:math:`t-{{\frac{1}{2}}{{\Delta t}}}`; it updates positions and
velocities using the forces :math:`\mathbf{F}(t)`
determined by the positions at time :math:`t` using these relations:

.. math:: \begin{aligned}
          \mathbf{v}(t+{{\frac{1}{2}}{{\Delta t}}})  &~=~&   \mathbf{v}(t-{{\frac{1}{2}}{{\Delta t}}})+\frac{{{\Delta t}}}{m}\mathbf{F}(t)   \\
          \mathbf{r}(t+{{\Delta t}})   &~=~&   \mathbf{r}(t)+{{\Delta t}}\mathbf{v}(t+{{\frac{1}{2}}{{\Delta t}}})\end{aligned}
          :label: eqnleapfrogv

The algorithm is visualized in :numref:`Fig. %s <fig-leapfrog>`. It
produces trajectories that are identical to the Verlet \ :ref:`23 <refVerlet67>`
algorithm, whose position-update relation is

.. math:: \mathbf{r}(t+{{\Delta t}})~=~2\mathbf{r}(t) - \mathbf{r}(t-{{\Delta t}}) + \frac{1}{m}\mathbf{F}(t){{\Delta t}}^2+O({{\Delta t}}^4)
          :label: eqnleapfrogp

The algorithm is of third order in :math:`\mathbf{r}` and
is time-reversible. See ref. \ :ref:`24 <refBerendsen86b>` for the
merits of this algorithm and comparison with other time integration
algorithms.

The equations of motion are modified for temperature coupling and
pressure coupling, and extended to include the conservation of
constraints, all of which are described below.

.. _vverlet:

The velocity Verlet integrator
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The velocity Verlet algorithm\ :ref:`25 <refSwope82>` is also implemented in
|Gromacs|, though it is not yet fully integrated with all sets of options.
In velocity Verlet, positions :math:`\mathbf{r}` and
velocities :math:`\mathbf{v}` at time :math:`t` are used
to integrate the equations of motion; velocities at the previous half
step are not required.

.. math:: \begin{aligned}
          \mathbf{v}(t+{{\frac{1}{2}}{{\Delta t}}})  &~=~&   \mathbf{v}(t)+\frac{{{\Delta t}}}{2m}\mathbf{F}(t)   \\
          \mathbf{r}(t+{{\Delta t}})   &~=~&   \mathbf{r}(t)+{{\Delta t}}\,\mathbf{v}(t+{{\frac{1}{2}}{{\Delta t}}}) \\
          \mathbf{v}(t+{{\Delta t}})   &~=~&   \mathbf{v}(t+{{\frac{1}{2}}{{\Delta t}}})+\frac{{{\Delta t}}}{2m}\mathbf{F}(t+{{\Delta t}})\end{aligned}
          :label: eqnvelocityverlet1

or, equivalently,

.. math:: \begin{aligned}
          \mathbf{r}(t+{{\Delta t}})   &~=~&   \mathbf{r}(t)+ {{\Delta t}}\,\mathbf{v} + \frac{{{\Delta t}}^2}{2m}\mathbf{F}(t) \\
          \mathbf{v}(t+{{\Delta t}})   &~=~&   \mathbf{v}(t)+ \frac{{{\Delta t}}}{2m}\left[\mathbf{F}(t) + \mathbf{F}(t+{{\Delta t}})\right]\end{aligned}
          :label: eqnvelocityverlet2

With no temperature or pressure coupling, and with *corresponding*
starting points, leap-frog and velocity Verlet will generate identical
trajectories, as can easily be verified by hand from the equations
above. Given a single starting file with the *same* starting point
:math:`\mathbf{x}(0)` and
:math:`\mathbf{v}(0)`, leap-frog and velocity Verlet will
*not* give identical trajectories, as leap-frog will interpret the
velocities as corresponding to :math:`t=-{{\frac{1}{2}}{{\Delta t}}}`,
while velocity Verlet will interpret them as corresponding to the
timepoint :math:`t=0`.

Understanding reversible integrators: The Trotter decomposition
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To further understand the relationship between velocity Verlet and
leap-frog integration, we introduce the reversible Trotter formulation
of dynamics, which is also useful to understanding implementations of
thermostats and barostats in |Gromacs|.

A system of coupled, first-order differential equations can be evolved
from time :math:`t = 0` to time :math:`t` by applying the evolution
operator

.. math:: \begin{aligned}
          \Gamma(t) &=& \exp(iLt) \Gamma(0) \nonumber \\
          iL &=& \dot{\Gamma}\cdot \nabla_{\Gamma},\end{aligned}
          :label: eqnevoluoperator

where :math:`L` is the Liouville operator, and :math:`\Gamma` is the
multidimensional vector of independent variables (positions and
velocities). A short-time approximation to the true operator, accurate
at time :math:`{{\Delta t}}= t/P`, is applied :math:`P` times in
succession to evolve the system as

.. math:: \Gamma(t) = \prod_{i=1}^P \exp(iL{{\Delta t}}) \Gamma(0)
          :label: eqnevolvesystem

For NVE dynamics, the Liouville operator is

.. math:: \begin{aligned}
          iL = \sum_{i=1}^{N} {{\mathbf{v}}}_i \cdot \nabla_{{{\mathbf{r}}}_i} + \sum_{i=1}^N \frac{1}{m_i}{{\mathbf{F}}}(r_i) \cdot \nabla_{{{\mathbf{v}}}_i}.\end{aligned}
          :label: eqnliouvilleoperator

This can be split into two additive operators

.. math:: \begin{aligned}
          iL_1 &=& \sum_{i=1}^N \frac{1}{m_i}{{\mathbf{F}}}(r_i) \cdot \nabla_{{{\mathbf{v}}}_i} \nonumber \\
          iL_2 &=& \sum_{i=1}^{N} {{\mathbf{v}}}_i \cdot \nabla_{{{\mathbf{r}}}_i} \end{aligned}
          :label: eqnlotwoadditive

Then a short-time, symmetric, and thus reversible approximation of the
true dynamics will be

.. math:: \begin{aligned}
          \exp(iL{{\Delta t}}) = \exp(iL_2{{\frac{1}{2}}{{\Delta t}}}) \exp(iL_1{{\Delta t}}) \exp(iL_2{{\frac{1}{2}}{{\Delta t}}}) + \mathcal{O}({{\Delta t}}^3).
          \end{aligned}
          :label: eqNVETrotter

This corresponds to velocity Verlet integration. The first exponential
term over :math:`{{\frac{1}{2}}{{\Delta t}}}` corresponds to a velocity
half-step, the second exponential term over :math:`{{\Delta t}}`
corresponds to a full velocity step, and the last exponential term over
:math:`{{\frac{1}{2}}{{\Delta t}}}` is the final velocity half step. For
future times :math:`t = n{{\Delta t}}`, this becomes

.. math:: \begin{aligned}
          \exp(iLn{{\Delta t}}) &\approx&  \left(\exp(iL_2{{\frac{1}{2}}{{\Delta t}}}) \exp(iL_1{{\Delta t}}) \exp(iL_2{{\frac{1}{2}}{{\Delta t}}})\right)^n \nonumber \\
                       &\approx&  \exp(iL_2{{\frac{1}{2}}{{\Delta t}}}) \bigg(\exp(iL_1{{\Delta t}}) \exp(iL_2{{\Delta t}})\bigg)^{n-1} \nonumber \\
                       &       &  \;\;\;\; \exp(iL_1{{\Delta t}}) \exp(iL_2{{\frac{1}{2}}{{\Delta t}}}) \end{aligned}
          :label: eqntrottertimestep

This formalism allows us to easily see the difference between the
different flavors of Verlet integrators. The leap-frog integrator can be
seen as starting with :eq:`Eq. %s <eqNVETrotter>` with the
:math:`\exp\left(iL_1 {\Delta t}\right)` term, instead of the half-step
velocity term, yielding

.. math:: \begin{aligned}
          \exp(iLn{\Delta t}) &=& \exp\left(iL_1 {\Delta t}\right) \exp\left(iL_2 {{\Delta t}}\right) + \mathcal{O}({{\Delta t}}^3).\end{aligned}
          :label: eqnleapfroghalfvel

Here, the full step in velocity is between
:math:`t-{{\frac{1}{2}}{{\Delta t}}}` and
:math:`t+{{\frac{1}{2}}{{\Delta t}}}`, since it is a combination of the
velocity half steps in velocity Verlet. For future times
:math:`t = n{{\Delta t}}`, this becomes

.. math:: \begin{aligned}
          \exp(iLn{\Delta t}) &\approx& \bigg(\exp\left(iL_1 {\Delta t}\right) \exp\left(iL_2 {{\Delta t}}\right)  \bigg)^{n}.\end{aligned}
          :label: eqnvelverlethalfvel

Although at first this does not appear symmetric, as long as the full
velocity step is between :math:`t-{{\frac{1}{2}}{{\Delta t}}}` and
:math:`t+{{\frac{1}{2}}{{\Delta t}}}`, then this is simply a way of
starting velocity Verlet at a different place in the cycle.

Even though the trajectory and thus potential energies are identical
between leap-frog and velocity Verlet, the kinetic energy and
temperature will not necessarily be the same. Standard velocity Verlet
uses the velocities at the :math:`t` to calculate the kinetic energy and
thus the temperature only at time :math:`t`; the kinetic energy is then
a sum over all particles

.. math:: \begin{aligned}
          KE_{\mathrm{full}}(t) &=& \sum_i \left(\frac{1}{2m_i}\mathbf{v}_i(t)\right)^2 \nonumber\\ 
                &=& \sum_i \frac{1}{2m_i}\left(\frac{1}{2}\mathbf{v}_i(t-{{\frac{1}{2}}{{\Delta t}}})+\frac{1}{2}\mathbf{v}_i(t+{{\frac{1}{2}}{{\Delta t}}})\right)^2,\end{aligned}
          :label: eqnTrotterEkin

with the square on the *outside* of the average. Standard leap-frog
calculates the kinetic energy at time :math:`t` based on the average
kinetic energies at the timesteps :math:`t+{{\frac{1}{2}}{{\Delta t}}}`
and :math:`t-{{\frac{1}{2}}{{\Delta t}}}`, or the sum over all particles

.. math:: \begin{aligned}
          KE_{\mathrm{average}}(t) &=& \sum_i \frac{1}{2m_i}\left(\frac{1}{2}\mathbf{v}_i(t-{{\frac{1}{2}}{{\Delta t}}})^2+\frac{1}{2}\mathbf{v}_i(t+{{\frac{1}{2}}{{\Delta t}}})^2\right),\end{aligned}
          :label: eqnTrottersumparticles

where the square is *inside* the average.

A non-standard variant of velocity Verlet which averages the kinetic
energies :math:`KE(t+{{\frac{1}{2}}{{\Delta t}}})` and
:math:`KE(t-{{\frac{1}{2}}{{\Delta t}}})`, exactly like leap-frog, is
also now implemented in |Gromacs| (as :ref:`mdp` file option
:mdp-value:`integrator=md-vv-avek`). Without temperature and pressure coupling,
velocity Verlet with half-step-averaged kinetic energies and leap-frog
will be identical up to numerical precision. For temperature- and
pressure-control schemes, however, velocity Verlet with
half-step-averaged kinetic energies and leap-frog will be different, as
will be discussed in the section in thermostats and barostats.

The half-step-averaged kinetic energy and temperature are slightly more
accurate for a given step size; the difference in average kinetic
energies using the half-step-averaged kinetic energies (
:mdp-value:`integrator=md` and :mdp-value:`integrator=md-vv-avek`
) will be closer to the kinetic energy obtained in the limit
of small step size than will the full-step kinetic energy (using
:mdp-value:`integrator=md-vv`). For NVE simulations, this difference is usually not
significant, since the positions and velocities of the particles are
still identical; it makes a difference in the way the temperature of
the simulations are **interpreted**, but **not** in the trajectories that
are produced. Although the kinetic energy is more accurate with the
half-step-averaged method, meaning that it changes less as the timestep
gets large, it is also more noisy. The RMS deviation of the total energy
of the system (sum of kinetic plus potential) in the half-step-averaged
kinetic energy case will be higher (about twice as high in most cases)
than the full-step kinetic energy. The drift will still be the same,
however, as again, the trajectories are identical.

For NVT simulations, however, there **will** be a difference, as discussed
in the section on temperature control, since the velocities of the
particles are adjusted such that kinetic energies of the simulations,
which can be calculated either way, reach the distribution corresponding
to the set temperature. In this case, the three methods will not give
identical results.

Because the velocity and position are both defined at the same time
:math:`t` the velocity Verlet integrator can be used for some methods,
especially rigorously correct pressure control methods, that are not
actually possible with leap-frog. The integration itself takes
negligibly more time than leap-frog, but twice as many communication
calls are currently required. In most cases, and especially for large
systems where communication speed is important for parallelization and
differences between thermodynamic ensembles vanish in the :math:`1/N`
limit, and when only NVT ensembles are required, leap-frog will likely
be the preferred integrator. For pressure control simulations where the
fine details of the thermodynamics are important, only velocity Verlet
allows the true ensemble to be calculated. In either case, simulation
with double precision may be required to get fine details of
thermodynamics correct.

Multiple time-stepping
~~~~~~~~~~~~~~~~~~~~~~

The leap-frog integrator in |Gromacs| supports a configurable multiple
time-stepping scheme. This can be used to improve performance by
computing slowly varying forces less frequently. The RESPA scheme
:ref:`191 <refTuckerman92>` is used, which is based on a TROTTER
decomposition and is therefore reversible and symplectic.

In order to allow tuning this for each system, the integrator makes it
possible to specify different types of bonded and non-bonded interactions
for multiple-time step integration. 
To avoid integration errors, it is still imperative that the integration
interval used for each force component is short enough, and there is no
universal formula that allows the algorithm to detect this. Since the
slowly-varying forces are often of smaller magnitude, using time steps that
are too large might not result in simulations crashing, so it is recommended
to be conservative and only gradually increase intervals while ensuring you
get proper sampling and avoid energy drifts.
As an initial guidance, many of the most common biomolecular force fields appear
to run into stability problems when the period of integrating Lennard-Jones
forces is 4 fs or longer, so for now we only recommend computing long-range
electrostatics (PME mesh contribution) less frequently than every step when
using a base time step of 2 fs.
Another, rather different, scenario is to use a base time step of 0.5 fs
with non-constrained harmonic bonds, and compute other interactions
every second or fourth step. Despite these caveats, we encourage users to test
the functionality, assess stability and energy drifts, and either discuss your
experience in the GROMACS forums or suggest improvements to the documentation
so we can improve this guidance in the future.

For using larger time steps for all interactions, and integration, angle
vibrations involving hydrogen atoms can be removed using virtual
interaction sites (see sec. :ref:`rmfast`), which brings the shortest
time step up to PME mesh update frequency of a multiple time stepping
scheme. This results in a near doubling of the simulation performance.

.. _temp-coupling:

Temperature coupling
~~~~~~~~~~~~~~~~~~~~

While direct use of molecular dynamics gives rise to the NVE (constant
number, constant volume, constant energy ensemble), most quantities that
we wish to calculate are actually from a constant temperature (NVT)
ensemble, also called the canonical ensemble. |Gromacs| can use the
*weak-coupling* scheme of Berendsen \ :ref:`26 <refBerendsen84>`, stochastic
randomization through the Andersen thermostat \ :ref:`27 <refAndersen80>`, the
extended ensemble Nosé-Hoover scheme \ :ref:`28 <refNose84>`, :ref:`29 <refHoover85>`, or a
velocity-rescaling scheme \ :ref:`30 <refBussi2007a>` to
simulate constant temperature, with advantages of each of the schemes
laid out below.

There are several other reasons why it might be necessary to control the
temperature of the system (drift during equilibration, drift as a result
of force truncation and integration errors, heating due to external or
frictional forces), but this is not entirely correct to do from a
thermodynamic standpoint, and in some cases only masks the symptoms
(increase in temperature of the system) rather than the underlying
problem (deviations from correct physics in the dynamics). For larger
systems, errors in ensemble averages and structural properties incurred
by using temperature control to remove slow drifts in temperature appear
to be negligible, but no completely comprehensive comparisons have been
carried out, and some caution must be taking in interpreting the
results.

When using temperature and/or pressure coupling the total energy is no
longer conserved. Instead there is a conserved energy quantity the
formula of which will depend on the combination or temperature and
pressure coupling algorithm used. For all coupling algorithms, except
for Andersen temperature coupling and Parrinello-Rahman pressure
coupling combined with shear stress, the conserved energy quantity is
computed and stored in the energy and log file. Note that this quantity
will not be conserved when external forces are applied to the system,
such as pulling on group with a changing distance or an electric field.
Furthermore, how well the energy is conserved depends on the accuracy of
all algorithms involved in the simulation. Usually the algorithms that
cause most drift are constraints and the pair-list buffer, depending on
the parameters used.

Berendsen temperature coupling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The Berendsen algorithm mimics weak coupling with first-order kinetics
to an external heat bath with given temperature :math:`T_0`. See
ref. \ :ref:`31 <refBerendsen91>` for a comparison with the Nosé-Hoover scheme. The
effect of this algorithm is that a deviation of the system temperature
from :math:`T_0` is slowly corrected according to:

.. math::  \frac{{\mbox{d}}T}{{\mbox{d}}t} = \frac{T_0-T}{\tau}
           :label: eqnTcoupling

which means that a temperature deviation decays exponentially with a
time constant :math:`\tau`. This method of coupling has the advantage
that the strength of the coupling can be varied and adapted to the user
requirement: for equilibration purposes the coupling time can be taken
quite short (*e.g.* 0.01 ps), but for reliable equilibrium runs it can
be taken much longer (*e.g.* 0.5 ps) in which case it hardly influences
the conservative dynamics.

The Berendsen thermostat suppresses the fluctuations of the kinetic
energy. This means that one does not generate a proper canonical
ensemble, so rigorously, the sampling will be incorrect. This error
scales with :math:`1/N`, so for very large systems most ensemble
averages will not be affected significantly, except for the distribution
of the kinetic energy itself. However, fluctuation properties, such as
the heat capacity, will be affected. A similar thermostat which does
produce a correct ensemble is the velocity rescaling
thermostat \ :ref:`30 <refBussi2007a>` described below, so while the
Berendsen thermostat is supported for historical reasons, including
the ability to reproduce old simulations, we strongly recommend
against using it for new simulations.

The heat flow into or out of the system is affected by scaling the
velocities of each particle every step, or every :math:`n_\mathrm{TC}`
steps, with a time-dependent factor :math:`\lambda`, given by:

.. math::  \lambda = \left[ 1 + \frac{n_\mathrm{TC} \Delta t}{\tau_T}
           \left\{\frac{T_0}{T(t -  {{\frac{1}{2}}{{\Delta t}}})} - 1 \right\} \right]^{1/2}
           :label: eqnlambda

The parameter :math:`\tau_T` is close, but not exactly equal, to the
time constant :math:`\tau` of the temperature coupling
(:eq:`eqn. %s <eqnTcoupling>`):

.. math:: \tau = 2 C_V \tau_T / N_{df} k
          :label: eqnTcoupltau

where :math:`C_V` is the total heat capacity of the system, :math:`k`
is Boltzmann’s constant, and :math:`N_{df}` is the total number of
degrees of freedom. The reason that :math:`\tau \neq \tau_T` is that the
kinetic energy change caused by scaling the velocities is partly
redistributed between kinetic and potential energy and hence the change
in temperature is less than the scaling energy. In practice, the ratio
:math:`\tau / \tau_T` ranges from 1 (gas) to 2 (harmonic solid) to 3
(water). When we use the term *temperature coupling time constant*, we
mean the parameter :math:`\tau_T`. **Note** that in practice the scaling
factor :math:`\lambda` is limited to the range of 0.8
:math:`<= \lambda <=` 1.25, to avoid scaling by very large numbers which
may crash the simulation. In normal use, :math:`\lambda` will always be
much closer to 1.0.

The thermostat modifies the kinetic energy at each scaling step by:

.. math:: \Delta E_k = (\lambda - 1)^2 E_k
          :label: eqnThermostat

The sum of these changes over the run needs to subtracted from the
total energy to obtain the conserved energy quantity.

Velocity-rescaling temperature coupling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The velocity-rescaling thermostat \ :ref:`30 <refBussi2007a>`
is essentially a Berendsen thermostat (see above) with an additional
stochastic term that ensures a correct kinetic energy distribution by
modifying it according to

.. math::  {\mbox{d}}K = (K_0 - K) \frac{{\mbox{d}}t}{\tau_T} + 2 \sqrt{\frac{K K_0}{N_f}} \frac{{\mbox{d}}W}{\sqrt{\tau_T}},
           :label: eqnvrescale

where :math:`K` is the kinetic energy, :math:`N_f` the number of
degrees of freedom and :math:`{\mbox{d}}W` a Wiener process. There are
no additional parameters, except for a random seed. This thermostat
produces a correct canonical ensemble and still has the advantage of the
Berendsen thermostat: first order decay of temperature deviations and no
oscillations.

Andersen thermostat
^^^^^^^^^^^^^^^^^^^

One simple way to maintain a thermostatted ensemble is to take an
:math:`NVE` integrator and periodically re-select the velocities of the
particles from a Maxwell-Boltzmann distribution \ :ref:`27 <refAndersen80>`. This
can either be done by randomizing all the velocities simultaneously
(massive collision) every :math:`\tau_T/{{\Delta t}}` steps
(``andersen-massive``), or by randomizing every particle
with some small probability every timestep (``andersen``),
equal to :math:`{{\Delta t}}/\tau`, where in both cases
:math:`{{\Delta t}}` is the timestep and :math:`\tau_T` is a
characteristic coupling time scale. Because of the way constraints
operate, all particles in the same constraint group must be randomized
simultaneously. Because of parallelization issues, the
``andersen`` version cannot currently (5.0) be used in
systems with constraints. ``andersen-massive`` can be used
regardless of constraints. This thermostat is also currently only
possible with velocity Verlet algorithms, because it operates directly
on the velocities at each timestep.

This algorithm completely avoids some of the ergodicity issues of other
thermostatting algorithms, as energy cannot flow back and forth between
energetically decoupled components of the system as in velocity scaling
motions. However, it can slow down the kinetics of system by randomizing
correlated motions of the system, including slowing sampling when
:math:`\tau_T` is at moderate levels (less than 10 ps). This algorithm
should therefore generally not be used when examining kinetics or
transport properties of the system \ :ref:`32 <refBasconi2013>`.

Nosé-Hoover temperature coupling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The Berendsen weak-coupling algorithm is extremely efficient for
relaxing a system to the target temperature, but once the system has
reached equilibrium it might be more important to probe a correct
canonical ensemble. This is unfortunately not the case for the
weak-coupling scheme.

To enable canonical ensemble simulations, |Gromacs| also supports the
extended-ensemble approach first proposed by Nosé :ref:`28 <refNose84>` and later
modified by Hoover \ :ref:`29 <refHoover85>`. The system Hamiltonian is extended by
introducing a thermal reservoir and a friction term in the equations of
motion. The friction force is proportional to the product of each
particle’s velocity and a friction parameter, :math:`\xi`. This friction
parameter (or *heat bath* variable) is a fully dynamic quantity with its
own momentum (:math:`p_{\xi}`) and equation of motion; the time
derivative is calculated from the difference between the current kinetic
energy and the reference temperature.

In this formulation, the particles´ equations of motion in
the global :ref:`MD scheme <gmx-md-scheme>` are replaced by:

.. math:: \frac {{\mbox{d}}^2\mathbf{r}_i}{{\mbox{d}}t^2} = \frac{\mathbf{F}_i}{m_i} - 
          \frac{p_{\xi}}{Q}\frac{{\mbox{d}}\mathbf{r}_i}{{\mbox{d}}t} ,
          :label: eqnNHeqnofmotion

where the equation of motion for the heat bath parameter :math:`\xi` is:

.. math:: \frac {{\mbox{d}}p_{\xi}}{{\mbox{d}}t} = \left( T - T_0 \right).
          :label: eqnNHheatbath

The reference temperature is denoted :math:`T_0`, while :math:`T` is
the current instantaneous temperature of the system. The strength of the
coupling is determined by the constant :math:`Q` (usually called the
*mass parameter* of the reservoir) in combination with the reference
temperature.  [1]_

The conserved quantity for the Nosé-Hoover equations of motion is not
the total energy, but rather

.. math:: \begin{aligned}
          H = \sum_{i=1}^{N} \frac{{{\mathbf{p}}}_i}{2m_i} + U\left({{\mathbf{r}}}_1,{{\mathbf{r}}}_2,\ldots,{{\mathbf{r}}}_N\right) +\frac{p_{\xi}^2}{2Q} + N_{f}kT\xi,\end{aligned}
          :label: eqnNHconservedbasic

where :math:`N_f` is the total number of degrees of freedom.

In our opinion, the mass parameter is a somewhat awkward way of
describing coupling strength, especially due to its dependence on
reference temperature (and some implementations even include the number
of degrees of freedom in your system when defining :math:`Q`). To
maintain the coupling strength, one would have to change :math:`Q` in
proportion to the change in reference temperature. For this reason, we
prefer to let the |Gromacs| user work instead with the period
:math:`\tau_T` of the oscillations of kinetic energy between the system
and the reservoir instead. It is directly related to :math:`Q` and
:math:`T_0` via:

.. math:: Q = \frac {\tau_T^2 T_0}{4 \pi^2}.
          :label: eqnNHQ

This provides a much more intuitive way of selecting the Nosé-Hoover
coupling strength (similar to the weak-coupling relaxation), and in
addition :math:`\tau_T` is independent of system size and reference
temperature.

It is however important to keep the difference between the weak-coupling
scheme and the Nosé-Hoover algorithm in mind: Using weak coupling you
get a strongly damped *exponential relaxation*, while the Nosé-Hoover
approach produces an *oscillatory relaxation*. The actual time it takes
to relax with Nosé-Hoover coupling is several times larger than the
period of the oscillations that you select. These oscillations (in
contrast to exponential relaxation) also means that the time constant
normally should be 4–5 times larger than the relaxation time used with
weak coupling, but your mileage may vary.

Nosé-Hoover dynamics in simple systems such as collections of harmonic
oscillators, can be *nonergodic*, meaning that only a subsection of
phase space is ever sampled, even if the simulations were to run for
infinitely long. For this reason, the Nosé-Hoover chain approach was
developed, where each of the Nosé-Hoover thermostats has its own
Nosé-Hoover thermostat controlling its temperature. In the limit of an
infinite chain of thermostats, the dynamics are guaranteed to be
ergodic. Using just a few chains can greatly improve the ergodicity, but
recent research has shown that the system will still be nonergodic, and
it is still not entirely clear what the practical effect of
this \ :ref:`33 <refCooke2008>`. Currently, the default number of chains is 10, but
this can be controlled by the user. In the case of chains, the equations
are modified in the following way to include a chain of thermostatting
particles \ :ref:`34 <refMartyna1992>`:

.. math::  \begin{aligned}
           \frac {{\mbox{d}}^2\mathbf{r}_i}{{\mbox{d}}t^2} &~=~& \frac{\mathbf{F}_i}{m_i} - \frac{p_{{\xi}_1}}{Q_1} \frac{{\mbox{d}}\mathbf{r}_i}{{\mbox{d}}t} \nonumber \\
           \frac {{\mbox{d}}p_{{\xi}_1}}{{\mbox{d}}t} &~=~& \left( T - T_0 \right) - p_{{\xi}_1} \frac{p_{{\xi}_2}}{Q_2} \nonumber \\
           \frac {{\mbox{d}}p_{{\xi}_{i=2\ldots N}}}{{\mbox{d}}t} &~=~& \left(\frac{p_{\xi_{i-1}}^2}{Q_{i-1}} -kT\right) - p_{\xi_i} \frac{p_{\xi_{i+1}}}{Q_{i+1}} \nonumber \\
           \frac {{\mbox{d}}p_{\xi_N}}{{\mbox{d}}t} &~=~& \left(\frac{p_{\xi_{N-1}}^2}{Q_{N-1}}-kT\right)
           \end{aligned}
           :label: eqnNHchaineqnofmotion

The conserved quantity for Nosé-Hoover chains is

.. math:: \begin{aligned}
          H = \sum_{i=1}^{N} \frac{{{\mathbf{p}}}_i}{2m_i} + U\left({{\mathbf{r}}}_1,{{\mathbf{r}}}_2,\ldots,{{\mathbf{r}}}_N\right) +\sum_{k=1}^M\frac{p^2_{\xi_k}}{2Q^{\prime}_k} + N_fkT\xi_1 + kT\sum_{k=2}^M \xi_k \end{aligned}
          :label: eqnNHconservedquantity

The values and velocities of the Nosé-Hoover thermostat variables are
generally not included in the output, as they take up a fair amount of
space and are generally not important for analysis of simulations, but
by setting an :ref:`mdp` option the values of all the positions and velocities
of all Nosé-Hoover particles in the chain are written to the :ref:`edr` file.
Leap-frog simulations currently can only have Nosé-Hoover chain lengths
of 1, but this will likely be updated in later version.

As described in the integrator section, for temperature coupling, the
temperature that the algorithm attempts to match to the reference
temperature is calculated differently in velocity Verlet and leap-frog
dynamics. Velocity Verlet (*md-vv*) uses the full-step kinetic energy,
while leap-frog and *md-vv-avek* use the half-step-averaged kinetic
energy.

We can examine the Trotter decomposition again to better understand the
differences between these constant-temperature integrators. In the case
of Nosé-Hoover dynamics (for simplicity, using a chain with :math:`N=1`,
with more details in Ref. \ :ref:`35 <refMartyna1996>`), we split the Liouville
operator as

.. math:: iL = iL_1 + iL_2 + iL_{\mathrm{NHC}},
          :label: eqnNHTrotter

where

.. math:: \begin{aligned}
          iL_1 &=& \sum_{i=1}^N \left[\frac{{{\mathbf{p}}}_i}{m_i}\right]\cdot \frac{\partial}{\partial {{\mathbf{r}}}_i} \nonumber \\
          iL_2 &=& \sum_{i=1}^N {{\mathbf{F}}}_i\cdot \frac{\partial}{\partial {{\mathbf{p}}}_i} \nonumber \\
          iL_{\mathrm{NHC}} &=& \sum_{i=1}^N-\frac{p_{\xi}}{Q}{{\mathbf{v}}}_i\cdot \nabla_{{{\mathbf{v}}}_i} +\frac{p_{\xi}}{Q}\frac{\partial }{\partial \xi} + \left( T - T_0 \right)\frac{\partial }{\partial p_{\xi}}\end{aligned}
          :label: eqnNHTrotter2

For standard velocity Verlet with Nosé-Hoover temperature control, this
becomes

.. math:: \begin{aligned}
          \exp(iL{\Delta t}) &=& \exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) \exp\left(iL_2 {\Delta t}/2\right) \nonumber \\
          &&\exp\left(iL_1 {\Delta t}\right) \exp\left(iL_2 {\Delta t}/2\right) \exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) + \mathcal{O}({{\Delta t}}^3).\end{aligned}
          :label: eqnNHTrotter3

For half-step-averaged temperature control using *md-vv-avek*, this
decomposition will not work, since we do not have the full step
temperature until after the second velocity step. However, we can
construct an alternate decomposition that is still reversible, by
switching the place of the NHC and velocity portions of the
decomposition:

.. math::  \begin{aligned}
   \exp(iL{\Delta t}) &=& \exp\left(iL_2 {\Delta t}/2\right) \exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right)\exp\left(iL_1 {\Delta t}\right)\nonumber \\
   &&\exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) \exp\left(iL_2 {\Delta t}/2\right)+ \mathcal{O}({{\Delta t}}^3)
   \end{aligned}
   :label: eqhalfstepNHCintegrator

This formalism allows us to easily see the difference between the
different flavors of velocity Verlet integrator. The leap-frog
integrator can be seen as starting with
:eq:`Eq. %s <eqhalfstepNHCintegrator>` just before the
:math:`\exp\left(iL_1 {\Delta t}\right)` term, yielding:

.. math:: \begin{aligned}
          \exp(iL{\Delta t}) &=&  \exp\left(iL_1 {\Delta t}\right) \exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) \nonumber \\
          &&\exp\left(iL_2 {\Delta t}\right) \exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) + \mathcal{O}({{\Delta t}}^3)\end{aligned}
          :label: eqnNHleapfrog

and then using some algebra tricks to solve for some quantities are
required before they are actually calculated \ :ref:`36 <refHolian95>`.

Group temperature coupling
^^^^^^^^^^^^^^^^^^^^^^^^^^

In |Gromacs| temperature coupling can be performed on groups of atoms,
typically a protein and solvent. The reason such algorithms were
introduced is that energy exchange between different components is not
perfect, due to different effects including cut-offs etc. If now the
whole system is coupled to one heat bath, water (which experiences the
largest cut-off noise) will tend to heat up and the protein will cool
down. Typically 100 K differences can be obtained. With the use of
proper electrostatic methods (PME) these difference are much smaller but
still not negligible. The parameters for temperature coupling in groups
are given in the :ref:`mdp` file. Recent investigation has shown that small
temperature differences between protein and water may actually be an
artifact of the way temperature is calculated when there are finite
timesteps, and very large differences in temperature are likely a sign
of something else seriously going wrong with the system, and should be
investigated carefully \ :ref:`37 <refEastwood2010>`.

One special case should be mentioned: it is possible to
temperature-couple only part of the system, leaving other parts without
temperature coupling. This is done by specifying :math:`{-1}` for the
time constant :math:`\tau_T` for the group that should not be
thermostatted. If only part of the system is thermostatted, the system
will still eventually converge to an NVT system. In fact, one suggestion
for minimizing errors in the temperature caused by discretized timesteps
is that if constraints on the water are used, then only the water
degrees of freedom should be thermostatted, not protein degrees of
freedom, as the higher frequency modes in the protein can cause larger
deviations from the *true* temperature, the temperature obtained with
small timesteps \ :ref:`37 <refEastwood2010>`.

Pressure coupling
~~~~~~~~~~~~~~~~~

In the same spirit as the temperature coupling, the system can also be
coupled to a *pressure bath.* |Gromacs| supports both the Berendsen
algorithm \ :ref:`26 <refBerendsen84>` that scales coordinates and box
vectors every step (we strongly recommend not to use it), a new
stochastic cell rescaling algorithm, the extended-ensemble Parrinello-Rahman
approach \ :ref:`38 <refParrinello81>`, :ref:`39 <refNose83>`, and for the
velocity Verlet variants, the Martyna-Tuckerman-Tobias-Klein (MTTK)
implementation of pressure control \ :ref:`35 <refMartyna1996>`.
Parrinello-Rahman and Berendsen can be combined with any of the
temperature coupling methods above. MTTK can only be used with
Nosé-Hoover temperature control. From 5.1 afterwards, it can only used
when the system does not have constraints.

Berendsen pressure coupling
^^^^^^^^^^^^^^^^^^^^^^^^^^^

The Berendsen algorithm rescales the coordinates and box vectors every
step, or every :math:`n_\mathrm{PC}` steps, with a matrix :math:`\mu`,
which has the effect of a first-order kinetic relaxation of the pressure
towards a given reference pressure :math:`{\bf P}_0` according to

.. math:: \frac{{\mbox{d}}{\bf P}}{{\mbox{d}}t} = \frac{{\bf P}_0-{\bf P}}{\tau_p}.
          :label: eqnberendsenpressure

The scaling matrix :math:`\mu` is given by

.. math::  \mu_{ij}
           = \delta_{ij} - \frac{n_\mathrm{PC}\Delta t}{3\, \tau_p} \beta_{ij} \{P_{0ij} - P_{ij}(t) \}.
           :label: eqnmu

Here, :math:`\beta` is the isothermal compressibility of the system. In
most cases this will be a diagonal matrix, with equal elements on the
diagonal, the value of which is generally not known. It suffices to take
a rough estimate because the value of :math:`\beta` only influences the
non-critical time constant of the pressure relaxation without affecting
the average pressure itself. For water at 1 atm and 300 K
:math:`\beta = 4.6 \times 10^{-10}`
Pa\ :math:`^{-1} = 4.6 \times 10^{-5}` bar\ :math:`^{-1}`, which is
:math:`7.6 \times 10^{-4}` MD units (see chapter :ref:`defunits`). Most
other liquids have similar values. When scaling completely
anisotropically, the system has to be rotated in order to obey
:eq:`eqn. %s <eqnboxrot>`. This rotation is approximated in first order in the
scaling, which is usually less than :math:`10^{-4}`. The actual scaling
matrix :math:`\mu'` is

.. math:: \mathbf{\mu'} = 
          \left(\begin{array}{ccc}
          \mu_{xx} & \mu_{xy} + \mu_{yx} & \mu_{xz} + \mu_{zx} \\
          0        & \mu_{yy}            & \mu_{yz} + \mu_{zy} \\
          0        & 0                   & \mu_{zz}
          \end{array}\right).
          :label: eqnberendsenpressurescaling

The velocities are neither scaled nor rotated. Since the equations of
motion are modified by pressure coupling, the conserved energy quantity
also needs to be modified. For first order pressure coupling, the work
the barostat applies to the system every step needs to be subtracted
from the total energy to obtain the conserved energy quantity:

.. math:: - \sum_{i,j} (\mu_{ij} -\delta_{ij}) P_{ij} V =
          \sum_{i,j} 2(\mu_{ij} -\delta_{ij}) \Xi_{ij}
          :label: eqnberendsenpressureconserved

where :math:`\delta_{ij}` is the Kronecker delta and :math:`{\bf \Xi}`
is the virial. Note that the factor 2 originates from the factor
:math:`\frac{1}{2}` in the virial definition
(:eq:`eqn. %s <eqnXi>`).

In |Gromacs|, the Berendsen scaling can also be done isotropically, which
means that instead of :math:`\mathbf{P}` a diagonal matrix
with elements of size trace\ :math:`(\mathbf{P})/3` is
used. For systems with interfaces, semi-isotropic scaling can be useful.
In this case, the :math:`x/y`-directions are scaled isotropically and
the :math:`z` direction is scaled independently. The compressibility in
the :math:`x/y` or :math:`z`-direction can be set to zero, to scale only
in the other direction(s).

If you allow full anisotropic deformations and use constraints you might
have to scale more slowly or decrease your timestep to avoid errors from
the constraint algorithms.

It is important to note that although the
Berendsen pressure control algorithm yields a simulation with the
correct average pressure, it does not yield the exact NPT ensemble, and
it is not yet clear exactly what errors this approximation may yield.
We strongly advise against using it for new simulations. The only
useful role it has had recently is to ensure fast relaxation without
oscillations, e.g. at the start of a simulation for from equilibrium,
but this is now provided by the stochastic cell rescaling, which should
be used instead. For full anisotropic simulations you need to use the
Parrinello-Rahman barostat (for now). This does have the same
oscillation problems as many other correct-ensemble barostats, so if
you cannot get your initial system stable you might need to use
Berendsen briefly - but the warnings/errors you get are a reminder
it should not be used for production runs.


Stochastic cell rescaling
^^^^^^^^^^^^^^^^^^^^^^^^^

The stochastic cell rescaling algorithm is a variant of the Berendsen
algorithm that allows correct fluctuations to be sampled. Similarly
to the Berendsen algorithm, it rescales the coordinates and box vectors
every step, or every :math:`n_\mathrm{PC}` steps
with the effect of a first-order kinetic relaxation of the
pressure towards a given reference pressure :math:`P_0`.
At variance with the Berendsen algorithm, the rescaling matrix is calculated
including a stochastic term that makes volume fluctuations correct.

The isotropic version can be easily written in term of the strain
:math:`\epsilon=\log(V/V_0)` that is evolved according to the following equation
of motion

.. math:: \mbox{d}\epsilon=-\frac{\beta}{\tau_p}(P_0-P)\mbox{d}t + \sqrt{\frac{2k_BT\beta}{V\tau_p}}\mbox{d}W
          :label: eqnstochasticcellrescaling


Here, :math:`\beta` is the isothermal compressibility of the system.
It suffices to take a rough estimate because the value of :math:`\beta` only influences
the non-critical time constant of the pressure relaxation without affecting
the volume distribution itself. For water at 1 atm and 300 K
:math:`\beta = 4.6 \times 10^{-10}`
Pa\ :math:`^{-1} = 4.6 \times 10^{-5}` bar\ :math:`^{-1}`, which is
:math:`7.6 \times 10^{-4}` MD units (see chapter :ref:`defunits`). Most
other liquids have similar values.

Another difference with respect to the Berendsen algorithm is that
velocities are scaled with a factor that is the reciprocal of the
scaling factor for positions.

A semi-isotropic implementation is also provided. By defining the variables
:math:`\epsilon_{xy}=\log(A/A_0)` and :math:`\epsilon_z=\log(L/L_0)`,
where :math:`A` and :math:`L` are the area of the simulation box in the
:math:`xy` plane and its height, respectively, the following equations
can be obtained:

.. math:: \mbox{d}\epsilon_{xy}=-\frac{2\beta}{3\tau_p}(P_0-\frac{\gamma}{L}-\frac{P_{xx}+P_{yy}}{2})\mbox{d}t+\sqrt{\frac{4k_BT\beta}{3V\tau_p}}\mbox{d}W_{xy}
          :label: eqnstochasticcellrescalingxy

.. math:: \mbox{d}\epsilon_z=-\frac{\beta}{3\tau_p}(P_0-P_{zz})\mbox{d}t + \sqrt{\frac{2k_BT\beta}{3V\tau_p}}\mbox{d}W_z
          :label: eqnstochasticcellrescalingz

Here :math:`\gamma` is the external surface tension and :math:`P_{xx}`,
:math:`P_{yy}`, and :math:`P_{zz}` the components of the internal pressure.

More detailed explanations can be found in the original reference \ :ref:`184 <refBernetti2020>`.


Parrinello-Rahman pressure coupling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In cases where the fluctuations in pressure or volume are important *per
se* (*e.g.* to calculate thermodynamic properties), especially for small
systems, it may be a problem that the exact ensemble is not well defined
for the weak-coupling scheme, and that it does not simulate the true NPT
ensemble.

|Gromacs| also supports constant-pressure simulations using the
Parrinello-Rahman approach \ :ref:`38 <refParrinello81>`,
:ref:`39 <refNose83>`, which is similar to the Nosé-Hoover temperature
coupling, and in theory gives the true NPT ensemble. With the
Parrinello-Rahman barostat, the box vectors as represented by the matrix
obey the matrix equation of motion [2]_

.. math:: \frac{{\mbox{d}}\mathbf{b}^2}{{\mbox{d}}t^2}= V \mathbf{W}^{-1} \mathbf{b}'^{-1} \left( \mathbf{P} - \mathbf{P}_{ref}\right).
          :label: eqnPRpressure

The volume of the box is denoted :math:`V`, and
:math:`\mathbf{W}` is a matrix parameter that determines
the strength of the coupling. The matrices and :math:`_{ref}` are the
current and reference pressures, respectively.

The equations of motion for the particles are also changed, just as for
the Nosé-Hoover coupling. In most cases you would combine the
Parrinello-Rahman barostat with the Nosé-Hoover thermostat, but to keep
it simple we only show the Parrinello-Rahman modification here. The
modified Hamiltonian, which will be conserved, is:

.. math:: E_\mathrm{pot} + E_\mathrm{kin} +  \sum_i P_{ii} V +
          \sum_{i,j} \frac{1}{2} W_{ij}  \left( \frac{{\mbox{d}}b_{ij}}{{\mbox{d}}t} \right)^2
          :label: eqnPRpressureconserved

The equations of motion for the atoms, obtained from the Hamiltonian
are:

.. math:: \begin{aligned}
          \frac {{\mbox{d}}^2\mathbf{r}_i}{{\mbox{d}}t^2} & = & \frac{\mathbf{F}_i}{m_i} -
          \mathbf{M} \frac{{\mbox{d}}\mathbf{r}_i}{{\mbox{d}}t} , \\ \mathbf{M} & = & \mathbf{b}^{-1} \left[
          \mathbf{b} \frac{{\mbox{d}}\mathbf{b}'}{{\mbox{d}}t} + \frac{{\mbox{d}}\mathbf{b}}{{\mbox{d}}t} \mathbf{b}'
          \right] \mathbf{b}'^{-1}.
          \end{aligned}
          :label: eqnPRpressuremotion

This extra term has the appearance of a friction, but it should be
noted that it is ficticious, and rather an effect of the
Parrinello-Rahman equations of motion being defined with all particle
coordinates represented relative to the box vectors, while |Gromacs| uses
normal Cartesian coordinates for positions, velocities and forces. It is
worth noting that the kinetic energy too should formally be calculated
based on velocities relative to the box vectors. This can have an effect
e.g. for external constant stress, but for now we only support coupling
to constant external pressures, and for any normal simulation the
velocities of box vectors should be extremely small compared to particle
velocities. Gang Liu has done some work on deriving this for Cartesian
coordinates\ :ref:`40 <refLiu2015>` that we will try to implement at some
point in the future together with support for external stress.

The (inverse) mass parameter matrix
:math:`\mathbf{W}^{-1}` determines the strength of the
coupling, and how the box can be deformed. The box restriction
(:eq:`%s <eqnboxrot>`) will be fulfilled automatically if the corresponding
elements of :math:`\mathbf{W}^{-1}` are zero. Since the
coupling strength also depends on the size of your box, we prefer to
calculate it automatically in |Gromacs|. You only have to provide the
approximate isothermal compressibilities :math:`\beta` and the pressure
time constant :math:`\tau_p` in the input file (:math:`L` is the largest
box matrix element):

.. math:: \left(
          \mathbf{W}^{-1} \right)_{ij} = \frac{4 \pi^2 \beta_{ij}}{3 \tau_p^2 L}.
          :label: eqnPRpressuretimeconst

Just as for the Nosé-Hoover thermostat, you should realize that the
Parrinello-Rahman time constant is *not* equivalent to the relaxation
time used in the Berendsen pressure coupling algorithm. In most cases
you will need to use a 4–5 times larger time constant with
Parrinello-Rahman coupling. If your pressure is very far from
equilibrium, the Parrinello-Rahman coupling may result in very large box
oscillations that could even crash your run. In that case you would have
to increase the time constant, or (better) use the weak-coupling scheme
to reach the target pressure, and then switch to Parrinello-Rahman
coupling once the system is in equilibrium. Additionally, using the
leap-frog algorithm, the pressure at time :math:`t` is not available
until after the time step has completed, and so the pressure from the
previous step must be used, which makes the algorithm not directly
reversible, and may not be appropriate for high precision thermodynamic
calculations.

Surface-tension coupling
^^^^^^^^^^^^^^^^^^^^^^^^

When a periodic system consists of more than one phase, separated by
surfaces which are parallel to the :math:`xy`-plane, the surface tension
and the :math:`z`-component of the pressure can be coupled to a pressure
bath. Presently, this only works with the Berendsen pressure coupling
algorithm in |Gromacs|. The average surface tension :math:`\gamma(t)` can
be calculated from the difference between the normal and the lateral
pressure

.. math:: \begin{aligned}
          \gamma(t) & = & 
          \frac{1}{n} \int_0^{L_z}
          \left\{ P_{zz}(z,t) - \frac{P_{xx}(z,t) + P_{yy}(z,t)}{2} \right\} \mbox{d}z \\
          & = &
          \frac{L_z}{n} \left\{ P_{zz}(t) - \frac{P_{xx}(t) + P_{yy}(t)}{2} \right\},\end{aligned}
          :label: eqnsurftenscoupl

where :math:`L_z` is the height of the box and :math:`n` is the number
of surfaces. The pressure in the z-direction is corrected by scaling the
height of the box with :math:`\mu_{zz}`

.. math:: \Delta P_{zz} = \frac{\Delta t}{\tau_p} \{ P_{0zz} - P_{zz}(t) \}
          :label: eqnzpressure

.. math:: \mu_{zz} = 1 + \beta_{zz} \Delta P_{zz}
          :label: eqnzpressure2

This is similar to normal pressure coupling, except that the factor of
:math:`1/3` is missing. The pressure correction in the
:math:`z`-direction is then used to get the correct convergence for the
surface tension to the reference value :math:`\gamma_0`. The correction
factor for the box length in the :math:`x`/:math:`y`-direction is

.. math:: \mu_{x/y} = 1 + \frac{\Delta t}{2\,\tau_p} \beta_{x/y}
          \left( \frac{n \gamma_0}{\mu_{zz} L_z}
          - \left\{ P_{zz}(t)+\Delta P_{zz} - \frac{P_{xx}(t) + P_{yy}(t)}{2} \right\} 
          \right)
          :label: eqnboxlengthcorr

The value of :math:`\beta_{zz}` is more critical than with normal
pressure coupling. Normally an incorrect compressibility will just scale
:math:`\tau_p`, but with surface tension coupling it affects the
convergence of the surface tension. When :math:`\beta_{zz}` is set to
zero (constant box height), :math:`\Delta P_{zz}` is also set to zero,
which is necessary for obtaining the correct surface tension.

MTTK pressure control algorithms
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

As mentioned in the previous section, one weakness of leap-frog
integration is in constant pressure simulations, since the pressure
requires a calculation of both the virial and the kinetic energy at the
full time step; for leap-frog, this information is not available until
*after* the full timestep. Velocity Verlet does allow the calculation,
at the cost of an extra round of global communication, and can compute,
mod any integration errors, the true NPT ensemble.

The full equations, combining both pressure coupling and temperature
coupling, are taken from Martyna *et al.*  :ref:`35 <refMartyna1996>` and
Tuckerman \ :ref:`41 <refTuckerman2006>` and are referred to here as MTTK
equations (Martyna-Tuckerman-Tobias-Klein). We introduce for convenience
:math:`\epsilon = (1/3)\ln (V/V_0)`, where :math:`V_0` is a reference
volume. The momentum of :math:`\epsilon` is
:math:`{v_{\epsilon}}= p_{\epsilon}/W =
\dot{\epsilon} = \dot{V}/3V`, and define :math:`\alpha = 1 + 3/N_{dof}`
(see Ref \ :ref:`41 <refTuckerman2006>`)

The isobaric equations are

.. math:: \begin{aligned}
          \dot{{{\mathbf{r}}}}_i &=& \frac{{{\mathbf{p}}}_i}{m_i} + \frac{{p_{\epsilon}}}{W} {{\mathbf{r}}}_i \nonumber \\
          \frac{\dot{{{\mathbf{p}}}}_i}{m_i} &=& \frac{1}{m_i}{{\mathbf{F}}}_i - \alpha\frac{{p_{\epsilon}}}{W} \frac{{{\mathbf{p}}}_i}{m_i} \nonumber \\
          \dot{\epsilon} &=& \frac{{p_{\epsilon}}}{W} \nonumber \\
          \frac{\dot{{p_{\epsilon}}}}{W} &=& \frac{3V}{W}(P_{\mathrm{int}} - P) + (\alpha-1)\left(\sum_{n=1}^N\frac{{{\mathbf{p}}}_i^2}{m_i}\right),\\\end{aligned}
          :label: eqnMTTKisobaric

where

.. math:: \begin{aligned}
          P_{\mathrm{int}} &=& P_{\mathrm{kin}} -P_{\mathrm{vir}} = \frac{1}{3V}\left[\sum_{i=1}^N \left(\frac{{{\mathbf{p}}}_i^2}{2m_i} - {{\mathbf{r}}}_i \cdot {{\mathbf{F}}}_i\
          \right)\right].\end{aligned}
          :label: eqnMTTKisobaric2

The terms including :math:`\alpha` are required to make phase space
incompressible \ :ref:`41 <refTuckerman2006>`. The :math:`\epsilon`
acceleration term can be rewritten as

.. math:: \begin{aligned}
          \frac{\dot{{p_{\epsilon}}}}{W} &=& \frac{3V}{W}\left(\alpha P_{\mathrm{kin}} - P_{\mathrm{vir}} - P\right)\end{aligned}
          :label: eqnMTTKaccel

In terms of velocities, these equations become

.. math:: \begin{aligned}
          \dot{{{\mathbf{r}}}}_i &=& {{\mathbf{v}}}_i + {v_{\epsilon}}{{\mathbf{r}}}_i \nonumber \\
          \dot{{{\mathbf{v}}}}_i &=& \frac{1}{m_i}{{\mathbf{F}}}_i - \alpha{v_{\epsilon}}{{\mathbf{v}}}_i \nonumber \\
          \dot{\epsilon} &=& {v_{\epsilon}}\nonumber \\
          \dot{{v_{\epsilon}}} &=& \frac{3V}{W}(P_{\mathrm{int}} - P) + (\alpha-1)\left( \sum_{n=1}^N \frac{1}{2} m_i {{\mathbf{v}}}_i^2\right)\nonumber \\
          P_{\mathrm{int}} &=& P_{\mathrm{kin}} - P_{\mathrm{vir}} = \frac{1}{3V}\left[\sum_{i=1}^N \left(\frac{1}{2} m_i{{\mathbf{v}}}_i^2 - {{\mathbf{r}}}_i \cdot {{\mathbf{F}}}_i\right)\right]\end{aligned}
          :label: eqnMTTKvel

For these equations, the conserved quantity is

.. math:: \begin{aligned}
          H = \sum_{i=1}^{N} \frac{{{\mathbf{p}}}_i^2}{2m_i} + U\left({{\mathbf{r}}}_1,{{\mathbf{r}}}_2,\ldots,{{\mathbf{r}}}_N\right) + \frac{p_\epsilon}{2W} + PV\end{aligned}
          :label: eqnMTTKconserved

The next step is to add temperature control. Adding Nosé-Hoover chains,
including to the barostat degree of freedom, where we use :math:`\eta`
for the barostat Nosé-Hoover variables, and :math:`Q^{\prime}` for the
coupling constants of the thermostats of the barostats, we get

.. math:: \begin{aligned}
          \dot{{{\mathbf{r}}}}_i &=& \frac{{{\mathbf{p}}}_i}{m_i} + \frac{{p_{\epsilon}}}{W} {{\mathbf{r}}}_i \nonumber \\
          \frac{\dot{{{\mathbf{p}}}}_i}{m_i} &=& \frac{1}{m_i}{{\mathbf{F}}}_i - \alpha\frac{{p_{\epsilon}}}{W} \frac{{{\mathbf{p}}}_i}{m_i} - \frac{p_{\xi_1}}{Q_1}\frac{{{\mathbf{p}}}_i}{m_i}\nonumber \\
          \dot{\epsilon} &=& \frac{{p_{\epsilon}}}{W} \nonumber \\
          \frac{\dot{{p_{\epsilon}}}}{W} &=& \frac{3V}{W}(\alpha P_{\mathrm{kin}} - P_{\mathrm{vir}} - P) -\frac{p_{\eta_1}}{Q^{\prime}_1}{p_{\epsilon}}\nonumber \\
          \dot{\xi}_k &=& \frac{p_{\xi_k}}{Q_k} \nonumber \\ 
          \dot{\eta}_k &=& \frac{p_{\eta_k}}{Q^{\prime}_k} \nonumber \\
          \dot{p}_{\xi_k} &=& G_k - \frac{p_{\xi_{k+1}}}{Q_{k+1}} \;\;\;\; k=1,\ldots, M-1 \nonumber \\ 
          \dot{p}_{\eta_k} &=& G^\prime_k - \frac{p_{\eta_{k+1}}}{Q^\prime_{k+1}} \;\;\;\; k=1,\ldots, M-1 \nonumber \\
          \dot{p}_{\xi_M} &=& G_M \nonumber \\
          \dot{p}_{\eta_M} &=& G^\prime_M, \nonumber \\\end{aligned}
          :label: eqnMTTKthermandbar

where

.. math:: \begin{aligned}
          P_{\mathrm{int}} &=& P_{\mathrm{kin}} - P_{\mathrm{vir}} = \frac{1}{3V}\left[\sum_{i=1}^N \left(\frac{{{\mathbf{p}}}_i^2}{2m_i} - {{\mathbf{r}}}_i \cdot {{\mathbf{F}}}_i\right)\right] \nonumber \\
          G_1  &=& \sum_{i=1}^N \frac{{{\mathbf{p}}}^2_i}{m_i} - N_f kT \nonumber \\
          G_k  &=&  \frac{p^2_{\xi_{k-1}}}{2Q_{k-1}} - kT \;\; k = 2,\ldots,M \nonumber \\
          G^\prime_1 &=& \frac{{p_{\epsilon}}^2}{2W} - kT \nonumber \\
          G^\prime_k &=& \frac{p^2_{\eta_{k-1}}}{2Q^\prime_{k-1}} - kT \;\; k = 2,\ldots,M\end{aligned}
          :label: eqnMTTKthermandbar2

The conserved quantity is now

.. math:: \begin{aligned}
          H = \sum_{i=1}^{N} \frac{{{\mathbf{p}}}_i}{2m_i} + U\left({{\mathbf{r}}}_1,{{\mathbf{r}}}_2,\ldots,{{\mathbf{r}}}_N\right) + \frac{p^2_\epsilon}{2W} + PV + \nonumber \\
          \sum_{k=1}^M\frac{p^2_{\xi_k}}{2Q_k} +\sum_{k=1}^M\frac{p^2_{\eta_k}}{2Q^{\prime}_k} + N_{f}kT\xi_1 +  kT\sum_{i=2}^M \xi_k + kT\sum_{k=1}^M \eta_k\end{aligned}
          :label: eqnMTTKthermandbarconserved

Returning to the Trotter decomposition formalism, for pressure control
and temperature control \ :ref:`35 <refMartyna1996>` we get:

.. math:: \begin{aligned}
          iL = iL_1 + iL_2 + iL_{\epsilon,1} + iL_{\epsilon,2} + iL_{\mathrm{NHC-baro}} + iL_{\mathrm{NHC}}\end{aligned}
          :label: eqnMTTKthermandbarTrotter

where “NHC-baro” corresponds to the Nosè-Hoover chain of the barostat,
and NHC corresponds to the NHC of the particles,

.. math:: \begin{aligned}
          iL_1 &=& \sum_{i=1}^N \left[\frac{{{\mathbf{p}}}_i}{m_i} + \frac{{p_{\epsilon}}}{W}{{\mathbf{r}}}_i\right]\cdot \frac{\partial}{\partial {{\mathbf{r}}}_i} \\
          iL_2 &=& \sum_{i=1}^N {{\mathbf{F}}}_i - \alpha \frac{{p_{\epsilon}}}{W}{{\mathbf{p}}}_i \cdot \frac{\partial}{\partial {{\mathbf{p}}}_i} \\
          iL_{\epsilon,1} &=& \frac{p_\epsilon}{W} \frac{\partial}{\partial \epsilon}\\
          iL_{\epsilon,2} &=& G_{\epsilon} \frac{\partial}{\partial p_\epsilon}\end{aligned}
          :label: eqnMTTKthermandbarTrotter2

and where

.. math:: \begin{aligned}
          G_{\epsilon} = 3V\left(\alpha P_{\mathrm{kin}} - P_{\mathrm{vir}} - P\right)\end{aligned}
          :label: eqnMTTKthermandbarTrotter3

Using the Trotter decomposition, we get

.. math:: \begin{aligned}
           \exp(iL{\Delta t}) &=& \exp\left(iL_{\mathrm{NHC-baro}}{\Delta t}/2\right)\exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) \nonumber \nonumber \\
           &&\exp\left(iL_{\epsilon,2}{\Delta t}/2\right) \exp\left(iL_2 {\Delta t}/2\right) \nonumber \nonumber \\
           &&\exp\left(iL_{\epsilon,1}{\Delta t}\right) \exp\left(iL_1 {\Delta t}\right) \nonumber \nonumber \\
           &&\exp\left(iL_2 {\Delta t}/2\right) \exp\left(iL_{\epsilon,2}{\Delta t}/2\right) \nonumber \nonumber \\
           &&\exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right)\exp\left(iL_{\mathrm{NHC-baro}}{\Delta t}/2\right) + \mathcal{O}({\Delta t}^3)\end{aligned}
           :label: eqnMTTKthermandbarTrotterdecomp

The action of :math:`\exp\left(iL_1 {\Delta t}\right)` comes from the
solution of the differential equation
:math:`\dot{{{\mathbf{r}}}}_i = {{\mathbf{v}}}_i + {v_{\epsilon}}{{\mathbf{r}}}_i`
with
:math:`{{\mathbf{v}}}_i = {{\mathbf{p}}}_i/m_i`
and :math:`{v_{\epsilon}}` constant with initial condition
:math:`{{\mathbf{r}}}_i(0)`, evaluate at
:math:`t=\Delta t`. This yields the evolution

.. math:: {{\mathbf{r}}}_i({\Delta t}) = {{\mathbf{r}}}_i(0)e^{{v_{\epsilon}}{\Delta t}} + \Delta t {{\mathbf{v}}}_i(0) e^{{v_{\epsilon}}{\Delta t}/2} {\frac{\sinh{\left( {v_{\epsilon}}{\Delta t}/2\right)}}{{v_{\epsilon}}{\Delta t}/2}}.
          :label: eqnMTTKthermandbarTrotterevol

The action of :math:`\exp\left(iL_2 {\Delta t}/2\right)` comes from the
solution of the differential equation
:math:`\dot{{{\mathbf{v}}}}_i = \frac{{{\mathbf{F}}}_i}{m_i} -
\alpha{v_{\epsilon}}{{\mathbf{v}}}_i`, yielding

.. math:: {{\mathbf{v}}}_i({\Delta t}/2) = {{\mathbf{v}}}_i(0)e^{-\alpha{v_{\epsilon}}{\Delta t}/2} + \frac{\Delta t}{2m_i}{{\mathbf{F}}}_i(0) e^{-\alpha{v_{\epsilon}}{\Delta t}/4}{\frac{\sinh{\left( \alpha{v_{\epsilon}}{\Delta t}/4\right)}}{\alpha{v_{\epsilon}}{\Delta t}/4}}.
          :label: eqnMTTKthermandbarTrotterevol2

*md-vv-avek* uses the full step kinetic energies for determining the
pressure with the pressure control, but the half-step-averaged kinetic
energy for the temperatures, which can be written as a Trotter
decomposition as

.. math:: \begin{aligned}
          \exp(iL{\Delta t}) &=& \exp\left(iL_{\mathrm{NHC-baro}}{\Delta t}/2\right)\nonumber \exp\left(iL_{\epsilon,2}{\Delta t}/2\right) \exp\left(iL_2 {\Delta t}/2\right) \nonumber \\
          &&\exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) \exp\left(iL_{\epsilon,1}{\Delta t}\right) \exp\left(iL_1 {\Delta t}\right) \exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) \nonumber \\
          &&\exp\left(iL_2 {\Delta t}/2\right) \exp\left(iL_{\epsilon,2}{\Delta t}/2\right) \exp\left(iL_{\mathrm{NHC-baro}}{\Delta t}/2\right) + \mathcal{O}({\Delta t}^3)\end{aligned}
          :label: eqnvvavekTrotterdecomp

With constraints, the equations become significantly more complicated,
in that each of these equations need to be solved iteratively for the
constraint forces. Before |Gromacs| 5.1, these iterative constraints were
solved as described in \ :ref:`42 <refYu2010>`. From |Gromacs| 5.1 onward,
MTTK with constraints has been removed because of numerical stability
issues with the iterations.

Infrequent evaluation of temperature and pressure coupling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Temperature and pressure control require global communication to compute
the kinetic energy and virial, which can become costly if performed
every step for large systems. We can rearrange the Trotter decomposition
to give alternate symplectic, reversible integrator with the coupling
steps every :math:`n` steps instead of every steps. These new
integrators will diverge if the coupling time step is too large, as the
auxiliary variable integrations will not converge. However, in most
cases, long coupling times are more appropriate, as they disturb the
dynamics less \ :ref:`35 <refMartyna1996>`.

Standard velocity Verlet with Nosé-Hoover temperature control has a
Trotter expansion

.. math:: \begin{aligned}
          \exp(iL{\Delta t}) &\approx& \exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right) \exp\left(iL_2 {\Delta t}/2\right) \nonumber \\
          &&\exp\left(iL_1 {\Delta t}\right) \exp\left(iL_2 {\Delta t}/2\right) \exp\left(iL_{\mathrm{NHC}}{\Delta t}/2\right).\end{aligned}
          :label: eqnVVNHTrotter

If the Nosé-Hoover chain is sufficiently slow with respect to the
motions of the system, we can write an alternate integrator over
:math:`n` steps for velocity Verlet as

.. math:: \begin{aligned}
          \exp(iL{\Delta t}) &\approx& (\exp\left(iL_{\mathrm{NHC}}(n{\Delta t}/2)\right)\left[\exp\left(iL_2 {\Delta t}/2\right)\right. \nonumber \\
          &&\left.\exp\left(iL_1 {\Delta t}\right) \exp\left(iL_2 {\Delta t}/2\right)\right]^n \exp\left(iL_{\mathrm{NHC}}(n{\Delta t}/2)\right).\end{aligned}
          :label: eqnVVNHTrotter2

For pressure control, this becomes

.. math:: \begin{aligned}
          \exp(iL{\Delta t}) &\approx& \exp\left(iL_{\mathrm{NHC-baro}}(n{\Delta t}/2)\right)\exp\left(iL_{\mathrm{NHC}}(n{\Delta t}/2)\right) \nonumber \nonumber \\
          &&\exp\left(iL_{\epsilon,2}(n{\Delta t}/2)\right) \left[\exp\left(iL_2 {\Delta t}/2\right)\right. \nonumber \nonumber \\
          &&\exp\left(iL_{\epsilon,1}{\Delta t}\right) \exp\left(iL_1 {\Delta t}\right) \nonumber \nonumber \\
          &&\left.\exp\left(iL_2 {\Delta t}/2\right)\right]^n \exp\left(iL_{\epsilon,2}(n{\Delta t}/2)\right) \nonumber \nonumber \\
          &&\exp\left(iL_{\mathrm{NHC}}(n{\Delta t}/2)\right)\exp\left(iL_{\mathrm{NHC-baro}}(n{\Delta t}/2)\right),\end{aligned}
          :label: eqnVVNpressure

where the box volume integration occurs every step, but the auxiliary
variable integrations happen every :math:`n` steps.

The complete update algorithm
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.. _gmx_md_update:

**THE UPDATE ALGORITHM**

--------------

 
 Given:
 Positions :math:`\mathbf{r}` of all atoms at time
 :math:`t`
 Velocities :math:`\mathbf{v}` of all atoms at time
 :math:`t-{{\frac{1}{2}}{{\Delta t}}}`
 Accelerations :math:`\mathbf{F}/m` on all atoms at time
 :math:`t`.
 (Forces are computed disregarding any constraints)
 Total kinetic energy and virial at :math:`t-{{\Delta t}}`
 :math:`\Downarrow`

 1. Compute the scaling factors :math:`\lambda` and :math:`\mu`
 according to :eq:`eqns. %s <eqnlambda>` and :eq:`%s <eqnmu>`
 :math:`\Downarrow`

 2. Update and scale velocities:
 :math:`\mathbf{v}' =  \lambda (\mathbf{v} +
 \mathbf{a} \Delta t)`
 :math:`\Downarrow`

 3. Compute new unconstrained coordinates:
 :math:`\mathbf{r}' = \mathbf{r} + \mathbf{v}'
 \Delta t`
 :math:`\Downarrow`

 4. Apply constraint algorithm to coordinates:
 constrain(\ :math:`\mathbf{r}^{'} \rightarrow  \mathbf{r}'';
 \,  \mathbf{r}`)
 :math:`\Downarrow`

 5. Correct velocities for constraints:
 :math:`\mathbf{v} = (\mathbf{r}'' -
 \mathbf{r}) / \Delta t`
 :math:`\Downarrow`

 6. Scale coordinates and box:
 :math:`\mathbf{r} = \mu \mathbf{r}''; \mathbf{b} =
 \mu  \mathbf{b}`

The complete algorithm for the update of velocities and coordinates is
given using leap-frog in :ref:`the outline above <gmx_md_update>`
The SHAKE algorithm of step 4 is explained below.

|Gromacs| has a provision to *freeze* (prevent motion of) selected
particles, which must be defined as a *freeze group*. This is
implemented using a *freeze factor* :math:`\mathbf{f}_g`,
which is a vector, and differs for each freeze group (see
sec. :ref:`groupconcept`). This vector contains only zero (freeze) or one
(don’t freeze). When we take this freeze factor and the external
acceleration :math:`\mathbf{a}_h` into account the update
algorithm for the velocities becomes

.. math:: \mathbf{v}(t+{\frac{\Delta t}{2}})~=~\mathbf{f}_g * \lambda * \left[ \mathbf{v}(t-{\frac{\Delta t}{2}}) +\frac{\mathbf{F}(t)}{m}\Delta t + \mathbf{a}_h \Delta t \right],
          :label: eqntotalupdate

where :math:`g` and :math:`h` are group indices which differ per atom.

Output step
~~~~~~~~~~~

The most important output of the MD run is the *trajectory file*, which
contains particle coordinates and (optionally) velocities at regular
intervals. The trajectory file contains frames that could include
positions, velocities and/or forces, as well as information about the
dimensions of the simulation volume, integration step, integration time,
etc. The interpretation of the time varies with the integrator chosen,
as described above. For Velocity Verlet integrators, velocities labeled
at time :math:`t` are for that time. For other integrators (e.g.
leap-frog, stochastic dynamics), the velocities labeled at time
:math:`t` are for time :math:`t - {{\frac{1}{2}}{{\Delta t}}}`.

Since the trajectory files are lengthy, one should not save every step!
To retain all information it suffices to write a frame every 15 steps,
since at least 30 steps are made per period of the highest frequency in
the system, and Shannon’s sampling theorem states that two samples per
period of the highest frequency in a band-limited signal contain all
available information. But that still gives very long files! So, if the
highest frequencies are not of interest, 10 or 20 samples per ps may
suffice. Be aware of the distortion of high-frequency motions by the
*stroboscopic effect*, called *aliasing*: higher frequencies are
mirrored with respect to the sampling frequency and appear as lower
frequencies.

|Gromacs| can also write reduced-precision coordinates for a subset of the
simulation system to a special compressed trajectory file format. All
the other tools can read and write this format. See the User Guide for
details on how to set up your :ref:`mdp` file to have :ref:`mdrun <gmx mdrun>` use this feature.

.. [1]
   Note that some derivations, an alternative notation
   :math:`\xi_{\mathrm{alt}} = v_{\xi} = p_{\xi}/Q` is used.

.. [2]
   The box matrix representation in corresponds to the transpose of the
   box matrix representation in the paper by Nosé and Klein. Because of
   this, some of our equations will look slightly different.

Parallelization
---------------

The CPU time required for a simulation can be reduced by running the
simulation in parallel over more than one core. Ideally, one would want
to have linear scaling: running on :math:`N` cores makes the simulation
:math:`N` times faster. In practice this can only be achieved for a
small number of cores. The scaling will depend a lot on the algorithms
used. Also, different algorithms can have different restrictions on the
interaction ranges between atoms.

Domain decomposition
--------------------

Since most interactions in molecular simulations are local, domain
decomposition is a natural way to decompose the system. In domain
decomposition, a spatial domain is assigned to each rank, which will
then integrate the equations of motion for the particles that currently
reside in its local domain. With domain decomposition, there are two
choices that have to be made: the division of the unit cell into domains
and the assignment of the forces to domains. Most molecular simulation
packages use the half-shell method for assigning the forces. But there
are two methods that always require less communication: the eighth
shell \ :ref:`69 <refLiem1991>` and the midpoint \ :ref:`70 <refShaw2006>`
method. |Gromacs| currently uses the eighth shell method, but
for certain systems or hardware architectures it might be advantageous
to use the midpoint method. Therefore, we might implement the midpoint
method in the future. Most of the details of the domain decomposition
can be found in the |Gromacs| 4 paper \ :ref:`5 <refHess2008b>`.

Coordinate and force communication
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the most general case of a triclinic unit cell, the space in divided
with a 1-, 2-, or 3-D grid in parallelepipeds that we call domain
decomposition cells. Each cell is assigned to a particle-particle rank.
The system is partitioned over the ranks at the beginning of each MD
step in which neighbor searching is performed. The minimum unit of
partitioning can be an atom, or a charge group with the (deprecated)
group cut-off scheme or an update group. An update group is a group
of atoms that has dependencies during update, which occurs when using
constraints and/or virtual sites. Thus different update groups can be
updated independenly. Currently update groups can only be used with at most
two sequential constraints, which is the case when only constraining
bonds involving hydrogen atoms. The advantages of update groups are that
no communication is required in the update and that this allows updating part
of the system while computing forces for other parts. Atom groups are assigned
to the cell where their center of geometry resides. Before the forces can
be calculated, the coordinates from some neighboring cells need to be
communicated, and after the forces are calculated, the forces need to be
communicated in the other direction. The communication and force
assignment is based on zones that can cover one or multiple cells. An
example of a zone setup is shown in :numref:`Fig. %s <fig-ddcells>`.

.. _fig-ddcells:

.. figure:: plots/dd-cells.*
   :width: 6.00000cm

   A non-staggered domain decomposition grid of
   3\ :math:`\times`\ 2\ :math:`\times`\ 2 cells. Coordinates in zones 1
   to 7 are communicated to the corner cell that has its home particles
   in zone 0. :math:`r_c` is the cut-off radius.

The coordinates are communicated by moving data along the “negative”
direction in :math:`x`, :math:`y` or :math:`z` to the next neighbor.
This can be done in one or multiple pulses. In :numref:`Fig. %s <fig-ddcells>` two
pulses in :math:`x` are required, then one in :math:`y` and then one in
:math:`z`. The forces are communicated by reversing this procedure. See
the |Gromacs| 4 paper \ :ref:`5 <refHess2008b>` for details on determining which
non-bonded and bonded forces should be calculated on which rank.

Dynamic load balancing
~~~~~~~~~~~~~~~~~~~~~~

When different ranks have a different computational load (load
imbalance), all ranks will have to wait for the one that takes the most
time. One would like to avoid such a situation. Load imbalance can occur
due to four reasons:

-  inhomogeneous particle distribution

-  inhomogeneous interaction cost distribution (charged/uncharged,
   water/non-water due to |Gromacs| water innerloops)

-  statistical fluctuation (only with small particle numbers)

-  differences in communication time, due to network topology and/or
   other jobs on the machine interfering with our communication

So we need a dynamic load balancing algorithm where the volume of each
domain decomposition cell can be adjusted *independently*. To achieve
this, the 2- or 3-D domain decomposition grids need to be staggered.
:numref:`Fig. %s <fig-ddtric>` shows the most general case in 2-D. Due to the
staggering, one might require two distance checks for deciding if a
charge group needs to be communicated: a non-bonded distance and a
bonded distance check.

.. _fig-ddtric:

.. figure:: plots/dd-tric.*
   :width: 7.00000cm

   The zones to communicate to the rank of zone 0, see the text
   for details. :math:`r_c` and :math:`r_b` are the non-bonded and
   bonded cut-off radii respectively, :math:`d` is an example of a
   distance between following, staggered boundaries of cells.

By default, :ref:`mdrun <gmx mdrun>` automatically turns on the dynamic load balancing
during a simulation when the total performance loss due to the force
calculation imbalance is 2% or more. **Note** that the reported force
load imbalance numbers might be higher, since the force calculation is
only part of work that needs to be done during an integration step. The
load imbalance is reported in the log file at log output steps and when
the ``-v`` option is used also on screen. The average load imbalance and the
total performance loss due to load imbalance are reported at the end of
the log file.

There is one important parameter for the dynamic load balancing, which
is the minimum allowed scaling. By default, each dimension of the domain
decomposition cell can scale down by at least a factor of 0.8. For 3-D
domain decomposition this allows cells to change their volume by about a
factor of 0.5, which should allow for compensation of a load imbalance
of 100%. The minimum allowed scaling can be changed with the
``-dds`` option of :ref:`mdrun <gmx mdrun>`.

The load imbalance is measured by timing a single region of the MD step
on each MPI rank. This region can not include MPI communication, as
timing of MPI calls does not allow separating wait due to imbalance from
actual communication. The domain volumes are then scaled, with
under-relaxation, inversely proportional with the measured time. This
procedure will decrease the load imbalance when the change in load in
the measured region correlates with the change in domain volume and the
load outside the measured region does not depend strongly on the domain
volume. In CPU-only simulations, the load is measured between the
coordinate and the force communication. In simulations with non-bonded
work on GPUs, we overlap communication and work on the CPU with
calculation on the GPU. Therefore we measure from the last communication
before the force calculation to when the CPU or GPU is finished,
whichever is last. When not using PME ranks, we subtract the time in PME
from the CPU time, as this includes MPI calls and the PME load is
independent of domain size. This generally works well, unless the
non-bonded load is low and there is imbalance in the bonded
interactions. Then two issues can arise. Dynamic load balancing can
increase the imbalance in update and constraints and with PME the
coordinate and force redistribution time can go up significantly.
Although dynamic load balancing can significantly improve performance in
cases where there is imbalance in the bonded interactions on the CPU,
there are many situations in which some domains continue decreasing in
size and the load imbalance increases and/or PME coordinate and force
redistribution cost increases significantly. As of version 2016.1, :ref:`mdrun <gmx mdrun>`
disables the dynamic load balancing when measurement indicates that it
deteriorates performance. This means that in most cases the user will
get good performance with the default, automated dynamic load balancing
setting.

.. _plincs:

Constraints in parallel
~~~~~~~~~~~~~~~~~~~~~~~

Since with domain decomposition parts of molecules can reside on
different ranks, bond constraints can cross cell boundaries.
This will not happen in |Gromacs| when update groups are used, which happens
when only bonds involving hydrogens are constrained. Then atoms connected
by constraints are assigned to the same domain. But without update groups
a parallel constraint algorithm is required. |Gromacs| uses the P-LINCS
algorithm \ :ref:`50 <refHess2008a>`, which is the parallel version of the LINCS
algorithm \ :ref:`49 <refHess97>` (see :ref:`lincs`). The P-LINCS procedure
is illustrated in :numref:`Fig. %s <fig-plincs>`. When molecules cross the cell
boundaries, atoms in such molecules up to (``lincs_order + 1``) bonds away
are communicated over the cell boundaries. Then, the normal LINCS
algorithm can be applied to the local bonds plus the communicated ones.
After this procedure, the local bonds are correctly constrained, even
though the extra communicated ones are not. One coordinate communication
step is required for the initial LINCS step and one for each iteration.
Forces do not need to be communicated.

.. _fig-plincs:

.. figure:: plots/par-lincs2.*
   :width: 6.00000cm

   Example of the parallel setup of P-LINCS with one molecule
   split over three domain decomposition cells, using a matrix expansion
   order of 3. The top part shows which atom coordinates need to be
   communicated to which cells. The bottom parts show the local
   constraints (solid) and the non-local constraints (dashed) for each
   of the three cells.

Interaction ranges
~~~~~~~~~~~~~~~~~~

Domain decomposition takes advantage of the locality of interactions.
This means that there will be limitations on the range of interactions.
By default, :ref:`mdrun <gmx mdrun>` tries to find the optimal balance between interaction
range and efficiency. But it can happen that a simulation stops with an
error message about missing interactions, or that a simulation might run
slightly faster with shorter interaction ranges. A list of interaction
ranges and their default values is given in :numref:`Table %s <table-ddranges>`

.. |nbrange| replace:: :math:`r_c`\ =\ max(\ :math:`r_{\mathrm{list}}`\ ,\ :math:`r_{\mathrm{VdW}}`\ ,\ :math:`r_{\mathrm{Coul}}`\ )
.. |tbrange| replace:: max(:math:`r_{\mathrm{mb}}`\ ,\ :math:`r_c`) 
.. |mbrange| replace:: :math:`r_{\mathrm{mb}}` 
.. |csrange| replace:: :math:`r_{\mathrm{con}}`
.. |vsrange| replace:: :math:`r_{\mathrm{con}}` 
.. |mdrunr| replace:: :ref:`mdrun <gmx mdrun>` ``-rdd``
.. |mdrunc| replace:: :ref:`mdrun <gmx mdrun>` ``-rcon``

.. _table-ddranges:

.. table:: The interaction ranges with domain decomposition.
    :widths: auto
    :align: center

    +-------------------+-----------+-----------------+------------------------+
    | interaction       | range     | option          | default                |
    +===================+===========+=================+========================+
    | non-bonded        | |nbrange| | :ref:`mdp` file |                        |
    +-------------------+-----------+-----------------+------------------------+
    | two-body bonded   | |tbrange| | |mdrunr|        | starting conf. + 10%   |
    +-------------------+-----------+-----------------+------------------------+
    | multi-body bonded | |mbrange| | |mdrunr|        | starting conf. + 10%   |
    +-------------------+-----------+-----------------+------------------------+
    | constraints       | |csrange| | |mdrunc|        | est. from bond lengths |
    +-------------------+-----------+-----------------+------------------------+
    | virtual sites     | |vsrange| | |mdrunc|        | 0                      |
    +-------------------+-----------+-----------------+------------------------+

In most cases the defaults of :ref:`mdrun <gmx mdrun>` should not cause the simulation to
stop with an error message of missing interactions. The range for the
bonded interactions is determined from the distance between bonded
charge-groups in the starting configuration, with 10% added for
headroom. For the constraints, the value of :math:`r_{\mathrm{con}}` is
determined by taking the maximum distance that (``lincs_order + 1``) bonds
can cover when they all connect at angles of 120 degrees. The actual
constraint communication is not limited by :math:`r_{\mathrm{con}}`, but
by the minimum cell size :math:`L_C`, which has the following lower
limit:

.. math:: L_C \geq \max(r_{\mathrm{mb}},r_{\mathrm{con}})
          :label: eqnDDmincellsize

Without dynamic load balancing the system is actually allowed to scale
beyond this limit when pressure scaling is used. **Note** that for
triclinic boxes, :math:`L_C` is not simply the box diagonal component
divided by the number of cells in that direction, rather it is the
shortest distance between the triclinic cells borders. For rhombic
dodecahedra this is a factor of :math:`\sqrt{3/2}` shorter along
:math:`x` and :math:`y`.

When :math:`r_{\mathrm{mb}} > r_c`, :ref:`mdrun <gmx mdrun>` employs a smart algorithm to
reduce the communication. Simply communicating all charge groups within
:math:`r_{\mathrm{mb}}` would increase the amount of communication
enormously. Therefore only charge-groups that are connected by bonded
interactions to charge groups which are not locally present are
communicated. This leads to little extra communication, but also to a
slightly increased cost for the domain decomposition setup. In some
cases, *e.g.* coarse-grained simulations with a very short cut-off, one
might want to set :math:`r_{\mathrm{mb}}` by hand to reduce this cost.

.. _mpmdpme:

Multiple-Program, Multiple-Data PME parallelization
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Electrostatics interactions are long-range, therefore special algorithms
are used to avoid summation over many atom pairs. In |Gromacs| this is
usually PME (sec. :ref:`pme`). Since with PME all particles interact with
each other, global communication is required. This will usually be the
limiting factor for scaling with domain decomposition. To reduce the
effect of this problem, we have come up with a Multiple-Program,
Multiple-Data approach \ :ref:`5 <refHess2008b>`. Here, some ranks are
selected to do only the PME mesh calculation, while the other ranks,
called particle-particle (PP) ranks, do all the rest of the work. For
rectangular boxes the optimal PP to PME rank ratio is usually 3:1, for
rhombic dodecahedra usually 2:1. When the number of PME ranks is reduced
by a factor of 4, the number of communication calls is reduced by about
a factor of 16. Or put differently, we can now scale to 4 times more
ranks. In addition, for modern 4 or 8 core machines in a network, the
effective network bandwidth for PME is quadrupled, since only a quarter
of the cores will be using the network connection on each machine during
the PME calculations.

.. _fig-mpmdpme:

.. figure:: plots/mpmd-pme.*
   :width: 12.00000cm

   Example of 8 ranks without (left) and with (right) MPMD. The
   PME communication (red arrows) is much higher on the left than on the
   right. For MPMD additional PP - PME coordinate and force
   communication (blue arrows) is required, but the total communication
   complexity is lower.

:ref:`mdrun <gmx mdrun>` will by default interleave the PP and PME ranks.
If the ranks are not number consecutively inside the machines, one might
want to use :ref:`mdrun <gmx mdrun>` ``-ddorder pp_pme``. For machines with a
real 3-D torus and proper communication software that assigns the ranks
accordingly one should use :ref:`mdrun <gmx mdrun>` ``-ddorder cartesian``.

To optimize the performance one should usually set up the cut-offs and
the PME grid such that the PME load is 25 to 33% of the total
calculation load. :ref:`grompp <gmx grompp>` will print an estimate for this load at the end
and also :ref:`mdrun <gmx mdrun>` calculates the same estimate to determine the optimal
number of PME ranks to use. For high parallelization it might be
worthwhile to optimize the PME load with the :ref:`mdp` settings and/or the
number of PME ranks with the ``-npme`` option of :ref:`mdrun <gmx mdrun>`. For changing the
electrostatics settings it is useful to know the accuracy of the
electrostatics remains nearly constant when the Coulomb cut-off and the
PME grid spacing are scaled by the same factor. **Note** that it is
usually better to overestimate than to underestimate the number of PME
ranks, since the number of PME ranks is smaller than the number of PP
ranks, which leads to less total waiting time.

The PME domain decomposition can be 1-D or 2-D along the :math:`x`
and/or :math:`y` axis. 2-D decomposition is also known as pencil
decomposition because of the shape of the domains at high
parallelization. 1-D decomposition along the :math:`y` axis can only be
used when the PP decomposition has only 1 domain along :math:`x`. 2-D
PME decomposition has to have the number of domains along :math:`x`
equal to the number of the PP decomposition. :ref:`mdrun <gmx mdrun>` automatically chooses
1-D or 2-D PME decomposition (when possible with the total given number
of ranks), based on the minimum amount of communication for the
coordinate redistribution in PME plus the communication for the grid
overlap and transposes. To avoid superfluous communication of
coordinates and forces between the PP and PME ranks, the number of DD
cells in the :math:`x` direction should ideally be the same or a
multiple of the number of PME ranks. By default, :ref:`mdrun <gmx mdrun>` takes care of
this issue.

Domain decomposition flow chart
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In :numref:`Fig. %s <fig-ddflow>` a flow chart is shown for domain decomposition
with all possible communication for different algorithms. For simpler
simulations, the same flow chart applies, without the algorithms and
communication for the algorithms that are not used.

.. _fig-ddflow:

.. figure:: plots/flowchart.*
   :width: 12.00000cm

   Flow chart showing the algorithms and communication (arrows)
   for a standard MD simulation with virtual sites, constraints and
   separate PME-mesh ranks.

.. raw:: latex

    \clearpage


Particle type
-------------

In |Gromacs|, there are three types of
particles
, see :numref:`Table %s <tab-ptype>`. Only regular atoms and virtual
interaction sites are used in |Gromacs|; shells are necessary for
polarizable models like the Shell-Water models \ :ref:`45 <refMaaren2001a>`.

.. _tab-ptype:

.. table:: Particle types in |Gromacs|

           +--------------+----------+
           | Particle     | Symbol   |
           +==============+==========+
           | atom         | A        |
           +--------------+----------+
           | shell        | S        |
           +--------------+----------+
           | virtual side | V (or D) |
           +--------------+----------+


.. _atomtype:

Atom types
~~~~~~~~~~

Each force field defines a set of atom
types,
which have a characteristic name or number, and mass (in a.m.u.). These
listings are found in the ``atomtypes.atp`` file (:ref:`atp` =
**a**\ tom **t**\ ype **p**\ arameter file). Therefore, it is in this
file that you can begin to change and/or add an atom type. This file is
only used by :ref:`gmx pdb2gmx`.
A sample from the ``gromos43a1.ff`` force field is listed below.

::

     |  O  15.99940 ;     carbonyl oxygen (C=O)
     | OM  15.99940 ;     carboxyl oxygen (CO-)
     | OA  15.99940 ;     hydroxyl, sugar or ester oxygen
     | OW  15.99940 ;     water oxygen
     |  N  14.00670 ;     peptide nitrogen (N or NH)
     | NT  14.00670 ;     terminal nitrogen (NH2)
     | NL  14.00670 ;     terminal nitrogen (NH3)
     | NR  14.00670 ;     aromatic nitrogen
     | NZ  14.00670 ;     Arg NH (NH2)
     | NE  14.00670 ;     Arg NE (NH)
     |  C  12.01100 ;     bare carbon
     |CH1  13.01900 ;     aliphatic or sugar CH-group
     |CH2  14.02700 ;     aliphatic or sugar CH2-group
     |CH3  15.03500 ;     aliphatic CH3-group

**Note:** |Gromacs| makes use of the atom types as a name, *not* as a
number (as *e.g.* in GROMOS).

The interaction parameters for the atom types are set through the
``[ atomtypes ]`` section in the topology file, often obtained through
including a force field parameter file. The atomtypes listed in
the ``atomtypes.atp`` file and the ``[ atomtypes ]`` section are
non-bonded atom types. These are used to look up the
non-bonded Van der Waals interaction parameters. Some force fields use these
same atom types to look up parameters for bonded interactions. Other force
fields additionally use bonded atom types to look up parameters for bonded
interactions. This is because there are often far fewer bonded atom types
needed than non-bonded atom types. In this case, the set of parameters for
each non-bonded atom type includes a bonded atom type. Another optional
parameter for non-bonded atom types is the atomic number. This is only
used in hybrid QM/MM simulations.


.. _vsitetop:

Virtual sites
~~~~~~~~~~~~~

Some force fields use virtual interaction sites (interaction sites that
are constructed from other particle positions) on which certain
interactions are located (*e.g.* on benzene rings, to reproduce the
correct quadrupole). This is described in sec. :ref:`virtualsites`.

To make virtual sites in your system, you should include a section
``[ virtual_sites? ]`` (for backward compatibility the old
name ``[ dummies? ]`` can also be used) in your topology
file, where the ``?`` stands for the number constructing
particles for the virtual site. This will be ``2`` for
type 2, ``3`` for types 3, 3fd, 3fad and 3out and
``4`` for type 4fdn. The last of these replace an older
4fd type (with the ‘type’ value 1) that could occasionally be unstable;
while it is still supported internally in the code, the old 4fd type
should not be used in new input files. The different types are explained
in sec. :ref:`virtualsites`.

Parameters for type 1 should look like this:

::

    [ virtual_sites1 ]
    ; Site  from        funct
    5       1           1

for type 2 like this:

::

    [ virtual_sites2 ]
    ; Site  from        funct  a
    5       1     2     1      0.7439756

for type 2fd like this:

::

    [ virtual_sites2 ]
    ; Site  from        funct  d
    5       1     2     2      -0.105

for type 3 like this:

::

    [ virtual_sites3 ]
    ; Site  from               funct   a          b
    5       1     2     3      1       0.7439756  0.128012

for type 3fd like this:

::

    [ virtual_sites3 ]
    ; Site  from               funct   a          d
    5       1     2     3      2       0.5        -0.105

for type 3fad like this:

::

    [ virtual_sites3 ]
    ; Site  from               funct   theta      d
    5       1     2     3      3       120        0.5

for type 3out like this:

::

    [ virtual_sites3 ]
    ; Site  from               funct   a          b          c
    5       1     2     3      4       -0.4       -0.4       6.9281

for type 4fdn like this:

::

    [ virtual_sites4 ]
    ; Site  from                      funct   a          b          c
    5       1     2     3     4       2       1.0        0.9       0.105

This will result in the construction of a virtual site, number 5 (first
column ``Site``), based on the positions of the atoms
whose indices are 1 and 2 or 1, 2 and 3 or 1, 2, 3 and 4 (next two,
three or four columns ``from``) following the rules
determined by the function number (next column ``funct``)
with the parameters specified (last one, two or three columns
``a b . .``). Obviously, the atom numbers (including
virtual site number) depend on the molecule. It may be instructive to
study the topologies for TIP4P or TIP5P water models that are included
with the |Gromacs| distribution.

**Note** that if any constant bonded interactions are defined between
virtual sites and/or normal atoms, they will be removed by
:ref:`grompp <gmx grompp>` (unless the option ``-normvsbds`` is used). This
removal of bonded interactions is done after generating exclusions, as
the generation of exclusions is based on “chemically” bonded
interactions.

Virtual sites can be constructed in a more generic way using basic
geometric parameters. The directive that can be used is ``[ virtual_sitesn ]``. Required
parameters are listed in :numref:`Table %s <tab-topfile2>`. An example entry for
defining a virtual site at the center of geometry of a given set of
atoms might be:

::

    [ virtual_sitesn ]
    ; Site   funct    from
    5        1        1     2     3     4
Parameter files
---------------

Atoms
~~~~~

The *static* properties (see  :numref:`Table %s <tab-statprop>`) assigned to the atom
types are assigned based on data in several places. The mass is listed
in ``atomtypes.atp`` (see :ref:`atomtype`), whereas the charge is listed
in :ref:`rtp` (:ref:`rtp` = **r**\ esidue **t**\ opology **p**\ arameter file,
see :ref:`rtp`). This implies that the charges are only defined in the
building blocks of amino acids, nucleic acids or otherwise, as defined
by the user. When generating a :ref:`topology <top>` using the :ref:`pdb2gmx <gmx pdb2gmx>`
program, the information from these files is combined.

.. _tab-statprop:

.. table:: Static atom type properties in |Gromacs|

           +----------+------------------+----------+
           | Property | Symbol           | Unit     |
           +==========+==================+==========+
           | Type     | -                | -        |
           +----------+------------------+----------+
           | Mass     | m                | a.m.u.   |
           +----------+------------------+----------+
           | Charge   | q                | electron |
           +----------+------------------+----------+
           | epsilon  | :math:`\epsilon` | kJ/mol   |
           +----------+------------------+----------+
           | sigma    | :math:`\sigma`   | nm       |
           +----------+------------------+----------+


.. _nbpar:

Non-bonded parameters
~~~~~~~~~~~~~~~~~~~~~

The non-bonded parameters consist of the van der Waals parameters V (``c6``
or :math:`\sigma`, depending on the combination rule) and W (``c12`` or
:math:`\epsilon`), as listed in the file ``ffnonbonded.itp``, where ``ptype`` is
the particle type (see :numref:`Table %s <tab-ptype>`). As with the bonded
parameters, entries in ``[ *type ]`` directives are applied to their counterparts in
the topology file. Missing parameters generate warnings, except as noted
below in section :ref:`pairinteractions`.

::

    [ atomtypes ]
    ;name   at.num      mass      charge   ptype         V(c6)        W(c12)
        O        8  15.99940       0.000       A   0.22617E-02   0.74158E-06
       OM        8  15.99940       0.000       A   0.22617E-02   0.74158E-06
       .....

    [ nonbond_params ]
      ; i    j func       V(c6)        W(c12)
        O    O    1 0.22617E-02   0.74158E-06
        O   OA    1 0.22617E-02   0.13807E-05
        .....

**Note** that most of the included force fields also include the ``at.num.``
column, but this same information is implied in the OPLS-AA ``bond_type``
column. The interpretation of the parameters V and W depends on the
combination rule that was chosen in the ``[ defaults ]`` section of the topology file
(see :ref:`topfile`):

.. math:: \begin{aligned}
          \mbox{for combination rule 1}: & &
          \begin{array}{llllll}
            \mbox{V}_{ii} & = & C^{(6)}_{i}  & = & 4\,\epsilon_i\sigma_i^{6} &
            \mbox{[ kJ mol$^{-1}$ nm$^{6}$ ]}\\
            \mbox{W}_{ii} & = & C^{(12)}_{i} & = & 4\,\epsilon_i\sigma_i^{12} &
            \mbox{[ kJ mol$^{-1}$ nm$^{12}$ ]}\\
          \end{array}
          \\
          \mbox{for combination rules 2 and 3}: & &
          \begin{array}{llll}
            \mbox{V}_{ii} & = & \sigma_i   & \mbox{[ nm ]} \\
            \mbox{W}_{ii} & = & \epsilon_i & \mbox{[ kJ mol$^{-1}$ ]}
          \end{array}\end{aligned}
          :label: eqndefcombrule

Some or all combinations for different atom types can be given in the
``[ nonbond_params ]`` section, again with parameters V and
W as defined above. Any combination that is not given will be computed
from the parameters for the corresponding atom types, according to the
combination rule:

.. math:: \begin{aligned}
          \mbox{for combination rules 1 and 3}: & &
          \begin{array}{lll}
            C^{(6)}_{ij}  & = & \left(C^{(6)}_i\,C^{(6)}_j\right)^{\frac{1}{2}} \\
            C^{(12)}_{ij} & = & \left(C^{(12)}_i\,C^{(12)}_j\right)^{\frac{1}{2}}
          \end{array}
          \\
          \mbox{for combination rule 2}: & &
          \begin{array}{lll}
            \sigma_{ij}   & = & \frac{1}{2}(\sigma_i+\sigma_j) \\
            \epsilon_{ij} & = & \sqrt{\epsilon_i\,\epsilon_j}
          \end{array}\end{aligned}
          :label: eqngivencombrule

When :math:`\sigma` and :math:`\epsilon` need to be supplied (rules 2
and 3), it would seem it is impossible to have a non-zero :math:`C^{12}`
combined with a zero :math:`C^6` parameter. However, providing a
negative :math:`\sigma` will do exactly that, such that :math:`C^6` is
set to zero and :math:`C^{12}` is calculated normally. This situation
represents a special case in reading the value of :math:`\sigma`, and
nothing more.

There is only one set of combination rules for Buckingham potentials:

.. math:: \begin{array}{rcl}
          A_{ij}   &=& \left(A_{ii} \, A_{jj}\right)^{1/2}    \\
          B_{ij}   &=& 2 / \left(\frac{1}{B_{ii}} + \frac{1}{B_{jj}}\right)        \\
          C_{ij}   &=& \left(C_{ii} \, C_{jj}\right)^{1/2}
          \end{array}
          :label: eqnbuckinghamcombrule

Bonded parameters
~~~~~~~~~~~~~~~~~

The bonded
parameters
(*i.e.* bonds, bond angles, improper and proper dihedrals) are listed in
``ffbonded.itp``.  The entries in this database describe,
respectively, the atom types in the interactions, the type of the
interaction, and the parameters associated with that interaction. These
parameters are then read by
:ref:`grompp <gmx grompp>` when processing a
topology and applied to the relevant bonded parameters, *i.e.*
``bondtypes`` are applied to entries in the
``[ bonds ]`` directive, etc. Any bonded parameter that is
missing from the relevant :``[ *type ]`` directive generates
a fatal error. The types of interactions are listed in
:numref:`Table %s <tab-topfile2>`. Example excerpts from such files
follow:

::

    [ bondtypes ]
      ; i    j func        b0          kb
        C    O    1   0.12300     502080.
        C   OM    1   0.12500     418400.
        ......

    [ angletypes ]
      ; i    j    k func       th0         cth
       HO   OA    C    1   109.500     397.480
       HO   OA  CH1    1   109.500     397.480
       ......

    [ dihedraltypes ]
      ; i    l func        q0          cq
     NR5*  NR5    2     0.000     167.360
     NR5* NR5*    2     0.000     167.360
     ......

    [ dihedraltypes ]
      ; j    k func      phi0          cp   mult
        C   OA    1   180.000      16.736      2
        C    N    1   180.000      33.472      2
        ......

    [ dihedraltypes ]
    ;
    ; Ryckaert-Bellemans Dihedrals
    ;
    ; aj    ak      funct
    CP2     CP2     3       9.2789  12.156  -13.120 -3.0597 26.240  -31.495

In the ``ffbonded.itp`` file, you can add bonded parameters.
If you want to include parameters for new atom types, make sure you
define them in ``atomtypes.atp`` as well.

For most interaction types, bonded parameters are searched and assigned
using an exact match for all type names and allowing only a single set
of parameters. The exception to this rule are
dihedral
parameters. For
``[ dihedraltypes ]`` wildcard atom type names can be
specified with the letter ``X`` in one or more of the four
positions. Thus one can for example assign proper dihedral parameters
based on the types of the middle two atoms. The parameters for the entry
with the most exact matches, i.e. the least wildcard matches, will be
used. Note that |Gromacs| versions older than 5.1.3 used the first match,
which means that a full match would be ignored if it is preceded by an
entry that matches on wildcards. Thus it is suggested to put wildcard
entries at the end, in case someone might use a forcefield with older
versions of |Gromacs|. In addition there is a dihedral type 9 which adds
the possibility of assigning multiple dihedral potentials, useful for
combining terms with different multiplicities. The different dihedral
potential parameter sets should be on directly adjacent lines in the
``[ dihedraltypes ]`` section.
Molecule definition
-------------------

Moleculetype entries
~~~~~~~~~~~~~~~~~~~~

An organizational structure that usually corresponds to molecules is the
``[ moleculetype ]`` entry. This entry serves two main
purposes. One is to give structure to the topology file(s), usually
corresponding to real molecules. This makes the topology easier to read
and writing it less labor intensive. A second purpose is computational
efficiency. The system definition that is kept in memory is proportional
in size of the ``moleculetype`` definitions. If a molecule
is present in 100000 copies, this saves a factor of 100000 in memory,
which means the system usually fits in cache, which can improve
performance tremendously. Interactions that correspond to chemical
bonds, that generate exclusions, can only be defined between atoms
within a ``moleculetype``. It is allowed to have multiple
molecules which are not covalently bonded in one
``moleculetype`` definition. Molecules can be made
infinitely long by connecting to themselves over periodic boundaries.
When such periodic molecules are present, an option in the
:ref:`mdp` file needs to be set to tell |Gromacs| not to attempt
to make molecules that are broken over periodic boundaries whole again.

Intermolecular interactions
~~~~~~~~~~~~~~~~~~~~~~~~~~~

In some cases, one would like atoms in different molecules to also
interact with other interactions than the usual non-bonded interactions.
This is often the case in binding studies. When the molecules are
covalently bound, e.g. a ligand binding covalently to a protein, they
are effectively one molecule and they should be defined in one
``[ moleculetype ]`` entry. Note that
:ref:`pdb2gmx <gmx pdb2gmx>` has an option to put two or more molecules in
one ``[ moleculetype ]`` entry. When molecules are not
covalently bound, it is much more convenient to use separate
``moleculetype`` definitions and specify the intermolecular
interactions in the ``[ intermolecular_interactions]``
section. In this section, which is placed at the end of the topology
(see :numref:`Table %s <tab-topfile1>`), normal bonded interactions
can be specified using global atom indices. The only restrictions are
that no interactions can be used that generates exclusions and no
constraints can be used.

.. _pairinteractions:

Intramolecular pair interactions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Extra Lennard-Jones and electrostatic interactions between pairs of
atoms in a molecule can be added in the ``[ pairs ]`` section of a molecule
definition. The parameters for these interactions can be set
independently from the non-bonded interaction parameters. In the GROMOS
force fields, pairs are only used to modify the 1-4 interactions
(interactions of atoms separated by three bonds). In these force fields
the 1-4 interactions are excluded from the non-bonded interactions (see
sec. :ref:`excl`).

::


    [ pairtypes ]
      ; i    j func         cs6          cs12 ; THESE ARE 1-4 INTERACTIONS
        O    O    1 0.22617E-02   0.74158E-06
        O   OM    1 0.22617E-02   0.74158E-06
        .....

The pair interaction parameters for the atom types in ``ffnonbonded.itp``
are listed in the ``[ pairtypes ]`` section. The GROMOS force fields list all these
interaction parameters explicitly, but this section might be empty for
force fields like OPLS that calculate the 1-4 interactions by uniformly
scaling the parameters. Pair parameters that are not present in the ``[ pairtypes ]``
section are only generated when ``gen-pairs`` is set to ``yes`` in the
``[ defaults ]`` directive of ``forcefield.itp`` (see :ref:`topfile`). When ``gen-pairs`` is
set to ``no``, :ref:`grompp <gmx grompp>` will give a warning for each pair type for which no
parameters are given.

The normal pair interactions, intended for 1-4 interactions, have
function type 1. Function type 2 and the ``[ pairs_nb ]`` are intended for free-energy
simulations. When determining hydration free energies, the solute needs
to be decoupled from the solvent. This can be done by adding a B-state
topology (see sec. :ref:`fecalc`) that uses zero for all solute
non-bonded parameters, *i.e.* charges and LJ parameters. However, the
free energy difference between the A and B states is not the total
hydration free energy. One has to add the free energy for reintroducing
the internal Coulomb and LJ interactions in the solute when in vacuum.
This second step can be combined with the first step when the Coulomb
and LJ interactions within the solute are not modified. For this
purpose, there is a pairs function type 2, which is identical to
function type 1, except that the B-state parameters are always identical
to the A-state parameters. For searching the parameters in the ``[ pairtypes ]`` section,
no distinction is made between function type 1 and 2. The pairs section
``[ pairs_nb ]`` is intended to replace the non-bonded interaction. It uses the unscaled
charges and the non-bonded LJ parameters; it also only uses the A-state
parameters. **Note** that one should add exclusions for all atom pairs
listed in ``[ pairs_nb ]``, otherwise such pairs will also end up in the normal neighbor
lists.

Alternatively, this same behavior can be achieved without ever touching
the topology, by using the ``couple-moltype``, ``couple-lambda0``,
``couple-lambda1``, and ``couple-intramol`` keywords. See sections
sec. :ref:`fecalc` and sec. :ref:`dgimplement` for more information.

All three pair types always use plain Coulomb interactions, even when
Reaction-field, PME, Ewald or shifted Coulomb interactions are selected
for the non-bonded interactions. Energies for types 1 and 2 are written
to the energy and log file in separate “LJ-14” and “Coulomb-14” entries
per energy group pair. Energies for ``[ pairs_nb ]`` are added to the “LJ-(SR)” and
“Coulomb-(SR)” terms.

.. _excl:

Exclusions
~~~~~~~~~~

The exclusions for non-bonded interactions are generated by :ref:`grompp <gmx grompp>` for
neighboring atoms up to a certain number of bonds away, as defined in
the ``[ moleculetype ]`` section in the topology file (see :ref:`topfile`). Particles are
considered bonded when they are connected by “chemical” bonds (``[ bonds ]`` types 1
to 5, 7 or 8) or constraints (``[ constraints ]`` type 1). Type 5 ``[ bonds ]`` can be used to create a
connection between two atoms without creating an interaction. There is a
harmonic interaction (``[ bonds ]`` type 6) that does not connect the atoms by a
chemical bond. There is also a second constraint type (``[ constraints ]`` type 2) that
fixes the distance, but does not connect the atoms by a chemical bond.
For a complete list of all these interactions, see :numref:`Table %s <tab-topfile2>`.

Extra exclusions within a molecule can be added manually in a
``[ exclusions ]`` section. Each line should start with one
atom index, followed by one or more atom indices. All non-bonded
interactions between the first atom and the other atoms will be
excluded.

When all non-bonded interactions within or between groups of atoms need
to be excluded, is it more convenient and much more efficient to use
energy monitor group exclusions (see sec. :ref:`groupconcept`).
.. _constraintalg:

Constraint algorithms
---------------------

Constraints are defined in the ``[ constraints ]`` section. The format is two atom numbers
followed by the function type, which can be 1 or 2, and the constraint
distance. The only difference between the two types is that type 1 is
used for generating exclusions and type 2 is not (see sec. :ref:`excl`).
The distances are constrained using the LINCS or the SHAKE algorithm,
which can be selected in the :ref:`mdp` file. Both types of constraints can be
perturbed in free-energy calculations by adding a second constraint
distance (see :ref:`constraintforce`). Several types of bonds and
angles (see :numref:`Table %s <tab-topfile2>`) can be converted automatically to
constraints by :ref:`grompp <gmx grompp>`. There are several options for this in the :ref:`mdp`
file.

We have also implemented the SETTLE
algorithm \ :ref:`47 <refMiyamoto92>`, which is an analytical solution of SHAKE, specifically for
water. SETTLE can be selected in the topology file. See, for instance,
the SPC molecule definition:

::

    [ moleculetype ]
    ; molname       nrexcl
    SOL             1

    [ atoms ]
    ; nr    at type res nr  ren nm  at nm   cg nr   charge
    1       OW      1       SOL     OW1     1       -0.82
    2       HW      1       SOL     HW2     1        0.41
    3       HW      1       SOL     HW3     1        0.41

    [ settles ]
    ; OW    funct   doh     dhh
    1       1       0.1     0.16333

    [ exclusions ]
    1       2       3
    2       1       3
    3       1       2

The ``[ settles ]`` directive defines the first atom of the
water molecule. The settle funct is always 1, and the distance between
O-H and H-H distances must be given. **Note** that the algorithm can
also be used for TIP3P and TIP4P \ :ref:`128 <refJorgensen83>`. TIP3P just has
another geometry. TIP4P has a virtual site, but since that is generated
it does not need to be shaken (nor stirred).
File formats
------------

.. _topfile:

Topology file
~~~~~~~~~~~~~

The topology file is built following the |Gromacs| specification for a
molecular topology. A :ref:`top` file can be generated by
:ref:`pdb2gmx <gmx pdb2gmx>`. All possible entries in the topology file are
listed in :numref:`Tables %s <tab-topfile1>` and
:numref:`%s <tab-topfile2>`. Also tabulated are: all the units of
the parameters, which interactions can be perturbed for free energy
calculations, which bonded interactions are used by
:ref:`grompp <gmx grompp>` for generating exclusions, and which bonded
interactions can be converted to constraints by :ref:`grompp <gmx grompp>`.

.. |VCR| replace:: V\ :math:`^{(cr)}`
.. |WCR| replace:: W\ :math:`^{(cr)}`
.. |CRO| replace:: :math:`^{(cr)}`
.. |TREF| replace:: :numref:`Table %s <tab-topfile2>`
.. |AKJM| replace:: :math:`a~\mathrm{kJ~mol}^{-1}`
.. |KJN6| replace:: :math:`\mathrm{kJ~mol}^{-1}~\mathrm{nm}^{-6}`
.. |BNM| replace:: :math:`b~\mathrm{nm}^{-1}`
.. |C6LJ| replace:: :math:`c_6`
.. |STAR| replace:: :math:`^{(*)}`
.. |NREX| replace:: :math:`n_{ex}^{(nrexcl)}`
.. |QEMU| replace:: :math:`q` (e); :math:`m` (u)
.. |MQM| replace:: :math:`q,m`

.. _tab-topfile1:

.. table:: The :ref:`topology <top>` file.

        +------------------------------------------------------------------------------------------------------------+
        | Parameters                                                                                                 |
        +===================+===========================+=====+====+=================================================+
        | interaction type  | directive                 | #   | f. | parameters                                      |
        |                   |                           | at. | tp |                                                 |
        +-------------------+---------------------------+-----+----+-------------------------------------------------+
        | *mandatory*       | ``defaults``              |            non-bonded function type;                       |
        |                   |                           |            combination rule\ |CRO|;                        |
        |                   |                           |            generate pairs (no/yes);                        |
        |                   |                           |            fudge LJ (); fudge QQ ()                        |
        +-------------------+---------------------------+----------+-------------------------------------------------+
        | *mandatory*       | ``atomtypes``             |            atom type; bonded type; atomic number;          |
        |                   |                           |            m (u); q (e); particle type;                    |
        |                   |                           |            |VCR| ; |WCR|                                   |
        |                   |                           |            (bonded type and atomic number are optional)    |
        +-------------------+---------------------------+----------+-------------------------------------------------+
        |                   | ``bondtypes``             |          | (see |TREF|, directive ``bonds``)               |
        +-------------------+---------------------------+------------------------------------------------------------+
        |                   | ``pairtypes``             |          | (see |TREF|, directive ``pairs``)               |
        +-------------------+---------------------------+------------------------------------------------------------+
        |                   | ``angletypes``            |          | (see |TREF|, directive ``angles``)              |
        +-------------------+---------------------------+------------------------------------------------------------+
        |                   | ``dihedraltypes``\ |STAR| |          | (see |TREF|, directive ``dihedrals``)           |
        +-------------------+---------------------------+------------------------------------------------------------+
        |                   | ``constrainttypes``       |          | (see |TREF|, directive ``constraints``)         |
        +-------------------+---------------------------+-----+----+-------------------------------------------------+
        | LJ                | ``nonbond_params``        |  2  | 1  |  |VCR|  ; |WCR|                                 |
        +-------------------+---------------------------+-----+----+-------------------------------------------------+
        | Buckingham        | ``nonbond_params``        |  2  | 2  |  |AKJM| ; |BNM|;                                |
        |                   |                           |     |    |  |C6LJ| (|KJN6|)                                |
        +-------------------+---------------------------+-----+----+-------------------------------------------------+

.. table::

        +----------------------------------------------------------------------------------------------------+-------+
        | Molecule definition(s)                                                                             | F. E. |
        +===================+===========================+=====+==============================================+=======+
        | *mandatory*       | ``moleculetype``          |     | molecule name; |NREX|                        |       |
        +-------------------+---------------------------+-----+----------------------------------------------+-------+
        | *mandatory*       | ``atoms``                 | 1   | atom type; residue number;                   | type  |
        |                   |                           |     | residue name; atom name;                     |       |
        |                   |                           |     | charge group number; |QEMU|                  | |MQM| |
        +-------------------+---------------------------+-----+----------------------------------------------+-------+
        | intra-molecular interaction and geometry definitions as described in |TREF|                                |
        +------------------------------------------------------------------------------------------------------------+

.. table::

        +-------------+---------------+------------------------------------+
        | System      |               |                                    |
        +=============+===============+====================================+
        | *mandatory* | ``system``    | system name                        |
        +-------------+---------------+------------------------------------+
        | *mandatory* | ``molecules`` | molecule name; number of molecules |
        +-------------+---------------+------------------------------------+

.. table::

        +------------------------------+----------------------------------------------------+
        | Inter-molecular interactions |                                                    |
        +==============================+====================================================+
        | *optional*                   | ``intermolecular_interactions``                    |
        +------------------------------+----------------------------------------------------+
        | one or more bonded interactions as described in |TREF|, with two or more atoms,   |
        | no interactions that generate exclusions, no constraints, use global atom numbers |
        +-----------------------------------------------------------------------------------+

-   ``# at`` is the required number of atom type indices for this directive

-   ``f. tp`` is the value used to select this function type

-   ``F. E.`` indicates which of the parameters can be interpolated in free energy calculations

-   |CRO| the combination rule determines the type of LJ parameters, see :ref:`nbpar`

-   |STAR| for ``dihedraltypes`` one can specify 4 atoms or the inner (outer for improper) 2 atoms

-   |NREX| exclude neighbors :math:`n_{ex}` bonds away for non-bonded interactions

-   For free energy calculations, type, :math:`q` and :math:`m`  or no parameters should be added for topology ``B`` (:math:`\lambda = 1`) on the same line, after the normal parameters.

.. |BZERO| replace:: :math:`b_0`
.. |KB| replace:: :math:`k_b`
.. |KDR| replace:: :math:`k_{dr}`
.. |NM2| replace:: (kJ mol\ :math:`^{-1}`\ nm\ :math:`^{-2}`
.. |NM4| replace:: (kJ mol\ :math:`^{-1}`\ nm\ :math:`^{-4}`
.. |DKJ| replace:: :math:`D` (kJ mol\ :math:`^{-1}`
.. |BETA| replace:: :math:`\beta` (nm\ :math:`^{-1}`
.. |C23| replace:: :math:`C_{i=2,3}` (kJ mol\ :math:`^{-1}`\ nm\ :math:`^{-i}`
.. |BMM| replace:: :math:`b_m`
.. |GE0| replace:: :math:`\geq 0`
.. |KO| replace:: :math:`k`
.. |KJM| replace:: kJ mol\ :math:`^{-1}`
.. |LUU| replace:: low, up\ :math:`_1`,\ :math:`_2`
.. |MV| replace:: :math:`V`
.. |MW| replace:: :math:`W`
.. |QIJ| replace:: :math:`q_i`; :math:`q_j`
.. |THE0| replace:: :math:`\theta_0`
.. |KTHE| replace:: :math:`k_\theta`
.. |KJR2| replace:: kJ mol\ :math:`^{-1}`\ rad\ :math:`^{-2}`
.. |RN13| replace:: :math:`r_{13}`
.. |KUB| replace:: :math:`k_{UB}`
.. |C024| replace:: :math:`C_{i=0,1,2,3,4}`
.. |KJRI| replace:: kJ mol\ :math:`^{-1}`\ rad\ :math:`^{-i}`
.. |PHIS| replace:: :math:`\phi_s`
.. |PHI0| replace:: :math:`\phi_0`
.. |KPHI| replace:: :math:`k_\phi`
.. |PHIK| replace:: :math:`\phi,k`
.. |KLIN| replace:: :math:`k_{lin}`
.. |XI0| replace:: :math:`\xi_0`
.. |KXI| replace:: :math:`k_\xi`
.. |C0| replace:: :math:`C_0`
.. |C1| replace:: :math:`C_1`
.. |C2| replace:: :math:`C_2`
.. |C3| replace:: :math:`C_3`
.. |C4| replace:: :math:`C_4`
.. |C5| replace:: :math:`C_5`
.. |A0| replace:: :math:`a_0`
.. |A1| replace:: :math:`a_1`
.. |A2| replace:: :math:`a_2`
.. |A3| replace:: :math:`a_3`
.. |A4| replace:: :math:`a_4`
.. |DOH| replace:: :math:`d_{\mbox{\sc oh}}`
.. |DHH| replace:: :math:`d_{\mbox{\sc hh}}`
.. |AO| replace:: :math:`a`
.. |BO| replace:: :math:`b`
.. |CO| replace:: :math:`c`
.. |DO| replace:: :math:`d`
.. |KX| replace:: :math:`k_{x}`
.. |KY| replace:: :math:`k_{y}`
.. |KZ| replace:: :math:`k_{z}`
.. |GO| replace:: :math:`g`
.. |RO| replace:: :math:`r`
.. |DPHI| replace:: :math:`\Delta\phi`
.. |DIHR| replace:: :math:`k_{\mathrm{dihr}}`
.. |THET| replace:: :math:`\theta`
.. |NM| replace:: nm\ :math:`^{-1}`
.. |KC| replace:: :math:`k_c`
.. |THEK| replace:: :math:`\theta,k`
.. |R1E| replace:: :math:`r_{1e}`
.. |R2E| replace:: :math:`r_{2e}`
.. |R3E| replace:: :math:`r_{3e}`
.. |KRR| replace:: :math:`k_{rr'}`
.. |KRTH| replace:: :math:`k_{r\theta}`
.. |ALPH| replace:: :math:`\alpha`; |CO| (U nm\ :math:`^{\alpha}`
.. |UM1| replace:: U\ :math:`^{-1}`

.. _tab-topfile2:

.. table:: Details of ``[ moleculetype ]`` directives

            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | Name of interaction                | Topology file directive    | num.       | func.     | Order of parameters and their units                                     | use in     |
            |                                    |                            | atoms [1]_ | type [2]_ |                                                                         | F.E.? [3]_ |
            +====================================+============================+============+===========+=========================================================================+============+
            | bond                               | ``bonds`` [4]_, [5]_       | 2          | 1         | |BZERO| (nm); |KB| |NM2|                                                | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | G96 bond                           | ``bonds`` [4]_, [5]_       | 2          | 2         | |BZERO| (nm); |KB| |NM4|                                                | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | Morse                              | ``bonds`` [4]_, [5]_       | 2          | 3         | |BZERO| (nm); |DKJ|; |BETA|                                             | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | cubic bond                         | ``bonds`` [4]_, [5]_       | 2          | 4         | |BZERO| (nm); |C23|                                                     |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | connection                         | ``bonds`` [4]_             | 2          | 5         |                                                                         |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | harmonic potential                 | ``bonds``                  | 2          | 6         | |BZERO| (nm); |KB| |NM2|                                                | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | FENE bond                          | ``bonds`` [4]_             | 2          | 7         | |BMM|   (nm); |KB| |NM2|                                                |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | tabulated bond                     | ``bonds`` [4]_             | 2          | 8         | table number (|GE0|); |KO| |KJM|                                        | |KO|       |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | tabulated bond [6]_                | ``bonds``                  | 2          | 9         | table number (|GE0|); |KO| |KJM|                                        | |KO|       |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | restraint potential                | ``bonds``                  | 2          | 10        | |LUU| (nm); |KDR| (|NM2|)                                               | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | extra LJ or Coulomb                | ``pairs``                  | 2          | 1         | |MV| [7]_; |MW| [7]_                                                    | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | extra LJ or Coulomb                | ``pairs``                  | 2          | 2         | fudge QQ (); |QIJ| (e), |MV| [7]_; |MW| [7]_                            |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | extra LJ or Coulomb                | ``pairs_nb``               | 2          | 1         | |QIJ| (e); |MV| [7]_; |MW| [7]_                                         |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | angle                              | ``angles`` [5]_            | 3          | 1         | |THE0| (deg); |KTHE| (|KJR2|)                                           | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | G96 angle                          | ``angles`` [5]_            | 3          | 2         | |THE0| (deg); |KTHE| (|KJM|)                                            | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | cross bond-bond                    | ``angles``                 | 3          | 3         | |R1E|, |R2E| (nm); |KRR| (|NM2|)                                        |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | cross bond-angle                   | ``angles``                 | 3          | 4         | |R1E|, |R2E|, |R3E| (nm); |KRTH| (|NM2|)                                |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | Urey-Bradley                       | ``angles`` [5]_            | 3          | 5         | |THE0| (deg); |KTHE| (|KJR2|); |RN13| (nm); |KUB| (|NM2|)               | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | quartic angle                      | ``angles`` [5]_            | 3          | 6         | |THE0| (deg); |C024| (|KJRI|)                                           |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | tabulated angle                    | ``angles``                 | 3          | 8         | table number (|GE0|); |KO| (|KJM|)                                      | |KO|       |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | linear angle                       | ``angles``                 | 3          | 9         | |A0|; |KLIN| (|NM2|)                                                    | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            |  |  restricted                     |                            |            |           |                                                                         |            |
            |  |  bending potential              | ``angles``                 | 3          | 10        | |THE0| (deg); |KTHE| (|KJM|)                                            |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | proper dihedral                    | ``dihedrals``              | 4          | 1         | |PHIS| (deg); |KPHI| (|KJM|); multiplicity                              | |PHIK|     |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | improper dihedral                  | ``dihedrals``              | 4          | 2         | |XI0| (deg); |KXI| (|KJR2|)                                             | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | Ryckaert-Bellemans dihedral        | ``dihedrals``              | 4          | 3         | |C0|, |C1|, |C2|, |C3|, |C4|, |C5| (|KJM|)                              | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | periodic improper dihedral         | ``dihedrals``              | 4          | 4         | |PHIS| (deg); |KPHI| (|KJM|); multiplicity                              | |PHIK|     |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | Fourier dihedral                   | ``dihedrals``              | 4          | 5         | |C1|, |C2|, |C3|, |C4|, |C5| (|KJM|)                                    | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | tabulated dihedral                 | ``dihedrals``              | 4          | 8         | table number (|GE0|); |KO| (|KJM|)                                      | |KO|       |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | proper dihedral (multiple)         | ``dihedrals``              | 4          | 9         | |PHIS| (deg); |KPHI| (|KJM|); multiplicity                              | |PHIK|     |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | restricted dihedral                | ``dihedrals``              | 4          | 10        | |PHI0| (deg); |KPHI| (|KJM|)                                            |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | combined bending-torsion potential | ``dihedrals``              | 4          | 11        | |KPHI| (|KJM|); |A0|, |A1|, |A2|, |A3|, |A4|                            |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | exclusions                         | ``exclusions``             | 1          |           | one or more atom indices                                                |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | constraint                         | ``constraints`` [4]_       | 2          | 1         | |BZERO| (nm)                                                            | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | constraint [6]_                    | ``constraints``            | 2          | 2         | |BZERO| (nm)                                                            | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | SETTLE                             | ``settles``                | 1          | 1         | |DOH|, |DHH| (nm)                                                       |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | 1-body virtual site                | ``virtual_sites1``         | 2          | 0         |                                                                         |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | 2-body virtual site                | ``virtual_sites2``         | 3          | 1         | |AO| ()                                                                 |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | 2-body virtual site (fd)           | ``virtual_sites2``         | 3          | 2         | |DO| (nm)                                                               |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | 3-body virtual site                | ``virtual_sites3``         | 4          | 1         | |AO|, |BO| ()                                                           |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | 3-body virtual site (fd)           | ``virtual_sites3``         | 4          | 2         | |AO| (); |DO| (nm)                                                      |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | 3-body virtual site (fad)          | ``virtual_sites3``         | 4          | 3         | |THET| (deg); |DO| (nm)                                                 |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | 3-body virtual site (out)          | ``virtual_sites3``         | 4          | 4         | |AO|, |BO| (); |CO| (|NM|)                                              |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | 4-body virtual site (fdn)          | ``virtual_sites4``         | 5          | 2         | |AO|, |BO| (); |CO| (nm)                                                |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | N-body virtual site (COG)          | ``virtual_sitesn``         | 1          | 1         | one or more constructing atom indices                                   |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | N-body virtual site (COM)          | ``virtual_sitesn``         | 1          | 2         | one or more constructing atom indices                                   |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | N-body virtual site (COW)          | ``virtual_sitesn``         | 1          | 3         |  |  one or more pairs consisting of                                     |            |
            |                                    |                            |            |           |  |  constructing atom index and weight                                  |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | position restraint                 | ``position_restraints``    | 1          | 1         | |KX|, |KY|, |KZ| (|NM2|)                                                | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | flat-bottomed position restraint   | ``position_restraints``    | 1          | 2         | |GO|, |RO| (nm), |KO| (|NM2|)                                           |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | distance restraint                 | ``distance_restraints``    | 2          | 1         | type; label; |LUU| (nm); weight ()                                      |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | dihedral restraint                 | ``dihedral_restraints``    | 4          | 1         | |PHI0| (deg); |DPHI| (deg); |DIHR| (|KJR2|)                             | all        |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | orientation restraint              | ``orientation_restraints`` | 2          | 1         | exp.; label; |ALPH|; obs. (U); weight (|UM1|)                           |            |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | angle restraint                    | ``angle_restraints``       | 4          | 1         | |THE0| (deg); |KC| (|KJM|); multiplicity                                | |THEK|     |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+
            | angle restraint (z)                | ``angle_restraints_z``     | 2          | 1         | |THE0| (deg); |KC| (|KJM|); multiplicity                                | |THEK|     |
            +------------------------------------+----------------------------+------------+-----------+-------------------------------------------------------------------------+------------+

.. [1]
   The required number of atom indices for this directive

.. [2]
   The index to use to select this function type

.. [3]
   Indicates which of the parameters can be interpolated in free energy calculations

.. [4]
   This interaction type will be used by :ref:`grompp <gmx grompp>` for generating exclusions

.. [5]
   This interaction type can be converted to constraints by :ref:`grompp <gmx grompp>`

.. [7]
   The combination rule determines the type of LJ parameters, see :ref:`nbpar`

.. [6]
   No connection, and so no exclusions, are generated for this interaction

Description of the file layout:

-  Semicolon (;) and newline characters surround comments

-  On a line ending with :math:`\backslash` the newline character is
   ignored.

-  Directives are surrounded by ``[`` and ``]``

-  The topology hierarchy (which must be followed) consists of three
   levels:

   -  the parameter level, which defines certain force-field
      specifications (see :numref:`Table %s <tab-topfile1>`)

   -  the molecule level, which should contain one or more molecule
      definitions (see :numref:`Table %s <tab-topfile2>`)

   -  the system level, containing only system-specific information
      (``[ system ]`` and ``[ molecules ]``)

-  Items should be separated by spaces or tabs, not commas

-  Atoms in molecules should be numbered consecutively starting at 1

-  Atoms in the same charge group must be listed consecutively

-  Bonded atom type name must contain at least one non-digit character.

-  The file is parsed only once, which implies that no forward
   references can be treated: items must be defined before they can be
   used

-  Exclusions can be generated from the bonds or overridden manually

-  The bonded force types can be generated from the atom types or
   overridden per bond

-  It is possible to apply multiple bonded interactions of the same type
   on the same atoms

-  Descriptive comment lines and empty lines are highly recommended

-  Starting with |Gromacs| version 3.1.3, all directives at the parameter
   level can be used multiple times and there are no restrictions on the
   order, except that an atom type needs to be defined before it can be
   used in other parameter definitions

-  If parameters for a certain interaction are defined multiple times
   for the same combination of atom types the last definition is used;
   starting with |Gromacs| version 3.1.3 :ref:`grompp <gmx grompp>` generates
   a warning for parameter redefinitions with different values

-  Using one of the ``[ atoms ]``,
   ``[ bonds ]``, ``[ pairs ]``,
   ``[ angles ]``, etc. without having used
   ``[ moleculetype ]`` before is meaningless and generates
   a warning

-  Using ``[ molecules ]`` without having used
   ``[ system ]`` before is meaningless and generates a
   warning.

-  After ``[ system ]`` the only allowed directive is
   ``[ molecules ]``

-  Using an unknown string in ``[ ]`` causes all the data
   until the next directive to be ignored and generates a warning

Here is an example of a topology file, ``urea.top``:

::

    ;
    ;       Example topology file
    ;
    ; The force-field files to be included
    #include "amber99.ff/forcefield.itp"

    [ moleculetype ]
    ; name  nrexcl
    Urea         3

    [ atoms ]
       1  C  1  URE      C      1     0.880229  12.01000   ; amber C  type
       2  O  1  URE      O      2    -0.613359  16.00000   ; amber O  type
       3  N  1  URE     N1      3    -0.923545  14.01000   ; amber N  type
       4  H  1  URE    H11      4     0.395055   1.00800   ; amber H  type
       5  H  1  URE    H12      5     0.395055   1.00800   ; amber H  type
       6  N  1  URE     N2      6    -0.923545  14.01000   ; amber N  type
       7  H  1  URE    H21      7     0.395055   1.00800   ; amber H  type
       8  H  1  URE    H22      8     0.395055   1.00800   ; amber H  type

    [ bonds ]
        1    2
        1    3
        1    6
        3    4
        3    5
        6    7
        6    8

    [ dihedrals ]
    ;   ai    aj    ak    al funct  definition
         2     1     3     4   9
         2     1     3     5   9
         2     1     6     7   9
         2     1     6     8   9
         3     1     6     7   9
         3     1     6     8   9
         6     1     3     4   9
         6     1     3     5   9

    [ dihedrals ]
         3     6     1     2   4
         1     4     3     5   4
         1     7     6     8   4

    [ position_restraints ]
    ; you wouldn't normally use this for a molecule like Urea,
    ; but we include it here for didactic purposes
    ; ai   funct    fc
       1     1     1000    1000    1000 ; Restrain to a point
       2     1     1000       0    1000 ; Restrain to a line (Y-axis)
       3     1     1000       0       0 ; Restrain to a plane (Y-Z-plane)

    [ dihedral_restraints ]
    ; ai   aj    ak    al  type  phi  dphi  fc
        3    6     1    2     1  180     0  10
        1    4     3    5     1  180     0  10

    ; Include TIP3P water topology
    #include "amber99.ff/tip3p.itp"

    [ system ]
    Urea in Water

    [ molecules ]
    ;molecule name   nr.
    Urea             1
    SOL              1000

Here follows the explanatory text.

**#include “amber99.ff/forcefield.itp” :** this includes
the information for the force field you are using, including bonded and
non-bonded parameters. This example uses the AMBER99 force field, but
your simulation may use a different force field. :ref:`grompp <gmx grompp>`
will automatically go and find this file and copy-and-paste its content.
That content can be seen in
``share/top/amber99.ff/forcefield.itp}``, and it
is

::

    #define _FF_AMBER
    #define _FF_AMBER99

    [ defaults ]
    ; nbfunc        comb-rule       gen-pairs       fudgeLJ fudgeQQ
    1               2               yes             0.5     0.8333

    #include "ffnonbonded.itp"
    #include "ffbonded.itp"

The two ``#define`` statements set up the conditions so that
future parts of the topology can know that the AMBER 99 force field is
in use.

**[ defaults ] :**

-  ``nbfunc`` is the non-bonded function type. Use 1 (Lennard-Jones) or 2
   (Buckingham)

-  ``comb-rule`` is the number of the combination rule (see :ref:`nbpar`).

-  ``gen-pairs`` is for pair generation. The default is
   ‘no’, *i.e.* get 1-4 parameters from the pairtypes list. When
   parameters are not present in the list, stop with a fatal error.
   Setting ‘yes’ generates 1-4 parameters that are not present in the
   pair list from normal Lennard-Jones parameters using
   ``fudgeLJ``

-  ``fudgeLJ`` is the factor by which to multiply
   Lennard-Jones 1-4 interactions, default 1

-  ``fudgeQQ`` is the factor by which to multiply
   electrostatic 1-4 interactions, default 1

-  :math:`N` is the power for the repulsion term in a 6-\ :math:`N`
   potential (with nonbonded-type Lennard-Jones only), starting with
   |Gromacs| version 4.5, :ref:`grompp <gmx mdrun>` also reads and applies
   :math:`N`, for values not equal to 12 tabulated interaction functions
   are used (in older version you would have to use user tabulated
   interactions).

**Note** that ``gen-pairs``, ``fudgeLJ``,
``fudgeQQ``, and :math:`N` are optional.
``fudgeLJ`` is only used when generate pairs is set to
‘yes’, and ``fudgeQQ`` is always used. However, if you want
to specify :math:`N` you need to give a value for the other parameters
as well.

Then some other ``#include`` statements add in the large
amount of data needed to describe the rest of the force field. We will
skip these and return to ``urea.top``. There we will see

**[ moleculetype ] :** defines the name of your molecule
in this :ref:`top` and nrexcl = 3 stands for excluding
non-bonded interactions between atoms that are no further than 3 bonds
away.

**[ atoms ] :** defines the molecule, where
``nr`` and ``type`` are fixed, the rest is user
defined. So ``atom`` can be named as you like,
``cgnr`` made larger or smaller (if possible, the total
charge of a charge group should be zero), and charges can be changed
here too.

**[ bonds ] :** no comment.

**[ pairs ] :** LJ and Coulomb 1-4 interactions

**[ angles ] :** no comment

**[ dihedrals ] :** in this case there are 9 proper
dihedrals (funct = 1), 3 improper (funct = 4) and no Ryckaert-Bellemans
type dihedrals. If you want to include Ryckaert-Bellemans type dihedrals
in a topology, do the following (in case of *e.g.* decane):

::

    [ dihedrals ]
    ;  ai    aj    ak    al funct       c0       c1       c2
        1    2     3     4     3
        2    3     4     5     3

In the original implementation of the potential for
alkanes \ :ref:`131 <refRyckaert78>` no 1-4 interactions were used, which means that in
order to implement that particular force field you need to remove the
1-4 interactions from the ``[ pairs ]`` section of your
topology. In most modern force fields, like OPLS/AA or Amber the rules
are different, and the Ryckaert-Bellemans potential is used as a cosine
series in combination with 1-4 interactions.

**[ position_restraints ] :** harmonically restrain the selected particles to reference
positions (:ref:`positionrestraint`). The reference positions are read
from a separate coordinate file by :ref:`grompp <gmx grompp>`.

**[ dihedral_restraints ] :** restrain selected dihedrals to a reference value. The
implementation of dihedral restraints is described in section
:ref:`dihedralrestraint` of the manual. The parameters specified in
the ``[dihedral_restraints]`` directive are as follows:

-  ``type`` has only one possible value which is 1

-  ``phi`` is the value of :math:`\phi_0` in :eq:`eqn. %s <eqndphi>` and
   :eq:`eqn. %s <eqndihre>` of the manual.

-  ``dphi`` is the value of :math:`\Delta\phi` in :eq:`eqn. %s <eqndihre>` of the
   manual.

-  ``fc`` is the force constant :math:`k_{dihr}` in :eq:`eqn. %s <eqndihre>` of the
   manual.

**#include “tip3p.itp” :** includes a topology file that was already
constructed (see section :ref:`molitp`).

**[ system ] :** title of your system, user-defined

**[ molecules ] :** this defines the total number of (sub)molecules in your system
that are defined in this :ref:`top`. In this example file, it stands for 1
urea molecule dissolved in 1000 water molecules. The molecule type ``SOL``
is defined in the ``tip3p.itp`` file. Each name here must correspond to a
name given with ``[ moleculetype ]`` earlier in the topology. The order of the blocks of
molecule types and the numbers of such molecules must match the
coordinate file that accompanies the topology when supplied to :ref:`grompp <gmx grompp>`.
The blocks of molecules do not need to be contiguous, but some tools
(e.g. :ref:`genion <gmx genion>`) may act only on the first or last such block of a
particular molecule type. Also, these blocks have nothing to do with the
definition of groups (see sec. :ref:`groupconcept` and
sec. :ref:`usinggroups`).

.. _molitp:

Molecule.itp file
~~~~~~~~~~~~~~~~~

If you construct a topology file you will use frequently (like the water
molecule, ``tip3p.itp``, which is already constructed for
you) it is good to make a ``molecule.itp`` file. This only
lists the information of one particular molecule and allows you to
re-use the ``[ moleculetype ]`` in multiple systems without
re-invoking :ref:`pdb2gmx <gmx pdb2gmx>` or manually copying and pasting. An
example ``urea.itp`` follows:

::

    [ moleculetype ]
    ; molname	nrexcl
    URE		3

    [ atoms ]
       1  C  1  URE      C      1     0.880229  12.01000   ; amber C  type
    ...
       8  H  1  URE    H22      8     0.395055   1.00800   ; amber H  type

    [ bonds ]
        1	2
    ...
        6	8
    [ dihedrals ]
    ;   ai    aj    ak    al funct  definition
         2     1     3     4   9
    ...
         6     1     3     5   9
    [ dihedrals ]
         3     6     1     2   4
         1     4     3     5   4
         1     7     6     8   4

Using :ref:`itp` files results in a very short
:ref:`top` file:

::

    ;
    ;       Example topology file
    ;
    ; The force field files to be included
    #include "amber99.ff/forcefield.itp"

    #include "urea.itp"

    ; Include TIP3P water topology
    #include "amber99/tip3p.itp"

    [ system ]
    Urea in Water

    [ molecules ]
    ;molecule name   nr.
    Urea             1
    SOL              1000

Ifdef statements
~~~~~~~~~~~~~~~~

A very powerful feature in |Gromacs| is the use of ``#ifdef``
statements in your :ref:`top` file. By making use of this
statement, and associated ``#define`` statements like were
seen in ``amber99.ff/forcefield.itp`` earlier,
different parameters for one molecule can be used in the same
:ref:`top` file. An example is given for TFE, where there is
an option to use different charges on the atoms: charges derived by De
Loof et al. :ref:`132 <refLoof92>` or by Van Buuren and
Berendsen \ :ref:`133 <refBuuren93a>`. In fact, you can use much of the
functionality of the C preprocessor, ``cpp``, because
:ref:`grompp <gmx grompp>` contains similar pre-processing functions to scan
the file. The way to make use of the ``#ifdef`` option is as
follows:

-  either use the option ``define = -DDeLoof`` in the
   :ref:`mdp` file (containing :ref:`grompp <gmx grompp>` input
   parameters), or use the line ``#define DeLoof`` early in
   your :ref:`top` or :ref:`itp` file; and

-  put the ``#ifdef`` statements in your
   :ref:`top`, as shown below:


::

    ...



    [ atoms ]
    ; nr     type     resnr    residu     atom      cgnr      charge        mass
    #ifdef DeLoof
    ; Use Charges from DeLoof
       1        C        1        TFE        C         1        0.74
       2        F        1        TFE        F         1       -0.25
       3        F        1        TFE        F         1       -0.25
       4        F        1        TFE        F         1       -0.25
       5      CH2        1        TFE      CH2         1        0.25
       6       OA        1        TFE       OA         1       -0.65
       7       HO        1        TFE       HO         1        0.41
    #else
    ; Use Charges from VanBuuren
       1        C        1        TFE        C         1        0.59
       2        F        1        TFE        F         1       -0.2
       3        F        1        TFE        F         1       -0.2
       4        F        1        TFE        F         1       -0.2
       5      CH2        1        TFE      CH2         1        0.26
       6       OA        1        TFE       OA         1       -0.55
       7       HO        1        TFE       HO         1        0.3
    #endif

    [ bonds ]
    ;  ai    aj funct           c0           c1
        6     7     1 1.000000e-01 3.138000e+05
        1     2     1 1.360000e-01 4.184000e+05
        1     3     1 1.360000e-01 4.184000e+05
        1     4     1 1.360000e-01 4.184000e+05
        1     5     1 1.530000e-01 3.347000e+05
        5     6     1 1.430000e-01 3.347000e+05
    ...

This mechanism is used by :ref:`pdb2gmx <gmx pdb2gmx>` to implement optional position
restraints (:ref:`positionrestraint`) by ``#include``-ing an :ref:`itp` file
whose contents will be meaningful only if a particular ``#define`` is set
(and spelled correctly!)

Topologies for free energy calculations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Free energy differences between two systems, A and B, can be calculated
as described in sec. :ref:`fecalc`. Systems A and B are described by
topologies consisting of the same number of molecules with the same
number of atoms. Masses and non-bonded interactions can be perturbed by
adding B parameters under the ``[ atoms ]`` directive. Bonded interactions can be
perturbed by adding B parameters to the bonded types or the bonded
interactions. The parameters that can be perturbed are listed in
:numref:`Tables %s <tab-topfile1>` and :numref:`%s <tab-topfile2>`.
The :math:`\lambda`-dependence of the
interactions is described in section sec. :ref:`feia`. The bonded
parameters that are used (on the line of the bonded interaction
definition, or the ones looked up on atom types in the bonded type
lists) is explained in :numref:`Table %s <tab-topfe>`. In most cases, things should
work intuitively. When the A and B atom types in a bonded interaction
are not all identical and parameters are not present for the B-state,
either on the line or in the bonded types, :ref:`grompp <gmx grompp>` uses the A-state
parameters and issues a warning. For free energy calculations, all or no
parameters for topology B (:math:`\lambda = 1`) should be added on the
same line, after the normal parameters, in the same order as the normal
parameters. From |Gromacs| 4.6 onward, if :math:`\lambda` is treated as a
vector, then the ``bonded-lambdas`` component controls all bonded terms that
are not explicitly labeled as restraints. Restrain terms are controlled
by the ``restraint-lambdas`` component.

.. |NOT| replace:: :math:`-`

.. _tab-topfe:

.. table:: The bonded parameters that are used for free energy topologies,
           on the line of the bonded interaction definition or looked up
           in the bond types section based on atom types. A and B indicate the
           parameters used for state A and B respectively, + and |NOT| indicate
           the (non-)presence of parameters in the topology, x indicates that
           the presence has no influence.

           +--------------------+---------------+-----------------------------------+---------+
           | B-state atom types | parameters    | parameters in   | parameters in   |         |
           |                    |               | bonded types    | bonded types    | expected|
           | all identical to   | on line       | of A atoms      | of B atoms      | message |
           |                    +-------+-------+-------+---------+-------+---------+         |
           | A-state atom types | A     | B     | A     | B       | A     | B       |         |
           +====================+=======+=======+=======+=========+=======+=========+=========+
           | yes                | +AB   | |NOT| | x     | x       |       |         |         |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | yes                | +A    | +B    | x     | x       |       |         |         |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | yes                | |NOT| | |NOT| | |NOT| | |NOT|   |       |         | error   |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | yes                | |NOT| | |NOT| | +AB   | |NOT|   |       |         |         |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | yes                | |NOT| | |NOT| | +A    | +B      |       |         |         |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | no                 | +AB   | |NOT| | x     | x       | x     | x       | warning |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | no                 | +A    | +B    | x     | x       | x     | x       |         |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | no                 | |NOT| | |NOT| | |NOT| | |NOT|   | x     | x       | error   |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | no                 | |NOT| | |NOT| | +AB   | |NOT|   | |NOT| | |NOT|   | warning |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | no                 | |NOT| | |NOT| | +A    | +B      | |NOT| | |NOT|   | warning |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | no                 | |NOT| | |NOT| | +A    | x       | +B    | |NOT|   |         |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+
           | no                 | |NOT| | |NOT| | +A    | x       | +     | +B      |         |
           +--------------------+-------+-------+-------+---------+-------+---------+---------+



Below is an example of a topology which changes from 200 propanols to
200 pentanes using the GROMOS-96 force field.

::


    ; Include force field parameters
    #include "gromos43a1.ff/forcefield.itp"

    [ moleculetype ]
    ; Name            nrexcl
    PropPent          3

    [ atoms ]
    ; nr type resnr residue atom cgnr  charge    mass  typeB chargeB  massB
      1    H    1     PROP    PH    1   0.398    1.008  CH3     0.0  15.035
      2   OA    1     PROP    PO    1  -0.548  15.9994  CH2     0.0  14.027
      3  CH2    1     PROP   PC1    1   0.150   14.027  CH2     0.0  14.027
      4  CH2    1     PROP   PC2    2   0.000   14.027
      5  CH3    1     PROP   PC3    2   0.000   15.035

    [ bonds ]
    ;  ai    aj funct    par_A  par_B
        1     2     2    gb_1   gb_26
        2     3     2    gb_17  gb_26
        3     4     2    gb_26  gb_26
        4     5     2    gb_26

    [ pairs ]
    ;  ai    aj funct
        1     4     1
        2     5     1

    [ angles ]
    ;  ai    aj    ak funct    par_A   par_B
        1     2     3     2    ga_11   ga_14
        2     3     4     2    ga_14   ga_14
        3     4     5     2    ga_14   ga_14

    [ dihedrals ]
    ;  ai    aj    ak    al funct    par_A   par_B
        1     2     3     4     1    gd_12   gd_17
        2     3     4     5     1    gd_17   gd_17

    [ system ]
    ; Name
    Propanol to Pentane

    [ molecules ]
    ; Compound        #mols
    PropPent          200

Atoms that are not perturbed, ``PC2`` and
``PC3``, do not need B-state parameter specifications, since
the B parameters will be copied from the A parameters. Bonded
interactions between atoms that are not perturbed do not need B
parameter specifications, as is the case for the last bond in the
example topology. Topologies using the OPLS/AA force field need no
bonded parameters at all, since both the A and B parameters are
determined by the atom types. Non-bonded interactions involving one or
two perturbed atoms use the free-energy perturbation functional forms.
Non-bonded interactions between two non-perturbed atoms use the normal
functional forms. This means that when, for instance, only the charge of
a particle is perturbed, its Lennard-Jones interactions will also be
affected when lambda is not equal to zero or one.

**Note** that this topology uses the GROMOS-96 force field, in which the
bonded interactions are not determined by the atom types. The bonded
interaction strings are converted by the C-preprocessor. The force-field
parameter files contain lines like:

::

    #define gb_26       0.1530  7.1500e+06

    #define gd_17     0.000       5.86          3

.. _constraintforce:

Constraint forces
~~~~~~~~~~~~~~~~~

| The constraint force between two atoms in one molecule can be
  calculated with the free energy perturbation code by adding a
  constraint between the two atoms, with a different length in the A and
  B topology. When the B length is 1 nm longer than the A length and
  lambda is kept constant at zero, the derivative of the Hamiltonian
  with respect to lambda is the constraint force. For constraints
  between molecules, the pull code can be used, see sec. :ref:`pull`.
  Below is an example for calculating the constraint force at 0.7 nm
  between two methanes in water, by combining the two methanes into one
  “molecule.” **Note** that the definition of a “molecule” in |Gromacs|
  does not necessarily correspond to the chemical definition of a
  molecule. In |Gromacs|, a “molecule” can be defined as any group of
  atoms that one wishes to consider simultaneously. The added constraint
  is of function type 2, which means that it is not used for generating
  exclusions (see sec. :ref:`excl`). Note that the constraint free energy
  term is included in the derivative term, and is specifically included
  in the ``bonded-lambdas`` component. However, the free energy for changing
  constraints is *not* included in the potential energy differences used
  for BAR and MBAR, as this requires reevaluating the energy at each of
  the constraint components. This functionality is planned for later
  versions.

::

    ; Include force-field parameters
    #include "gromos43a1.ff/forcefield.itp"

    [ moleculetype ]
    ; Name            nrexcl
    Methanes               1

    [ atoms ]
    ; nr   type   resnr  residu   atom    cgnr     charge    mass
       1    CH4     1     CH4      C1       1          0    16.043
       2    CH4     1     CH4      C2       2          0    16.043
    [ constraints ]
    ;  ai    aj funct   length_A  length_B
        1     2     2        0.7       1.7

    #include "gromos43a1.ff/spc.itp"

    [ system ]
    ; Name
    Methanes in Water

    [ molecules ]
    ; Compound        #mols
    Methanes              1
    SOL                2002

Coordinate file
~~~~~~~~~~~~~~~

Files with the :ref:`gro` file extension contain a molecular
structure in GROMOS-87 format. A sample piece is included below:

::

    MD of 2 waters, reformat step, PA aug-91
        6
        1WATER  OW1    1   0.126   1.624   1.679  0.1227 -0.0580  0.0434
        1WATER  HW2    2   0.190   1.661   1.747  0.8085  0.3191 -0.7791
        1WATER  HW3    3   0.177   1.568   1.613 -0.9045 -2.6469  1.3180
        2WATER  OW1    4   1.275   0.053   0.622  0.2519  0.3140 -0.1734
        2WATER  HW2    5   1.337   0.002   0.680 -1.0641 -1.1349  0.0257
        2WATER  HW3    6   1.326   0.120   0.568  1.9427 -0.8216 -0.0244
       1.82060   1.82060   1.82060

This format is fixed, *i.e.* all columns are in a fixed position. If you
want to read such a file in your own program without using the |Gromacs|
libraries you can use the following formats:

**C-format:**
``“%5i%5s%5s%5i%8.3f%8.3f%8.3f%8.4f%8.4f%8.4f”``

Or to be more precise, with title *etc.* it looks like this:

::

      "%s\n", Title
      "%5d\n", natoms
      for (i=0; (i<natoms); i++) {
        "%5d%-5s%5s%5d%8.3f%8.3f%8.3f%8.4f%8.4f%8.4f\n",
          residuenr,residuename,atomname,atomnr,x,y,z,vx,vy,vz
      }
      "%10.5f%10.5f%10.5f%10.5f%10.5f%10.5f%10.5f%10.5f%10.5f\n",
        box[X][X],box[Y][Y],box[Z][Z],
        box[X][Y],box[X][Z],box[Y][X],box[Y][Z],box[Z][X],box[Z][Y]

**Fortran format:**
``(i5,2a5,i5,3f8.3,3f8.4)``

So ``confin.gro`` is the |Gromacs| coordinate file and is
almost the same as the GROMOS-87 file (for GROMOS users: when used with
``ntx=7``). The only difference is the box for which |Gromacs|
uses a tensor, not a vector.
.. _pdb2gmxfiles:

:ref:`pdb2gmx <gmx pdb2gmx>` input files
----------------------------------------

The |Gromacs| program :ref:`pdb2gmx <gmx pdb2gmx>` generates a topology for the input
coordinate file. Several formats are supported for that coordinate file,
but :ref:`pdb` is the most commonly-used format (hence the name :ref:`pdb2gmx <gmx pdb2gmx>`).
:ref:`pdb2gmx <gmx pdb2gmx>` searches for force fields in sub-directories of the |Gromacs|
``share/top`` directory and your working directory. Force fields are
recognized from the file ``forcefield.itp`` in a directory with the
extension ``.ff``. The file ``forcefield.doc`` may be present, and if so, its
first line will be used by :ref:`pdb2gmx <gmx pdb2gmx>` to present a short description to the
user to help in choosing a force field. Otherwise, the user can choose a
force field with the ``-ff xxx`` command-line argument to :ref:`pdb2gmx <gmx pdb2gmx>`, which
indicates that a force field in a ``xxx.ff`` directory is desired. :ref:`pdb2gmx <gmx pdb2gmx>`
will search first in the working directory, then in the |Gromacs|
``share/top`` directory, and use the first matching ``xxx.ff`` directory found.

Two general files are read by :ref:`pdb2gmx <gmx pdb2gmx>`: an atom type file (extension
:ref:`atp`, see :ref:`atomtype`) from the force-field directory, and a file
called ``residuetypes.dat`` from either the working directory, or the
|Gromacs| ``share/top`` directory. ``residuetypes.dat`` determines which residue
names are considered protein, DNA, RNA, water, and ions.

:ref:`pdb2gmx <gmx pdb2gmx>` can read one or multiple databases with topological information
for different types of molecules. A set of files belonging to one
database should have the same basename, preferably telling something
about the type of molecules (*e.g.* aminoacids, rna, dna). The possible
files are:

-  ``<basename>.rtp``

-  ``<basename>.r2b (optional)``

-  ``<basename>.arn (optional)``

-  ``<basename>.hdb (optional)``

-  ``<basename>.n.tdb (optional)``

-  ``<basename>.c.tdb (optional)``

Only the :ref:`rtp` file, which contains the topologies of the building
blocks, is mandatory. Information from other files will only be used for
building blocks that come from an :ref:`rtp` file with the same base name. The
user can add building blocks to a force field by having additional files
with the same base name in their working directory. By default, only
extra building blocks can be defined, but calling :ref:`pdb2gmx <gmx pdb2gmx>` with the ``-rtpo``
option will allow building blocks in a local file to replace the default
ones in the force field.

Residue database
~~~~~~~~~~~~~~~~

The files holding the residue databases have the extension :ref:`rtp`.
Originally this file contained building blocks (amino acids) for
proteins, and is the |Gromacs| interpretation of the ``rt37c4.dat`` file of
GROMOS. So the residue database file contains information (bonds,
charges, charge groups, and improper dihedrals) for a frequently-used
building block. It is better *not* to change this file because it is
standard input for :ref:`pdb2gmx <gmx pdb2gmx>`, but if changes are needed make them in the
:ref:`top` file (see :ref:`topfile`), or in a :ref:`rtp` file in the working
directory as explained in sec. :ref:`pdb2gmxfiles`. Defining topologies
of new small molecules is probably easier by writing an include topology
file :ref:`itp` directly. This will be discussed in section :ref:`molitp`.
When adding a new protein residue to the database, don’t forget to add
the residue name to the residuetypes.dat file, so that :ref:`grompp <gmx grompp>`, :ref:`make_ndx <gmx make_ndx>`
and analysis tools can recognize the residue as a protein residue (see
:ref:`defaultgroups`).

The :ref:`rtp` files are only used by :ref:`pdb2gmx <gmx pdb2gmx>`. As mentioned before, the only
extra information this program needs from the :ref:`rtp` database is bonds,
charges of atoms, charge groups, and improper dihedrals, because the
rest is read from the coordinate input file. Some proteins contain
residues that are not standard, but are listed in the coordinate file.
You have to construct a building block for this “strange” residue,
otherwise you will not obtain a :ref:`top` file. This also holds for molecules
in the coordinate file such as ligands, polyatomic ions, crystallization
co-solvents, etc. The residue database is constructed in the following
way:

::

    [ bondedtypes ]  ; mandatory
    ; bonds  angles  dihedrals  impropers
         1       1          1          2  ; mandatory

    [ GLY ]  ; mandatory

     [ atoms ]  ; mandatory 
    ; name  type  charge  chargegroup 
         N     N  -0.280     0
         H     H   0.280     0
        CA   CH2   0.000     1
         C     C   0.380     2
         O     O  -0.380     2

     [ bonds ]  ; optional
    ;atom1 atom2      b0      kb
         N     H
         N    CA
        CA     C
         C     O
        -C     N

     [ exclusions ]  ; optional
    ;atom1 atom2

     [ angles ]  ; optional
    ;atom1 atom2 atom3    th0    cth

     [ dihedrals ]  ; optional
    ;atom1 atom2 atom3 atom4   phi0     cp   mult

     [ impropers ]  ; optional
    ;atom1 atom2 atom3 atom4     q0     cq
         N    -C    CA     H
        -C   -CA     N    -O

    [ ZN ]

     [ atoms ]
        ZN    ZN   2.000     0

The file is free format; the only restriction is that there can be at
most one entry on a line. The first field in the file is the ``[ bondedtypes ]`` field,
which is followed by four numbers, indicating the interaction type for
bonds, angles, dihedrals, and improper dihedrals. The file contains
residue entries, which consist of atoms and (optionally) bonds, angles,
dihedrals, and impropers. The charge group codes denote the charge group
numbers. Atoms in the same charge group should always be ordered
consecutively. When using the hydrogen database with :ref:`pdb2gmx <gmx pdb2gmx>` for adding
missing hydrogens (see :ref:`hdb`), the atom names defined in the :ref:`rtp`
entry should correspond exactly to the naming convention used in the
hydrogen database. The atom names in the bonded interaction can be
preceded by a minus or a plus, indicating that the atom is in the
preceding or following residue respectively. Explicit parameters added
to bonds, angles, dihedrals, and impropers override the standard
parameters in the :ref:`itp` files. This should only be used in special cases.
Instead of parameters, a string can be added for each bonded
interaction. This is used in GROMOS-96 :ref:`rtp` files. These strings are
copied to the topology file and can be replaced by force-field
parameters by the C-preprocessor in :ref:`grompp <gmx grompp>` using ``#define`` statements.

:ref:`pdb2gmx <gmx pdb2gmx>` automatically generates all angles. This means
that for most force fields the ``[ angles ]`` field is only
useful for overriding :ref:`itp` parameters. For the GROMOS-96
force field the interaction number of all angles needs to be specified.

:ref:`pdb2gmx <gmx pdb2gmx>` automatically generates one proper dihedral for every rotatable
bond, preferably on heavy atoms. When the ``[ dihedrals ]`` field is used, no other
dihedrals will be generated for the bonds corresponding to the specified
dihedrals. It is possible to put more than one dihedral function on a
rotatable bond. In the case of CHARMM27 FF :ref:`pdb2gmx <gmx pdb2gmx>` can add correction
maps to the dihedrals using the default ``-cmap`` option. Please refer to
:ref:`charmmff` for more information.

:ref:`pdb2gmx <gmx pdb2gmx>` sets the number of exclusions to 3, which means
that interactions between atoms connected by at most 3 bonds are
excluded. Pair interactions are generated for all pairs of atoms that
are separated by 3 bonds (except pairs of hydrogens). When more
interactions need to be excluded, or some pair interactions should not
be generated, an ``[ exclusions ]`` field can be added,
followed by pairs of atom names on separate lines. All non-bonded and
pair interactions between these atoms will be excluded.

Residue to building block database
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Each force field has its own naming convention for residues. Most
residues have consistent naming, but some, especially those with
different protonation states, can have many different names. The
:ref:`r2b` files are used to convert standard residue names to
the force-field build block names. If no :ref:`r2b` is present
in the force-field directory or a residue is not listed, the building
block name is assumed to be identical to the residue name. The
:ref:`r2b` can contain 2 or 5 columns. The 2-column format has
the residue name in the first column and the building block name in the
second. The 5-column format has 3 additional columns with the building
block for the residue occurring in the N-terminus, C-terminus and both
termini at the same time (single residue molecule). This is useful for,
for instance, the AMBER force fields. If one or more of the terminal
versions are not present, a dash should be entered in the corresponding
column.

There is a |Gromacs| naming convention for residues which is only apparent
(except for the :ref:`pdb2gmx <gmx pdb2gmx>` code) through the
:ref:`r2b` file and ``specbond.dat`` files. This
convention is only of importance when you are adding residue types to an
:ref:`rtp` file. The convention is listed in :numref:`Table %s <tab-r2b>`.
For special bonds with, for instance,
a heme group, the |Gromacs| naming convention is introduced through
``specbond.dat`` (see :ref:`specbond`),
which can subsequently be translated by the :ref:`r2b` file,
if required.

.. |NDEL| replace:: N\ :math:`_\delta`
.. |NEPS| replace:: N\ :math:`_\epsilon`

.. _tab-r2b:

.. table:: Internal |Gromacs| residue naming convention.

           +--------------+-----------------------------------------------------------+
           | |Gromacs| ID | Residue                                                   |
           +==============+===========================================================+
           | ARG          | protonated arginine                                       |
           +--------------+-----------------------------------------------------------+
           | ARGN         | neutral arginine                                          |
           +--------------+-----------------------------------------------------------+
           | ASP          | negatively charged aspartic acid                          |
           +--------------+-----------------------------------------------------------+
           | ASPH         | neutral aspartic acid                                     |
           +--------------+-----------------------------------------------------------+
           | CYS          | neutral cysteine                                          |
           +--------------+-----------------------------------------------------------+
           | CYS2         | cysteine with sulfur bound to another cysteine or a heme  |
           +--------------+-----------------------------------------------------------+
           | GLU          |  negatively charged glutamic acid                         |
           +--------------+-----------------------------------------------------------+
           | GLUH         |  neutral glutamic acid                                    |
           +--------------+------------------------------+----------------------------+
           | HISD         | neutral histidine with |NDEL| protonated                  |
           +--------------+-----------------------------------------------------------+
           | HISE         | neutral histidine with |NEPS| protonated                  |
           +--------------+------------------------------+----------------------------+
           | HISH         | positive histidine with both |NDEL| and |NEPS| protonated |
           +--------------+-----------------------------------------------------------+
           | HIS1         | histidine bound to a heme                                 |
           +--------------+-----------------------------------------------------------+
           | LYSN         | neutral lysine                                            |
           +--------------+-----------------------------------------------------------+
           | LYS          | protonated lysine                                         |
           +--------------+-----------------------------------------------------------+
           | HEME         | heme                                                      |
           +--------------+-----------------------------------------------------------+


Atom renaming database
~~~~~~~~~~~~~~~~~~~~~~

Force fields often use atom names that do not follow IUPAC or PDB
convention. The :ref:`arn` database is used to translate the
atom names in the coordinate file to the force-field names. Atoms that
are not listed keep their names. The file has three columns: the
building block name, the old atom name, and the new atom name,
respectively. The residue name supports question-mark wildcards that
match a single character.

An additional general atom renaming file called
``xlateat.dat`` is present in the ``share/top``
directory, which translates common non-standard atom names in the
coordinate file to IUPAC/PDB convention. Thus, when writing force-field
files, you can assume standard atom names and no further atom name
translation is required, except for translating from standard atom names
to the force-field ones.

Hydrogen database
~~~~~~~~~~~~~~~~~

The hydrogen database is stored in :ref:`hdb` files. It contains information
for the :ref:`pdb2gmx <gmx pdb2gmx>` program on how to connect hydrogen atoms to existing
atoms. In versions of the database before |Gromacs| 3.3, hydrogen atoms
were named after the atom they are connected to: the first letter of the
atom name was replaced by an ‘H.’ In the versions from 3.3 onwards, the
H atom has to be listed explicitly, because the old behavior was
protein-specific and hence could not be generalized to other molecules.
If more than one hydrogen atom is connected to the same atom, a number
will be added to the end of the hydrogen atom name. For example, adding
two hydrogen atoms to ``ND2`` (in asparagine), the hydrogen atoms will
be named ``HD21`` and ``HD22``. This is important since atom naming in
the :ref:`rtp` file (see :ref:`rtp`) must be the same. The format of the
hydrogen database is as follows:

::

    ; res   # additions
            # H add type    H       i       j       k
    ALA     1
            1       1       H       N       -C      CA
    ARG     4
            1       2       H       N       CA      C
            1       1       HE      NE      CD      CZ
            2       3       HH1     NH1     CZ      NE
            2       3       HH2     NH2     CZ      NE

On the first line we see the residue name (ALA or ARG) and the number of
kinds of hydrogen atoms that may be added to this residue by the
hydrogen database. After that follows one line for each addition, on
which we see:

-  The number of H atoms added

-  The method for adding H atoms, which can be any of:

   #. | *one planar hydrogen*, *e.g.* *rings or peptide bond*
      | One hydrogen atom (n) is generated, lying in the plane of atoms
        (i,j,k) on the plane bisecting angle (j-i-k) at a distance of
        0.1 nm from atom i, such that the angles (n-i-j) and (n-i-k) are
        :math:`>` 90\ :math:`^{\rm o}`.

   #. | *one single hydrogen*, *e.g.* *hydroxyl*
      | One hydrogen atom (n) is generated at a distance of 0.1 nm from
        atom i, such that angle (n-i-j)=109.5 degrees and dihedral
        (n-i-j-k)=trans.

   #. | *two planar hydrogens*, *e.g.* *ethylene -C=CH*\ :math:`_2`, *or amide
        -C(=O)NH*\ :math:`_2`
      | Two hydrogens (n1,n2) are generated at a distance of 0.1 nm from
        atom i, such that angle (n1-i-j)=(n2-i-j)=120 degrees and
        dihedral (n1-i-j-k)=cis and (n2-i-j-k)=trans, such that names
        are according to IUPAC standards \ :ref:`129 <refiupac70>`.

   #. | *two or three tetrahedral hydrogens*, *e.g.* *-CH*\ :math:`_3`
      | Three (n1,n2,n3) or two (n1,n2) hydrogens are generated at a
        distance of 0.1 nm from atom i, such that angle
        (n1-i-j)=(n2-i-j)=(n3-i-j)=109.47\ :math:`^{\rm o}`, dihedral
        (n1-i-j-k)=trans, (n2-i-j-k)=trans+120 and
        (n3-i-j-k)=trans+240\ :math:`^{\rm o}`.

   #. | *one tetrahedral hydrogen*, *e.g.* *C*\ :math:`_3`\ *CH*
      | One hydrogen atom (n\ :math:`^\prime`) is generated at a distance
        of 0.1 nm from atom i in tetrahedral conformation such that
        angle
        (n\ :math:`^\prime`-i-j)=(n\ :math:`^\prime`-i-k)=(n\ :math:`^\prime`-i-l)=109.47\ :math:`^{\rm o}`.

   #. | *two tetrahedral hydrogens*, *e.g.* *C-CH*\ :math:`_2`\ *-C*
      | Two hydrogen atoms (n1,n2) are generated at a distance of 0.1 nm
        from atom i in tetrahedral conformation on the plane bisecting
        angle j-i-k with angle
        (n1-i-n2)=(n1-i-j)=(n1-i-k)=109.47\ :math:`^{\rm o}`.

   #. | *two water hydrogens*
      | Two hydrogens are generated around atom i according to
        SPC \ :ref:`80 <refBerendsen81>` water geometry. The symmetry
        axis will alternate between three coordinate axes in both
        directions.

   #. | *three water “hydrogens”*
      | Two hydrogens are generated around atom i according to
        SPC \ :ref:`80 <refBerendsen81>` water geometry. The symmetry
        axis will alternate between three coordinate axes in both
        directions. In addition, an extra particle is generated on the
        position of the oxygen with the first letter of the name
        replaced by ‘M’. This is for use with four-atom water models
        such as TIP4P \ :ref:`128 <refJorgensen83>`.

   #. | *four water “hydrogens”*
      | Same as above, except that two additional particles are
        generated on the position of the oxygen, with names ‘LP1’ and
        ‘LP2.’ This is for use with five-atom water models such as
        TIP5P \ :ref:`130 <refMahoney2000a>`.

-  The name of the new H atom (or its prefix, *e.g.* ``HD2``
   for the asparagine example given earlier).

-  Three or four control atoms (i,j,k,l), where the first always is the
   atom to which the H atoms are connected. The other two or three
   depend on the code selected. For water, there is only one control
   atom.

Some more exotic cases can be approximately constructed from the above
tools, and with suitable use of energy minimization are good enough for
beginning MD simulations. For example secondary amine hydrogen, nitrenyl
hydrogen (:math:`\mathrm{C}=\mathrm{NH}`)
and even ethynyl hydrogen could be approximately constructed using
method 2 above for hydroxyl hydrogen.

Termini database
~~~~~~~~~~~~~~~~

The termini
databases
are stored in ``aminoacids.n.tdb`` and
``aminoacids.c.tdb`` for the N- and C-termini respectively.
They contain information for the :ref:`pdb2gmx <gmx pdb2gmx>` program on how
to connect new atoms to existing ones, which atoms should be removed or
changed, and which bonded interactions should be added. Their format is
as follows (from ``gromos43a1.ff/aminoacids.c.tdb``):

::

    [ None ]

    [ COO- ]
    [ replace ]
    C	C	C	12.011	0.27
    O 	O1	OM	15.9994	-0.635
    OXT	O2	OM	15.9994	-0.635
    [ add ]
    2	8	O	C	CA	N
    	OM	15.9994	-0.635
    [ bonds ]
    C	O1	gb_5
    C	O2	gb_5
    [ angles ]
    O1	C	O2	ga_37
    CA	C	O1	ga_21
    CA	C	O2	ga_21
    [ dihedrals ]
    N	CA	C	O2	gd_20
    [ impropers ]
    C	CA	O2	O1	gi_1

The file is organized in blocks, each with a header specifying the name
of the block. These blocks correspond to different types of termini that
can be added to a molecule. In this example ``[ COO- ]`` is
the first block, corresponding to changing the terminal carbon atom into
a deprotonated carboxyl group. ``[ None ]`` is the second
terminus type, corresponding to a terminus that leaves the molecule as
it is. Block names cannot be any of the following:
``replace``, ``add``, ``delete``,
``bonds``, ``angles``,
``dihedrals``, ``impropers``. Doing so would
interfere with the parameters of the block, and would probably also be
very confusing to human readers.

For each block the following options are present:

-  | ``[ replace ]``
   | Replace an existing atom by one with a different atom type, atom
     name, charge, and/or mass. This entry can be used to replace an
     atom that is present both in the input coordinates and in the
     :ref:`rtp` database, but also to only rename an atom in
     the input coordinates such that it matches the name in the force
     field. In the latter case, there should also be a corresponding
     ``[ add ]`` section present that gives instructions to
     add the same atom, such that the position in the sequence and the
     bonding is known. Such an atom can be present in the input
     coordinates and kept, or not present and constructed by
     :ref:`pdb2gmx <gmx pdb2gmx>`. For each atom to be replaced on line
     should be entered with the following fields:

   -  name of the atom to be replaced

   -  new atom name (optional)

   -  new atom type

   -  new mass

   -  new charge

-  | ``[ add ]``
   | Add new atoms. For each (group of) added atom(s), a two-line entry
     is necessary. The first line contains the same fields as an entry
     in the hydrogen database (name of the new atom, number of atoms,
     type of addition, control atoms, see :ref:`hdb`), but the
     possible types of addition are extended by two more, specifically
     for C-terminal additions:

   #. | *two carboxyl oxygens, -COO*:math:`^-`
      | Two oxygens (n1,n2) are generated according to rule 3, at a
        distance of 0.136 nm from atom i and an angle
        (n1-i-j)=(n2-i-j)=117 degrees

   #. | *carboxyl oxygens and hydrogen, -COOH*
      | Two oxygens (n1,n2) are generated according to rule 3, at
        distances of 0.123 nm and 0.125 nm from atom i for n1 and n2,
        respectively, and angles (n1-i-j)=121 and (n2-i-j)=115 degrees.
        One hydrogen (n\ :math:`^\prime`) is generated around n2 according
        to rule 2, where n-i-j and n-i-j-k should be read as
        n\ :math:`^\prime`-n2-i and n\ :math:`^\prime`-n2-i-j,
        respectively.

   After this line, another line follows that specifies the details of
   the added atom(s), in the same way as for replacing atoms, *i.e.*:

   -  atom type

   -  mass

   -  charge

   -  charge group (optional)

   Like in the hydrogen database (see :ref:`rtp`), when more than one
   atom is connected to an existing one, a number will be appended to
   the end of the atom name. **Note** that, like in the hydrogen
   database, the atom name is now on the same line as the control atoms,
   whereas it was at the beginning of the second line prior to |Gromacs|
   version 3.3. When the charge group field is left out, the added atom
   will have the same charge group number as the atom that it is bonded
   to.

-  | ``[ delete ]``
   | Delete existing atoms. One atom name per line.

-  | ``[ bonds ]``, ``[ angles ]``,
     ``[ dihedrals ]`` and ``[ impropers ]``
   | Add additional bonded parameters. The format is identical to that
     used in the :ref:`rtp` file, see :ref:`rtp`.

Virtual site database
~~~~~~~~~~~~~~~~~~~~~

Since we cannot rely on the positions of hydrogens in input files, we
need a special input file to decide the geometries and parameters with
which to add virtual site hydrogens. For more complex virtual site
constructs (*e.g.* when entire aromatic side chains are made rigid) we
also need information about the equilibrium bond lengths and angles for
all atoms in the side chain. This information is specified in the
:ref:`vsd` file for each force field. Just as for the termini,
there is one such file for each class of residues in the
:ref:`rtp` file.

The virtual site database is not really a very simple list of
information. The first couple of sections specify which mass centers
(typically called MCH\ :math:`_3`/MNH\ :math:`_3`) to use for
CH\ :math:`_3`, NH\ :math:`_3`, and NH\ :math:`_2` groups. Depending on
the equilibrium bond lengths and angles between the hydrogens and heavy
atoms we need to apply slightly different constraint distances between
these mass centers. **Note** that we do *not* have to specify the actual
parameters (that is automatic), just the type of mass center to use. To
accomplish this, there are three sections names ``[ CH3 ]``,
``[ NH3 ]``, and ``[ NH2 ]``. For each of these we expect three columns.
The first column is the atom type bound to the 2/3 hydrogens, the second
column is the next heavy atom type which this is bound, and the third
column the type of mass center to use. As a special case, in the
``[ NH2 ]`` section it is also possible to specify ``planar`` in the
second column, which will use a different construction without mass
center. There are currently different opinions in some force fields
whether an NH\ :math:`_2` group should be planar or not, but we try hard
to stick to the default equilibrium parameters of the force field.

The second part of the virtual site database contains explicit
equilibrium bond lengths and angles for pairs/triplets of atoms in
aromatic side chains. These entries are currently read by specific
routines in the virtual site generation code, so if you would like to
extend it *e.g.* to nucleic acids you would also need to write new code
there. These sections are named after the short amino acid names
(``[ PHE ]``, ``[ TYR ]``, ``[ TRP ]``, ``[ HID ]``, ``[ HIE ]``,
``[ HIP ]``), and simply contain 2 or 3 columns with atom names,
followed by a number specifying the bond length (in nm) or angle (in
degrees). **Note** that these are approximations of the equilibrated
geometry for the entire molecule, which might not be identical to the
equilibrium value for a single bond/angle if the molecule is strained.

.. _specbond:

Special bonds
~~~~~~~~~~~~~

The primary mechanism used by
:ref:`pdb2gmx <gmx pdb2gmx>` to generate
inter-residue bonds relies on head-to-tail linking of backbone atoms in
different residues to build a macromolecule. In some cases (*e.g.*
disulfide bonds, a heme
group, branched
polymers), it is necessary to
create inter-residue bonds that do not lie on the backbone. The file
``specbond.dat`` takes
care of this function. It is necessary that the residues belong to the
same ``[ moleculetype ]``. The ``-merge`` and
``-chainsep`` functions of :ref:`pdb2gmx <gmx pdb2gmx>` can be
useful when managing special inter-residue bonds between different
chains.

The first line of ``specbond.dat`` indicates the number of
entries that are in the file. If you add a new entry, be sure to
increment this number. The remaining lines in the file provide the
specifications for creating bonds. The format of the lines is as
follows:

``resA atomA nbondsA resB atomB nbondsB length newresA
newresB``

The columns indicate:

#. ``resA`` The name of residue A that participates in the
   bond.

#. ``atomA`` The name of the atom in residue A that forms
   the bond.

#. ``nbondsA`` The total number of bonds
   ``atomA`` can form.

#. ``resB`` The name of residue B that participates in the
   bond.

#. ``atomB`` The name of the atom in residue B that forms
   the bond.

#. ``nbondsB`` The total number of bonds
   ``atomB`` can form.

#. ``length`` The reference length for the bond. If
   ``atomA`` and ``atomB`` are not within
   ``length`` :math:`\pm` 10% in the coordinate file
   supplied to :ref:`pdb2gmx <gmx pdb2gmx>`, no bond will be formed.

#. ``newresA`` The new name of residue A, if necessary. Some
   force fields use *e.g.* CYS2 for a cysteine in a disulfide or heme
   linkage.

#. ``newresB`` The new name of residue B, likewise.
.. _fforganization:

Force field organization
------------------------

.. _fffiles:

Force-field files
~~~~~~~~~~~~~~~~~

Many force fields are available by default. Force fields are detected by
the presence of ``<name>.ff`` directories in the
``$GMXLIB/share/gromacs/top`` sub-directory and/or the
working directory. The information regarding the location of the force
field files is printed by :ref:`pdb2gmx <gmx pdb2gmx>` so you can easily keep
track of which version of a force field is being called, in case you
have made modifications in one location or another. The force fields
included with |Gromacs| are:

-  AMBER03 protein, nucleic AMBER94 (Duan et al., J. Comp. Chem. 24,
   1999-2012, 2003)

-  AMBER94 force field (Cornell et al., JACS 117, 5179-5197, 1995)

-  AMBER96 protein, nucleic AMBER94 (Kollman et al., Acc. Chem. Res. 29,
   461-469, 1996)

-  AMBER99 protein, nucleic AMBER94 (Wang et al., J. Comp. Chem. 21,
   1049-1074, 2000)

-  AMBER99SB protein, nucleic AMBER94 (Hornak et al., Proteins 65,
   712-725, 2006)

-  AMBER99SB-ILDN protein, nucleic AMBER94 (Lindorff-Larsen et al.,
   Proteins 78, 1950-58, 2010)

-  AMBERGS force field (Garcia & Sanbonmatsu, PNAS 99, 2782-2787, 2002)

-  CHARMM27 all-atom force field (CHARM22 plus CMAP for proteins)

-  GROMOS96 43a1 force field

-  GROMOS96 43a2 force field (improved alkane dihedrals)

-  GROMOS96 45a3 force field (Schuler JCC 2001 22 1205)

-  GROMOS96 53a5 force field (JCC 2004 vol 25 pag 1656)

-  GROMOS96 53a6 force field (JCC 2004 vol 25 pag 1656)

-  GROMOS96 54a7 force field (Eur. Biophys. J. (2011), 40,, 843-856,
   DOI: 10.1007/s00249-011-0700-9)

-  OPLS-AA/L all-atom force field (2001 aminoacid dihedrals)

A force field is included at the beginning of a topology file with an
``#include`` statement followed by
``<name>.ff/forcefield.itp``. This statement includes the
force-field file, which, in turn, may include other force-field files.
All the force fields are organized in the same way. An example of the
``amber99.ff/forcefield.itp`` was shown in
:ref:`topfile`.

For each force field, there several files which are only used by
:ref:`pdb2gmx <gmx pdb2gmx>`. These are: residue databases
(:ref:`rtp`) the hydrogen
database (:ref:`hdb`), two
termini databases (``.n.tdb`` and ``.c.tdb``,
see ) and the atom type database
(:ref:`atp`), which
contains only the masses. Other optional files are described in sec. :ref:`pdb2gmxfiles`.

Changing force-field parameters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If one wants to change the parameters of few bonded interactions in a
molecule, this is most easily accomplished by typing the parameters
behind the definition of the bonded interaction directly in the
:ref:`top` file under the ``[ moleculetype ]``
section (see :ref:`topfile` for the format and units).
If one wants to change the parameters for all instances of a
certain interaction one can change them in the force-field file or add a
new ``[ ???types ]`` section after including the force
field. When parameters for a certain interaction are defined multiple
times, the last definition is used. As of |Gromacs| version 3.1.3, a
warning is generated when parameters are redefined with a different
value. Changing the Lennard-Jones parameters of an atom type is not
recommended, because in the GROMOS force fields the Lennard-Jones
parameters for several combinations of atom types are not generated
according to the standard combination rules. Such combinations (and
possibly others that do follow the combination rules) are defined in the
``[ nonbond_params ]`` section, and changing the
Lennard-Jones parameters of an atom type has no effect on these
combinations.

Adding atom types
~~~~~~~~~~~~~~~~~

As of |Gromacs| version 3.1.3, atom types can be added in an extra
``[ atomtypes ]`` section after the inclusion of the
normal force field. After the definition of the new atom type(s),
additional non-bonded and pair parameters can be defined. In pre-3.1.3
versions of |Gromacs|, the new atom types needed to be added in the
``[ atomtypes ]`` section of the force-field files, because
all non-bonded parameters above the last ``[ atomtypes ]``
section would be overwritten using the standard combination rules.

.. raw:: latex

    \clearpage


.. _gmx-cmdline:

Command-line reference
======================

.. toctree::
   :hidden:
   :glob:

   /onlinehelp/gmx
   /onlinehelp/gmx-*

|Gromacs| includes many tools for preparing, running and analyzing
molecular dynamics simulations. These are all structured as part of a single
:command:`gmx` wrapper binary, and invoked with commands like :command:`gmx grompp`.
or :command:`gmx mdrun`. Documentation for these can
be found at the respective sections below, as well as on man pages (e.g.,
:manpage:`gmx-grompp(1)`) and with :samp:`gmx help {command}` or
:samp:`gmx {command} -h`.

If you've installed an MPI version of |Gromacs|, by default the
:command:`gmx` binary is called :command:`gmx_mpi` and you should adapt
accordingly.

Command-line interface and conventions
--------------------------------------

All |Gromacs| commands require an option before any arguments (i.e., all
command-line arguments need to be preceded by an argument starting with a
dash, and values not starting with a dash are arguments to the preceding
option).  Most options, except for boolean flags, expect an argument (or
multiple in some cases) after the option name.
The argument must be a separate command-line argument, i.e., separated by
space, as in ``-f traj.xtc``.  If more than one argument needs to be given to
an option, they should be similarly separated from each other.
Some options also have default arguments, i.e., just specifying the option
without any argument uses the default argument.
If an option is not specified at all, a default value is used; in the case of
optional files, the default might be not to use that file (see below).

All |Gromacs| command options start with a single dash, whether they are
single- or multiple-letter options.  However, two dashes are also recognized
(starting from 5.1).

In addition to command-specific options, some options are handled by the
:command:`gmx` wrapper, and can be specified for any command.  See
:doc:`wrapper binary help </onlinehelp/gmx>` for the list of such options.
These options are recognized both before the command name (e.g.,
:command:`gmx -quiet grompp`) as well as after the command name (e.g.,
:command:`gmx grompp -quiet`).
There is also a ``-hidden`` option that can be specified in combination with
``-h`` to show help for advanced/developer-targeted options.

Most analysis commands can process a trajectory with fewer atoms than the
run input or structure file, but only if the trajectory consists of the
first *n* atoms of the run input or structure file.

Handling specific types of command-line options
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

boolean options
  Boolean flags can be specified like ``-pbc`` and negated like ``-nopbc``.
  It is also possible to use an explicit value like ``-pbc no`` and
  ``-pbc yes``.
file name options
  Options that accept files names have features that support using default file
  names (where the default file name is specific to that option):

  * If a required option is not set, the default is used.
  * If an option is marked optional, the file is not used unless the option
    is set (or other conditions make the file required).
  * If an option is set, and no file name is provided, the default is used.

  All such options will accept file names without a file extension.
  The extension is automatically appended in such a case.
  When multiple input formats are accepted, such as a generic structure format,
  the directory will be searched for files of each type with the supplied or
  default name. When no file with a recognized extension is found, an error is given.
  For output files with multiple formats, a default file type will be used.

  Some file formats can also be read from compressed (:file:`.Z` or
  :file:`.gz`) formats.
enum options
  Enumerated options (enum) should be used with one of the arguments listed in
  the option description. The argument may be abbreviated, and the first match
  to the shortest argument in the list will be selected.
vector options
  Some options accept a vector of values.  Either 1 or 3 parameters can be
  supplied; when only one parameter is supplied the two other values are also
  set to this value.
selection options
  See :doc:`/onlinehelp/selections`.

Commands by name
----------------

.. include:: /fragments/byname.rst

Commands by topic
-----------------

.. include:: /fragments/bytopic.rst

Special topics
--------------

The information in these topics is also accessible through
:samp:`gmx help {topic}` on the command line.

Selection syntax and usage
^^^^^^^^^^^^^^^^^^^^^^^^^^

.. toctree::

   /onlinehelp/selections

.. _command-changes:

Command changes between versions
--------------------------------

Starting from |Gromacs| 5.0, some of the analysis commands (and a few other
commands as well) have changed significantly.

One main driver for this has been that many new tools mentioned below now
accept selections through one or more command-line options instead of prompting
for a static index group.  To take full advantage of selections, the interface
to the commands has changed somewhat, and some previous command-line options
are no longer present as the same effect can be achieved with suitable
selections.
Please see :doc:`/onlinehelp/selections` additional information on how to use
selections.

In the process, some old analysis commands have been removed in favor of more
powerful functionality that is available through an alternative tool.
For removed or replaced commands, this page documents how to perform the same
tasks with new tools.
For new commands, a brief note on the available features is given.  See the
linked help for the new commands for a full description.

This section lists only major changes; minor changes like additional/removed
options or bug fixes are not typically included.

For more information about changed features, please check out the
:ref:`release notes <release-notes>`.

Version 2020
^^^^^^^^^^^^

gmx convert-trj
...............

**new**

:ref:`gmx convert-trj` has been introduced as a selection-enabled alternative
for exchanging trajectory file format (previously done in :ref:`gmx trjconv`).

gmx extract-cluster
...................

**new**

:ref:`gmx extract-cluster` has been introduced as a selection-enabled way to
write sub-trajectories based on the output from a cluster analysis. The 
corresponding option **-sub** in :ref:`gmx trjconv` has been removed.

Version 2018
^^^^^^^^^^^^

gmx trajectory
..............

**new**

:ref:`gmx trajectory` has been introduced as a selection-enabled version of
:ref:`gmx traj`.  It supports output of coordinates, velocities, and/or forces
for positions calculated for selections.

Version 2016
^^^^^^^^^^^^

Analysis on arbitrary subsets of atoms
......................................

Tools implemented in the new analysis framework can now operate upon trajectories
that match only a subset of the atoms in the input structure file.

gmx insert-molecules
....................

**improved**

:ref:`gmx insert-molecules` has gained an option ``-replace`` that makes it
possible to insert molecules into a solvated configuration, replacing any
overlapping solvent atoms.  In a fully solvated box, it is also possible to
insert into a certain region of the solvent only by selecting a subset of the
solvent atoms (``-replace`` takes a selection that can also contain expressions
like ``not within 1 of ...``).

gmx rdf
.......

**improved**

The normalization for the output RDF can now also be the radial number density.

gmx genconf
...........

**simplified**

Removed ``-block``, ``-sort`` and ``-shuffle``.

Version 5.1
^^^^^^^^^^^

General
.......

Symbolic links from 5.0 are no longer supported.  The only way to invoke a
command is through :samp:`gmx {<command>}`.

gmx pairdist
............

**new**

:ref:`gmx pairdist` has been introduced as a selection-enabled replacement for
:ref:`gmx mindist` (``gmx mindist`` still exists unchanged).  It can calculate
min/max pairwise distances between a pair of selections, including, e.g.,
per-residue minimum distances or distances from a single point to a set of
residue-centers-of-mass.

gmx rdf
.......

**rewritten**

:ref:`gmx rdf` has been rewritten for 5.1 to use selections for specifying the
points from which the RDFs are calculated.  The interface is mostly the same,
except that there are new command-line options to specify the selections.
The following additional changes have been made:

* ``-com`` and ``-rdf`` options have been removed.  Equivalent functionality is
  available through selections:

  * ``-com`` can be replaced with a :samp:`com of {<selection>}` as the
    reference selection.
  * ``-rdf`` can be replaced with a suitable set of selections (e.g.,
    :samp:`res_com of {<selection>}`) and/or using ``-seltype``.

* ``-rmax`` option is added to specify a cutoff for the RDFs.  If set to a
  value that is significantly smaller than half the box size, it can speed up
  the calculation significantly if a grid-based neighborhood search can be
  used.
* ``-hq`` and ``-fade`` options have been removed, as they are simply
  postprocessing steps on the raw numbers that can be easily done after the
  analysis.

Version 5.0
^^^^^^^^^^^

General
.......

Version 5.0 introduced the :command:`gmx` wrapper binary.
For backwards compatibility, this version still creates symbolic links by default for
old tools: e.g., ``g_order <options>`` is equivalent to ``gmx order <options>``, and
``g_order`` is simply a symbolic link on the file system.

g_bond
......

**replaced**

This tool has been removed in 5.0. A replacement is :ref:`gmx distance`.

You can provide your existing index file to :ref:`gmx distance`, and it will
calculate the same distances.  The differences are:

* ``-blen`` and ``-tol`` options have different default values.
* You can control the output histogram with ``-binw``.
* ``-aver`` and ``-averdist`` options are not present.  Instead, you can choose
  between the different things to calculate using ``-oav`` (corresponds to
  ``-d`` with ``-averdist``), ``-oall`` (corresponds to ``-d`` without
  ``-averdist``), ``-oh`` (corresponds to ``-o`` with ``-aver``), and
  ``-oallstat`` (corresponds to ``-l`` without ``-aver``).

You can produce any combination of output files.  Compared to ``g_bond``,
``gmx distance -oall`` is currently missing labels for the output columns.

g_dist
......

**replaced**

This tool has been removed in 5.0.  A replacement is :ref:`gmx distance` (for
most options) or :ref:`gmx select` (for ``-dist`` or ``-lt``).

If you had index groups A and B in :file:`index.ndx` for ``g_dist``, you can use the
following command to compute the same distance with ``gmx distance``::

  gmx distance -n index.ndx -select 'com of group "A" plus com of group "B"' -oxyz -oall

The ``-intra`` switch is replaced with ``-nopbc``.

If you used ``-dist D``, you can do the same calculation with ``gmx select``::

  gmx select -n index.ndx -select 'group "B" and within D of com of group "A"' -on/-oi/-os/-olt

You can select the output option that best suits your post-processing needs
(``-olt`` is a replacement for ``g_dist -dist -lt``)

gmx distance
............

**new**

:ref:`gmx distance` has been introduced as a selection-enabled replacement for
various tools that computed distances between fixed pairs of atoms (or
centers-of-mass of groups).  It has a combination of the features of ``g_bond``
and ``g_dist``, allowing computation of one or multiple distances, either
between atom-atom pairs or centers-of-mass of groups, and providing a
combination of output options that were available in one of the tools.

gmx gangle
..........

**new**

:ref:`gmx gangle` has been introduced as a selection-enabled replacement for
``g_sgangle``.  In addition to supporting atom-atom vectors, centers-of-mass
can be used as endpoints of the vectors, and there are a few additional angle
types that can be calculated.  The command also has basic support for
calculating normal angles between three atoms and/or centers-of-mass, making it
a partial replacement for :ref:`gmx angle` as well.

gmx protonate
.............

**replaced**

This was a very old tool originally written for united atom force fields,
where it was necessary to generate all hydrogens after running a trajectory
in order to calculate e.g. distance restraint violations. The functionality
to simply protonate a structure is available in :ref:`gmx pdb2gmx`. 
If there is significant interest, we might reintroduce it after moving to new
topology formats in the future.

gmx freevolume
..............

**new**

This tool has been introduced in 5.0.  It uses a Monte Carlo sampling method to
calculate the fraction of free volume within the box (using a probe of a given
size).

g_sas
.....

**rewritten**

This tool has been rewritten in 5.0, and renamed to :ref:`gmx sasa` (the
underlying surface area calculation algorithm is still the same).

The main difference in the new tool is support for selections.  Instead of
prompting for an index group, a (potentially dynamic) selection for the
calculation can be given with ``-surface``.  Any number of output groups can be
given with ``-output``, allowing multiple parts of the surface area to be
computed in a single run.  The total area of the ``-surface`` group is now
always calculated.

The tool no longer automatically divides the surface into hydrophobic and
hydrophilic areas, and there is no ``-f_index`` option.  The same effects can
be obtained by defining suitable selections for ``-output``.  If you want
output that contains the same numbers as with the old tool for a calculation
group ``A`` and output group ``B``, you can use ::

  gmx sasa -surface 'group "A"' -output '"Hydrophobic" group "A" and charge {-0.2 to 0.2}; "Hydrophilic" group "B" and not charge {-0.2 to 0.2}; "Total" group "B"'

Solvation free energy estimates are now calculated only if separately requested
with ``-odg``, and are written into a separate file.

Output option ``-i`` for a position restraint file is not currently implemented
in the new tool, but would not be very difficult to add if requested.

g_sgangle
.........

**replaced**

This tool has been removed in 5.0.  A replacement is :ref:`gmx gangle` (for
angle calculation) and :ref:`gmx distance` (for ``-od``, ``-od1``, ``-od2``).

If you had index groups A and B in index.ndx for ``g_sgangle``, you can use the
following command to compute the same angle with ``gmx gangle``::

  gmx gangle -n index.ndx -g1 vector/plane -group1 'group "A"' -g2 vector/plane -group2 'group "B"' -oav

You need to select either ``vector`` or ``plane`` for the ``-g1`` and ``-g2``
options depending on which one your index groups specify.

If you only had a single index group A in index.ndx and you used ``g_sgangle``
``-z`` or ``-one``, you can use::

  gmx gangle -n index.ndx -g1 vector/plane -group1 'group "A"' -g2 z/t0 -oav

For the distances, you can use :ref:`gmx distance` to compute one or more
distances as you want.  Both distances between centers of groups or individual
atoms are supported using the new selection syntax.

genbox
......

This tool has been split to :ref:`gmx solvate` and :ref:`gmx insert-molecules`.

tpbconv
.......

This tool has been renamed :ref:`gmx convert-tpr`.
.. _gmx-ff-included:

Force fields in |Gromacs|
=========================

.. _gmx-amber-ff:

AMBER
^^^^^

`AMBER`_ (Assisted Model Building and Energy Refinement) refers both to a set of molecular mechanical
:ref:`force fields <gmx-force-field>` for the simulation of biomolecules and a package of molecular simulation programs.

|Gromacs| versions higher than 4.5 support the following AMBER force fields natively:

* AMBER94
* AMBER96
* AMBER99
* AMBER99SB
* AMBER99SB-ILDN
* AMBER03
* AMBERGS

Information concerning the force field can be found using the following information:

* `AMBER Force Fields <http://ambermd.org/#ff>`__ - background about the AMBER force fields
* `AMBER Programs <http://ambermd.org/#code>`__ - information about the AMBER suite of
  programs for molecular simulation
* `ANTECHAMBER/GAFF <http://ambermd.org/antechamber/antechamber.html>`__ -
  Generalized Amber Force Field (GAFF) which is supposed to provide parameters
  suitable for small molecules that are compatible with the AMBER protein/nucleic
  acid force fields. It is available either together with AMBER, or through the
  antechamber package, which is also distributed separately. There are scripts
  available for converting AMBER systems (set up, for example, with GAFF) to
  |Gromacs| (`amb2gmx.pl <https://github.com/choderalab/mmtools/blob/master/converters/amb2gmx.pl>`__,
  or `ACPYPE <https://github.com/alanwilter/acpype>`_), but they do require 
  `AmberTools <https://ambermd.org/AmberTools.php>`_ installation to work.

Older |Gromacs| versions need a separate installation of the ffamber ports:

* `Using AMBER Force Field in GROMACS <http://chemistry.csulb.edu/ffamber/>`__
  - known as the "ffamber ports," a number of AMBER force fields, complete with documentation.

* Using the ffamber ports with |Gromacs| requires that the input structure files adhere to
  the AMBER nomenclature for residues.  Problematic residues involve termini (prefixed with
  N and C), lysine (either LYN or LYP), histidine (HID, HIE, or HIS), and cysteine (CYN or CYX).
  Please see the `ffamber documentation <http://chemistry.csulb.edu/ffamber/#usage>`__.

.. _AMBER: http://ambermd.org/

.. _gmx-charmm-ff:

CHARMM
^^^^^^

`CHARMM`_ (Chemistry at HARvard Macromolecular Mechanics) is a both a set of force fields and
a software package for :ref:`molecular dynamics <gmx-md>` simulations and analysis. Includes united atom
(CHARMM19) and all atom (CHARMM22, CHARMM27, CHARMM36) :ref:`force fields <gmx-force-field>`.  The CHARMM27 force field
has been ported to GROMACS and is officially supported as of version 4.5.  CHARMM36 force field files can be
obtained from the `MacKerell lab website`_, which regularly produces up-to-date CHARMM force field files in GROMACS format.

.. _CHARMM: http://www.charmm.org/
.. _MacKerell lab website: http://mackerell.umaryland.edu/charmm_ff.shtml#gromacs

For using CHARMM36 in |Gromacs| 5.0 and newer, please use the following settings in the :ref:`mdp` file::

    constraints = h-bonds
    cutoff-scheme = Verlet
    vdwtype = cutoff
    vdw-modifier = force-switch
    rlist = 1.2
    rvdw = 1.2
    rvdw-switch = 1.0
    coulombtype = PME
    rcoulomb = 1.2
    DispCorr = no

Note that dispersion correction should be applied in the case of lipid monolayers, but not bilayers.

Please also note that the switching distance is a matter of some debate in lipid bilayer simulations,
and it is dependent to some extent on the nature of the lipid. Some studies have found that an 0.8-1.0 nm
switch is appropriate, others argue 0.8-1.2 nm is best, and yet others stand by 1.0-1.2 nm. The user
is cautioned to thoroughly investigate the force field literature for their chosen lipid(s) before beginning a simulation!

Anyone using very old versions of |Gromacs| may find this script useful:

    CHARMM to |Gromacs| - perl scripts intended to facilitate calculations using |Gromacs| programs and CHARMM forcefields (needed for |Gromacs| versions < 4.5). (`link <http://www.gromacs.org/@api/deki/files/76/=charmm_to_gromacs.tgz>`_)

.. _gmx-gromos-ff:

GROMOS
^^^^^^

`GROMOS`_ is is a general-purpose molecular dynamics computer simulation package for the
study of biomolecular systems. It also incorporates its own force field covering proteins,
nucleotides, sugars etc. and can be applied to chemical and physical systems ranging from
glasses and liquid crystals, to polymers and crystals and solutions of biomolecules.

|Gromacs| supports the GROMOS force fields, with all parameters provided in the distribution
for 43a1, 43a2, 45a3, 53a5, 53a6 and 54a7. The GROMOS force fields are
:ref:`united atom force fields <gmx-force-field>`, i.e. without explicit aliphatic (non-polar) hydrogens.

* GROMOS 53a6 - in GROMACS format (J. Comput. Chem. 2004 vol. 25 (13): 1656-1676).
* GROMOS 53a5 - in GROMACS format (J. Comput. Chem. 2004 vol. 25 (13): 1656-1676).
* GROMOS 43a1p - 43a1 modified to contain SEP (phosphoserine), TPO (phosphothreonine),
  and PTR (phosphotyrosine) (all PO42- forms), and SEPH, TPOH, PTRH (PO4H- forms).

.. todo:: Add new force fields to the list

.. _GROMOS: https://www.igc.ethz.ch/gromos.html
.. _reference manual: gmx-manual-parent-dir_


.. _gmx-opls:

OPLS
^^^^

OPLS (Optimized Potential for Liquid Simulations) is a set of force fields developed by
Prof. William L. Jorgensen for condensed phase simulations, with the latest version
being `OPLS-AA/M <http://zarbi.chem.yale.edu/oplsaam.html>`__.

The standard implementations for those force fields are the *BOSS* and *MCPRO*
programs developed by the `Jorgensen group <http://zarbi.chem.yale.edu/software.html>`__

As there is no central web-page to point to, the user is advised to consult the
original literature for the `united atom (OPLS-UA) <https://doi.org/10.1021%2Fja00214a001>`__
and `all atom (OPLS-AA) <https://doi.org/10.1021%2Fja9621760>`__ force fields, as well as the
Jorgensen group `page <http://zarbi.chem.yale.edu/>`__
.. _gmx-performance:

Getting good performance from :ref:`mdrun <gmx mdrun>`
======================================================

Here we give an overview on the parallelization and acceleration schemes employed by |Gromacs|.
The aim is to provide an understanding of the underlying mechanisms that make |Gromacs| one of the
fastest molecular dynamics packages. The information presented
should help choosing appropriate parallelization options, run configuration,
as well as acceleration options to achieve optimal simulation performance.


The |Gromacs| build system and the :ref:`gmx mdrun` tool have a lot of built-in
and configurable intelligence to detect your hardware and make pretty
effective use of it. For a lot of casual and serious use of
:ref:`gmx mdrun`, the automatic machinery works well enough. But to get the
most from your hardware to maximize your scientific quality, read on!

Hardware background information
-------------------------------
Modern computer hardware is complex and heterogeneous, so we need to
discuss a little bit of background information and set up some
definitions. Experienced HPC users can skip this section.

.. glossary::

    core
        A hardware compute unit that actually executes
        instructions. There is normally more than one core in a
        processor, often many more.

    cache
        A special kind of memory local to core(s) that is much faster
        to access than main memory, kind of like the top of a human's
        desk, compared to their filing cabinet. There are often
        several layers of caches associated with a core.

    socket
        A group of cores that share some kind of locality, such as a
        shared cache. This makes it more efficient to spread
        computational work over cores within a socket than over cores
        in different sockets. Modern processors often have more than
        one socket.

    node
        A group of sockets that share coarser-level locality, such as
        shared access to the same memory without requiring any network
        hardware. A normal laptop or desktop computer is a node. A
        node is often the smallest amount of a large compute cluster
        that a user can request to use.

    thread
        A stream of instructions for a core to execute. There are many
        different programming abstractions that create and manage
        spreading computation over multiple threads, such as OpenMP,
        pthreads, winthreads, CUDA, OpenCL, and OpenACC. Some kinds of
        hardware can map more than one software thread to a core; on
        Intel x86 processors this is called "hyper-threading", while
        the more general concept is often called SMT for
        "simultaneous multi-threading". IBM Power8 can for instance use
        up to 8 hardware threads per core.
        This feature can usually be enabled or disabled either in
        the hardware bios or through a setting in the Linux operating
        system. |Gromacs| can typically make use of this, for a moderate
        free performance boost. In most cases it will be
        enabled by default e.g. on new x86 processors, but in some cases
        the system administrators might have disabled it. If that is the
        case, ask if they can re-enable it for you. If you are not sure
        if it is enabled, check the output of the CPU information in
        the log file and compare with CPU specifications you find online.

    thread affinity (pinning)
        By default, most operating systems allow software threads to migrate
        between cores (or hardware threads) to help automatically balance
        workload. However, the performance of :ref:`gmx mdrun` can deteriorate
        if this is permitted and will degrade dramatically especially when
        relying on multi-threading within a rank. To avoid this,
        :ref:`gmx mdrun` will by default
        set the affinity of its threads to individual cores/hardware threads,
        unless the user or software environment has already done so
        (or not the entire node is used for the run, i.e. there is potential
        for node sharing).
        Setting thread affinity is sometimes called thread "pinning".

    MPI
        The dominant multi-node parallelization-scheme, which provides
        a standardized language in which programs can be written that
        work across more than one node.

    rank
        In MPI, a rank is the smallest grouping of hardware used in
        the multi-node parallelization scheme. That grouping can be
        controlled by the user, and might correspond to a core, a
        socket, a node, or a group of nodes. The best choice varies
        with the hardware, software and compute task. Sometimes an MPI
        rank is called an MPI process.

    GPU
        A graphics processing unit, which is often faster and more
        efficient than conventional processors for particular kinds of
        compute workloads. A GPU is always associated with a
        particular node, and often a particular socket within that
        node.

    OpenMP
        A standardized technique supported by many compilers to share
        a compute workload over multiple cores. Often combined with
        MPI to achieve hybrid MPI/OpenMP parallelism.

    CUDA
        A proprietary parallel computing framework and API developed by NVIDIA
        that allows targeting their accelerator hardware.
        |Gromacs| uses CUDA for GPU acceleration support with NVIDIA hardware.

    OpenCL
        An open standard-based parallel computing framework that consists
        of a C99-based compiler and a programming API for targeting heterogeneous
        and accelerator hardware. |Gromacs| uses OpenCL for GPU acceleration
        on AMD devices (both GPUs and APUs) and Intel integrated GPUs; NVIDIA
        hardware is also supported.

    SIMD
        A type of CPU instruction by which modern CPU cores can execute multiple
        floating-point instructions in a single cycle.


Work distribution by parallelization in |Gromacs|
-------------------------------------------------

The algorithms in :ref:`gmx mdrun` and their implementations are most relevant
when choosing how to make good use of the hardware. For details,
see the :ref:`Reference Manual <gmx-reference-manual-rst>`. The most important of these are

.. _gmx-domain-decomp:

.. glossary::

    Domain Decomposition
        The domain decomposition (DD) algorithm decomposes the
        (short-ranged) component of the non-bonded interactions into
        domains that share spatial locality, which permits the use of
        efficient algorithms. Each domain handles all of the
        particle-particle (PP) interactions for its members, and is
        mapped to a single MPI rank. Within a PP rank, OpenMP threads
        can share the workload, and some work can be offloaded to a
        GPU. The PP rank also handles any bonded interactions for the
        members of its domain. A GPU may perform work for more than
        one PP rank, but it is normally most efficient to use a single
        PP rank per GPU and for that rank to have thousands of
        particles. When the work of a PP rank is done on the CPU,
        :ref:`mdrun <gmx mdrun>` will make extensive use of the SIMD
        capabilities of the core. There are various
        :ref:`command-line options <controlling-the-domain-decomposition-algorithm>`
        to control the behaviour of the DD algorithm.

    Particle-mesh Ewald
        The particle-mesh Ewald (PME) algorithm treats the long-ranged
        component of the non-bonded interactions (Coulomb and possibly also
        Lennard-Jones).  Either all, or just a subset of ranks may
        participate in the work for computing the long-ranged component
        (often inaccurately called simply the "PME"
        component). Because the algorithm uses a 3D FFT that requires
        global communication, its parallel efficiency gets worse as more ranks
        participate, which can mean it is fastest to use just a subset
        of ranks (e.g.  one-quarter to one-half of the ranks). If
        there are separate PME ranks, then the remaining ranks handle
        the PP work. Otherwise, all ranks do both PP and PME work.

Parallelization schemes
-----------------------

|Gromacs|, being performance-oriented, has a strong focus on efficient parallelization.
There are multiple parallelization schemes available, therefore a simulation can be run on a
given hardware with different choices of run configuration.

.. _intra-core-parallelization:

Intra-core parallelization via SIMD: SSE, AVX, etc.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

One level of performance improvement available in |Gromacs| is through the use of
``Single Instruction Multiple Data (SIMD)`` instructions. In detail information
for those can be found under :ref:`SIMD support <gmx-simd-support>` in the installation
guide.

In |Gromacs|, SIMD instructions are used to parallelize the parts of the code with
the highest impact on performance (nonbonded and bonded force calculation,
PME and neighbour searching), through the use of hardware specific SIMD kernels.
Those form one of the three levels of non-bonded kernels that are available: reference or generic
kernels (slow but useful for producing reference values for testing),
optimized plain-C kernels (can be used cross-platform but still slow)
and SIMD intrinsics accelerated kernels.

The SIMD intrinsic code is compiled by the compiler.
Technically, it is possible to compile different levels of acceleration into one binary,
but this is difficult to manage with acceleration in many parts of the code.
Thus, you need to configure and compile |Gromacs| for the SIMD capabilities of the target CPU.
By default, the build system will detect the highest supported
acceleration of the host where the compilation is carried out. For cross-compiling for
a machine with a different highest SIMD instructions set, in order to set the target acceleration,
the ``-DGMX_SIMD`` CMake option can be used.
To use a single
installation on multiple different machines, it is convenient to compile the analysis tools with
the lowest common SIMD instruction set (as these rely little on SIMD acceleration), but for best
performance :ref:`mdrun <gmx mdrun>` should be compiled be compiled separately with the
highest (latest) ``native`` SIMD instruction set of the target architecture (supported by |Gromacs|).

Recent Intel CPU architectures bring tradeoffs between the maximum clock frequency of the
CPU (ie. its speed), and the width of the SIMD instructions it executes (ie its throughput
at a given speed). In particular, the Intel ``Skylake`` and ``Cascade Lake`` processors
(e.g. Xeon SP Gold/Platinum), can offer better throughput when using narrower SIMD because
of the better clock frequency available. Consider building :ref:`mdrun <gmx mdrun>`
configured with ``GMX_SIMD=AVX2_256`` instead of ``GMX_SIMD=AVX512`` for better
performance in GPU accelerated or highly parallel MPI runs.

Some of the latest ARM based CPU, such as the Fujitsu A64fx, support the Scalable Vector Extensions (SVE).
Though SVE can be used to generate fairly efficient Vector Length Agnostic (VLA) code,
this is not a good fit for |Gromacs| (as the SIMD vector length assumed to be known at
CMake time). Consequently, the SVE vector length must be fixed at CMake time. The default
is to automatically detect the default vector length at CMake time
(via the ``/proc/sys/abi/sve_default_vector_length`` pseudo-file, and this can be changed by
configuring with ``GMX_SIMD_ARM_SVE_LENGTH=<len>``.
The supported vector lengths are 128, 256, 512 and 1024. Since the SIMD short-range non-bonded kernels
only support up to 16 floating point numbers per SIMD vector, 1024 bits vector length is only
valid in double precision (e.g. ``-DGMX_DOUBLE=on``).
Note that even if :ref:`mdrun <gmx mdrun>` does check the SIMD vector length at runtime, running with a different
vector length than the one used at CMake time is undefined behavior, and :ref:`mdrun <gmx mdrun>` might crash before reaching
the check (that would abort with a user-friendly error message).

Process(-or) level parallelization via OpenMP
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

|Gromacs| :ref:`mdrun <gmx mdrun>` supports OpenMP multithreading for all parts
of the code. OpenMP is enabled by default and
can be turned on/off at configure time with the ``GMX_OPENMP`` CMake variable
and at run-time with the ``-ntomp`` option (or the ``OMP_NUM_THREADS`` environment variable).
The OpenMP implementation is quite efficient and scales well for up to 12-24 threads on
Intel and 6-8 threads on AMD CPUs.

Node level parallelization via GPU offloading and thread-MPI
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Multithreading with thread-MPI
..............................

The thread-MPI library implements a subset of the MPI 1.1 specification,
based on the system threading support. Both POSIX pthreads and Windows threads are supported,
thus providing great portability to most UNIX/Linux and Windows operating systems.
Acting as a drop-in replacement for MPI, thread-MPI enables compiling and running :ref:`mdrun <gmx mdrun>`
on a single machine (i.e. not across a network) without MPI. Additionally, it not only provides a
convenient way to use computers with multicore CPU(s), but thread-MPI does in some
cases make :ref:`mdrun <gmx mdrun>` run slightly faster than with MPI.

Thread-MPI is included in the |Gromacs| source and it is the default parallelization since
version 4.5, practically rendering the serial :ref:`mdrun <gmx mdrun>` deprecated.
Compilation with thread-MPI is controlled by the ``GMX_THREAD_MPI`` CMake variable.

Thread-MPI is compatible with most :ref:`mdrun <gmx mdrun>` features and parallelization schemes,
including OpenMP, GPUs; it is not compatible with MPI and multi-simulation runs.

By default, the thread-MPI :ref:`mdrun <gmx mdrun>` will use all available cores in the machine by starting
an appropriate number of ranks or OpenMP threads to occupy all of them. The number of
ranks can be controlled using the
``-nt`` and ``-ntmpi`` options. ``-nt`` represents the total number of threads
to be used (which can be a mix of thread-MPI and OpenMP threads.

Hybrid/heterogeneous acceleration
.................................

Hybrid acceleration means distributing compute work between available CPUs and GPUs
to improve simulation performance. New non-bonded algorithms
have been developed with the aim of efficient acceleration both on CPUs and GPUs.

The most compute-intensive parts of simulations, non-bonded force calculation, as well
as possibly the PME, bonded force calculation and update and constraints can be
offloaded to GPUs and carried out simultaneously with remaining CPU work.
Native GPU acceleration is supported for the most commonly used algorithms in
|Gromacs|.
For more information about the GPU kernels, please see the :ref:`Installation guide <gmx-gpu-support>`.

The native GPU acceleration can be turned on or off, either at run-time using the
:ref:`mdrun <gmx mdrun>` ``-nb`` option, or at configuration time using the ``GMX_GPU`` CMake variable.

To efficiently use all compute resource available, CPU and GPU computation is done simultaneously.
Overlapping with the OpenMP multithreaded bonded force and PME long-range electrostatic calculations
on the CPU, non-bonded forces are calculated on the GPU. Multiple GPUs, both in a single node as
well as across multiple nodes, are supported using domain-decomposition. A single GPU is assigned
to the non-bonded workload of a domain, therefore, the number GPUs used has to match the number
of of MPI processes (or thread-MPI threads) the simulation is started with. The available
CPU cores are partitioned among the processes (or thread-MPI threads) and a set of cores
with a GPU do the calculations on the respective domain.

With PME electrostatics, :ref:`mdrun <gmx mdrun>` supports automated CPU-GPU load-balancing by
shifting workload from the PME mesh calculations, done on the CPU, to the particle-particle
non-bonded calculations, done on the GPU. At startup a few iterations of tuning are executed
during the first 100 to 1000 MD steps. These iterations involve scaling the electrostatics cut-off
and PME grid spacing to determine the value that gives optimal CPU-GPU load balance. The cut-off
value provided using the :mdp:`rcoulomb` ``=rvdw`` :ref:`mdp` option represents the minimum
electrostatics cut-off the tuning starts with and therefore should be chosen as small as
possible (but still reasonable for the physics simulated). The Lennard-Jones cut-off ``rvdw``
is kept fixed. We don't allow scaling to shorter cut-off as we don't want to change ``rvdw``
and there would be no performance gain.

While the automated CPU-GPU load balancing always attempts to find the optimal cut-off setting,
it might not always be possible to balance CPU and GPU workload. This happens when the CPU threads
finish calculating the bonded forces and PME faster than the GPU the non-bonded force calculation,
even with the shortest possible cut-off. In such cases the CPU will wait for the GPU and this
time will show up as ``Wait GPU local`` in the cycle and timing summary table at the end
of the log file.

Parallelization over multiple nodes via MPI
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

At the heart of the MPI parallelization in |Gromacs| is the neutral-territory
:ref:`domain decomposition <gmx-domain-decomp>` with dynamic load balancing.
To parallelize simulations across multiple machines (e.g. nodes of a cluster)
:ref:`mdrun <gmx mdrun>` needs to be compiled with MPI which can be enabled using the ``GMX_MPI`` CMake variable.

.. _controlling-the-domain-decomposition-algorithm:

Controlling the domain decomposition algorithm
..............................................

This section lists options that affect how the domain
decomposition algorithm decomposes the workload to the available
parallel hardware.

``-rdd``
    Can be used to set the required maximum distance for inter
    charge-group bonded interactions. Communication for two-body
    bonded interactions below the non-bonded cut-off distance always
    comes for free with the non-bonded communication. Particles beyond
    the non-bonded cut-off are only communicated when they have
    missing bonded interactions; this means that the extra cost is
    minor and nearly independent of the value of ``-rdd``. With dynamic
    load balancing, option ``-rdd`` also sets the lower limit for the
    domain decomposition cell sizes. By default ``-rdd`` is determined
    by :ref:`gmx mdrun` based on the initial coordinates. The chosen value will
    be a balance between interaction range and communication cost.

``-ddcheck``
    On by default. When inter charge-group bonded interactions are
    beyond the bonded cut-off distance, :ref:`gmx mdrun` terminates with an
    error message. For pair interactions and tabulated bonds that do
    not generate exclusions, this check can be turned off with the
    option ``-noddcheck``.

``-rcon``
    When constraints are present, option ``-rcon`` influences
    the cell size limit as well.
    Particles connected by NC constraints, where NC is the LINCS order
    plus 1, should not be beyond the smallest cell size. A error
    message is generated when this happens, and the user should change
    the decomposition or decrease the LINCS order and increase the
    number of LINCS iterations.  By default :ref:`gmx mdrun` estimates the
    minimum cell size required for P-LINCS in a conservative
    fashion. For high parallelization, it can be useful to set the
    distance required for P-LINCS with ``-rcon``.

``-dds``
    Sets the minimum allowed x, y and/or z scaling of the cells with
    dynamic load balancing. :ref:`gmx mdrun` will ensure that the cells can
    scale down by at least this factor. This option is used for the
    automated spatial decomposition (when not using ``-dd``) as well as
    for determining the number of grid pulses, which in turn sets the
    minimum allowed cell size. Under certain circumstances the value
    of ``-dds`` might need to be adjusted to account for high or low
    spatial inhomogeneity of the system.



Multi-level parallelization: MPI and OpenMP
...........................................

The multi-core trend in CPU development substantiates the need for multi-level parallelization.
Current multiprocessor machines can have 2-4 CPUs with a core count as high as 64. As the memory
and cache subsystem is lagging more and more behind the multicore evolution, this emphasizes
non-uniform memory access (NUMA) effects, which can become a performance bottleneck. At the same
time, all cores share a network interface. In a purely MPI-parallel scheme, all MPI processes
use the same network interface, and although MPI intra-node communication is generally efficient,
communication between nodes can become a limiting factor to parallelization. This is especially
pronounced in the case of highly parallel simulations with PME (which is very communication
intensive) and with ``''fat''`` nodes connected by a slow network. Multi-level parallelism aims
to address the NUMA and communication related issues by employing efficient
intra-node parallelism, typically multithreading.

Combining OpenMP with MPI creates an additional overhead
especially when running separate multi-threaded PME ranks. Depending on the architecture,
input system size, as well as other factors, MPI+OpenMP runs can be as fast and faster
already at small number of processes (e.g. multi-processor Intel Westmere or Sandy Bridge),
but can also be considerably slower (e.g. multi-processor AMD Interlagos machines). However,
there is a more pronounced benefit of multi-level parallelization in highly parallel runs.

Separate PME ranks
^^^^^^^^^^^^^^^^^^

On CPU ranks, particle-particle (PP) and PME calculations are done in the same process one after
another. As PME requires all-to-all global communication, this is most of the time the limiting
factor to scaling on a large number of cores. By designating a subset of ranks for PME
calculations only, performance of parallel runs can be greatly improved.

OpenMP mutithreading in PME ranks is also possible.
Using multi-threading in PME can can improve performance at high
parallelization. The reason for this is that with N>1 threads the number of processes
communicating, and therefore the number of messages, is reduced by a factor of N.
But note that modern communication networks can process several messages simultaneously,
such that it could be advantageous to have more processes communicating.

Separate PME ranks are not used at low parallelization, the switch at higher parallelization
happens automatically (at > 16 processes). The number of PME ranks is estimated by mdrun.
If the PME load is higher than the PP load, mdrun will automatically balance the load, but
this leads to additional (non-bonded) calculations. This avoids the idling of a large fraction
of the ranks; usually 3/4 of the ranks are PP ranks. But to ensure the best absolute performance
of highly parallel runs, it is advisable to tweak this number which is automated by
the :ref:`tune_pme <gmx tune_pme>` tool.

The number of PME ranks can be set manually on the :ref:`mdrun <gmx mdrun>` command line using the ``-npme``
option, the number of PME threads can be specified on the command line with ``-ntomp_pme`` or
alternatively using the ``GMX_PME_NUM_THREADS`` environment variable. The latter is especially
useful when running on compute nodes with different number of cores as it enables
setting different number of PME threads on different nodes.

Running :ref:`mdrun <gmx mdrun>` within a single node
-----------------------------------------------------

:ref:`gmx mdrun` can be configured and compiled in several different ways that
are efficient to use within a single :term:`node`. The default configuration
using a suitable compiler will deploy a multi-level hybrid parallelism
that uses CUDA, OpenMP and the threading platform native to the
hardware. For programming convenience, in |Gromacs|, those native
threads are used to implement on a single node the same MPI scheme as
would be used between nodes, but much more efficient; this is called
thread-MPI. From a user's perspective, real MPI and thread-MPI look
almost the same, and |Gromacs| refers to MPI ranks to mean either kind,
except where noted. A real external MPI can be used for :ref:`gmx mdrun` within
a single node, but runs more slowly than the thread-MPI version.

By default, :ref:`gmx mdrun` will inspect the hardware available at run time
and do its best to make fairly efficient use of the whole node. The
log file, stdout and stderr are used to print diagnostics that
inform the user about the choices made and possible consequences.

A number of command-line parameters are available to modify the default
behavior.

``-nt``
    The total number of threads to use. The default, 0, will start as
    many threads as available cores. Whether the threads are
    thread-MPI ranks, and/or OpenMP threads within such ranks depends on
    other settings.

``-ntmpi``
    The total number of thread-MPI ranks to use. The default, 0,
    will start one rank per GPU (if present), and otherwise one rank
    per core.

``-ntomp``
    The total number of OpenMP threads per rank to start. The
    default, 0, will start one thread on each available core.
    Alternatively, :ref:`mdrun <gmx mdrun>` will honor the appropriate system
    environment variable (e.g. ``OMP_NUM_THREADS``) if set.
    Note that the maximum number of OpenMP threads (per rank) is,
    for efficiency reasons, limited to 64. While it is rarely beneficial to use
    a number of threads higher than this, the GMX_OPENMP_MAX_THREADS CMake variable
    can be used to increase the limit.

``-npme``
    The total number of ranks to dedicate to the long-ranged
    component of PME, if used. The default, -1, will dedicate ranks
    only if the total number of threads is at least 12, and will use
    around a quarter of the ranks for the long-ranged component.

``-ntomp_pme``
    When using PME with separate PME ranks,
    the total number of OpenMP threads per separate PME rank.
    The default, 0, copies the value from ``-ntomp``.

``-pin``
    Can be set to "auto," "on" or "off" to control whether
    :ref:`mdrun <gmx mdrun>` will attempt to set the affinity of threads to cores.
    Defaults to "auto," which means that if :ref:`mdrun <gmx mdrun>` detects that all the
    cores on the node are being used for :ref:`mdrun <gmx mdrun>`, then it should behave
    like "on," and attempt to set the affinities (unless they are
    already set by something else).

``-pinoffset``
    If ``-pin on``, specifies the logical core number to
    which :ref:`mdrun <gmx mdrun>` should pin the first thread. When running more than
    one instance of :ref:`mdrun <gmx mdrun>` on a node, use this option to to avoid
    pinning threads from different :ref:`mdrun <gmx mdrun>` instances to the same core.

``-pinstride``
    If ``-pin on``, specifies the stride in logical core
    numbers for the cores to which :ref:`mdrun <gmx mdrun>` should pin its threads. When
    running more than one instance of :ref:`mdrun <gmx mdrun>` on a node, use this option
    to avoid pinning threads from different :ref:`mdrun <gmx mdrun>` instances to the
    same core.  Use the default, 0, to minimize the number of threads
    per physical core - this lets :ref:`mdrun <gmx mdrun>` manage the hardware-, OS- and
    configuration-specific details of how to map logical cores to
    physical cores.

``-ddorder``
    Can be set to "interleave," "pp_pme" or "cartesian."
    Defaults to "interleave," which means that any separate PME ranks
    will be mapped to MPI ranks in an order like PP, PP, PME, PP, PP,
    PME, etc. This generally makes the best use of the available
    hardware. "pp_pme" maps all PP ranks first, then all PME
    ranks. "cartesian" is a special-purpose mapping generally useful
    only on special torus networks with accelerated global
    communication for Cartesian communicators. Has no effect if there
    are no separate PME ranks.

``-nb``
    Used to set where to execute the short-range non-bonded interactions.
    Can be set to "auto", "cpu", "gpu."
    Defaults to "auto," which uses a compatible GPU if available.
    Setting "cpu" requires that no GPU is used. Setting "gpu" requires
    that a compatible GPU is available and will be used.

``-pme``
    Used to set where to execute the long-range non-bonded interactions.
    Can be set to "auto", "cpu", "gpu."
    Defaults to "auto," which uses a compatible GPU if available.
    Setting "gpu" requires that a compatible GPU is available.
    Multiple PME ranks are not supported with PME on GPU, so if a GPU is used
    for the PME calculation -npme must be set to 1.

``-bonded``
    Used to set where to execute the bonded interactions that are part of the
    PP workload for a domain.
    Can be set to "auto", "cpu", "gpu."
    Defaults to "auto," which uses a compatible CUDA GPU only when one
    is available, a GPU is handling short-ranged interactions, and the
    CPU is handling long-ranged interaction work (electrostatic or
    LJ). The work for the bonded interactions takes place on the same
    GPU as the short-ranged interactions, and cannot be independently
    assigned.
    Setting "gpu" requires that a compatible GPU is available and will
    be used.

``-update``
    Used to set where to execute update and constraints, when present.
    Can be set to "auto", "cpu", "gpu."
    Defaults to "auto," which currently always uses the CPU.
    Setting "gpu" requires that a compatible CUDA GPU is available,
    the simulation uses a single rank.
    Update and constraints on a GPU is currently not supported
    with mass and constraints free-energy perturbation, domain
    decomposition, virtual sites, Ewald surface correction,
    replica exchange, constraint pulling, orientation restraints
    and computational electrophysiology.

``-gpu_id``
    A string that specifies the ID numbers of the GPUs that
    are available to be used by ranks on each node. For example,
    "12" specifies that the GPUs with IDs 1 and 2 (as reported
    by the GPU runtime) can be used by :ref:`mdrun <gmx mdrun>`. This is useful
    when sharing a node with other computations, or if a GPU that
    is dedicated to a display should not be used by |Gromacs|.
    Without specifying this parameter, :ref:`mdrun <gmx mdrun>`
    will utilize all GPUs. When many GPUs are
    present, a comma may be used to separate the IDs, so
    "12,13" would make GPUs 12 and 13 available to :ref:`mdrun <gmx mdrun>`.
    It could be necessary to use different GPUs on different
    nodes of a simulation, in which case the environment
    variable ``GMX_GPU_ID`` can be set differently for the ranks
    on different nodes to achieve that result.
    In |Gromacs| versions preceding 2018 this parameter used to
    specify both GPU availability and GPU task assignment.
    The latter is now done with the ``-gputasks`` parameter.

``-gputasks``
    A string that specifies the ID numbers of the GPUs to be
    used by corresponding GPU tasks on this node. For example,
    "0011" specifies that the first two GPU tasks will use GPU 0,
    and the other two use GPU 1. When using this option, the
    number of ranks must be known to :ref:`mdrun <gmx mdrun>`, as well as where
    tasks of different types should be run, such as by using
    ``-nb gpu`` - only the tasks which are set to run on GPUs
    count for parsing the mapping. See `Assigning tasks to GPUs`_
    for more details. Note that ``-gpu_id`` and
    ``-gputasks`` can not be used at the same time!
    In |Gromacs| versions preceding 2018 only a single type
    of GPU task ("PP") could be run on any rank. Now that there is some
    support for running PME on GPUs, the number of GPU tasks
    (and the number of GPU IDs expected in the ``-gputasks`` string)
    can actually be 3 for a single-rank simulation. The IDs
    still have to be the same in this case, as using multiple GPUs
    per single rank is not yet implemented.
    The order of GPU tasks per rank in the string is PP first,
    PME second. The order of ranks with different kinds of GPU tasks
    is the same by default, but can be influenced with the ``-ddorder``
    option and gets quite complex when using multiple nodes.
    Note that the bonded interactions for a PP task may
    run on the same GPU as the short-ranged work, or on the CPU,
    which can be controlled with the ``-bonded`` flag.
    The GPU task assignment (whether manually set, or automated),
    will be reported in the :ref:`mdrun <gmx mdrun>` output on
    the first physical node of the simulation. For example:

    ::

      gmx mdrun -gputasks 0001 -nb gpu -pme gpu -npme 1 -ntmpi 4

    will produce the following output in the log file/terminal:

    ::

      On host tcbl14 2 GPUs selected for this run.
      Mapping of GPU IDs to the 4 GPU tasks in the 4 ranks on this node:
      PP:0,PP:0,PP:0,PME:1

    In this case, 3 ranks are set by user to compute PP work
    on GPU 0, and 1 rank to compute PME on GPU 1.
    The detailed indexing of the GPUs is also reported in the log file.

    For more information about GPU tasks, please refer to
    :ref:`Types of GPU tasks<gmx-gpu-tasks>`.

``-pmefft``
    Allows choosing whether to execute the 3D FFT computation on a CPU or GPU.
    Can be set to "auto", "cpu", "gpu.".
    When PME is offloaded to a GPU ``-pmefft gpu`` is the default,
    and the entire PME calculation is executed on the GPU. However,
    in some cases, e.g. with a relatively slow or older generation GPU
    combined with fast CPU cores in a run, moving some work off of the GPU
    back to the CPU by computing FFTs on the CPU can improve performance.

.. _gmx-mdrun-single-node:

Examples for :ref:`mdrun <gmx mdrun>` on one node
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

::

    gmx mdrun

Starts :ref:`mdrun <gmx mdrun>` using all the available resources. :ref:`mdrun <gmx mdrun>`
will automatically choose a fairly efficient division
into thread-MPI ranks, OpenMP threads and assign work
to compatible GPUs. Details will vary with hardware
and the kind of simulation being run.

::

    gmx mdrun -nt 8

Starts :ref:`mdrun <gmx mdrun>` using 8 threads, which might be thread-MPI
or OpenMP threads depending on hardware and the kind
of simulation being run.

::

    gmx mdrun -ntmpi 2 -ntomp 4

Starts :ref:`mdrun <gmx mdrun>` using eight total threads, with two thread-MPI
ranks and four OpenMP threads per rank. You should only use
these options when seeking optimal performance, and
must take care that the ranks you create can have
all of their OpenMP threads run on the same socket.
The number of ranks should be a multiple of the number of
sockets, and the number of cores per node should be
a multiple of the number of threads per rank.

::

    gmx mdrun -ntmpi 4 -nb gpu -pme cpu

Starts :ref:`mdrun <gmx mdrun>` using four thread-MPI ranks. The CPU
cores available will be split evenly between the ranks using OpenMP
threads. The long-range component of the forces are calculated on
CPUs. This may be optimal on hardware where the CPUs are relatively
powerful compared to the GPUs. The bonded part of force calculation
will automatically be assigned to the GPU, since the long-range
component of the forces are calculated on CPU(s).

::

    gmx mdrun -ntmpi 1 -nb gpu -pme gpu -bonded gpu -update gpu

Starts :ref:`mdrun <gmx mdrun>` using a single thread-MPI rank that
will use all available CPU cores. All interaction types that can run
on a GPU will do so. This may be optimal on hardware where the CPUs
are extremely weak compared to the GPUs.

::

    gmx mdrun -ntmpi 4 -nb gpu -pme cpu -gputasks 0011

Starts :ref:`mdrun <gmx mdrun>` using four thread-MPI ranks, and maps them
to GPUs with IDs 0 and 1. The CPU cores available will be split evenly between
the ranks using OpenMP threads, with the first two ranks offloading short-range
nonbonded force calculations to GPU 0, and the last two ranks offloading to GPU 1.
The long-range component of the forces are calculated on CPUs. This may be optimal
on hardware where the CPUs are relatively powerful compared to the GPUs.

::

    gmx mdrun -ntmpi 4 -nb gpu -pme gpu -npme 1 -gputasks 0001

Starts :ref:`mdrun <gmx mdrun>` using four thread-MPI ranks, one of which is
dedicated to the long-range PME calculation. The first 3 threads offload their
short-range non-bonded calculations to the GPU with ID 0, the 4th (PME) thread
offloads its calculations to the GPU with ID 1.

::

    gmx mdrun -ntmpi 4 -nb gpu -pme gpu -npme 1 -gputasks 0011

Similar to the above example, with 3 ranks assigned to calculating short-range
non-bonded forces, and one rank assigned to calculate the long-range forces.
In this case, 2 of the 3 short-range ranks offload their nonbonded force
calculations to GPU 0. The GPU with ID 1 calculates the short-ranged forces of
the 3rd short-range rank, as well as the long-range forces of the PME-dedicated
rank. Whether this or the above example is optimal will depend on the capabilities
of the individual GPUs and the system composition.

::

    gmx mdrun -gpu_id 12

Starts :ref:`mdrun <gmx mdrun>` using GPUs with IDs 1 and 2 (e.g. because
GPU 0 is dedicated to running a display). This requires
two thread-MPI ranks, and will split the available
CPU cores between them using OpenMP threads.

::

    gmx mdrun -nt 6 -pin on -pinoffset 0 -pinstride 1
    gmx mdrun -nt 6 -pin on -pinoffset 6 -pinstride 1

Starts two :ref:`mdrun <gmx mdrun>` processes, each with six total threads
arranged so that the processes affect each other as little as possible by
being assigned to disjoint sets of physical cores.
Threads will have their affinities set to particular
logical cores, beginning from the first and 7th logical cores, respectively. The
above would work well on an Intel CPU with six physical cores and
hyper-threading enabled. Use this kind of setup only
if restricting :ref:`mdrun <gmx mdrun>` to a subset of cores to share a
node with other processes.
A word of caution: The mapping of logical CPUs/cores to physical
cores may differ between operating systems. On Linux,
``cat /proc/cpuinfo`` can be examined to determine this mapping.

::

    mpirun -np 2 gmx_mpi mdrun

When using an :ref:`gmx mdrun` compiled with external MPI,
this will start two ranks and as many OpenMP threads
as the hardware and MPI setup will permit. If the
MPI setup is restricted to one node, then the resulting
:ref:`gmx mdrun` will be local to that node.

.. _gmx-mdrun-multiple-nodes:

Running :ref:`mdrun <gmx mdrun>` on more than one node
------------------------------------------------------

This requires configuring |Gromacs| to build with an external MPI
library. By default, this :ref:`mdrun <gmx mdrun>` executable is run with
``gmx_mpi mdrun``. All of the considerations for running single-node
:ref:`mdrun <gmx mdrun>` still apply, except that ``-ntmpi`` and ``-nt`` cause a fatal
error, and instead the number of ranks is controlled by the
MPI environment.
Settings such as ``-npme`` are much more important when
using multiple nodes. Configuring the MPI environment to
produce one rank per core is generally good until one
approaches the strong-scaling limit. At that point, using
OpenMP to spread the work of an MPI rank over more than one
core is needed to continue to improve absolute performance.
The location of the scaling limit depends on the processor,
presence of GPUs, network, and simulation algorithm, but
it is worth measuring at around ~200 particles/core if you
need maximum throughput.

There are further command-line parameters that are relevant in these
cases.

``-tunepme``
    Defaults to "on." If "on," a simulation will
    optimize various aspects of the PME and DD algorithms, shifting
    load between ranks and/or GPUs to maximize throughput. Some
    :ref:`mdrun <gmx mdrun>` features are not compatible with this, and these ignore
    this option.

``-dlb``
    Can be set to "auto," "no," or "yes."
    Defaults to "auto." Doing Dynamic Load Balancing between MPI ranks
    is needed to maximize performance. This is particularly important
    for molecular systems with heterogeneous particle or interaction
    density. When a certain threshold for performance loss is
    exceeded, DLB activates and shifts particles between ranks to improve
    performance. If available, using ``-bonded gpu`` is expected
    to improve the ability of DLB to maximize performance.

During the simulation :ref:`gmx mdrun` must communicate between all
PP ranks to compute quantities such as kinetic energy for log file
reporting, or perhaps temperature coupling. By default, this happens
whenever necessary to honor several :ref:`mdp options <mdp-general>`,
so that the period between communication phases is the least common
denominator of :mdp:`nstlist`, :mdp:`nstcalcenergy`,
:mdp:`nsttcouple`, and :mdp:`nstpcouple`.

Note that ``-tunepme`` has more effect when there is more than one
:term:`node`, because the cost of communication for the PP and PME
ranks differs. It still shifts load between PP and PME ranks, but does
not change the number of separate PME ranks in use.

Note also that ``-dlb`` and ``-tunepme`` can interfere with each other, so
if you experience performance variation that could result from this,
you may wish to tune PME separately, and run the result with ``mdrun
-notunepme -dlb yes``.

The :ref:`gmx tune_pme` utility is available to search a wider
range of parameter space, including making safe
modifications to the :ref:`tpr` file, and varying ``-npme``.
It is only aware of the number of ranks created by
the MPI environment, and does not explicitly manage
any aspect of OpenMP during the optimization.

Examples for :ref:`mdrun <gmx mdrun>` on more than one node
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The examples and explanations for for single-node :ref:`mdrun <gmx mdrun>` are
still relevant, but ``-ntmpi`` is no longer the way
to choose the number of MPI ranks.

::

    mpirun -np 16 gmx_mpi mdrun

Starts :ref:`gmx mdrun` with 16 ranks, which are mapped to
the hardware by the MPI library, e.g. as specified
in an MPI hostfile. The available cores will be
automatically split among ranks using OpenMP threads,
depending on the hardware and any environment settings
such as ``OMP_NUM_THREADS``.

::

    mpirun -np 16 gmx_mpi mdrun -npme 5

Starts :ref:`gmx mdrun` with 16 ranks, as above, and
require that 5 of them are dedicated to the PME
component.

::

    mpirun -np 11 gmx_mpi mdrun -ntomp 2 -npme 6 -ntomp_pme 1

Starts :ref:`gmx mdrun` with 11 ranks, as above, and
require that six of them are dedicated to the PME
component with one OpenMP thread each. The remaining
five do the PP component, with two OpenMP threads
each.

::

    mpirun -np 4 gmx_mpi mdrun -ntomp 6 -nb gpu -gputasks 00

Starts :ref:`gmx mdrun` on a machine with two nodes, using
four total ranks, each rank with six OpenMP threads,
and both ranks on a node sharing GPU with ID 0.

::

    mpirun -np 8 gmx_mpi mdrun -ntomp 3 -gputasks 0000

Using a same/similar hardware as above,
starts :ref:`gmx mdrun` on a machine with two nodes, using
eight total ranks, each rank with three OpenMP threads,
and all four ranks on a node sharing GPU with ID 0.
This may or may not be faster than the previous setup
on the same hardware.

::

    mpirun -np 20 gmx_mpi mdrun -ntomp 4 -gputasks 00

Starts :ref:`gmx mdrun` with 20 ranks, and assigns the CPU cores evenly
across ranks each to one OpenMP thread. This setup is likely to be
suitable when there are ten nodes, each with one GPU, and each node
has two sockets each of four cores.

::

    mpirun -np 10 gmx_mpi mdrun -gpu_id 1

Starts :ref:`gmx mdrun` with 20 ranks, and assigns the CPU cores evenly
across ranks each to one OpenMP thread. This setup is likely to be
suitable when there are ten nodes, each with two GPUs, but another
job on each node is using GPU 0. The job scheduler should set the
affinity of threads of both jobs to their allocated cores, or the
performance of :ref:`mdrun <gmx mdrun>` will suffer greatly.

::

    mpirun -np 20 gmx_mpi mdrun -gpu_id 01

Starts :ref:`gmx mdrun` with 20 ranks. This setup is likely
to be suitable when there are ten nodes, each with two
GPUs, but there is no need to specify ``-gpu_id`` for the
normal case where all the GPUs on the node are available
for use.

Approaching the scaling limit
-----------------------------

There are several aspects of running a |Gromacs| simulation that are important as the number
of atoms per core approaches the current scaling limit of ~100 atoms/core.

One of these is that the use of ``constraints = all-bonds``  with P-LINCS
sets an artificial minimum on the size of domains. You should reconsider the use
of constraints to all bonds (and bear in mind possible consequences on the safe maximum for dt),
or change lincs_order and lincs_iter suitably.

Finding out how to run :ref:`mdrun <gmx mdrun>` better
------------------------------------------------------

The Wallcycle module is used for runtime performance measurement of :ref:`gmx mdrun`.
At the end of the log file of each run, the "Real cycle and time accounting" section
provides a table with runtime statistics for different parts of the :ref:`gmx mdrun` code
in rows of the table.
The table contains columns indicating the number of ranks and threads that
executed the respective part of the run, wall-time and cycle
count aggregates (across all threads and ranks) averaged over the entire run.
The last column also shows what precentage of the total runtime each row represents.
Note that the :ref:`gmx mdrun` timer resetting functionalities (``-resethway`` and ``-resetstep``)
reset the performance counters and therefore are useful to avoid startup overhead and
performance instability (e.g. due to load balancing) at the beginning of the run.

The performance counters are:

* Particle-particle during Particle mesh Ewald
* Domain decomposition
* Domain decomposition communication load
* Domain decomposition communication bounds
* Virtual site constraints
* Send X to Particle mesh Ewald
* Neighbor search
* Launch GPU operations
* Communication of coordinates
* Force
* Waiting + Communication of force
* Particle mesh Ewald
* PME redist. X/F
* PME spread
* PME gather
* PME 3D-FFT
* PME 3D-FFT Communication
* PME solve Lennard-Jones
* PME solve LJ
* PME solve Elec
* PME wait for particle-particle
* Wait + Receive PME force
* Wait GPU nonlocal
* Wait GPU local
* Wait PME GPU spread
* Wait PME GPU gather
* Reduce PME GPU Force
* Non-bonded position/force buffer operations
* Virtual site spread
* COM pull force
* AWH (accelerated weight histogram method)
* Write trajectory
* Update
* Constraints
* Communication of energies
* Enforced rotation
* Add rotational forces
* Position swapping
* Interactive MD

As performance data is collected for every run, they are essential to assessing
and tuning the performance of :ref:`gmx mdrun` performance. Therefore, they benefit
both code developers as well as users of the program.
The counters are an average of the time/cycles different parts of the simulation take,
hence can not directly reveal fluctuations during a single run (although comparisons across
multiple runs are still very useful).

Counters will appear in an MD log file only if the related parts of the code were
executed during the :ref:`gmx mdrun` run. There is also a special counter called "Rest" which
indicates the amount of time not accounted for by any of the counters above. Therefore,
a significant amount "Rest" time (more than a few percent) will often be an indication of
parallelization inefficiency (e.g. serial code) and it is recommended to be reported to the
developers.

An additional set of subcounters can offer more fine-grained inspection of performance. They are:

* Domain decomposition redistribution
* DD neighbor search grid + sort
* DD setup communication
* DD make topology
* DD make constraints
* DD topology other
* Neighbor search grid local
* NS grid non-local
* NS search local
* NS search non-local
* Bonded force
* Bonded-FEP force
* Restraints force
* Listed buffer operations
* Nonbonded pruning
* Nonbonded force
* Launch non-bonded GPU tasks
* Launch PME GPU tasks
* Ewald force correction
* Non-bonded position buffer operations
* Non-bonded force buffer operations

Subcounters are geared toward developers and have to be enabled during compilation. See
:doc:`/dev-manual/build-system` for more information.

..  todo::

    In future patch:
    - red flags in log files, how to interpret wallcycle output
    - hints to devs how to extend wallcycles

.. _gmx-mdrun-on-gpu:

Running :ref:`mdrun <gmx mdrun>` with GPUs
------------------------------------------

.. _gmx-gpu-tasks:

Types of GPU tasks
^^^^^^^^^^^^^^^^^^

To better understand the later sections on different GPU use cases for
calculation of :ref:`short range<gmx-gpu-pp>`, :ref:`PME<gmx-gpu-pme>`,
:ref:`bonded interactions<gmx-gpu-bonded>` and
:ref:`update and constraints <gmx-gpu-update>`
we first introduce the concept of different GPU tasks. When thinking about
running a simulation, several different kinds of interactions between the atoms
have to be calculated (for more information please refer to the reference manual).
The calculation can thus be split into several distinct parts that are largely independent
of each other (hence can be calculated in any order, e.g. sequentially or concurrently),
with the information from each of them combined at the end of
time step to obtain the final forces on each atom and to propagate the system
to the next time point. For a better understanding also please see the section
on :ref:`domain decomposition <gmx-domain-decomp>`.

Of all calculations required for an MD step,
GROMACS aims to optimize performance bottom-up for each step
from the lowest level (SIMD unit, cores, sockets, accelerators, etc.).
Therefore many of the individual computation units are
highly tuned for the lowest level of hardware parallelism: the SIMD units.
Additionally, with GPU accelerators used as *co-processors*, some of the work
can be *offloaded*, that is calculated simultaneously/concurrently with the CPU
on the accelerator device, with the result being communicated to the CPU.
Right now, |Gromacs| supports GPU accelerator offload of two tasks:
the short-range :ref:`nonbonded interactions in real space <gmx-gpu-pp>`,
and :ref:`PME <gmx-gpu-pme>`.

**Please note that the solving of PME on GPU is still only the initial
version supporting this behaviour, and comes with a set of limitations
outlined further below.**

Right now, we generally support short-range nonbonded offload with and
without dynamic pruning on a wide range of GPU accelerators
(NVIDIA, AMD, and Intel). This is compatible with the grand majority of
the features and parallelization modes and can be used to scale to large machines.

Simultaneously offloading both short-range nonbonded and long-range
PME work to GPU accelerators is a new feature that that has some
restrictions in terms of feature and parallelization
compatibility (please see the :ref:`section below <gmx-pme-gpu-limitations>`).

.. _gmx-gpu-pp:

GPU computation of short range nonbonded interactions
.....................................................

.. todo:: make this more elaborate and include figures

Using the GPU for the short-ranged nonbonded interactions provides
the majority of the available speed-up compared to run using only the CPU.
Here, the GPU acts as an accelerator that can effectively parallelize
this problem and thus reduce the calculation time.

.. _gmx-gpu-pme:

GPU accelerated calculation of PME
..................................

.. todo:: again, extend this and add some actual useful information concerning performance etc...

|Gromacs| now allows the offloading of the PME calculation
to the GPU, to further reduce the load on the CPU and improve usage overlap between
CPU and GPU. Here, the solving of PME will be performed in addition to the calculation
of the short range interactions on the same GPU as the short range interactions.

.. _gmx-pme-gpu-limitations:

Known limitations
.................

**Please note again the limitations outlined below!**

- Only a PME order of 4 is supported on GPUs.

- PME will run on a GPU only when exactly one rank has a
  PME task, ie. decompositions with multiple ranks doing PME are not supported.

- Only single precision is supported.

- Only dynamical integrators are supported (ie. leap-frog, Velocity Verlet,
  stochastic dynamics)

- LJ PME is not supported on GPUs.

.. _gmx-gpu-bonded:

GPU accelerated calculation of bonded interactions (CUDA only)
..............................................................

.. todo:: again, extend this and add some actual useful information concerning performance etc...

|Gromacs| now allows the offloading of the bonded part of the PP
workload to a CUDA-compatible GPU. This is treated as part of the PP
work, and requires that the short-ranged non-bonded task also runs on
a GPU. Typically, there is a performance advantage to offloading
bonded interactions in particular when the amount of CPU resources per GPU
is relatively little (either because the CPU is weak or there are few CPU
cores assigned to a GPU in a run) or when there are other computations on the CPU.
A typical case for the latter is free-energy calculations.

.. _gmx-gpu-update:

GPU accelerated calculation of constraints and coordinate update (CUDA and SYCL only)
.....................................................................................

.. TODO again, extend this and add some actual useful information concerning performance etc...

|Gromacs| makes it possible to also perform the coordinate update and (if requested)
constraint calculation on a CUDA-compatible GPU. This allows executing all
(supported) computation of a simulation step on the GPU. 
This feature is supported in single domain runs (unless using the experimental
GPU domain decomposition feature), and needs to be explicitly requested by the user. 
This is a new parallelization mode where all force and coordinate
data can be "GPU resident" for a number of steps, typically between neighbor searching steps.
This has the benefit that there is less coupling between CPU host and GPU and
on typical MD steps data does not need to be transferred between CPU and GPU.
In this scheme it is however still possible for part of the computation to be 
executed on the CPU concurrently with GPU calculation.
This helps supporting the broad range of |Gromacs| features not all of which are 
ported to GPUs. At the same time, it also allows improving performance by making 
use of the otherwise mostly idle CPU. It can often be advantageous to move the bonded 
or PME calculation back to the CPU, but the details of this will depending on the
relative performance if the CPU cores paired in a simulation with a GPU.

It is possible to change the default behaviour by setting the
``GMX_FORCE_UPDATE_DEFAULT_GPU`` environment variable to a non-zero value. In this
case simulations will try to run all parts by default on the GPU, and will only fall
back to the CPU based calculation if the simulation is not compatible.

Using this parallelization mode is typically advantageous in cases where a fast GPU is
used with a weak CPU, in particular if there is only single simulation assigned to a GPU.
However, in typical throughput cases where multiple runs are assigned to each GPU,
offloading everything, especially without moving back some of the work to the CPU
can perform worse than the parallelization mode where only force computation is offloaded.


Assigning tasks to GPUs
.......................

Depending on which tasks should be performed on which hardware, different kinds of
calculations can be combined on the same or different GPUs, according to the information
provided for running :ref:`mdrun <gmx mdrun>`.

It is possible to assign the calculation of the different computational tasks to the same GPU, meaning
that they will share the computational resources on the same device, or to different processing units
that will each perform one task each.

One overview over the possible task assignments is given below:

|Gromacs| version 2018:

  Two different types of assignable GPU accelerated tasks are available, NB and PME.
  Each PP rank has a NB task that can be offloaded to a GPU.
  If there is only one rank with a PME task (including if that rank is a
  PME-only rank), then that task can be offloaded to a GPU. Such a PME
  task can run wholly on the GPU, or have its latter stages run only on the CPU.

  Limitations are that PME on GPU does not support PME domain decomposition,
  so that only one PME task can be offloaded to a single GPU
  assigned to a separate PME rank, while NB can be decomposed and offloaded to multiple GPUs.

|Gromacs| version 2019:

  No new assignable GPU tasks are available, but any bonded interactions
  may run on the same GPU as the short-ranged interactions for a PP task.
  This can be influenced with the ``-bonded`` flag.

Performance considerations for GPU tasks
........................................

#) The performance balance depends on the speed and number of CPU cores you
   have vs the speed and number of GPUs you have.

#) With slow/old GPUs and/or fast/modern CPUs with many
   cores, it might make more sense to let the CPU do PME calculation,
   with the GPUs focused on the calculation of the NB.

#) With fast/modern GPUs and/or slow/old CPUs with few cores,
   it generally helps to have the GPU do PME.

#) Offloading bonded work to a GPU will often not improve simulation performance
   as efficient CPU-based kernels can complete the bonded computation
   before the GPU is done with other offloaded work. Therefore,
   `gmx mdrun` will default to no bonded offload when PME is offloaded.
   Typical cases where performance can be improvement with bonded offload are:
   with significant bonded work (e.g. pure lipid or mostly polymer systems with little solvent),
   with very few and/or slow CPU cores per GPU, or when the CPU does
   other computation (e.g. PME, free energy).

#) It *is* possible to use multiple GPUs with PME offload
   by letting e.g.
   3 MPI ranks use one GPU each for short-range interactions,
   while a fourth rank does the PME on its GPU.

#) The only way to know for sure what alternative is best for
   your machine is to test and check performance.

.. todo:: we need to be more concrete here, i.e. what machine/software aspects to take into consideration, when will default run mode be using PME-GPU and when will it not, when/how should the user reason about testing different settings than the default.

.. todo:: someone who knows about the mixed mode should comment further.

Reducing overheads in GPU accelerated runs
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In order for CPU cores and GPU(s) to execute concurrently, tasks are
launched and executed asynchronously on the GPU(s) while the CPU cores
execute non-offloaded force computation (like long-range PME electrostatics).
Asynchronous task launches are handled by GPU device driver and
require CPU involvement. Therefore, the work of scheduling
GPU tasks will incur an overhead that can in some cases significantly
delay or interfere with the CPU execution.

Delays in CPU execution are caused by the latency of launching GPU tasks,
an overhead that can become significant as simulation ns/day increases
(i.e. with shorter wall-time per step).
The overhead is measured by :ref:`gmx mdrun` and reported in the performance
summary section of the log file ("Launch GPU ops" row).
A few percent of runtime spent in this category is normal,
but in fast-iterating and multi-GPU parallel runs 10% or larger overheads can be observed.
In general, a user can do little to avoid such overheads, but there
are a few cases where tweaks can give performance benefits.
In OpenCL runs, timing of GPU tasks is by default enabled and,
while in most cases its impact is small, in fast runs performance can be affected.
In these cases, when more than a few percent of "Launch GPU ops" time is observed,
it is recommended to turn off timing by setting the ``GMX_DISABLE_GPU_TIMING``
environment variable.
In parallel runs with many ranks sharing a GPU,
launch overheads can also be reduced by starting fewer thread-MPI
or MPI ranks per GPU; e.g. most often one rank per thread or core is not optimal.

The second type of overhead, interference of the GPU driver with CPU computation,
is caused by the scheduling and coordination of GPU tasks.
A separate GPU driver thread can require CPU resources
which may clash with the concurrently running non-offloaded tasks,
potentially degrading the performance of PME or bonded force computation.
This effect is most pronounced when using AMD GPUs with OpenCL with
older driver releases (e.g. fglrx 12.15).
To minimize the overhead it is recommended to
leave a CPU hardware thread unused when launching :ref:`gmx mdrun`,
especially on CPUs with high core counts and/or HyperThreading enabled.
E.g. on a machine with a 4-core CPU and eight threads (via HyperThreading) and an AMD GPU,
try ``gmx mdrun -ntomp 7 -pin on``.
This will leave free CPU resources for the GPU task scheduling
reducing interference with CPU computation.
Note that assigning fewer resources to :ref:`gmx mdrun` CPU computation
involves a tradeoff which may outweigh the benefits of reduced GPU driver overhead,
in particular without HyperThreading and with few CPU cores.

.. todo:: In future patch: any tips not covered above

Running the OpenCL version of mdrun
-----------------------------------

Currently supported hardware architectures are:
- GCN-based AMD GPUs;
- NVIDIA GPUs (with at least OpenCL 1.2 support);
- Intel iGPUs.
Make sure that you have the latest drivers installed. For AMD GPUs,
the compute-oriented `ROCm <https://rocm.github.io/>`_ stack is recommended;
alternatively, the AMDGPU-PRO stack is also compatible; using the outdated
and unsupported ``fglrx`` proprietary driver and runtime is not recommended (but
for certain older hardware that may be the only way to obtain support).
In addition Mesa version 17.0 or newer with LLVM 4.0 or newer is also supported.
For NVIDIA GPUs, using the proprietary driver is
required as the open source nouveau driver (available in Mesa) does not
provide the OpenCL support.
For Intel integrated GPUs, the `Neo driver <https://github.com/intel/compute-runtime/releases>`_ is
recommended.

The minimum OpenCL version required is |REQUIRED_OPENCL_MIN_VERSION|. See
also the :ref:`known limitations <opencl-known-limitations>`.

Devices from the AMD GCN architectures (all series) are compatible
and regularly tested; NVIDIA Kepler and later (compute capability 3.0)
are known to work, but before doing production runs always make sure that the |Gromacs| tests
pass successfully on the hardware.

The OpenCL GPU kernels are compiled at run time. Hence,
building the OpenCL program can take a few seconds, introducing a slight
delay in the :ref:`gmx mdrun` startup. This is not normally a
problem for long production MD, but you might prefer to do some kinds
of work, e.g. that runs very few steps, on just the CPU (e.g. see ``-nb`` above).

The same ``-gpu_id`` option (or ``GMX_GPU_ID`` environment variable)
used to select CUDA devices, or to define a mapping of GPUs to PP
ranks, is used for OpenCL devices.

Some other :ref:`OpenCL management <opencl-management>` environment
variables may be of interest to developers.

.. _opencl-known-limitations:

Known limitations of the OpenCL support
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Limitations in the current OpenCL support of interest to |Gromacs| users:

- Intel integrated GPUs are supported. Intel CPUs and Xeon Phi are not supported.
- Due to blocking behavior of some asynchronous task enqueuing functions
  in the NVIDIA OpenCL runtime, with the affected driver versions there is
  almost no performance gain when using NVIDIA GPUs.
  The issue affects NVIDIA driver versions up to 349 series, but it
  known to be fixed 352 and later driver releases.
- On NVIDIA GPUs the OpenCL kernels achieve much lower performance
  than the equivalent CUDA kernels due to limitations of the NVIDIA OpenCL
  compiler.
- On the NVIDIA Volta and Turing architectures the OpenCL code is known to produce
  incorrect results with driver version up to 440.x (most likely due to compiler issues).
  Runs typically fail on these architectures.

Limitations of interest to |Gromacs| developers:

- The current implementation requires a minimum execution with of 16; kernels
  compiled for narrower execution width (be it due to hardware requirements or
  compiler choice) will not be suitable and will trigger a runtime error.

Performance checklist
---------------------

There are many different aspects that affect the performance of simulations in
|Gromacs|. Most simulations require a lot of computational resources, therefore
it can be worthwhile to optimize the use of those resources. Several issues
mentioned in the list below could lead to a performance difference of a factor
of 2. So it can be useful go through the checklist.

|Gromacs| configuration
^^^^^^^^^^^^^^^^^^^^^^^

* Don't use double precision unless you're absolute sure you need it.
* Compile the FFTW library (yourself) with the correct flags on x86 (in most
  cases, the correct flags are automatically configured).
* On x86, use gcc as the compiler (not icc, pgi or the Cray compiler).
* On POWER, use gcc instead of IBM's xlc.
* Use a new compiler version, especially for gcc (e.g. from version 5 to 6
  the performance of the compiled code improved a lot).
* MPI library: OpenMPI usually has good performance and causes little trouble.
* Make sure your compiler supports OpenMP (some versions of Clang don't).
* If you have GPUs that support either CUDA, OpenCL, or SYCL, use them.

  * Configure with ``-DGMX_GPU=CUDA``, ``-DGMX_GPU=OpenCL``, or ``-DGMX_GPU=SYCL``.
  * For CUDA, use the newest CUDA available for your GPU to take advantage of the
    latest performance enhancements.
  * Use a recent GPU driver.
  * Make sure you use an :ref:`gmx mdrun` with ``GMX_SIMD`` appropriate for the CPU
    architecture; the log file will contain a warning note if suboptimal setting is used.
    However, prefer ``AVX2` over ``AVX512`` in GPU or highly parallel MPI runs (for more
    information see the :ref:`intra-core parallelization information <intra-core-parallelization>`).
  * If compiling on a cluster head node, make sure that ``GMX_SIMD``
    is appropriate for the compute nodes.

Run setup
^^^^^^^^^

* For an approximately spherical solute, use a rhombic dodecahedron unit cell.
* When using a time-step of 2 fs, use :mdp-value:`constraints=h-bonds`
  (and not :mdp-value:`constraints=all-bonds`), since this is faster, especially with GPUs,
  and most force fields have been parametrized with only bonds involving
  hydrogens constrained.
* You can increase the time-step to 4 or 5 fs when using virtual interaction
  sites (``gmx pdb2gmx -vsite h``).
* For massively parallel runs with PME, you might need to try different numbers
  of PME ranks (``gmx mdrun -npme ???``) to achieve best performance;
  :ref:`gmx tune_pme` can help automate this search.
* For massively parallel runs (also ``gmx mdrun -multidir``), or with a slow
  network, global communication can become a bottleneck and you can reduce it
  by choosing larger periods for algorithms such as temperature and
  pressure coupling).

Checking and improving performance
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

* Look at the end of the ``md.log`` file to see the performance and the cycle
  counters and wall-clock time for different parts of the MD calculation. The
  PP/PME load ratio is also printed, with a warning when a lot of performance is
  lost due to imbalance.
* Adjust the number of PME ranks and/or the cut-off and PME grid-spacing when
  there is a large PP/PME imbalance. Note that even with a small reported
  imbalance, the automated PME-tuning might have reduced the initial imbalance.
  You could still gain performance by changing the mdp parameters or increasing
  the number of PME ranks.
* If the neighbor searching takes a lot of time, increase nstlist. If a Verlet
  buffer tolerance is used, this is done automatically by :ref:`gmx mdrun`
  and the pair-list buffer is increased to keep the energy drift constant.

  * If ``Comm. energies`` takes a lot of time (a note will be printed in the log
    file), increase nstcalcenergy.
  * If all communication takes a lot of time, you might be running on too many
    cores, or you could try running combined MPI/OpenMP parallelization with 2
    or 4 OpenMP threads per MPI process.
Common errors when using |Gromacs|
==================================

The vast majority of error messages generated by |Gromacs| are descriptive,
informing the user where the exact error lies. Some errors that arise are noted
below, along with more details on what the issue is and how to solve it.

..  Moved my text that I duplicated to this page now, so that there is only one page for errors and
    not two. Kept formatting from new pages, can be changed later.

.. _common-errors:

Common errors during usage
--------------------------

.. _out-of-memory:

Out of memory when allocating
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The program has attempted to assign memory to be used in the calculation, but is unable to due to insufficient memory.

Possible solutions are:

* reduce the scope of the number of atoms selected for analysis.
* reduce the length of trajectory file being processed.
* in some cases confusion between Ångström and nm may lead to users generating a
  :ref:`pdb2gmx <gmx pdb2gmx>` water box that is |10to3| times larger than what they think it is (e.g. :ref:`gmx solvate`).
* use a computer with more memory.
* install more memory in the computer.

.. |10to3| replace:: 10\ :sup:`3`

The user should bear in mind that the cost in time and/or memory for various activities will
scale with the number of atoms/groups/residues *N* or the simulation length *T* as order N,
NlogN, or |Nsquared| (or maybe worse!) and the same for *T*, depending on the type of activity.
If it takes a long time, have a think about what you are doing, and the underlying algorithm
(see the `Reference manual`_, man page, or use the -h flag for the utility), and
see if there's something sensible you can do that has better scaling properties.

.. _Reference manual: `gmx-manual-parent-dir`_
.. |Nsquared| replace:: N\ :sup:`2`

.. _pdb2gmx-errors:

Errors in :ref:`pdb2gmx <gmx pdb2gmx>`
--------------------------------------

Residue 'XXX' not found in residue topology database
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


This means that the force field you have selected while running :ref:`pdb2gmx <gmx pdb2gmx>` does not have an entry in
the :ref:`residue database<rtp>` for XXX. The :ref:`residue database<rtp>` entry is necessary both for stand-alone
molecules (e.g. formaldehyde) or a peptide (standard or non-standard). This entry defines the atom
types, connectivity, bonded and non-bonded interaction types for the residue and is necessary
to use :ref:`pdb2gmx <gmx pdb2gmx>` to build a :ref:`top` file. A :ref:`residue database<rtp>`
entry may be missing simply because the
database does not contain the residue at all, or because the name is different.

For new users, this error appears because they are running :ref:`pdb2gmx <gmx pdb2gmx>` on a
:ref:`PDB<pdb>` file they have, without consideration of the contents of the file. A :ref:`force field<gmx-force-field>`
is not magical, it can only deal with molecules or residues (building blocks) that are
provided in the :ref:`residue database<rtp>` or included otherwise.

If you want to use :ref:`pdb2gmx <gmx pdb2gmx>` to automatically generate your topology, you have
to ensure that the appropriate :ref:`rtp` entry is present within the desired :ref:`force field<gmx-force-field>` and
has the same name as the building block you are trying to use. If you call your
molecule "HIS," then :ref:`pdb2gmx <gmx pdb2gmx>` will try to build histidine, based on the
``[ HIS ]`` entry in the :ref:`rtp` file, so it will look for the exact atomic entries for histidine, no more no less.

If you want a :ref:`topology<top>` for an arbitrary molecule, you cannot use :ref:`pdb2gmx <gmx pdb2gmx>` (unless you
build the :ref:`rtp` entry yourself). You will have to build that entry by hand, or use another program
(such as :ref:`x2top<gmx x2top>` or one of the scripts contributed by users) to build the :ref:`top` file.

If there is not an entry for this residue in the database, then
the options for obtaining the force field parameters are:

* see if there is a different name being used for the residue
  in the :ref:`residue database<rtp>` and rename as appropriate,
* parameterize the residue / molecule yourself (lots of work, even for an expert),
* find a :ref:`topology file<top>` for the molecule, convert it to an
  :ref:`itp` file and include it in your :ref:`top` file,
* use another :ref:`force field<gmx-force-field>` which has parameters available for this,
* search the primary literature for publications for parameters for the
  residue that are consistent with the force field that is being used.

Once you have determined the parameters and topology for your residue, see
:ref:`adding a residue to a force field <gmx_add_residue>` for instructions on how to proceed.

Long bonds and/or missing atoms
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

There are probably atoms missing earlier in the :ref:`pdb` file which makes :ref:`pdb2gmx <gmx pdb2gmx>` go crazy.
Check the screen output of :ref:`pdb2gmx <gmx pdb2gmx>`, as it will tell you which one is missing. Then add
the atoms in your :ref:`pdb` file, energy minimization will put them in the right place, or
fix the side chain with e.g. the `WHAT IF <https://swift.cmbi.umcn.nl/whatif/>`_ program.


Chain identifier 'X' was used in two non-sequential blocks
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This means that within the :ref:`coordinate file<gmx-structure-files>` fed to :ref:`pdb2gmx<gmx pdb2gmx>`, the X
chain has been split, possibly by the incorrect insertion of one molecule within another.
The solution is simple: move the inserted molecule to a location within the file so that it is not splitting another molecule.
This message may also mean that the same chain identifier has been used for two
separate chains. In that case, rename the second chain to a unique identifier.

.. _gmx-atom-missing:

WARNING: atom X is missing in residue XXX Y in the pdb file
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Related to the long bonds/missing atoms error above, this error is usually quite
obvious in its meaning. That is, :ref:`pdb2gmx<gmx pdb2gmx>` expects certain atoms within
the given residue, based on the entries in the force field :ref:`rtp` file.
There are several cases to which this error applies:

* Missing hydrogen atoms; the error message may be suggesting that an entry in the :ref:`hdb`
  file is missing.  More likely, the nomenclature of your hydrogen atoms simply does not match
  what is expected by the :ref:`rtp` entry.  In this case, use ``-ignh`` to
  allow :ref:`pdb2gmx<gmx pdb2gmx>` to add the correct hydrogens for you,
  or re-name the problematic atoms.
* A terminal residue (usually the N-terminus) is missing H atoms; this usually suggests
  that the proper ``-ter`` option has not been supplied or chosen properly. In the case of
  the :ref:`AMBER force fields<gmx-amber-ff>`, nomenclature is typically the problem.
  N-terminal and C-terminal residues must be prefixed by N and C, respectively.
  For example, an N-terminal alanine should not be listed in the :ref:`pdb` file
  as ``ALA``, but rather ``NALA``, as specified in the
  `ffamber <http://ffamber.cnsm.csulb.edu/ffamber.php>`_ instructions.
* Atoms are simply missing in the structure file provided to :ref:`pdb2gmx<gmx pdb2gmx>`;
  look for ``REMARK 465`` and ``REMARK 470`` entries in the :ref:`pdb` file. These atoms
  will have to be modeled in using external software. There is no
  |Gromacs| tool to re-construct incomplete models.

Contrary to what the error message says, the use of the option ``-missing``
is almost always inappropriate.  The ``-missing`` option should only be used to
generate specialized topologies for amino acid-like molecules to take
advantage of :ref:`rtp` entries.  If you find yourself using ``-missing``
in order to generate a topology for a protein or nucleic acid,
don't; the topology produced is likely physically unrealistic.

Atom X in residue YYY not found in rtp entry
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If you are attempting to assemble a topology using :ref:`pdb2gmx <gmx pdb2gmx>`, the atom names
are expected to match those found in the :ref:`rtp` file that define the building
block(s) in your structure.  In most cases, the problem arises from a naming mismatch,
so simply re-name the atoms in your :ref:`coordinate file <gmx-structure-files>` appropriately.
In other cases, you may be supplying a structure that has residues that do not conform
to the expectations of the :ref:`force field <gmx-force-field>`, in which case you should
investigate why such a difference is occurring and make a decision based on what you
find - use a different :ref:`force field <gmx-force-field>`, manually edit the structure, etc.

No force fields found (files with name 'forcefield.itp' in subdirectories ending on '.ff')
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This means your environment is not configured to use |Gromacs| properly, because
:ref:`pdb2gmx <gmx pdb2gmx>` cannot find its databases of forcefield information. This could
happen because a |Gromacs| installation was moved from one location to another.
Either follow the instructions about
:ref:`getting access to |Gromacs|`
or re-install |Gromacs| before doing so.

Errors in :ref:`grompp <gmx grompp>`
------------------------------------

Found a second defaults directive file
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This is caused by the ``[defaults]`` directive appearing more than once in the :ref:`topology <top>` or
:ref:`force field <gmx-force-field>` files for the system - it can only appear once. A typical cause of
this is a second defaults being set in an included :ref:`topology <top>` file, :ref:`itp`, that
has been sourced from somewhere else. For specifications on how the topology files work,
see the `reference manual`_, Section 5.6.::

    [ defaults ]
    ; nbfunc comb-rule gen-pairs fudgeLJ fudgeQQ
    1       1       no       1.0       1.0

One solution is to simply comment out (or delete) the lines of code out in the file where it is included for the second time i.e.,::

    ;[ defaults ]
    ; nbfunc comb-rule gen-pairs fudgeLJ fudgeQQ
    ;1       1       no       1.0       1.0

A better approach to finding a solution is to re-think what you are doing. The ``[defaults]``
directive should only be appearing at the top of your :ref:`top` file
where you choose the :ref:`force field <gmx-force-field>`. If you are trying
to mix two :ref:`force fields <gmx-force-field>`, then you are asking for trouble.
If a molecule :ref:`itp` file tries to choose a force field, then whoever produced it is asking for trouble.

Invalid order for directive xxx
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The directives in the .top and .itp files have rules about the order in which they can
appear, and this error is seen when the order is violated. Consider the examples and
discussion in chapter 5 of the `reference manual`_, and/or from tutorial material.
The :ref:`include file mechanism <gmx-topo-include>` cannot be used to ``#include`` a
file in just any old location, because they contain directives and these have to be properly placed.

In particular, ``Invalid order for directive defaults`` is a result of defaults being
set in the :ref:`topology <top>` or :ref:`force field <gmx-force-field>` files in the inappropriate location;
the ``[defaults]`` section can only appear once and must be the first directive in
the :ref:`topology <top>`.  The ``[defaults]`` directive is typically present in the :ref:`force field <gmx-force-field>`
file (forcefield.itp), and is added to the :ref:`topology <top>` when you ``#include`` this file in the system topology.

If the directive in question is ``[atomtypes]`` (which is the most common source of this error) or
any other bonded or nonbonded ``[*types]`` directive, typically the user is adding some
non-standard species (ligand, solvent, etc) that introduces new atom types or parameters
into the system. As indicated above, these new types and parameters must appear before
any ``[moleculetype]`` directive. The :ref:`force field <gmx-force-field>` has to be
fully constructed before any molecules can be defined.

Atom index n in position_restraints out of bounds
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A common problem is placing position restraint files for multiple molecules out of order.
Recall that a position restraint :ref:`itp` file containing a ``[ position_restraints ]``
block can only belong to the ``[ moleculetype ]`` block that contains it. For example:

WRONG::

    #include "topol_A.itp"
    #include "topol_B.itp"
    #include "ligand.itp"

    #ifdef POSRES
    #include "posre_A.itp"
    #include "posre_B.itp"
    #include "ligand_posre.itp"
    #endif

RIGHT::

    #include "topol_A.itp"
    #ifdef POSRES
    #include "posre_A.itp"
    #endif

    #include "topol_B.itp"
    #ifdef POSRES
    #include "posre_B.itp"
    #endif

    #include "ligand.itp"
    #ifdef POSRES
    #include "ligand_posre.itp"
    #endif

Further, the atom index of each ``[position_restraint]`` must be relative to the
``[moleculetype]``, not relative to the system (because the parsing has not reached
``[molecules]`` yet, there is no such concept as "system"). So you cannot use the output
of a tool like :ref:`genrestr <gmx genrestr>` blindly (as ``genrestr -h`` warns).

System has non-zero total charge
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Notifies you that counter-ions may be required for the system to neutralize the charge or
there may be problems with the topology.

If the charge is not very close to an integer, then this indicates that there is a problem with the :ref:`topology <top>`.
If :ref:`pdb2gmx <gmx pdb2gmx>` has been used, then look at the right-hand
comment column of the atom listing, which lists
the cumulative charge. This should be an integer after every residue (and/or charge group where
applicable). This will assist in finding the residue where things start departing from
integer values. Also check the terminal capping groups that have been used.

If the charge is already close to an integer, then the difference is caused by
:ref:`rounding errors <gmx-floating-point>` and not a major problem.

Note for PME users: It is possible to use a uniform neutralizing background
charge in PME to compensate for a system with a net background charge.
This may however, especially for non-homogeneous systems, lead to unwanted artifacts, as
shown in \ :ref:`181 <refGroenhofEwaldArtefact>` (http://pubs.acs.org/doi/abs/10.1021/ct400626b).
Nevertheless, it is a standard practice to actually add counter-ions to make the system net neutral.

Incorrect number of parameters
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Look at the :ref:`topology <top>` file for the system. You've not given enough parameters for one of the
bonded definitions.  Sometimes this also occurs if you've mangled the :ref:`Include File Mechanism <gmx-topo-include>`
or the topology file format (see: `reference manual`_ Chapter 5) when you edited the file.

Number of coordinates in coordinate file does not match topology
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This is pointing out that, based on the information provided in the :ref:`topology <top>` file, :ref:`top`,
the total number of atoms or particles within the system does not match exactly with what
is provided within the :ref:`coordinate file <gmx-structure-files>`, often a :ref:`gro` or a :ref:`pdb`.

The most common reason for this is simply that the user has failed to update the topology file
after solvating or adding additional molecules to the system, or made a typographical error in
the number of one of the molecules within the system. Ensure that the end of the topology file
being used contains something like the following, that matches exactly with what is within the
coordinate file being used, in terms of both numbers and order of the molecules::

    [ molecules ]
    ; Compound   #mol
    Protein      1
    SOL          10189
    NA+          10

Fatal error: No such moleculetype XXX
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Each type of molecule in your ``[ molecules ]`` section of your :ref:`top` file must have a
corresponding ``[ moleculetype ]`` section defined previously, either in the :ref:`top` file or
an :ref:`included <gmx-topo-include>` :ref:`itp` file. See the `reference manual`_ section 5.6.1
for the syntax description. Your :ref:`top` file doesn't have such a definition for the
indicated molecule. Check the contents of the relevant files, how you have named your
molecules, and how you have tried to refer to them later. Pay attention to the status
of ``#ifdef`` and / or ``#include`` statements.

T-Coupling group XXX has fewer than 10% of the atoms
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

It is possible to specify separate :ref:`thermostats <gmx-thermostats>` (temperature coupling groups)
for every molecule type within a simulation. This is a particularly bad practice employed by
many new users to molecular dynamics simulations.  Doing so is a bad idea, as you can
introduce errors and artifacts that are hard to predict. In some cases it is best to have all
molecules within a single group, using the default ``System`` group. If separate coupling groups are required to avoid
the ``hot-solvent, cold-solute`` problem, then ensure that they are of ``sufficient size`` and
combine molecule types that appear together within the simulation. For example, for
a protein in water with counter-ions, one would likely want to use ``Protein`` and ``Non-Protein``.

The cut-off length is longer than half the shortest box vector or longer than the smallest box diagonal element. Increase the box size or decrease rlist
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This error is generated in the cases as noted within the message. The dimensions of the box are such that an atom will
interact with itself (when using periodic boundary conditions), thus violating the minimum image convention.
Such an event is totally unrealistic and will introduce some serious artefacts. The solution is again what is
noted within the message, either increase the size of the simulation box so that it is at an absolute minimum
twice the cut-off length in all three dimensions (take care here if are using pressure coupling,
as the box dimensions will change over time and if they decrease even slightly, you will still be
violating the minimum image convention) or decrease the cut-off length (depending on the
:ref:`force field <gmx-force-field>` utilised, this may not be an option).

Atom index (1) in bonds out of bounds
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This kind of error looks like::

    Fatal error:
    [ file spc.itp, line 32 ]
    Atom index (1) in bonds out of bounds (1-0).
    This probably means that you have inserted topology
    section "settles" in a part belonging to a different
    molecule than you intended to. in that case move the
    "settles" section to the right molecule.

This error is fairly self-explanatory. You should look at your :ref:`top` file and check that all
of the ``[molecules]`` sections contain all of the data pertaining to that molecule, and no
other data. That is, you cannot ``#include`` another molecule type (:ref:`itp` file) before
the previous ``[moleculetype]`` has ended. Consult the examples in chapter 5 of the `reference manual`_
for information on the required ordering of the different ``[sections]``. Pay attention to
the contents of any files you have :ref:`included <gmx-topo-include>` with ``#include`` directives.

This error can also arise if you are using a water model that is not enabled for use with your
chosen :ref:`force field <gmx-force-field>` by default. For example, if you are attempting to use
the SPC water model with an :ref:`AMBER force field <gmx-amber-ff>`, you will see this error.
The reason is that, in ``spc.itp``, there is no ``#ifdef`` statement defining atom types for any
of the :ref:`AMBER force fields <gmx-amber-ff>`. You can either add this section yourself, or use a different water model.

XXX non-matching atom names
^^^^^^^^^^^^^^^^^^^^^^^^^^^

This error usually indicates that the order of the :ref:`topology <top>` file does not match that
of the :ref:`coordinate file <gmx-structure-files>`.  When running :ref:`grompp <gmx grompp>`, the
program reads through the :ref:`topology <top>`, mapping the supplied parameters to the atoms in
the :ref:`coordinate <gmx-structure-files>` file.  If there is a mismatch, this error is generated.
To remedy the problem, make sure that the contents of your ``[ molecules ]`` directive
matches the exact order of the atoms in the coordinate file.

In a few cases, the error is harmless. Perhaps you are using a
:ref:`coordinate <gmx-structure-files>` file that has the old (pre-4.5) ion nomenclature.
In this case, allowing :ref:`grompp <gmx grompp>` to re-assign names is harmless.
For just about any other situation, when this error comes up, **it should not be ignored**.
Just because the ``-maxwarn`` option is available does not mean you should use it in the blind
hope of your simulation working. It will undoubtedly :ref:`blow up <blowing-up>`.

The sum of the two largest charge group radii (X) is larger than rlist - rvdw/rcoulomb
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This error warns that some combination of settings will result in poor energy conservation at the
longest cutoff, which occurs when charge groups move in or out of pair list range.
The error can have two sources:

* Your charge groups encompass too many atoms. Most charge groups should be less than 4 atoms or less.
* Your :ref:`mdp` settings are incompatible with the chosen algorithms. For switch or shift functions,
  rlist must be larger than the longest cutoff (``rvdw`` or ``rcoulomb``) to provide buffer space for charge
  groups that move beyond the neighbor searching radius. If set incorrectly, you may miss
  interactions, contributing to poor energy conservation.

A similar error ("The sum of the two largest charge group radii (X) is
larger than rlist") can arise under two following circumstances:

* The charge groups are inappropriately large or rlist is set too low.
* Molecules are broken across periodic boundaries, which is not a problem in a periodic system.
  In this case, the sum of the two largest charge groups will correspond to a value of twice
  the box vector along which the molecule is broken.


Invalid line in coordinate file for atom X
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This error arises if the format of the :ref:`gro` file is broken in some way. The
most common explanation is that the second line in the :ref:`gro` file specifies an incorrect
number of atoms, causing :ref:`grompp <gmx grompp>` to continue searching for atoms but finding box vectors.

Errors in :ref:`mdrun <gmx mdrun>`
----------------------------------

Stepsize too small, or no change in energy. Converged to machine precision, but not to the requested F\ :sub:`max`
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This may not be an error as such. It is simply informing you that during the energy
minimization process mdrun reached the limit possible to minimize the structure with your
current parameters. It does not mean that the system has not been minimized fully, but in
some situations that may be the case. If the system has a significant amount of water present,
then an E\ :sub:`pot` of the order of -10\ :sup:`5` to -10\ :sup:`6` (in conjunction with an
F\ :sub:`max` between 10 and 1000 kJ mol\ :sup:`-1` nm\ :sup:`-1`) is typically a reasonable value for
starting most MD simulations from the resulting structure. The most important result is
likely the value of F\ :sub:`max`, as it describes the slope of the potential energy
surface, i.e. how far from an energy minimum your structure lies. Only for special
purposes, such as normal mode analysis type of calculations, it may be necessary to minimize further.
Further minimization may be achieved by using a different energy minimization method or by
making use of double precision-enabled |Gromacs|.

Energy minimization has stopped because the force on at least one atom is not finite
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This likely indicates that (at least) two atoms are too close in the input coordinates, and
the forces exerted on each other are greater in magnitude than can be expressed to
the extent of the precision of |Gromacs|, and therefore minimization cannot proceed. It
is sometimes possible to minimize systems that have infinite forces with the use
of soft-core potentials, which scale down the magnitude of Lennard-Jones interactions
with the use of the |Gromacs| free energy code. This approach is an accepted workflow for
equilibration of some coarse-grained systems such as Martini.

LINCS/SETTLE/SHAKE warnings
^^^^^^^^^^^^^^^^^^^^^^^^^^^

Sometimes, when running dynamics, :ref:`mdrun <gmx mdrun>` may suddenly stop (perhaps after writing
several :ref:`pdb` files) after a series of warnings about the constraint algorithms
(e.g. LINCS, SETTLE or SHAKE) are written to the :ref:`log` file. These algorithms often
used to constrain bond lengths and/or angles. When a system is :ref:`blowing up <blowing-up>`
(i.e. exploding due to diverging forces), the constraints are usually the first thing to
fail. This doesn't necessarily mean you need to troubleshoot the constraint algorithm.
Usually it is a sign of something more fundamentally wrong (physically unrealistic) with
your system. See also the advice here about :ref:`diagnosing unstable systems <system-diagnosis>`.

1-4 interaction not within cut-off
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Some of your atoms have moved so two atoms separated by three bonds are separated by more
than the cut-off distance. **This is BAD**. Most importantly, **do not increase your cut-off**!
This error actually indicates that the atoms have very large velocities, which usually means
that (part of) your molecule(s) is (are) :ref:`blowing up <blowing-up>`. If you are using
LINCS for constraints, you probably also already got a number of LINCS warnings. When using
SHAKE this will give rise to a SHAKE error, which halts your simulation before the
``1-4 not within cutoff`` error can appear.

There can be a number of reasons for the large velocities in your system. If it happens
at the beginning of the simulation, your system might be not equilibrated well enough
(e.g. it contains some bad contacts). Try a(nother) round of energy minimization to
fix this. Otherwise you might have a very high temperature, and/or a timestep that is too
large. Experiment with these parameters until the error stops occurring. If this doesn't help,
check the validity of the parameters in your :ref:`topology <top>`!

Simulation running but no output
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Not an error as such, but mdrun appears to be chewing up CPU time but nothing is being
written to the output files. There are a number of reasons why this may occur:

* Your simulation might simply be (very) :ref:`slow <gmx-performance>`, and since output is buffered, it can take quite
  some time for output to appear in the respective files. If you are trying to fix some problems
  and you want to get output as fast as possible, you can set the environment variable ``GMX_LOG_BUFFER`` to 0.
* Something might be going wrong in your simulation, causing e.g. not-a-numbers (NAN) to be
  generated (these are the result of e.g. division by zero). Subsequent calculations
  with NAN's will generate floating point exceptions which slow everything down by orders of
  magnitude.
* You might have all ``nst*`` parameters (see your :ref:`mdp` file) set to 0, this will suppress most output.
* Your disk might be full. Eventually this will lead to :ref:`mdrun <gmx mdrun>` crashing, but
  since output is buffered, it might take a while for mdrun to realize it can't write.

Can not do Conjugate Gradients with constraints
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This means you can't do energy minimization with the conjugate gradient
algorithm if your topology has constraints defined. Please check the
`reference manual`_.

Pressure scaling more than 1%
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This error tends to be generated when the simulation box begins to oscillate (due to large
pressures and / or small coupling constants), the system starts to resonate
and :ref:`then crashes <blowing-up>`.
This can mean that the system isn't equilibrated sufficiently before using pressure coupling.
Therefore, better / more equilibration may fix the issue.

It is recommended to observe the system trajectory prior and during the crash. This may
indicate if a particular part of the system / structure is the problem.

In some cases, if the system has been equilibrated sufficiently, this error can mean that the pressure
coupling constant, :mdp:`tau-p`, is too small (particularly when using the Berendsen weak coupling method).
Increasing that value will slow down the response to pressure changes and may stop the resonance from occurring.
You are also more likely to see this error if you use Parrinello-Rahman pressure coupling
on a system that is not yet equilibrated - start with the much more forgiving
Berendsen method first, then switch to other algorithms.

This error can also appear when using a timestep that is too large, e.g. 5 fs,
in the absence of constraints and / or virtual sites.

Range Checking error
^^^^^^^^^^^^^^^^^^^^

This usually means your simulation is :ref:`blowing up <blowing-up>`. Probably you need to do better
energy minimization and/or equilibration and/or topology design.

X particles communicated to PME node Y are more than a cell length out of the domain decomposition cell of their charge group
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This is another way that :ref:`mdrun <gmx mdrun>` tells you your system is :ref:`blowing up <blowing-up>`.
If you have particles
that are flying across the system, you will get this fatal error. The message indicates that some
piece of your system is tearing apart (hence out of the "cell of their charge group"). Refer to
the :ref:`Blowing Up <blowing-up>` page for advice on how to fix this issue.

A charge group moved too far between two domain decomposition steps.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

See information above.

Software inconsistency error: Some interactions seem to be assigned multiple times
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

See information above

There is no domain decomposition for n ranks that is compatible with the given box and a minimum cell size of x nm
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This means you tried to run a parallel calculation, and when :ref:`mdrun <gmx mdrun>` tried to
partition your simulation cell into chunks, it couldn't. The minimum
cell size is controlled by the size of the largest charge group or bonded interaction and the
largest of ``rvdw``, ``rlist`` and ``rcoulomb``, some other effects of bond constraints,
and a safety margin. Thus it is not possible to run a small simulation with large numbers
of processors. So, if :ref:`grompp <gmx grompp>` warned you about a large charge group, pay
attention and reconsider its size. :ref:`mdrun <gmx mdrun>` prints a breakdown of how it
computed this minimum size in the :ref:`log` file, so you can perhaps find a cause there.

If you didn't think you were running a parallel calculation, be aware that from 4.5, |Gromacs|
uses thread-based parallelism by default. To prevent this, give :ref:`mdrun <gmx mdrun>`
the ``-ntmpi 1`` command line option. Otherwise, you might be using an MPI-enabled |Gromacs| and
not be aware of the fact.
.. _gmx-sysprep:

System preparation
==================

.. toctree::
   :hidden:

There are many ways to prepare a simulation system to run with
|Gromacs|. These often vary with the kind of scientific question being
considered, or the model physics involved. A protein-ligand atomistic
free-energy simulation might need a multi-state topology, while a
coarse-grained simulation might need to manage defaults that suit
systems with higher density.

Steps to consider
-----------------

The following general guidance should help with planning successful
simulations. Some stages are optional for some kinds of simulations.

1. Clearly identify the property or phenomena of interest to be
   studied by performing the simulation. Do not continue further until
   you are clear on this! Do not run your simulation and then seek to
   work out how to use it to test your hypothesis, because it may be
   unsuitable, or the required information was not saved.

2. Select the appropriate tools to be able to perform the simulation
   and observe the property or phenomena of interest. It is important
   to read and familiarize yourself with publications by other
   researchers on similar systems. Choices of tools include:

   - software with which to perform the simulation (consideration of
     force field may influence this decision)

   - the force field, which describes how the particles within the
     system interact with each other. Select one that is appropriate
     for the system being studied and the property or phenomena of
     interest. This is a very important and non-trivial step! Consider
     now how you will analyze your simulation data to make your
     observations.

3. Obtain or generate the initial coordinate file for each molecule to
   be placed within the system. Many different software packages are
   able to build molecular structures and assemble them into suitable
   configurations.

4. Generate the raw starting structure for the system by placing the
   molecules within the coordinate file as appropriate. Molecules may
   be specifically placed or arranged randomly. Several non-|Gromacs|
   tools are useful here; within |Gromacs| :ref:`gmx solvate`,
   :ref:`gmx insert-molecules` and :ref:`gmx genconf` solve frequent
   problems.

5. Obtain or generate the topology file for the system, using (for
   example) :ref:`gmx pdb2gmx`, :ref:`gmx x2top`, `SwissParam
   <http://swissparam.ch/>`_ (for CHARMM forcefield), `PRODRG
   <http://davapc1.bioch.dundee.ac.uk/cgi-bin/prodrg>`_ (for GROMOS96
   43A1), `Automated Topology Builder
   <https://atb.uq.edu.au/>`_ (for GROMOS96 53A6),
   `MKTOP <http://www.aribeiro.net.br/mktop>`_ (for OPLS/AA) or your
   favourite text editor in concert with chapter 5 of the |Gromacs|
   `Reference Manual`_. For the AMBER force fields, `antechamber
   <https://ambermd.org/antechamber/antechamber.html>`__ or
   `acpype <https://github.com/alanwilter/acpype>`__
   might be appropriate.

6. Describe a simulation box (e.g. using :ref:`gmx editconf`) whose
   size is appropriate for the eventual density you would like, fill
   it with solvent (e.g. using :ref:`gmx solvate`), and add any
   counter-ions needed to neutralize the system (e.g. using :ref:`gmx
   grompp` and :ref:`gmx insert-molecules`). In these steps you may
   need to edit your topology file to stay current with your
   coordinate file.

7. Run an energy minimization
   on the system (using :ref:`gmx grompp`
   and :ref:`gmx mdrun`). This is required to sort out any bad
   starting structures caused during generation of the system, which
   may cause the production simulation to crash. It may be necessary
   also to minimize your solute structure in vacuo before introducing
   solvent molecules (or your lipid bilayer or whatever else). You
   should consider using flexible water models and not using bond
   constraints or frozen groups. The use of position restraints and/or
   distance restraints should be evaluated carefully.

8. Select the appropriate simulation parameters for the equilibration
   simulation (defined in :ref:`mdp` file). You need to choose simulation
   parameters that are consistent with how force field was
   derived. You may need to simulate at NVT with position restraints
   on your solvent and/or solute to get the temperature almost right,
   then relax to NPT to fix the density (which should be done with
   Berendsen until after the density is stabilized, before a further
   switch to a barostat that produces the correct ensemble), then move
   further (if needed) to reach your production simulation ensemble
   (e.g. NVT, NVE). If you have problems here with the system :ref:`blowing
   up <blowing-up>`,
   consider using the suggestions on that page, e.g. position
   restraints on solutes, or not using bond constraints, or using
   smaller integration timesteps, or several gentler heating stage(s).

9. Run the equilibration simulation for sufficient time so that the
   system relaxes sufficiently in the target ensemble to allow the
   production run to be commenced (using :ref:`gmx grompp` and
   :ref:`gmx mdrun`, then :ref:`gmx energy` and `trajectory
   visualization tools
   <http://www.gromacs.org/Documentation/How-tos/Trajectory_Visualization>`_).

10. Select the appropriate simulation parameters for the production
    simulation (defined in :ref:`mdp` file). In particular, be careful not
    to re-generate the velocities. You still need to be consistent
    with how the force field was derived and how to measure the
    property or phenomena of interest.

.. _Reference Manual: `gmx-manual-parent-dir`_

Tips and tricks
---------------

Database files
^^^^^^^^^^^^^^

The ``share/top`` directory of a |Gromacs| installation contains
numerous plain-text helper files with the ``.dat`` file extension.
Some of the command-line tools (see :doc:`cmdline`) refer to these,
and each tool documents which files it uses, and how they are used.

If you need to modify these files (e.g. to introduce new atom types
with VDW radii into ``vdwradii.dat``), you can copy the file from your
installation directory into your working directory, and the |Gromacs|
tools will automatically load the copy from your working directory
rather than the standard one. To suppress all the standard
definitions, use an empty file in the working directory.
.. NOTE: Below is a useful bash one-liner to verify whether there are variables in this file
..        no longer present in the code.
.. ( export INPUT_FILE='docs/user-guide/environment-variables.rst' GIT_PAGER="cat "; for s in $(grep '^`'  $INPUT_FILE | sed 's/`//g' | sed 's/,/ /g'); do count=$(git grep $s | grep -v $INPUT_FILE | wc -l); [ $count -eq 0 ] && printf "%-30s%s\n" $s $count; done ; )
.. Another useful one-liner to find undocumentedvariables:
..  ( export INPUT_FILE=docs/user-guide/environment-variables.rst; GIT_PAGER="cat ";   for ss in `for s in $(git grep getenv |  sed 's/.*getenv("\(.*\)".*/\1/' | sort -u  | grep '^[A-Z]'); do [ $(grep $s $INPUT_FILE -c) -eq 0 ] && echo $s; done `; do git grep $ss ; done )

Environment Variables
=====================

|Gromacs| programs may be influenced by the use of
environment variables.  First of all, the variables set in
the ``GMXRC`` file are essential for running and
compiling |Gromacs|. Some other useful environment variables are
listed in the following sections. Most environment variables function
by being set in your shell to any non-NULL value. Specific
requirements are described below if other values need to be set. You
should consult the documentation for your shell for instructions on
how to set environment variables in the current shell, or in configuration
files for future shells. Note that requirements for exporting
environment variables to jobs run under batch control systems vary and
you should consult your local documentation for details.

Output Control
--------------
``GMX_MAXBACKUP``
        |Gromacs| automatically backs up old
        copies of files when trying to write a new file of the same
        name, and this variable controls the maximum number of
        backups that will be made, default 99. If set to 0 it fails to
        run if any output file already exists. And if set to -1 it
        overwrites any output file without making a backup.

``GMX_NO_QUOTES``
        if this is explicitly set, no cool quotes
        will be printed at the end of a program.

``GMX_SUPPRESS_DUMP``
        prevent dumping of step files during
        (for example) blowing up during failure of constraint
        algorithms.

``GMX_TPI_DUMP``
        dump all configurations to a :ref:`pdb`
        file that have an interaction energy less than the value set
        in this environment variable.

``GMX_VIEW_XVG``
        ``GMX_VIEW_EPS`` and ``GMX_VIEW_PDB``, commands used to
        automatically view :ref:`xvg`, :ref:`eps`
        and :ref:`pdb` file types, respectively; they default to ``xmgrace``,
        ``ghostview`` and ``rasmol``. Set to empty to disable
        automatic viewing of a particular file type. The command will
        be forked off and run in the background at the same priority
        as the |Gromacs| tool (which might not be what you want).
        Be careful not to use a command which blocks the terminal
        (e.g. ``vi``), since multiple instances might be run.

``GMX_LOG_BUFFER``
        the size of the buffer for file I/O. When set
        to 0, all file I/O will be unbuffered and therefore very slow.
        This can be handy for debugging purposes, because it ensures
        that all files are always totally up-to-date.

``GMX_LOGO_COLOR``
        set display color for logo in :ref:`gmx view`.

``GMX_PRINT_LONGFORMAT``
        use long float format when printing
        decimal values.

``GMX_COMPELDUMP``
        Applies for computational electrophysiology setups
        only (see reference manual). The initial structure gets dumped to
        :ref:`pdb` file, which allows to check whether multimeric channels have
        the correct PBC representation.

``GMX_TRAJECTORY_IO_VERBOSITY``
        Defaults to 1, which prints frame count e.g. when reading trajectory
        files. Set to 0 for quiet operation.

``GMX_ENABLE_GPU_TIMING``
        Enables GPU timings in the log file for CUDA and SYCL. Note that CUDA
        timings are incorrect with multiple streams, as happens with domain
        decomposition or with both non-bondeds and PME on the GPU (this is
        also the main reason why they are not turned on by default).

``GMX_DISABLE_GPU_TIMING``
        Disables GPU timings in the log file for OpenCL.

Debugging
---------
``GMX_DD_NST_DUMP``
        number of steps that elapse between dumping
        the current DD to a PDB file (default 0). This only takes effect
        during domain decomposition, so it should typically be
        0 (never), 1 (every DD phase) or a multiple of :mdp:`nstlist`.

``GMX_DD_NST_DUMP_GRID``
        number of steps that elapse between dumping
        the current DD grid to a PDB file (default 0). This only takes effect
        during domain decomposition, so it should typically be
        0 (never), 1 (every DD phase) or a multiple of :mdp:`nstlist`.

``GMX_DD_DEBUG``
        general debugging trigger for every domain
        decomposition (default 0, meaning off). Currently only checks
        global-local atom index mapping for consistency.

``GMX_DD_NPULSE``
        over-ride the number of DD pulses used
        (default 0, meaning no over-ride). Normally 1 or 2.

``GMX_DISABLE_ALTERNATING_GPU_WAIT``
        disables the specialized polling wait path used to wait for the PME and nonbonded
        GPU tasks completion to overlap to do the reduction of the resulting forces that
        arrive first. Setting this variable switches to the generic path with fixed waiting
        order.

``GMX_TEST_REQUIRED_NUMBER_OF_DEVICES``
        sets the number of GPUs required by the test suite. By default, the test suite would
        fall-back to using CPU if GPUs could not be detected. Set it to a positive integer value
        to ensure that at least this at least this number of usable GPUs are detected. Default:
        0 (not testing GPU availability).

There are a number of extra environment variables like these
that are used in debugging - check the code!

Performance and Run Control
---------------------------
``GMX_DO_GALACTIC_DYNAMICS``
        planetary simulations are made possible (just for fun) by setting
        this environment variable, which allows setting :mdp:`epsilon-r` to -1 in the :ref:`mdp`
        file. Normally, :mdp:`epsilon-r` must be greater than zero to prevent a fatal error.
        See webpage_ for example input files for a planetary simulation.

``GMX_BONDED_NTHREAD_UNIFORM``
        Value of the number of threads per rank from which to switch from uniform
        to localized bonded interaction distribution; optimal value dependent on
        system and hardware, default value is 4.

``GMX_DD_SINGLE_RANK``
        Controls the use of the domain decomposition machinery when using a single MPI rank.
        Value 0 turns DD off, 1 turns DD on. Default is automated choice based on heuristics.

``GMX_GPU_NB_EWALD_TWINCUT``
        force the use of twin-range cutoff kernel even if :mdp:`rvdw` equals
        :mdp:`rcoulomb` after PP-PME load balancing. The switch to twin-range kernels is automated,
        so this variable should be used only for benchmarking.

``GMX_GPU_NB_ANA_EWALD``
        force the use of analytical Ewald kernels. Should be used only for benchmarking.

``GMX_GPU_NB_TAB_EWALD``
        force the use of tabulated Ewald kernels. Should be used only for benchmarking.

``GMX_DISABLE_CUDA_TIMING``
        Deprecated. Use ``GMX_DISABLE_GPU_TIMING`` instead.

``GMX_GPU_DD_COMMS``
        Removed, use GMX_ENABLE_DIRECT_GPU_COMM instead.

``GMX_GPU_PME_PP_COMMS``
        Removed, use GMX_ENABLE_DIRECT_GPU_COMM instead.

``GMX_ENABLE_DIRECT_GPU_COMM``
        Enable direct GPU communication in multi-rank parallel runs.
	Note that domain decomposition with CUDA-aware MPI does not support
	multiple pulses along the second and third decomposition dimension,
	so for very small systems the feature will be disabled internally.

``GMX_ENABLE_STAGED_GPU_TO_CPU_PMEPP_COMM``
        Use a staged implementation of GPU communications for PME force
        transfers from the PME GPU to the CPU memory of a PP rank for
        thread-MPI. The staging is done via a GPU buffer on the PP
        GPU. This is expected to be beneficial for servers with direct
        communication links between GPUs.

``GMX_DISABLE_STAGED_GPU_TO_CPU_PMEPP_COMM``
        Use direct rather than staged GPU communications for PME force
        transfers from the PME GPU to the CPU memory of a PP
        rank. This may have advantages in PCIe-only servers, or for
        runs with low atom counts (which are more sensitive to latency
        than bandwidth).

``GMX_GPU_SYCL_NO_SYNCHRONIZE``
        disable synchronizations between different GPU streams in SYCL build, instead relying on SYCL runtime to
        do scheduling based on data dependencies. Experimental.

``GMX_GPU_SYCL_USE_SUBDEVICES``
        partition the GPUs that support it into sub-devices, and treat each one as an independent device.
        GPUs that can not be split are ignored. Intended for use with multi-tile GPUs.

``GMX_GPU_SYCL_USE_GPU_FFT``
        enable the use of GPU FFT with DPC++ on Intel GPUs. Unless this variable is set, only Mixed Mode PME is
        available on Intel GPUs. It has been tested with oneAPI 2022.0.1 and OpenCL backend; older oneAPI
        versions will not work or will produce wrong results. For hipSYCL builds, GPU FFT is always enabled on AMD GPUs,
        and not affected by this variable.

``GMX_CYCLE_ALL``
        times all code during runs.  Incompatible with threads.

``GMX_CYCLE_BARRIER``
        calls MPI_Barrier before each cycle start/stop call.

``GMX_DD_ORDER_ZYX``
        build domain decomposition cells in the order
        (z, y, x) rather than the default (x, y, z).

``GMX_DD_USE_SENDRECV2``
        during constraint and vsite communication, use a pair
        of ``MPI_Sendrecv`` calls instead of two simultaneous non-blocking calls
        (default 0, meaning off). Might be faster on some MPI implementations.

``GMX_DLB_BASED_ON_FLOPS``
        do domain-decomposition dynamic load balancing based on flop count rather than
        measured time elapsed (default 0, meaning off).
        This makes the load balancing reproducible, which can be useful for debugging purposes.
        A value of 1 uses the flops; a value > 1 adds (value - 1)*5% of noise to the flops to increase the imbalance and the scaling.

``GMX_DLB_MAX_BOX_SCALING``
        maximum percentage box scaling permitted per domain-decomposition
        load-balancing step (default 10)

``GMX_DD_RECORD_LOAD``
        record DD load statistics for reporting at end of the run (default 1, meaning on)

``GMX_DETAILED_PERF_STATS``
        when set, print slightly more detailed performance information
        to the :ref:`log` file. The resulting output is the way performance summary is reported in versions
        4.5.x and thus may be useful for anyone using scripts to parse :ref:`log` files or standard output.

``GMX_DISABLE_SIMD_KERNELS``
        disables architecture-specific SIMD-optimized (SSE2, SSE4.1, AVX, etc.)
        non-bonded kernels thus forcing the use of plain C kernels.

``GMX_DISABLE_GPU_TIMING``
        timing of asynchronously executed GPU operations can have a
        non-negligible overhead with short step times. Disabling timing can improve performance in these cases.
        Timings are disabled by default with CUDA and SYCL.

``GMX_DISABLE_GPU_DETECTION``
        when set, disables GPU detection even if :ref:`gmx mdrun` was compiled
        with GPU support.

``GMX_DISRE_ENSEMBLE_SIZE``
        the number of systems for distance restraint ensemble
        averaging. Takes an integer value.

``GMX_EMULATE_GPU``
        emulate GPU runs by using algorithmically equivalent CPU reference code instead of
        GPU-accelerated functions. As the CPU code is slow, it is intended to be used only for debugging purposes.

``GMX_ENX_NO_FATAL``
        disable exiting upon encountering a corrupted frame in an :ref:`edr`
        file, allowing the use of all frames up until the corruption.

``GMX_FORCE_UPDATE``
        update forces when invoking ``mdrun -rerun``.

``GMX_FORCE_GPU_AWARE_MPI``
        Override the result of build- and runtime GPU-aware MPI detection and force the use of
        direct GPU MPI communication. Aimed at cases where the user knows that the MPI library is
        GPU-aware, but |GROMACS| is not able to detect this. Note that only CUDA builds support
        such functionality.

``GMX_FORCE_UPDATE_DEFAULT_GPU``
        Force update to run on the GPU by default, overriding the ``mdrun -update auto`` option. Works similar to setting
        ``mdrun -update gpu``, but (1) falls back to the CPU code-path, if set with input that is not supported and
        (2) can be used to run update on GPUs in multi-rank cases. The latter case should be
        considered experimental since it lacks substantial testing. Also, GPU update is only supported with the GPU direct
        communications and ``GMX_FORCE_UPDATE_DEFAULT_GPU`` variable should be set simultaneously with
        ``GMX_ENABLE_DIRECT_GPU_COMM`` environment variable in multi-rank cases using library-MPI. Does not override ``mdrun -update cpu``.

``GMX_GPU_ID``
        set in the same way as ``mdrun -gpu_id``, ``GMX_GPU_ID``
        allows the user to specify different GPU IDs for different ranks, which can be useful for selecting different
        devices on different compute nodes in a cluster.  Cannot be used in conjunction with ``mdrun -gpu_id``.

``GMX_GPUTASKS``
        set in the same way as ``mdrun -gputasks``, ``GMX_GPUTASKS`` allows the mapping
        of GPU tasks to GPU device IDs to be different on different ranks, if e.g. the MPI
        runtime permits this variable to be different for different ranks. Cannot be used
        in conjunction with ``mdrun -gputasks``. Has all the same requirements as ``mdrun -gputasks``.

``GMX_GPU_DISABLE_COMPATIBILITY_CHECK``
        Disables the hardware compatibility check in OpenCL and SYCL. Useful for developers
        and allows testing the OpenCL/SYCL kernels on non-supported platforms without source code modification.

``GMX_IGNORE_FSYNC_FAILURE_ENV``
        allow :ref:`gmx mdrun` to continue even if
        a file is missing.

``GMX_LJCOMB_TOL``
        when set to a floating-point value, overrides the default tolerance of
        1e-5 for force-field floating-point parameters.

``GMX_MAXCONSTRWARN``
        if set to -1, :ref:`gmx mdrun` will
        not exit if it produces too many LINCS warnings.

``GMX_NB_MIN_CI``
        neighbor list balancing parameter used when running on GPU. Sets the
        target minimum number pair-lists in order to improve multi-processor load-balance for better
        performance with small simulation systems. Must be set to a non-negative integer,
        the 0 value disables list splitting.
        The default value is optimized for supported GPUs
        therefore changing it is not necessary for normal usage, but it can be useful on future architectures.

``GMX_NBNXN_CYCLE``
        when set, print detailed neighbor search cycle counting.

``GMX_NBNXN_EWALD_ANALYTICAL``
        force the use of analytical Ewald non-bonded kernels,
        mutually exclusive of ``GMX_NBNXN_EWALD_TABLE``.

``GMX_NBNXN_EWALD_TABLE``
        force the use of tabulated Ewald non-bonded kernels,
        mutually exclusive of ``GMX_NBNXN_EWALD_ANALYTICAL``.

``GMX_NBNXN_SIMD_2XNN``
        force the use of 2x(N+N) SIMD CPU non-bonded kernels,
        mutually exclusive of ``GMX_NBNXN_SIMD_4XN``.

``GMX_NBNXN_SIMD_4XN``
        force the use of 4xN SIMD CPU non-bonded kernels,
        mutually exclusive of ``GMX_NBNXN_SIMD_2XNN``.

``GMX_NOOPTIMIZEDKERNELS``
        deprecated, use ``GMX_DISABLE_SIMD_KERNELS`` instead.

``GMX_NO_CART_REORDER``
        used in initializing domain decomposition communicators. Rank reordering
        is default, but can be switched off with this environment variable.

``GMX_NO_LJ_COMB_RULE``
        force the use of LJ paremeter lookup instead of using combination rules
        in the non-bonded kernels.

``GMX_NO_INT``, ``GMX_NO_TERM``, ``GMX_NO_USR1``
        disable signal handlers for SIGINT,
        SIGTERM, and SIGUSR1, respectively.

``GMX_NO_NODECOMM``
        do not use separate inter- and intra-node communicators.

``GMX_NO_NONBONDED``
        skip non-bonded calculations; can be used to estimate the possible
        performance gain from adding a GPU accelerator to the current hardware setup -- assuming that this is
        fast enough to complete the non-bonded calculations while the CPU does bonded force and PME computation.
        Freezing the particles will be required to stop the system blowing up.

``GMX_PULL_PARTICIPATE_ALL``
        disable the default heuristic for when to use a separate pull MPI communicator (at >=32 ranks).

``GMX_NOPREDICT``
        shell positions are not predicted.

``GMX_NO_UPDATEGROUPS``
        turns off update groups. May allow for a decomposition of more
        domains for small systems at the cost of communication during update.

``GMX_PME_NUM_THREADS``
        set the number of OpenMP or PME threads; overrides the default set by
        :ref:`gmx mdrun`; can be used instead of the ``-npme`` command line option,
        also useful to set heterogeneous per-process/-node thread count.

``GMX_PME_P3M``
        use P3M-optimized influence function instead of smooth PME B-spline interpolation.

``GMX_PME_THREAD_DIVISION``
        PME thread division in the format "x y z" for all three dimensions. The
        sum of the threads in each dimension must equal the total number of PME threads (set in
        :envvar:`GMX_PME_NTHREADS`).

``GMX_PMEONEDD``
        if the number of domain decomposition cells is set to 1 for both x and y,
        decompose PME in one dimension.

``GMX_REQUIRE_SHELL_INIT``
        require that shell positions are initiated.

``GMX_TPIC_MASSES``
        should contain multiple masses used for test particle insertion into a cavity.
        The center of mass of the last atoms is used for insertion into the cavity.

``GMX_VERLET_BUFFER_RES``
        resolution of buffer size in Verlet cutoff scheme.  The default value is
        0.001, but can be overridden with this environment variable.

``HWLOC_XMLFILE``
        Not strictly a |Gromacs| environment variable, but on large machines
        the hwloc detection can take a few seconds if you have lots of MPI processes.
        If you run the hwloc command :command:`lstopo out.xml` and set this environment
        variable to point to the location of this file, the hwloc library will use
        the cached information instead, which can be faster.

``MPIRUN``
        the ``mpirun`` command used by :ref:`gmx tune_pme`.

``MDRUN``
        the :ref:`gmx mdrun` command used by :ref:`gmx tune_pme`.

``GMX_DISABLE_DYNAMICPRUNING``
        disables dynamic pair-list pruning. Note that :ref:`gmx mdrun` will
        still tune nstlist to the optimal value picked assuming dynamic pruning. Thus
        for good performance the -nstlist option should be used.

``GMX_NSTLIST_DYNAMICPRUNING``
        overrides the dynamic pair-list pruning interval chosen heuristically
        by mdrun. Values should be between the pruning frequency value
        (1 for CPU and 2 for GPU) and :mdp:`nstlist` ``- 1``.

.. _opencl-management:

OpenCL management
-----------------
Currently, several environment variables exist that help customize some aspects
of the OpenCL_ version of |Gromacs|. They are mostly related to the runtime
compilation of OpenCL kernels, but they are also used in device selection.

``GMX_OCL_GENCACHE``
        Enable OpenCL binary caching. Only intended to be used for
        development and (expert) testing as neither concurrency
        nor cache invalidation is implemented safely!

``GMX_OCL_NOFASTGEN``
        If set, generate and compile all algorithm flavors, otherwise
        only the flavor required for the simulation is generated and
        compiled.

``GMX_OCL_DISABLE_FASTMATH``
        Prevents the use of ``-cl-fast-relaxed-math`` compiler option.
        Note: fast math is always disabled on Intel devices due to instability.

``GMX_OCL_DUMP_LOG``
        If defined, the OpenCL build log is always written to the
        mdrun log file. Otherwise, the build log is written to the
        log file only when an error occurs.

``GMX_OCL_VERBOSE``
        If defined, it enables verbose mode for OpenCL kernel build.
        Currently available only for NVIDIA GPUs. See ``GMX_OCL_DUMP_LOG``
        for details about how to obtain the OpenCL build log.

``GMX_OCL_DUMP_INTERM_FILES``

        If defined, intermediate language code corresponding to the
        OpenCL build process is saved to file. Caching has to be
        turned off in order for this option to take effect.

            - NVIDIA GPUs: PTX code is saved in the current directory
              with the name ``device_name.ptx``
            - AMD GPUs: ``.IL/.ISA`` files will be created for each OpenCL
              kernel built.  For details about where these files are
              created check AMD documentation for ``-save-temps`` compiler
              option.

``GMX_OCL_DEBUG``
        Use in conjunction with ``OCL_FORCE_CPU`` or with an AMD device.
        It adds the debug flag to the compiler options (-g).

``GMX_OCL_NOOPT``
        Disable optimisations. Adds the option ``cl-opt-disable`` to the
        compiler options.

``GMX_OCL_FORCE_CPU``
        Force the selection of a CPU device instead of a GPU.  This
        exists only for debugging purposes. Do not expect |Gromacs| to
        function properly with this option on, it is solely for the
        simplicity of stepping in a kernel and see what is happening.

``GMX_OCL_DISABLE_I_PREFETCH``
        Disables i-atom data (type or LJ parameter) prefetch allowing
        testing.

``GMX_OCL_ENABLE_I_PREFETCH``
        Enables i-atom data (type or LJ parameter) prefetch allowing
        testing on platforms where this behavior is not default.

``GMX_OCL_FILE_PATH``
        Use this parameter to force |Gromacs| to load the OpenCL
        kernels from a custom location. Use it only if you want to
        override |Gromacs| default behavior, or if you want to test
        your own kernels.

``GMX_OCL_SHOW_DIAGNOSTICS``
        Use Intel OpenCL extension to show additional runtime performance
        diagnostics.

Analysis and Core Functions
---------------------------

``DSSP``
        used by :ref:`gmx do_dssp` to point to the ``dssp``
        executable (not just its path).

``GMX_DIPOLE_SPACING``
        spacing used by :ref:`gmx dipoles`.

``GMX_MAXRESRENUM``
        sets the maximum number of residues to be renumbered by
        :ref:`gmx grompp`. A value of -1 indicates all residues should be renumbered.

``GMX_NO_FFRTP_TER_RENAME``
        Some force fields (like AMBER) use specific names for N- and C-
        terminal residues (NXXX and CXXX) as :ref:`rtp` entries that are normally renamed. Setting
        this environment variable disables this renaming.

``GMX_FONT``
        name of X11 font used by :ref:`gmx view`.

``GMXTIMEUNIT``
        the time unit used in output files, can be
        anything in fs, ps, ns, us, ms, s, m or h.


``GMX_ENER_VERBOSE``
        make :ref:`gmx energy` and :ref:`gmx eneconv`
        loud and noisy.

``VMD_PLUGIN_PATH``
        where to find VMD plug-ins. Needed to be
        able to read file formats recognized only by a VMD plug-in.

``VMDDIR``
        base path of VMD installation.

``GMX_USE_XMGR``
        sets viewer to ``xmgr`` (deprecated) instead of ``xmgrace``.
Flow Chart
==========

This is a flow chart of a typical |Gromacs| MD run of a protein
in a box of water.
A more detailed example is available in :doc:`getting-started`.
Several steps of energy minimization may be necessary,
these consist of cycles: :ref:`gmx grompp` -> :ref:`gmx mdrun`.

.. digraph:: flowchart

   node [ shape=box, width=1.5 ]

   input_pdb [
     label="eiwit.pdb"
     tooltip="Protein Databank file"
     URL="../reference-manual/file-formats.html#pdb"
     shape=none, width=0, height=0, margin=0
     group=input
   ]
   pdb2gmx [
     label="Generate a GROMACS topology\ngmx pdb2gmx"
     tooltip="Convert PDB file to GROMACS coordinate file and topology"
     URL="../onlinehelp/gmx-pdb2gmx.html"
     width=3
     group=main
   ]

   input_pdb -> pdb2gmx [ headport=e ]

   editconf [
     label="Enlarge the box\ngmx editconf"
     tooltip="Adjust box size and placement of molecule"
     URL="../onlinehelp/gmx-editconf.html"
   ]

   pdb2gmx -> editconf [
     label="conf.gro"
     labeltooltip="GROMACS coordinate file containing molecules from PDB file"
     URL="../reference-manual/file-formats.html#gro"
   ]

   solvate [
     label="Solvate protein\ngmx solvate"
     tooltip="Fill box with water (solvate molecule)"
     URL="../onlinehelp/gmx-solvate.html"
     width=3
     group=main
   ]

   pdb2gmx -> solvate [
     label="topol.top"
     labeltooltip="GROMACS ascii topology file"
     URL="../reference-manual/file-formats.html#top"
   ]
   editconf -> solvate [
     label="conf.gro"
     labeltooltip="GROMACS coordinate file with adjusted box etc."
     URL="../reference-manual/file-formats.html#gro"
   ]

   input_mdp [
     label="grompp.mdp"
     tooltip="Parameter file from grompp (controls all MD parameters)"
     URL="../reference-manual/file-formats.html#mdp"
     shape=none, width=0, height=0, margin=0
     group=input
   ]
   grompp [
     label="Generate mdrun input file\ngmx grompp"
     tooltip="Process parameters, coordinates and topology and write binary topology"
     URL="../onlinehelp/gmx-grompp.html"
     width=3
     group=main
   ]

   input_pdb -> input_mdp [ style=invis, minlen=3 ]

   input_mdp -> grompp [ headport=e, weight=0 ]
   solvate -> grompp [
     label="conf.gro"
     labeltooltip="GROMACS coordinate file with water molecules added"
     URL="../reference-manual/file-formats.html#gro"
   ]
   solvate -> grompp [
     label="topol.top"
     labeltooltip="GROMACS ascii topology file with water molecules added"
     URL="../reference-manual/file-formats.html#top"
   ]

   mdrun [
     label="Run the simulation (EM or MD)\ngmx mdrun"
     tooltip="The moment you have all been waiting for! START YOUR MD RUN"
     URL="../onlinehelp/gmx-mdrun.html"
     width=3
     group=main
   ]

   grompp -> mdrun [
     label="topol.tpr"
     labeltooltip="Portable GROMACS binary run input file (contains all information to start MD run)"
     URL="../reference-manual/file-formats.html#tpr"
   ]
   mdrun -> mdrun [
     label="Continuation\nstate.cpt"
     labeltooltip="Checkpoint file"
     URL="../reference-manual/file-formats.html#cpt"
   ]

   analysis [
     label="Analysis\ngmx ...\ngmx view"
     tooltip="Your favourite GROMACS analysis tool"
     URL="cmdline.html#commands-by-topic"
   ]

   mdrun -> analysis [
     label="traj.xtc / traj.trr"
     labeltooltip="Portable compressed trajectory / full precision portable trajectory"
     URL="../reference-manual/file-formats.html#xtc"
   ]

   energy [
     label="Analysis\ngmx energy"
     tooltip="Energy plots, averages and fluctuations"
     URL="../onlinehelp/gmx-energy.html"
   ]

   mdrun -> energy [
     label="ener.edr"
     labeltooltip="Portable energy file"
     URL="../reference-manual/file-formats.html#edr"
   ]
.. _user guide:

**********
User guide
**********

.. highlight:: bash

This guide provides

* material introducing |Gromacs|
* practical advice for making effective use of |Gromacs|.

For getting, building and installing |Gromacs|, see the
:doc:`/install-guide/index`.
For background on algorithms and implementations, see the
:ref:`reference manual part <gmx-reference-manual-rst>` of the documentation.
If you have questions not answered by these resources, 
please visit the `GROMACS users forum <https://gromacs.bioexcel.eu/>`_
and search for a potential answer or ask a question from the community.

|GMX_MANUAL_DOI_STRING|

|GMX_SOURCE_DOI_STRING|

.. todo::

   This is going to require more organization now that
   we are getting more content available.

.. toctree::
   :maxdepth: 2

   known-issues
   getting-started
   system-preparation
   managing-simulations
   faq
   force-fields
   mdp-options
   mdrun-features
   mdrun-performance
   run-time-errors
   cmdline
   terminology
   environment-variables
   floating-point
   security
   deprecation-policy
.. _deprecation-policy:

Policy for deprecating |Gromacs| functionality
==============================================

Occasionally functionality ceases being useful, is unable to be fixed
or maintained, or its user interface needs to be improved. The
development team does this sparingly. Broken functionality might be
removed without notice if nobody willing to fix it can be found.
Working functionality will be changed only after announcing in the
previous major release the intent to remove and/or change the form of
such functionality. Thus there is typically a year for users and
external tool providers to prepare for such changes, and contact the
|Gromacs| developers to see how they might be affected and how best to
adapt. There is a :ref:`current list <deprecated-functionality>`
of deprecated functionality.

When environment variables are deprecated, it is up to the user to make
sure that their scripts are updated accordingly for the new release. In
cases where it is sensible, the development team should do the effort to
keep the old environment variables working for one extra release cycle,
before fully removing them. The user should be informed about this future
deprecation with a warning. If keeping the old environment variable is
not possible or highly problematic, setting the removed environment
variable should be triggering a warning during one release cycle.
.. _gmx-floating-point:

Floating point arithmetic
=========================

|Gromacs| spends its life doing arithmetic on real numbers, often summing many
millions of them. These real numbers are encoded on computers in so-called
binary floating-point representation. This representation is somewhat like
scientific exponential notation (but uses binary rather than decimal), and is
necessary for the fastest possible speed for calculations. Unfortunately the
laws of algebra only approximately apply to binary floating-point. In part,
this is because some real numbers that are represented simply and exactly in
decimal (like 1/5=0.2) have no exact representation in binary floating-point,
just as 1/3 cannot be represented in decimal. There are many sources you can
find with a search engine that discuss this issue more exhaustively, such as
`Wikipedia <https://en.wikipedia.org/wiki/Floating-point_arithmetic>`__ and
David Goldberg's 1991 paper *What every computer scientist should know about
floating-point arithmetic* (`article <https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html>`__,
`addendum <https://docs.oracle.com/cd/E37069_01/html/E39019/z400228248508.html>`__).
Bruce Dawson also has a written a number of very valuable blog posts on modern
floating-point programming at his
`Random ASCII site <https://randomascii.wordpress.com/category/floating-point/>`__
that are worth reading.

So, the sum of a large number of binary representations of exact decimal
numbers need not equal the expected algebraic or decimal result. Users observe
this phenomenon in sums of partial charges expressed to two decimal places that
sometimes only approximate the integer total charge to which they contribute
(however a deviation in the first decimal place would always be indicative of a
badly-formed topology).  When |Gromacs| has to represent such floating-point
numbers in output, it sometimes uses a computer form of scientific notation
known as E notation. In such notation, a number like -9.999971e-01 is actually
-0.9999971, which is close enough to -1 for purposes of assessing the total
charge of a system.

It is also not appropriate for |Gromacs| to guess to round things, because such
rounding relies on assumptions about the inputs that need not be true. Instead
the user needs to understand how their tools work.
Useful mdrun features
=======================
This section discusses features in :ref:`gmx mdrun` that don't fit well
elsewhere.

.. _single-point energy:

Re-running a simulation
-----------------------
The rerun feature allows you to take any trajectory file ``traj.trr``
and compute quantities based upon the coordinates in that file using
the model physics supplied in the ``topol.tpr`` file. It can be used
with command lines like ``mdrun -s topol -rerun traj.trr``. That :ref:`tpr`
could be different from the one that generated the trajectory. This
can be used to compute the energy or forces for exactly the
coordinates supplied as input, or to extract quantities based on
subsets of the molecular system (see :ref:`gmx convert-tpr` and
:ref:`gmx trjconv`). It is easier to do a correct "single-point" energy
evaluation with this feature than a 0-step simulation.

Neighbor searching is performed for every frame in the trajectory
independently of the value in :mdp:`nstlist`, since
:ref:`gmx mdrun` can no longer assume anything about how the
structures were generated. Naturally, no update or constraint
algorithms are ever used.

The rerun feature cannot, in general, compute many of the quantities
reported during full simulations. It does only take positions as input
(ignoring potentially present velocities), and does only report potential
energies, volume and density, dH/dl terms, and restraint information.
It does notably not report kinetic, total or conserved energy, temperature,
virial or pressure.

Running a simulation in reproducible mode
-----------------------------------------
It is generally difficult to run an efficient parallel MD simulation
that is based primarily on floating-point arithmetic and is fully
reproducible. By default, :ref:`gmx mdrun` will observe how things are going
and vary how the simulation is conducted in order to optimize
throughput. However, there is a "reproducible mode" available with
``mdrun -reprod`` that will systematically eliminate all sources of
variation within that run; repeated invocations on the same input and
hardware will be binary identical. However, running in this mode on
different hardware, or with a different compiler, etc. will not be
reproducible. This should normally only be used when investigating
possible problems.

Halting running simulations
---------------------------

When :ref:`gmx mdrun` receives a TERM or INT signal (e.g. when ctrl+C is
pressed), it will stop at the next neighbor search step or at the
second global communication step, whichever happens later.
When :ref:`gmx mdrun` receives a second TERM or INT signal and
reproducibility is not requested, it will stop at the first global
communication step.
In both cases all the usual output will be written to file and
a checkpoint file is written at the last step.
When :ref:`gmx mdrun` receives an ABRT signal or the third TERM or INT signal,
it will abort directly without writing a new checkpoint file.
When running with MPI, a signal to one of the :ref:`gmx mdrun` ranks
is sufficient, this signal should not be sent to mpirun or
the :ref:`gmx mdrun` process that is the parent of the others.

Running multi-simulations
-------------------------
There are numerous situations where running a related set of
simulations within the same invocation of mdrun are necessary or
useful. Running a replica-exchange simulation requires it, as do
simulations using ensemble-based distance or orientation restraints.
Running a related series of lambda points for a free-energy
computation is also convenient to do this way.

This feature requires
:ref:`configuring |Gromacs| with an external MPI library <mpi-support>`
so that the set of
simulations can communicate. The ``n`` simulations within the set can
use internal MPI parallelism also, so that ``mpirun -np x gmx_mpi mdrun``
for ``x`` a multiple of ``n`` will use ``x/n`` ranks per simulation.

There are two ways of organizing files when running such
simulations. All of the normal mechanisms work in either case,
including ``-deffnm``.

``-multidir``
   You must create a set of ``n`` directories for the ``n`` simulations,
   place all the relevant input files in those directories (e.g. named
   ``topol.tpr``), and run with
   ``mpirun -np x gmx_mpi mdrun -s topol -multidir <names-of-directories>``.
   If the order of the simulations
   within the multi-simulation is significant, then you are responsible
   for ordering their names when you provide them to ``-multidir``. Be
   careful with shells that do filename globbing dictionary-style, e.g.
   ``dir1 dir10 dir11 ... dir2 ...``. This option is generally the
   most convenient to use. ``gmx mdrun -table`` for the group cutoff-scheme
   works only in this mode.

Examples running multi-simulations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

::

    mpirun -np 32 gmx_mpi mdrun -multidir a b c d

Starts a multi-simulation on 32 ranks with 4 simulations. The input
and output files are found in directories ``a``, ``b``, ``c``, and ``d``.

::

    mpirun -np 32 gmx_mpi mdrun -multidir a b c d -gputasks 0000000011111111

Starts the same multi-simulation as before. On a machine with two
physical nodes and two GPUs per node, there will be 16 MPI ranks per
node, and 8 MPI ranks per simulation. The 16 MPI ranks doing PP work
on a node are mapped to the GPUs with IDs 0 and 1, even though they
come from more than one simulation. They are mapped in the order
indicated, so that the PP ranks from each simulation use a single
GPU. However, the order ``0101010101010101`` could run faster.

Running replica-exchange simulations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When running a multi-simulation, using ``gmx mdrun -replex n`` means that a
replica exchange is attempted every given number of steps. The number
of replicas is set with ``-multidir`` option, described
above.  All run input files should use a different value for the
coupling parameter (e.g. temperature), which ascends over the set of
input files. The random seed for replica exchange is set with
``-reseed``. After every exchange, the velocities are scaled and
neighbor searching is performed. See the Reference Manual for more
details on how replica exchange functions in |Gromacs|.

Controlling the length of the simulation
----------------------------------------

Normally, the length of an MD simulation is best managed through the
:ref:`mdp` option :mdp:`nsteps`, however there are situations where
more control is useful. :samp:`gmx mdrun -nsteps 100` overrides the :ref:`mdp`
file and executes 100 steps. :samp:`gmx mdrun -maxh 2.5` will terminate the
simulation shortly before 2.5 hours elapse, which can be useful when
running under cluster queues (as long as the queuing system does not
ever suspend the simulation).

Security when using |Gromacs|
=============================

.. _gmx-security:

We advise the users of |Gromacs| to be careful when using |Gromacs|
with files obtained from an unknown source (e.g. the Internet).

We cannot guarantee that the program won't crash with serious errors
that could cause execution of code with the same privileges as |Gromacs|
and e.g. delete the contents of your home directory..

Files that the user has created themselves don't carry those risks, but may
still misbehave and crash or consume large amounts of resources upon
malformed input.

Run input files obtained from outside sources should be treated with the
same caution as an executable file from the same source.

.. _managing long simulations:

Managing long simulations
=========================

Molecular simulations often extend beyond the lifetime of a single
UNIX command-line process. It is useful to be able to stop and
restart the simulation in a
way that is equivalent to a single run. When :ref:`gmx mdrun` is
halted, it writes a checkpoint file that can restart the simulation
exactly as if there was no interruption. To do this, the checkpoint
retains a full-precision version of the positions and velocities,
along with state information necessary to restart algorithms e.g.
that implement coupling to external thermal reservoirs. A restart can
be attempted using e.g. a :ref:`gro` file with velocities, but since
the :ref:`gro` file has significantly less precision, and none of
the coupling algorithms will have their state carried over, such
a restart is less continuous than a normal MD step.

Such a checkpoint file is also written periodically by :ref:`gmx
mdrun` during the run. The interval is given by the ``-cpt`` flag to
:ref:`gmx mdrun`. When :ref:`gmx mdrun` attemps to write each
successive checkpoint file, it first renames the old file with the
suffix ``_prev``, so that even if something goes wrong while writing
the new checkpoint file, only recent progress can be lost.

:ref:`gmx mdrun` can be halted in several ways:

* the number of simulation :mdp:`nsteps` can expire
* the user issues a termination signal (e.g. with Ctrl-C on the terminal)
* the job scheduler issues a termination signal when time expires
* when :ref:`gmx mdrun` detects that the length specified with
  ``-maxh`` has elapsed (this option is useful to help cooperate with
  a job scheduler, but can be problematic if jobs can be suspended)
* some kind of catastrophic failure, such as loss of power, or a
  disk filling up, or a network failing

To use the checkpoint file for a restart, use a command line such as

::

   gmx mdrun -cpi state

which directs mdrun to use the checkpoint file (which is named
``state.cpt`` by default). You can choose to give the output
checkpoint file a different name with the ``-cpo`` flag, but if so
then you must provide that name as input to ``-cpi`` when you later
use that file. You can
query the contents of checkpoint files with :ref:`gmx check` and
:ref:`gmx dump`.

Appending to output files
-------------------------

By default, :ref:`gmx mdrun` will append to the old output files. If
the previous part ended in a regular way, then the performance data at
the end of the log file will will be removed, some new information
about the run context written, and the simulation will proceed. Otherwise,
mdrun will truncate all the output files back to the time of the last
written checkpoint file, and continue from there, as if the simulation
stopped at that checkpoint in a regular way.

You can choose not to append the output files by using the
``-noappend`` flag, which forces mdrun to write each output to a
separate file, whose name includes a ".partXXXX" string to describe
which simulation part is contained in this file. This numbering starts
from zero and increases monotonically as simulations are restarted,
but does not reflect the number of simulation steps in each part. The
:mdp:`simulation-part` option can be used to set this number manually
in :ref:`gmx grompp`, which can be useful if data has been lost,
e.g. through filesystem failure or user error.

Appending will not work if any output files have been modified or
removed after mdrun wrote them, because the checkpoint file maintains
a checksum of each file that it will verify before it writes to them
again. In such cases, you must either restore the file, name them
as the checkpoint file expects, or continue with ``-noappend``. If
your original run used ``-deffnm``, and you want appending, then
your continuations must also use ``-deffnm``.

Backing up your files
---------------------

You should arrange to back up your simulation files frequently. Network
file systems on clusters can be configured in more or less conservative
ways, and this can lead :ref:`gmx mdrun` to be told that a checkpoint
file has been written to disk when actually it is still in memory
somewhere and vulnerable to a power failure or disk that fills or
fails in the meantime. The UNIX tool rsync can be a useful way to
periodically copy your simulation output to a remote storage location,
which works safely even while the simulation is underway. Keeping a copy
of the final checkpoint file from each part of a job submitted to a
cluster can be useful if a file system is unreliable.

Extending a .tpr file
---------------------

If the simulation described by :ref:`tpr` file has completed and should
be extended, use the :ref:`gmx convert-tpr` tool to extend the run, e.g.

::

   gmx convert-tpr -s previous.tpr -extend timetoextendby -o next.tpr
   gmx mdrun -s next.tpr -cpi state.cpt

The time can also be extended using the ``-until`` and ``-nsteps``
options. Note that the original :ref:`mdp` file may have generated
velocities, but that is a one-time operation within :ref:`gmx grompp`
that is never performed again by any other tool.

Changing mdp options for a restart
----------------------------------

If you wish to make changes to your simulations settings other than
length, then you should do so in the :ref:`mdp` file or topology, and
then call

::

   gmx grompp -f possibly-changed.mdp -p possibly-changed.top -c state.cpt -o new.tpr
   gmx mdrun -s new.tpr -cpi state.cpt

to instruct :ref:`gmx grompp` to copy the full-precision coordinates
in the checkpoint file into the new :ref:`tpr` file. You should
consider your choices for :mdp:`tinit`, :mdp:`init-step`,
:mdp:`nsteps` and :mdp:`simulation-part`. You should generally not
regenerate velocities with :mdp:`gen-vel`, and generally select
:mdp:`continuation` so that constraints are not re-applied before
the first integration step.

Restarts without checkpoint files
---------------------------------

It used to be possible to continue simulations without the checkpoint
files. As this approach could be unreliable or lead to
unphysical results, only restarts from checkpoints are permitted now.

Are continuations exact?
------------------------

If you had a computer with unlimited precision, or if you integrated
the time-discretized equations of motion by hand, exact continuation
would lead to identical results. But since practical computers have
limited precision and MD is chaotic, trajectories will diverge very
rapidly even if one bit is different. Such trajectories will all be
equally valid, but eventually very different. Continuation using a
checkpoint file, using the same code compiled with the same compiler
and running on the same computer architecture using the same number of
processors without GPUs (see next section) would lead to binary
identical results. However,
by default the actual work load will be balanced across the hardware
according to the observed execution times. Such trajectories are
in principle not reproducible, and in particular a run that took
place in more than one part will not be identical with an equivalent
run in one part - but neither of them is better in any sense.

Reproducibility
---------------

The following factors affect the reproducibility of a simulation, and thus its output:

* Precision (mixed / double) with double giving "better" reproducibility.
* Number of cores, due to different order in which forces are
  accumulated. For instance (a+b)+c is not necessarily binary
  identical to a+(b+c) in floating-point arithmetic.
* Type of processors. Even within the same processor family there can be slight differences.
* Optimization level when compiling.
* Optimizations at run time: e.g. the FFTW library that is typically
  used for fast Fourier transforms determines at startup which version
  of their algorithms is fastest, and uses that for the remainder of
  the calculations. Since the speed estimate is not deterministic, the
  results may vary from run to run.
* Random numbers used for instance as a seed for generating velocities
  (in |Gromacs| at the preprocessing stage).
* Uninitialized variables in the code (but there shouldn't be any)
* Dynamic linking to different versions of shared libraries (e.g. for FFTs)
* Dynamic load balancing, since particles are redistributed to
  processors based on elapsed wallclock time, which will lead to
  (a+b)+c != a+(b+c) issues as above
* Number of PME-only ranks (for parallel PME simulations)
* MPI reductions typically do not guarantee the order of the
  operations, and so the absence of associativity for floating-point
  arithmetic means the result of a reduction depends on the order
  actually chosen
* On GPUs, the reduction of e.g. non-bonded forces has a non-deterministic
  summation order, so any fast implementation is non-reprodudible by
  design.

The important question is whether it is a problem if simulations are
not completely reproducible. The answer is yes and no. Reproducibility
is a cornerstone of science in general, and hence it is important.
The `Central Limit Theorem <https://en.wikipedia.org/wiki/Central_limit_theorem>`_
tells us that in the case of infinitely long
simulations, all observables converge to their equilibrium
values. Molecular simulations in |Gromacs| adhere to this theorem, and
hence, for instance, the energy of your system will converge to a
finite value, the diffusion constant of your water molecules will
converge to a finite value, and so on. That means all the important
observables, which are the values you would like to get out of your
simulation, are reproducible. Each individual trajectory is not
reproducible, however.

However, there are a few cases where it would be useful if
trajectories were reproducible, too. These include developers doing
debugging, and searching for a rare event in a trajectory when, if
it occurs, you want to have manually saved your checkpoint file so
you can restart the simulation under different conditions, e.g.
writing output much more frequently.

In order to obtain this reproducible trajectory, it is important
to look over the list above and eliminate the factors that could
affect it. Further, using

::

   gmx mdrun -reprod

will eliminate all sources of non-reproducibility that it can,
i.e. same executable + same hardware + same shared libraries + same
run input file + same command line parameters will lead to
reproducible results.
Terminology
===========

.. _gmx-pressure:

Pressure
--------

The pressure in molecular dynamics can be computed from the kinetic energy and
the virial. 

Fluctuation
^^^^^^^^^^^

Whether or not pressure coupling is used within a simulation, the pressure
value for the simulation box will oscillate significantly. Instantaneous
pressure is meaningless, and not well-defined. Over a picosecond time scale it
usually will not be a good indicator of the true pressure. This variation is
entirely normal due to the fact that pressure is a macroscopic property and can
only be measured properly as time average, while it is being measured and/or
adjusted with pressure coupling on the microscopic scale. How much it varies
and the speed at which it does depends on the number of atoms in the system,
the type of pressure coupling used and the value of the coupling constants.
Fluctuations of the order of hundreds of bar are typical. For a box of 216
waters, fluctuations of 500-600 bar are standard. Since the fluctuations go
down with the square root of the number of particles, a system of 21600 water
molecules (100 times larger) will still have pressure fluctuations of 50-60 bar.

.. _gmx-pbc:

Periodic boundary conditions
----------------------------

Periodic boundary conditions (PBC) are used in molecular dynamics simulations
to avoid problems with boundary effects caused by finite size, and make the
system more like an infinite one, at the cost of possible periodicity effects.

Beginners visualizing a trajectory sometimes think they are observing a problem
when

* the molecule(s) does not stay in the centre of the box, or
* it appears that (parts of) the molecule(s) diffuse out of the box, or
* holes are created, or
* broken molecules appear, or
* their unit cell was a rhombic dodecahedron or cubic octahedron but it looks
  like a slanted cube after the simulation, or
* crazy bonds all across the simulation cell appear.

This is not a problem or error that is occurring, it is what you should expect.

The existence of PBC means that any atom that leaves a simulation box by, say,
the right-hand face, then enters the simulation box by the left-hand face. In
the example of a large protein, if you look at the face of the simulation box
that is opposite to the one from which the protein is protruding, then a hole
in the solvent will be visible. The reason that the molecule(s) move from where
they were initially located within the box is (for the vast majority of
simulations) they are free to diffuse around. And so they do. They are not held
in a magic location of the box. The box is not centered around anything while
performing the simulation. Molecules are not made whole as a matter of course.
Moreover, any periodic cell shape can be expressed as a parallelepiped (a.k.a.
triclinic cell), and |Gromacs| does so internally regardless of the initial
shape of the box.

These visual issues can be fixed after the conclusion of the simulation by
judicious use of the optional inputs to :ref:`gmx trjconv` to process the
trajectory files. Similarly, analyses such as RMSD of atomic positions can be
flawed when a reference structure is compared with a structure that needs
adjusting for periodicity effects, and the solution with :ref:`gmx trjconv`
follows the same lines. Some complex cases needing more than one operation will
require more than one invocation of :ref:`gmx trjconv` in order to work.

For further information, see the corresponding section in the :ref:`Reference Manual <pbc>`.

Suggested workflow
^^^^^^^^^^^^^^^^^^

Fixing periodicity effects with :ref:`gmx trjconv` to suit visualization or
analysis can be tricky. Multiple invocations can be necessary. You may need to
create custom index groups (e.g. to keep your ligand with your protein)
Following the steps below in order (omitting those not required) should help
get a pleasant result. You will need to consult ``gmx trjconv -h`` to find out
the details for each step. That's deliberate -- there is no magic "do what I
want" recipe. You have to decide what you want, first. :-)

#. First make your molecules whole if you want them whole.
#. Cluster your molecules/particles if you want them clustered.
#. If you want jumps removed, extract the first frame from the trajectory to
   use as the reference, and then use ``-pbc nojump`` with that first
   frame as reference.
#. Center your system using some criterion. Doing so shifts the system, so
   don't use ``-pbc nojump`` after this step.
#. Perhaps put everything in some box with the other ``-pbc`` or ``-ur``
   options.
#. Fit the resulting trajectory to some (other) reference structure (if
   desired), and don't use any PBC related option afterwards.

With point three, the issue is that :ref:`gmx trjconv` removes the jumps from
the first frame using the reference structure provided with -s. If the reference
structure (run input file) is not clustered/whole, using ``-pbc nojump``
will undo steps 1 and 2.

.. _gmx-thermostats:

Thermostats
-----------

Thermostats are designed to help a simulation sample from the correct ensemble
(i.e. NVT or NPT) by modulating the temperature of the system in some fashion.
First, we need to establish what we mean by temperature. In simulations, the
"instantaneous (kinetic) temperature" is usually computed from the kinetic
energy of the system using the equipartition theorem. In other words, the
temperature is computed from the system's total kinetic energy.

So, what's the goal of a thermostat? Actually, it turns out the goal is not to
keep the temperature constant, as that would mean fixing the total kinetic
energy, which would be silly and not the aim of NVT or NPT. Rather, it's to
ensure that the average temperature of a system be correct.

To see why this is the case, imagine a glass of water sitting in a room.
Suppose you can look very closely at a few molecules in some small region of
the glass, and measure their kinetic energies. You would not expect the kinetic
energy of this small number of particles to remain precisely constant; rather,
you'd expect fluctuations in the kinetic energy due to the small number of
particles. As you average over larger and larger numbers of particles, the
fluctuations in the average get smaller and smaller, so finally by the time you
look at the whole glass, you say it has "constant temperature".

Molecular dynamics simulations are often fairly small compared to a glass of
water, so we have bigger fluctuations. So it's really more appropriate here to
think of the role of a thermostat as ensuring that we have

(a) the correct average temperature, and
(b) the fluctuations of the correct size.

See the relevant section in the :ref:`Reference Manual <temp-coupling>`
for details on how temperature coupling is applied and
the types currently available.

.. _gmx-thermostats-do:

What to do
^^^^^^^^^^

Some hints on practices that generally are a good idea:

* Preferably, use a thermostat that samples the correct distribution of
  temperatures (for examples, see the corresponding manual section), in addition
  to giving you the correct average temperature.
* At least: use a thermostat that gives you the correct average temperature,
  and apply it to components of your system for which they are justified (see
  the first bullet in `What not to do`_). In some cases, using
  ``tc-grps = System`` may lead to the "hot solvent/cold solute" problem
  described in the 3rd reference in `Further reading`_.

.. _gmx-thermostats-dont:

What not to do
^^^^^^^^^^^^^^

Some hints on practices that generally not a good idea to use:

* Do not use separate thermostats for every component of your system. Some
  molecular dynamics thermostats only work well in the thermodynamic limit. A
  group must be of sufficient size to justify its own thermostat. If you use one
  thermostat for, say, a small molecule, another for protein, and another for
  water, you are likely introducing errors and artifacts that are hard to
  predict. In particular, do not couple ions in aqueous solvent in a separate
  group from that solvent. For a protein simulation, using ``tc-grps = Protein
  Non-Protein`` is usually best.
* Do not use thermostats that work well only in the limit of a large number of
  degrees of freedom for systems with few degrees of freedom. For example, do
  not use Nosé-Hoover or Berendsen thermostats for types of free energy
  calculations where you will have a component of the system with very few
  degrees of freedom in an end state (i.e. a noninteracting small molecule).

Further reading
^^^^^^^^^^^^^^^

#. Cheng, A. & Merz, K. M. Application of the Nosé-Hoover chain algorithm to
   the study of protein dynamics. *J. Phys. Chem.* **100** (5), 1927–1937
   (`1996 <http://pubs.acs.org/doi/abs/10.1021/jp951968y>`_).
#. Mor, A., Ziv, G. & Levy, Y. Simulations of proteins with inhomogeneous
   degrees of freedom: the effect of thermostats. *J. Comput. Chem.* **29**
   (12), 1992–1998 (`2008 <http://dx.doi.org/10.1002/jcc.20951>`_).
#. Lingenheil, M., Denschlag, R., Reichold, R. & Tavan, P. The
   "hot-solvent/cold-solute" problem revisited. *J. Chem. Theory Comput.* **4**
   (8), 1293–1306 (`2008 <http://pubs.acs.org/doi/abs/10.1021/ct8000365>`__).

Energy conservation
-------------------

In principle, a molecular dynamics simulation should conserve the total energy,
the total momentum and (in a non-periodic system) the total angular momentum. A
number of algorithmic and numerical issues make that this is not always the
case:

* Cut-off treatment and/or long-range electrostatics treatment (see Van Der
  Spoel, D. & van Maaren, P. J. The origin of layer structure artifacts in
  simulations of liquid water. *J. Chem. Theor. Comp.* **2**, 1–11
  (`2006 <https://doi.org/10.1021/ct0502256>`_).)
* Treatment of pair lists,
* Constraint algorithms (see e.g. Hess, B. P-LINCS: A parallel linear constraint
  solver for molecular simulation. *J. Chem. Theor. Comp.* **4**, 116–122
  (`2008 <https://doi.org/10.1021/ct700200b>`__).).
* The integration timestep.
* :ref:`Temperature coupling <gmx-thermostats>` and :ref:`pressure coupling <gmx-pressure>`.
* Round-off error (in particular in single precision), for example subtracting
  large numbers (Lippert, R. A. et al. A common, avoidable source of error in
  molecular dynamics integrators. *J. Chem. Phys.* **126**, 046101 (`2007 <http://dx.doi.org/10.1063/1.2431176>`_).).
* The choice of the integration algorithm (in |Gromacs| this is normally
  leap-frog).
* Removal of center of mass motion: when doing this in more than one group the
  conservation of energy will be violated.

Average structure
-----------------

Various |Gromacs| utilities can compute average structures. Presumably the idea
for this comes from something like an ensemble-average NMR structure. In some
cases, it makes sense to calculate an average structure (as a step on the way
to calculating root-mean-squared fluctuations (RMSF), for example, one needs
the average position of all of the atoms).

However, it's important to remember that an average structure isn't necessarily
meaningful. By way of analogy, suppose I alternate holding a ball in my left
hand, then in my right hand. What's the average position of the ball? Halfway
in between -- even though I always have it either in my left hand or my right
hand. Similarly, for structures, averages will tend to be meaningless anytime
there are separate metastable conformational states. This can happen on a
sidechain level, or for some regions of backbone, or even whole helices or
components of the secondary structure.

Thus, if you derive an average structure from a molecular dynamics simulation,
and find artifacts like unphysical bond lengths, weird structures, etc., this
doesn't necessarily mean something is wrong. It just shows the above: an
average structure from a simulation is not necessarily a physically meaningful
structure.

.. _blowing-up:

Blowing up
----------

*Blowing up* is a highly technical term used to describe a common sort of
simulation failure. In brief, it describes a failure typically due to an
unacceptably large force that ends up resulting in a failure of the integrator.

To give a bit more background, it's important to remember that molecular
dynamics numerically integrates Newton's equations of motion by taking small,
discrete timesteps, and using these timesteps to determine new velocities and
positions from velocities, positions, and forces at the previous timestep. If
forces become too large at one timestep, this can result in extremely large
changes in velocity/position when going to the next timestep. Typically, this
will result in a cascade of errors: one atom experiences a very large force one
timestep, and thus goes shooting across the system in an uncontrolled way in
the next timestep, overshooting its preferred location or landing on top of
another atom or something similar. This then results in even larger forces the
next timestep, more uncontrolled motions, and so on. Ultimately, this will
cause the simulation package to crash in some way, since it can't cope with
such situations. In simulations with constraints, the first symptom of this
will usually be some LINCS or SHAKE warning or error -- not because the
constraints are the source of the problem, but just because they're the first
thing to crash. Similarly, in simulations with domain decomposition, you may
see messages about particles being more than a cell length out of the domain
decomposition cell of their charge group, which are symptomatic of your
underlying problem, and not the domain decomposition algorithm itself. Likewise
for warnings about tabulated or 1-4 interactions being outside the distance
supported by the table. This can happen on one computer system while another
resulted in a stable simulation because of the impossibility of numerical
reproducibility of these calculations on different computer systems.

Possible causes include:

* you didn't minimize well enough,
* you have a bad starting structure, perhaps with steric clashes,
* you are using too large a timestep (particularly given your choice of
  constraints),
* you are doing particle insertion in free energy calculations without using
  soft core,
* you are using inappropriate pressure coupling (e.g. when you are not in
  equilibrium, Berendsen can be best while relaxing the volume, but you will
  need to switch to a more accurate pressure-coupling algorithm later),
* you are using inappropriate temperature coupling, perhaps on inappropriate
  groups, or
* your position restraints are to coordinates too different from those present
  in the system, or
* you have a single water molecule somewhere within the system that is
  isolated from the other water molecules, or
* you are experiencing a bug in :ref:`gmx mdrun`.

Because blowing up is due, typically, to forces that are too large for a
particular timestep size, there are a couple of basic solutions:

* make sure the forces don't get that large, or
* use a smaller timestep.

Better system preparation is a way to make sure that forces don't get large, if
the problems are occurring near the beginning of a simulation.

.. _system-diagnosis:

Diagnosing an unstable system
-----------------------------

Troubleshooting a system that is blowing up can be challenging, especially for
an inexperienced user. Here are a few general tips that one may find useful
when addressing such a scenario:

#. If the crash is happening relatively early (within a few steps), set
   ``nstxout`` (or ``nstxout-compressed``) to 1, capturing all possible frames.
   Watch the resulting trajectory to see which atoms/residues/molecules become
   unstable first.
#. Simplify the problem to try to establish a cause:

   * If you have a new box of solvent, try minimizing and simulating a single
     molecule to see if the instability is due to some inherent problem with
     the molecule's topology or if instead there are clashes in your starting
     configuration.
   * If you have a protein-ligand system, try simulating the protein alone in
     the desired solvent. If it is stable, simulate the ligand in vacuo to see
     if its topology gives stable configurations, energies, etc.
   * Remove the use of fancy algorithms, particularly if you haven't
     equilibrated thoroughly first

#. Monitor various components of the system's energy using :ref:`gmx energy`.
   If an intramolecular term is spiking, that may indicate improper bonded
   parameters, for example.
#. Make sure you haven't been ignoring error messages (missing atoms when
   running :ref:`gmx pdb2gmx`, mismatching names when running :ref:`gmx grompp`,
   etc.) or using work-arounds (like using ``gmx grompp -maxwarn`` when you
   shouldn't be) to make sure your topology is intact and being interpreted
   correctly.
#. Make sure you are using appropriate settings in your :ref:`mdp` file for the
   force field you have chosen and the type of system you have. Particularly
   important settings are treatment of cutoffs, proper neighbor searching
   interval (``nstlist``), and temperature coupling. Improper settings can lead
   to a breakdown in the model physics, even if the starting configuration of
   the system is reasonable.

When using no explict solvent, starting your equilibration with a smaller time
step than your production run can help energy equipartition more stably.

There are several common situations in which instability frequently arises,
usually in the introduction of new species (ligands or other molecules) into
the system. To determine the source of the problem, simplify the system (e.g.
the case of a protein-ligand complex) in the following way.

#. Does the protein (in water) minimize adequately by itself? This is a test of
   the integrity of the coordinates and system preparation. If this fails,
   something probably went wrong when running :ref:`gmx pdb2gmx` (see below), or
   maybe :ref:`gmx genion` placed an ion very close to the protein (it is
   random, after all).
#. Does the ligand minimize in vacuo? This is a test of the topology. If it
   does not, check your parameterization of the ligand and any implementation of
   new parameters in force field files.
#. (If previous item is successful) Does the ligand minimize in water, and/or
   does a short simulation of the ligand in water succeed?

Other sources of possible problems are in the biomolecule topology itself.

#. Did you use ``-missing`` when running :ref:`gmx pdb2gmx`? If so, don't.
   Reconstruct missing coordinates rather than ignoring them.
#. Did you override long/short bond warnings by changing the lengths? If so,
   don't. You probably have missing atoms or some terrible input geometry.

.. _gmx-md:

Molecular dynamics
------------------

Molecular dynamics (MD) is computer simulation with atoms and/or molecules
interacting using some basic laws of physics.
The |Gromacs| :ref:`Reference Manual <md>` provides a good general introduction to this area,
as well as specific material for use with |Gromacs|. The first few chapters are mandatory reading
for anybody wishing to use |Gromacs| and not waste time.

* Introduction to molecular modeling (`slides`_, `video`_)] - theoretical framework, modeling levels,
  limitations and possibilities, systems and methods (Erik Lindahl).

Books
^^^^^

There are several text books around.

Good introductory books are:

* \A. Leach (2001) Molecular Modeling: Principles and Applications.
* \T. Schlick (2002) Molecular Modeling and Simulation

With programming background:

* \D. Rapaport (1996) The Art of Molecular Dynamics Simulation
* \D. Frenkel, B. Smith (2001) Understanding Molecular Simulation

More from the physicist's view:

* \M. Allen, D. Tildesley (1989) Computer simulation of liquids
* \H.J.C. Berendsen (2007) Simulating the Physical World: Hierarchical Modeling from Quantum Mechanics to Fluid Dynamics

Types / Ensembles
^^^^^^^^^^^^^^^^^
* NVE - number of particles (N), system volume (V) and energy (E) are constant / conserved.
* NVT - number of particles (N), system volume (V) and temperature (T) are
  constant / conserved. (See :ref:`thermostats <gmx-thermostats>` for more on *constant* temperature).
* NPT - number of particles (N), system pressure (P) and temperature (T) are constant / conserved.
  (See :ref:`pressure coupling <gmx-pressure>` for more on *constant* pressure).

.. _slides: https://extras.csc.fi/chem/courses/gmx2007/Erik_Talks/preworkshop_tutorial_introduction.pdf
.. _video:  http://tv.funet.fi/medar/showRecordingInfo.do?id=/metadata/fi/csc/courses/gromacs_workshop_2007/IntroductiontoMolecularSimulationandGromacs.xml

.. _gmx-force-field:

Force field
-----------

Force fields are sets of potential functions and parametrized interactions that can be used to study
physical systems. A general introduction to their history, function and use is beyond the scope of this
guide, and the user is asked to consult either the relevant literature or 
try to start at the relevant `Wikipedia page`_.

.. _Wikipedia page: https://en.wikipedia.org/wiki/Force_field_(chemistry)
Answers to frequently asked questions (FAQs)
============================================

.. _reference manual: `gmx-manual-parent-dir`_

.. Migrated from old website

.. toctree::
   :maxdepth: 2
   :hidden:

Questions regarding |Gromacs| installation
------------------------------------------

#. Do I need to compile all utilities with MPI?

   With one rarely-used exception (:ref:`pme_error <gmx pme_error>`), only
   :ref:`mdrun <gmx mdrun>` is able to use the :ref:`MPI <mpi-support>`
   parallelism. So you only need to use the ``-DGMX_MPI=on`` flag
   when :ref:`configuring <configure-cmake>` for a build intended to run
   the main simulation engine :ref:`mdrun <gmx mdrun>`. Generally that
   is desirable when running on a multi-node cluster, and necessary
   when using multi-simulation algorithms. Usually also installing a
   build of GROMACS configured without MPI is convenient for users.


#. Should my version be compiled using double precision?

   In general, |Gromacs| only needs to be build in its default mixed-precision mode.
   For more details, see the discussion in Chapter 2 of the `reference manual`_.
   Sometimes, usage may also depend on your target system, and should be decided
   upon according to the :ref:`individual instructions <gmx-special-build>`.

Questions concerning system preparation and preprocessing
---------------------------------------------------------

#. Where can I find a solvent :ref:`coordinate file <gmx-structure-files>` for use with :ref:`solvate <gmx solvate>`?

   Suitable equilibrated boxes of solvent :ref:`structure files <gmx-structure-files>` can be found
   in the ``$GMXDIR/share/gromacs/top`` directory. That location will be searched by default
   by :ref:`solvate <gmx solvate>`, for example by using ``-cs spc216.gro`` as an argument.
   Other solvent boxes can be prepared by the user as described
   on the manual page for :ref:`solvate <gmx solvate>` and elsewhere.
   Note that suitable topology files will be needed for the solvent boxes to be useful in
   :ref:`grompp <gmx grompp>`. These are available for some force fields, and may be
   found in the respective subfolder of ``$GMXDIR/share/gromacs/top``.

#. How to prevent :ref:`solvate <gmx solvate>` from placing waters in undesired places?

   Water placement is generally well behaved when solvating proteins, but can be difficult when setting up
   membrane or micelle simulations. In those cases, waters may be placed in between the
   alkyl chains of the lipids, leading to problems later :ref:`during the simulation <blowing-up>`.
   You can either remove those waters by hand (and do the accounting for molecule types in the
   :ref:`topology <top>` file), or set up a local copy of the ``vdwradii.dat`` file from the ``$GMXLIB``
   directory, specific for your project and located in your working directory. In it, you can
   increase the vdW radius of the atoms, to suppress such interstitial insertions.
   Recommended e.g. at a common `tutorial`_ is the use of 0.375 instead of 0.15.

.. _tutorial: http://www.mdtutorials.com/gmx/lysozyme/03_solvate.html

#. How do I provide multiple definitions of bonds / dihedrals in a topology?

   You can add additional bonded terms beyond those that are normally defined for a residue (e.g. when defining
   a special ligand) by including additional copies of the respective lines under the
   ``[ bonds ]``, ``[ pairs ]``, ``[ angles ]`` and ``[ dihedrals ]`` sections in the ``[ moleculetype ]``
   section for your molecule, found either in the :ref:`itp` file
   or the :ref:`topology <top>` file. This will **add** those extra terms to the potential energy evaluation,
   but **will not** remove the previous ones. So be careful with duplicate entries. Also keep in mind that this **does not**
   apply to duplicated entries for ``[ bondtypes ]``, ``[ angletypes ]``, or ``[ dihedraltypes ]``, in force-field
   definition files, where duplicates overwrite the previous values.

#. Do I really need a :ref:`gro` file?

   The :ref:`gro` file is used in |Gromacs| as a unified :ref:`structure file <gmx-structure-files>` format
   that can be read by all utilities. The large majority of |Gromacs| routines can also use other file
   types such as :ref:`pdb`, with the limitations that no velocities are available in :ref:`this case <gmx-need-for-gro>`.
   If you need a text-based format with more digits of precision, the :ref:`g96` format is suitable and supported.

#. Do I always need to run :ref:`pdb2gmx <gmx pdb2gmx>` when I already produced an :ref:`itp` file elsewhere?

   You don't need to prepare additional files if you already have all :ref:`itp` and :ref:`top` files prepared through other tools.

   Examples for those are `CHARMM-GUI <http://www.charmm-gui.org/>`__, `ATB (Automated Topology Builder) <https://atb.uq.edu.au/>`__,
   `pmx <http://pmx.mpibpc.mpg.de/instructions.html>`__. and `PRODRG <http://davapc1.bioch.dundee.ac.uk/cgi-bin/prodrg>`__.

#. How can I build in missing atoms?

   |Gromacs| has no support for building coordinates of missing non-hydrogen atoms. If your system is missing some part,
   you will have to add the missing pieces using external programs to avoid the :ref:`missing atom <gmx-atom-missing>`
   error. This can be done using programs such as `Chimera <https://www.cgl.ucsf.edu/chimera/>`__ in combination
   with `Modeller <https://salilab.org/modeller/>`__, `Swiss PDB Viewer <https://spdbv.vital-it.ch/>`__,
   `Maestro <https://www.schrodinger.com/maestro>`__. **Do not run** a simulation that had missing atoms unless
   you know exactly why it will be stable.

#. Why is the total charge of my system not an integer like it should be?

   In :ref:`floating point <gmx-floating-point>` math, real numbers can not be displayed to arbitrary precision
   (for more on this, see e.g. `Wikipedia <https://en.wikipedia.org/wiki/Floating-point_arithmetic>`__). This means
   that very small differences to the final integer value will persist, and |Gromacs| will not lie to you and
   round those values up or down. If your charge differs from the integer value by a larger amount, e.g. at least
   0.01, this usually means that something went wrong during your system preparation

Questions regarding simulation methodology
------------------------------------------

#.  Should I couple a handful of ions to their own temperature-coupling bath?

    **No**. You need to consider the minimal size of your
    temperature coupling groups, as explained in :ref:`gmx-thermostats` and more
    specifically in :ref:`gmx-thermostats-dont`, as well as the implementation
    of your chosen thermostat as described in the `reference manual`_.

#.  Why do my grompp restarts always start from time zero?

    You can choose different values for :mdp:`tinit` and :mdp:`init-step`.

    .. todo:: Add "Continuing simulations" content (label: gmx-cont-simulation) and link.

        e.g. ``:ref:`Continuing simulations <gmx-cont-simulation>`.``

#.  Why can't I do conjugate gradient minimization with constraints?

    Minimization with the conjugate gradient scheme can not be performed with constraints
    as described in the `reference manual`_, and some additional information
    on `Wikipedia <https://en.wikipedia.org/wiki/Conjugate_gradient_method>`__.

#.  How do I hold atoms in place in my energy minimization or simulation?

    Groups may be frozen in place using ``freeze groups`` (see the `reference manual`_).
    It is more common to use a set of position
    restraints, to place penalties on movement of the atoms. Files that control this
    kind of behaviour can be created using :ref:`genrestr <gmx genrestr>`.

#.  How do I extend a completed a simulation to longer times?

    Please see the section on :ref:`managing long simulations`.
    You can either prepare a new :ref:`mdp` file, or extend the simulation time
    in the original :ref:`tpr` file using :ref:`convert-tpr <gmx convert-tpr>`.

    .. todo:: #.  How do I complete a crashed simulation?

       Need gmx-cont-crash doc target.

       .. code-block:: none

           This can be easily achieved using the checkpoint reading
           :ref:`available <gmx-cont-crash>` in |Gromacs| versions newer than 4.

    .. todo:: #.  How can I do a simulation at constant pH?

       Need gmx-howto-cph doc target.

        .. code-block:: none

           This is a rather large topic, and you should at least read the short
           :ref:`Constant pH How-To <gmx-howto-cph>` and all of the literature
           included there to get an overview over the topic.

#.  How should I compute a single-point energy?

    This is best achieved with the ``-rerun`` option to :ref:`mdrun <gmx mdrun>`.
    See the :ref:`single-point energy` section.

Parameterization and Force Fields
---------------------------------

#.  I want to simulate a molecule (protein, DNA, etc.) which complexes with
    various transition metal ions, iron-sulfur clusters, or other exotic species.
    Parameters for these exotic species aren't available in force field X.
    What should I do?

    First, you should consider how well :ref:`MD <gmx-md>` will actually describe your
    system (e.g. see some of the `recent literature <https://dx.doi.org/10.1021%2Facs.chemrev.6b00440>`__).
    Many species are infeasible to model without either atomic polarizability, or QM treatments.
    Then you need to prepare your own set of parameters and add a new residue
    to your :ref:`force field <gmx-force-field>` of choice. Then you will have to validate that
    your system behaves in a physical way, before continuing your simulation studies. You could
    also try to build a more simplified model that does not rely on the complicated additions,
    as long as it still represents the correct *real* object in the laboratory.

#.  Should I take parameters from one force field and apply them inside another that is missing them?

    **NO**. Molecules parametrized for a given
    :ref:`force field <gmx-force-field>` will not behave in a physical manner when interacting with
    other molecules that have been parametrized according to different standards. If your
    required molecule is not included in the force field you need to use, you will
    have to parametrize it yourself according to the methodology of this force field.

Analysis and Visualization
--------------------------

.. todo:: #.  How do I visualize a trajectory?

   gmx-howto-visualize doc target:

   .. code-block:: none

       Use one of the number of different programs that can visualize
       coordinate :ref:`files and trajectories <gmx-howto-visualize>`.

#.  Why am I seeing bonds being created when I watch the trajectory?

    Most visualization softwares determine the bond status of atoms depending
    on a set of predefined distances. So the bonding pattern created by them
    might not be the one defined in your :ref:`topology <top>` file. What
    matters is the information encoded in there. If the software has read
    a :ref:`tpr <tpr>` file, then the information is in reliable agreement
    with the topology you supplied to :ref:`grompp <gmx grompp>`.

#.  When visualizing a trajectory from a simulation using PBC, why are there holes or my peptide leaving the simulation box?

    Those holes and molecules moving around are just a result of molecules
    ranging over the :ref:`box boundaries and wrapping around <gmx-pbc>`,
    and are not a reason for concern. You can fix the visualization using :ref:`trjconv <gmx trjconv>`
    to prepare the structure for analysis.

#.  Why is my total simulation time not an integer like it should be?

    As the simulation time is calculated using :ref:`floating point arithmetic <gmx-floating-point>`,
    rounding errors can occur but are not of concern.
.. _gmx-getting-started:

Getting started
===============

.. toctree::
   :hidden:

   flow

In this chapter we assume the reader is familiar with Molecular Dynamics and
familiar with Unix, including the use of a text editor such as ``jot``, ``emacs``
or ``vi``. We furthermore assume the |Gromacs| software is installed properly on
your system. When you see a line like

::

    ls -l

you are supposed to type the contents of that line on your computer terminal.

Setting up your environment
---------------------------
In order to check whether you have access to |Gromacs|, please
start by entering the command:

::

    gmx -version

This command should print out information about the version of |Gromacs|
installed. If this, in contrast, returns the phrase

::

    gmx: command not found.

then you have to find where your version of |Gromacs| is installed. In
the default case, the binaries are located in
``/usr/local/gromacs/bin``, however, you can ask your local system
administrator for more information, and then follow the advice for
:ref:`getting access to |Gromacs|`.

Flowchart of typical simulation
-------------------------------
A typical simulation workflow with |Gromacs| is :doc:`illustrated here <flow>`.

Important files
---------------
Here is an overview of the most important |Gromacs| file types that you will
encounter.

Molecular Topology file (``.top``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The molecular topology file is generated by the program :ref:`gmx pdb2gmx`.
:ref:`gmx pdb2gmx` translates a :ref:`PDB` structure file of any
peptide or protein to a molecular topology file. This topology file
contains a complete description of all the interactions in your
peptide or protein.

.. _gmx-topo-include:

Topology #include file mechanism
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When constructing a system topology in a :ref:`top` file for presentation to grompp,
GROMACS uses a built-in version of the so-called C preprocessor, cpp (in GROMACS 3, it really was cpp). cpp interprets lines like::

    #include "ions.itp"

by looking for the indicated file in the current directory, the GROMACS share/top directory as indicated
by the GMXLIB environment variable, and any directory indicated by a ``-I`` flag in the value of the
include :mdp:`run parameter <include>` in the :ref:`mdp` file. It either finds this file or reports
a warning. (Note that when you supply a directory name, you should use Unix-style forward
slashes '/', not Windows-style backslashes '\' for separators.) When found, it then uses the contents
exactly as if you had cut and pasted the included file into the main file yourself. Note that you shouldn't
go and do this copy-and-paste yourself, since the main purposes of the include file mechanism are to re-use
previous work, make future changes easier, and prevent typos.

Further, ``cpp`` interprets code such as::

    #ifdef POSRES_WATER
    ; Position restraint for each water oxygen
    [ position_restraints ]
    ;  i funct       fcx        fcy        fcz
        1    1       1000       1000       1000
    #endif

by testing whether the preprocessor variable ``POSRES_WATER`` was defined somewhere (i.e. "if defined").
This could be done with ``#define POSRES_WATER`` earlier in the :ref:`top` file (or its ``#include`` files),
with a ``-D`` flag in the ``include`` run parameter as above, or on the command line to ``cpp``.
The function of the ``-D`` flag is borrowed from the similar usage in ``cpp``. The string that
follows ``-D`` must match exactly; using ``-DPOSRES`` will not trigger ``#ifdef POSRE`` or ``#ifdef DPOSRES``.
This mechanism allows you to change your :ref:`mdp` file to choose whether or not you want position
restraints on your solvent, rather than your :ref:`top` file. Note that preprocessor variables
are not the same as shell environment variables.

.. _gmx-need-for-gro:

Molecular Structure file (``.gro``, ``.pdb``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When :ref:`gmx pdb2gmx` is executed to generate a molecular topology, it
also translates the structure file (:ref:`pdb` file) to a GROMOS structure
file (:ref:`gro` file). The main difference between a :ref:`pdb` file and a gromos
file is their format and that a :ref:`gro` file can also hold
velocities. However, if you do not need the velocities, you can also
use a :ref:`PDB` file in all programs. To generate a box of solvent
molecules around the peptide, the program :ref:`gmx solvate` is
used. First the program :ref:`gmx editconf` should be used to define a box
of appropriate size around the molecule. :ref:`gmx solvate` solvates a
solute molecule (the peptide) into any solvent (in this case,
water). The output of :ref:`gmx solvate` is a gromos structure file of the
peptide solvated in water. :ref:`gmx solvate` also changes the molecular
topology file (generated by :ref:`gmx pdb2gmx`) to add solvent to the
topology.

Molecular Dynamics parameter file (``.mdp``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The Molecular Dynamics Parameter (:ref:`mdp`) file contains all information
about the Molecular Dynamics simulation itself e.g. time-step, number
of steps, temperature, pressure etc. The easiest way of handling such
a file is by adapting a sample :ref:`mdp` file. A :ref:`sample mdp file <mdp>`
is available.

Index file (``.ndx``)
^^^^^^^^^^^^^^^^^^^^^

Sometimes you may need an index file to specify actions on groups of
atoms (e.g. temperature coupling, accelerations, freezing). Usually
the default index groups will be sufficient, so for this demo we will
not consider the use of index files.

Run input file (``.tpr``)
^^^^^^^^^^^^^^^^^^^^^^^^^

The next step is to combine the molecular structure (:ref:`gro` file),
topology (:ref:`top` file) MD-parameters (:ref:`mdp` file) and (optionally) the
index file (:ref:`ndx`) to generate a run input file (:ref:`tpr` extension). This
file contains all information needed to start a simulation with
|Gromacs|. The :ref:`gmx grompp` program processes all input files and
generates the run input :ref:`tpr` file.

Trajectory file (``.trr``, ``.tng``, or ``.xtc``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Once the run input file is available, we can start the simulation. The
program which starts the simulation is called :ref:`gmx mdrun`.
The only input file of :ref:`gmx mdrun`
that you usually need in order to start a run is the run input
file (:ref:`tpr` file). The typical output files of :ref:`gmx mdrun` are the
trajectory file (:ref:`trr` file), a logfile (:ref:`log` file), and perhaps a
checkpoint file (:ref:`cpt` file).

Tutorial material
-----------------
There are several third-party `tutorials`_ available that cover aspects of using |Gromacs|.
Further information can also be found in the :doc:`How to <../how-to/index>` section.

Background reading
------------------
*   Berendsen, H.J.C., Postma, J.P.M., van Gunsteren, W.F., Hermans, J. (1981)
    Intermolecular Forces, chapter Interaction models for water in relation to
    protein hydration, pp 331-342. Dordrecht: D. Reidel Publishing Company
    Dordrecht
*   Kabsch, W., Sander, C. (1983).     Dictionary of protein secondary
    structure: Pattern recognition of hydrogen-bonded and geometrical features.
    Biopolymers **22**, 2577--2637.
*   Mierke, D.F., Kessler, H. (1991).     Molecular dynamics with dimethyl
    sulfoxide as a solvent. Conformation of a cyclic hexapeptide. J. Am. Chem.
    Soc. **113**, 9446.
*   Stryer, L. (1988).     Biochemistry vol. 1, p. 211. New York: Freeman, 3
    edition.
.. README
   See the "run control" section for a working example of the
   syntax to use when making .mdp entries, with and without detailed
   documentation for values those entries might take. Everything can
   be cross-referenced, see the examples there.

.. todo:: Make more cross-references.

Molecular dynamics parameters (.mdp options)
============================================

.. _mdp-general:

General information
-------------------

Default values are given in parentheses, or listed first among
choices. The first option in the list is always the default
option. Units are given in square brackets. The difference between a
dash and an underscore is ignored.

A :ref:`sample mdp file <mdp>` is available. This should be
appropriate to start a normal simulation. Edit it to suit your
specific needs and desires.


Preprocessing
^^^^^^^^^^^^^

.. mdp:: include

   directories to include in your topology. Format:
   ``-I/home/john/mylib -I../otherlib``

.. mdp:: define

   defines to pass to the preprocessor, default is no defines. You can
   use any defines to control options in your customized topology
   files. Options that act on existing :ref:`top` file mechanisms
   include

      ``-DFLEXIBLE`` will use flexible water instead of rigid water
      into your topology, this can be useful for normal mode analysis.

      ``-DPOSRES`` will trigger the inclusion of ``posre.itp`` into
      your topology, used for implementing position restraints.


Run control
^^^^^^^^^^^

.. mdp:: integrator

   (Despite the name, this list includes algorithms that are not
   actually integrators over time. :mdp-value:`integrator=steep` and
   all entries following it are in this category)

   .. mdp-value:: md

      A leap-frog algorithm for integrating Newton's equations of motion.

   .. mdp-value:: md-vv

      A velocity Verlet algorithm for integrating Newton's equations
      of motion.  For constant NVE simulations started from
      corresponding points in the same trajectory, the trajectories
      are analytically, but not binary, identical to the
      :mdp-value:`integrator=md` leap-frog integrator. The kinetic
      energy, which is determined from the whole step velocities and
      is therefore slightly too high. The advantage of this integrator
      is more accurate, reversible Nose-Hoover and Parrinello-Rahman
      coupling integration based on Trotter expansion, as well as
      (slightly too small) full step velocity output. This all comes
      at the cost off extra computation, especially with constraints
      and extra communication in parallel. Note that for nearly all
      production simulations the :mdp-value:`integrator=md` integrator
      is accurate enough.

   .. mdp-value:: md-vv-avek

      A velocity Verlet algorithm identical to
      :mdp-value:`integrator=md-vv`, except that the kinetic energy is
      determined as the average of the two half step kinetic energies
      as in the :mdp-value:`integrator=md` integrator, and this thus
      more accurate.  With Nose-Hoover and/or Parrinello-Rahman
      coupling this comes with a slight increase in computational
      cost.

   .. mdp-value:: sd

      An accurate and efficient leap-frog stochastic dynamics
      integrator. With constraints, coordinates needs to be
      constrained twice per integration step. Depending on the
      computational cost of the force calculation, this can take a
      significant part of the simulation time. The temperature for one
      or more groups of atoms (:mdp:`tc-grps`) is set with
      :mdp:`ref-t`, the inverse friction constant for each group is
      set with :mdp:`tau-t`.  The parameters :mdp:`tcoupl` and :mdp:`nsttcouple`
      are ignored. The random generator is initialized with
      :mdp:`ld-seed`. When used as a thermostat, an appropriate value
      for :mdp:`tau-t` is 2 ps, since this results in a friction that
      is lower than the internal friction of water, while it is high
      enough to remove excess heat NOTE: temperature deviations decay
      twice as fast as with a Berendsen thermostat with the same
      :mdp:`tau-t`.

   .. mdp-value:: bd

      An Euler integrator for Brownian or position Langevin dynamics,
      the velocity is the force divided by a friction coefficient
      (:mdp:`bd-fric`) plus random thermal noise (:mdp:`ref-t`). When
      :mdp:`bd-fric` is 0, the friction coefficient for each particle
      is calculated as mass/ :mdp:`tau-t`, as for the integrator
      :mdp-value:`integrator=sd`. The random generator is initialized
      with :mdp:`ld-seed`.

   .. mdp-value:: steep

      A steepest descent algorithm for energy minimization. The
      maximum step size is :mdp:`emstep`, the tolerance is
      :mdp:`emtol`.

   .. mdp-value:: cg

      A conjugate gradient algorithm for energy minimization, the
      tolerance is :mdp:`emtol`. CG is more efficient when a steepest
      descent step is done every once in a while, this is determined
      by :mdp:`nstcgsteep`. For a minimization prior to a normal mode
      analysis, which requires a very high accuracy, |Gromacs| should be
      compiled in double precision.

   .. mdp-value:: l-bfgs

      A quasi-Newtonian algorithm for energy minimization according to
      the low-memory Broyden-Fletcher-Goldfarb-Shanno approach. In
      practice this seems to converge faster than Conjugate Gradients,
      but due to the correction steps necessary it is not (yet)
      parallelized.

   .. mdp-value:: nm

      Normal mode analysis is performed on the structure in the :ref:`tpr`
      file.  |Gromacs| should be compiled in double precision.

   .. mdp-value:: tpi

      Test particle insertion. The last molecule in the topology is
      the test particle. A trajectory must be provided to ``mdrun
      -rerun``. This trajectory should not contain the molecule to be
      inserted. Insertions are performed :mdp:`nsteps` times in each
      frame at random locations and with random orientiations of the
      molecule. When :mdp:`nstlist` is larger than one,
      :mdp:`nstlist` insertions are performed in a sphere with radius
      :mdp:`rtpi` around a the same random location using the same
      pair list. Since pair list construction is expensive,
      one can perform several extra insertions with the same list
      almost for free. The random seed is set with
      :mdp:`ld-seed`. The temperature for the Boltzmann weighting is
      set with :mdp:`ref-t`, this should match the temperature of the
      simulation of the original trajectory. Dispersion correction is
      implemented correctly for TPI. All relevant quantities are
      written to the file specified with ``mdrun -tpi``. The
      distribution of insertion energies is written to the file
      specified with ``mdrun -tpid``. No trajectory or energy file is
      written. Parallel TPI gives identical results to single-node
      TPI. For charged molecules, using PME with a fine grid is most
      accurate and also efficient, since the potential in the system
      only needs to be calculated once per frame.

   .. mdp-value:: tpic

      Test particle insertion into a predefined cavity location. The
      procedure is the same as for :mdp-value:`integrator=tpi`, except
      that one coordinate extra is read from the trajectory, which is
      used as the insertion location. The molecule to be inserted
      should be centered at 0,0,0. |Gromacs| does not do this for you,
      since for different situations a different way of centering
      might be optimal. Also :mdp:`rtpi` sets the radius for the
      sphere around this location. Neighbor searching is done only
      once per frame, :mdp:`nstlist` is not used. Parallel
      :mdp-value:`integrator=tpic` gives identical results to
      single-rank :mdp-value:`integrator=tpic`.

   .. mdp-value:: mimic

      Enable MiMiC QM/MM coupling to run hybrid molecular dynamics.
      Keey in mind that its required to launch CPMD compiled with MiMiC as well.
      In this mode all options regarding integration (T-coupling, P-coupling,
      timestep and number of steps) are ignored as CPMD will do the integration
      instead. Options related to forces computation (cutoffs, PME parameters,
      etc.) are working as usual. Atom selection to define QM atoms is read
      from :mdp:`QMMM-grps`

.. mdp:: tinit

        (0) [ps]
        starting time for your run (only makes sense for time-based
        integrators)

.. mdp:: dt

        (0.001) [ps]
        time step for integration (only makes sense for time-based
        integrators)

.. mdp:: nsteps

        (0)
        maximum number of steps to integrate or minimize, -1 is no
        maximum

.. mdp:: init-step

        (0)
        The starting step. The time at step i in a run is
        calculated as: t = :mdp:`tinit` + :mdp:`dt` *
        (:mdp:`init-step` + i). The free-energy lambda is calculated
        as: lambda = :mdp:`init-lambda` + :mdp:`delta-lambda` *
        (:mdp:`init-step` + i). Also non-equilibrium MD parameters can
        depend on the step number. Thus for exact restarts or redoing
        part of a run it might be necessary to set :mdp:`init-step` to
        the step number of the restart frame. :ref:`gmx convert-tpr`
        does this automatically.

.. mdp:: simulation-part

         (0)
         A simulation can consist of multiple parts, each of which has
         a part number. This option specifies what that number will
         be, which helps keep track of parts that are logically the
         same simulation. This option is generally useful to set only
         when coping with a crashed simulation where files were lost.

.. mdp:: mts

   .. mdp-value:: no

      Evaluate all forces at every integration step.

   .. mdp-value:: yes

      Use a multiple timing-stepping integrator to evaluate some forces, as specified
      by :mdp:`mts-level2-forces` every :mdp:`mts-level2-factor` integration
      steps. All other forces are evaluated at every step. MTS is currently
      only supported with :mdp-value:`integrator=md`.

.. mdp:: mts-levels

        (2)
	The number of levels for the multiple time-stepping scheme.
	Currently only 2 is supported.

.. mdp:: mts-level2-forces

   (longrange-nonbonded)
   A list of one or more force groups that will be evaluated only every
   :mdp:`mts-level2-factor` steps. Supported entries are:
   ``longrange-nonbonded``, ``nonbonded``, ``pair``, ``dihedral``, ``angle``,
   ``pull`` and ``awh``. With ``pair`` the listed pair forces (such as 1-4)
   are selected. With ``dihedral`` all dihedrals are selected, including cmap.
   All other forces, including all restraints, are evaluated and
   integrated every step. When PME or Ewald is used for electrostatics
   and/or LJ interactions, ``longrange-nonbonded`` can not be omitted here.

.. mdp:: mts-level2-factor

      (2) [steps]
      Interval for computing the forces in level 2 of the multiple time-stepping
      scheme

.. mdp:: comm-mode

   .. mdp-value:: Linear

      Remove center of mass translational velocity

   .. mdp-value:: Angular

      Remove center of mass translational and rotational velocity

   .. mdp-value:: Linear-acceleration-correction

      Remove center of mass translational velocity. Correct the center of
      mass position assuming linear acceleration over :mdp:`nstcomm` steps.
      This is useful for cases where an acceleration is expected on the
      center of mass which is nearly constant over :mdp:`nstcomm` steps.
      This can occur for example when pulling on a group using an absolute
      reference.

   .. mdp-value:: None

      No restriction on the center of mass motion

.. mdp:: nstcomm

   (100) [steps]
   frequency for center of mass motion removal

.. mdp:: comm-grps

   group(s) for center of mass motion removal, default is the whole
   system


Langevin dynamics
^^^^^^^^^^^^^^^^^

.. mdp:: bd-fric

   (0) [amu ps\ :sup:`-1`]
   Brownian dynamics friction coefficient. When :mdp:`bd-fric` is 0,
   the friction coefficient for each particle is calculated as mass/
   :mdp:`tau-t`.

.. mdp:: ld-seed

   (-1) [integer]
   used to initialize random generator for thermal noise for
   stochastic and Brownian dynamics. When :mdp:`ld-seed` is set to -1,
   a pseudo random seed is used. When running BD or SD on multiple
   processors, each processor uses a seed equal to :mdp:`ld-seed` plus
   the processor number.


Energy minimization
^^^^^^^^^^^^^^^^^^^

.. mdp:: emtol

   (10.0) [kJ mol\ :sup:`-1` nm\ :sup:`-1`]
   the minimization is converged when the maximum force is smaller
   than this value

.. mdp:: emstep

   (0.01) [nm]
   initial step-size

.. mdp:: nstcgsteep

   (1000) [steps]
   frequency of performing 1 steepest descent step while doing
   conjugate gradient energy minimization.

.. mdp:: nbfgscorr

   (10)
   Number of correction steps to use for L-BFGS minimization. A higher
   number is (at least theoretically) more accurate, but slower.


Shell Molecular Dynamics
^^^^^^^^^^^^^^^^^^^^^^^^

When shells or flexible constraints are present in the system the
positions of the shells and the lengths of the flexible constraints
are optimized at every time step until either the RMS force on the
shells and constraints is less than :mdp:`emtol`, or a maximum number
of iterations :mdp:`niter` has been reached. Minimization is converged
when the maximum force is smaller than :mdp:`emtol`. For shell MD this
value should be 1.0 at most.

.. mdp:: niter

   (20)
   maximum number of iterations for optimizing the shell positions and
   the flexible constraints.

.. mdp:: fcstep

   (0) [ps\ :sup:`2`]
   the step size for optimizing the flexible constraints. Should be
   chosen as mu/(d2V/dq2) where mu is the reduced mass of two
   particles in a flexible constraint and d2V/dq2 is the second
   derivative of the potential in the constraint direction. Hopefully
   this number does not differ too much between the flexible
   constraints, as the number of iterations and thus the runtime is
   very sensitive to fcstep. Try several values!


Test particle insertion
^^^^^^^^^^^^^^^^^^^^^^^

.. mdp:: rtpi

   (0.05) [nm]
   the test particle insertion radius, see integrators
   :mdp-value:`integrator=tpi` and :mdp-value:`integrator=tpic`


Output control
^^^^^^^^^^^^^^

.. mdp:: nstxout

   (0) [steps]
   number of steps that elapse between writing coordinates to the output
   trajectory file (:ref:`trr`), the last coordinates are always written
   unless 0, which means coordinates are not written into the trajectory
   file.

.. mdp:: nstvout

   (0) [steps]
   number of steps that elapse between writing velocities to the output
   trajectory file (:ref:`trr`), the last velocities are always written
   unless 0, which means velocities are not written into the trajectory
   file.

.. mdp:: nstfout

   (0) [steps]
   number of steps that elapse between writing forces to the output
   trajectory file (:ref:`trr`), the last forces are always written,
   unless 0, which means forces are not written into the trajectory
   file.

.. mdp:: nstlog

   (1000) [steps]
   number of steps that elapse between writing energies to the log
   file, the last energies are always written.

.. mdp:: nstcalcenergy

   (100)
   number of steps that elapse between calculating the energies, 0 is
   never. This option is only relevant with dynamics. This option affects the
   performance in parallel simulations, because calculating energies
   requires global communication between all processes which can
   become a bottleneck at high parallelization.

.. mdp:: nstenergy

   (1000) [steps]
   number of steps that elapse between writing energies to energy file,
   the last energies are always written, should be a multiple of
   :mdp:`nstcalcenergy`. Note that the exact sums and fluctuations
   over all MD steps modulo :mdp:`nstcalcenergy` are stored in the
   energy file, so :ref:`gmx energy` can report exact energy averages
   and fluctuations also when :mdp:`nstenergy` > 1

.. mdp:: nstxout-compressed

   (0) [steps]
   number of steps that elapse between writing position coordinates
   using lossy compression (:ref:`xtc` file), 0 for not writing
   compressed coordinates output.

.. mdp:: compressed-x-precision

   (1000) [real]
   precision with which to write to the compressed trajectory file

.. mdp:: compressed-x-grps

   group(s) to write to the compressed trajectory file, by default the
   whole system is written (if :mdp:`nstxout-compressed` > 0)

.. mdp:: energygrps

   group(s) for which to write to write short-ranged non-bonded
   potential energies to the energy file (not supported on GPUs)


Neighbor searching
^^^^^^^^^^^^^^^^^^

.. mdp:: cutoff-scheme

   .. mdp-value:: Verlet

      Generate a pair list with buffering. The buffer size is
      automatically set based on :mdp:`verlet-buffer-tolerance`,
      unless this is set to -1, in which case :mdp:`rlist` will be
      used.

   .. mdp-value:: group

      Generate a pair list for groups of atoms, corresponding
      to the charge groups in the topology. This option is no longer
      supported.

.. mdp:: nstlist

   (10) [steps]

   .. mdp-value:: >0

      Frequency to update the neighbor list. When dynamics and
      :mdp:`verlet-buffer-tolerance` set, :mdp:`nstlist` is actually
      a minimum value and :ref:`gmx mdrun` might increase it, unless
      it is set to 1. With parallel simulations and/or non-bonded
      force calculation on the GPU, a value of 20 or 40 often gives
      the best performance. With energy minimization this parameter
      is not used as the pair list is updated when at least one atom
      has moved by more than half the pair list buffer size.

   .. mdp-value:: 0

      The neighbor list is only constructed once and never
      updated. This is mainly useful for vacuum simulations in which
      all particles see each other. But vacuum simulations are
      (temporarily) not supported.

   .. mdp-value:: <0

      Unused.

.. mdp:: pbc

   .. mdp-value:: xyz

      Use periodic boundary conditions in all directions.

   .. mdp-value:: no

      Use no periodic boundary conditions, ignore the box. To simulate
      without cut-offs, set all cut-offs and :mdp:`nstlist` to 0. For
      best performance without cut-offs on a single MPI rank, set
      :mdp:`nstlist` to zero and :mdp-value:`ns-type=simple`.

   .. mdp-value:: xy

      Use periodic boundary conditions in x and y directions
      only. This works only with :mdp-value:`ns-type=grid` and can be used
      in combination with walls_. Without walls or with only one wall
      the system size is infinite in the z direction. Therefore
      pressure coupling or Ewald summation methods can not be
      used. These disadvantages do not apply when two walls are used.

.. mdp:: periodic-molecules

   .. mdp-value:: no

      molecules are finite, fast molecular PBC can be used

   .. mdp-value:: yes

      for systems with molecules that couple to themselves through the
      periodic boundary conditions, this requires a slower PBC
      algorithm and molecules are not made whole in the output

.. mdp:: verlet-buffer-tolerance

   (0.005) [kJ mol\ :sup:`-1` ps\ :sup:`-1`]

   Used when performing a simulation with dynamics. This sets
   the maximum allowed error for pair interactions per particle caused
   by the Verlet buffer, which indirectly sets :mdp:`rlist`. As both
   :mdp:`nstlist` and the Verlet buffer size are fixed (for
   performance reasons), particle pairs not in the pair list can
   occasionally get within the cut-off distance during
   :mdp:`nstlist` -1 steps. This causes very small jumps in the
   energy. In a constant-temperature ensemble, these very small energy
   jumps can be estimated for a given cut-off and :mdp:`rlist`. The
   estimate assumes a homogeneous particle distribution, hence the
   errors might be slightly underestimated for multi-phase
   systems. (See the `reference manual`_ for details). For longer
   pair-list life-time (:mdp:`nstlist` -1) * :mdp:`dt` the buffer is
   overestimated, because the interactions between particles are
   ignored. Combined with cancellation of errors, the actual drift of
   the total energy is usually one to two orders of magnitude
   smaller. Note that the generated buffer size takes into account
   that the |Gromacs| pair-list setup leads to a reduction in the
   drift by a factor 10, compared to a simple particle-pair based
   list. Without dynamics (energy minimization etc.), the buffer is 5%
   of the cut-off. For NVE simulations the initial temperature is
   used, unless this is zero, in which case a buffer of 10% is
   used. For NVE simulations the tolerance usually needs to be lowered
   to achieve proper energy conservation on the nanosecond time
   scale. To override the automated buffer setting, use
   :mdp:`verlet-buffer-tolerance` =-1 and set :mdp:`rlist` manually.

.. mdp:: rlist

   (1) [nm]
   Cut-off distance for the short-range neighbor list. With dynamics,
   this is by default set by the :mdp:`verlet-buffer-tolerance` option
   and the value of :mdp:`rlist` is ignored. Without dynamics, this
   is by default set to the maximum cut-off plus 5% buffer, except
   for test particle insertion, where the buffer is managed exactly
   and automatically. For NVE simulations, where the automated
   setting is not possible, the advised procedure is to run :ref:`gmx grompp`
   with an NVT setup with the expected temperature and copy the resulting
   value of :mdp:`rlist` to the NVE setup.


Electrostatics
^^^^^^^^^^^^^^

.. mdp:: coulombtype

   .. mdp-value:: Cut-off

      Plain cut-off with pair list radius :mdp:`rlist` and
      Coulomb cut-off :mdp:`rcoulomb`, where :mdp:`rlist` >=
      :mdp:`rcoulomb`.

   .. mdp-value:: Ewald

      Classical Ewald sum electrostatics. The real-space cut-off
      :mdp:`rcoulomb` should be equal to :mdp:`rlist`. Use *e.g.*
      :mdp:`rlist` =0.9, :mdp:`rcoulomb` =0.9. The highest magnitude
      of wave vectors used in reciprocal space is controlled by
      :mdp:`fourierspacing`. The relative accuracy of
      direct/reciprocal space is controlled by :mdp:`ewald-rtol`.

      NOTE: Ewald scales as O(N\ :sup:`3/2`) and is thus extremely slow for
      large systems. It is included mainly for reference - in most
      cases PME will perform much better.

   .. mdp-value:: PME

      Fast smooth Particle-Mesh Ewald (SPME) electrostatics. Direct
      space is similar to the Ewald sum, while the reciprocal part is
      performed with FFTs. Grid dimensions are controlled with
      :mdp:`fourierspacing` and the interpolation order with
      :mdp:`pme-order`. With a grid spacing of 0.1 nm and cubic
      interpolation the electrostatic forces have an accuracy of
      2-3*10\ :sup:`-4`. Since the error from the vdw-cutoff is larger than
      this you might try 0.15 nm. When running in parallel the
      interpolation parallelizes better than the FFT, so try
      decreasing grid dimensions while increasing interpolation.

   .. mdp-value:: P3M-AD

      Particle-Particle Particle-Mesh algorithm with analytical
      derivative for for long range electrostatic interactions. The
      method and code is identical to SPME, except that the influence
      function is optimized for the grid. This gives a slight increase
      in accuracy.

   .. mdp-value:: Reaction-Field

      Reaction field electrostatics with Coulomb cut-off
      :mdp:`rcoulomb`, where :mdp:`rlist` >= :mdp:`rvdw`. The
      dielectric constant beyond the cut-off is
      :mdp:`epsilon-rf`. The dielectric constant can be set to
      infinity by setting :mdp:`epsilon-rf` =0.

   .. mdp-value:: User

      Currently unsupported.
      :ref:`gmx mdrun` will now expect to find a file ``table.xvg``
      with user-defined potential functions for repulsion, dispersion
      and Coulomb. When pair interactions are present, :ref:`gmx
      mdrun` also expects to find a file ``tablep.xvg`` for the pair
      interactions. When the same interactions should be used for
      non-bonded and pair interactions the user can specify the same
      file name for both table files. These files should contain 7
      columns: the ``x`` value, ``f(x)``, ``-f'(x)``, ``g(x)``,
      ``-g'(x)``, ``h(x)``, ``-h'(x)``, where ``f(x)`` is the Coulomb
      function, ``g(x)`` the dispersion function and ``h(x)`` the
      repulsion function. When :mdp:`vdwtype` is not set to User the
      values for ``g``, ``-g'``, ``h`` and ``-h'`` are ignored. For
      the non-bonded interactions ``x`` values should run from 0 to
      the largest cut-off distance + :mdp:`table-extension` and
      should be uniformly spaced. For the pair interactions the table
      length in the file will be used. The optimal spacing, which is
      used for non-user tables, is ``0.002 nm`` when you run in mixed
      precision or ``0.0005 nm`` when you run in double precision. The
      function value at ``x=0`` is not important. More information is
      in the printed manual.

   .. mdp-value:: PME-Switch

      Currently unsupported.
      A combination of PME and a switch function for the direct-space
      part (see above). :mdp:`rcoulomb` is allowed to be smaller than
      :mdp:`rlist`.

   .. mdp-value:: PME-User

      Currently unsupported.
      A combination of PME and user tables (see
      above). :mdp:`rcoulomb` is allowed to be smaller than
      :mdp:`rlist`. The PME mesh contribution is subtracted from the
      user table by :ref:`gmx mdrun`. Because of this subtraction the
      user tables should contain about 10 decimal places.

   .. mdp-value:: PME-User-Switch

      Currently unsupported.
      A combination of PME-User and a switching function (see
      above). The switching function is applied to final
      particle-particle interaction, *i.e.* both to the user supplied
      function and the PME Mesh correction part.

.. mdp:: coulomb-modifier

   .. mdp-value:: Potential-shift

      Shift the Coulomb potential by a constant such that it is zero
      at the cut-off. This makes the potential the integral of the
      force. Note that this does not affect the forces or the
      sampling.

   .. mdp-value:: None

      Use an unmodified Coulomb potential. This can be useful
      when comparing energies with those computed with other software.

.. mdp:: rcoulomb-switch

   (0) [nm]
   where to start switching the Coulomb potential, only relevant
   when force or potential switching is used

.. mdp:: rcoulomb

   (1) [nm]
   The distance for the Coulomb cut-off. Note that with PME this value
   can be increased by the PME tuning in :ref:`gmx mdrun` along with
   the PME grid spacing.

.. mdp:: epsilon-r

   (1)
   The relative dielectric constant. A value of 0 means infinity.

.. mdp:: epsilon-rf

   (0)
   The relative dielectric constant of the reaction field. This
   is only used with reaction-field electrostatics. A value of 0
   means infinity.


Van der Waals
^^^^^^^^^^^^^

.. mdp:: vdwtype

   .. mdp-value:: Cut-off

      Plain cut-off with pair list radius :mdp:`rlist` and VdW
      cut-off :mdp:`rvdw`, where :mdp:`rlist` >= :mdp:`rvdw`.

   .. mdp-value:: PME

      Fast smooth Particle-mesh Ewald (SPME) for VdW interactions. The
      grid dimensions are controlled with :mdp:`fourierspacing` in
      the same way as for electrostatics, and the interpolation order
      is controlled with :mdp:`pme-order`. The relative accuracy of
      direct/reciprocal space is controlled by :mdp:`ewald-rtol-lj`,
      and the specific combination rules that are to be used by the
      reciprocal routine are set using :mdp:`lj-pme-comb-rule`.

   .. mdp-value:: Shift

      This functionality is deprecated and replaced by using
      :mdp-value:`vdwtype=Cut-off` with :mdp-value:`vdw-modifier=Force-switch`.
      The LJ (not Buckingham) potential is decreased over the whole range and
      the forces decay smoothly to zero between :mdp:`rvdw-switch` and
      :mdp:`rvdw`.

   .. mdp-value:: Switch

      This functionality is deprecated and replaced by using
      :mdp-value:`vdwtype=Cut-off` with :mdp-value:`vdw-modifier=Potential-switch`.
      The LJ (not Buckingham) potential is normal out to :mdp:`rvdw-switch`, after
      which it is switched off to reach zero at :mdp:`rvdw`. Both the
      potential and force functions are continuously smooth, but be
      aware that all switch functions will give rise to a bulge
      (increase) in the force (since we are switching the
      potential).

   .. mdp-value:: User

      Currently unsupported.
      See user for :mdp:`coulombtype`. The function value at zero is
      not important. When you want to use LJ correction, make sure
      that :mdp:`rvdw` corresponds to the cut-off in the user-defined
      function. When :mdp:`coulombtype` is not set to User the values
      for the ``f`` and ``-f'`` columns are ignored.

.. mdp:: vdw-modifier

   .. mdp-value:: Potential-shift

      Shift the Van der Waals potential by a constant such that it is
      zero at the cut-off. This makes the potential the integral of
      the force. Note that this does not affect the forces or the
      sampling.

   .. mdp-value:: None

      Use an unmodified Van der Waals potential. This can be useful
      when comparing energies with those computed with other software.

   .. mdp-value:: Force-switch

      Smoothly switches the forces to zero between :mdp:`rvdw-switch`
      and :mdp:`rvdw`. This shifts the potential shift over the whole
      range and switches it to zero at the cut-off. Note that this is
      more expensive to calculate than a plain cut-off and it is not
      required for energy conservation, since Potential-shift
      conserves energy just as well.

   .. mdp-value:: Potential-switch

      Smoothly switches the potential to zero between
      :mdp:`rvdw-switch` and :mdp:`rvdw`. Note that this introduces
      articifically large forces in the switching region and is much
      more expensive to calculate. This option should only be used if
      the force field you are using requires this.

.. mdp:: rvdw-switch

   (0) [nm]
   where to start switching the LJ force and possibly the potential,
   only relevant when force or potential switching is used

.. mdp:: rvdw

   (1) [nm]
   distance for the LJ or Buckingham cut-off

.. mdp:: DispCorr

   .. mdp-value:: no

      don't apply any correction

   .. mdp-value:: EnerPres

      apply long range dispersion corrections for Energy and Pressure

   .. mdp-value:: Ener

      apply long range dispersion corrections for Energy only


Tables
^^^^^^

.. mdp:: table-extension

   (1) [nm]
   Extension of the non-bonded potential lookup tables beyond the
   largest cut-off distance. With actual non-bonded interactions
   the tables are never accessed beyond the cut-off. But a longer
   table length might be needed for the 1-4 interactions, which
   are always tabulated irrespective of the use of tables for
   the non-bonded interactions.

.. mdp:: energygrp-table

   Currently unsupported.
   When user tables are used for electrostatics and/or VdW, here one
   can give pairs of energy groups for which separate user tables
   should be used. The two energy groups will be appended to the table
   file name, in order of their definition in :mdp:`energygrps`,
   separated by underscores. For example, if ``energygrps = Na Cl
   Sol`` and ``energygrp-table = Na Na Na Cl``, :ref:`gmx mdrun` will
   read ``table_Na_Na.xvg`` and ``table_Na_Cl.xvg`` in addition to the
   normal ``table.xvg`` which will be used for all other energy group
   pairs.


Ewald
^^^^^

.. mdp:: fourierspacing

   (0.12) [nm]
   For ordinary Ewald, the ratio of the box dimensions and the spacing
   determines a lower bound for the number of wave vectors to use in
   each (signed) direction. For PME and P3M, that ratio determines a
   lower bound for the number of Fourier-space grid points that will
   be used along that axis. In all cases, the number for each
   direction can be overridden by entering a non-zero value for that
   :mdp:`fourier-nx` direction. For optimizing the relative load of
   the particle-particle interactions and the mesh part of PME, it is
   useful to know that the accuracy of the electrostatics remains
   nearly constant when the Coulomb cut-off and the PME grid spacing
   are scaled by the same factor. Note that this spacing can be scaled
   up along with :mdp:`rcoulomb` by the PME tuning in :ref:`gmx mdrun`.

.. mdp:: fourier-nx
.. mdp:: fourier-ny
.. mdp:: fourier-nz

   (0)
   Highest magnitude of wave vectors in reciprocal space when using Ewald.
   Grid size when using PME or P3M. These values override
   :mdp:`fourierspacing` per direction. The best choice is powers of
   2, 3, 5 and 7. Avoid large primes. Note that these grid sizes can
   be reduced along with scaling up :mdp:`rcoulomb` by the PME tuning
   in :ref:`gmx mdrun`.

.. mdp:: pme-order

   (4)
   Interpolation order for PME. 4 equals cubic interpolation. You
   might try 6/8/10 when running in parallel and simultaneously
   decrease grid dimension.

.. mdp:: ewald-rtol

   (10\ :sup:`-5`)
   The relative strength of the Ewald-shifted direct potential at
   :mdp:`rcoulomb` is given by :mdp:`ewald-rtol`. Decreasing this
   will give a more accurate direct sum, but then you need more wave
   vectors for the reciprocal sum.

.. mdp:: ewald-rtol-lj

   (10\ :sup:`-3`)
   When doing PME for VdW-interactions, :mdp:`ewald-rtol-lj` is used
   to control the relative strength of the dispersion potential at
   :mdp:`rvdw` in the same way as :mdp:`ewald-rtol` controls the
   electrostatic potential.

.. mdp:: lj-pme-comb-rule

   (Geometric)
   The combination rules used to combine VdW-parameters in the
   reciprocal part of LJ-PME. Geometric rules are much faster than
   Lorentz-Berthelot and usually the recommended choice, even when the
   rest of the force field uses the Lorentz-Berthelot rules.

   .. mdp-value:: Geometric

      Apply geometric combination rules

   .. mdp-value:: Lorentz-Berthelot

      Apply Lorentz-Berthelot combination rules

.. mdp:: ewald-geometry

   .. mdp-value:: 3d

      The Ewald sum is performed in all three dimensions.

   .. mdp-value:: 3dc

      The reciprocal sum is still performed in 3D, but a force and
      potential correction applied in the ``z`` dimension to produce a
      pseudo-2D summation. If your system has a slab geometry in the
      ``x-y`` plane you can try to increase the ``z``-dimension of the box
      (a box height of 3 times the slab height is usually ok) and use
      this option.

.. mdp:: epsilon-surface

   (0)
   This controls the dipole correction to the Ewald summation in
   3D. The default value of zero means it is turned off. Turn it on by
   setting it to the value of the relative permittivity of the
   imaginary surface around your infinite system. Be careful - you
   shouldn't use this if you have free mobile charges in your
   system. This value does not affect the slab 3DC variant of the long
   range corrections.


Temperature coupling
^^^^^^^^^^^^^^^^^^^^

.. mdp:: tcoupl

   .. mdp-value:: no

      No temperature coupling.

   .. mdp-value:: berendsen

      Temperature coupling with a Berendsen thermostat to a bath with
      temperature :mdp:`ref-t`, with time constant
      :mdp:`tau-t`. Several groups can be coupled separately, these
      are specified in the :mdp:`tc-grps` field separated by spaces.
      This is a historical thermostat needed to be able to reproduce
      previous simulations, but we strongly recommend not to use it
      for new production runs. Consult the manual for details.

   .. mdp-value:: nose-hoover

      Temperature coupling using a Nose-Hoover extended ensemble. The
      reference temperature and coupling groups are selected as above,
      but in this case :mdp:`tau-t` controls the period of the
      temperature fluctuations at equilibrium, which is slightly
      different from a relaxation time. For NVT simulations the
      conserved energy quantity is written to the energy and log files.

   .. mdp-value:: andersen

      Temperature coupling by randomizing a fraction of the particle velocities
      at each timestep. Reference temperature and coupling groups are
      selected as above. :mdp:`tau-t` is the average time between
      randomization of each molecule. Inhibits particle dynamics
      somewhat, but little or no ergodicity issues. Currently only
      implemented with velocity Verlet, and not implemented with
      constraints.

   .. mdp-value:: andersen-massive

      Temperature coupling by randomizing velocities of all particles at
      infrequent timesteps. Reference temperature and coupling groups are
      selected as above. :mdp:`tau-t` is the time between
      randomization of all molecules. Inhibits particle dynamics
      somewhat, but little or no ergodicity issues. Currently only
      implemented with velocity Verlet.

   .. mdp-value:: v-rescale

      Temperature coupling using velocity rescaling with a stochastic
      term (JCP 126, 014101). This thermostat is similar to Berendsen
      coupling, with the same scaling using :mdp:`tau-t`, but the
      stochastic term ensures that a proper canonical ensemble is
      generated. The random seed is set with :mdp:`ld-seed`. This
      thermostat works correctly even for :mdp:`tau-t` =0. For NVT
      simulations the conserved energy quantity is written to the
      energy and log file.

.. mdp:: nsttcouple

   (-1)
   The frequency for coupling the temperature. The default value of -1
   sets :mdp:`nsttcouple` equal to 10, or fewer steps if required
   for accurate integration. Note that the default value is not 1
   because additional computation and communication is required for
   obtaining the kinetic energy. For velocity
   Verlet integrators :mdp:`nsttcouple` is set to 1.

.. mdp:: nh-chain-length

   (10)
   The number of chained Nose-Hoover thermostats for velocity Verlet
   integrators, the leap-frog :mdp-value:`integrator=md` integrator
   only supports 1. Data for the NH chain variables is not printed
   to the :ref:`edr` file by default, but can be turned on with the
   :mdp:`print-nose-hoover-chain-variables` option.

.. mdp:: print-nose-hoover-chain-variables

   .. mdp-value:: no

      Do not store Nose-Hoover chain variables in the energy file.

   .. mdp-value:: yes

      Store all positions and velocities of the Nose-Hoover chain
      in the energy file.

.. mdp:: tc-grps

   groups to couple to separate temperature baths

.. mdp:: tau-t

   [ps]
   time constant for coupling (one for each group in
   :mdp:`tc-grps`), -1 means no temperature coupling

.. mdp:: ref-t

   [K]
   reference temperature for coupling (one for each group in
   :mdp:`tc-grps`)


Pressure coupling
^^^^^^^^^^^^^^^^^

.. mdp:: pcoupl

   .. mdp-value:: no

      No pressure coupling. This means a fixed box size.

   .. mdp-value:: Berendsen

      Exponential relaxation pressure coupling with time constant
      :mdp:`tau-p`. The box is scaled every :mdp:`nstpcouple` steps.
      This barostat does not yield a correct thermodynamic ensemble;
      it is only included to be able to reproduce previous runs,
      and we strongly recommend against using it for new simulations.
      See the manual for details.

   .. mdp-value:: C-rescale

      Exponential relaxation pressure coupling with time constant
      :mdp:`tau-p`, including a stochastic term to enforce correct
      volume fluctuations.  The box is scaled every :mdp:`nstpcouple`
      steps. It can be used for both equilibration and production,
      but presently it cannot be used for full anisotropic coupling.

   .. mdp-value:: Parrinello-Rahman

      Extended-ensemble pressure coupling where the box vectors are
      subject to an equation of motion. The equation of motion for the
      atoms is coupled to this. No instantaneous scaling takes
      place. As for Nose-Hoover temperature coupling the time constant
      :mdp:`tau-p` is the period of pressure fluctuations at
      equilibrium. This is probably a better method when you want to
      apply pressure scaling during data collection, but beware that
      you can get very large oscillations if you are starting from a
      different pressure. For simulations where the exact fluctations
      of the NPT ensemble are important, or if the pressure coupling
      time is very short it may not be appropriate, as the previous
      time step pressure is used in some steps of the |Gromacs|
      implementation for the current time step pressure.

   .. mdp-value:: MTTK

      Martyna-Tuckerman-Tobias-Klein implementation, only useable with
      :mdp-value:`integrator=md-vv` or :mdp-value:`integrator=md-vv-avek`, very similar to
      Parrinello-Rahman. As for Nose-Hoover temperature coupling the
      time constant :mdp:`tau-p` is the period of pressure
      fluctuations at equilibrium. This is probably a better method
      when you want to apply pressure scaling during data collection,
      but beware that you can get very large oscillations if you are
      starting from a different pressure. Currently (as of version
      5.1), it only supports isotropic scaling, and only works without
      constraints.

.. mdp:: pcoupltype

   Specifies the kind of isotropy of the pressure coupling used. Each
   kind takes one or more values for :mdp:`compressibility` and
   :mdp:`ref-p`. Only a single value is permitted for :mdp:`tau-p`.

   .. mdp-value:: isotropic

      Isotropic pressure coupling with time constant
      :mdp:`tau-p`. One value each for :mdp:`compressibility` and
      :mdp:`ref-p` is required.

   .. mdp-value:: semiisotropic

      Pressure coupling which is isotropic in the ``x`` and ``y``
      direction, but different in the ``z`` direction. This can be
      useful for membrane simulations. Two values each for
      :mdp:`compressibility` and :mdp:`ref-p` are required, for
      ``x/y`` and ``z`` directions respectively.

   .. mdp-value:: anisotropic

      Same as before, but 6 values are needed for ``xx``, ``yy``, ``zz``,
      ``xy/yx``, ``xz/zx`` and ``yz/zy`` components,
      respectively. When the off-diagonal compressibilities are set to
      zero, a rectangular box will stay rectangular. Beware that
      anisotropic scaling can lead to extreme deformation of the
      simulation box.

   .. mdp-value:: surface-tension

      Surface tension coupling for surfaces parallel to the
      xy-plane. Uses normal pressure coupling for the ``z``-direction,
      while the surface tension is coupled to the ``x/y`` dimensions of
      the box. The first :mdp:`ref-p` value is the reference surface
      tension times the number of surfaces ``bar nm``, the second
      value is the reference ``z``-pressure ``bar``. The two
      :mdp:`compressibility` values are the compressibility in the
      ``x/y`` and ``z`` direction respectively. The value for the
      ``z``-compressibility should be reasonably accurate since it
      influences the convergence of the surface-tension, it can also
      be set to zero to have a box with constant height.

.. mdp:: nstpcouple

   (-1)
   The frequency for coupling the pressure. The default value of -1
   sets :mdp:`nstpcouple` equal to 10, or fewer steps if required
   for accurate integration. Note that the default value is not 1
   because additional computation and communication is required for
   obtaining the virial. For velocity
   Verlet integrators :mdp:`nstpcouple` is set to 1.

.. mdp:: tau-p

   (1) [ps]
   The time constant for pressure coupling (one value for all
   directions).

.. mdp:: compressibility

   [bar\ :sup:`-1`]
   The compressibility (NOTE: this is now really in bar\ :sup:`-1`) For water at 1
   atm and 300 K the compressibility is 4.5e-5 bar\ :sup:`-1`. The number of
   required values is implied by :mdp:`pcoupltype`.

.. mdp:: ref-p

   [bar]
   The reference pressure for coupling. The number of required values
   is implied by :mdp:`pcoupltype`.

.. mdp:: refcoord-scaling

   .. mdp-value:: no

      The reference coordinates for position restraints are not
      modified. Note that with this option the virial and pressure
      might be ill defined, see :ref:`here <reference-manual-position-restraints>`
      for more details.

   .. mdp-value:: all

      The reference coordinates are scaled with the scaling matrix of
      the pressure coupling.

   .. mdp-value:: com

      Scale the center of mass of the reference coordinates with the
      scaling matrix of the pressure coupling. The vectors of each
      reference coordinate to the center of mass are not scaled. Only
      one COM is used, even when there are multiple molecules with
      position restraints. For calculating the COM of the reference
      coordinates in the starting configuration, periodic boundary
      conditions are not taken into account. Note that with this option
      the virial and pressure might be ill defined, see
      :ref:`here <reference-manual-position-restraints>` for more details.


Simulated annealing
^^^^^^^^^^^^^^^^^^^

Simulated annealing is controlled separately for each temperature
group in |Gromacs|. The reference temperature is a piecewise linear
function, but you can use an arbitrary number of points for each
group, and choose either a single sequence or a periodic behaviour for
each group. The actual annealing is performed by dynamically changing
the reference temperature used in the thermostat algorithm selected,
so remember that the system will usually not instantaneously reach the
reference temperature!

.. mdp:: annealing

   Type of annealing for each temperature group

   .. mdp-value:: no

       No simulated annealing - just couple to reference temperature value.

   .. mdp-value:: single

       A single sequence of annealing points. If your simulation is
       longer than the time of the last point, the temperature will be
       coupled to this constant value after the annealing sequence has
       reached the last time point.

   .. mdp-value:: periodic

       The annealing will start over at the first reference point once
       the last reference time is reached. This is repeated until the
       simulation ends.

.. mdp:: annealing-npoints

   A list with the number of annealing reference/control points used
   for each temperature group. Use 0 for groups that are not
   annealed. The number of entries should equal the number of
   temperature groups.

.. mdp:: annealing-time

   List of times at the annealing reference/control points for each
   group. If you are using periodic annealing, the times will be used
   modulo the last value, *i.e.* if the values are 0, 5, 10, and 15,
   the coupling will restart at the 0ps value after 15ps, 30ps, 45ps,
   etc. The number of entries should equal the sum of the numbers
   given in :mdp:`annealing-npoints`.

.. mdp:: annealing-temp

   List of temperatures at the annealing reference/control points for
   each group. The number of entries should equal the sum of the
   numbers given in :mdp:`annealing-npoints`.

Confused? OK, let's use an example. Assume you have two temperature
groups, set the group selections to ``annealing = single periodic``,
the number of points of each group to ``annealing-npoints = 3 4``, the
times to ``annealing-time = 0 3 6 0 2 4 6`` and finally temperatures
to ``annealing-temp = 298 280 270 298 320 320 298``. The first group
will be coupled to 298K at 0ps, but the reference temperature will
drop linearly to reach 280K at 3ps, and then linearly between 280K and
270K from 3ps to 6ps. After this is stays constant, at 270K. The
second group is coupled to 298K at 0ps, it increases linearly to 320K
at 2ps, where it stays constant until 4ps. Between 4ps and 6ps it
decreases to 298K, and then it starts over with the same pattern
again, *i.e.* rising linearly from 298K to 320K between 6ps and
8ps. Check the summary printed by :ref:`gmx grompp` if you are unsure!


Velocity generation
^^^^^^^^^^^^^^^^^^^

.. mdp:: gen-vel

   .. mdp-value:: no

        Do not generate velocities. The velocities are set to zero
        when there are no velocities in the input structure file.

   .. mdp-value:: yes

        Generate velocities in :ref:`gmx grompp` according to a
        Maxwell distribution at temperature :mdp:`gen-temp`, with
        random seed :mdp:`gen-seed`. This is only meaningful with
        :mdp-value:`integrator=md`.

.. mdp:: gen-temp

   (300) [K]
   temperature for Maxwell distribution

.. mdp:: gen-seed

   (-1) [integer]
   used to initialize random generator for random velocities,
   when :mdp:`gen-seed` is set to -1, a pseudo random seed is
   used.


Bonds
^^^^^

.. mdp:: constraints

   Controls which bonds in the topology will be converted to rigid
   holonomic constraints. Note that typical rigid water models do not
   have bonds, but rather a specialized ``[settles]`` directive, so
   are not affected by this keyword.

   .. mdp-value:: none

      No bonds converted to constraints.

   .. mdp-value:: h-bonds

      Convert the bonds with H-atoms to constraints.

   .. mdp-value:: all-bonds

      Convert all bonds to constraints.

   .. mdp-value:: h-angles

      Convert all bonds to constraints and convert the angles that
      involve H-atoms to bond-constraints.

   .. mdp-value:: all-angles

      Convert all bonds to constraints and all angles to bond-constraints.

.. mdp:: constraint-algorithm

   Chooses which solver satisfies any non-SETTLE holonomic
   constraints.

   .. mdp-value:: LINCS

      LINear Constraint Solver. With domain decomposition the parallel
      version P-LINCS is used. The accuracy in set with
      :mdp:`lincs-order`, which sets the number of matrices in the
      expansion for the matrix inversion. After the matrix inversion
      correction the algorithm does an iterative correction to
      compensate for lengthening due to rotation. The number of such
      iterations can be controlled with :mdp:`lincs-iter`. The root
      mean square relative constraint deviation is printed to the log
      file every :mdp:`nstlog` steps. If a bond rotates more than
      :mdp:`lincs-warnangle` in one step, a warning will be printed
      both to the log file and to ``stderr``. LINCS should not be used
      with coupled angle constraints.

   .. mdp-value:: SHAKE

      SHAKE is slightly slower and less stable than LINCS, but does
      work with angle constraints. The relative tolerance is set with
      :mdp:`shake-tol`, 0.0001 is a good value for "normal" MD. SHAKE
      does not support constraints between atoms on different
      decomposition domains, so it can only be used with domain
      decomposition when so-called update-groups are used, which is
      usally the case when only bonds involving hydrogens are
      constrained. SHAKE can not be used with energy minimization.

.. mdp:: continuation

   This option was formerly known as ``unconstrained-start``.

   .. mdp-value:: no

      apply constraints to the start configuration and reset shells

   .. mdp-value:: yes

      do not apply constraints to the start configuration and do not
      reset shells, useful for exact coninuation and reruns

.. mdp:: shake-tol

   (0.0001)
   relative tolerance for SHAKE

.. mdp:: lincs-order

   (4)
   Highest order in the expansion of the constraint coupling
   matrix. When constraints form triangles, an additional expansion of
   the same order is applied on top of the normal expansion only for
   the couplings within such triangles. For "normal" MD simulations an
   order of 4 usually suffices, 6 is needed for large time-steps with
   virtual sites or BD. For accurate energy minimization in double
   precision an order of 8 or more might be required. Note that in
   single precision an order higher than 6 will often lead to worse
   accuracy due to amplification of rounding errors.
   With domain decomposition, the cell size
   is limited by the distance spanned by :mdp:`lincs-order` +1
   constraints. When one wants to scale further than this limit, one
   can decrease :mdp:`lincs-order` and increase :mdp:`lincs-iter`,
   since the accuracy does not deteriorate when (1+ :mdp:`lincs-iter`
   )* :mdp:`lincs-order` remains constant.

.. mdp:: lincs-iter

   (1)
   Number of iterations to correct for rotational lengthening in
   LINCS. For normal runs a single step is sufficient, but for NVE
   runs where you want to conserve energy accurately or for accurate
   energy minimization in double precision you might want to increase
   it to 2. Note that in single precision using more than 1 iteration
   will often lead to worse accuracy due to amplification of rounding
   errors.

.. mdp:: lincs-warnangle

   (30) [deg]
   maximum angle that a bond can rotate before LINCS will complain

.. mdp:: morse

   .. mdp-value:: no

      bonds are represented by a harmonic potential

   .. mdp-value:: yes

      bonds are represented by a Morse potential


Energy group exclusions
^^^^^^^^^^^^^^^^^^^^^^^

.. mdp:: energygrp-excl

   Pairs of energy groups for which all non-bonded interactions are
   excluded. An example: if you have two energy groups ``Protein`` and
   ``SOL``, specifying ``energygrp-excl = Protein Protein SOL SOL``
   would give only the non-bonded interactions between the protein and
   the solvent. This is especially useful for speeding up energy
   calculations with ``mdrun -rerun`` and for excluding interactions
   within frozen groups.


Walls
^^^^^

.. mdp:: nwall

   (0)
   When set to 1 there is a wall at ``z=0``, when set to 2 there is
   also a wall at ``z=z-box``. Walls can only be used with :mdp:`pbc`
   ``=xy``. When set to 2, pressure coupling and Ewald summation can be
   used (it is usually best to use semiisotropic pressure coupling
   with the ``x/y`` compressibility set to 0, as otherwise the surface
   area will change). Walls interact wit the rest of the system
   through an optional :mdp:`wall-atomtype`. Energy groups ``wall0``
   and ``wall1`` (for :mdp:`nwall` =2) are added automatically to
   monitor the interaction of energy groups with each wall. The center
   of mass motion removal will be turned off in the ``z``-direction.

.. mdp:: wall-atomtype

   the atom type name in the force field for each wall. By (for
   example) defining a special wall atom type in the topology with its
   own combination rules, this allows for independent tuning of the
   interaction of each atomtype with the walls.

.. mdp:: wall-type

   .. mdp-value:: 9-3

      LJ integrated over the volume behind the wall: 9-3 potential

   .. mdp-value:: 10-4

      LJ integrated over the wall surface: 10-4 potential

   .. mdp-value:: 12-6

      direct LJ potential with the ``z`` distance from the wall

.. mdp:: table

   user defined potentials indexed with the ``z`` distance from the
   wall, the tables are read analogously to the
   :mdp:`energygrp-table` option, where the first name is for a
   "normal" energy group and the second name is ``wall0`` or
   ``wall1``, only the dispersion and repulsion columns are used

.. mdp:: wall-r-linpot

   (-1) [nm]
   Below this distance from the wall the potential is continued
   linearly and thus the force is constant. Setting this option to a
   postive value is especially useful for equilibration when some
   atoms are beyond a wall. When the value is <=0 (<0 for
   :mdp:`wall-type` =table), a fatal error is generated when atoms
   are beyond a wall.

.. mdp:: wall-density

   [nm\ :sup:`-3`] / [nm\ :sup:`-2`]
   the number density of the atoms for each wall for wall types 9-3
   and 10-4

.. mdp:: wall-ewald-zfac

   (3)
   The scaling factor for the third box vector for Ewald summation
   only, the minimum is 2. Ewald summation can only be used with
   :mdp:`nwall` =2, where one should use :mdp:`ewald-geometry`
   ``=3dc``. The empty layer in the box serves to decrease the
   unphysical Coulomb interaction between periodic images.


COM pulling
^^^^^^^^^^^

Sets whether pulling on collective variables is active.
Note that where pulling coordinates are applicable, there can be more
than one (set with :mdp:`pull-ncoords`) and multiple related :ref:`mdp`
variables will exist accordingly. Documentation references to things
like :mdp:`pull-coord1-vec` should be understood to apply to to the
applicable pulling coordinate, eg. the second pull coordinate is described by
pull-coord2-vec, pull-coord2-k, and so on.

.. mdp:: pull

   .. mdp-value:: no

      No center of mass pulling. All the following pull options will
      be ignored (and if present in the :ref:`mdp` file, they unfortunately
      generate warnings)

   .. mdp-value:: yes

       Center of mass pulling will be applied on 1 or more groups using
       1 or more pull coordinates.

.. mdp:: pull-cylinder-r

   (1.5) [nm]
   the radius of the cylinder for :mdp-value:`pull-coord1-geometry=cylinder`

.. mdp:: pull-constr-tol

   (10\ :sup:`-6`)
   the relative constraint tolerance for constraint pulling

.. mdp:: pull-print-com

   .. mdp-value:: no

      do not print the COM for any group

   .. mdp-value:: yes

      print the COM of all groups for all pull coordinates

.. mdp:: pull-print-ref-value

   .. mdp-value:: no

      do not print the reference value for each pull coordinate

   .. mdp-value:: yes

      print the reference value for each pull coordinate

.. mdp:: pull-print-components

   .. mdp-value:: no

      only print the distance for each pull coordinate

   .. mdp-value:: yes

      print the distance and Cartesian components selected in
      :mdp:`pull-coord1-dim`

.. mdp:: pull-nstxout

   (50)
   frequency for writing out the COMs of all the pull group (0 is
   never)

.. mdp:: pull-nstfout

   (50)
   frequency for writing out the force of all the pulled group
   (0 is never)

.. mdp:: pull-pbc-ref-prev-step-com

   .. mdp-value:: no

      Use the reference atom (:mdp:`pull-group1-pbcatom`) for the
      treatment of periodic boundary conditions.

   .. mdp-value:: yes

      Use the COM of the previous step as reference for the treatment
      of periodic boundary conditions. The reference is initialized
      using the reference atom (:mdp:`pull-group1-pbcatom`), which should
      be located centrally in the group. Using the COM from the
      previous step can be useful if one or more pull groups are large.

.. mdp:: pull-xout-average

   .. mdp-value:: no

      Write the instantaneous coordinates for all the pulled groups.

   .. mdp-value:: yes

      Write the average coordinates (since last output) for all the
      pulled groups. N.b., some analysis tools might expect instantaneous
      pull output.

.. mdp:: pull-fout-average

   .. mdp-value:: no

      Write the instantaneous force for all the pulled groups.

   .. mdp-value:: yes

      Write the average force (since last output) for all the
      pulled groups. N.b., some analysis tools might expect instantaneous
      pull output.

.. mdp:: pull-ngroups

   (1)
   The number of pull groups, not including the absolute reference
   group, when used. Pull groups can be reused in multiple pull
   coordinates. Below only the pull options for group 1 are given,
   further groups simply increase the group index number.

.. mdp:: pull-ncoords

   (1)
   The number of pull coordinates. Below only the pull options for
   coordinate 1 are given, further coordinates simply increase the
   coordinate index number.

.. mdp:: pull-group1-name

   The name of the pull group, is looked up in the index file or in
   the default groups to obtain the atoms involved.

.. mdp:: pull-group1-weights

   Optional relative weights which are multiplied with the masses of
   the atoms to give the total weight for the COM. The number should
   be 0, meaning all 1, or the number of atoms in the pull group.

.. mdp:: pull-group1-pbcatom

   (0)
   The reference atom for the treatment of periodic boundary
   conditions inside the group (this has no effect on the treatment of
   the pbc between groups). This option is only important when the
   diameter of the pull group is larger than half the shortest box
   vector. For determining the COM, all atoms in the group are put at
   their periodic image which is closest to
   :mdp:`pull-group1-pbcatom`. A value of 0 means that the middle
   atom (number wise) is used, which is only safe for small groups.
   :ref:`gmx grompp` checks that the maximum distance from the reference
   atom (specifically chosen, or not) to the other atoms in the group
   is not too large. This parameter is not used with
   :mdp:`pull-coord1-geometry` cylinder. A value of -1 turns on cosine
   weighting, which is useful for a group of molecules in a periodic
   system, *e.g.* a water slab (see Engin et al. J. Chem. Phys. B
   2010).

.. mdp:: pull-coord1-type

   .. mdp-value:: umbrella

      Center of mass pulling using an umbrella potential between the
      reference group and one or more groups.

   .. mdp-value:: constraint

      Center of mass pulling using a constraint between the reference
      group and one or more groups. The setup is identical to the
      option umbrella, except for the fact that a rigid constraint is
      applied instead of a harmonic potential. Note that this type is
      not supported in combination with multiple time stepping.

   .. mdp-value:: constant-force

      Center of mass pulling using a linear potential and therefore a
      constant force. For this option there is no reference position
      and therefore the parameters :mdp:`pull-coord1-init` and
      :mdp:`pull-coord1-rate` are not used.

   .. mdp-value:: flat-bottom

      At distances above :mdp:`pull-coord1-init` a harmonic potential
      is applied, otherwise no potential is applied.

   .. mdp-value:: flat-bottom-high

      At distances below :mdp:`pull-coord1-init` a harmonic potential
      is applied, otherwise no potential is applied.

   .. mdp-value:: external-potential

      An external potential that needs to be provided by another
      module.

.. mdp:: pull-coord1-potential-provider

      The name of the external module that provides the potential for
      the case where :mdp:`pull-coord1-type` is external-potential.

.. mdp:: pull-coord1-geometry

   .. mdp-value:: distance

      Pull along the vector connecting the two groups. Components can
      be selected with :mdp:`pull-coord1-dim`.

   .. mdp-value:: direction

      Pull in the direction of :mdp:`pull-coord1-vec`.

   .. mdp-value:: direction-periodic

      As :mdp-value:`pull-coord1-geometry=direction`, but does not apply
      periodic box vector corrections to keep the distance within half
      the box length. This is (only) useful for pushing groups apart
      by more than half the box length by continuously changing the reference
      location using a pull rate. With this geometry the box should not be
      dynamic (*e.g.* no pressure scaling) in the pull dimensions and
      the pull force is not added to the virial.

   .. mdp-value:: direction-relative

      As :mdp-value:`pull-coord1-geometry=direction`, but the pull vector is the vector
      that points from the COM of a third to the COM of a fourth pull
      group. This means that 4 groups need to be supplied in
      :mdp:`pull-coord1-groups`. Note that the pull force will give
      rise to a torque on the pull vector, which is turn leads to
      forces perpendicular to the pull vector on the two groups
      defining the vector. If you want a pull group to move between
      the two groups defining the vector, simply use the union of
      these two groups as the reference group.

   .. mdp-value:: cylinder

      Designed for pulling with respect to a layer where the reference
      COM is given by a local cylindrical part of the reference group.
      The pulling is in the direction of :mdp:`pull-coord1-vec`. From
      the first of the two groups in :mdp:`pull-coord1-groups` a
      cylinder is selected around the axis going through the COM of
      the second group with direction :mdp:`pull-coord1-vec` with
      radius :mdp:`pull-cylinder-r`. Weights of the atoms decrease
      continously to zero as the radial distance goes from 0 to
      :mdp:`pull-cylinder-r` (mass weighting is also used). The radial
      dependence gives rise to radial forces on both pull groups.
      Note that the radius should be smaller than half the box size.
      For tilted cylinders they should be even smaller than half the
      box size since the distance of an atom in the reference group
      from the COM of the pull group has both a radial and an axial
      component. This geometry is not supported with constraint
      pulling.

   .. mdp-value:: angle

      Pull along an angle defined by four groups. The angle is
      defined as the angle between two vectors: the vector connecting
      the COM of the first group to the COM of the second group and
      the vector connecting the COM of the third group to the COM of
      the fourth group.

   .. mdp-value:: angle-axis

      As :mdp-value:`pull-coord1-geometry=angle` but the second vector is given by :mdp:`pull-coord1-vec`.
      Thus, only the two groups that define the first vector need to be given.

   .. mdp-value:: dihedral

      Pull along a dihedral angle defined by six groups. These pairwise
      define three vectors: the vector connecting the COM of group 1
      to the COM of group 2, the COM of group 3 to the COM of group 4,
      and the COM of group 5 to the COM group 6. The dihedral angle is
      then defined as the angle between two planes: the plane spanned by the
      the two first vectors and the plane spanned the two last vectors.

   .. mdp-value:: transformation

      Transforms other pull coordinates using a mathematical expression defined by :mdp:`pull-coord1-expression`.
      Pull coordinates of lower indices can be used as variables to this pull coordinate.
      Thus, pull transformation coordinates should have a higher pull coordinate index
      than all pull coordinates they transform.

.. mdp:: pull-coord1-expression

   Mathematical expression to transform pull coordinates of lower indices to a new one.
   The pull coordinates are referred to as variables in the equation so that
   pull-coord1's value becomes 'x1', pull-coord2 value becomes 'x2' etc.
   The mathematical expression are evaluated using muParser.
   Only relevant if :mdp:`pull-coord1-geometry` is set to :mdp-value:`transformation`.

.. mdp:: pull-coord1-dx

   (1e-9)
   Size of finite difference to use in numerical derivation of the pull coordinate
   with respect to other pull coordinates.
   The current implementation uses a simple first order finite difference method to perform derivation so that
   f'(x) = (f(x+dx)-f(x))/dx
   Only relevant if :mdp:`pull-coord1-geometry` is set to :mdp-value:`transformation`.

.. mdp:: pull-coord1-groups

   The group indices on which this pull coordinate will operate.
   The number of group indices required is geometry dependent.
   The first index can be 0, in which case an
   absolute reference of :mdp:`pull-coord1-origin` is used. With an
   absolute reference the system is no longer translation invariant
   and one should think about what to do with the center of mass
   motion.

.. mdp:: pull-coord1-dim

   (Y Y Y)
   Selects the dimensions that this pull coordinate acts on and that
   are printed to the output files when
   :mdp:`pull-print-components` = :mdp-value:`pull-coord1-start=yes`. With
   :mdp:`pull-coord1-geometry` = :mdp-value:`pull-coord1-geometry=distance`, only Cartesian
   components set to Y contribute to the distance. Thus setting this
   to Y Y N results in a distance in the x/y plane. With other
   geometries all dimensions with non-zero entries in
   :mdp:`pull-coord1-vec` should be set to Y, the values for other
   dimensions only affect the output.

.. mdp:: pull-coord1-origin

   (0.0 0.0 0.0)
   The pull reference position for use with an absolute reference.

.. mdp:: pull-coord1-vec

   (0.0 0.0 0.0)
   The pull direction. :ref:`gmx grompp` normalizes the vector.

.. mdp:: pull-coord1-start

   .. mdp-value:: no

      do not modify :mdp:`pull-coord1-init`

   .. mdp-value:: yes

      add the COM distance of the starting conformation to
      :mdp:`pull-coord1-init`

.. mdp:: pull-coord1-init

   (0.0) [nm] or [deg]
   The reference distance or reference angle at t=0.

.. mdp:: pull-coord1-rate

   (0) [nm/ps] or [deg/ps]
   The rate of change of the reference position or reference angle.

.. mdp:: pull-coord1-k

   (0) [kJ mol\ :sup:`-1` nm\ :sup:`-2`] or [kJ mol\ :sup:`-1` nm\ :sup:`-1`] or
   [kJ mol\ :sup:`-1` rad\ :sup:`-2`] or [kJ mol\ :sup:`-1` rad\ :sup:`-1`]
   The force constant. For umbrella pulling this is the harmonic force
   constant in kJ mol\ :sup:`-1` nm\ :sup:`-2` (or kJ mol\ :sup:`-1` rad\ :sup:`-2`
   for angles). For constant force pulling this is the
   force constant of the linear potential, and thus the negative (!)
   of the constant force in kJ mol\ :sup:`-1` nm\ :sup:`-1`
   (or kJ mol\ :sup:`-1` rad\ :sup:`-1` for angles).
   Note that for angles the force constant is expressed in terms of radians
   (while :mdp:`pull-coord1-init` and :mdp:`pull-coord1-rate` are expressed in degrees).

.. mdp:: pull-coord1-kB

   (pull-k1) [kJ mol\ :sup:`-1` nm\ :sup:`-2`] or [kJ mol\ :sup:`-1` nm\ :sup:`-1`]
   or [kJ mol\ :sup:`-1` rad\ :sup:`-2`] or [kJ mol\ :sup:`-1` rad\ :sup:`-1`]
   As :mdp:`pull-coord1-k`, but for state B. This is only used when
   :mdp:`free-energy` is turned on. The force constant is then (1 -
   lambda) * :mdp:`pull-coord1-k` + lambda * :mdp:`pull-coord1-kB`.

AWH adaptive biasing
^^^^^^^^^^^^^^^^^^^^

.. mdp:: awh

   .. mdp-value:: no

      No biasing.

   .. mdp-value:: yes

      Adaptively bias a reaction coordinate using the AWH method and estimate
      the corresponding PMF. The PMF and other AWH data are written to energy
      file at an interval set by :mdp:`awh-nstout` and can be extracted with
      the ``gmx awh`` tool. The AWH coordinate can be
      multidimensional and is defined by mapping each dimension to a pull coordinate index.
      This is only allowed if :mdp-value:`pull-coord1-type=external-potential` and
      :mdp:`pull-coord1-potential-provider` = ``awh`` for the concerned pull coordinate
      indices. Pull geometry 'direction-periodic' is not supported by AWH.

.. mdp:: awh-potential

   .. mdp-value:: convolved

      The applied biasing potential is the convolution of the bias function and a
      set of harmonic umbrella potentials (see :mdp-value:`awh-potential=umbrella` below). This results
      in a smooth potential function and force. The resolution of the potential is set
      by the force constant of each umbrella, see :mdp:`awh1-dim1-force-constant`. This option is not
      compatible with using the free energy lambda state as an AWH reaction coordinate.

   .. mdp-value:: umbrella

      The potential bias is applied by controlling the position of an harmonic potential
      using Monte-Carlo sampling.  The force constant is set with
      :mdp:`awh1-dim1-force-constant`. The umbrella location
      is sampled using Monte-Carlo every :mdp:`awh-nstsample` steps.
      This is option is required when using the free energy lambda state as an AWH reaction coordinate.
      Apart from that, this option is mainly for comparison
      and testing purposes as there are no advantages to using an umbrella.

.. mdp:: awh-share-multisim

   .. mdp-value:: no

      AWH will not share biases across simulations started with
      :ref:`gmx mdrun` option ``-multidir``. The biases will be independent.

   .. mdp-value:: yes

      With :ref:`gmx mdrun` and option ``-multidir`` the bias and PMF estimates
      for biases with :mdp:`awh1-share-group` >0 will be shared across simulations
      with the biases with the same :mdp:`awh1-share-group` value.
      The simulations should have the same AWH settings for sharing to make sense.
      :ref:`gmx mdrun` will check whether the simulations are technically
      compatible for sharing, but the user should check that bias sharing
      physically makes sense.

.. mdp:: awh-seed

   (-1) Random seed for Monte-Carlo sampling the umbrella position,
   where -1 indicates to generate a seed. Only used with
   :mdp-value:`awh-potential=umbrella`.

.. mdp:: awh-nstout

   (100000)
   Number of steps between printing AWH data to the energy file, should be
   a multiple of :mdp:`nstenergy`.

.. mdp:: awh-nstsample

   (10)
   Number of steps between sampling of the coordinate value. This sampling
   is the basis for updating the bias and estimating the PMF and other AWH observables.

.. mdp:: awh-nsamples-update

   (10)
   The number of coordinate samples used for each AWH update.
   The update interval in steps is :mdp:`awh-nstsample` times this value.

.. mdp:: awh-nbias

   (1)
   The number of biases, each acting on its own coordinate.
   The following options should be specified
   for each bias although below only the options for bias number 1 is shown. Options for
   other bias indices are  obtained by replacing '1' by the bias index.

.. mdp:: awh1-error-init

   (10.0) [kJ mol\ :sup:`-1`]
   Estimated initial average error of the PMF for this bias. This value together with the
   given diffusion constant(s) :mdp:`awh1-dim1-diffusion` determine the initial biasing rate.
   The error is obviously not known *a priori*. Only a rough estimate of :mdp:`awh1-error-init`
   is needed however.
   As a  general guideline, leave :mdp:`awh1-error-init` to its default value when starting a new
   simulation. On the other hand, when there is *a priori* knowledge of the PMF (e.g. when
   an initial PMF estimate is provided, see the :mdp:`awh1-user-data` option)
   then :mdp:`awh1-error-init` should reflect that knowledge.

.. mdp:: awh1-growth

   .. mdp-value:: exp-linear

   Each bias keeps a reference weight histogram for the coordinate samples.
   Its size sets the magnitude of the bias function and free energy estimate updates
   (few samples corresponds to large updates and vice versa).
   Thus, its growth rate sets the maximum convergence rate.
   By default, there is an initial stage in which the histogram grows close to exponentially (but slower than the sampling rate).
   In the final stage that follows, the growth rate is linear and equal to the sampling rate (set by :mdp:`awh-nstsample`).
   The initial stage is typically necessary for efficient convergence when starting a new simulation where
   high free energy barriers have not yet been flattened by the bias.

   .. mdp-value:: linear

   As :mdp-value:`awh1-growth=exp-linear` but skip the initial stage. This may be useful if there is *a priori*
   knowledge (see :mdp:`awh1-error-init`) which eliminates the need for an initial stage. This is also
   the setting compatible with :mdp-value:`awh1-target=local-boltzmann`.

.. mdp:: awh1-equilibrate-histogram

   .. mdp-value:: no

      Do not equilibrate histogram.

   .. mdp-value:: yes

      Before entering the initial stage (see :mdp-value:`awh1-growth=exp-linear`), make sure the
      histogram of sampled weights is following the target distribution closely enough (specifically,
      at least 80% of the target region needs to have a local relative error of less than 20%). This
      option would typically only be used when :mdp:`awh1-share-group` > 0
      and the initial configurations poorly represent the target
      distribution.

.. mdp:: awh1-target

   .. mdp-value:: constant

      The bias is tuned towards a constant (uniform) coordinate distribution
      in the defined sampling interval (defined by  [:mdp:`awh1-dim1-start`, :mdp:`awh1-dim1-end`]).

   .. mdp-value:: cutoff

      Similar to :mdp-value:`awh1-target=constant`, but the target
      distribution is proportional to 1/(1 + exp(F - :mdp-value:`awh1-target=cutoff`)),
      where F is the free energy relative to the estimated global minimum.
      This provides a smooth switch of a flat target distribution in
      regions with free energy lower than the cut-off to a Boltzmann
      distribution in regions with free energy higher than the cut-off.

   .. mdp-value:: boltzmann

      The target distribution is a Boltzmann distribtution with a scaled beta (inverse temperature)
      factor given by :mdp:`awh1-target-beta-scaling`. *E.g.*, a value of 0.1
      would give the same coordinate distribution as sampling with a simulation temperature
      scaled by 10.

   .. mdp-value:: local-boltzmann

      Same target distribution and use of :mdp:`awh1-target-beta-scaling`
      but the convergence towards the target distribution is inherently local *i.e.*, the rate of
      change of the bias only depends on the local sampling. This local convergence property is
      only compatible with :mdp-value:`awh1-growth=linear`, since for
      :mdp-value:`awh1-growth=exp-linear` histograms are globally rescaled in the initial stage.

.. mdp:: awh1-target-beta-scaling

   (0)
   For :mdp-value:`awh1-target=boltzmann` and :mdp-value:`awh1-target=local-boltzmann`
   it is the unitless beta scaling factor taking values in (0,1).

.. mdp:: awh1-target-cutoff

   (0) [kJ mol\ :sup:`-1`]
   For :mdp-value:`awh1-target=cutoff` this is the cutoff, should be > 0.

.. mdp:: awh1-user-data

   .. mdp-value:: no

      Initialize the PMF and target distribution with default values.

   .. mdp-value:: yes

      Initialize the PMF and target distribution with user provided data. For :mdp:`awh-nbias` = 1,
      :ref:`gmx mdrun` will expect a file ``awhinit.xvg`` to be present in the run directory.
      For multiple biases, :ref:`gmx mdrun` expects files ``awhinit1.xvg``, ``awhinit2.xvg``, etc.
      The file name can be changed with the ``-awh`` option.
      The first :mdp:`awh1-ndim` columns of
      each input file should contain the coordinate values, such that each row defines a point in
      coordinate space. Column :mdp:`awh1-ndim` + 1 should contain the PMF value (in kT) for each point.
      The target distribution column can either follow the PMF (column  :mdp:`awh1-ndim` + 2) or
      be in the same column as written by :ref:`gmx awh`.

.. mdp:: awh1-share-group

   .. mdp-value:: 0

      Do not share the bias.

   .. mdp-value:: positive

      Share the bias and PMF estimates between simulations. This currently
      only works between biases with the same index. Note that currently
      sharing within a single simulation is not supported.
      The bias will be shared across simulations that specify the same
      value for :mdp:`awh1-share-group`. To enable this, use
      :mdp-value:`awh-share-multisim=yes` and the :ref:`gmx mdrun` option
      ``-multidir``.
      Sharing may increase convergence initially, although the starting configurations
      can be critical, especially when sharing between many biases.

.. mdp:: awh1-ndim

   (1) [integer]
   Number of dimensions of the coordinate, each dimension maps to 1 pull coordinate.
   The following options should be specified for each such dimension. Below only
   the options for dimension number 1 is shown. Options for other dimension indices are
   obtained by replacing '1' by the dimension index.

.. mdp:: awh1-dim1-coord-provider

   .. mdp-value:: pull

      The pull module is providing the reaction coordinate for this dimension.
      With multiple time-stepping, AWH and pull should be in the same MTS level.

   .. mdp-value:: fep-lambda

      The free energy lambda state is the reaction coordinate for this dimension.
      The lambda states to use are specified by :mdp:`fep-lambdas`, :mdp:`vdw-lambdas`,
      :mdp:`coul-lambdas` etc. This is not compatible with delta-lambda. It also requires
      calc-lambda-neighbors to be -1. With multiple time-stepping, AWH should
      be in the slow level. This option requires :mdp-value:`awh-potential=umbrella`.

.. mdp:: awh1-dim1-coord-index

   (1)
   Index of the pull coordinate defining this coordinate dimension.

.. mdp:: awh1-dim1-force-constant

   (0) [kJ mol\ :sup:`-1` nm\ :sup:`-2`] or [kJ mol\ :sup:`-1` rad\ :sup:`-2`]
   Force constant for the (convolved) umbrella potential(s) along this
   coordinate dimension.

.. mdp:: awh1-dim1-start

   (0.0) [nm] or [deg]
   Start value of the sampling interval along this dimension. The range of allowed
   values depends on the relevant pull geometry (see :mdp:`pull-coord1-geometry`).
   For dihedral geometries :mdp:`awh1-dim1-start` greater than :mdp:`awh1-dim1-end`
   is allowed. The interval will then wrap around from +period/2 to -period/2.
   For the direction geometry, the dimension is made periodic when
   the direction is along a box vector and covers more than 95%
   of the box length. Note that one should not apply pressure coupling
   along a periodic dimension.

.. mdp:: awh1-dim1-end

   (0.0) [nm] or [deg]
   End value defining the sampling interval together with :mdp:`awh1-dim1-start`.

.. mdp:: awh1-dim1-diffusion

   (10\ :sup:`-5`) [nm\ :sup:`2`/ps], [rad\ :sup:`2`/ps] or [ps\ :sup:`-1`]
   Estimated diffusion constant for this coordinate dimension determining the initial
   biasing rate. This needs only be a rough estimate and should not critically
   affect the results unless it is set to something very low, leading to slow convergence,
   or very high, forcing the system far from equilibrium. Not setting this value
   explicitly generates a warning.

.. mdp:: awh1-dim1-cover-diameter

   (0.0) [nm] or [deg]
   Diameter that needs to be sampled by a single simulation around a coordinate value
   before the point is considered covered in the initial stage (see :mdp-value:`awh1-growth=exp-linear`).
   A value > 0  ensures that for each covering there is a continuous transition of this diameter
   across each coordinate value.
   This is trivially true for independent simulations but not for for multiple bias-sharing simulations
   (:mdp:`awh1-share-group`>0).
   For a diameter = 0, covering occurs as soon as the simulations have sampled the whole interval, which
   for many sharing simulations does not guarantee transitions across free energy barriers.
   On the other hand, when the diameter >= the sampling interval length, covering occurs when a single simulation
   has independently sampled the whole interval.

Enforced rotation
^^^^^^^^^^^^^^^^^

These :ref:`mdp` parameters can be used enforce the rotation of a group of atoms,
e.g. a protein subunit. The `reference manual`_ describes in detail 13 different potentials
that can be used to achieve such a rotation.

.. mdp:: rotation

   .. mdp-value:: no

      No enforced rotation will be applied. All enforced rotation options will
      be ignored (and if present in the :ref:`mdp` file, they unfortunately
      generate warnings).

   .. mdp-value:: yes

      Apply the rotation potential specified by :mdp:`rot-type0` to the group of atoms given
      under the :mdp:`rot-group0` option.

.. mdp:: rot-ngroups

   (1)
   Number of rotation groups.

.. mdp:: rot-group0

   Name of rotation group 0 in the index file.

.. mdp:: rot-type0

   (iso)
   Type of rotation potential that is applied to rotation group 0. Can be of of the following:
   ``iso``, ``iso-pf``, ``pm``, ``pm-pf``, ``rm``, ``rm-pf``, ``rm2``, ``rm2-pf``,
   ``flex``, ``flex-t``, ``flex2``, or ``flex2-t``.

.. mdp:: rot-massw0

   (no)
   Use mass weighted rotation group positions.

.. mdp:: rot-vec0

   (1.0 0.0 0.0)
   Rotation vector, will get normalized.

.. mdp:: rot-pivot0

   (0.0 0.0 0.0) [nm]
   Pivot point for the potentials ``iso``, ``pm``, ``rm``, and ``rm2``.

.. mdp:: rot-rate0

   (0) [degree ps\ :sup:`-1`]
   Reference rotation rate of group 0.

.. mdp:: rot-k0

   (0) [kJ mol\ :sup:`-1` nm\ :sup:`-2`]
   Force constant for group 0.

.. mdp:: rot-slab-dist0

   (1.5) [nm]
   Slab distance, if a flexible axis rotation type was chosen.

.. mdp:: rot-min-gauss0

   (0.001)
   Minimum value (cutoff) of Gaussian function for the force to be evaluated
   (for the flexible axis potentials).

.. mdp:: rot-eps0

   (0.0001) [nm\ :sup:`2`]
   Value of additive constant epsilon for ``rm2*`` and ``flex2*`` potentials.

.. mdp:: rot-fit-method0

   (rmsd)
   Fitting method when determining the actual angle of a rotation group
   (can be one of ``rmsd``, ``norm``, or ``potential``).

.. mdp:: rot-potfit-nsteps0

   (21)
   For fit type ``potential``, the number of angular positions around the reference angle for which the
   rotation potential is evaluated.

.. mdp:: rot-potfit-step0

   (0.25)
   For fit type ``potential``, the distance in degrees between two angular positions.

.. mdp:: rot-nstrout

   (100)
   Output frequency (in steps) for the angle of the rotation group, as well as for the torque
   and the rotation potential energy.

.. mdp:: rot-nstsout

   (1000)
   Output frequency for per-slab data of the flexible axis potentials, i.e. angles, torques and slab centers.


NMR refinement
^^^^^^^^^^^^^^

.. mdp:: disre

   .. mdp-value:: no

      ignore distance restraint information in topology file

   .. mdp-value:: simple

      simple (per-molecule) distance restraints.

   .. mdp-value:: ensemble

      distance restraints over an ensemble of molecules in one
      simulation box. Normally, one would perform ensemble averaging
      over multiple simulations, using ``mdrun
      -multidir``. The environment
      variable ``GMX_DISRE_ENSEMBLE_SIZE`` sets the number of systems
      within each ensemble (usually equal to the number of directories
      supplied to ``mdrun -multidir``).

.. mdp:: disre-weighting

   .. mdp-value:: equal

      divide the restraint force equally over all atom pairs in the
      restraint

   .. mdp-value:: conservative

      the forces are the derivative of the restraint potential, this
      results in an weighting of the atom pairs to the reciprocal
      seventh power of the displacement. The forces are conservative
      when :mdp:`disre-tau` is zero.

.. mdp:: disre-mixed

   .. mdp-value:: no

      the violation used in the calculation of the restraint force is
      the time-averaged violation

   .. mdp-value:: yes

      the violation used in the calculation of the restraint force is
      the square root of the product of the time-averaged violation
      and the instantaneous violation

.. mdp:: disre-fc

   (1000) [kJ mol\ :sup:`-1` nm\ :sup:`-2`]
   force constant for distance restraints, which is multiplied by a
   (possibly) different factor for each restraint given in the ``fac``
   column of the interaction in the topology file.

.. mdp:: disre-tau

   (0) [ps]
   time constant for distance restraints running average. A value of
   zero turns off time averaging.

.. mdp:: nstdisreout

   (100) [steps]
   period between steps when the running time-averaged and
   instantaneous distances of all atom pairs involved in restraints
   are written to the energy file (can make the energy file very
   large)

.. mdp:: orire

   .. mdp-value:: no

      ignore orientation restraint information in topology file

   .. mdp-value:: yes

      use orientation restraints, ensemble averaging can be performed
      with ``mdrun -multidir``

.. mdp:: orire-fc

   (0) [kJ mol\ :sup:`-1`]
   force constant for orientation restraints, which is multiplied by a
   (possibly) different weight factor for each restraint, can be set
   to zero to obtain the orientations from a free simulation

.. mdp:: orire-tau

   (0) [ps]
   time constant for orientation restraints running average. A value
   of zero turns off time averaging.

.. mdp:: orire-fitgrp

   fit group for orientation restraining. This group of atoms is used
   to determine the rotation **R** of the system with respect to the
   reference orientation. The reference orientation is the starting
   conformation of the first subsystem. For a protein, backbone is a
   reasonable choice

.. mdp:: nstorireout

   (100) [steps]
   period between steps when the running time-averaged and
   instantaneous orientations for all restraints, and the molecular
   order tensor are written to the energy file (can make the energy
   file very large)


Free energy calculations
^^^^^^^^^^^^^^^^^^^^^^^^

.. mdp:: free-energy

   .. mdp-value:: no

      Only use topology A.

   .. mdp-value:: yes

      Interpolate between topology A (lambda=0) to topology B
      (lambda=1) and write the derivative of the Hamiltonian with
      respect to lambda (as specified with :mdp:`dhdl-derivatives`),
      or the Hamiltonian differences with respect to other lambda
      values (as specified with foreign lambda) to the energy file
      and/or to ``dhdl.xvg``, where they can be processed by, for
      example :ref:`gmx bar`. The potentials, bond-lengths and angles
      are interpolated linearly as described in the manual. When
      :mdp:`sc-alpha` is larger than zero, soft-core potentials are
      used for the LJ and Coulomb interactions.

.. mdp:: expanded

   Turns on expanded ensemble simulation, where the alchemical state
   becomes a dynamic variable, allowing jumping between different
   Hamiltonians. See the expanded ensemble options for controlling how
   expanded ensemble simulations are performed. The different
   Hamiltonians used in expanded ensemble simulations are defined by
   the other free energy options.

.. mdp:: init-lambda

   (-1)
   starting value for lambda (float). Generally, this should only be
   used with slow growth (*i.e.* nonzero :mdp:`delta-lambda`). In
   other cases, :mdp:`init-lambda-state` should be specified
   instead. If a lambda vector is given, :mdp: `init-lambda` is used to
   interpolate the vector instead of setting lambda directly.
   Must be greater than or equal to 0.

.. mdp:: delta-lambda

   (0)
   increment per time step for lambda

.. mdp:: init-lambda-state

   (-1)
   starting value for the lambda state (integer). Specifies which
   columm of the lambda vector (:mdp:`coul-lambdas`,
   :mdp:`vdw-lambdas`, :mdp:`bonded-lambdas`,
   :mdp:`restraint-lambdas`, :mdp:`mass-lambdas`,
   :mdp:`temperature-lambdas`, :mdp:`fep-lambdas`) should be
   used. This is a zero-based index: :mdp:`init-lambda-state` 0 means
   the first column, and so on.

.. mdp:: fep-lambdas

   [array]
   Zero, one or more lambda values for which Delta H values will be
   determined and written to dhdl.xvg every :mdp:`nstdhdl`
   steps. Values must be greater than or equal to 0; values greater than
   1 are allowed but should be used carefully. Free energy differences
   between different lambda values can then be determined with
   :ref:`gmx bar`. :mdp:`fep-lambdas` is different from the
   other -lambdas keywords because all components of the lambda vector
   that are not specified will use :mdp:`fep-lambdas` (including
   :mdp:`restraint-lambdas` and therefore the pull code restraints).

.. mdp:: coul-lambdas

   [array]
   Zero, one or more lambda values for which Delta H values will be
   determined and written to dhdl.xvg every :mdp:`nstdhdl`
   steps. Values must be greater than or equal to 0; values greater than
   1 are allowed but should be used carefully. If soft-core potentials are
   used, values must be between 0 and 1. Only the electrostatic
   interactions are controlled with this component of the lambda
   vector (and only if the lambda=0 and lambda=1 states have differing
   electrostatic interactions).

.. mdp:: vdw-lambdas

   [array]
   Zero, one or more lambda values for which Delta H values will be
   determined and written to dhdl.xvg every :mdp:`nstdhdl`
   steps.  Values must be greater than or equal to 0; values greater than
   1 are allowed but should be used carefully. If soft-core potentials are
   used, values must be between 0 and 1. Only the van der Waals
   interactions are controlled with this component of the lambda
   vector.

.. mdp:: bonded-lambdas

   [array]
   Zero, one or more lambda values for which Delta H values will be
   determined and written to dhdl.xvg every :mdp:`nstdhdl`
   steps.  Values must be greater than or equal to 0; values greater than
   1 are allowed but should be used carefully. Only the bonded interactions
   are controlled with this component of the lambda vector.

.. mdp:: restraint-lambdas

   [array]
   Zero, one or more lambda values for which Delta H values will be
   determined and written to dhdl.xvg every :mdp:`nstdhdl`
   steps.  Values must be greater than or equal to 0; values greater than
   1 are allowed but should be used carefully. Only the restraint
   interactions: dihedral restraints, and the pull code restraints are
   controlled with this component of the lambda vector.

.. mdp:: mass-lambdas

   [array]
   Zero, one or more lambda values for which Delta H values will be
   determined and written to dhdl.xvg every :mdp:`nstdhdl`
   steps.  Values must be greater than or equal to 0; values greater than
   1 are allowed but should be used carefully. Only the particle masses are
   controlled with this component of the lambda vector.

.. mdp:: temperature-lambdas

   [array]
   Zero, one or more lambda values for which Delta H values will be
   determined and written to dhdl.xvg every :mdp:`nstdhdl`
   steps.  Values must be greater than or equal to 0; values greater than
   1 are allowed but should be used carefully. Only the temperatures are
   controlled with this component of the lambda vector. Note that
   these lambdas should not be used for replica exchange, only for
   simulated tempering.

.. mdp:: calc-lambda-neighbors

   (1)
   Controls the number of lambda values for which Delta H values will
   be calculated and written out, if :mdp:`init-lambda-state` has
   been set. A positive value will limit the number of lambda points
   calculated to only the nth neighbors of :mdp:`init-lambda-state`:
   for example, if :mdp:`init-lambda-state` is 5 and this parameter
   has a value of 2, energies for lambda points 3-7 will be calculated
   and writen out. A value of -1 means all lambda points will be
   written out. For normal BAR such as with :ref:`gmx bar`, a value of
   1 is sufficient, while for MBAR -1 should be used.

.. mdp:: sc-function

   (beutler)

   .. mdp-value:: beutler

   Beutler *et al.* soft-core function

   .. mdp-value:: gapsys

   Gapsys *et al.* soft-core function

.. mdp:: sc-alpha

   (0)
   for `sc-function=beutler` the soft-core alpha parameter,
   a value of 0 results in linear interpolation of the
   LJ and Coulomb interactions.
   Used only with `sc-function=beutler`

.. mdp:: sc-r-power

   (6)
   power 6 for the radial term in the soft-core equation.
   Used only with `sc-function=beutler`

.. mdp:: sc-coul

   (no)
   Whether to apply the soft-core free energy interaction
   transformation to the Columbic interaction of a molecule. Default
   is no, as it is generally more efficient to turn off the Coulomic
   interactions linearly before turning off the van der Waals
   interactions. Note that it is only taken into account when lambda
   states are used, not with :mdp:`couple-lambda0` /
   :mdp:`couple-lambda1`, and you can still turn off soft-core
   interactions by setting :mdp:`sc-alpha` to 0.
   Used only with `sc-function=beutler`

.. mdp:: sc-power

   (0)
   the power for lambda in the soft-core function, only the values 1
   and 2 are supported. Used only with `sc-function=beutler`

.. mdp:: sc-sigma

   (0.3) [nm]
   for `sc-function=beutler` the soft-core sigma for particles
   which have a C6 or C12 parameter equal to zero or a sigma smaller
   than :mdp:`sc-sigma`.
   Used only with `sc-function=beutler`

.. mdp:: sc-gapsys-scale-linpoint-lj

   (0.85)
   for `sc-function=gapsys` it is the unitless alphaLJ parameter.
   It controls the softness of the van der Waals interactions
   by scaling the point for linearizing the vdw force.
   Setting it to 0 will result in the standard hard-core
   van der Waals interactions.
   Used only with `sc-function=gapsys`

.. mdp:: sc-gapsys-scale-linpoint-q

   (0.3) [nm/e^2]
   For `sc-function=gapsys` the alphaQ parameter
   with the unit of [nm/e^2] and default value of 0.3. It controls
   the softness of the Coulombic interactions. Setting it to 0 will
   result in the standard hard-core Coulombic interactions.
   Used only with `sc-function=gapsys`

.. mdp:: sc-gapsys-sigma-lj

   (0.3) [nm]
   for `sc-function=gapsys` the soft-core sigma for particles
   which have a C6 or C12 parameter equal to zero.
   Used only with `sc-function=gapsys`

.. mdp:: couple-moltype

   Here one can supply a molecule type (as defined in the topology)
   for calculating solvation or coupling free energies. There is a
   special option ``system`` that couples all molecule types in the
   system. This can be useful for equilibrating a system starting from
   (nearly) random coordinates. :mdp:`free-energy` has to be turned
   on. The Van der Waals interactions and/or charges in this molecule
   type can be turned on or off between lambda=0 and lambda=1,
   depending on the settings of :mdp:`couple-lambda0` and
   :mdp:`couple-lambda1`. If you want to decouple one of several
   copies of a molecule, you need to copy and rename the molecule
   definition in the topology.

.. mdp:: couple-lambda0

   .. mdp-value:: vdw-q

      all interactions are on at lambda=0

   .. mdp-value:: vdw

      the charges are zero (no Coulomb interactions) at lambda=0

   .. mdp-value:: q

      the Van der Waals interactions are turned at lambda=0; soft-core
      interactions will be required to avoid singularities

   .. mdp-value:: none

      the Van der Waals interactions are turned off and the charges
      are zero at lambda=0; soft-core interactions will be required to
      avoid singularities.

.. mdp:: couple-lambda1

   analogous to :mdp:`couple-lambda1`, but for lambda=1

.. mdp:: couple-intramol

   .. mdp-value:: no

      All intra-molecular non-bonded interactions for moleculetype
      :mdp:`couple-moltype` are replaced by exclusions and explicit
      pair interactions. In this manner the decoupled state of the
      molecule corresponds to the proper vacuum state without
      periodicity effects.

   .. mdp-value:: yes

      The intra-molecular Van der Waals and Coulomb interactions are
      also turned on/off. This can be useful for partitioning
      free-energies of relatively large molecules, where the
      intra-molecular non-bonded interactions might lead to
      kinetically trapped vacuum conformations. The 1-4 pair
      interactions are not turned off.

.. mdp:: nstdhdl

   (100)
   the frequency for writing dH/dlambda and possibly Delta H to
   dhdl.xvg, 0 means no ouput, should be a multiple of
   :mdp:`nstcalcenergy`.

.. mdp:: dhdl-derivatives

   (yes)

   If yes (the default), the derivatives of the Hamiltonian with
   respect to lambda at each :mdp:`nstdhdl` step are written
   out. These values are needed for interpolation of linear energy
   differences with :ref:`gmx bar` (although the same can also be
   achieved with the right foreign lambda setting, that may not be as
   flexible), or with thermodynamic integration

.. mdp:: dhdl-print-energy

   (no)

   Include either the total or the potential energy in the dhdl
   file. Options are 'no', 'potential', or 'total'. This information
   is needed for later free energy analysis if the states of interest
   are at different temperatures. If all states are at the same
   temperature, this information is not needed. 'potential' is useful
   in case one is using ``mdrun -rerun`` to generate the ``dhdl.xvg``
   file. When rerunning from an existing trajectory, the kinetic
   energy will often not be correct, and thus one must compute the
   residual free energy from the potential alone, with the kinetic
   energy component computed analytically.

.. mdp:: separate-dhdl-file

   .. mdp-value:: yes

      The free energy values that are calculated (as specified with
      the foreign lambda and :mdp:`dhdl-derivatives` settings) are
      written out to a separate file, with the default name
      ``dhdl.xvg``. This file can be used directly with :ref:`gmx
      bar`.

   .. mdp-value:: no

      The free energy values are written out to the energy output file
      (``ener.edr``, in accumulated blocks at every :mdp:`nstenergy`
      steps), where they can be extracted with :ref:`gmx energy` or
      used directly with :ref:`gmx bar`.

.. mdp:: dh-hist-size

   (0)
   If nonzero, specifies the size of the histogram into which the
   Delta H values (specified with foreign lambda) and the derivative
   dH/dl values are binned, and written to ener.edr. This can be used
   to save disk space while calculating free energy differences. One
   histogram gets written for each foreign lambda and two for the
   dH/dl, at every :mdp:`nstenergy` step. Be aware that incorrect
   histogram settings (too small size or too wide bins) can introduce
   errors. Do not use histograms unless you're certain you need it.

.. mdp:: dh-hist-spacing

   (0.1)
   Specifies the bin width of the histograms, in energy units. Used in
   conjunction with :mdp:`dh-hist-size`. This size limits the
   accuracy with which free energies can be calculated. Do not use
   histograms unless you're certain you need it.


Expanded Ensemble calculations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. mdp:: nstexpanded

   The number of integration steps beween attempted moves changing the
   system Hamiltonian in expanded ensemble simulations. Must be a
   multiple of :mdp:`nstcalcenergy`, but can be greater or less than
   :mdp:`nstdhdl`.

.. mdp:: lmc-stats

   .. mdp-value:: no

      No Monte Carlo in state space is performed.

   .. mdp-value:: metropolis-transition

      Uses the Metropolis weights to update the expanded ensemble
      weight of each state. Min{1,exp(-(beta_new u_new - beta_old
      u_old)}

   .. mdp-value:: barker-transition

      Uses the Barker transition critera to update the expanded
      ensemble weight of each state i, defined by exp(-beta_new
      u_new)/(exp(-beta_new u_new)+exp(-beta_old u_old))

   .. mdp-value:: wang-landau

      Uses the Wang-Landau algorithm (in state space, not energy
      space) to update the expanded ensemble weights.

   .. mdp-value:: min-variance

      Uses the minimum variance updating method of Escobedo et al. to
      update the expanded ensemble weights. Weights will not be the
      free energies, but will rather emphasize states that need more
      sampling to give even uncertainty.

.. mdp:: lmc-mc-move

   .. mdp-value:: no

      No Monte Carlo in state space is performed.

   .. mdp-value:: metropolis-transition

      Randomly chooses a new state up or down, then uses the
      Metropolis critera to decide whether to accept or reject:
      Min{1,exp(-(beta_new u_new - beta_old u_old)}

   .. mdp-value:: barker-transition

      Randomly chooses a new state up or down, then uses the Barker
      transition critera to decide whether to accept or reject:
      exp(-beta_new u_new)/(exp(-beta_new u_new)+exp(-beta_old u_old))

   .. mdp-value:: gibbs

       Uses the conditional weights of the state given the coordinate
       (exp(-beta_i u_i) / sum_k exp(beta_i u_i) to decide which state
       to move to.

   .. mdp-value:: metropolized-gibbs

       Uses the conditional weights of the state given the coordinate
       (exp(-beta_i u_i) / sum_k exp(beta_i u_i) to decide which state
       to move to, EXCLUDING the current state, then uses a rejection
       step to ensure detailed balance. Always more efficient that
       Gibbs, though only marginally so in many situations, such as
       when only the nearest neighbors have decent phase space
       overlap.

.. mdp:: lmc-seed

   (-1)
   random seed to use for Monte Carlo moves in state space. When
   :mdp:`lmc-seed` is set to -1, a pseudo random seed is us

.. mdp:: mc-temperature

   Temperature used for acceptance/rejection for Monte Carlo moves. If
   not specified, the temperature of the simulation specified in the
   first group of :mdp:`ref-t` is used.

.. mdp:: wl-ratio

   (0.8)
   The cutoff for the histogram of state occupancies to be reset, and
   the free energy incrementor to be changed from delta to delta *
   :mdp:`wl-scale`. If we define the Nratio = (number of samples at
   each histogram) / (average number of samples at each
   histogram). :mdp:`wl-ratio` of 0.8 means that means that the
   histogram is only considered flat if all Nratio > 0.8 AND
   simultaneously all 1/Nratio > 0.8.

.. mdp:: wl-scale

   (0.8)
   Each time the histogram is considered flat, then the current value
   of the Wang-Landau incrementor for the free energies is multiplied
   by :mdp:`wl-scale`. Value must be between 0 and 1.

.. mdp:: init-wl-delta

   (1.0)
   The initial value of the Wang-Landau incrementor in kT. Some value
   near 1 kT is usually most efficient, though sometimes a value of
   2-3 in units of kT works better if the free energy differences are
   large.

.. mdp:: wl-oneovert

   (no)
   Set Wang-Landau incrementor to scale with 1/(simulation time) in
   the large sample limit. There is significant evidence that the
   standard Wang-Landau algorithms in state space presented here
   result in free energies getting 'burned in' to incorrect values
   that depend on the initial state. when :mdp:`wl-oneovert` is true,
   then when the incrementor becomes less than 1/N, where N is the
   mumber of samples collected (and thus proportional to the data
   collection time, hence '1 over t'), then the Wang-Lambda
   incrementor is set to 1/N, decreasing every step. Once this occurs,
   :mdp:`wl-ratio` is ignored, but the weights will still stop
   updating when the equilibration criteria set in
   :mdp:`lmc-weights-equil` is achieved.

.. mdp:: lmc-repeats

   (1)
   Controls the number of times that each Monte Carlo swap type is
   performed each iteration. In the limit of large numbers of Monte
   Carlo repeats, then all methods converge to Gibbs sampling. The
   value will generally not need to be different from 1.

.. mdp:: lmc-gibbsdelta

   (-1)
   Limit Gibbs sampling to selected numbers of neighboring states. For
   Gibbs sampling, it is sometimes inefficient to perform Gibbs
   sampling over all of the states that are defined. A positive value
   of :mdp:`lmc-gibbsdelta` means that only states plus or minus
   :mdp:`lmc-gibbsdelta` are considered in exchanges up and down. A
   value of -1 means that all states are considered. For less than 100
   states, it is probably not that expensive to include all states.

.. mdp:: lmc-forced-nstart

   (0)
   Force initial state space sampling to generate weights. In order to
   come up with reasonable initial weights, this setting allows the
   simulation to drive from the initial to the final lambda state,
   with :mdp:`lmc-forced-nstart` steps at each state before moving on
   to the next lambda state. If :mdp:`lmc-forced-nstart` is
   sufficiently long (thousands of steps, perhaps), then the weights
   will be close to correct. However, in most cases, it is probably
   better to simply run the standard weight equilibration algorithms.

.. mdp:: nst-transition-matrix

   (-1)
   Frequency of outputting the expanded ensemble transition matrix. A
   negative number means it will only be printed at the end of the
   simulation.

.. mdp:: symmetrized-transition-matrix

   (no)
   Whether to symmetrize the empirical transition matrix. In the
   infinite limit the matrix will be symmetric, but will diverge with
   statistical noise for short timescales. Forced symmetrization, by
   using the matrix T_sym = 1/2 (T + transpose(T)), removes problems
   like the existence of (small magnitude) negative eigenvalues.

.. mdp:: mininum-var-min

   (100)
   The min-variance strategy (option of :mdp:`lmc-stats` is only
   valid for larger number of samples, and can get stuck if too few
   samples are used at each state. :mdp:`mininum-var-min` is the
   minimum number of samples that each state that are allowed before
   the min-variance strategy is activated if selected.

.. mdp:: init-lambda-weights

   The initial weights (free energies) used for the expanded ensemble
   states. Default is a vector of zero weights. format is similar to
   the lambda vector settings in :mdp:`fep-lambdas`, except the
   weights can be any floating point number. Units are kT. Its length
   must match the lambda vector lengths.

.. mdp:: lmc-weights-equil

   .. mdp-value:: no

      Expanded ensemble weights continue to be updated throughout the
      simulation.

   .. mdp-value:: yes

      The input expanded ensemble weights are treated as equilibrated,
      and are not updated throughout the simulation.

   .. mdp-value:: wl-delta

      Expanded ensemble weight updating is stopped when the
      Wang-Landau incrementor falls below this value.

   .. mdp-value:: number-all-lambda

      Expanded ensemble weight updating is stopped when the number of
      samples at all of the lambda states is greater than this value.

   .. mdp-value:: number-steps

      Expanded ensemble weight updating is stopped when the number of
      steps is greater than the level specified by this value.

   .. mdp-value:: number-samples

      Expanded ensemble weight updating is stopped when the number of
      total samples across all lambda states is greater than the level
      specified by this value.

   .. mdp-value:: count-ratio

      Expanded ensemble weight updating is stopped when the ratio of
      samples at the least sampled lambda state and most sampled
      lambda state greater than this value.

.. mdp:: simulated-tempering

   (no)
   Turn simulated tempering on or off. Simulated tempering is
   implemented as expanded ensemble sampling with different
   temperatures instead of different Hamiltonians.

.. mdp:: sim-temp-low

   (300) [K]
   Low temperature for simulated tempering.

.. mdp:: sim-temp-high

   (300) [K]
   High temperature for simulated tempering.

.. mdp:: simulated-tempering-scaling

   Controls the way that the temperatures at intermediate lambdas are
   calculated from the :mdp:`temperature-lambdas` part of the lambda
   vector.

   .. mdp-value:: linear

      Linearly interpolates the temperatures using the values of
      :mdp:`temperature-lambdas`, *i.e.* if :mdp:`sim-temp-low`
      =300, :mdp:`sim-temp-high` =400, then lambda=0.5 correspond to
      a temperature of 350. A nonlinear set of temperatures can always
      be implemented with uneven spacing in lambda.

   .. mdp-value:: geometric

      Interpolates temperatures geometrically between
      :mdp:`sim-temp-low` and :mdp:`sim-temp-high`. The i:th state
      has temperature :mdp:`sim-temp-low` * (:mdp:`sim-temp-high` /
      :mdp:`sim-temp-low`) raised to the power of
      (i/(ntemps-1)). This should give roughly equal exchange for
      constant heat capacity, though of course things simulations that
      involve protein folding have very high heat capacity peaks.

   .. mdp-value:: exponential

      Interpolates temperatures exponentially between
      :mdp:`sim-temp-low` and :mdp:`sim-temp-high`. The i:th state
      has temperature :mdp:`sim-temp-low` + (:mdp:`sim-temp-high` -
      :mdp:`sim-temp-low`)*((exp(:mdp:`temperature-lambdas`
      (i))-1)/(exp(1.0)-i)).


Non-equilibrium MD
^^^^^^^^^^^^^^^^^^

.. mdp:: acc-grps

   groups for constant acceleration (*e.g.* ``Protein Sol``) all atoms
   in groups Protein and Sol will experience constant acceleration as
   specified in the :mdp:`accelerate` line. Note that the kinetic energy
   of the center of mass of accelarated groups contributes to the kinetic
   energy and temperature of the system. If this is not desired, make
   each accelerate group also a separate temperature coupling group.

.. mdp:: accelerate

   (0) [nm ps\ :sup:`-2`]
   acceleration for :mdp:`acc-grps`; x, y and z for each group
   (*e.g.* ``0.1 0.0 0.0 -0.1 0.0 0.0`` means that first group has
   constant acceleration of 0.1 nm ps\ :sup:`-2` in X direction, second group
   the opposite).

.. mdp:: freezegrps

   Groups that are to be frozen (*i.e.* their X, Y, and/or Z position
   will not be updated; *e.g.* ``Lipid SOL``). :mdp:`freezedim`
   specifies for which dimension(s) the freezing applies. To avoid
   spurious contributions to the virial and pressure due to large
   forces between completely frozen atoms you need to use energy group
   exclusions, this also saves computing time. Note that coordinates
   of frozen atoms are not scaled by pressure-coupling algorithms.

.. mdp:: freezedim

   dimensions for which groups in :mdp:`freezegrps` should be frozen,
   specify ``Y`` or ``N`` for X, Y and Z and for each group (*e.g.*
   ``Y Y N N N N`` means that particles in the first group can move only in
   Z direction. The particles in the second group can move in any
   direction).

.. mdp:: cos-acceleration

   (0) [nm ps\ :sup:`-2`]
   the amplitude of the acceleration profile for calculating the
   viscosity. The acceleration is in the X-direction and the magnitude
   is :mdp:`cos-acceleration` cos(2 pi z/boxheight). Two terms are
   added to the energy file: the amplitude of the velocity profile and
   1/viscosity.

.. mdp:: deform

   (0 0 0 0 0 0) [nm ps\ :sup:`-1`]
   The velocities of deformation for the box elements: a(x) b(y) c(z)
   b(x) c(x) c(y). Each step the box elements for which :mdp:`deform`
   is non-zero are calculated as: box(ts)+(t-ts)*deform, off-diagonal
   elements are corrected for periodicity. The coordinates are
   transformed accordingly. Frozen degrees of freedom are (purposely)
   also transformed. The time ts is set to t at the first step and at
   steps at which x and v are written to trajectory to ensure exact
   restarts. Deformation can be used together with semiisotropic or
   anisotropic pressure coupling when the appropriate
   compressibilities are set to zero. The diagonal elements can be
   used to strain a solid. The off-diagonal elements can be used to
   shear a solid or a liquid.


Electric fields
^^^^^^^^^^^^^^^

.. mdp:: electric-field-x
.. mdp:: electric-field-y
.. mdp:: electric-field-z

   Here you can specify an electric field that optionally can be
   alternating and pulsed. The general expression for the field
   has the form of a gaussian laser pulse:

   .. math:: E(t) = E_0 \exp\left[-\frac{(t-t_0)^2}{2\sigma^2}\right]\cos\left[\omega (t-t_0)\right]

   For example, the four parameters for direction x are set in the
   fields of :mdp:`electric-field-x` (and similar for ``electric-field-y``
   and ``electric-field-z``) like

   ``electric-field-x  = E0 omega t0 sigma``

   with units (respectively) V nm\ :sup:`-1`, ps\ :sup:`-1`, ps, ps.

   In the special case that ``sigma = 0``, the exponential term is omitted
   and only the cosine term is used. In this case, ``t0`` must be set to 0.
   If also ``omega = 0`` a static electric field is applied.

   Read more at :ref:`electric fields` and in ref. \ :ref:`146 <refCaleman2008a>`.


Mixed quantum/classical molecular dynamics
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. mdp:: QMMM-grps

   groups to be descibed at the QM level for MiMiC QM/MM

.. MDP:: QMMM

   .. mdp-value:: no

      QM/MM is no longer supported via these .mdp options. For MiMic, use no here.

Computational Electrophysiology
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Use these options to switch on and control ion/water position exchanges in "Computational
Electrophysiology" simulation setups. (See the `reference manual`_ for details).

.. mdp:: swapcoords

   .. mdp-value:: no

      Do not enable ion/water position exchanges.

   .. mdp-value:: X ; Y ; Z

      Allow for ion/water position exchanges along the chosen direction.
      In a typical setup with the membranes parallel to the x-y plane,
      ion/water pairs need to be exchanged in Z direction to sustain the
      requested ion concentrations in the compartments.

.. mdp:: swap-frequency

   (1) The swap attempt frequency, i.e. every how many time steps the ion counts
   per compartment are determined and exchanges made if necessary.
   Normally it is not necessary to check at every time step.
   For typical Computational Electrophysiology setups, a value of about 100 is
   sufficient and yields a negligible performance impact.

.. mdp:: split-group0

   Name of the index group of the membrane-embedded part of channel #0.
   The center of mass of these atoms defines one of the compartment boundaries
   and should be chosen such that it is near the center of the membrane.

.. mdp:: split-group1

   Channel #1 defines the position of the other compartment boundary.

.. mdp:: massw-split0

   (no) Defines whether or not mass-weighting is used to calculate the split group center.

   .. mdp-value:: no

      Use the geometrical center.

   .. mdp-value:: yes

      Use the center of mass.

.. mdp:: massw-split1

   (no) As above, but for split-group #1.

.. mdp:: solvent-group

   Name of the index group of solvent molecules.

.. mdp:: coupl-steps

   (10) Average the number of ions per compartment over these many swap attempt steps.
   This can be used to prevent that ions near a compartment boundary
   (diffusing through a channel, e.g.) lead to unwanted back and forth swaps.

.. mdp:: iontypes

   (1) The number of different ion types to be controlled. These are during the
   simulation exchanged with solvent molecules to reach the desired reference numbers.

.. mdp:: iontype0-name

   Name of the first ion type.

.. mdp:: iontype0-in-A

   (-1) Requested (=reference) number of ions of type 0 in compartment A.
   The default value of -1 means: use the number of ions as found in time step 0
   as reference value.

.. mdp:: iontype0-in-B

   (-1) Reference number of ions of type 0 for compartment B.

.. mdp:: bulk-offsetA

   (0.0) Offset of the first swap layer from the compartment A midplane.
   By default (i.e. bulk offset = 0.0), ion/water exchanges happen between layers
   at maximum distance (= bulk concentration) to the split group layers. However,
   an offset b (-1.0 < b < +1.0) can be specified to offset the bulk layer from the middle at 0.0
   towards one of the compartment-partitioning layers (at +/- 1.0).

.. mdp:: bulk-offsetB

   (0.0) Offset of the other swap layer from the compartment B midplane.


.. mdp:: threshold

   (\1) Only swap ions if threshold difference to requested count is reached.

.. mdp:: cyl0-r

   (2.0) [nm] Radius of the split cylinder #0.
   Two split cylinders (mimicking the channel pores) can optionally be defined
   relative to the center of the split group. With the help of these cylinders
   it can be counted which ions have passed which channel. The split cylinder
   definition has no impact on whether or not ion/water swaps are done.

.. mdp:: cyl0-up

   (1.0) [nm] Upper extension of the split cylinder #0.

.. mdp:: cyl0-down

   (1.0) [nm] Lower extension of the split cylinder #0.

.. mdp:: cyl1-r

   (2.0) [nm] Radius of the split cylinder #1.

.. mdp:: cyl1-up

   (1.0) [nm] Upper extension of the split cylinder #1.

.. mdp:: cyl1-down

   (1.0) [nm] Lower extension of the split cylinder #1.

Density-guided simulations
^^^^^^^^^^^^^^^^^^^^^^^^^^

These options enable and control the calculation and application of additional
forces that are derived from three-dimensional densities, e.g., from cryo
electron-microscopy experiments. (See the `reference manual`_ for details)

.. mdp:: density-guided-simulation-active

   (no) Activate density-guided simulations.

.. mdp:: density-guided-simulation-group

   (protein) The atoms that are subject to the forces from the density-guided
   simulation and contribute to the simulated density.

.. mdp:: density-guided-simulation-similarity-measure

   (inner-product) Similarity measure between the density that is calculated
   from the atom positions and the reference density.

   .. mdp-value:: inner-product

      Takes the sum of the product of reference density and simulated density
      voxel values.

   .. mdp-value:: relative-entropy

      Uses the negative relative entropy (or Kullback-Leibler divergence)
      between reference density and simulated density as similarity measure.
      Negative density values are ignored.

   .. mdp-value:: cross-correlation

      Uses the Pearson correlation coefficient between reference density and
      simulated density as similarity measure.

.. mdp:: density-guided-simulation-atom-spreading-weight

   (unity) Determines the multiplication factor for the Gaussian kernel when
   spreading atoms on the grid.

   .. mdp-value:: unity

      Every atom in the density fitting group is assigned the same unit factor.

   .. mdp-value:: mass

      Atoms contribute to the simulated density proportional to their mass.

   .. mdp-value:: charge

      Atoms contribute to the simulated density proportional to their charge.

.. mdp:: density-guided-simulation-force-constant

   (1e+09) [kJ mol\ :sup:`-1`] The scaling factor for density-guided simulation
   forces. May also be negative.

.. mdp:: density-guided-simulation-gaussian-transform-spreading-width

   (0.2) [nm] The Gaussian RMS width for the spread kernel for the simulated
   density.

.. mdp:: density-guided-simulation-gaussian-transform-spreading-range-in-multiples-of-width

   (4) The range after which the gaussian is cut off in multiples of the Gaussian
   RMS width described above.

.. mdp:: density-guided-simulation-reference-density-filename

   (reference.mrc) Reference density file name using an absolute path or a path
   relative to the to the folder from which :ref:`gmx mdrun` is called.

.. mdp:: density-guided-simulation-nst

   (1) Interval in steps at which the density fitting forces are evaluated
   and applied. The forces are scaled by this number when applied (See the
   `reference manual`_ for details).

.. mdp:: density-guided-simulation-normalize-densities

   (true) Normalize the sum of density voxel values to one for the reference
   density as well as the simulated density.

.. mdp:: density-guided-simulation-adaptive-force-scaling

   (false) Adapt the force constant to ensure a steady increase in similarity
   between simulated and reference density.

   .. mdp-value: false

      Do not use adaptive force scaling.

   .. mdp-value:: true

      Use adaptive force scaling.

.. mdp:: density-guided-simulation-adaptive-force-scaling-time-constant

   (4) [ps] Couple force constant to increase in similarity with reference density
   with this time constant. Larger times result in looser coupling.

.. mdp:: density-guided-simulation-shift-vector

   (0,0,0) [nm] Add this vector to all atoms in the 
   density-guided-simulation-group before calculating forces and energies for
   density-guided-simulations. Affects only the density-guided-simulation forces
   and energies. Corresponds to a shift of the input density in the opposite
   direction by (-1) * density-guided-simulation-shift-vector.

.. mdp:: density-guided-simulation-transformation-matrix

   (1,0,0,0,1,0,0,0,1) Multiply all atoms with this matrix in the 
   density-guided-simulation-group before calculating forces and energies for
   density-guided-simulations. Affects only the density-guided-simulation forces
   and energies. Corresponds to a transformation of the input density by the
   inverse of this matrix. The matrix is given in row-major order.
   This option allows, e.g., rotation of the density-guided atom group around the
   z-axis by :math:`\theta` degress by using following input:
   :math:`(\cos \theta , -\sin \theta , 0 , \sin \theta , \cos \theta , 0 , 0 , 0 , 1)` .

QM/MM simulations with CP2K Interface 
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

These options enable and control the calculation and application of additional
QM/MM forces that are computed by the CP2K package if it is linked into |Gromacs|.
For further details about QM/MM interface implementation follow :ref:`qmmm`. 

.. mdp:: qmmm-cp2k-active

   (false) Activate QM/MM simulations. Requires CP2K to be linked with |Gromacs|

.. mdp:: qmmm-cp2k-qmgroup

   (System) Index group with atoms that are treated with QM.

.. mdp:: qmmm-cp2k-qmmethod

   (PBE) Method used to describe the QM part of the system.

   .. mdp-value:: PBE

      DFT using PBE functional and DZVP-MOLOPT basis set.

   .. mdp-value:: BLYP

      DFT using BLYP functional and DZVP-MOLOPT basis set.

   .. mdp-value:: INPUT

      Provide an external input file for CP2K when running :ref:`gmx grompp` with the ``-qmi`` command-line option.
      External input files are subject to the limitations that are described in :ref:`qmmm`.

.. mdp:: qmmm-cp2k-qmcharge

   (0) Total charge of the QM part.

.. mdp:: qmmm-cp2k-qmmultiplicity

   (1) Multiplicity or spin-state of QM part. Default value 1 means singlet state.

.. mdp:: qmmm-cp2k-qmfilenames

   () Names of the CP2K files that will be generated during the simulation. 
   When using the default, empty, value the name of the simulation input file will be used 
   with an additional ``_cp2k`` suffix.

User defined thingies
^^^^^^^^^^^^^^^^^^^^^

.. mdp:: user1-grps
.. mdp:: user2-grps
.. mdp:: userint1 (0)
.. mdp:: userint2 (0)
.. mdp:: userint3 (0)
.. mdp:: userint4 (0)
.. mdp:: userreal1 (0)
.. mdp:: userreal2 (0)
.. mdp:: userreal3 (0)
.. mdp:: userreal4 (0)

   These you can use if you modify code. You can pass integers and
   reals and groups to your subroutine. Check the inputrec definition
   in ``src/gromacs/mdtypes/inputrec.h``

Removed features
^^^^^^^^^^^^^^^^

These features have been removed from |Gromacs|, but so that old
:ref:`mdp` and :ref:`tpr` files cannot be mistakenly misused, we still
parse this option. :ref:`gmx grompp` and :ref:`gmx mdrun` will issue a
fatal error if this is set.

.. mdp:: adress

   (no)

.. mdp:: implicit-solvent

   (no)

.. _reference manual: gmx-manual-parent-dir_
Known issues affecting users of |Gromacs|
=========================================

.. _gmx-users-known-issues:

Here is a non-exhaustive list of issues that are we are aware of that are
affecting regular users of |Gromacs|.

Unable to compile with CUDA 11.3
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Due to a bug in the nvcc compiler, it is currently not possible
to compile NVIDIA GPU-enabled |Gromacs| with version 11.3 of the CUDA compiler.
We recommend using CUDA 11.2 or earlier until the compiler fix is released.

:issue:`4037`


gmxapi Python interface for GROMACS.

gmxapi provides Python access to GROMACS molecular simulation tools.
Operations can be connected flexibly to allow high performance simulation and
analysis with complex control and data flows. Users can define new operations
in C++ or Python with the same tool kit used to implement this package.

This Python package requires a compatible GROMACS installation with the API
libraries and headers.

See http://gmxapi.org/ for details on installation and usage.
