# 2.9.0
* Add `filename` option in `produce_or_load`, possibly overriding the default filename generated by `savename`
# 2.8.0
* Add filtering of `collect_results` using `rinclude` and `rexclude` keyword arguments.
# 2.7.2
* By default `storepatch` keywords are `false`. This means that `gitpatch` is NOT stored by default. This is a BUGFIX, because there is an unknown problem of non-halting when storing the patch.
# 2.7.0
* DrWatson-related `ENV`ironment variables are now available to globally set the default values for e.g. story git patches, tagging, or safe-saving in various functions like `tagsave` or `produce_or_load`.
# 2.6.0
* Use `JLD2`'s jldopen in `collect_results!` to speed up loading of metadata.
# 2.5.0
* Add an `update` option of `collect_results!` allowing the updating of an existing results collection if data files were modified or deleted.
# 2.4.1
* `savename`'s default options now have `sigdigits = 3` instead of `digits = 3` as stated in the documentation string. This was supposed to happen already since 2.0 but did not because of a bug. (#284)
* Any subtypes of `AbstractDict` now work with DrWatson (#283).

# 2.4.0
* Add the macro version of `produce_or_load` to enable tagging with the calling source file and line.
# 2.3.0
* Enable pass through of kwargs to `wsave` in `produce_or_load`, `tagsave` and `safesave` (to e.g. allow compression in JLD2 files).
# 2.2.0
* `isdirty(gitpath = projectdir())` function for checking if `gitpath` points to a dirty Git repository. (#263)
# 2.1.0
* `initialize_project` now allows for custom templates.
# 2.0.4
* `produce_or_load` now will not attempt to `tagsave` for inappropriate file formats, like `.csv`.
# 2.0.3
* Added a kwarg `equals` to `savename` to extend applicability.
# 2.0
## Breaking
* DrWatson has moved entirely on using JLD2.jl instead of BSON.jl for saving files, and also suggests the same to its users through the documentation.
* `tmpsave` now saves as JLD2.jl and requires loading explicitly the `"params"` field.
* `collect_results` saves as JLD2.jl by default now.
* `produce_or_load` saves as JLD2.jl by default now.
* `savename` will no longer replace a floating point number with its integer version, if they coincide with respect to rounding. Thus, "integer" `AbstractFloat`s will always end with `.0` in `savename`.
* `savename`'s `scientific` keyword has been replaced by `sigdigits`, as this was the only thing it was doing.
* `savename`'s default options now have `sigdigits = 3` instead of `digits = 3`.
## Non-breaking
* `savename` now allows a keyword `val_to_string` for customization.

# 1.18.3
* Remove type constraints on `produce_or_load` path argument (#229)
# 1.18.2
* Keyword `storepatch` now exists in `produce_or_load` as well.
# 1.18.1
* Fix `dict_list_count` returns wrong number of elements with `@onlyif`. (#223)
* Fix `gitpatch` for git versions not supporting submodules. (#224)
# 1.18.0
* Two new functions `tostringdict, tosymboldict` for changing dictionary key types.
# 1.17.0
* `produce_or_load` now supports passing function as the first argument to support the do-block syntax.
# 1.16.6
* `@onlyif` now doesn't expand vector arguments if it's placed inside another vector. (#209)
* `@onlyif` now supports chaining. See real world examples: "Defining parameter sets with restrictions". (#210)
# 1.16.5
* The patch information for a dirty repository now also contains the diff for submodules.
# 1.16.1
* `dict_list` now retains the value's type from the passed dictionary.
# 1.16.0
* Add a `sort` option to `savename`.
# 1.15.0
* Better default readme file for a new project.
# 1.14.6
* new keyword argument `rpath` for `collect_results!` that allows storing relative paths
# 1.14.0
* New macro `@onlyif` that allows placing restrictions on values in a dictionary used for expansion with `dict_list`
# 1.13.1
* `gitpach` now shows a warning if `git` was not found in PATH
# 1.13.0
* `savename` now includes `TimeType` (dates) in the default allowed types.
# 1.12.0
* `wsave/wload` now support keyword arguments.
# 1.11.0
* Macros `@pack!, @unpack` are re-exported by DrWatson.

# 1.10.0
* New function `struct2ntuple` that converts a struct to a NamedTuple (for saving)

# 1.9.0
* `savename` now has the `ignore` option.

# 1.8.0
* `@quickactivate` was enhanced to allow projects that also represent a module.
* `initialize_project` no resolves the folder name for naming the project if the path is given as "." or ".."

# 1.7.0
* Improve the introductory file created by DrWatson.

# 1.6.2
* `@tag!` and `@tagsave` now support using `;` as keywords separator (#111)

# 1.6.0
* `quickactivate` doesn't do anything anymore if you try to activate to already active project.
* New macro `@quickactivate`

# 1.5.0
* Started to add support for overloading save/load for custom files. See the updated docs around `wsave` and `wload`.

# 1.4.1
* Fix a bug that created incompatible version strings in generated `Project.toml` files on release candidate versions of Julia.

# 1.4.0
* `savename` now supports rounding to significant digits with the keyword argument `scientific`, where `scientific` defines the number of significant digits.
# 1.3.0
* `initialize_project` now adds a Julia version under `compat` in the created `Project.toml` when it is called.
* The functions `tag!, tagsave` and their respective macros now obtain their arguments (besides the first two) as keywords instead of positional arguments. The positional versions are deprecated (#93).
* New keyword `force = false` for `tag!` and co. which replaces the existing `gitcommit` field.

# 1.2.0
* Improved behavior of `savename` with respect to nested containers. If a nested container is empty, it is not printed instead. For example, `T=100_p=()_x=2` now becomes `T=100_x=2`. (if `p` is not empty then it is expanded as usual)

# 1.1.0
* `initialize_project` no longer makes a test directory.

# 1.0.1
* Allow `tag!` and derivatives to handle dictionaries with *key type* `Any`.
# 1.0.0
First major release (no notable change from 0.8.0).

# 0.8.0
* **[BREAKING]** : The `gitpath` argument used among many functions
  can now also point to a subdirectory within a git repository.
  Previously it had to be the top directory (i.e. the one containing
  `.git/`).
* **[BREAKING]** : Slightly changed how `produce_or_load` uses `path` and interacts with `savename`, to better incorporate the changes done in version 0.6.0. `prefix` is now also supported.
* `tag!` and co now also store the git diff patch if the repo is dirty, see `gitpatch` (#80).
* **[BREAKING]** : `tag!` now saves the commit information into a field `gitcommit` instead of just `commit`.

# 0.7.1
* `projectdir()` now warns if no project (other than the standard one) is
  active

# 0.7.0
* New macro `@savename` that is a shortcut for `savename(@dict vars...)`
* New function `gitdescribe` (see below)
* **[DEPRECATED]** `current_commit()` has been deprecated and replaced by
  `gitdescribe()` which now replaces the output of `git describe` if an
  annotated tag exists, otherwise it will return the latest commit hash.

# 0.6.0
* **[BREAKING]** Reworked the way the functions `projectdir` and derivatives work (#47, #64, #66). Now `projectdir(args...)` uses `joinpath` to connect arguments. None of the functions like `projectdir` and derivatives now end in `/` as well, to ensure more stability and motivate users to use `joinpath` or the new functionality of `projectdir(args...)` instead of using string multiplication `*`.
* New function `parse_savename` that attempts to reverse engineer the result of `savename`.

# 0.5.1
* Improvements to `.gitignore` (#55 , #54)
# 0.5.0
This release has **breaking changes**.
* Adjusted return value of `produce_or_load` (#52). It now always return the file and the path it is saved. If `loadfile = false` it returns `nothing, path`.
* The functionality of `default_prefix` has been modified (#51). Now there is a nice interplay between defining a `default_prefix` *and* passing a prefix to `savename`. They are merged like `joinpath(prefix, default_prefix)`. This is valid only when `default_prefix` has a value other than `""` (the default).
# 0.4.0
* Add expand functionality to `savename`, which handles better containers with nested containers (#50)
* `produce_or_load` now allows the possibility of not loading the file
* New function `struct2dict` that converts a struct to a dictionary (for saving)
# 0.3.0
* Added `test` as a directory of the default project (#43)
* Added `tmpsave` functionality: save the result of `dict_list` in temporary files and conveniently work with sequential clusters (#45)
* Now all saving related functions of DrWatson first `mkpath` of the path to save at and then save (#45)
# 0.2.1
* Improve type-stability of return value of `dict_list` (#41)
# 0.2.0
* Changed `path` and `projectpath` arguments of various functions (e.g. `tagsave`, `current_commit`) to `gitpath` universally.
* make keyword arguments of `tagsave` positional arguments instead (to work with the macros)
* Added two new macros: `@tag!` and `@tagsave`: these do the same thing as `tag!, tagsave` but in addition are able to record both the script name that called them as well as the line of code that they were called at.
# 0.1.0
This is the first beta release! Changelog is kept with respect to here!
![DrWatson](https://github.com/JuliaDynamics/JuliaDynamics/blob/master/videos/drwatson/DrWatson-banner.png?raw=true)

| **Documentation**   |  **Tests**     | **CodeCov**  | **Gitter** | Citation|
|:--------:|:---------------:|:-------:|:------:|:-----:|
|[![](https://img.shields.io/badge/docs-online-blue.svg)](https://JuliaDynamics.github.io/DrWatson.jl/dev)| [![CI](https://github.com/juliadynamics/DrWatson.jl/workflows/CI/badge.svg)](https://github.com/JuliaDynamics/DrWatson.jl/actions) | [![codecov](https://codecov.io/gh/JuliaDynamics/DrWatson.jl/branch/master/graph/badge.svg)](https://codecov.io/gh/JuliaDynamics/DrWatson.jl) | [![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg)](https://gitter.im/JuliaDynamics/Lobby) | [![DOI](https://joss.theoj.org/papers/10.21105/joss.02673/status.svg)](https://doi.org/10.21105/joss.02673)

DrWatson is a **scientific project assistant** software.
It helps people manage their scientific projects (or any project for that matter).

Specifically, it is a Julia package created to help people "deal" with their simulations, simulation parameters, where are files saved, experimental data, scripts, existing simulations, project source code, establishing reproducibility, and in general their scientific projects.
To install, simply type `] add DrWatson` in your Julia session.

Please read the [documentation page](https://JuliaDynamics.github.io/DrWatson.jl/dev) for more!

**DISCLAIMER** - The Julia package DrWatson, contained in this GitHub repository, is in no way related with the proprietary [Dr. Watson](https://en.wikipedia.org/wiki/Dr._Watson_(debugger)), a debugger implemented by Microsoft. In addition, the Julia package DrWatson contained in this GitHub repository is offered for free, without any monetary charge, and is provided with an MIT license.

---

If you have used DrWatson in a scientific project that lead to a publication, we'd appreciate you citing the paper associated with it:
```
@article{Datseris2020,
  doi = {10.21105/joss.02673},
  url = {https://doi.org/10.21105/joss.02673},
  year = {2020},
  publisher = {The Open Journal},
  volume = {5},
  number = {54},
  pages = {2673},
  author = {George Datseris and Jonas Isensee and Sebastian Pech and Tamás Gál},
  title = {DrWatson: the perfect sidekick for your scientific inquiries},
  journal = {Journal of Open Source Software}
}
```
# Contributing

Everyone is welcome to contribute! You can contribute via simply opening Issues reporting bugs or requesting features.

## Pull Request Contributions
The best way to contribute is by doing a Pull Request that fixes a bug or implements a new feature.
However, before opening the PR, consider first discussing the change you wish to make via an issue, so that a good design can be discussed.

To make a good PR, follow these steps:

1. Ensure all tests pass locally before starting the pull request.
1. Add adequate description in the Pull Request, or cite the corresponding issue if one exists by using hastag `#` and the issue number.
1. Always allow the "editing from maintainers" option in your PR.
2. Update the CHANGELOG.md with details of the (notable) changes to the exported API.
3. Increase the version number in Project.toml according to [SemVer](http://semver.org/).
4. Feel free to explicitly tag (with `@`) one of the main developers to request a review of your PR when it is ready.
---
title: 'DrWatson: the perfect sidekick for your scientific inquiries'
tags:
  - Julia
  - research
  - project management
  - data management
  - provenance
  - general purpose
authors:
  - name: George Datseris
    orcid: 0000-0003-0872-7098
    affiliation: 4
  - name: Jonas Isensee
    orcid: 0000-0001-6600-5590
    affiliation: 1
  - name: Sebastian Pech
    orcid: 0000-0002-8415-2823
    affiliation: 5
  - name: Tamás Gál
    orcid: 0000-0001-7821-8673
    affiliation: "2, 3"
affiliations:
 - name: Max Planck Institute for Dynamics and Self Organization
   index: 1
 - name: Erlangen Centre for Astroparticle Physics
   index: 2
 - name: Friedrich-Alexander-Universität Erlangen-Nürnberg
   index: 3
 - name: Max Planck Institute for Meteorology
   index: 4
 - name: Institute for Mechanics of Materials and Structures, TU Wien
   index: 5
date: 30 June 2020
bibliography: paper.bib
---
# Summary

Doing scientific work always involves a lot of focus and scrutiny, since producing a scientific result requires several levels of depth of analysis, all of which must be as accurate and as reproducible as possible.
All this required scrutiny *should* be naturally translated into the codebase of the scientific project.
One should strive for a code that is doing what it is supposed to, is reproducible, doesn't break over time, is sufficiently clear of bugs, and with simulation results that are appropriately labelled, and more.
The challenges associated with carrying out scientific work should not be made any worse by the difficulties of managing the codebase and resulting data/simulations.
An unfortunate but likely outcome of this stress is that scientific codebases tend to be *sloppy*: folders are not organized, there is no version control, data are not provenanced properly, most scripts break over time, and the whole project is very hard, if not impossible, to reproduce.
We have created the software DrWatson to make the process of scientific project management easier.
In this paper we will describe how DrWatson results in an efficient scientific workflow, taking time away from project management and giving it to doing science.

# Statement of need

DrWatson is a **scientific project assistance software**.
Its purpose is to help scientists manage their scientific codebase in a simple and clear manner, to make the process of creating the codebase faster and to enable true full reproducibility and project sharing.
DrWatson achieves this while being entirely non-invasive throughout the process.
It provides a well-tested science-driven framework for managing a scientific project, thus removing the unnecessary stress and giving more time to doing actual science.

Technically DrWatson is a package for the Julia language.
It is likely that Julia is the only language that can allow DrWatson to be the powerful framework that will be presented here, because Julia combines multiple dispatch, an integrated package manager, macros and code introspection.
That said, however, we believe that a large part of the design of DrWatson can be applied to other languages as well.

In this paper we provide a summary of what DrWatson can do (detailed documentation that is regularly updated is hosted on [GitHub](https://juliadynamics.github.io/DrWatson.jl/stable/)).
We will then highlight some examples of how using DrWatson speeds up the scientific workflow in real-world scenarios.
We close with a comparison with existing software.

# Features and Functionality
DrWatson has an opt-in design.
This means that DrWatson's features can be grouped into the following few main categories, which remain independent of each other (and thus you "opt-in" which to use).

* **Project setup & navigation**: A universal project structure and functions that allow you to consistently and robustly navigate through your project, no matter where it is located.
* **Naming schemes**: A robust and deterministic scheme for naming and handling your data structures.
* **Saving tools**: Tools for safely saving and loading your data, automatically tagging the Git commit ID to your saved files, and more.
* **Running & listing simulations**: Tools for producing tables of existing simulations/results, adding new simulation results to the tables, preparing batch parameter containers, and more.

The next section illustrates these categories. For a more thorough explanation, the reader is referred to DrWatson's main documentation.

Please note that DrWatson is not a data management system and provides only basic data management functionality that remains self-contained in a single scientific project.
One of our main future goals is to integrate DrWatson with a Relational Data Management System, specifically CaosDB [@Fitschen2019], which has been developed specifically to handle large data bases connecting several scientific projects.

# Typical workflow with DrWatson
In this section we demonstrate how using DrWatson makes the typical scientific workflow faster, more robust, and easily reproducible.
This section is a brief summary of the [DrWatson Workflow Tutorial](https://juliadynamics.github.io/DrWatson.jl/dev/workflow/), which in itself showcases a subset of DrWatson's functionality.
There the workflow is discussed and demonstrated more thoroughly via explicitly running every code command.

Typically, one starts a scientific project with the function `initialize_project`.
This creates a project folder that contains sensible default structure (e.g. folders for data, papers, scripts, etc.), while also making the project a Julia project.
This allows the scientific project to be tied with the full hierarchy of exact package versions used, which remains entirely independent from the main Julia installation (or any other project).
The project is also a git repository, which allows code versioning and reproducibility, and DrWatson provides functions that make this process seamless (see below).

Within the context of DrWatson, all project-related code runs *after* the corresponding Julia project has been activated.
Several DrWatson functions like `projectdir`, `datadir`, `plotsdir` and similar are then made available.
When these functions are called they always return the absolute path to the directory (or the appropriate subdirectories) in the active project, independently of the current working directory or the script directory these functions are called from.
This establishes a relative-only path relationship within the project, which allows it to naturally run on other machines when shared or synced via e.g. a cloud service.
Adding the command `@quickactivate "ProjectName"` to the start of every script automatically activates the appropriate project and thus enables all DrWatson features with minimal effort.

Once the project structure and navigation has been established, there are several functions that help the scientific workflow. For example, the function `dict_list` provides a convenient and consistent way of defining containers of parameter values.
`savename` can be used for preparing a file name or a figure title.
Using it would transform the following dictionary
```julia
parameters = Dict(:phi => 3, :pos_z => 0.5, :date => Date(2020,5,23))
```
into
```julia
savename(parameters, "jld2")
```
with output:
```
"date=2020-05-23_pos_z=0.5_phi=3.jld2"
```

Once a simulation script is created, taking advantage of e.g. `projectdir, dict_list, savename` among other functions, the user will typically want to save numeric results on disk.
DrWatson offers many functions that help the workflow at this level.
`safesave` ensures that saved data will never overwrite existing files, but make a new version instead (and back up the original file).
`tagsave` allows one to add git-related information to saved data.
`tagsave` is a function that excellently highlights how DrWatson is a minimally invasive framework.
Continuing from the dictionary `parameters` defined above, we would save any kind of `data` wrapped in a dictionary with the command `save(savename(parameters, "jld2"), data)` (ending `.jld2` is used as an example).
By only replacing the function `save` with `@tagsave`, it is possible to attach important information to the saved data

```julia
@tagsave(savename(parameters, "jld2"), Dict("data" => [1,2,3]));

load(savename(parameters, "jld2")) # load back saved data
```

yielding the output:

```
Dict{Symbol,Any} with 6 entries:
  :gitcommit => "v1.13.0-1-g3a5364f"
  :script    => "docs/build/string#3"
  :data      => [1, 2, 3]
  :gitpatch  => ""
```

The fields `:gitcommit, :script, :gitpatch` were added automatically and provide the necessary information for reproducibility. In case of uncommitted modifications (also called a "dirty git repository"), a patch is saved under the `:gitpatch` key which can be applied to the `:gitcommit` to restore the exact state of the repository.
Calling `@tagsave` without extra arguments assumes that you use DrWatson's suggested folder structure using `initialize_project`, and thus that it can find all git-related information automatically.
However this is not necessary: you can instead provide a keyword argument `gitpath` to `@tagsave` and explictly specify a git path.
Finally, the `parse_savename(filename; kwargs...)` function can be used to obtain the parameters dictionary from the filename.

A last step is data aggregation.
The function `collect_results` can traverse the data folder and collect all saved files into a `DataFrame` (the major Julia tabular datastructure) for further analysis. The function is adaptive in that it expands the table as needed when adding new simulations with potentially different parameters.

Sharing and reproducing a DrWatson project is in every respect trivial.
The entire project folder is simply sent to a different machine, and in a Julia session the user does the following:
```
using Pkg
Pkg.activate("path/to/project")
Pkg.instantiate()
```
and all necessary dependencies are installed automatically.
Since the project uses only relative paths because of the function `projectdir`, every script runs as it did on the original machine.
If all saved data are tagged with a git-commit, one can potentially re-create previous results by simply checking out the appropriate commit.
Finally, since all package versions used are "baked" into the project, a DrWatson project does not break over time even if the main Julia installation is regularly updated.

One thing that we hope to have highlighted in this section is how DrWatson's functionality is not only minimally invasive, but is also achieved with minimal effort.
All functionality is contained within the Julia programming language and within the script files naturally belonging to the project: no command-line usage or special commands are necessary, and neither is the preparation of additional configuration files outside of the scripts.
DrWatson's functionality comes directly from using the functions and macros exported by the package.
While this is a great advantage in many use cases, it does come with a natural limitation: When running and interacting with code from different languages, the relevant file-IO logic needs to happen in Julia to leverage the full power of DrWatson.


# Comparison with existing software

There are numerous tools, software packages and language extensions that provide functions to improve the scientific workflow and allow full reproducibility.
They contain features like version control, templates for folder structures, management of external code dependencies and data provenance.
Although the tools we investigated perform well in their respective domains and in some parts, such as data provenance, even outperform DrWatson, none of them supports the wide range of functions required for a scientific project, while being non-invasive and easy to use. Therefore, several tools must be combined to provide a similar set of functions as those provided by DrWatson.

One main aspect, and the entry point to every scientific project, is a consistent folder structure.
While DrWatson comes with a predefined structure, packages like `rrtools` [@rrtools], `prodigenr` [@prodigenr] and `starters` [@starters] for R or `Cookiecutter` [@cookiecutter] (with a template for scientific projects like `Cookiecutter-data-science` [@cookiecutter-data-science]) for Python, allow having a user-defined one.
Like DrWatson, most of the tools that initialize a folder structure also initialize a Git repository for version control.
In order to gain advantage from having code in version control, e.g. extracting diffs or commit ids, additional software packages, focused on data provenance, are needed.

Applications like `sumatra` [@sumatra], which is written in Python and also supports MATLAB, R, and BASH, while also providing extensibility for other languages,
work mainly by executing scripts through a separate standalone tool that captures and tags all files created at runtime. Another example of such an external manager is `ReproZip` [@ChirigatiRSF16], which traces system calls to identify which files are part of a specific analysis and generates additional metadata to combine everything together into zip-file in a reproducible manner.
`ActivePapers` [@HINSEN2011579] falls into the same category and provides a concept and guidelines for reproducible science. There are reference implementations of the ActivePapers concept for Python, JVM (Java Virtual Machine) and Pharo, see [@activepapers].
Specialised alternatives like `recordr` [@recordr] for R, `explore` for Matlab or `recipy` [@recipy] for Python aim at the non-invasive approach by redefining IO functions for logging metadata during saving.

The outlined tools, however, come with a cost of being limited to certain supported IO functions or the need of additional software to run code or a server infrastructure.
Moreover, most of them are tied to a specific programming language and data provenance is only provided in their own context and usually within a single process.
Scientific projects, however, often deal with heterogeneous computing environments and pipelines running a multitude of scripts and applications connected to each other, thus the orchestration and data provenance needs to be implemented in a more language-agnostic way.
An example for such a framework (with significantly different end-goals compared to DrWatson) is the Common Workflow Language [@cwl].
Notice that in principle DrWatson is tied to Julia, a single programming language. But because Julia has strong interop capabilities, allowing native C/FORTRAN calls and calls to Python or R (for example) via PyCall and RCall, the Julia-based design of DrWatson is much less of a limiting factor than for other languages.
In addition, DrWatson is suitable for both making repetitive workflows reproducible (which CWL targets) but also exploratory scientific work.

Therefore, DrWatson only implements basic data provenance features like logging version control information in Julia dictionaries and storing parameter configurations in paths using the `savename` function, which in many cases already covers the basic requirements.
The latter approach allows for a simple, universal, file-format-independent method for keeping simulation parameters together with result files.

In terms of portability of scientific projects, management of external code dependencies and packages is crucial.
Most of the mentioned languages come with a package manager enabling such functionality.
`renv` [@renv] for R implements a feature similar to projects that can be created with `Pkg.jl`, that DrWatson uses.
Dependency management is also possible in Python, e.g. by using virtual environments, which are included in the standard library of Python since version 3.5.

# Conclusion
In summary, DrWatson combines several functionalities, all communicating excellently with each other and almost all being entirely opt-in, while it goes well beyond only aiding data provenance or simply providing a default folder structure.
This results in an efficient scientific workflow, taking time off of project management and giving it to doing science.

# References
---
name: Bug report
about: Create a report to help us improve
title: ''
labels: ''
assignees: ''

---

**Describe the bug**
A clear and concise description of what the bug is.

**Minimal Working Example**
Please provide a piece of code that leads to the bug you encounter.

If the code is **runnable**, it will help us identify the problem faster.

Please also provide the version of `DrWatson` you have installed and your Julia version.
---
name: Feature request
about: Suggest an idea for this project
title: ''
labels: ''
assignees: ''

---

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.
# Running & Listing Simulations

## Preparing Simulation Runs
It is very often the case that you want to run "batch simulations", i.e. just submit a bunch of different simulations, all using same algorithms and code but just different parameters. This scenario always requires the user to prepare a set of simulation parameter containers which are then passed into some kind of "main" function that starts the simulation.

To make the preparation part simpler we provide the following functionality:
```@docs
dict_list
dict_list_count
@onlyif
```

Using the above function means that you can write your "preparation" step into a single dictionary and then let it automatically expand into many parameter containers. This keeps the code cleaner but also consistent, provided that it follows one simple rule: **Anything that is a `Vector` has many parameters, otherwise it is one parameter**. [`dict_list`](@ref) considers this true irrespectively of what the `Vector` contains. This allows users to use any iterable custom type as a single "parameter" of a simulation.

See the [Preparing & running jobs](@ref) for a very convenient application!

## Saving Temporary Dictionaries
The functionality of [`dict_list`](@ref) is great, but can fall short in cases of submitting jobs to a computer cluster. For serial clusters, each run is submitted to a different Julia process and thus one cannot propagate a Julia in-memory `Dict` (for parallel clusters using `pmap` is fine).

To balance this, we have here some simple functionality that stores the result of [`dict_list`](@ref) (or any other dictionary collection, really) to files with temporary names. The names are returned and can then be propagated into a `main`-like Julia process that can take the temp-name as an input, load the dictionary and then extract the data.
```@docs
tmpsave
```
An example usage is shown in [Using a Serial Cluster](@ref).

## Collecting Results
There are cases where you have saved a bunch of simulation results in a bunch of different files in a folder. It is useful to be able to collect all of these results into a single table, in this case a `DataFrame`. The function [`collect_results!`](@ref) provides this functionality. Importantly, the function is "future-proof" which means that it works nicely even if you add new parameters or remove old parameters from your results as your project progresses!

```@docs
collect_results!
collect_results
```

For an example of using this functionality please have a look at the [Real World Examples](@ref) page!
![DrWatson](https://github.com/JuliaDynamics/JuliaDynamics/blob/master/videos/drwatson/DrWatson-banner-nobg.png?raw=true)

---

DrWatson is a **scientific project assistant** software.
It helps people manage their scientific projects (or any project for that matter).

Specifically, it is a Julia package created to help people increase the consistency of their scientific projects, navigate them and share them faster and easier, manage scripts, existing simulations as well as project source code.
DrWatson helps establishing reproducibility, and in general it makes managing a scientific project a simple job.

See the [Functionality](@ref) section to get an impression of what you can do with DrWatson or see the [DrWatson Workflow Tutorial](@ref) to get a "crash course" of how DrWatson helps the typical scientific workflow.
The [Description of DrWatson](@ref) section describes the design decisions that make it a unique software that truly helps the scientific workflow.
If you want to see how DrWatson compares with other existing alternatives, please have a look at our paper in [Citing](@ref).

You can also watch this 8-minutes video that introduces DrWatson in JuliaCon2020:

```@raw html
<iframe width="560" height="400" src="https://www.youtube-nocookie.com/embed/jKATlEAu8eE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
```

To install, simply type `] add DrWatson` in your Julia session.
DrWatson is part of [JuliaDynamics](https://juliadynamics.github.io/JuliaDynamics/), check out our [website](https://juliadynamics.github.io/JuliaDynamics/) for more cool stuff!

!!! note "Star us on GitHub!"
    If you like DrWatson the please consider starring the [GitHub repository](https://github.com/JuliaDynamics/DrWatson.jl). This gives as an accurate lower bound of the number of people the software has helped!

## Rationale
Have you thought things like:

* Urgh, I moved my folders and now my `load` commands don't work anymore!
* Hold on, haven't I run this simulation already?
* Do I have to produce a dataframe of my finished simulations AGAIN?!
* Wait, are those experiments already processed?
* PFfffff I am tired of typing `savename = "w=$w_f=$f_x=$x.txt"`, can't I do it automatically?
* I wish I could just make a dataframe out of all my simulations with one command!
* Yeah you've sent me your project but none of the scripts work...
* It would be so nice to automatically integrate `git` information to all the data I save...

DrWatson tries to eradicate such bad thoughts and bedtime nightmares.


## Functionality
DrWatson is a **scientific project assistant software**. Here is what it can do:

* [Project Setup](@ref) : A universal project structure and functions that allow you to consistently and robustly navigate through your project, no matter where it is located.
* [Naming Simulations](@ref) : A robust and deterministic scheme for naming and handling your containers.
* [Saving Tools](@ref) : Tools for safely saving and loading your data, tagging the Git commit ID to your saved files, safety when tagging with dirty repos, and more.
* [Running & Listing Simulations](@ref): Tools for producing tables of existing simulations/data, adding new simulation results to the tables, preparing batch parameter containers, and more.

See the [DrWatson Workflow Tutorial](@ref) page to get a quick overview
over all of these functionalities.

Think of these core aspects of DrWatson as independent islands connected by bridges. If you don't like the approach of one of the islands, you don't have to use it to take advantage of DrWatson!

Applications of DrWatson are demonstrated the [Real World Examples](@ref) page. All of these examples are taken from code of real scientific projects that use DrWatson.

Please note that DrWatson is **not a data management system**.
It is also **not a Julia package creator** like [PkgTemplates.jl](https://github.com/invenia/PkgTemplates.jl) **nor a package development tool**.

## Description of DrWatson

DrWatson follows these simple principles:

1. **Non-Invasive.** DrWatson does not require you to follow strict rules or change the way you work and do science in order to use it. In addition DrWatson is function-based: you only have to call a function and everything else just works; you *do not* have to create additional special `struct` or other data types. In addition, you also do not have to do anything outside of your code (e.g. command line arguments or external software tools).
1. **Simple.** The functionality offered is a baseline from where you handle your project as you wish. This makes it more likely to be of general use but also means that you don't have to "study" to learn DrWatson: all concepts are simple, everything is easy to understand.
2. **Consistent.** The functionality is identical across all projects and DrWatson offers a universal base project structure.
3. **Allows increments.** You didn't plan your project well enough? Want to add more folders, more files, more variables to your simulations? It's fine.
5. **Reproducibility.** DrWatson aims to make your projects fully reproducible using Git, Julia's package manager and consistent naming schemes.
6. **Modular.** DrWatson has a flexible modular design (see [Functionality](@ref)) which means you only have to use what fits _your project_.
1. **General.** DrWatson is completely agnostic to the content of your project. It is not tailored to specific scientific workflows, or specific scientific communities.
4. **Scientific.** DrWatson has been beta tested in many real-world scientific projects and has matured based on feedback from scientists.

This is why we believe DrWatson can help you focus on the science and not worry about project code management.

## Citation
If you have used DrWatson in a scientific project that lead to a publication, we'd appreciate you citing the paper associated with it.
This paper also compares DrWatson to other software that have been used to aid the scientific workflow in one way or another,
and highlights the unique features of DrWatson.

```
@article{Datseris2020,
  doi = {10.21105/joss.02673},
  url = {https://doi.org/10.21105/joss.02673},
  year = {2020},
  publisher = {The Open Journal},
  volume = {5},
  number = {54},
  pages = {2673},
  author = {George Datseris and Jonas Isensee and Sebastian Pech and Tamás Gál},
  title = {DrWatson: the perfect sidekick for your scientific inquiries},
  journal = {Journal of Open Source Software}
}
```

or use the DOI directly:

[![DOI](https://joss.theoj.org/papers/10.21105/joss.02673/status.svg)](https://doi.org/10.21105/joss.02673)

## Other useful packages

### Simulation related
* <https://github.com/baggepinnen/Hyperopt.jl>
* <https://github.com/rafaqz/ModelParameters.jl>

### Efficient code writing
* <https://github.com/docopt/DocOpt.jl>
* <https://github.com/vtjnash/Glob.jl>

### Notebooks
* <https://github.com/JuliaLang/IJulia.jl>
* <https://github.com/JunoLab/Weave.jl>
* <https://github.com/fonsp/Pluto.jl>

### Documenting your code
* <https://github.com/JuliaDocs/Documenter.jl>
* <https://github.com/fredrikekre/Literate.jl>
* <https://github.com/caseykneale/Sherlock.jl>
* <https://github.com/miguelraz/DoctorDocstrings.jl> 

### Paper-related
* <https://github.com/Humans-of-Julia/Bibliography.jl>
* <https://github.com/SebastianM-C/PkgCite.jl>

### Writing and debugging code
* <https://junolab.org/>
* <https://github.com/timholy/Revise.jl>
* <https://github.com/JuliaDebug/Debugger.jl>
* <https://github.com/MichaelHatherly/InteractiveErrors.jl>

### Performance measures
* <https://github.com/JuliaCI/BenchmarkTools.jl>
* <https://github.com/timholy/ProgressMeter.jl>
* <https://github.com/KristofferC/TimerOutputs.jl>
* <https://github.com/JuliaDebug/Cthulhu.jl>
* ProfileViews.jl (similar available in Juno with `@profiler`)

### Saving Data
* BSON.jl
* JLD2.jl
* CSV.jl

### Data management & data bases
* <https://github.com/helgee/RemoteFiles.jl>
* <https://github.com/JuliaDynamics/CaosDB.jl>
* <https://juliadb.org/>
* <https://github.com/SebastianM-C/StorageGraphs.jl>

### Tabular data
* <https://juliadata.github.io/DataFrames.jl/stable/>
* <https://www.queryverse.org/>

### Traversing folders
* Base.Filesystem
* <https://github.com/Keno/AbstractTrees.jl/blob/master/examples/fstree.jl>


### Time management
* <https://github.com/oxinabox/ProjectManagement.jl>

## Support and Contributing
Questions about DrWatson can be asked by directly opening up an Issue on its GitHub page, or asking in the Julia slack channels `#helpdesk, #dynamics-bridged`.

If you wish to contribute, thats great! Please consult the [online guidelines](https://github.com/JuliaDynamics/DrWatson.jl/blob/master/CONTRIBUTING.md).


## Inspirations

Initial inspirations for DrWatson follow below. All inspirations are specific in scope and functionality, and since its original conception DrWatson has moved on to become a whole scientific project assistant.

https://drivendata.github.io/cookiecutter-data-science/#cookiecutter-data-science

https://discourse.julialang.org/t/computational-experiments-organising-different-algorithms-their-parameters-and-results/10774/7

http://neuralensemble.org/sumatra/

https://github.com/mohamed82008/ComputExp.jl

https://sacred.readthedocs.io/en/latest/index.html

https://experimentator.readthedocs.io/en/latest/
# Project Setup

Part of the functionality of DrWatson is creating and navigating through a project setup consistently. This works even if you move your project to a different location/computer or send it to a colleague with a different Julia installation. In addition, the navigation process is identical across any project that uses DrWatson.

This can "just work" (TM) because of the following principles:

1. **Your science project is also a [Julia project](https://julialang.github.io/Pkg.jl/v1/environments/) defined by a `Project.toml` file.** This way the project tracks the used packages (and their versions) and can be shared with any other Julia user.
2. **You first activate this project environment before running any code.** This way you ensure that your project runs on the specified package installation (instead of the global one). See [Activating a Project](@ref) for ways to do this.
3. **You use the functions `projectdir`, `datadir`, etc. from DrWatson** to navigate your project (see [Navigating a Project](@ref)).

Importantly, our suggested project setup was designed to be fully reproducible, see [Reproducibility](@ref).

## Default Project Setup

DrWatson suggests a universal project structure for any scientific project, which is the following:

```@setup project
using DrWatson
struct ShowFile
    file::String
end
function Base.show(io::IO, ::MIME"text/plain", f::ShowFile)
    write(io, read(f.file))
end
```
```@example project
ShowFile(dirname(pathof(DrWatson))*"/defaults/project_structure.txt") # hide
```

### `src` vs `scripts`
Seems like `src` and `scripts` folders have pretty similar functionality. However there is a distinction between these two. You can follow these mental rules to know where to put `file.jl`:

* If upon `include("file.jl")` there is _anything_ being produced, be it data files, plots or even output to the console, then it should be in `scripts`.
* If it is functionality used across multiple files or pipelines, it should be in `src`.
* `src` should only contain files that define functions or types but not output anything.

## Initializing a Project

To initialize a project as described in the [Default Project Setup](@ref) section, we provide the following function:
```@docs
initialize_project
```


## Activating a Project
This part of DrWatson's functionality requires you to have your scientific project (and as a consequence, the Julia project) activated.
This can be done in multiple ways:
   1. doing `Pkg.activate("path/to/project")` programmatically
   2. using the startup flag `--project path` when starting Julia
   3. by setting the [`JULIA_PROJECT`](https://docs.julialang.org/en/latest/manual/environment-variables/#JULIA_PROJECT-1) environment variable
   4. using the function [`quickactivate`](@ref) or the macro [`@quickactivate`](@ref) offered by DrWatson.

We recommend the fourth approach, although it does come with a caveat (see the docstring of [`quickactivate`](@ref)).

```@docs
quickactivate
@quickactivate
findproject
```

Notice that to get the current project's name you can use:
```@docs
projectname
```

## Including Julia packages/modules in `src`
Notice that the project initialized by DrWatson does not represent a Julia package. It represents a scientific project. That being said, it is often the case that you want to develop normal Julia Modules (and perhaps later publish them as packages) inside your project, so that you can later use them in your code with `using ModuleName`. The proper way to do this is to initialize Julia packages, using the package manager, inside the `src` folder, using these steps:

1. Active your project that uses DrWatson.
2. Change directory to the project's main folder (**important!**).
3. Go into package mode and initialize a package with the name that you want: `generate src/ModuleName`
4. `dev` the local path to `ModuleName` using the package manager: `dev src/ModuleName`. Notice that this command uses a local path, see [this PR](https://github.com/JuliaLang/Pkg.jl/pull/1215) for more details.
   * If you don't care to make this module a Julia package, simply delete its `.git` folder: `src/Modulename/.git`.
   * If you do care about publishing this module as a Julia package, then it is mandatory to keep it as git-repository. In this case it is sensible to put `src/ModuleName/.git` into the main `.gitignore` file.

Now whenever you do `using ModuleName`, the local version will be used. This will still work even if you transfer your project to another computer, because the Manifest.toml file stores the local path.

## Navigating a Project
To be able to navigate the project consistently, DrWatson provides the core function
```@docs
projectdir
```

Besides the above, the following derivative functions
```julia
datadir()
srcdir()
plotsdir()
scriptsdir()
papersdir()
```
behave exactly like `projectdir` but have as root the appropriate subdirectory. These are also defined due to the frequent use of these subdirectories.

All of these functions take advantage of `joinpath`, ensuring an error-free path creation that works across different operating systems. It is heavily advised to use `projectdir` and derivatives by giving them the subpaths as arguments, instead of using multiplication between paths:
```julia
datadir("foo", "test.jld2") # preferred
datadir() * "/foo/test.jld2" # not recommended
```

### Custom directory functions

It is straightforward to make custom directory functions if there is a directory you created that you access more often. Simply define
```julia
customdir(args...) = projectdir("custom", args...)
```
to make the `customdir` version that works exactly like e.g. `datadir` but for `"custom"` instead of `"data"`.

## Reproducibility
The project setup approach that DrWatson suggests is designed to work flawlessly with Julia standards, to be easy to share and to be fully reproducible. There are three reasons that **true** reproducibility is possible:
1. The project's used packages are embedded in the project because of `Manifest.toml`.
2. The navigation around the folders of the project uses local directories.
3. The project is a Git repository, which means that it has a detailed (and re-traceable) history of all changes and additions.

If you send your entire project folder to a colleague, they only need to do:
```julia
julia> cd("path/to/project")
pkg> activate .
pkg> instantiate
```
to use your project (*assuming of course that you are both using the same Julia installation and version*).
All required packages and dependencies will be installed and then any script that was running in your computer will also be running in their computer **in the same way!**

In addition, with DrWatson you have the possibility of "tagging" each simulation created with the commit id, see the discussion around [`gitdescribe`](@ref) and [`tag!`](@ref).
This way, any data result obtained at any moment can be truly reproduced simply by resetting the Git tree to the appropriate commit and running the code.

## Transitioning an existing project to DrWatson
If you already have an existing project with scripts and data etc., then there is no reason to use the [`initialize_project`](@ref) function.
The only requirement is that everything that belongs to your project is contained within a single folder (which can have an arbitrary amount of subfolders).
If your project is already a Julia project (which means it has its own Project.toml and Manifest.toml files), then there is nothing more necessary to be done,
you can immediatelly start using DrWatson with it.
Although we recommend following the [Default Project Setup](@ref), you don't have to do this either, since you can create your own [Custom directory functions](@ref).

If your project is _not_ also a Julia project, the steps necessary are still quite simple. You can do:
```julia
julia> cd("path/to/project")
pkg> activate .
pkg> add Package1 Package2 ...
```
Julia will automatically make the Project.toml and Manifest.toml files for you as you add packages used by your project.
# Real World Examples

## Easy local directories
I setup all my science projects using DrWatson's suggested setup, using [`initialize_project`](@ref). Then, every file in every project has a start that looks like this:
```julia
using DrWatson
quickactivate(@__DIR__, "MagneticBilliardsLyapunovs")
using DynamicalBilliards, PyPlot, LinearAlgebra

include(srcdir("plot_perturbationgrowth.jl"))
include(srcdir("unitcells.jl"))
```
In all projects I save data/plots using `datadir/plotdir`:
```julia
@tagsave(datadir("mushrooms", "Λ_N=$N.jld2"), (@strdict Λ Λσ ws hs description))
```
The advantage of this approach is that it will always work regardless of if I move the specific file to a different subfolder (which is very often necessary) or whether I move the entire project folder somewhere else!
**Please be sure you have understood the caveat of using [`quickactivate`](@ref)!**

Here is an example from another project. You will notice that another advantage is that I can use identical syntax to access the data or source folders even though I have different projects!
```julia
using DrWatson
@quickactivate "EmbeddingResearch"
using Parameters
using TimeseriesPrediction, LinearAlgebra, Statistics

include(srcdir("systems", "barkley.jl"))
include(srcdir("nrmse.jl"))

# stuff...

save(datadir("sim", "barkley", "astonishing_results.jld2"), data)
```

## Making your project a usable module
For some projects, it is often the case that some packages and files from the source folder are loaded at the beginning of _every file of the project_.
For example, I have a project that I know that for _any_ script I will write, the first five lines will be:
```julia
using DrWatson
@quickactivate "AlbedoProperties"
using Dates, Statistics, NCDatasets
include(srcdir("core.jl"))
include(srcdir("style.jl"))
```
It would be quite convenient to group all of these commands into one file and instead load that file, for example do `include(srcdir("everything.jl"))` and all commands are in there.

We can do even better though! Because of the way Julia handles project and module paths, it is in fact possible to transform the currently active project into a usable module. If one defines inside the `src` folder a file `AlbedoProperties.jl` and in that file define a module `AlbedoProperties` (notice that these names must match _exactly_ the project name), then upon doing `using AlbedoProperties` Julia will in fact just bring this module into scope.

So what I end up doing (for some projects where this makes sense) is creating the aforementioned file and putting inside things like
```julia
module AlbedoProperties

using Reexport
@reexport using Dates, Statistics
using NCDatasets: NCDataset, dimnames, NCDatasets
export NCDataset, dimnames
include("core.jl") # this file now also has export statements
include("style.jl")

end
```
and then the header of all my files is transformed to
```julia
using DrWatson
@quickactivate :AlbedoProperties
```
which takes advantage of [`@quickactivate`](@ref)'s feature to essentially combine the commands `@quickactivate "AlbedoProperties"` and `using AlbedoProperties` into one.

If you intend to share your project with a non-DrWatson user, you should consider the verbose syntax instead, as the above syntax is not really clear for someone that doesn't know what `@quickactivate` does.

## `savename` and tagging
The combination of using [`savename`](@ref) and [`tagsave`](@ref) makes it easy and fast to save output in a way that is consistent, robust and reproducible. Here is an example from a project:
```julia
using DrWatson
quickactivate(@__DIR__, "EmbeddingResearch")
using TimeseriesPrediction, LinearAlgebra, Statistics
include(srcdir("systems", "barkley.jl"))

ΔTs = [1.0, 0.5, 0.1] # resolution of the saved data
Ns = [50, 150] # spatial extent
for N ∈ Ns, ΔT ∈ ΔTs
    T = 10050 # we can offset up to 1000 units
    every = round(Int, ΔT/barkley_Δt)
    seed = 1111

    simulation = @ntuple T N ΔT seed
    U, V = barkley(T, N, every; seed = seed)

    @tagsave(
        datadir("sim", "bk", savename(simulation, "jld2")),
        @strdict U V simulation
    )
end
```
This saves files that look like:
```
path/to/project/data/sim/bk_N=50_T=10050_seed=1111_ΔT=1.jld2
```
and each file is a dictionary that has my data fields: `:U, :V, :simulation`, but also `:gitcommit, :script`. When I read this file I know exactly what was the source code that produced it (provided that I am not sloppy and commit code changes regularly :P).

## Customizing `savename`
Here is a simple example for customizing [`savename`](@ref). We are using a common struct `Experiment` across different experiments with cats and mice.

We first define the relevant types.
```@example customizing
using DrWatson, Dates
using Base: @kwdef # for defining structs with keyword values

# Define a type hierarchy we use at experiments
abstract type Species end
struct Mouse <: Species end
struct Cat <: Species end

# @with_kw comes from Parameters.jl
@kwdef struct Experiment{S<:Species}
    n::Int = 50
    c::Float64 = 10.0
    x::Float64 = 0.2
    date::Date = Date(Dates.now())
    species::S = Mouse()
    scientist::String = "George"
end

e1 = Experiment()
e2 = Experiment(species = Cat())
```

For analyzing our experiments we need information about the species used, and to use multiple dispatch later on we decided to make this information associated with a Type. This is why we defined `Species`.

Now, we want to customize [`savename`](@ref). We start by extending [`DrWatson.default_prefix`](@ref):
```@example customizing
DrWatson.default_prefix(e::Experiment) = "Experiment_"*string(e.date)

savename(e1)
```
However this is not good enough for us, as the information about the species is not contained in [`savename`](@ref) and also the date information is duplicated.
We have to extend [`DrWatson.default_allowed`](@ref) to specify which data types should be extended in `savename`:
```@example customizing
DrWatson.default_allowed(::Experiment) = (Real, String, Species)

savename(e1)
```
To make printing of `Species` better we can extend `Base.string`, which is what DrWatson uses internally in [`savename`](@ref) to display values.
```@example customizing
Base.string(::Mouse) = "mouse"
Base.string(::Cat) = "cat"
savename(e1)
```

Lastly, let's say that the information of which scientist performed the experiment is not really relevant for `savename`. We can extend the last method, [`DrWatson.allaccess`](@ref):
```@example customizing
DrWatson.allaccess(::Experiment) = (:n, :c, :x, :species)
```
so that only those four fields will be used (notice that the `date` field is already used in `default_prefix`). We finally have:
```@example customizing
println( savename(e1) )
println( savename(e2) )
```

## `savename` and nested containers
In the case of user-defined structs and projects of significant complexity, it is often necessary that your "main" container has other containers as subfields.
`savename` can adapt to these situations as well.
Consider the following example, where I need a core struct that represents a spatio temporal system, and its simulation:
```@example customizing
struct SpatioTemporalSystem
    model::String # system codeword
    N        # Integer or Tuple of integers: spatial extent
    Δt::Real # sampling time in real time units
    p        # parameters. nothing or Dict{Symbol}
end
const STS = SpatioTemporalSystem

struct SpatioTemporalTimeseries
    sts::STS
    T::Int       # total frame amount
    ic           # initial condition (matrix, string, seed)
    fields::Dict # resulting timeseries, dictionary of string to vector
end
const STT = SpatioTemporalTimeseries
```
For my use case, `p` can be `nothing` or it can be a dictionary itself, containing the possible parameters the spatiotemporal systems can have.
To adapt `savename` to situations like this, we use the functionality surrounding [`DrWatson.default_expand`](@ref).

Expanding the necessary methods allows me to do:
```@example customizing
DrWatson.allaccess(c::STS) = (:N, :Δt, :p)
DrWatson.default_prefix(c::STS) = c.model
DrWatson.default_allowed(c::STS) = (Real, Tuple, Dict, String)
DrWatson.default_expand(c::STS) = ["p"]

bk = STS("barkley", 60, 0.1, nothing)
savename(bk)
```
and when I do want to use different parameters than the default:
```@example customizing
a = 0.3; b = 0.5
bk = STS("barkley", 60, 0.1, @dict a b)
savename(bk)
```

Expanding to the second struct is also fine:
```@example customizing
DrWatson.default_prefix(c::STT) = savename(c.sts)
stt = STT(bk, 1000, nothing, Dict("U"=>rand(100), "V"=>rand(100)))
savename(stt)
```



## Stopping "Did I run this?"
It can become very tedious to have a piece of code that you may or may not have run and may or may not have saved the produced data. You then constantly ask yourself "Did I run this?". Typically one uses `isfile` and an `if` clause to either load a file or run some code. Especially in the cases where the code takes only a couple of minutes to finish you are left in a dilemma "Is it even worth it to save?".

This is the dilemma that [`produce_or_load`](@ref) resolves. You can wrap your code in a function and then [`produce_or_load`](@ref) will take care of the rest for you! I found it especially useful in scripts that generate figures for a publication.

Here is an example; originally I had this piece of code:
```julia
HTEST = 0.1:0.1:2.0
WS = [0.5, 1.0, 1.5]
N = 10000; T = 10000.0

toypar_h = [[] for l in WS]
for (wi, w) in enumerate(WS)
    println("w = $w")
    for h in HTEST
        toyp = toyparameters(h, w, N, T)
        push!(toypar_h[wi], toyp)
    end
end
```
that was taking some minutes to run. To use the function [`produce_or_load`](@ref) I first have to wrap this code in a high level function like so:
```julia
function g(d)
    HTEST = 0.1:0.1:2.0
    WS = [0.5, 1.0, 1.5]
    @unpack N, T = d
    toypar_h = [[] for l in WS]

    for (wi, w) in enumerate(WS)
        println("w = $w")
        for h in HTEST
            toyp = toyparameters(h, w, N, T)
            push!(toypar_h[wi], toyp)
        end
    end
    return @strdict toypar_h
end

N = 2000; T = 2000.0
data, file = produce_or_load(
    datadir("mushrooms", "toy"), # path
    @dict(N, T), # container
    g, # function
    prefix = "fig5_toyparams" # prefix for savename
)
@unpack toypar_h = data
```
Now, every time I run this code block the function tests automatically whether the file exists. Only if it does not, then the code is run while the new result is saved to ensure I won't have to run it again.

The extra step is that I have to extract the useful data I need from the container `file`. Thankfully the `@unpack` macro from [Parameters.jl](https://mauro3.github.io/Parameters.jl/stable/manual.html) makes this super easy.

## Preparing & running jobs
### Preparing the dictionaries
Here is a shortened script from a project that uses [`dict_list`](@ref):
```@example customizing
using DrWatson

general_args = Dict(
    "model" => ["barkley", "kuramoto"],
    "noise" => 0.075,
    "noisy_training" => [true, false],
    "N" => [100],
    "embedding" => [ #(γ, τ, r, c)
    (4, 5, 1, 0.34), (4, 6, 1, 0.28)]
)
```

```@example customizing
dicts = dict_list(general_args)
println("Total dictionaries made: ", length(dicts))
dicts[1]
```
Now, how you use these dictionaries is up to you. Typically each dictionary is given to a `main`-like Julia function which extracts the necessary data and calls the necessary functions.

Let's say I have written a function that takes in one of these dictionaries and saves the file somewhere locally:
```@example customizing
function cross_estimation(data)
    γ, τ, r, c = data["embedding"]
    N = data["N"]
    # add fake results:
    data["x"] = rand()
    data["error"] = rand(10)
    # Save data:
    prefix = datadir("results", data["model"])
    get(data, "noisy_training", false) && (prefix *= "_noisy")
    get(data, "symmetric_training", false) && (prefix *= "_symmetric")
    sname = savename((@dict γ τ r c N), "jld2")
    mkpath(datadir("results", data["model"]))
    save(datadir("results", data["model"], sname), data)
    return true
end
```

### Using map and pmap

One way to run many simulations is with `map` (identical process for using `pmap`).
To run all my simulations I just do:
```@example customizing
dicts = dict_list(general_args)
map(cross_estimation, dicts) # or pmap

# load one of the files to be sure everything is ok:
filename = readdir(datadir("results", "barkley"))[1]
file = load(datadir("results", "barkley", filename))
```

### Using a Serial Cluster
In case that I can't store the results of `dict_list` in memory, I have to
change my approach and load them from disk. This is easy with the function [`tmpsave`](@ref).

Instead of using Julia to run all jobs from one process with `map/pmap` one can use Julia to submit many jobs to a cluster que. For our example above, the Julia program that does this would look like this:

```julia
dicts = dict_list(general_args)
res = tmpsave(dicts)
for r in res
    submit = `qsub -q queuename julia runjob.jl $r`
    run(submit)
end
```
Now the file `runjob.jl` would have contents that look like:
```julia
f = ARGS[1]
dict = load(projectdir("_research", "tmp", f), "params")
cross_estimation(dict)
```
i.e. it just loads the `dict` and straightforwardly uses the "main" function `cross_estimation`. Remember to routinely clear the `tmp` directory!
You could do that by e.g. adding a line `rm(projectdir("_research", "tmp", f)`
at the end of the `runjob.jl` script.

## Listing completed runs
Continuing from the [Preparing & running jobs](@ref) section, we now want to collect the results of all these simulations into a single `DataFrame`. We will do that with the function [`collect_results!`](@ref).

It is quite simple actually! But because we don't want to include the error, we have to black-list it:
```@example customizing
using DataFrames # this is necessary to access collect_results!
bl = ["error"]
res = collect_results!(datadir("results"); black_list = bl, subfolders = true)
```

We can take also advantage of the basic processing functionality of [`collect_results!`](@ref) to use the excluded `"error"` column, replacing it with its average value:
```@example customizing
using Statistics: mean
special_list = [:avrg_error => data -> mean(data["error"])]
res = collect_results(
      datadir("results"),
      black_list = bl,
      special_list = special_list,
      subfolders = true
)

select!(res, Not(:path)) # don't show path this time
```

As you see here we used [`collect_results`](@ref) instead of the in-place version, since there already exists a `DataFrame` with all results processed (and thus everything would be skipped).

## Adapting to new data/parameters
We once again continue from the above example. But we now need to run some new simulations with some new parameters that _do not exist_ in the old simulations... Well, DrWatson says "no problem!" :)

Let's save these new parameters in a different subfolder, to have a neatly organized project:
```@example customizing
general_args_new = Dict(
    "model" => ["bocf"],
    "symmetry" => "radial",
    "symmetric_training" => [true, false],
    "N" => [100],
    "embedding" => [ #(γ, τ, r, c)
    (4, 5, 1, 0.34), (4, 6, 1, 0.28)]
)
```
As you can see, there here there are two parameters not existing in previous simulations, namely `"symmetry", "symmetric_training"`. In addition, the parameters `"noise", "noisy_training"` that existed in the _previous_ simulations do not exist in the current one.

No problem though, let's run the new simulations:
```@example customizing
dicts = dict_list(general_args_new)
map(cross_estimation, dicts)

# load one of the files to be sure everything is ok:
filename = readdir(datadir("results", "bocf"))[1]
file = load(datadir("results", "bocf", filename))
```

Alright, now we want to _add_ these new runs to our existing dataframe that has collected all previous results. This is straight-forward:
```@example customizing
res = collect_results!(datadir("results"); black_list = bl, subfolders = true)

select!(res, Not(:path)) # don't show path this time
```
All `missing` entries were adjusted automatically :)

## Defining parameter sets with restrictions

As already demonstrated in the examples above, for functions where the set of input parameters is the same for each simulation run, a basic dictionary can be used to define these parameters.
However, often some of the parameters or values should only be considered if another parameter is also included in the set or has a specific value.
The macro [`@onlyif`](@ref) allows to place such restrictions on values and parameters.
The following dictionary defines values and parameters for a genetic algorithm:

```@example customizing
ga_parameters = Dict(
    :population_size => [20,50,100],
    :selection => ["roulette-selection", "SUS", "tournament-selection", "linear ranking"],
    :fitness_scaling => @onlyif(:selection in ("SUS", "roulette-selection"), collect(1.0:20.0)),
    :tournamet_size => @onlyif(:selection == "tournament-selection", collect(2:10)),
    :chromosome => [:A, @onlyif(begin
        size_constr = (:population_size <= 50)
        select_constr = (:selection != "SUS")
        size_constr && select_constr
    end, :B)])
```

```@example customizing
dicts = dict_list(ga_parameters)
length(dicts)
```

```@example customizing
dicts[1]
```
The parameter restriction for the chromosome type shows that one can use arbitrary Julia expressions that return `true` or `false`.
In this case, first the conditions for the population size and for the selection method are evaluated and stored.
The expression then only returns true, if both conditions are met, thus restricting the usage of chromosome type `:B`.

As `@onlyif` is meant to be used with [`dict_list`](@ref), it supports the vector notation used for defining possible parameter values.
This is achieved by automatically broadcasting every `@onlyif` call over `Vector` arguments, which allows chaining those calls to combine conditions.
So in terms of the result, `@onlyif( :a == 2, [5, @onlyif(:b == 4, 6)])` is equivalent to `[@onlyif( :a == 2, 5), @onlyif(:a == 2 && :b == 4, 6)]`.

## Filtering by name with collect_results

Using [`collect_results`](@ref) on a folder with many (e.g. 1,000) files in it can be noticeably slow. To speed this up, you can use the `rinclude` and `rexclude` keyword arguments, both of which are vectors of [Regex expressions](https://docs.julialang.org/en/v1/manual/strings/#man-regex-literals). The results returned will have a filename which matches **any** of the Regex expressions in `rinclude` and does not match **any** of the Regex expressions in `rexclude`.

```julia
df = collect_results(datadir("results"); rinclude=[r"a=1"])
# Only include results whose filename contains "a=1"

df = collect_results(datadir("results"); rexclude=[r"a=3"])
# Exclude any results whose filename contains "a=3"

df = collect_results(datadir("results"); rinclude=[r"a=1", r"b=5"], rexclude=[r"a=3"])
# Only include results whose filename contains "a=1" OR "b=5" and exclude any which contain "a=3"
```

## Advanced usage of collect_results
At some point in your work you may want to run a single function
that returns multiple fields that you want to include in your
results `DataFrame`.
Depending on the problem you are trying to solve it may just make more sense to use a single function that extracts most or all of the meta-data.
For this case `DrWatson` has another syntax available.
Let us, for the sake of simplicity, assume that your data files
contain a very long array of numbers called `"manynumbers"`
and the information that you care about are the three largest values.

One way to implement this would be to write
```julia
special_list = [
    :first  => data -> sort(data["manynumbers"])[1],
    :second => data -> sort(data["manynumbers"])[2],
    :third  => data -> sort(data["manynumbers"])[3],
    ]
```
which makes very obvious that there should be a better way to do this.
There is no point in sorting the very long vector three times.
A better thing to do is the following
```julia
function largestthree(data)
    sorted = sort(data["manynumbers"])
    return [:first  => sorted[1],
            :second => sorted[2],
            :third  => sorted[3]]
end

special_list = [largestthree,]
```

## Using `savename` to produce logfiles

When your code runs for a long time or even runs on different machines such as a cluster
environment it becomes important to produce logfiles. Logfiles allow you to
view the progress of your program while it is still running, or check later
on if everything went according to plan.

```julia
using Dates

function logmessage(n, error)
    # current time
    time = Dates.format(now(UTC), dateformat"yyyy-mm-dd HH:MM:SS")

    # memory the process is using 
    maxrss = "$(round(Sys.maxrss()/1048576, digits=2)) MiB"

    logdata = (; 
        n, # iteration n
        error, # some super important progress update
        maxrss) # lastly the amount of memory being used

    println(savename(time, logdata; connector=" | ", equals=" = ", sort=false, digits=2))
end

function expensive_computation(N)

    for n = 1:N
        sleep(1) # heavy computation
        error = rand()/n # some super import progress update
        logmessage(n, error)
    end

end
```

This yields output that is both easy to read *and* machine parseable.
If you ever end up with too many logfiles to read, there is still `parse_savename` to
help you.
 
```julia
julia> expensive_computation(5)
2021-05-19 19:20:25 | n = 1 | error = 0.65 | maxrss = 326.27 MiB
2021-05-19 19:20:26 | n = 2 | error = 0.48 | maxrss = 326.27 MiB
2021-05-19 19:20:27 | n = 3 | error = 0.08 | maxrss = 326.27 MiB
2021-05-19 19:20:28 | n = 4 | error = 0.11 | maxrss = 326.27 MiB
2021-05-19 19:20:29 | n = 5 | error = 0.15 | maxrss = 326.27 MiB
```

## Taking project input-output automation to 11
The point of this section is to show how far one can take the interplay between [`savename`](@ref) and [`produce_or_load`](@ref) to **automate project input-to-output and eliminate as many duplicate lines of code as possible**. Read [Customizing `savename`](@ref) first, as knowledge of that section is used here.

The key ingredient is that [`produce_or_load`](@ref) was made to work well with [`savename`](@ref). You can use this to automate the input-to-output pipeline of your project by following these steps:
1. Define a custom struct that represents the input configuration for an experiment or a simulation. 
2. Extend [`savename`](@ref) appropriately for it. 
3. Define a "main" function that takes as input an instance of this configuration type, and returns the output of the experiment or simulation as dictionary (We're not changing here the "default" way to save files in Julia as `.jld2` files. To save files this way you need your data to be in a dictionary with `String` as keys).
4. All your input-output scripts are simply put together by first defining the input configuration type, and then calling [`produce_or_load`](@ref) with your pre-defined "main" function (Alternatively, this function can internally call `produce_or_load` and return something else that is of special interest to your specific case).

An example of where this approach is used in the "real world" is e.g. in our paper [Effortless estimation of basins of attraction](https://arxiv.org/abs/2110.04358). Its codebase is here: https://github.com/Datseris/EffortlessBasinsOfAttraction. Don't worry, you need to know nothing about the topic to follow the rest. The point is that we needed to run some kind of simulations for many different dynamical systems, which have different parameters, different dimensionality, etc. But they did have one thing in common: our output was always coming from the same function, `basins_of_attraction`, which allowed using the pipeline we discuss here using [`produce_or_load`](@ref). 

So we defined a struct called `BasinConfig` that stored configuration options and system parameters. Then we extended `savename` for it. We defined some function `produce_basins` that takes this configuration file, initializes a dynamical system accordingly, and then makes the output **using `produce_or_load`**. This ensures that we're not running simulations twice if they exist. And keep in mind when you have so many parameters and different possible systems, it is quite easy to unintentionally run the same simulation twice because you "forgot about it". All of this can be found in this file: https://github.com/Datseris/EffortlessBasinsOfAttraction/blob/master/src/produce_basins.jl 

The benefit? All of our scripts that actually produce what we care about are this short:
```julia
using DrWatson
@quickactivate :EffortlessBasinsOfAttraction

a, b = 1.4, 0.3
p = @ntuple a b
system = :henon

basin_kwargs = (horizon_limit=100.0, mx_chk_fnd_att=30, mx_chk_lost=2)
Z = 201
xg = range(-1.5, 1.5; length = Z)
yg = range(-0.5, 0.5; length = Z)
grid = (xg, yg)

config = BasinConfig(; system, p, basin_kwargs, grid)
basins, attractors = produce_basins(config)
```
and more importantly, the only lines that are genuinely "copy-pasted" from script to script are the last two. All other lines are unique for each script. This minimization of copy-pasting duplicate information makes the workflow robust and makes bugs easier to find.
# Saving Tools
This page discusses numerous tools that can significantly improve process of saving & loading files, always in a scientific context.

These tools are also used in the examples demonstrated in the [Real World Examples](@ref) page. After reading the proper documentation here it might be worth it to have a look there as well!

In DrWatson we save and load files with the functions `wsave(filename, data)` and `wload(filename)`. These functions are further used in the tools below, like e.g. [`tagsave`](@ref) and can be overloaded for your own specific datatype.

In addition, `wsave` **ensures** that `mkpath` is always called on the path you are trying to save your file at. We all know how unpleasant it is to run a 2-hour simulation and save no data because `FileIO.save` complains that the path you are trying to save at does not exist...

To overload the saving part, add a new method to `DrWatson._wsave(filename, ::YourType)` (notice the `_`). By overloading `_wsave` you get all the extra functionality of [`tagsave`](@ref), [`safesave`](@ref), etc., for free for your own types (`tagsave` requires that you save your data as a dictionary).

!!! warning "Saving and loading fallback"
    By default we fallback to `FileIO.save` and `FileIO.load` for and types.
    This means that you have to install yourself whatever saving backend you want to use.
    `FileIO` by itself does _not_ install a package that saves data, it only provides the interface!

    The *suffix* of the file name determines which package will be used for actually saving the file. It is **your responsibility** to know how the saving package works and what input it expects!


## Safely saving data
Almost all packages that save data by default overwrite existing files (if given a save name of an existing file). This is the default behavior because often it is desired.

Sometimes it is not though! And the consequences of overwritten data can range from irrelevant to catastrophic. To avoid such an event we provide an alternative way to save data that will never overwrite existing files:
```@docs
safesave
```

## Tagging a run using Git
For reproducibility reasons (and also to not go insane when asking "HOW DID I GET THOSE RESUUUULTS") it is useful to "tag" any simulation/result/process using the Git status of the repository.

To this end we have some functions that can be used to ensure reproducibility:
```@docs
tagsave
@tagsave
```
The functions also incorporate [`safesave`](@ref) if need be.

### Low level functions
[`@tagsave`](@ref) internally uses the following low level functions:
```@docs
tag!
@tag!
gitdescribe
DrWatson.gitpatch
isdirty
```

Please notice that `tag!` will operate in place only when possible. If not possible then a new dictionary is returned. Also (importantly) these functions will **never error** as they are most commonly used when saving simulations and this could risk data not being saved!

## Produce or Load

`produce_or_load` is a function that very conveniently integrates with [`savename`](@ref) to either load a file if it exists, or if it doesn't to produce it, save it and then return it!

This saves you the effort of checking if a file exists and then loading, or then running some code and saving, or writing a bunch of `if` clauses in your code.
In addition, it attempts to minimize computing energy spent on getting a result.

```@docs
produce_or_load
@produce_or_load
istaggable
```

See [Stopping "Did I run this?"](@ref) for an example usage of `produce_or_load`. While `produce_or_load` will try to by default tag your data if possible, you can also use it with other formats. An example is when your simulation function `f` returns a `DataFrame` and the file suffix is `"csv"`. In this case tagging will not happen, but `produce_or_load` will work as expected.


## Converting a struct to a dictionary
[`savename`](@ref) gives great support for getting a name out of any Julia composite type. To save something though, one needs a dictionary. So the following function can be conveniently used to directly save a struct using any saving function:
```@docs
struct2dict
struct2ntuple
```
# Naming Simulations
Here we overview functionality that helps you quickly produce containers of parameters and name them using a consistent and intuitive naming scheme.

## Naming Schemes

A robust naming scheme allows you to create quick names for simulations, create lists of simulations, check existing simulations, etc. More importantly it allows you to easily create simulation-based names **consistently** and **deterministically**.

This is what the function [`savename`](@ref) does. Of course, you don't have to use it only for using names to save files. You could use it for anything that fits you (like e.g. adding identifiers to tabular data).
[`savename`](@ref) is also surprisingly useful for creating titles of figures, e.g. `savename(c; connector = ", ")`.

```@docs
savename
```

Notice that this naming scheme integrates perfectly with Parameters.jl.

## Convenience functions
Convenience functions are provided to shorten common function calls and easily create named tuples, dictionaries as well as switch between them:
```@docs
@dict
@strdict
@ntuple
@savename
ntuple2dict
dict2ntuple
tostringdict
tosymboldict
```

Notice that we also re-export the convenient `@pack!, @unpack` tools from [UnPack.jl](https://github.com/mauro3/UnPack.jl), because they play very well with [`@dict`](@ref) and similar functions. Be aware of the syntactic `,` difference: `d = @dict a b c` versus `@unpack a, b, c = d`.
```@docs
@unpack
@pack!
```

## Customizing `savename`
You can customize [`savename`](@ref) for your own Types. For example you could make it so that it only uses some specific keys instead of all of them, only specific types, or you could make it access data in a different way (maybe even loading files!). You can even make it have a custom `prefix`!

To do that you may extend any of the following functions:
```@docs
DrWatson.allaccess
DrWatson.access
DrWatson.allignore
DrWatson.default_allowed
DrWatson.default_prefix
DrWatson.default_expand
```

See [Real World Examples](@ref) for an example of customizing `savename`.
Specifically, have a look at [`savename` and nested containers](@ref) for a way to

## Reverse-engineering `savename`
```@docs
parse_savename
```
