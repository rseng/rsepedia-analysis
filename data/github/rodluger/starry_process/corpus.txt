p aligncent img width srchttpsrawgithubusercontentcomrodlugerstarry_processmasterstarry_processgif br hrefhttpsgithubcomrodlugerstarry_processactionsqueryworkflowatest img srchttpsgithubcomrodlugerstarry_processworkflowstestsbadgesvg hrefhttpsstarryprocessreadthedocsioenlatestbadgelatest img srchttpsreadthedocsorgprojectsstarryprocessbadgeversionlatest altdocument statu hrefhttpsgithubcomrodlugerstarry_processrawjosspaperjosspaperpdf img srchttpsgithubcomrodlugerstarry_processworkflowsjosspaperbadgesvg br hrefhttpstarryprocessflatironinstituteorg img srchttpsimgshieldsiobadgewebapporangesvgstyleflat hrefhttpsgithubcomrodlugermapping_stellar_surfacesrawpaperpdfmspdf img srchttpsimgshieldsiobadgereadpaper_bluesvgstyleflat hrefhttpsgithubcomrodlugermapping_stellar_surfacesrawpaperpdfmspdf img srchttpsimgshieldsiobadgereadpaper_bluesvgstyleflat p p aligncent interpret gaussian process stellar light curv use hrefhttpsgithubcomrodlugerstarrystarrya p gaussian process stellar variabl starry_process code implement interpret gaussian process gp model stellar light curv whether goal margin stellar variabl signal think nois understand surfac featur gener think data code gp implement work like gp might alreadi use analysi except hyperparamet physic interpret among other radiu spot mean varianc latitud distribut spot contrast number spot user also specifi thing like rotat period star limb darken paramet inclin margin inclin known code written python reli theano packagehttpstheanopymcreadthedocsioenstableindexhtml littl familiar recommend check crash cours herehttpsstarryprocessreadthedocsioenlatestnotebooksquickstartcompilingtheanofunct would like report issu contribut project pleas check contributingmdcontributingmd instal quickest way via pip bash pip instal starryprocess note starry_process packag requir python later quickstart import main interfac python starry_process import starryprocess draw sampl gaussian process small midlatitud spot python import numpi np import matplotlibpyplot plt instanti gp sp starryprocess r spot radiu degre mu central spot latitud degre sigma latitud std dev degre c fraction spot contrast n number spot draw visual spheric harmon sampl spsample_ylmev spvisualizey comput plot flux inclin nplinspac flux spfluxi ieval pltplott flux img srchttpsrawgithubusercontentcomrodlugerstarry_processmasterdocssamples_png highlatitud spot python sp starryprocessr mu sigma c n img srchttpsrawgithubusercontentcomrodlugerstarry_processmasterdocssamples_png larg equatori spot python sp starryprocessr mu sigma c n img srchttpsrawgithubusercontentcomrodlugerstarry_processmasterdocssamples_png small approxim isotrop spot python sp starryprocessr mu sigma c n img srchttpsrawgithubusercontentcomrodlugerstarry_processmasterdocssamples_png inform check full quickstart tutorialhttpsstarryprocessreadthedocsioenlatestnotebooksquickstart complet documentationhttpsstarryprocessreadthedocsioenlatest refer attribut code describ joss paperhttpsgithubcomrodlugerstarry_processrawjosspaperjosspaperpdf backbon map stellar surfaceshttpsgithubcomrodlugermapping_stellar_surfac paper seri includ degeneraci rotat light curv problemhttpsgithubcomrodlugermapping_stellar_surfacesrawpaperpdfmspdf interpret gaussian process model stellar light curveshttpsgithubcomrodlugermapping_stellar_surfacesrawpaperpdfmspdf make use code research pleas cite articlelugera author luger rodrigo foremanmackey daniel hedg christina hogg david w titl map stellar surfac degeneraci rotat light curv problem journal arxiv eprint keyword astrophys solar stellar astrophys astrophys instrument method astrophys year month jan eid arxiv page arxiv archiveprefix arxiv eprint primaryclass astrophsr adsurl httpsuiadsabsharvardeduabsarxivl adsnot provid saonasa astrophys data system articlelugerb author luger rodrigo foremanmackey daniel hedg christina titl map stellar surfac ii interpret gaussian process model light curv journal arxiv eprint keyword astrophys solar stellar astrophys astrophys earth planetari astrophys astrophys instrument method astrophys year month feb eid arxiv page arxiv archiveprefix arxiv eprint primaryclass astrophsr adsurl httpsuiadsabsharvardeduabsarxivl adsnot provid saonasa astrophys data system articlelugerc author luger rodrigo foremanmackey daniel hedg christina titl starry_process interpret gaussian process stellar light curv journal arxiv eprint keyword astrophys solar stellar astrophys astrophys earth planetari astrophys astrophys instrument method astrophys year month feb eid arxiv page arxiv archiveprefix arxiv eprint primaryclass astrophsr adsurl httpsuiadsabsharvardeduabsarxivl adsnot provid saonasa astrophys data system contribut starry_process report issu find bug unexpect behavior use starry_process open issu github repositoryhttpsgithubcomrodlugerstarry_processissu tri respond hope solv problem time manner question andor featur request also welcom report issu pleas provid detail need reproduc problem packag version depend version platform small standalon piec code demonstr problem clearli contribut code welcom contribut codebas scale typo fix new featur would like add substanti featur would good idea first open issuehttpsgithubcomrodlugerstarry_processissu describ plan discuss advanc titl starry_process interpret gaussian process stellar light curv tag python astronomi author name rodrigo luger orcid affili name daniel foremanmackey orcid affili name christina hedg orcid affili affili name center comput astrophys flatiron institut new york ny index name virtual planetari laboratori univers washington seattl wa index name bay area environment research institut po box moffett field ca usa index name nasa ame research center moffett field ca index date januari aasdoi abfdb aasjourn astronom journal bibliographi bibbib summari starry_process code implement interpret gaussian process gp model variabl stellar light curv dark starspot rotat view total flux receiv distant star chang time unresolv flux time seri therefor encod inform spatial structur featur stellar surfac starry_process softwar packag allow one easili model flux variabl due starspot whether one interest understand properti spot margin stellar variabl treat nuisanc signal main differ gp implement typic gp use model stellar variabl explicit depend gp physic properti star period inclin limb darken coeffici properti spot radiu latitud distribut see figur reffigsampl code python implement interpret gp algorithm develop paperii five random sampl gp column condit two differ hyperparamet vector pmbtheta_bullet row sampl shown surfac star mollweid project alongsid correspond light curv view sever differ inclin sampl gp describ star small midlatitud spot b sampl gp describ star larger highlatitud spot labelfigsamplesfiguressamplespdf statement need map surfac star use time seri measur fundament problem modern timedomain stellar astrophys invers problem illpos comput intract associ aa journal public submit parallel paper paperii deriv interpret effect gaussian process gp model problem enabl robust probabilist character stellar surfac use photometr time seri observ model build previou work perger semiinterpret gaussian process stellar timeseri data morrisb approxim infer larg ensembl stellar light curv implement model requir effici evalu set special function recurs relat readili avail exist probabilist program framework starry_process packag provid necessari element perform analysi exist forthcom astronom dataset implement implement interpret gp userfriendli python packag starry_process instal via pip sourc githubhttpsgithubcomrodlugerstarry_process code thoroughli unittestedhttpsgithubcomrodlugerstarry_processtreemastertest well documentedhttpsstarry_processreadthedocsio exampleshttpsstarryprocessreadthedocsioenlatestexampl use gp custom infer problem discuss associ aa journal public paperii user choos among option whether margin stellar inclin whether model normal process user also choos spheric harmon degre expans although recommend use l_mathrmmax see user may comput mean vector covari matrix either spheric harmon basi flux basi may sampl use comput margin likelihood arbitrari order limb darken implement follow agol code design maxim speed numer stabil comput although comput gp covari involv mani layer nest sum spheric harmon coeffici may express highdimension tensor product evalu effici modern hardwar mani express also either precomput comput recurs maxim speed algorithm code implement hybrid cpython use justintim compil capabl theano packag theano sinc equat deriv close form express autodifferenti straightforward numer stabl manner enabl comput backpropag gradient within theano starry_process design work outofth box theanobas infer tool pymc nutshmc advi sampl salvati figur reffigspe show comput scale python implement algorithm case condit gp specif valu inclin blue case margin inclin orang curv show time second comput likelihood averag mani trial obtain robust estim function number point k singl light curv k lesssim comput time constant ms algorithm approxim time typic modern laptop taken comput gp covari matrix given set hyperparamet pmbtheta_bullet larger valu k cost approach scale k domin factor covari matrix solv oper comput likelihood likelihood margin inclin slightli slower comput thank trick discuss paperii evalu time second singl loglikelihood comput function number point k light curv condit valu inclin blue margin inclin orang l_mathrmmax comput covari matrix gp take ms ms typic laptop dash line show asymptot scale algorithm due choleski factor solv operationslabelfigspeedfiguresspeedpdf log condit number covari spheric harmon basi function spheric harmon degre expans l_mathrmmax differ line correspond differ valu pmbtheta_bullet drawn uniform prior see text detail major case matrix becom illcondit l_mathrmmax labelfigstabilityfiguresstabilitypdf mani modern gp packag eg ambikasaran foremanmackey significantli better asymptot scale usual due specif structur impos kernel function assumpt stationar kernel structur determin physic perhap accur geometri stellar surfac nonstationar consequ normal step rel photometri paperi moreov unlik typic kernel use gp regress kernel nontrivi function hyperparamet pmbtheta_bullet comput necessarili expens nevertheless fact gp may use likelihood evalu small fraction second typic dataset k sim make extrem use infer recal implicitli margin properti empheveri spot surfac star ensembl analys must comput likelihood light curv condit pmbtheta_bullet practic star differ rotat period differ limb darken coeffici differ photometr uncertainti mean must factor differ covari matric fortun spheric harmon covari pmbsigma_mathbfi need comput linearli transform flux basi light curv evalu pmbsigma_mathbfi computationallyintens step likelihood evalu typic scale sublinearli furthermor possibl margin period limb darken coeffici would remov scale entir photometr precis light curv even algorithm still greatli sped although implement defer next paper algorithm also numer stabl nearli prior volum l_mathrmmax figur reffigst show log condit number covari matrix spheric harmon basi function spheric harmon degre expans draw uniform prior domain hyperparamet r circ circ mu_phi circ circ sigma_phi circ circ n condit number nearli constant l_mathrmmax almost case valu algorithm suddenli becom unstabl covari illcondit instabl occur within comput latitud longitud moment integr like due larg number oper involv linear combin hypergeometr gamma function may possibl achiev stabil higher valu l_mathrmmax via care reparametr equat find l_mathrmmax high enough practic purpos final instabl also occur sigma_phi small andor n larg valu sigma_phi lesssim circ lead instabl comput hypergeometr function valu n gtrsim sometim caus choleski factor covari fail although mitig ad small quantiti diagon ensur positivesemidefinitess case algorithm goe unstabl loglikelihood evalu return infti word silent reject implicit prior fortun case like unphys practic alway finit amount varianc latitud spot star spot like spot individu spot discern first place instead like sensit emphgroup spot gp flexibl enough model refer eigen c templat librari linear algebra matric vector numer solver relat algorithm inform go httpeigentuxfamilyorg eigen tensor tensor multidimension array element element typic scalar complex type string also support toc tensor class manipul tensor one follow class namespac eigen class tensordata_typ rank class use creat tensor alloc memori class templat tensor datatyp float int tensor rank rank number dimens exampl rank matrix tensor class resiz exampl assign tensor differ size tensor tensor resiz match new valu constructor tensordata_typ ranksiz size constructor tensor constructor must pass rank integ indic size instanc along rank dimens creat tensor rank size tensor own memori hold float point valu x x tensorfloat t_d resiz t_d assign tensor differ size rank t_d tensorfloat constructor tensordata_typ ranksize_array constructor size constructor specifi array valu instead explicitli list paramet array type use eigenarrayeigenindex array construct automat initi list creat tensor string rank size tensorstr t_d class tensorfixedsizedata_typ sizess size class use tensor fix size size known compil time fix size tensor provid fast comput dimens known compil fixeds tensor resiz total number element fix size tensor small enough tensor data held onto stack caus heap alloc free creat x tensor float tensorfixedsizefloat size t_x class tensormaptensordata_typ rank class use creat tensor top memori alloc own anoth part code allow view piec alloc memori tensor instanc class memori data store tensormap resiz memori data store constructor tensormaptensordata_typ rankdata size size constructor tensor constructor must pass pointer storag data rank size attribut storag larg enough hold data map tensor int top stackalloc storag int storag x x x tensormaptensorint t_dstorag storag view differ tensor also pass size array tensormaptensorint t_dstorag also map fixeds tensor get view fixeds tensor tensorfloat size t_x tensormaptensorfloat t_t_x class tensorref see assign tensorref access tensor element data_typ tensorindex index return element posit index index tensor tensor must pass mani paramet rank tensor express use lvalu set valu element specifi posit valu return datatyp tensor set valu element posit tensorfloat t_d t_d f initi element random valu int int j j j int k k k t_di j k random valu print element tensor int loginfo t_di tensorlayout tensor librari support layout colmajor default rowmajor default column major layout current fulli support therefor recommend attempt use row major layout moment layout tensor option specifi part type specifi explicitli column major assum tensorfloat colmajor col_major equival tensorfloat tensormaptensorfloat rowmajor row_majordata argument express must use layout attempt mix differ layout result compil error possibl chang layout tensor express use swap_layout method note also revers order dimens tensorfloat colmajor col_major tensorfloat rowmajor row_major tensorfloat col_major_result col_major ok layout match tensorfloat col_major_result row_major compil simpl layout swap col_major_result row_majorswap_layout eigen_assertcol_major_resultdimens eigen_assertcol_major_resultdimens swap layout preserv order dimens arrayint shuffl col_major_result row_majorswap_layoutshuffleshuffl eigen_assertcol_major_resultdimens eigen_assertcol_major_resultdimens tensor oper eigen tensor librari provid vast librari oper tensor numer oper addit multipl geometri oper slice shuffl etc oper avail method tensor class case oper overload exampl follow code comput elementwis addit two tensor tensorfloat set valu tensorfloat set valu set element wise sum tensorfloat code look easi enough import understand express actual ad valu tensor express instead construct tensor oper object class tensorcwisebinaryopscalar_sum refer tensor small c object know add valu express assign tensor addit actual perform technic happen overload oper tensor class mechan comput tensor express allow lazi evalu optim make tensor librari fast cours tensor oper nest express f actual repres approxim tree oper tensorcwisebinaryopscalar_sumt tensorcwiseunaryopscalar_mult f tensor oper c auto tensor oper creat tensor oper c auto keyword intuit mean consid line code tensorfloat auto first line alloc tensor contain result addit second line actual tree tensor oper comput addit fact tensor get valu element tensorfloat cout ok print valu auto cout compil error use auto get tensor result instead nonevalu express use auto delay evalu unfortun singl underli concret type hold nonevalu express henc use auto case want hold nonevalu express need result set tensor comput assign result tensor capabl hold onto either normal tensor fix size tensor tensormap exist piec memori follow work auto tensorfloat result could also resultt cout result tensormapfloat resulta float enough space size cout result tensorfixedsizefloat sizess result cout result need result keep oper around even reus addit oper long keep express oper comput perform one way comput expt f auto auto f auto texp tensorfloat result anoth way exactli effici previou one tensorfloat result fexp control express evalu sever way control express evalu assign tensor tensorfixeds tensormap use eval method assign tensorref assign tensor tensorfixeds tensormap common way evalu express assign tensor exampl auto declar make intermedi valu oper tensor caus express evalu assign tensor result caus evalu oper auto oper auto f oper auto texp oper tensorfloat result oper evalu know rank size oper valu assign oper tensorfixeds instead tensor bit effici know result xx tensor tensorfixedsizefloat result simiarli assign express tensormap caus evalu like tensor type tensorfixeds tensormap resiz rank size express assign call eval comput larg composit express sometim want tell eigen intermedi valu express tree worth evalu ahead time done insert call eval method express oper previou exampl could written tensorfloat result fexp want comput ahead time write tensorfloat result teval fexp semant call eval equival materi valu express temporari tensor right size code effect eval know size tensorfixedsizefloat tmp tensorfloat result tmp fexp note return valu eval oper follow code may think evalu oper evalu yet auto teval use anoth express still evalu auto fexp valu evalu assign oper tensor use intermedi tensor repres tx tensorfloat result exampl call eval make differ perform case make huge differ express broadcast express caus xmaximum express evalu mani time tensor x tensor x xmaximumdepth_dimreshapedimsdbroadcastbcast betaexp insert call eval maximum reshap call guarante maximum comput greatli speedsup execut tensor x xmaximumdepth_dimevalreshapedimsdbroadcastbcast betaexp exampl tensor use express assign alias problem evalu done right order updat increment evalu result bogu result tensor ysumdepth_dimreshapedimsdbroadcastbcast insert call eval sum reshap express ensur sum comput updat done ysumdepth_dimevalreshapedimsdbroadcastbcast note eval around full right hand side express need gener comput ith valu right hand side assign left hand side howev assign express valu shuffl would need forc eval correct ad eval call right hand side yshuffl ysumdepth_dimevalreshapedimsdbroadcastbcastev assign tensorref need access element valu express avoid materi valu full tensor use tensorref tensorref small wrapper class eigen oper provid overload oper let access individu valu express tensorref conveni oper provid way access individu element creat tensorref express express evalu yet tensorreftensorfloat ref fexp use ref access individu element express evalu fli float at_ ref cout ref use tensorref need subset valu express tensorref comput valu access howev note go access valu much faster materi result tensor first case full tensor result would larg may save memori access tensorref alway dont count control express evalu tensor librari provid sever implement variou oper contract convolut implement optim differ environ singl thread cpu multi thread cpu gpu use cuda addit implement may ad later choos implement use devic call choos implement explicitli default implement use singl thread cpu use default implement optim recent intel cpu take advantag sse avx fma instruct work ongo tune librari arm cpu note need pass compilerdepend flag enabl use sse avx instruct exampl follow code add two tensor use default singlethread cpu implement tensorfloat tensorfloat b tensorfloat c b choos differ implement insert devic call assign result technic c reason requir tensor result declar mean know size result eigentensorfloat c cdevic b call devic must last call left oper must pass devic call eigen devic object present three devic use defaultdevic threadpooldevic gpudevic evalu defaultdevic exactli insert devic call defaultdevic my_devic cdevicemy_devic b evalu thread pool creat eigen threadpooldevic eigenthreadpooldevic my_devic number thread use use devic evalu express eigentensorfloat c cdevicemy_devic acontractb dot_product_dim evalu gpu present bit complic use thread pool devic need creat gpu devic also need explicitli alloc memori tensor cuda api refer datatyp document tensor method oper mention datatyp tensortyp specif tensortypedimens act like array int int size attribut index like array access individu valu use repres dimens tensor see dimens tensortypeindex act like int use index tensor along dimens see oper dimens size tensortypescalar repres datatyp individu tensor element exampl tensorfloat scalar type float see setconst oper use pseudo type indic tensor oper return method indic text type dimens tensor oper return evalu oper evalu exampl assign tensor access valu result tensor also access valu tensorref builtin tensor method usual c method act tensor immedi oper provid delay evalu result unless specifi otherwis method list avail tensor class tensor tensorfixeds tensormap metadata int numdimens constant valu indic number dimens tensor also known tensor rank eigentensorfloat cout dim anumdimens dim dimens dimens return arraylik object repres dimens tensor actual type dimens result tensortypedimens eigentensorfloat const eigentensorfloat dimens adimens cout dim size dsize dim dim dim size dim dim use c compil use auto simplifi code const auto adimens cout dim size dsize dim dim dim size dim dim index dimensionindex n return nth dimens tensor actual type dimens result tensortypeindex alway use like int eigentensorfloat int dim adimens cout dim dim dim index size return total number element tensor product tensor dimens actual type size result tensortypeindex alway use like int eigentensorfloat cout size asiz size get dimens oper oper provid dimens directli eg tensorreslicingop oper defer calcul dimens oper evalu need access dimens defer oper wrap tensorref see assign tensorref provid dimens dimens tensorref also wrap plain tensor type use idiom templat context underli object could either raw tensor defer oper eg slice tensor case templat code wrap object tensorref reason dimension remain agnost underli type constructor tensor creat tensor specifi size number argument must equal rank tensor content tensor initi eigentensorfloat cout numrow adimens numcol adimens endl numrow numcol tensorfixeds creat tensor specifi size number argument size templat paramet determin rank tensor content tensor initi eigentensorfixedsizefloat size cout rank arank endl rank cout numrow adimens numcol adimens endl numrow numcol tensormap creat tensor map exist array data data must freed tensormap discard size data must larg enough accomod coeffici tensor float data eigentensormapfloat adata cout numrow adimens numcol adimens endl numrow numcol cout endl content initi new tensor new tensorfixeds creat memori alloc hold tensor element memori initi similarli new tensormap creat top noniniti memori memori content initi use one method initi tensor memori immedi effect tensor return tensor result tensor oper delay evalu tensortyp setconstantconst scalar val set element tensor constant valu val scalar type data store tensor pass valu convert type return tensor case want chain anoth call asetconstantf cout constant endl endl endl constant note setconst use tensor element type copi constructor oper eigentensorstr asetconstantyolo cout string tensor endl endl endl string tensor yolo yolo yolo yolo yolo yolo tensortyp setzero fill tensor zero equival setconstantscalar return tensor case want chain anoth call asetzero cout zero endl endl endl zero tensortyp setvaluesinitializer_list fill tensor explicit valu specifi stdinitializer_list type initi list depend type rank tensor tensor rank n initi list must nest n time deepli nest list must contain p scalar tensor type p size last dimens tensor exampl tensorfixedsizefloat initi list must contain list float setvalu return tensor case want chain anoth call eigentensorfloat asetvaluesf f f f f f cout endl endl endl list short correspond element tensor chang valid level nest exampl follow code set valu first row tensor eigentensorint asetconst asetvalu cout endl endl endl tensortyp setrandom fill tensor random valu return tensor case want chain anoth call asetrandom cout random endl endl endl random custom setrandom provid random number gener templat argument asetrandommyrandomgener myrandomgener must struct follow member function scalar index tensortypescalar tensortypeindex see struct uniformrandomgener tensorfunctorsh exampl custom number gener use setrandom struct myrandomgener default copi constructor need myrandomgener myrandomgeneratorconst myrandomgener return random valu use element_loc locat entri set tensor typic ignor scalar operatoreigendenseindex element_loc eigendenseindex unus const return randomli gener valu type gener sever number time typenam internalpacket_traitsscalartyp packetop eigendenseindex packet_loc eigendenseindex unus const return packet randomli gener valu also use one random number gener part tensor librari uniformrandomgener normalrandomgener data access tensor tensorfixeds tensorref class provid follow accessor access tensor coeffici const scalar operatorconst arrayindex numindic indic const scalar operatorindex firstindex indextyp otherindic scalar operatorconst arrayindex numindic indic scalar operatorindex firstindex indextyp otherindic number indic must equal rank tensor moreov accessor avail tensor express order access valu tensor express express must either evalu wrap tensorref scalar data const scalar data const return pointer storag tensor pointer const tensor const allow direct access data layout data depend tensor layout rowmajor colmajor access usual need special case exampl mix eigen tensor code librari scalar type data store tensor eigentensorfloat float a_data adata a_data f cout tensor oper method document return non evalu tensor oper chain appli anoth tensor oper valu return method chain oper evalu lazili typic assign tensor see control express evalu detail evalu oper constantconst scalar val return tensor type dimens origin tensor element valu val use exampl want add subtract constant tensor multipli everi element tensor scalar eigentensorfloat asetconstantf eigentensorfloat b aconstantf eigentensorfloat c b bconstantf cout endl endl endl cout b endl b endl endl cout c endl c endl endl b c oper random return tensor type dimens current tensor element random valu exampl use add random valu exist tensor gener random valu custom manner setrandom eigentensorfloat asetconstantf eigentensorfloat b arandom cout endl endl endl cout b endl b endl endl b unari element wise oper oper take singl input tensor argument return tensor type dimens tensor appli request oper appli element independ oper oper return tensor type dimens origin tensor contain opposit valu origin tensor eigentensorfloat asetconstantf eigentensorfloat b cout endl endl endl cout b endl b endl endl b oper sqrt return tensor type dimens origin tensor contain squar root origin tensor oper rsqrt return tensor type dimens origin tensor contain invers squar root origin tensor oper squar return tensor type dimens origin tensor contain squar origin tensor valu oper invers return tensor type dimens origin tensor contain invers origin tensor valu oper exp return tensor type dimens origin tensor contain exponenti origin tensor oper log return tensor type dimens origin tensor contain natur logarithm origin tensor oper ab return tensor type dimens origin tensor contain absolut valu origin tensor oper powscalar expon return tensor type dimens origin tensor contain coeffici origin tensor power expon type expon scalar alway type tensor coeffici exampl integ expon use conjunt tensor integ valu use cast lift restrict exampl comput cubic root int tensor eigentensorint asetvalu eigentensordoubl b acastdoublepow cout endl endl endl cout b endl b endl endl b oper oper scalar scale multipli coeffici input tensor provid scale oper cwisemaxscalar threshold todo oper cwiseminscalar threshold todo oper unaryexprconst customunaryop func todo binari element wise oper oper take two input tensor argument input tensor type dimens result tensor dimens tensor appli unless otherwis specifi also type request oper appli pair element independ oper operatorconst otherderiv return tensor type dimens input tensor contain coeffici wise sum input oper operatorconst otherderiv return tensor type dimens input tensor contain coeffici wise differ input oper operatorconst otherderiv return tensor type dimens input tensor contain coeffici wise product input oper operatorconst otherderiv return tensor type dimens input tensor contain coeffici wise quotient input oper support integ type oper cwisemaxconst otherderiv return tensor type dimens input tensor contain coeffici wise maximum input oper cwiseminconst otherderiv return tensor type dimens input tensor contain coeffici wise mimimum input oper logic oper follow logic oper support well operatorconst otherderiv operatorconst otherderiv operatorconst otherderiv operatorconst otherderiv operatorconst otherderiv operatorconst otherderiv operatorconst otherderiv operatorconst otherderiv return tensor boolean valu select selectconst thenderiv thentensor const elsederiv elsetensor select coefficientwis ternari oper tensor equival ifthenels oper tensorbool tensorfloat tensorfloat els tensorfloat result ifselectthen els argument must dimens also dimens result tensor must type boolean els tensor must type also type result coeffici result equal correspond coeffici tensor correspond valu tensor true result coeffici come els tensor contract tensor contract gener matrix product multidimension case creat matric use tensor rank eigentensorint asetvalu eigentensorint b asetvalu comput tradit matrix product arrayindexpairint product_dim indexpair eigentensorint ab acontractb product_dim comput product transpos matric arrayindexpairint transpose_product_dim indexpair eigentensorint atbt acontractb transposed_product_dim reduct oper reduct oper return tensor fewer dimens origin tensor valu return tensor comput appli reduct oper slice valu origin tensor specifi dimens along slice made eigen tensor librari provid set predefin reduct oper maximum sum let defin addit oper implement method reductor templat reduct dimens reduct oper take singl paramet type tensortypedimens alway specifi array int call reduct dimens valu indic dimens input tensor reduct done paramet mani element rank input tensor element must less tensor rank indic one dimens reduc dimens input tensor occur reduct dimens implement remov duplic order valu reduct dimens affect result code may execut faster list dimens increas order exampl reduct along one dimens creat tensor dimens eigentensorint asetvalu reduc along second dimens eigenarrayint dim dimens reduc use maximum oper result tensor one dimens size dimens first nonreduc dimens eigentensorint b amaximumdim cout endl endl endl cout b endl b endl endl b exampl reduct along two dimens eigentensorfloat eigencolmajor asetvaluesf f f f f f f f f f f f f f f f f f f f f f f f tensor dimens reduc along first result tensor singl dimens size last dimens note pass array reduct dimens directli maximum call eigentensorfloat eigencolmajor b amaximumeigenarrayint cout b endl b endl endl b reduct along dimens special case pass paramet reduct oper origin tensor reduc along dimens result scalar repres zerodimens tensor eigentensorfloat asetvaluesf f f f f f f f f f f f f f f f f f f f f f f f reduc along dimens use sum oper eigentensorfloat b asum cout b endl b endl endl b oper sumconst dimens new_dim oper sum reduc tensor use sum oper result valu sum reduc valu oper meanconst dimens new_dim oper mean reduc tensor use mean oper result valu mean reduc valu oper maximumconst dimens new_dim oper maximum reduc tensor use maximum oper result valu largest reduc valu oper minimumconst dimens new_dim oper minimum reduc tensor use minimum oper result valu smallest reduc valu oper prodconst dimens new_dim oper prod reduc tensor use prod oper result valu product reduc valu oper allconst dimens new_dim oper reduc tensor use oper cast tensor bool check whether element true run element rather shortcircuit may significantli ineffici oper anyconst dimens new_dim oper reduc tensor use oper cast tensor bool check whether element true run element rather shortcircuit may significantli ineffici oper reduceconst dimens new_dim const reduc reduc reduc tensor use userdefin reduct oper see sumreduc tensorfunctorsh inform implement reduct oper scan oper scan oper return tensor dimens origin tensor oper perform inclus scan along specifi axi mean comput run total along axi given reduct oper reduct oper correspond summat comput prefix sum tensor along given axi exampl dd comment line creat tensor dimens eigentensorint asetvalu scan along second dimens use summat eigentensorint b acumsum result tensor size input cout endl endl endl cout b endl b endl endl b oper cumsumconst index axi perform scan sum consecut entri oper cumprodconst index axi perform scan multipli consecut entri convolut oper convolveconst kernel kernel const dimens dim return tensor output convolut input tensor kernel along specifi dimens input tensor dimens size dimens output tensor part convolut reduc formula output_dim_s input_dim_s kernel_dim_s requir input_dim_s kernel_dim_s dimens size dimens part convolut remain perform convolut depend length stride input tensor dimens along convolut comput first dimens shortest stride colmajor wherea rowmajor shortest stride last dimens comput convolut along second third dimens tensorfloat datalayout input tensorfloat datalayout kernel tensorfloat datalayout output inputsetrandom kernelsetrandom eigenarrayptrdiff_t dim specifi second third dimens convolut output inputconvolvekernel dim int int j j j int k k k int l l l const float result outputijkl const float expect inputijkl kernel inputijkl kernel inputijkl kernel inputijkl kernel verify_is_approxresult expect geometr oper oper return tensor differ dimens origin tensor use access slice tensor see differ dimens pad tensor addit data oper reshapeconst dimens new_dim return view input tensor reshap specifi new dimens argument new_dim array index valu rank result tensor equal number element new_dim product size new dimens array must equal number element input tensor increas rank input tensor introduc new dimens size tensorfloat input arrayint three_dim tensorfloat result inputreshapethree_dim decreas rank input tensor merg dimens arrayint one_dim tensorfloat result inputreshapeone_dim oper move data input tensor result content reshap tensor depend data layout origin tensor exampl happen reshap colmajor tensor one dimens eigentensorfloat eigencolmajor asetvaluesf f f f f f eigenarrayeigendenseindex one_dim eigentensorfloat eigencolmajor b areshapeone_dim cout b endl b endl b happen tensor rowmajor eigentensorfloat eigenrowmajor asetvaluesf f f f f f eigenarrayeigendenseindex one_dim eigentensorfloat eigenrowmajor b areshapeone_dim cout b endl b endl b reshap oper lvalu word use left side assign oper previou exampl rewritten follow eigentensorfloat eigencolmajor asetvaluesf f f f f f eigenarrayeigendenseindex two_dim eigentensorfloat eigencolmajor b breshapetwo_dim cout b endl b endl b note b reshap instead assign done reshap view b oper shuffleconst shuffl shuffl return copi input tensor whose dimens reorder accord specifi permut argument shuffl array index valu size rank input tensor must contain permut rank ith dimens output tensor equal size shuffleith dimens input tensor exampl shuffl dimens left tensorfloat input set valu input tensorfloat output inputshuffl eigen_assertoutputdimens eigen_assertoutputdimens eigen_assertoutputdimens indic output tensor shuffl accordingli formul indic input tensor exampl one assert code snippet eigen_assertoutput input gener one assert eigen_assertoutput indicesshufflei input indicesi shuffl oper result lvalu mean assign word use left side assign oper let rewrit previou exampl take advantag featur shuffl dimens left tensorfloat input set valu input tensorfloat output outputshuffl input oper strideconst stride stride return view input tensor stride skip stride element along dimens argument stride array index valu dimens result tensor ceilinput_dimensionsi stridesi exampl happen stride tensor eigentensorint asetvalu eigenarrayeigendenseindex stride eigentensorint b astridestrid cout b endl b endl b possibl assign tensor stride tensorfloat input set valu input tensorfloat output outputstrid input oper sliceconst startindic offset const size extent return subtensor given tensor dimens slice made coeffici store offseti offseti extentsi input tensor eigentensorint asetvalu eigenarrayint offset eigenarrayint extent eigentensorint slice asliceoffset extent cout endl endl cout slice endl slice endl slice oper chipconst index offset const index dim chip special kind slice subtensor given offset dimens dim return tensor one fewer dimens input tensor dimens dim remov exampl matrix chip would either row column input matrix eigentensorint asetvalu eigentensorint row_ achip eigentensorint col_ achip cout endl endl cout row_ endl row_ endl row_ cout col_ endl col_ endl col_ possibl assign valu tensor chip sinc chip oper lvalu exampl eigentensorint asetvalu eigentensorint b bsetzero bchip cout endl endl cout b endl b endl b oper reverseconst reversedimens revers return view input tensor revers order coeffici along subset dimens argument revers array boolean valu indic whether order coeffici revers along dimens oper preserv dimens input tensor exampl happen revers first dimens tensor eigentensorint asetvalu eigenarraybool reversetru fals eigentensorint b areverserevers cout endl endl b endl b endl b oper broadcastconst broadcast broadcast return view input tensor input replic one mani time broadcast argument specifi mani copi input tensor need made dimens eigentensorint asetvalu eigenarrayint bcast eigentensorint b abroadcastbcast cout endl endl b endl b endl b oper concatenateconst otherderiv axi axi todo oper padconst paddingdimens pad return view input tensor input pad zero eigentensorint asetvalu eigenarraypairint int pad pad make_pair pad make_pair eigentensorint b apadpad cout endl endl b endl b endl b oper extract_patchesconst patchdim patch_dim return tensor coeffici patch extract input tensor patch dimens specifi patch_dim return tensor one greater dimens input tensor use index patch patch index output tensor depend data layout input tensor patch index last dimens colmajor layout first dimens rowmajor layout exampl given follow input tensor eigentensorfloat datalayout tensor tensorsetvaluesf f f f f f f f f f f f cout tensor endl tensor endl tensor six x patch extract index use follow code eigentensorfloat datalayout patch eigenarrayptrdiff_t patch_dim patch_dim patch_dim patch tensorextract_patchespatch_dim int k k k cout patch index k endl int int j j j datalayout colmajor cout patchi j k els cout patchk j cout endl code result follow output data layout colmajor patch index patch index patch index patch index patch index patch index code result follow output data layout rowmajor note set patch colmajor index differ patch index patch index patch index patch index patch index patch index oper extract_image_patchesconst index patch_row const index patch_col const index row_strid const index col_strid const paddingtyp padding_typ return tensor coeffici imag patch extract input tensor expect dimens order follow depend data layout input tensor number addit dimens n colmajor st dimens channel size nd dimens row size r rd dimens column size c thnth dimens time video batch bulk process rowmajor revers order colmajor stnth dimens time video batch bulk process nth dimens column size c nth dimens row size r nth dimens channel size return tensor one greater dimens input tensor use index patch patch index output tensor depend data layout input tensor patch index th dimens colmajor layout th last dimens rowmajor layout exampl given follow input tensor follow dimens size depth row column batch tensorfloat tensor tensorfloat rowmajor tensor_row_major tensorswap_layout x imag patch extract index use follow code patch colmajor patch index secondtolast dimens tensorfloat twod_patch twod_patch tensorextract_image_patch twod_patchdimens twod_patchdimens twod_patchdimens twod_patchdimens twod_patchdimens patch rowmajor patch index second dimens tensorfloat rowmajor twod_patch_row_major twod_patch_row_major tensor_row_majorextract_image_patch twod_patch_row_majordimens twod_patch_row_majordimens twod_patch_row_majordimens twod_patch_row_majordimens twod_patch_row_majordimens special oper oper castt return tensor type dimens origin tensor return tensor contain valu origin tensor convert type eigentensorfloat eigentensorint b acastint use exampl need elementwis divis tensor integ current support tensor librari easili cast tensor float divis eigentensorint asetvalu eigentensorint b acastfloat aconstantcastfloatcastint cout endl endl endl cout b endl b endl endl b oper eval todo represent scalar valu scalar valu often repres tensor size rank would logic user friendli use tensor rank instead exampl tensort nmaximum current return tensort similarli inner product tensor contract return tensor futur oper might updat return tensor instead limit number tensor dimens current limit use compil support cxx limit older compil indexlist class requir cxx compliant compil use array indic instead dont access modern compil gpu float point valu properli test optim complex integ valu known broken gpu tri use youll like end trigger static assert failur eigen_static_assertpackets you_made_a_programming_mistak