changelog notabl chang project document file format base keep changeloghttpskeepachangelogcomen unreleas yyyymmdd ad ad elast keyword paramet rayexecutor api api support staticnonelast elast horovod job resolv issu httpsgithubcomhorovodhorovodissu tensorflow ad inplac broadcast variabl httpsgithubcomhorovodhorovodpul ad support resurrect blacklist host httpsgithubcomhorovodhorovodpul chang move cmake version firstclass cuda languag support reenabl parallel build httpsgithubcomhorovodhorovodpul deprec deprec elasticrayexecutor api favor new rayexecutor api issu httpsgithubcomhorovodhorovodissu remov fix fix exampl pytorch_lightning_mnistpi httpsgithubcomhorovodhorovodpul call _setup remot trainer point correct share lib path httpsgithubcomhorovodhorovodpul v ad ad process set concurr run collect oper subset horovod process tensorflow pytorch mxnet httpsgithubcomhorovodhorovodpul httpsgithubcomhorovodhorovodpul httpsgithubcomhorovodhorovodpul httpsgithubcomhorovodhorovodpul httpsgithubcomhorovodhorovodpul httpsgithubcomhorovodhorovodpul ad xla support allreduc via tffunctionjit_compiletru httpsgithubcomhorovodhorovodpul ad fuse buffer scale unpackpack kernel gpu httpsgithubcomhorovodhorovodpul ad support nccl cuda httpsgithubcomhorovodhorovodissu ad fp compress mxnet httpsgithubcomhorovodhorovodissu ad terminate_on_nan flag spark lightn estim httpsgithubcomhorovodhorovodissu ad barrier api torch modul support simpl synchron among rank achiev pariti pytorch ddp similar framework httpsgithubcomhorovodhorovodpul ad param custom tensorboard callback httpsgithubcomhorovodhorovodissu ad hvdcross_rank kera httpsgithubcomhorovodhorovodissu ad barrier api torch modul support simpl synchron among rank achiev pariti pytorch ddp similar framework httpsgithubcomhorovodhorovodpul chang implement asynchron depend handl gpu httpsgithubcomhorovodhorovodpul ray rayexecutor use current placement group instead alway creat new one httpsgithubcomhorovodhorovodpul lightn turn shuffl valid dataset httpsgithubcomhorovodhorovodpul ray rayexecutor use current placement group one exist httpsgithubcomhorovodhorovodpul extend hvdjoin return last rank join httpsgithubcomhorovodhorovodpul deprec remov sparkkera remov bare kera support httpsgithubcomhorovodhorovodpul fix fix horovod developedit instal mode increment build httpsgithubcomhorovodhorovodpul estimatorlightn use lightn datamodul httpsgithubcomhorovodhorovodpul fix horovod spark stringtyp numpi type map issu httpsgithubcomhorovodhorovodpul fix error kera learningrateschedul httpsgithubcomhorovodhorovodpul fix bug lightn profil ray httpsgithubcomhorovodhorovodpul fix torch op lazi releas prevent oom elast train httpsgithubcomhorovodhorovodpul lightn fix usag checkpoint callback httpsgithubcomhorovodhorovodpul fix mpich support use intel mpi implement httpsgithubcomhorovodhorovodpul fix race condit pytorch async dataload httpsgithubcomhorovodhorovodpul kera fix learn rate schedul httpsgithubcomhorovodhorovodpul httpsgithubcomhorovodhorovodpul v ad estim ad support load data gc adl remot filesystem httpsgithubcomhorovodhorovodissu estim ad custom spark data loader interfac httpsgithubcomhorovodhorovodissu lightningestim ad support suppli logger associ paramet control frequenc log httpsgithubcomhorovodhorovodpul estim ad check ensur rank devic type httpsgithubcomhorovodhorovodpul chang chang behavior use tensorboardlogg use fallback logger suppli httpsgithubcomhorovodhorovodpul ray disabl captur child task placement group httpsgithubcomhorovodhorovodpul fix fix hvdtensorflowkerascompress accident remov v httpsgithubcomhorovodhorovodpul torchestim fix usag validation_step place validation_steps_per_epoch httpsgithubcomhorovodhorovodpul tensorflow fix c api tf v httpsgithubcomhorovodhorovodpul pytorch fix sparse_allreduce_async pytorch v httpsgithubcomhorovodhorovodpul v ad ad pytorch_lightn spark estim enabl train pytorch_lightn model httpsgithubcomhorovodhorovodpul ad nvtx trace hook profil nsight system httpsgithubcomhorovodhorovodpul ad gener num_work api rayexecutor httpsgithubcomhorovodhorovodpul support ray client without code chang httpsgithubcomhorovodhorovodpul support inmemori cach option kera estim httpsgithubcomhorovodhorovodpul ad fp support gpu tensor mxnet httpsgithubcomhorovodhorovodpul ad respons cach allgath oper httpsgithubcomhorovodhorovodpul estim add petastorm reader_pool_typ constructor httpsgithubcomhorovodhorovodpul chang chang alltoal return receiv split second return valu nonuniform split sent httpsgithubcomhorovodhorovodpul chang rayexecutor use ray placement groupshttpsdocsrayioenmasterplacementgrouphtml worker coloc httpsgithubcomhorovodhorovodpul chang inmemori dataload usag torch estim petastorm v releas httpsgithubcomhorovodhorovodpul fix chang rayexecutor use ray node id enabl multicontainersinglehost setup httpsgithubcomhorovodhorovodpul support spars gradient aggreg tf kera httpsgithubcomhorovodhorovodpul respect global_step paramet legacyoptim aggreg gradient httpsgithubcomhorovodhorovodpul fix compat pytorch httpsgithubcomhorovodhorovodpul v ad add group paramet distributedoptim custom allreduc group httpsgithubcomhorovodhorovodpul remov remov num_group paramet distributedoptim replac group httpsgithubcomhorovodhorovodpul fix fix worker desynchron deadlock issu tensorflow httpsgithubcomhorovodhorovodpul dedup kera learningratewarmupcallback log gradual learn rate warmup httpsgithubcomhorovodhorovodpul v ad ad support intelr mpi horovodrun httpsgithubcomhorovodhorovodpul add support callback ray elast executor httpsgithubcomhorovodhorovodpul ad forward stdoutstderr captur driver gloo httpsgithubcomhorovodhorovodpul fix fix broadcast_optimizer_st handl nonetyp param pytorch httpsgithubcomhorovodhorovodpul fix local_rank support ray httpsgithubcomhorovodhorovodpul fix dl estim obtain output df schema without sampl input httpsgithubcomhorovodhorovodpul fix wrong default horovodtensorflowkerasallreduc averag httpsgithubcomhorovodhorovodpul v ad ad inmemori dataset cach param torchestim httpsgithubcomhorovodhorovodpul ad val_batch_s param estim api httpsgithubcomhorovodhorovodpul ad support torchscript modul use torchestim httpsgithubcomhorovodhorovodpul chang migrat oneccl align oneapi specif v httpsgithubcomhorovodhorovodpul ad knob set cach hint oneccl allreduc httpsgithubcomhorovodhorovodpul renam horovodrun arg cclbgtaffin threadaffin httpsgithubcomhorovodhorovodpul chang default build parallel j j address potenti race condit httpsgithubcomhorovodhorovodpul fix fix build horovod rocm pytorch newer hipifi script httpsgithubcomhorovodhorovodpul fix execut class support ray httpsgithubcomhorovodhorovodpul fix torchestim return model without switch eval mode httpsgithubcomhorovodhorovodpul remov ssh relianc ray elast train httpsgithubcomhorovodhorovodpul fix error handl chang framework without reinstal horovod httpsgithubcomhorovodhorovodpul fix intermedi path exist error dbfslocalstor httpsgithubcomhorovodhorovodpul avoid synchron worker shrink elast mode httpsgithubcomhorovodhorovodpul fix ray resourc test httpsgithubcomhorovodhorovodpul fix usag env variabl horovod_gloo_timeout_second horovodrun httpsgithubcomhorovodhorovodpul v ad ad support backward_passes_per_step tf kera graph mode httpsgithubcomhorovodhorovodpul ad support backward_passes_per_step tf kera eager execut httpsgithubcomhorovodhorovodpul ad support backward_passes_per_step tf legacyoptim graph mode httpsgithubcomhorovodhorovodpul ad group allreduc enabl effici tensor fusion determinist train httpsgithubcomhorovodhorovodpul add support specifi op compress horovodtensorflowkerasallreduc httpsgithubcomhorovodhorovodpul ad support batch dd memcopi kernel gpu httpsgithubcomhorovodhorovodpul ad schema infer spark estim without sampl httpsgithubcomhorovodhorovodpul ad storecreatedbf map dbfslocalstoredbf httpsgithubcomhorovodhorovodpul chang chang kera callback requir paramet initial_lr learningrateschedulecallback learningratewarmupcallback httpsgithubcomhorovodhorovodpul chang default cycl time ms ms fusion threshold mb mb httpsgithubcomhorovodhorovodpul fix fix support tensorflow v httpsgithubcomhorovodhorovodpul fix averag use cuda half implement one element half buffer httpsgithubcomhorovodhorovodpul fix horovod_thread_affin use oneccl httpsgithubcomhorovodhorovodpul ad timeout ssh check horovodrun prevent hang httpsgithubcomhorovodhorovodpul ad horovod_gloo_timeout_second valu error messag httpsgithubcomhorovodhorovodpul fix race condit dynam timelin api httpsgithubcomhorovodhorovodpul fix loghidetimestamp appli driver log gloo httpsgithubcomhorovodhorovodpul fix search order eigen flatbuff path httpsgithubcomhorovodhorovodpul fix type check torchestim correctli use isinst httpsgithubcomhorovodhorovodpul ad ad elast ray integr httpsgithubcomhorovodhorovodpul chang remov depend ssh access ray httpsgithubcomhorovodhorovodpul fix fix build horovod without horovod_without_mxnet mxnet instal httpsgithubcomhorovodhorovodpul ad ad databrick storag dbfslocalstor support gpuawar schedul horovodspark estim httpsgithubcomhorovodhorovodpul ad elasticsampl pytorch elast imagenet exampl httpsgithubcomhorovodhorovodpul ad abil dynam start stop timelin programmat httpsgithubcomhorovodhorovodpul ad support gloo maco httpsgithubcomhorovodhorovodpul expos name argument tensorflow allreduc oper httpsgithubcomhorovodhorovodpul ad option strip outer name scope horovod op tensorflow httpsgithubcomhorovodhorovodpul fix fix usag verbos set custom makeflag httpsgithubcomhorovodhorovodpul fix bug kera elast callback class httpsgithubcomhorovodhorovodpul fix relwithdebinfo build made default optim httpsgithubcomhorovodhorovodpul fix usag tfcond tensorflow alltoal gradient httpsgithubcomhorovodhorovodpul fix allreduc averag tf indexedslic rocm path httpsgithubcomhorovodhorovodpul includ stdexcept handl certain compil framework dont includ alreadi httpsgithubcomhorovodhorovodpul fix debug build set compil option base cmake build type httpsgithubcomhorovodhorovodpul skip launch zeros sendrecv ncclalltoal httpsgithubcomhorovodhorovodpul fix miss run tf kera elast mode httpsgithubcomhorovodhorovodpul fix loss function tensorflow elast synthet benchmark httpsgithubcomhorovodhorovodpul fix usag horovod_mixed_instal env var alltoal test httpsgithubcomhorovodhorovodpul remov kera requir ray exampl httpsgithubcomhorovodhorovodpul ad ad baremet elast mode implement enabl autosc fault toler httpsgithubcomhorovodhorovodpul ad elast horovod support spark autosc httpsgithubcomhorovodhorovodpul ad alltoal oper tensorflow pytorch mxnet httpsgithubcomhorovodhorovodpul ad support gradient_predivide_factor averag horovod backend httpsgithubcomhorovodhorovodpul ad nccl implement allgath oper httpsgithubcomhorovodhorovodpul ad horovod_gpu_oper instal variabl simplifi enabl nccl support gpu oper httpsgithubcomhorovodhorovodpul ad tensorflow implement syncbatchnorm layer httpsgithubcomhorovodhorovodpul ad hvdis_initi method httpsgithubcomhorovodhorovodpul ad hvdallgather_object function tensorflow pytorch mxnet httpsgithubcomhorovodhorovodpul ad hvdbroadcast_object function mxnet httpsgithubcomhorovodhorovodpul ad label_shap paramet kerasestim torchestim httpsgithubcomhorovodhorovodpul ad option modelcheckpoint callback kerasestim param httpsgithubcomhorovodhorovodpul ad ssh_identity_fil argument horovodrun httpsgithubcomhorovodhorovodpul ad support horovodrun kubeflowmpijob httpsgithubcomhorovodhorovodpul ad ray integr httpsgithubcomhorovodhorovodpul chang move horovodrunrunnerrun horovodrun httpsgithubcomhorovodhorovodpul horovod_thread_affin accept multipl valu one everi horovod rank httpsgithubcomhorovodhorovodpul migrat build system nativ librari cmake httpsgithubcomhorovodhorovodpul deprec horovod_ccl_bgt_affin deprect use horovod_thread_affin instead httpsgithubcomhorovodhorovodpul remov drop support python httpsgithubcomhorovodhorovodpul drop support tensorflow httpsgithubcomhorovodhorovodpul drop support pytorch httpsgithubcomhorovodhorovodpul fix fix mxnet allgath implement correctli handl resiz output buffer httpsgithubcomhorovodhorovodpul fix kera spark estim incompat tensorflow due tfautograph httpsgithubcomhorovodhorovodpul fix api compat pytorch httpsgithubcomhorovodhorovodpul fix kera api compat tensorflow httpsgithubcomhorovodhorovodpul fix allgath gradient tensorflow case tensor shape known graph construct httpsgithubcomhorovodhorovodpul fix run use gloo imbalanc number worker per host httpsgithubcomhorovodhorovodpul govern horovod project horovod graduat project within lf ai data foundationhttpslfaidatafound charter find horovod charter herehttpswikilfaifoundationdownloadattachmentshorovodprojecttechnicalcharterfinalpdfversionmodificationdateapiv technic steer committe horovod develop govern horovod technic steer committe tsc tsc consist vote nonvot member addit chairman respons run tsc meet set meet agenda call vote propos current chairman horovod tsc travi addairhttpsgithubcomtgaddair predibas current vote member horovod tsc alex sergeevhttpsgithubcomalsrgv carbon robot travi addairhttpsgithubcomtgaddair predibas karakushttpsgithubcomkarakusc amazon josh romerohttpsgithubcomromerojosh nvidia nicola castethttpsgithubcomnvcastet nvidia enrico minackhttpsgithubcomenricomi gresearch xu ninghttpsgithubcomthuningxu uber todd mytkowiczhttpsgithubcomklipto microsoft current nonvot member horovod tsc leonard lausenhttpsgithubcomleezu amazon jonathan dekhtiarhttpsgithubcomdekhtiarjonathan nvidia richard liawhttpsgithubcomrichardliaw anyscal neil conwayhttpsgithubcomneilconway determin ai hpe min caihttpsgithubcommincai uber chongxiao caohttpsgithubcomchongxiaoc uber max gerlachhttpsgithubcommaxhgerlach deepl ryan beethehttpsgithubcomrbdeterminedai determin ai hpe abin shahabhttpsgithubcomashahab linkedin tj xuhttpsgithubcomtixxx uber emeritu member horovod tsc lin yuanhttpsgithubcomapeforest haibin linhttpsgithubcomerichaibinlin yuxi huhttpsgithubcomyuxihu emad barsoumhttpsgithubcomebarsoum aaron harlaphttpsgithubcomaaronh jaliya ekanayakehttpsgithubcomjaliya kaarthik sivashanmugamhttpsgithubcomskaarthik armand mcqueenhttpsgithubcomarmandmcqueen nonvot member tsc maintain commit access horovod github repositori take part stand tsc meet mail list emeritu member longer activ maintain project welcom particip tsc meet horovod tsc meet monthli publish meet note via mail listhttpslistslfaifoundationghorovodtsc mail list also util reach tsc major decis regard technic direct horovod project brought tsc discuss accompani propos document term rfc request comment technic decis made tsc unanim vote nonvot member either agre propos abstain pass consensu reach propos put vote among vote member tsc point major vote tsc must agre propos pass decis add chang member tsc either vote nonvot capac handl propos without rfc attempt made reach unanim decis among entir tsc follow vote among vote member consensu reach secur polici report vulner pleas report secur vulner horovodsecuritylistslfaidatafound anyon post mail list howev activ maintain horovod project abl read messag code conduct horovod project host lf ai foundat would like urg pleas mind adher linux foundat code conducthttpslfprojectsorgpoliciescodeofconduct contribut horovod question concern pleas email infolfaifound thank contribut horovod thank take time contribut refer follow guidelin contribut new function bug fix horovod use autopephttpsgithubcomhhattoautopep format python code use clangformathttpsclangllvmorgdocsclangformathtml format c code add unit test new code write run unit test cpu gpu environ code conduct pleas mind adher linux foundat code conducthttpslfprojectsorgpoliciescodeofconduct contribut horovod checklist submit read contributor guidehttpsgithubcomhorovodhorovodblobmastercontributingmd updat doc write test valid chang updat changeloghttpsgithubcomhorovodhorovodblobmasterchangelogmd chang affect user descript fix issu review process land test check must succeed least one member technic steer committeehttpsgithubcomhorovodhorovodblobmastercontributingmd must review approv member technic steer committe request chang must address name bug report question use horovod get work environ use httpsgithubcomhorovodhorovoddiscuss titl label bug assigne environ framework tensorflow kera pytorch mxnet framework version horovod version mpi version cuda version nccl version python version spark pyspark version ray version os version gcc version cmake version checklist search issu find somebodi ask question question hang read dochttpsgithubcomhorovodhorovodblobmasterdocsrunningrst question docker read dochttpsgithubcomhorovodhorovodblobmasterdocsdockerrst check question answer troubleshoot guidehttpsgithubcomhorovodhorovodblobmasterdocstroubleshootingrst bug report pleas describ erron behavior your observ step reproduc name featur request suggest idea project titl label enhanc assigne featur request relat problem pleas describ clear concis descript problem ex im alway frustrat describ solut youd like clear concis descript want happen describ altern youv consid clear concis descript altern solut featur youv consid addit context add context screenshot featur request horovod docker imag often instal horovod bare metal difficult environ setup correctli cuda mpi g cmake etc docker imag provid simplifi onboard process new user serv start point build runtim environ repositori separ imag provid differ horovod configur publish separ repo dockerhub horovodhorovod horovod built cuda support packag latest stabl tensorflow pytorch mxnet spark releas horovodhorovodcpu horovod built cpu train packag latest stabl tensorflow pytorch mxnet spark releas horovodhorovodray horoovd built cuda support latest rayprojectraynightlygpuhttpsgithubcomrayprojectray packag latest stabl tensorflow pytorch releas imag tag master built horovod master branch nightli nightli build horovod shacommit point version horovod design git sha charact commit point build custom imag build argument provid allow user build horovod custom version variou framework includ tensorflow_vers version tensorflow pip packag instal pytorch_vers version torch pip packag instal pytorch_lightning_vers version pytorch_lightn pip packag instal torchvision_vers version torchvis pip packag instal mxnet_vers version mxnet pip packag instal cudnn_vers version libcudnn apt packag instal horovod imag nccl_version version libnccl apt packag instal horovod imag cuda_docker_vers tag nvidiacuda imag build horovod imag ray_docker_vers tag rayprojectray gpu imag build horovodray imag build docker imag run root horovod directori exampl export docker_buildkit docker build buildarg tensorflow_vers buildarg pytorch_versioncu f dockerhorovoddockerfil run contain see horovod dockerdocsdockerrst document guidanc run docker imag horovod raydocsrayrst usag ray raw html p aligncenterimg srchttpsuserimagesgithubusercontentcomdccefeeedfpng altlogo widthp br horovod raw html div aligncent imag httpsbadgefuryiopyhorovodsvg target httpsbadgefuryiopyhorovod alt pypi version imag httpsbadgebuildkitecomfbccdfcdebdebbaeesvgbranchmast target httpsbuildkitecomhorovodhorovod alt build statu imag httpsreadthedocsorgprojectshorovodbadgeversionlatest target httpshorovodreadthedocsioenlatest alt document statu imag httpsimgshieldsiobadgeslackchatgreensvglogoslack target httpsformsglecpgvtyhptgfg alt slack raw html div raw html div aligncent imag httpsimgshieldsiobadgelicenseapachebluesvg target httpsimgshieldsiobadgelicenseapachebluesvg alt licens imag httpsappfossacomapiprojectsgitbgithubcomfhorovodfhorovodsvgtypeshield target httpsappfossacomprojectsgitbgithubcomfhorovodfhorovodrefbadge_shield alt fossa statu imag httpsbestpracticescoreinfrastructureorgprojectsbadg target httpsbestpracticescoreinfrastructureorgproject alt cii best practic imag httpspepytechbadgehorovod target httpspepytechprojecthorovod alt download raw html div inclusionmarkerstartdonotremov horovod distribut deep learn train framework tensorflow kera pytorch apach mxnet goal horovod make distribut deep learn fast easi use raw html pimg srchttpsrawgithubusercontentcomlfaiartworkmasterlfaidataassetslfaidataprojectbadgegraduatecolorlfaidataprojectbadgegraduatecolorpng altlf ai data widthp horovod host lf ai data foundat httpslfdlio_ lf ai data compani deepli commit use open sourc technolog artifici intellig machin deep learn want support commun open sourc project domain consid join lf ai data foundat detail who involv horovod play role read linux foundat announc httpslfdliopresslfdeeplearningwelcomeshorovoddistributedtrainingframeworkasnewestproject_ content document latest releas httpshorovodreadthedocsioenstable_ master httpshorovodreadthedocsioenlatest_ horovod primari motiv project make easi take singlegpu train script success scale train across mani gpu parallel two aspect much modif one make program make distribut easi run much faster would run distribut mode intern uber found mpi model much straightforward requir far less code chang previou solut distribut tensorflow paramet server train script written scale horovod run singlegpu multiplegpu even multipl host without code chang see usag usage__ section detail addit easi use horovod fast chart repres benchmark done server pascal gpu connect rocecap gbit network imag httpsuserimagesgithubusercontentcombfccaeabcepng alt gpu benchmark horovod achiev scale effici incept v resnet scale effici vgg see benchmark docsbenchmarksrst_ find reproduc number instal mpi nccl may seem like extra hassl need done team deal infrastructur everyon els compani build model enjoy simplic train scale instal instal horovod linux maco instal cmake httpscmakeorginstall__ raw html p youv instal tensorflow pypi httpspypiorgprojecttensorflow__ make sure g instal youv instal pytorch pypi httpspypiorgprojecttorch__ make sure g instal youv instal either packag conda httpscondaio_ make sure gxx_linux conda packag instal raw html p instal horovod pip packag run cpu codeblock bash pip instal horovod run gpu nccl codeblock bash horovod_gpu_operationsnccl pip instal horovod detail instal horovod gpu support read horovod gpu docsgpusrst_ full list horovod instal option read instal guid docsinstallrst_ want use mpi read horovod mpi docsmpirst_ want use conda read build conda environ gpu support horovod docscondarst_ want use docker read horovod docker docsdockerrst_ compil horovod sourc follow instruct contributor guid docscontributorsrst_ concept horovod core principl base mpi httpmpiforumorg_ concept size rank local rank allreduc allgath broadcast alltoal see page docsconceptsrst_ detail support framework see page horovod exampl best practic horovod tensorflow docstensorflowrst_ horovod xla tensorflow xlarst_ horovod kera docskerasrst_ horovod pytorch docspytorchrst_ horovod mxnet docsmxnetrst_ usag use horovod make follow addit program run hvdinit initi horovod raw html p pin gpu singl process avoid resourc content typic setup one gpu per process set local rank first process server alloc first gpu second process alloc second gpu forth raw html p scale learn rate number worker effect batch size synchron distribut train scale number worker increas learn rate compens increas batch size raw html p wrap optim hvddistributedoptim distribut optim deleg gradient comput origin optim averag gradient use allreduc allgath appli averag gradient raw html p broadcast initi variabl state rank process necessari ensur consist initi worker train start random weight restor checkpoint raw html p modifi code save checkpoint worker prevent worker corrupt raw html p exampl use tensorflow v see exampl httpsgithubcomhorovodhorovodblobmasterexamples_ directori full train exampl codeblock python import tensorflow tf import horovodtensorflow hvd initi horovod hvdinit pin gpu use process local rank one gpu per process config tfconfigproto configgpu_optionsvisible_device_list strhvdlocal_rank build model loss opt tftrainadagradoptim hvdsize add horovod distribut optim opt hvddistributedoptimizeropt add hook broadcast variabl rank process initi hook hvdbroadcastglobalvariableshook make train oper train_op optminimizeloss save checkpoint worker prevent worker corrupt checkpoint_dir tmptrain_log hvdrank els none monitoredtrainingsess take care session initi restor checkpoint save checkpoint close done error occur tftrainmonitoredtrainingsessioncheckpoint_dircheckpoint_dir configconfig hookshook mon_sess mon_sessshould_stop perform synchron train mon_sessruntrain_op run horovod exampl command show run distribut train see run horovod docsrunningrst_ detail includ roceinfiniband tweak tip deal hang run machin gpu codeblock bash horovodrun np h localhost python trainpi run machin gpu codeblock bash horovodrun np h serverserverserverserv python trainpi run use open mpi without horovodrun wrapper see run horovod open mpi docsmpirst_ run docker see horovod docker docsdockerrst_ run kubernet see kubeflow mpi oper httpsgithubcomkubeflowmpioperator_ helm chart httpsgithubcomkuberneteschartstreemasterstablehorovod_ ffdl httpsgithubcomibmffdltreemasteretcexampleshorovod_ polyaxon httpsdocspolyaxoncomintegrationshorovod_ run spark see horovod spark docssparkrst_ run ray see horovod ray docsrayrst_ run singular see singular httpsgithubcomsylabsexamplestreemastermachinelearninghorovod_ run lsf hpc cluster eg summit see lsf docslsfrst_ run hadoop yarn see toni httpsgithubcomlinkedintony_ gloo gloo httpsgithubcomfacebookincubatorgloo_ open sourc collect commun librari develop facebook gloo come includ horovod allow user run horovod without requir mpi instal environ support mpi gloo choos use gloo runtim pass gloo argument horovodrun codeblock bash horovodrun gloo np python trainpi mpipi horovod support mix match horovod collect mpi librari mpipi httpsmpipyscipyorg_ provid mpi built multithread support check mpi multithread support queri hvdmpi_threads_support function codeblock python import horovodtensorflow hvd initi horovod hvdinit verifi mpi multithread support assert hvdmpi_threads_support mpipi import mpi assert hvdsize mpicomm_worldget_s also initi horovod mpipi subcommun case subcommun run independ horovod train codeblock python mpipi import mpi import horovodtensorflow hvd split comm_world subcommun subcomm mpicomm_worldsplitcolormpicomm_worldrank keympicomm_worldrank initi horovod hvdinitcommsubcomm printcomm_world rank horovod rank mpicomm_worldrank hvdrank infer learn optim model infer remov horovod oper graph docsinferencerst_ tensor fusion one uniqu thing horovod abil interleav commun comput coupl abil batch small allreduc oper result improv perform call batch featur tensor fusion see docstensorfusionrst__ full detail tweak instruct horovod timelin horovod abil record timelin activ call horovod timelin imag httpsuserimagesgithubusercontentcomedaaceaedaacpng alt horovod timelin use horovod timelin analyz horovod perform see docstimelinerst__ full detail usag instruct autom perform tune select right valu effici make use tensor fusion advanc horovod featur involv good amount trial error provid system autom perform optim process call autotun enabl singl command line argument horovodrun see docsautotunerst__ full detail usag instruct horovod process set horovod allow concurr run distinct collect oper differ group process take part one distribut train set hvdprocess_set object make use capabl see process set docsprocess_setrst__ detail instruct guid run distribut train microsoft azur use batch ai horovod httpsgithubcomazurebatchaitreemasterrecipeshorovod_ distribut model train use horovod httpsspellmlblogdistributedmodeltrainingusinghorovodxvqegruaacgaath_ send us link user guid want publish site troubleshoot see troubleshoot docstroubleshootingrst_ submit ticket httpsgithubcomhorovodhorovodissuesnew_ cant find answer citat pleas cite horovod public help research articlesergeevhorovod author alexand sergeev mike del balso journal arxiv preprint arxiv titl horovod fast easi distribut deep learn tensorflow year public sergeev del balso meet horovod uber open sourc distribut deep learn framework tensorflow retriev httpsengubercomhorovod httpsengubercomhorovod_ sergeev horovod distribut tensorflow made easi retriev httpswwwslidesharenetalexandersergeevhorovoddistributedtensorflowmadeeasi httpswwwslidesharenetalexandersergeevhorovoddistributedtensorflowmadeeasy_ sergeev del balso horovod fast easi distribut deep learn tensorflow retriev arxiv httpsarxivorgabs_ refer horovod sourc code base baidu tensorflowallreduc httpsgithubcombaiduresearchtensorflowallreduce_ repositori written andrew gibianski joel hest origin work describ articl bring hpc techniqu deep learn httpandrewgibianskycomblogmachinelearningbaiduallreduce_ get involv commun slack httpsformsglecpgvtyhptgfg_ collabor discuss horovod announc httpslistslfaifoundationghorovodannounce_ updat project horovod technicaldiscuss httpslistslfaifoundationghorovodtechnicaldiscuss_ public discuss horovod secur httpslistslfaifoundationghorovodsecurity_ report secur vulner inclusionmarkerenddonotremov place content also appear readthedoc content alreadi part readthedoc tabl content inclusionmarkerstartdonotremov concept horovod core principl base mpi httpmpiforumorg_ concept size rank local rank allreduc allgath broadcast alltoal best explain exampl say launch train script server gpu launch one copi script per gpu size would number process case rank would uniqu process id size local rank would uniqu process id within server allreduc oper aggreg data among multipl process distribut result back allreduc use averag dens tensor here illustr mpi tutori httpmpitutorialcomtutorialsmpireduceandallreduce__ imag httpmpitutorialcomtutorialsmpireduceandallreducempi_allreduce_png alt allreduc illustr allgath oper gather data process everi process allgath use collect valu spars tensor here illustr mpi tutori httpmpitutorialcomtutorialsmpiscattergatherandallgather__ imag httpmpitutorialcomtutorialsmpiscattergatherandallgatherallgatherpng alt allgath illustr broadcast oper broadcast data one process identifi root rank onto everi process here illustr mpi tutori httpmpitutorialcomtutorialsmpibroadcastandcollectivecommunication__ imag httpmpitutorialcomtutorialsmpibroadcastandcollectivecommunicationbroadcast_patternpng alt broadcast illustr alltoal oper exchang data process alltoal may use implement neural network advanc architectur span multipl devic inclusionmarkerenddonotremov includ hyperparameter_searchrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ mpirst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ installrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov autotun autom perform tune horovod come sever adjust knob affect runtim perform includ fusionthresholdmb cycletimem tensor fusion cachecapac respons cach hierarch collect algorithm hierarchicalallreduc hierarchicalallgath determin best combin valu maxim perform minim time converg matter trialanderror mani factor includ model complex network bandwidth gpu memori etc affect input per second throughput train horovod provid mechan autom process select best valu knob call autotun horovod autotun system use bayesian optim httpsenwikipediaorgwikibayesian_optimization_ intellig search space paramet combin train featur enabl set autotun flag horovodrun codeblock bash horovodrun np autotun python trainpi autotun enabl horovod spend first step epoch train experi differ paramet valu collect metric perform measur byte allreduc allgath per unit time experi reach converg set number sampl collect system record best combin paramet discov continu use durat train log paramet combin explor best valu select record provid autotunelogfil option horovodrun codeblock bash horovodrun np autotun autotunelogfil tmpautotune_logcsv python trainpi log best paramet file opt set best paramet discov command line instead rerun autotun train paus later resum note configur paramet like tensor compress includ part autotun process affect model converg purpos autotun time entir improv scale effici without make tradeoff model perform constant paramet sometim may wish hold certain valu constant tune unspecifi paramet accomplish explicitli set valu command line config file provid configfil codeblock bash horovodrun np autotun cachecapac nohierarchicalallgath python trainpi exampl paramet cachecapac hierarchicalallgath adjust autotun advanc autotun enabl autotun impos tradeoff degrad perform earli phase train exchang better perform later gener recommend use autotun situat train expect take long time mani epoch larg dataset scale effici found lack use default set tune autotun system chang number warmup sampl discard sampl begin step per sampl maximum sampl codeblock bash horovodrun np autotun autotunewarmupsampl autotunestepspersampl autotunebayesoptmaxsampl python trainpi increas valu gener improv accuraci autotun process cost greater time spent autotun process degrad perform final familiar underli theori bayesian optim gaussian process tune nois regular term alpha account varianc network system resourc codeblock bash horovodrun np autotun autotunegaussianprocessnois python trainpi inclusionmarkerenddonotremov horovod mxnet horovod support apach mxnet regular tensorflow similar way see full train mnist httpsgithubcomhorovodhorovodblobmasterexamplesmxnetmxnet_mnistpy__ imagenet httpsgithubcomhorovodhorovodblobmasterexamplesmxnetmxnet_imagenet_resnetpy__ exampl script provid simpl skeleton code block base apach mxnet gluon api codeblock python import mxnet mx import horovodmxnet hvd mxnet import autograd initi horovod hvdinit pin gpu use process local rank context mxgpuhvdlocal_rank num_work hvdsize build model model modelhybrid creat optim optimizer_param opt mxoptimizercreatesgd optimizer_param initi paramet modelinitializeiniti ctxcontext fetch broadcast paramet param modelcollect_param param none hvdbroadcast_parametersparam root_rank creat distributedtrain subclass gluontrain trainer hvddistributedtrainerparam opt creat loss function loss_fn train model epoch rangenum_epoch train_datareset nbatch batch enumeratetrain_data start data batchdataas_in_contextcontext label batchlabelas_in_contextcontext autogradrecord output modeldataastypedtyp copyfals loss loss_fnoutput label lossbackward trainerstepbatch_s note mxnet version work horovod mxnet earlier gcc incompat issu httpsgithubcomhorovodhorovodissues__ use mxnet later horovod later avoid incompat mxnet post miss mkldnn header work horovod use post post post respect mxnet post post avail mxnetcu mxnetcu includ tensorfusionrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov distribut hyperparamet search horovod data parallel train capabl allow scale speed workload train deep learn model howev simpli use x worker necessarili mean model obtain accuraci x less time address often need retun hyperparamet train scale mani hyperparamet exhibit differ behavior larger scale horovod offer ray tune_ integr enabl parallel hyperparamet tune distribut train imag mediatunepng align center scale ray tune_ industri standard tool distribut hyperparamet tune ray tune_ includ latest hyperparamet search algorithm integr tensorboard analysi librari nativ support distribut train ray tune_ horovod integr leverag underli ray framework provid scalabl comprehens hyperparamet tune setup end guid learn set ray tune_ horovod tune hyperparamet typic hyperparamet configur distribut train horovod ray tune leverag ray tune_ horovod combin distribut hyperparamet tune distribut train exampl demonstr basic usag codeblock python import horovodtorch hvd ray import tune import time def training_functionconfig dict hvdinit rangeconfigepoch timesleep model modellearning_rateconfiglr tunereporttest rankhvdrank trainabl distributedtrainablecr training_funct num_slot use_gpuuse_gpu analysi tunerun trainabl num_sampl config epoch tunegrid_search lr tunegrid_search printanalysisbest_config basic setup use ray tune distributedtrainablecreator_ function adapt horovod train function compat ray tune distributedtrainablecreator_ expos num_host num_slot use_gpu num_cpus_per_slot use paramet specifi resourc alloc singl trial trainabl distribut train job codeblock python train job use gpu trainabl distributedtrainablecr training_funct num_slot use_gputru train function must three thing must adher tune function api signatur httpsdocsrayioenlatesttuneapi_docstrainablehtmlfunctionapi__ bodi must includ horovodinit call must call tunereport doc httpsdocsrayioenlatesttuneapi_docstrainablehtmltunereporttunecheckpointfunctionapi__ train typic call iter end everi epoch optim hyperparamet ray tune_ abl orchestr complex comput pattern ray actor api httpsdocsrayioenlatestactorshtml__ hyperparamet tune ray tune_ abl conduct parallel bayesian optim httpsdocsrayioenlatesttuneapi_docssuggestionhtml__ popul base train httpsdocsrayioenlatesttuneapi_docsschedulershtml__ group distribut model may need implement model checkpoint rest optim process configur coupl line code codeblock python ray import tune raytunesuggestbayesopt import bayesoptsearch raytunesuggest import concurrencylimit def training_functionconfig algo bayesoptsearch algo concurrencylimiteralgo max_concurr result tunerun training_funct configlr tuneuniform namehorovod metricmean_loss modemin search_algalgo printresultsbest_config search space tune nativ interfac specifi search space httpsdocsrayioenmastertuneapi_docssearch_spacehtmltunesearchspace__ specifi search space via tunerunconfig therebi either use tunegrid_search primit specifi axi grid search codeblock python tunerun trainabl configbar tunegrid_searchtru fals one random sampl primit specifi distribut codeblock python tunerun trainabl config param tunechoicetru fals bar tuneuniform alpha tunesample_fromlambda _ nprandomuniform const hello also ok specifi constant valu read tune search space api httpsdocsrayioenmastertuneapi_docssearch_spacehtmltunesearchspace__ analyz result tunerun return analysi httpsdocsrayioenmastertuneapi_docsanalysishtml__ object method analyz train codeblock python analysi tuneruntrain search_algalgo stoptraining_iter best_trial analysisbest_tri get best trial best_config analysisbest_config get best trial hyperparamet best_logdir analysisbest_logdir get best trial logdir best_checkpoint analysisbest_checkpoint get best trial best checkpoint best_result analysisbest_result get best trial last result best_result_df analysisbest_result_df get best result panda datafram set tune cluster leverag ray tune_ horovod laptop singl machin multipl gpu across multipl machin run singl machin execut python script asi exampl horovod_simplepi httpsdocsrayioenlatesttuneexampleshorovod_simplehtml__ assum ray horovod instal properli codeblock bash python horovod_simplepi leverag distribut hyperparamet tune setup ray tune_ horovod instal ray set ray cluster httpsdocsrayioenlatestclusterindexhtml__ start ray cluster ray cluster launcher httpsdocsrayioenlatestclusterlauncherhtml__ manual well use ray cluster launcher httpsdocsrayioenlatestclusterlauncherhtml__ start ray list node cluster manag cloud provid first specifi configur file exampl use aw ec launch cluster cloud provid codeblock yaml ray_clusteryaml cluster_nam horovodclust provid type aw region uswest auth ssh_user ubuntu min_work max_work deep learn ami ubuntu version head_nod instancetyp pxlarg imageid amibfdea worker_nod instancetyp pxlarg imageid amibfdea setup_command set node horovod_with_gloo horovod_gpu_operationsnccl pip instal horovodray run ray ray_clusteryaml cluster node head node worker node automat start ray codeblock bash start ray runtim find activ ray process share connect close local node ip info servicespi view ray dashboard httplocalhost ray runtim start next step connect ray runtim anoth node run ray start address redispassword altern use follow python code import ray rayinitaddressauto _redis_password connect fail check firewal set network configur termin ray runtim run ray stop share connect close new statu uptod use command monitor autosc ray exec devcfgscheckautoscaleryaml tail n f tmpraysession_latestlogsmonitor connect termin cluster head ray attach devcfgscheckautoscaleryaml get remot shell cluster manual ssh identitiesonlyy sshrayautoscaler__uswestpem ubuntu cluster ssh head node run tune script implement underneath hood underneath hood ray tune_ launch multipl trial httpsdocsrayioenlatesttunekeyconceptshtmltunerunandtrials__ parallel trial refer set ray actor httpsdocsrayioenlatestactorshtml__ trial coordin actor coordin actor manag n train actor one basic assumpt implement subwork trial place evenli across differ machin imag mediatunehorovodjpg train actor hold copi model creat commun group horovod allreduc train execut actor report intermedi metric back tune api requir gloo underli commun primit sure instal horovod horovod_with_gloo enabl httpshorovodreadthedocsioenstableinstall_includehtmlgloo__ common hyperparamet cover coupl common hyperparamet may need retun scale batch size learn rate schedul optim paramet batch size use data parallel necessari scale batch size along worker avoid reduc perwork workload maxim worker effici howev increas batch size easili caus gener issu see facebook imagenet train paper httpsresearchfbcomwpcontentuploadsimagenetkinhpdf__ detail common solut linear scale learn rate minibatch size multipli k multipli learn rate k dynam adjust batch size cours train one origin paper present simpl baselin increas batch size time absa provid way httpsopenreviewnetpdfidhlnjrqt__ leverag second order inform guid batch size time gradient nois scale httpsopenaicomblogscienceofai__ calcul guid increas batch size time leverag dynam chang batch size train either leverag gradient accumul httpsgistgithubcomthomwolfacadabceeacacbbdd__ implement trialschedul dynam chang number worker come soon paramet learn rate schedul warmup note facebook imagenet train paper httpsresearchfbcomwpcontentuploadsimagenetkinhpdf__ linear scale rule break network rapidli chang commonli occur earli stage train issu address warmup strategi use less aggress learn rate start train common solut goyal et al propos warmup schedul train usual start small learn rate gradual increas match larger target learn rate warmup period usual epoch regular learn rate schedul use multistep polynomi decay etc thu gener three paramet warmup schedul length warmup number epoch start learn rate peak learn rate paramet optim optim algorithmsmethod use updat network weight iter common optim deep learn includ adam rmsprop sgd momentum larg scale learn naiv approach optim updat neural network weight lead poor gener decreas perform exampl alexnet imagenet use standard sgd momentum warmup scheme stop scale bk common solut lar httpsarxivorgpdfpdf__ calcul local learn rate per layer optim step normal gradient magnitud layer instead use userset coeffici magnitud layer weight comput learn rate origin paper lar present perform improv train alexnet larg batch size lamb httpstowardsdatasciencecomanintuitiveunderstandingofthelamboptimizerfcae__ stand layerwis adapt moment optim batch train make small chang lar spirit combin adam optim layerwis scale lar origin motiv lamb work lar work well attentionbas architectur bert _ray tune httpsdocsrayioenlatesttun _distributedtrainablecr httpsdocsrayioenlatesttuneapi_docsintegrationhtmlhorovodtuneintegrationhorovod inclusionmarkerenddonotremov includ lsfrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov contributor guid guid cover process contribut horovod develop environ setup clone repositori local codeblock bash git clone recurs httpsgithubcomhorovodhorovodgit develop within virtual environ avoid depend issu codeblock bash python venv env envbinactiv recommend instal packag version match test buildkit httpsgithubcomhorovodhorovodblobmasterbuildkitegenpipelinesh__ follow version recommend see default version defin codearg dockerfiletestcpu httpsgithubcomhorovodhorovodblobmasterdockerfiletestcpu__ dockerfiletestgpu httpsgithubcomhorovodhorovodblobmasterdockerfiletestgpu__ file find nonpython packag need instal system horovod build dockerfiletestcpu httpsgithubcomhorovodhorovodblobmasterdockerfiletestcpu__ dockerfiletestgpu httpsgithubcomhorovodhorovodblobmasterdockerfiletestgpu__ file specif see coderun aptget instal line build instal insid horovod root directori instal horovod developedit mode codeblock bash horovod_with_pytorch horovod_with_tensorflow pip instal v e set horovod_without_framework disabl build horovod plugin framework use your test featur one framework particular wish save time set horovod_with_framework gener error horovod plugin framework fail build set horovod_debug debug build check assert disabl compil optim etc environment variabl found instal document httpsgithubcomhorovodhorovodblobmasterdocsinstallrstenvironmentvariables__ instal option depend defin setuppi httpsgithubcomhorovodhorovodblobmastersetuppy__ ad bracket end command line eg test test depend instal specif dl framework yet add dev instal cpu version support dl framework develop mode edit horovod sourc directli repo folder python code chang take effect immedi ccuda code pip instal v e command need invok perform increment build test horovod unit test framework testparallel invok via horovodrun mpirun test script may requir run independ test script codeblock bash cd testparallel horovodrun np pytest v test_tensorflowpi horovodrun np pytest v test_torchpi run framework test cd testparallel ls test_pi xarg n horovodrun np pytest v moreov integr test nonparallel test run directli via pytest codeblock bash cd testintegr pytest v cd testsingl pytest v note need pyspark java run spark test import test contain gpuonli codepath skip run without gpu support case fewer four gpu instal continu integr horovod use buildkit httpsbuildkitecomhorovodhorovod__ continu integr aw run intel cpu hardwar nvidia gpu nccl test run per night master automat commit remot branch buildkit test configur defin dockercomposetestyml httpsgithubcomhorovodhorovodblobmasterdockercomposetestyml__ test configur defin docker imag built either dockertestcpu httpsgithubcomhorovodhorovodblobmasterdockerfiletestcpu__ cpu test dockertestgpu httpsgithubcomhorovodhorovodblobmasterdockerfiletestgpu__ gpu test individu test run configur defin genpipelinesh httpsgithubcomhorovodhorovodblobmasterbuildkitegenpipelinesh__ everi test configur need also defin order run test time time run_test call new test artifact gener buildkit either succe fail depend exit code aw configur gpu test run gpu per contain test run worker process howev model parallel requir gpu per worker requir gpu total document horovod document publish httpshorovodreadthedocsio html page render rst file locat doc directori need set sphinx compil document first time codeblock bash cd doc pip instal r requirementstxt make clean build html page open docs_buildhtmlindexhtml codeblock bash cd doc make html open _buildhtmlindexhtml sphinx render document mani format type make get list avail format ad custom oper oper horovod use transform tensor across worker horovod current support oper implement broadcast allreduc allgath interfac gradient horovod aggreg allreduc oper except spars gradient use allgath data transfer oper implement horovodcommonop httpsgithubcomhorovodhorovodtreemasterhorovodcommonops__ directori implement organ collect commun librari use perform oper eg mpi_operationscc httpsgithubcomhorovodhorovodblobmasterhorovodcommonopsmpi_operationscc__ mpi creat new custom oper start defin new class inherit base oper file correspond librari youll use implement oper codeblock c class customallreduc public allreduceop public customallreducempicontext mpi_context horovodglobalst global_st virtual customallreduc default statu executestdvectortensortableentri entri const respons respons overrid bool enabledconst parametermanag parameter_manag const stdvectortensortableentri entri const respons respons const overrid execut member function respons perform oper list tensor entri paramet provid access tensor buffer metadata need process respons paramet contain addit metadata includ devic use differ rank enabl return true oper perform given tensor entri subject current paramet set respons metadata youv written implement oper add operationmanag createoperationmanag function operationscc httpsgithubcomhorovodhorovodblobmasterhorovodcommonoperationscc__ one oper may enabl time one perform given vector tensor entri consid order oper operationmanag vector ad first oper vector check end first oper enabl perform broadli order oper custom oper trigger base paramet configur runtim eg ncclhierarchicalallreduc acceler oper take advantag special hardwar avail eg ncclallreduc default oper run use standard cpu host memori eg mpiallreduc custom oper requir precondit runtim flag fall first categori ad compress algorithm gradient compress use reduc amount data sent network allreduc oper compress algorithm implement per framework tensorflow pytorch mxnet etc horovodframeworkcompressionpi see tensorflow httpsgithubcomhorovodhorovodblobmasterhorovodtensorflowcompressionpy__ pytorch httpsgithubcomhorovodhorovodblobmasterhorovodtorchcompressionpy__ implement new compress algorithm first add new class inherit compressor codeblock python class customcompressorcompressor staticmethod def compresstensor someth return tensor_compress ctx staticmethod def decompresstensor ctx someth return tensor_decompress compress method take tensor gradient return compress form along addit context necessari decompress tensor back origin form similarli decompress take compress tensor context return decompress tensor compress done pure python c use custom op eg mpi_opscc httpsgithubcomhorovodhorovodblobmasterhorovodtensorflowmpi_opscc__ tensorflow implement add compressor subclass compressor class emul enumer api codeblock python class compressionobject custom customcompressor final start use new compressor pass distributedoptim codeblock python opt hvddistributedoptimizeropt compressionhvdcompressioncustom horovod spark horovodspark packag make easi run horovod job spark cluster follow section outlin horovod orchestr spark mpi horovod job becom spark driver creat num_proc task spark cluster horovodspark_make_spark_thread task run horovodspark_task_fn regist driver driver know task ip port run also send host hash string treat mpi hostnam note horovod expect task run time cluster provid least num_proc core horovod job multipl core per executor executor process multipl task host also multipl executor driver signal task task run task continu initialis wait rpc termin signal task driver run mpi_run launch python function task rpc usual mpi connect host via ssh would allow launch python function insid spark executor therefor mpi connect executor invok horovodsparkdrivermpirun_rsh method remot shell executor method commun task smallest index per host hash task execut ort command provid mpi way singl ort process run per executor even executor multipl core task mpi use ort launch python function executor one python function run per core executor insid first task task host hash wait first task termin follow diagram illustr process imag _staticsparkmpipng elast horovod spark elast horovod spark constraint host singl slot simplifi autosc spark host hash includ index task disallow share memori across task run host see host hash host hash host hash repres singl unit process power share memori usual regular host scenario yarn use alloc core spark job memori alloc share within executor multipl executor run horovod job host limit memori alloc henc executor get host hash requir python function run task process within spark executor index task becom part host hash well shown use elast horovod spark simplif releas process section appli contributor permiss releas new version horovod public version bump make pr chang __version__ horovod__init__pi exampl httpsgithubcomhorovodhorovodpull_ tag codeblock bash git tag v horovodrun config file bugfix git push origin v creat releas follow github instruct creat releas httpsdocsgithubcomengithubadministeringarepositoryreleasingprojectsongithubmanagingreleasesinarepositorycreatingarelease_ releas creat trigger workflow upload horovod sourc distribut pypi httpspypiorg_ automat use twine httpspypiorgprojecttwine_ workflow complet verifi latest version horovod avail codeblock bash pip instal upgrad horovod inclusionmarkerenddonotremov horovod tensorflow use horovod tensorflow make follow modif train script run hvdinit raw html p pin gpu singl process typic setup one gpu per process set local rank first process server alloc first gpu second process alloc second gpu forth tensorflow v codeblock python config tfconfigproto configgpu_optionsvisible_device_list strhvdlocal_rank tensorflow v codeblock python gpu tfconfigexperimentallist_physical_devicesgpu gpu gpu tfconfigexperimentalset_memory_growthgpu true gpu tfconfigexperimentalset_visible_devicesgpushvdlocal_rank gpu raw html p scale learn rate number worker effect batch size synchron distribut train scale number worker increas learn rate compens increas batch size raw html p wrap optim hvddistributedoptim distribut optim deleg gradient comput origin optim averag gradient use allreduc allgath appli averag gradient tensorflow v use tfgradienttap wrap tape hvddistributedgradienttap instead wrap optim raw html p broadcast initi variabl state rank process necessari ensur consist initi worker train start random weight restor checkpoint tensorflow v add hvdbroadcastglobalvariableshook use monitoredtrainingsess use monitoredtrainingsess execut hvdbroadcast_global_vari op global variabl initi tensorflow v use hvdbroadcast_vari model optim initi raw html p modifi code save checkpoint worker prevent worker corrupt tensorflow v accomplish pass checkpoint_dirnon tftrainmonitoredtrainingsess hvdrank tensorflow v construct tftraincheckpoint call checkpointsav hvdrank raw html p tensorflow v exampl see exampl httpsgithubcomhorovodhorovodblobmasterexamples_ directori full train exampl codeblock python import tensorflow tf import horovodtensorflow hvd initi horovod hvdinit pin gpu use process local rank one gpu per process config tfconfigproto configgpu_optionsvisible_device_list strhvdlocal_rank build model loss opt tftrainadagradoptim hvdsize add horovod distribut optim opt hvddistributedoptimizeropt add hook broadcast variabl rank process initi hook hvdbroadcastglobalvariableshook make train oper train_op optminimizeloss save checkpoint worker prevent worker corrupt checkpoint_dir tmptrain_log hvdrank els none monitoredtrainingsess take care session initi restor checkpoint save checkpoint close done error occur tftrainmonitoredtrainingsessioncheckpoint_dircheckpoint_dir configconfig hookshook mon_sess mon_sessshould_stop perform synchron train mon_sessruntrain_op tensorflow v exampl mnist httpsgithubcomhorovodhorovodblobmasterexamplestensorflowtensorflow_mnistpy_ exampl codeblock python import tensorflow tf import horovodtensorflow hvd initi horovod hvdinit pin gpu use process local rank one gpu per process gpu tfconfigexperimentallist_physical_devicesgpu gpu gpu tfconfigexperimentalset_memory_growthgpu true gpu tfconfigexperimentalset_visible_devicesgpushvdlocal_rank gpu build model dataset dataset model loss tflossessparsecategoricalcrossentropi opt tfoptimizersadam hvdsize checkpoint_dir checkpoint checkpoint tftraincheckpointmodelmodel optimizeropt tffunction def training_stepimag label first_batch tfgradienttap tape prob mnist_modelimag trainingtru loss_valu losslabel prob horovod add horovod distribut gradienttap tape hvddistributedgradienttapetap grad tapegradientloss_valu mnist_modeltrainable_vari optapply_gradientszipgrad mnist_modeltrainable_vari horovod broadcast initi variabl state rank process necessari ensur consist initi worker train start random weight restor checkpoint note broadcast done first gradient step ensur optim initi first_batch hvdbroadcast_variablesmnist_modelvari root_rank hvdbroadcast_variablesoptvari root_rank return loss_valu horovod adjust number step base number gpu batch imag label enumeratedatasettak hvdsize loss_valu training_stepimag label batch batch hvdlocal_rank printstep dtloss f batch loss_valu horovod save checkpoint worker prevent worker corrupt hvdrank checkpointsavecheckpoint_dir includ rayrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ onecclrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov adasum horovod adapt summat adasum novel algorithm improv distribut data parallel train deep learn model improv seen differ way reduc number step achiev accuraci case allow scale train worker without penal learn rate converg stabil adasum use horovod pytorchtensorflow content introduct adasum algorithm scale dnn train mani gpu alway come converg degrad larger batch size gradient averag learn rate per exampl smaller address learn rate usual scale lead diverg model paramet adasum address two issu without introduc hyperparamet suppos two almostparallel gradient two differ gpu g g need reduc shown figur two common practic reduct gg gray vector gg green vector gg may caus diverg model sinc effect move direct g g two time magnitud g g therefor gener gg safer desir note gg penal compon g g equal imag mediaabcdfaebpng consid two orthogon gradient g g figur sinc g g two differ dimens independ gg may caus diverg imag mediacffdbdcaccaaaepng final consid third scenario g g neither parallel orthogon shown figur case take sum might caus diverg adasum control effect overal gradient updat subtract half gs project gpink vector g subtract half gs project g orang vector g sum two compon togeth imag mediaafabafbddaaccpng imag mediadbccdcfeadefaadecpng formula reduc sum g g orthogon averag g g parallel idea extend mani gradient well suppos n gradient come n differ gpu adasum induct take pair gradient reduc use method reduc one gradient thu adasum need number node power current implement distribut optim adasum adasum use distribut adasum optim updat weight model step usual dataparallel train scenario gradient calcul independ backpropag node reduc averag gradient node gradient updat weight model distribut optim adasum first obtain local gradient backpropag step current local mini batch instead perform reduc point appli optim function local gradient perform weight updat delta differ weight updat obtain reduc instead gradient worker delta weight updat step perform sum initi weight delta sinc natur adasum requir oper full magnitud gradient newli ad distribut optim use differ magnitud weight optim perform step deliv accur estim instal usag instruct adasum use experi horovod pytorchtensorflow addit two option use adasum horovod messag pass interfac mpi nccl httpsdevelopernvidiacomnccl_ valid implement mpi use adasum test openmpi httpswwwopenmpiorg_ intelmpi httpssoftwareintelcomenusmpilibrary_ set environ requir run horovod adasum cuda openmpi nccl pytorch tensorflow horovod use nccl horovod_gpu_operationsnccl flag use compil horovod nccl use instead case nccl use intranod commun adasum use internod commun mode oper adasum use follow way depend hardwar setup avail pure cpu deal hardwar setup multipl node node worker gpu connect high speed interconnect like nvlink httpswwwnvidiacomenusdatacenternvlink_ commun happen cpu adasum mpi use intranod internod commun case adasum op perform cpu hardwar setup allow differ mode like ring hierarch use must use instead get highest perform benefit imag mediacbabfcedcpng ring specif configur machin dgx httpswwwnvidiacomenusdatacenterdgx_ node gpu ring mode use instead pure cpu mode mode ident pure cpu mode internod commun abl intranod commun without go cpu util cudaawar mpi openmpi built ucx httpswwwopenucxorg_ support order allow direct gpu gpu commun within node result ident converg benefit pure cpu mode much better throughput node support ring mode current support dgx node gpu imag mediaaafaeecacaceaaecpng hierarch case hardwar support ring mode throughput higher pure cpu mode desir hierarch mode use instead hierarch mode function similar ring mode except use nccl regular averag intranod instead use cudaawar mpi adasumlik ring note hierarch also work hardwar configur limit dgx practic hierarch yield best throughput lower converg benefit adasum due op regular averag rule thumb typic converg benefit degrad insignific cluster larg number node case enough internod adasum op perform ideal hierarch scenario reason use hierarch even smaller cluster ring mode support cpu mode throughput simpli low viabl note case converg benefit compar use adasum might minor learn rate use equal best learn rate singl worker gpu scale number gpu local node larg cluster scale even anoth factor x might give better result guarante tri scale local size suffici good converg imag mediaaddecaeadfpng modif code new distribut optim ad tensorflow pytorch support adasum algorithm option paramet op ad distributedoptim allreduc api user specifi oper perform ophvdadasum specifi new optim use adasum highli effect scale larg batch size backward_passes_per_step paramet distributedoptim use gradient accumul order scale larger effect batch size without limit gpu memori tensorflow distributedoptim codeblock python opt tftrainadamoptim opt hvddistributedoptimizeropt backward_passes_per_step ophvdadasum allreduc codeblock python hvdallreducetensor ophvdadasum pytorch distributedoptim codeblock python optim optimsgdmodelparamet lrargslr momentumargsmomentum optim hvddistributedoptimizeroptim named_parametersmodelnamed_paramet compressioncompress backward_passes_per_step ophvdadasum allreduc codeblock python hvdallreducetensor ophvdadasum case studi squar cubic optim simpl case studi understand adasum behavior order understand behavior potenti benefit adasum compar averag consid simpl experi squar optim use adasum goal estim coeffici polynomi degre featur gener randomli sampl uniform distribut scale factor x_max specifi set complex data use estim coeffici addit learn rate op use allreduc specifi well true label calcul origin true coeffici without ad nois order estim coeffici stochast gradient descent use train stop gradient zero two consecut run optim run rang learn rate number worker data rang set x_max also modifi cubic optim problem experi run jupyt notebook adasum_benchipynb examplesadasumadasum_benchipynb_ model defin adasum_small_modelpi examplesadasumadasum_small_modelpy_ run experi differ number worker draw follow conclus simpl scenario plain sgd optim number step converg problem adasum achiev accuraci case lower number step compar averag depend complex problem reduct anywher less complex squar paramet optim scale learn rate higher number worker tradit averag number worker increas local batch size increas global batch size caus higher smooth effect gradient increas speed converg recommend learn rate scale number worker recommend paper accur larg minibatch sgd train imagenet hour httpsarxivorgabs_ exampl see adasum lr need scale linearli number worker better scale factor would use lr decay adasum see form regular effect alreadi take place gradient train progress magnitud gradient reduc simul effect decay learn rate although decay might necessari train complex model result must kept mind extent decay might necessari mnist higher accuraci number step test applic observ simpl cubic optim problem train mnist adasum scale best learn rate singl worker case use adasum higher number node see consist get better accuraci number step compar averag key takeaway adasum ensur correct converg behavior even larg effect batch size number rank scale learn rate need scale linearli use cpu adasum reduct good scale factor would best learn rate singl worker horovod_gpu_operationsnccl flag use compil horovod learn rate use equal best learn rate singl worker gpu scale number gpu local node larg cluster scale even anoth factor x might give better result guarante tri scale local size suffici good converg pytorch train fp format yet support integr apex new optim enabl full mix precis train adasum pytorch work progress horovod_gpu_operationsnccl flag use compil horovod train run singl node averag nccl librari use perform reduct adasum algorithm take place configur inclusionmarkerenddonotremov includ inferencerst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ runningrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ gpusrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ timelinerst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ conceptsrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov benchmark imag httpsuserimagesgithubusercontentcombfccaeabcepng alt gpu benchmark benchmark done server pascal gpu connect rocecap gbit network horovod achiev scale effici incept v resnet scale effici vgg reproduc benchmark instal horovod use instruct provid horovod gpu httpsgithubcomhorovodhorovodblobmasterdocsgpusrst__ page clone httpsgithubcomtensorflowbenchmark httpsgithubcomtensorflowbenchmarks__ codeblock bash git clone httpsgithubcomtensorflowbenchmark cd benchmark run benchmark exampl open mpi codeblock bash horovodrun np h serverserverserverserv python scriptstf_cnn_benchmarkstf_cnn_benchmarkspi model resnet batch_siz variable_upd horovod end run see number imag process per second codeblock bash total imagessec real data benchmark benchmark instruct synthet data benchmark run benchmark real data need download imagenet dataset httpimagenetorgdownloadimages__ convert use tfrecord preprocess script httpsgithubcomtensorflowmodelsblobmasterresearchslimdatasetsdownload_and_convert_imagenetsh__ simpli add data_dir pathtoimagenettfrecord data_nam imagenet num_batch train command codeblock bash horovodrun np h serverserverserverserv python scriptstf_cnn_benchmarkstf_cnn_benchmarkspi model resnet batch_siz variable_upd horovod data_dir pathtoimagenettfrecord data_nam imagenet num_batch horovod synthet benchmark horovod also come outofthebox benchmark support tensorflow v httpsgithubcomhorovodhorovodblobmasterexamplestensorflowtensorflow_synthetic_benchmarkpy__ tensorflow v httpsgithubcomhorovodhorovodblobmasterexamplestensorflowtensorflow_synthetic_benchmarkpy__ pytorch httpsgithubcomhorovodhorovodblobmasterexamplespytorchpytorch_synthetic_benchmarkpy__ benchmark allow measur horovod perform scalabl environ well tri advanc horovod featur like gradient compress codeblock bash horovodrun np h serverserv python fpallreduc tensorflow_synthetic_benchmarkpi diagnos perform issu recommend run synthet benchmark first ensur issu origin train script inclusionmarkerenddonotremov horovod pytorch use horovod pytorch make follow modif train script run hvdinit raw html p pin gpu singl process typic setup one gpu per process set local rank first process server alloc first gpu second process alloc second gpu forth codeblock python torchcudais_avail torchcudaset_devicehvdlocal_rank raw html p scale learn rate number worker effect batch size synchron distribut train scale number worker increas learn rate compens increas batch size raw html p wrap optim hvddistributedoptim distribut optim deleg gradient comput origin optim averag gradient use allreduc allgath appli averag gradient raw html p broadcast initi variabl state rank process codeblock python hvdbroadcast_parametersmodelstate_dict root_rank hvdbroadcast_optimizer_stateoptim root_rank necessari ensur consist initi worker train start random weight restor checkpoint raw html p modifi code save checkpoint worker prevent worker corrupt accomplish guard model checkpoint code hvdrank raw html p exampl also see full train exampl httpsgithubcomhorovodhorovodblobmasterexamplespytorchpytorch_mnistpy__ codeblock python import torch import horovodtorch hvd initi horovod hvdinit pin gpu use process local rank one gpu per process torchcudaset_devicehvdlocal_rank defin dataset train_dataset partit dataset among worker use distributedsampl train_sampl torchutilsdatadistributeddistributedsampl train_dataset num_replicashvds rankhvdrank train_load torchutilsdatadataloadertrain_dataset batch_siz samplertrain_sampl build model model modelcuda optim optimsgdmodelparamet add horovod distribut optim optim hvddistributedoptimizeroptim named_parametersmodelnamed_paramet broadcast paramet rank process hvdbroadcast_parametersmodelstate_dict root_rank epoch rang batch_idx data target enumeratetrain_load optimizerzero_grad output modeldata loss fnll_lossoutput target lossbackward optimizerstep batch_idx argslog_interv printtrain epoch tloss format epoch batch_idx lendata lentrain_sampl lossitem note pytorch gpu support requir nccl later also work nccl use roce infiniband pytorch lightn horovod support distribut backend pytorch lightn httpsgithubcompytorchlightningpytorchlightning_ v pytorch lightn distribut train use horovod requir singl line code chang exist train script codeblock python train horovod gpu number gpu machin provid commandlin trainer pltraineracceleratorhorovod gpu train horovod cpu number process machin provid commandlin trainer pltraineracceleratorhorovod may need chang paramet acceler name distributed_backend older version pytorch_lightn start train job specifi number worker command line normal would use horovod codeblock bash run train gpu singl machin horovodrun np python trainpi run train gpu two machin gpu horovodrun np h hostnamehostnam python trainpi find exampl use pytorch lightn trainer horovod backend pytorch_lightning_mnistpi examplespytorchpytorch_lightning_mnistpy__ see pytorch lightn doc httpspytorchlightningreadthedocsioenstablemulti_gpuhtmlhorovod_ detail pytorchlightn base spark estim also ad exampl pytorch_lightning_spark_mnistpi examplessparkpytorchpytorch_lightning_spark_mnistpy__ includ process_setrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov infer infer infer may done outsid python script use train model refer horovod librari run infer checkpoint gener horovoden train script optim graph keep oper necessari forward pass model optim infer httpsgithubcomtensorflowtensorflowblobmastertensorflowpythontoolsoptimize_for_inferencepy__ script tensorflow repositori want convert checkpoint frozen graph httpsgithubcomtensorflowtensorflowblobmastertensorflowpythontoolsfreeze_graphpy__ optim describ otherwis freez graph httpsgithubcomtensorflowtensorflowblobmastertensorflowpythontoolsfreeze_graphpy__ script fail load horovod op codeblock bash valueerror op name horovodallreduc defin oper inclusionmarkerenddonotremov inclusionmarkerstartdonotremov horovod intelr oneccl use horovod intelr oneapi collect commun librari oneccl follow step instal oneccl httpsgithubcominteloneccl_ instal oneccl follow step httpsgithubcomintelonecclblobmasterreadmemd_ sourc setvarssh start use oneccl codeblock bash sourc install_direnvsetvarssh set horovod_cpu_oper variabl codeblock bash export horovod_cpu_operationsccl instal horovod sourc code codeblock bash python setuppi build python setuppi instal via pip codeblock bash pip instal horovod advanc set affin specifi affin horovod background thread horovod_thread_affin environ variabl see instruct set horovod background thread affin accord rule n horovod process per node variabl contain valu everi local process use comma separ codeblock bash export horovod_thread_affinitycccn ccn core id pin background thread local process set number oneccl worker codeblock bash export ccl_worker_countx x number oneccl worker thread worker per process youd like dedic drive commun set oneccl worker affin automat codeblock bash export ccl_worker_affinityauto default mode exact core id depend process launcher use set oneccl worker affin explicitli codeblock bash export ccl_worker_affinitycccx cccx core id dedic local oneccl worker ie x ccl_worker_count number process per node pleas refer execut commun oper httpsoneapisrcgithubiooneccloperation_executionhtml_ inform exampl node node socket socket cpu socket cpu dedic last two core socket oneccl worker pin horovod background thread one hyperthread core oneccl workerss core core exclud intel mpi pin use i_mpi_pin_processor_exclude_list dedic oneccl horovod task thu avoid conflict framework comput thread codeblock bash export ccl_worker_count export ccl_worker_affin export horovod_thread_affin export i_mpi_pin_domainsocket export i_mpi_pin_processor_exclude_list mpirun n ppn hostfil host python run_examplepi cach set cach hint oneccl oper codeblock bash export horovod_ccl_cach avail allreduc yet disabl default pleas refer cach commun oper httpsoneapisrcgithubiooneccloperation_cachinghtml_ inform inclusionmarkerenddonotremov horovod xla tensorflow basic usag xla horovod op enabl set horovod_enable_xla_op control registr op tensorflowxla two main way enabl xla could work horovod differ way explicit compil tffunctionjit_compiletru codeblock python osenvironhorovod_enable_xla_op tffunctionjit_compiletru def compiled_hvd_allreduceself dtype dim tensor selfrandom_uniform dim dtypedtyp sum hvdallreducetensor averagefals return sum way op compiled_hvd_allreduc function lower xla per compil requir xla horovod op enabl xla report compil error autoclust autoclust conveni way use xla simpli set tf_xla_flagstf_xla_auto_jit xla jit automat select op tensorflow graph lower xla mode enabl xla horovod op option autoclust work even horovod op left run tensorflow devic part graph lower onto xla devic list support xla horovod op support op list horovodallreduc inclusionmarkerstartdonotremov horovod gpu use horovod gpu read option see one appli best gpu situat use nccl significantli improv perform cpu version nccl provid allreduc oper optim nvidia gpu varieti network devic roce infiniband instal nccl httpsdevelopernvidiacomnccl__ follow step httpdocsnvidiacomdeeplearningsdkncclinstallguideindexhtml__ instal nccl use ncclversiontxz packag add librari path ld_library_path environ variabl regist etcldsoconf codeblock bash export ld_library_pathld_library_pathusrlocalncclversionlib option your use nvidia tesla gpu nic gpudirect rdma support speed nccl instal nv_peer_memori httpsgithubcommellanoxnv_peer_memory__ driver gpudirect httpsdevelopernvidiacomgpudirect__ allow gpu transfer memori among without cpu involv significantli reduc latenc load cpu nccl abl use gpudirect automat allreduc oper detect instal open mpi httpswwwopenmpiorg__ anoth mpi implement follow step httpswwwopenmpiorgfaqcategorybuildingeasybuild__ note open mpi issu may caus hang recommend fix downgrad open mpi upgrad open mpi instal tensorflow pypi httpspypiorgprojecttensorflow__ make sure g instal instal pytorch pypi httpspypiorgprojecttorch__ make sure g instal instal either packag conda httpscondaio_ make sure gxx_linux conda packag instal instal horovod pip packag instal nccl use ncclversiontxz packag specifi path nccl use horovod_nccl_hom environ variabl codeblock bash horovod_nccl_homeusrlocalncclvers horovod_gpu_operationsnccl pip instal nocachedir horovod instal nccl use ubuntu packag run codeblock bash horovod_gpu_operationsnccl pip instal nocachedir horovod instal nccl use cento rhel packag httpsdocsnvidiacomdeeplearningsdkncclinstallguideindexhtmlrhel_centos__ run codeblock bash horovod_nccl_includeusrinclud horovod_nccl_libusrlib horovod_gpu_operationsnccl pip instal nocachedir horovod note model high comput commun ratio benefit allreduc cpu even gpu version avail forc allreduc happen cpu pass device_densecpu hvddistributedoptim codeblock python opt hvddistributedoptimizeropt device_densecpu advanc proprietari mpi implement gpu support optim network section relev proprietari mpi implement gpu support ie open mpi mpich user follow one section mpi vendor implement allreduc oper gpu faster nccl configur horovod use instead codeblock bash horovod_gpu_allreducempi pip instal nocachedir horovod addit mpi vendor implement support allgath broadcast oper gpu configur horovod use well codeblock bash horovod_gpu_operationsmpi pip instal nocachedir horovod note allgath alloc output tensor proportion number process particip train find run gpu memori forc allgath happen cpu pass device_sparsecpu hvddistributedoptim codeblock python opt hvddistributedoptimizeropt device_sparsecpu inclusionmarkerenddonotremov inclusionmarkerstartdonotremov troubleshoot import tensorflow fail instal tensorflow instal see error messag mean tensorflow instal pleas instal tensorflow instal horovod codeblock bash error import tensorflow fail instal traceback recent call last file tmppipofe_yxbuildsetuppi line fully_define_extens import tensorflow tf importerror modul name tensorflow cuda librari avail see error messag mean tensorflow load your instal horovod contain machin without gpu may use cuda stub driver work around issu codeblock bash error import tensorflow fail instal traceback recent call last file tmppipacqbuildsetuppi line fully_define_extens import tensorflow tf file usrlocallibpythondistpackagestensorflow__init__pi line modul tensorflowpython import file usrlocallibpythondistpackagestensorflowpython__init__pi line modul tensorflowpython import pywrap_tensorflow file usrlocallibpythondistpackagestensorflowpythonpywrap_tensorflowpi line modul rais importerrormsg importerror traceback recent call last file usrlocallibpythondistpackagestensorflowpythonpywrap_tensorflowpi line modul tensorflowpythonpywrap_tensorflow_intern import file usrlocallibpythondistpackagestensorflowpythonpywrap_tensorflow_internalpi line modul _pywrap_tensorflow_intern swig_import_help file usrlocallibpythondistpackagestensorflowpythonpywrap_tensorflow_internalpi line swig_import_help _mod impload_module_pywrap_tensorflow_intern fp pathnam descript importerror libcudaso open share object file file directori use cuda stub driver codeblock bash temporari add stub driver ldsocach ldconfig usrlocalcudalibstub instal horovod add horovod_ environ variabl necessari horovod_gpu_operationsnccl horovod_nccl_homepathtonccl pip instal nocachedir horovod revert standard librari ldconfig mpi found instal mpi path see error messag mean mpicxx found path typic mpicxx locat directori mpirun add directori contain mpicxx path instal horovod codeblock bash error mpicxx show fail mpicxx path traceback recent call last file tmppipdqaabuildsetuppi line get_mpi_flag mpicxx show universal_newlinestruestrip file usrlibpythonsubprocesspi line check_output process popenstdoutpip popenarg kwarg file usrlibpythonsubprocesspi line __init__ errread errwrit file usrlibpythonsubprocesspi line _execute_child rais child_except oserror errno file directori use custom mpi directori codeblock bash export pathpathpathtompibin horovod_gpu_operationsnccl horovod_nccl_homepathtonccl pip instal nocachedir horovod mpi librari ad ld_library_path ldsoconf see error messag mean mpicxx abl load mpi librari recent instal mpi make sure path mpi librari present ld_library_path environ variabl etcldsoconf file codeblock bash mpicxx error load share librari libopenpalso open share object file file directori error mpicxx show fail see error mpi path traceback recent call last file tmppipbuildwrtvwhhorovodsetuppi line get_mpi_flag shlexsplitshow_command universal_newlinestruestrip file usrlibpythonsubprocesspi line check_output rais calledprocesserrorretcod cmd outputoutput calledprocesserror command mpicxx show return nonzero exit statu instal mpi user directori add mpi librari directori ld_library_path codeblock bash export ld_library_pathld_library_pathpathtompilib instal mpi nonstandard system locat ie usr usrloc add etcldsoconf file codeblock bash echo pathtompilib sudo tee etcldsoconf addit instal mpi system locat run sudo ldconfig instal regist librari cach codeblock bash sudo ldconfig error instal invalid convers const void void fpermiss see error messag mean mpi like outdat recommend instal open mpi httpswwwopenmpiorgfaqcategorybuildingeasybuild__ note prior instal new version open mpi dont forget remov exist mpi instal codeblock bash horovodtensorflowmpi_opscc function void horovodtensorflowanonymousperformoperationhorovodtensorflowanonymoustensort horovodtensorflowmpirespons horovodtensorflowmpi_opscc error invalid convers const void void fpermiss recvcount displcmnt dtype mpi_comm_world file includ horovodtensorflowmpi_opscc usranacondaincludempih error initi argument int mpi_allgathervvoid int mpi_datatyp void int int mpi_datatyp mpi_comm fpermiss int mpi_allgathervvoid int mpi_datatyp void int int mpi_datatyp mpi_comm horovodtensorflowmpi_opscc error invalid convers const void void fpermiss mpi_comm_world error instal fatal error pyconfigh file directori see error messag mean need instal python header codeblock bash buildhorovodtorchmpi_lib_mpi_libc fatal error pyconfigh file directori includ pyconfigh compil termin instal pythondev pythondev packag exampl debian ubuntu system codeblock bash sudo aptget instal pythondev nccl found instal see error messag mean nccl found standard librari locat directori instal nccl includ lib directori contain ncclh libncclso respect pass via horovod_nccl_hom environ variabl otherwis specifi separ via horovod_nccl_includ horovod_nccl_lib environ variabl codeblock bash buildtemplinuxx_test_compiletest_ncclcc fatal error ncclh file directori includ ncclh compil termin error nccl librari later version found see error pleas specifi correct nccl locat via horovod_nccl_hom environ variabl combin horovod_nccl_includ horovod_nccl_lib environ variabl horovod_nccl_hom path nccl includ lib directori found horovod_nccl_includ path nccl includ directori horovod_nccl_lib path nccl lib directori exampl codeblock bash horovod_gpu_operationsnccl horovod_nccl_homepathtonccl pip instal nocachedir horovod codeblock bash horovod_gpu_operationsnccl horovod_nccl_includepathtoncclinclud horovod_nccl_libpathtonccllib pip instal nocachedir horovod pip instal option nocachedir see error messag mean version pip date remov nocachedir flag sinc version pip cach nocachedir flag ad exampl ensur chang horovod compil flag rebuilt sourc reinstal pip cach modern pip default behavior httpspippypaioenstablereferencepip_installcaching__ codeblock bash pip instal nocachedir horovod usag pip instal option requir specifi pip instal option r requir file pip instal option e vc project url pip instal option e local project path pip instal option archiv urlpath option nocachedir exampl codeblock bash horovod_gpu_operationsnccl horovod_nccl_homepathtonccl pip instal nocachedir horovod ncclallreduc fail invalid data type see error messag train mean horovod link wrong version nccl librari codeblock bash unknownerror see traceback ncclallreduc fail invalid data type node distributedmomentumoptimizer_allreducehorovodallreduce_gradients_addn__ horovodallreducetdt_float _devicejoblocalhostreplicataskdevicegpugradientsaddn_ node train_op_ _recvclient_terminatedfals recv_devicejoblocalhostreplicataskdevicecpu send_devicejoblocalhostreplicataskdevicegpu send_device_incarn tensor_nameedge__train_op tensor_typedt_float _devicejoblocalhostreplicataskdevicecpu your use anaconda miniconda like nccl packag instal solut remov packag reinstal horovod codeblock bash conda remov nccl pip uninstal horovod horovod_gpu_operationsnccl horovod_nccl_homepathtonccl pip instal nocachedir horovod transportppcu warn fail open cuda ipc handl unknown error see error messag train x nccl_debuginfo like mean multipl server share hostnam codeblock bash node transportppcu warn fail open cuda ipc handl unknown error mpi nccl reli hostnam distinguish server make sure everi server uniqu hostnam run memori notic program run gpu memori multipl process place gpu like program depend creat tfsession use config pin specif gpu possibl track part program use addit tfsession pass configur altern place follow snippet begin program ask tensorflow minim amount memori prealloc gpu codeblock python small_cfg tfconfigproto small_cfggpu_optionsallow_growth true tfsessionconfigsmall_cfg pass last resort replac set configgpu_optionsvisible_device_list differ code codeblock python pin gpu use import os osenvironcuda_visible_devic strhvdlocal_rank note set cuda_visible_devic incompat configgpu_optionsvisible_device_list set cuda_visible_devic addit disadvantag gpu version cuda abl use ipc like caus nccl mpi fail order disabl ipc nccl mpi allow fallback share memori use export nccl_pp_disabl nccl mca btl_smcuda_use_cuda_ipc flag openmpi similar flag vendor libcudartsoxi open share object file file directori notic program crash libcudartsoxi open share object file file directori error like framework horovod build differ version cuda build horovod specif cuda version use horovod_cuda_hom environ variabl instal codeblock bash pip uninstal horovod horovod_gpu_operationsnccl horovod_nccl_homepathtonccl horovod_cuda_homepathtocuda pip instal nocachedir horovod forcetermin data unpack would read past end buffer see error messag train like wrong version hwloc instal system codeblock bash intern error occur ort forcetermin data unpack would read past end buffer error grpcomm_directc someth report develop futurestanfordedu orte_error_log data unpack would read past end buffer file grpcomm_directc line purg hwloc system codeblock bash apt purg hwlocnox libhwlocdev libhwlocplugin libhwloc hwloc purg reinstal open mpi httpswwwopenmpiorgfaqcategorybuildingeasybuild__ see issu httpsgithubcomopenmpiompiissues__ detail segment fault tensorflow higher mention hwloc use tensorflow get segment fault check whether mention hwloc signal segment fault signal code address map fail address x libx_linuxgnulibcsoxefxfdff usrlibx_linuxgnulibopenpalsoopal_hwloc_base_free_topologyxxfca could conflict hwloc symbol explort tensorflow fix locat hwloc librari ldconfig p grep libhwlocso set ld_preload exampl ld_preloadusrlibx_linuxgnulibhwlocso python c import horovodtensorflow hvd hvdinit see issuehttpsgithubcomhorovodhorovodissu inform bash ort command found see error messag train like open mpi find one compon path codeblock bash bash ort command found ort unabl reliabl start one daemon usual caus find requir librari andor binari one node pleas check path ld_library_path set configur ompi enableorterunprefixbydefault lack author execut one specifi node pleas verifi alloc author inabl write startup file tmp tmpdirorte_tmpdir_bas pleas check sy admin determin correct locat use compil ort dynam librari static requir eg cray pleas check configur cmd line consid use one contribplatform definit system type inabl creat connect back mpirun due lack common network interfac andor rout found pleas check network connect includ firewal network rout requir recommend reinstal open mpi enableorterunprefixbydefault flag like codeblock bash wget httpswwwopenmpiorgsoftwareompivdownloadsopenmpitargz tar zxf openmpitargz cd openmpi configur enableorterunprefixbydefault make j nproc make instal ldconfig inclusionmarkerenddonotremov inclusionmarkerstartdonotremov elast horovod elast train enabl horovod scale number worker dynam runtim without requir restart resum checkpoint save durabl storag elast train worker come go horovod job without interrupt train process use elast train run autosc httpsenwikipediaorgwikiautoscaling__ job may acquir resourc train time job run preemptabl spot instanc may come go littl warn node unreli want job continu train host fail requir tensorflow pytorch horovod gloo support instal horovod use horovod_with_gloo ensur instal way discov avail host runtim modifi train script state synchron biggest differ move normal distribut train elast train need track synchron state among worker worker ad remov job enabl elast train make follow chang train script wrap main train process everyth follow initi function decor hvdelasticrun first argument decor function instanc hvdelasticst execut decor function state object synchron across worker ensur worker newli ad well worker might inconsist state share state train begin sync function use collect op upon worker add activ worker reset function horovod collect op broadcast allreduc allgath etc call function place variabl need kept sync worker replica model paramet optim state epoch batch number etc hvdelasticst object standard state implement provid tensorflow kera pytorch howev may necessari case overrid base hvdelasticst object handl broadcast custom type period call statecommit backup copi state memori use prevent corrupt state event worker fail unexpectedli exampl train fail middl paramet updat gradient updat may appli other still allreduc happen horovodinternalerror rais paramet restor valu time last commit commit expens model size increas tradeoff perbatch process time far train process need rollback event failur exampl commit everi batch reduc amount copi factor failur occur may need redo previous process batch elast horovod avoid rollback perform call grace remov worker driver process discov host made avail flag remov push notif worker next time statecommit lightweight statecheck_host_upd call hostsupdatedinterrupt rais event handl similar horovodinternalerror except paramet state restor last commit gener hardwar gener reliabl orchestr system give driver ampl warn host schedul remov job safe call statecommit reduc frequenc call statecheck_host_upd end batch instead regist callback hvdelasticst object respond chang worker membership job exampl rescal learn rate new world size repartit dataset would commonli done callback callback call horovod reiniti state synchron across worker reset process follow horovodinternalerror failur hostsupdatedinterrupt addremov request follow catch except within hvdelasticrun decor restor last commit state horovodinternalerror rais reiniti horovod context perform new round rendezv synchron state among worker broadcast new worker resum train execut underli train function rendezv older worker take prioriti assign worker statu ensur state broadcast date elast tensorflow tensorflow v exampl codeblock python emphasizelin import tensorflow tf import horovodtensorflow hvd hvdinit config tfconfigproto configgpu_optionsallow_growth true configgpu_optionsvisible_device_list strhvdlocal_rank dataset model lr tfvariablebase_lr hvdsize optim tftraingradientdescentoptimizerlr optim hvddistributedoptimizeroptim hvdelasticrun def trainstat train_one_batch stateepoch rangestateepoch epoch statebatch rangestatebatch batches_per_epoch train_one_batch statebatch batches_per_commit statecommit statebatch tfsessionconfigconfig session sessionruntfglobal_variables_initi def on_state_reset lrloadbase_lr hvdsize session state hvdelastictensorflowstatesessionsess batch epoch stateregister_reset_callbackson_state_reset train_opt optimizerminimizeloss trainstat lambda sessionruntrain_opt tensorflow v exampl codeblock python emphasizelin import tensorflow tf import horovodtensorflow hvd hvdinit gpu tfconfigexperimentallist_physical_devicesgpu gpu gpu tfconfigexperimentalset_memory_growthgpu true gpu tfconfigexperimentalset_visible_devicesgpushvdlocal_rank gpu dataset model optim tfoptimizersadamlr hvdsize tffunction def train_one_batchdata target allreducetru tfgradienttap tape prob modeldata trainingtru loss tflossescategorical_crossentropytarget prob allreduc tape hvddistributedgradienttapetap gradient tapegradientloss modeltrainable_vari optimizerapply_gradientszipgradi modeltrainable_vari initi model optim state synchron across worker data target get_random_batch train_one_batchdata target allreducefals hvdelasticrun def trainstat stateepoch rangestateepoch epoch statebatch rangestatebatch batches_per_epoch data target get_random_batch train_one_batchdata target statebatch batches_per_commit statecommit statebatch def on_state_reset optimizerlrassignlr hvdsize state hvdelastictensorflowkerasstatemodel optim batch epoch stateregister_reset_callbackson_state_reset trainstat elast kera codeblock python emphasizelin import tensorflow tf import horovodtensorflowkera hvd hvdinit config tfconfigproto configgpu_optionsallow_growth true configgpu_optionsvisible_device_list strhvdlocal_rank tfkerasbackendset_sessiontfsessionconfigconfig dataset model opt kerasoptimizersadadeltalr hvdsize opt hvddistributedoptimizeropt modelcompilelosskeraslossessparse_categorical_crossentropi optimizeropt metricsaccuraci def on_state_reset tfkerasbackendset_valuemodeloptimizerlr lr hvdsize state hvdelastickerasstatemodel batch epoch stateregister_reset_callbackson_state_reset callback hvdelasticcommitstatecallbackst hvdelasticupdatebatchstatecallbackst hvdelasticupdateepochstatecallbackst hvdrank callbacksappendkerascallbacksmodelcheckpointcheckpointepochh hvdelasticrun def trainstat modelfitdataset steps_per_epoch hvdsize callbackscallback epochsepoch stateepoch verbos hvdrank els trainstat elast pytorch codeblock python emphasizelin import torch import horovodtorch hvd hvdinit torchcudaset_devicehvdlocal_rank dataset model optim optimsgdmodelparamet lr hvdsize optim hvddistributedoptimizeroptim hvdelasticrun def trainstat batch_offset statebatch stateepoch rangestateepoch epoch statebatch rangestatebatch batches_per_epoch data target get_random_batch optimizerzero_grad output modeldata loss fnll_lossoutput target lossbackward optimizerstep statebatch batches_per_commit statecommit statebatch def on_state_reset adjust learn rate reset param_group optimizerparam_group param_grouplr lr hvdsize state hvdelastictorchstatemodel optim batch epoch stateregister_reset_callbackson_state_reset trainstat run horovodrun elast train job start use horovodrun command line tool major differ launch elast job host specifi explicitli instead discov runtim gener way allow horovod discov avail host provid hostdiscoveryscript launch job codeblock bash horovodrun np hostdiscoveryscript discover_hostssh python trainpi host discoveri script must user execut permiss return one host avail slot per line form hostnameslot exampl codeblock bash discover_hostssh host host host host discoveri script fail execut due permiss issu otherwis return nonzero exit code first time call train process fail immedi howev subsequ error result retri job timesout due failur discov suffici number slot discoveri script may omit slot explicitli specifi number slot per host argument codeblock bash horovodrun np hostdiscoveryscript discover_hostssh slot python trainpi elast train job start least np slot avail run worker process addit specifi minimum maximum number process run job codeblock bash horovodrun np minnp maxnp hostdiscoveryscript discover_hostssh python trainpi number avail slot fall minnp due host failur preemption etc job paus wait host becom avail horovod_elastic_timeout default second elaps unspecifi minimum np default np maximum np use cap number process prevent overutil avail resourc serv refer point learn rate scale data partit case need held constant regardless current number worker unspecifi maximum np also default np instanc fail ad blacklist may faulti hardwar host remain blacklist configur cooldown period cooldown period end host whitelist back account transient failur case host ad back job cooldown period configur blacklistcooldownrang paramet like codeblock bash horovodrun np blacklistcooldownrang minnp maxnp hostdiscoveryscript discover_hostspi python trainpi exampl configur minimum cooldown period second maximum cooldown period second intial cooldown period would second repeat failur cooldown period would grow exponenti backoff delay constant expon howev maximum cooldown period would cap second regardless failur count random backoff fraction cooldown lower limit ad cooldown delay default behavior cooldown period blacklist host would remain blacklist rank fail repeatedli result job failur may case train process make progress run ray run elast train script ray simpl provid addit benefit exist horovod elast function execut train interact python environ ie jupyt notebook automat leverag ray autoscal addremov spot instanc awsgcpazurekubernet use elast train ray codeblock python import horovodtorch hvd put horovod concept singl function function serial cloudpickl def training_fn hvdinit model model torchcudaset_devicehvdlocal_rank hvdelasticrun def trainstat stateepoch rangestateepoch epoch statecommit state hvdelastictorchstatemodel optim batch epoch stateregister_reset_callbackson_state_reset trainstat return horovodray import elasticrayexecutor import ray rayinit rayinitaddressauto ray cluster set elasticrayexecutorcreate_settingsverbosetru executor elasticrayexecutorset use_gputru cpus_per_slot executorstart executorruntraining_fn run spark current constraint max_np min_np none equal num_np ie autosc fault toler practic consider consist train worker frequent ad remov train process creat possibl learn rate number partit paramet vari number worker hurt model converg properli handl learn rate need rescal via callback use gradient averag use adasum adjust need made assum local size remain use random sampl read data repartit need occur time recommend strategi simplifi elast train configur use dataset partit callback may use repartit dataset necessari skip alreadi process data care need taken partit data ensur data process prefer approach keep number partit constant hvdmax_siz redistribut partit use local gradient aggreg keep total batch size constant inclusionmarkerenddonotremov raw html p aligncenterimg srchttpsuserimagesgithubusercontentcomdccefeeedfpng altlogo widthp br horovod raw html div aligncent imag httpsbadgefuryiopyhorovodsvg target httpsbadgefuryiopyhorovod alt pypi version imag httpsbadgebuildkitecomfbccdfcdebdebbaeesvgbranchmast target httpsbuildkitecomhorovodhorovod alt build statu imag httpsreadthedocsorgprojectshorovodbadgeversionlatest target httpshorovodreadthedocsioenlatest alt document statu imag httpsimgshieldsiobadgeslackchatgreensvglogoslack target httpsformsglecpgvtyhptgfg alt slack raw html div raw html div aligncent imag httpsimgshieldsiobadgelicenseapachebluesvg target httpsimgshieldsiobadgelicenseapachebluesvg alt licens imag httpsappfossacomapiprojectsgitbgithubcomfhorovodfhorovodsvgtypeshield target httpsappfossacomprojectsgitbgithubcomfhorovodfhorovodrefbadge_shield alt fossa statu imag httpsbestpracticescoreinfrastructureorgprojectsbadg target httpsbestpracticescoreinfrastructureorgproject alt cii best practic imag httpspepytechbadgehorovod target httpspepytechprojecthorovod alt download raw html div inclusionmarkerstartdonotremov horovod distribut deep learn train framework tensorflow kera pytorch apach mxnet goal horovod make distribut deep learn fast easi use raw html pimg srchttpsrawgithubusercontentcomlfaiartworkmasterlfaidataassetslfaidataprojectbadgegraduatecolorlfaidataprojectbadgegraduatecolorpng altlf ai data widthp horovod host lf ai data foundat httpslfdlio_ lf ai data compani deepli commit use open sourc technolog artifici intellig machin deep learn want support commun open sourc project domain consid join lf ai data foundat detail who involv horovod play role read linux foundat announc httpslfdliopresslfdeeplearningwelcomeshorovoddistributedtrainingframeworkasnewestproject_ content horovod primari motiv project make easi take singlegpu train script success scale train across mani gpu parallel two aspect much modif one make program make distribut easi run much faster would run distribut mode intern uber found mpi model much straightforward requir far less code chang previou solut distribut tensorflow paramet server train script written scale horovod run singlegpu multiplegpu even multipl host without code chang see usag usage__ section detail addit easi use horovod fast chart repres benchmark done server pascal gpu connect rocecap gbit network imag httpsuserimagesgithubusercontentcombfccaeabcepng alt gpu benchmark horovod achiev scale effici incept v resnet scale effici vgg see benchmark benchmarksrst_ find reproduc number instal mpi nccl may seem like extra hassl need done team deal infrastructur everyon els compani build model enjoy simplic train scale instal instal horovod linux maco instal cmake httpscmakeorginstall__ raw html p youv instal tensorflow pypi httpspypiorgprojecttensorflow__ make sure g instal youv instal pytorch pypi httpspypiorgprojecttorch__ make sure g instal youv instal either packag conda httpscondaio_ make sure gxx_linux conda packag instal raw html p instal horovod pip packag run cpu codeblock bash pip instal horovod run gpu nccl codeblock bash horovod_gpu_operationsnccl pip instal horovod detail instal horovod gpu support read horovod gpu gpusrst_ full list horovod instal option read instal guid installrst_ want use mpi read horovod mpi mpirst_ want use conda read build conda environ gpu support horovod condarst_ want use docker read horovod docker dockerrst_ compil horovod sourc follow instruct contributor guid contributorsrst_ concept horovod core principl base mpi httpmpiforumorg_ concept size rank local rank allreduc allgath broadcast alltoal see page conceptsrst_ detail support framework see page horovod exampl best practic horovod tensorflow tensorflowrst_ horovod xla tensorflow xlarst_ horovod kera kerasrst_ horovod pytorch pytorchrst_ horovod mxnet mxnetrst_ usag use horovod make follow addit program run hvdinit initi horovod raw html p pin gpu singl process avoid resourc content typic setup one gpu per process set local rank first process server alloc first gpu second process alloc second gpu forth raw html p scale learn rate number worker effect batch size synchron distribut train scale number worker increas learn rate compens increas batch size raw html p wrap optim hvddistributedoptim distribut optim deleg gradient comput origin optim averag gradient use allreduc allgath appli averag gradient raw html p broadcast initi variabl state rank process necessari ensur consist initi worker train start random weight restor checkpoint raw html p modifi code save checkpoint worker prevent worker corrupt raw html p exampl use tensorflow v see exampl httpsgithubcomhorovodhorovodblobmasterexamples_ directori full train exampl codeblock python import tensorflow tf import horovodtensorflow hvd initi horovod hvdinit pin gpu use process local rank one gpu per process config tfconfigproto configgpu_optionsvisible_device_list strhvdlocal_rank build model loss opt tftrainadagradoptim hvdsize add horovod distribut optim opt hvddistributedoptimizeropt add hook broadcast variabl rank process initi hook hvdbroadcastglobalvariableshook make train oper train_op optminimizeloss save checkpoint worker prevent worker corrupt checkpoint_dir tmptrain_log hvdrank els none monitoredtrainingsess take care session initi restor checkpoint save checkpoint close done error occur tftrainmonitoredtrainingsessioncheckpoint_dircheckpoint_dir configconfig hookshook mon_sess mon_sessshould_stop perform synchron train mon_sessruntrain_op run horovod exampl command show run distribut train see run horovod runningrst_ detail includ roceinfiniband tweak tip deal hang run machin gpu codeblock bash horovodrun np h localhost python trainpi run machin gpu codeblock bash horovodrun np h serverserverserverserv python trainpi run use open mpi without horovodrun wrapper see run horovod open mpi mpirst_ run docker see horovod docker dockerrst_ run kubernet see kubeflow mpi oper httpsgithubcomkubeflowmpioperator_ helm chart httpsgithubcomkuberneteschartstreemasterstablehorovod_ ffdl httpsgithubcomibmffdltreemasteretcexampleshorovod_ polyaxon httpsdocspolyaxoncomintegrationshorovod_ run spark see horovod spark sparkrst_ run ray see horovod ray rayrst_ run singular see singular httpsgithubcomsylabsexamplestreemastermachinelearninghorovod_ run lsf hpc cluster eg summit see lsf lsfrst_ run hadoop yarn see toni httpsgithubcomlinkedintony_ gloo gloo httpsgithubcomfacebookincubatorgloo_ open sourc collect commun librari develop facebook gloo come includ horovod allow user run horovod without requir mpi instal environ support mpi gloo choos use gloo runtim pass gloo argument horovodrun codeblock bash horovodrun gloo np python trainpi mpipi horovod support mix match horovod collect mpi librari mpipi httpsmpipyscipyorg_ provid mpi built multithread support check mpi multithread support queri hvdmpi_threads_support function codeblock python import horovodtensorflow hvd initi horovod hvdinit verifi mpi multithread support assert hvdmpi_threads_support mpipi import mpi assert hvdsize mpicomm_worldget_s also initi horovod mpipi subcommun case subcommun run independ horovod train codeblock python mpipi import mpi import horovodtensorflow hvd split comm_world subcommun subcomm mpicomm_worldsplitcolormpicomm_worldrank keympicomm_worldrank initi horovod hvdinitcommsubcomm printcomm_world rank horovod rank mpicomm_worldrank hvdrank infer learn optim model infer remov horovod oper graph inferencerst_ tensor fusion one uniqu thing horovod abil interleav commun comput coupl abil batch small allreduc oper result improv perform call batch featur tensor fusion see tensorfusionrst__ full detail tweak instruct horovod timelin horovod abil record timelin activ call horovod timelin imag httpsuserimagesgithubusercontentcomedaaceaedaacpng alt horovod timelin use horovod timelin analyz horovod perform see timelinerst__ full detail usag instruct autom perform tune select right valu effici make use tensor fusion advanc horovod featur involv good amount trial error provid system autom perform optim process call autotun enabl singl command line argument horovodrun see autotunerst__ full detail usag instruct horovod process set horovod allow concurr run distinct collect oper differ group process take part one distribut train set hvdprocess_set object make use capabl see process set process_setrst__ detail instruct guid run distribut train microsoft azur use batch ai horovod httpsgithubcomazurebatchaitreemasterrecipeshorovod_ distribut model train use horovod httpsspellmlblogdistributedmodeltrainingusinghorovodxvqegruaacgaath_ send us link user guid want publish site troubleshoot see troubleshoot troubleshootingrst_ submit ticket httpsgithubcomhorovodhorovodissuesnew_ cant find answer citat pleas cite horovod public help research articlesergeevhorovod author alexand sergeev mike del balso journal arxiv preprint arxiv titl horovod fast easi distribut deep learn tensorflow year public sergeev del balso meet horovod uber open sourc distribut deep learn framework tensorflow retriev httpsengubercomhorovod httpsengubercomhorovod_ sergeev horovod distribut tensorflow made easi retriev httpswwwslidesharenetalexandersergeevhorovoddistributedtensorflowmadeeasi httpswwwslidesharenetalexandersergeevhorovoddistributedtensorflowmadeeasy_ sergeev del balso horovod fast easi distribut deep learn tensorflow retriev arxiv httpsarxivorgabs_ refer horovod sourc code base baidu tensorflowallreduc httpsgithubcombaiduresearchtensorflowallreduce_ repositori written andrew gibianski joel hest origin work describ articl bring hpc techniqu deep learn httpandrewgibianskycomblogmachinelearningbaiduallreduce_ get involv commun slack httpsformsglecpgvtyhptgfg_ collabor discuss horovod announc httpslistslfaifoundationghorovodannounce_ updat project horovod technicaldiscuss httpslistslfaifoundationghorovodtechnicaldiscuss_ public discuss horovod secur httpslistslfaifoundationghorovodsecurity_ report secur vulner inclusionmarkerenddonotremov place content also appear readthedoc content alreadi part readthedoc tabl content includ condarst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov horovod mpi mpi use altern gloo coordin work process horovod use nccl perform similar two cpu train notic perform benefit use mpi first instal open mpi httpswwwopenmpiorg_ anoth mpi implement learn instal open mpi page httpswwwopenmpiorgfaqcategorybuildingeasybuild_ note open mpi issu may caus hang recommend fix downgrad open mpi upgrad open mpi mpirun horovodrun introduc conveni open mpibas wrapper run horovod script case desir finegrain control option pass open mpi page describ run horovod train directli use open mpi run machin gpu codeblock bash horovodrun np python trainpi equival open mpi command codeblock bash mpirun np bindto none mapbi slot x nccl_debuginfo x ld_library_path x path mca pml ob mca btl openib python trainpi run machin gpu codeblock bash horovodrun np h serverserverserverserv python trainpi equival open mpi command codeblock bash mpirun np h serverserverserverserv bindto none mapbi slot x nccl_debuginfo x ld_library_path x path mca pml ob mca btl openib python trainpi start open mpi import add bindto none mapbi slot argument bindto none specifi open mpi bind train process singl cpu core would hurt perform mapbi slot allow mixtur differ numa configur default behavior bind socket mca pml ob mca btl openib flag forc use tcp mpi commun avoid mani multiprocess issu open mpi rdma typic result segment fault use tcp mpi notic perform impact sinc heavi commun done nccl use rdma via roce infiniband theyr avail see horovod gpu gpusrst_ notabl except rule model heavili use hvdbroadcast hvdallgath oper make oper use rdma read open mpi rdma openmpiwithrdma_ section x option specifi x nccl_debuginfo copi x ld_library_path environ variabl worker custom ssh port specifi custom ssh port mca plm_rsh_arg p port follow codeblock bash mpirun np h serverserverserverserv bindto none mapbi slot mca plm_rsh_arg p x nccl_debuginfo x ld_library_path x path mca pml ob mca btl openib python trainpi frequent use case run horovod docker environ dockerrst_ open mpi rdma note use tcp mpi commun signific effect perform major case model make heavi use hvdbroadcast hvdallgath oper except rule default open mpi openib btl provid rdma function work well mpi multithread order use rdma openib multithread must disabl via x horovod_mpi_threads_dis option see exampl codeblock bash mpirun np h serverserverserverserv bindto none mapbi slot x nccl_debuginfo x ld_library_path x horovod_mpi_threads_dis x path mca pml ob python trainpi mpi rdma implement may may benefit disabl multithread pleas consult vendor document horovod paramet knob mani configur paramet avail command line argument horovodrun use mpirun use environ variabl tensor fusion codeblock bash mpirun x horovod_fusion_threshold x horovod_cycle_tim python trainpi timelin codeblock bash mpirun x horovod_timelinepathtotimelinejson x horovod_timeline_mark_cycl python trainpi autotun codeblock bash mpirun x horovod_autotun x horovod_autotune_logtmpautotune_logcsv python trainpi note use horovodrun command line argument overrid valu set environ hang due nonrout network interfac network interfac rout caus open mpi hang exampl interfac docker see nonrout interfac like docker output ifconfig tell open mpi nccl use via mca btl_tcp_if_exclud interfaceinterfac nccl_socket_ifnameinterfaceinterfac paramet codeblock bash ifconfig produc output like docker link encapethernet hwaddr dea inet addr bcast mask broadcast multicast mtu metric rx packet error drop overrun frame tx packet error drop overrun carrier collis txqueuelen rx byte b tx byte b eth link encapethernet hwaddr abdb inet addr bcast mask broadcast run multicast mtu metric rx packet error drop overrun frame tx packet error drop overrun carrier collis txqueuelen rx byte gib tx byte gib eth link encapethernet hwaddr abda inet addr bcast mask broadcast run multicast mtu metric rx packet error drop overrun frame tx packet error drop overrun carrier collis txqueuelen rx byte mib tx byte mib lo link encaploc loopback inet addr mask inet addr scopehost loopback run mtu metric rx packet error drop overrun frame tx packet error drop overrun carrier collis txqueuelen rx byte gib tx byte gib exampl mpirun command lo docker interfac exclud codeblock bash mpirun np h serverserverserverserv bindto none mapbi slot x nccl_debuginfo x ld_library_path x path x nccl_socket_ifnamelodock mca pml ob mca btl openib mca btl_tcp_if_exclud lodock python trainpi inclusionmarkerenddonotremov includ sparkrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov horovod ray horovodray allow user leverag horovod ray cluster httpsdocsrayioenlatestclusterindexhtml_ current ray horovod integr provid refrayexecutor api horovod_ray_api note ray horovod integr current support gloo backend instal use extra ray option instal ray along horovod codeblock bash horovod_with_gloo pip instal horovodray see ray document advanc instal instruct httpsdocsrayioenlatestinstallationhtml_ horovod ray executor horovod ray integr offer rayexecutor abstract refdoc horovod_ray_api wrapper group ray actor state process httpsdocsrayioenlatestwalkthroughhtmlremoteclassesactors_ codeblock python horovodray import rayexecutor start ray cluster attach exist ray cluster rayinit start num_work actor cluster executor rayexecutor set num_workersnum_work use_gputru launch num_work actor ray cluster executorstart actor part horovod ring rayexecutor invoc abl support arbitrari horovod collect oper note implicit assumpt cluster homogen shape ie machin number slot avail simpli implement detail fundament limit actual execut function run follow codeblock python use stateless run method function take arg kwarg def simple_fn hvdinit printhvd rank hvdrank return hvdrank execut function worker result executorrunsimple_fn check rank worker uniqu assert lensetresult host num_slot executorshutdown state execut uniqu featur ray support state actor httpsdocsrayioenlatestwalkthroughhtmlremoteclassesactors_ mean start arbitrari python class worker easili support oper call data cach memori codeblock python import torch horovodtorch import hvd horovodray import rayexecutor class mymodel def __init__self learning_r selfmodel neuralnet optim torchoptimsgd selfmodelparamet lrlearning_r selfoptim hvddistributedoptimizeroptim def get_weightsself return dictselfmodelparamet def trainself return self_trainselfmodel selfoptim rayinit executor rayexecutor executorstartexecutable_clsmymodel run train step rang state execut method take current worker execut paramet executorexecutelambda worker workertrain obtain train weight model replica result executorexecutelambda worker workerget_weight result n copi model weight assert allisinstancer dict re result elast ray executor ray also support elast execut elasticrst_ via refth rayexecutor horovod_ray_api similar default horovod differ nonelast elast version ray host number worker dynam determin runtim must first set ray cluster_ ray cluster support autosc cloud provid aw gcp azur codeblock bash first run pip instal boto aw configur creat updat cluster command finish print command use ssh cluster head node ray raypythonrayautoscalerawsexamplefullyaml ray cluster setup need move part exist elast horovod train script train function specif instanti model invoc hvdelasticrun call done insid function codeblock python import horovodtorch hvd put horovod concept singl function function serial cloudpickl def training_fn hvdinit model model torchcudaset_devicehvdlocal_rank hvdelasticrun def trainstat stateepoch rangestateepoch epoch statecommit state hvdelastictorchstatemodel optim batch epoch stateregister_reset_callbackson_state_reset trainstat return attach underli ray cluster execut train function codeblock python import ray horovodray import rayexecutor rayinitaddressauto attach ray cluster set rayexecutorcreate_settingsverbosetru executor rayexecutor set min_work use_gputru cpus_per_slot executorstart executorruntraining_fn ray automat start remot actor execut training_fn node becom avail note executorrun call termin whenev one train function termin success worker fail aw cluster launcher also easili leverag ray cluster launcher httpsdocsrayioenlatestclusterlauncherhtml_ spin cloud instanc codeblock yaml save ray_clusteryaml cluster_nam horovodclust provid type aw region uswest auth ssh_user ubuntu min_work max_work deep learn ami ubuntu version head_nod instancetyp pxlarg imageid amibfdea worker_nod instancetyp pxlarg imageid amibfdea setup_command set node horovod_with_gloo horovod_gpu_operationsnccl pip instal horovodray start specifi ray cluster monitor statu codeblock bash ray ray_clusteryaml start head node ray monitor ray_clusteryaml wait worker node python script make sure add rayinitaddressauto connect distribut ray cluster codeblock diff rayinit rayinitaddressauto execut ray script cluster codeblock bash ray submit ray_clusteryaml your_scriptpi equival ray attach ray_clusteryaml ssh ubuntuip python your_scriptpi inclusionmarkerenddonotremov inclusionmarkerstartdonotremov tensor fusion one uniqu thing horovod abil interleav commun comput coupl abil batch small allreduc oper result improv perform call batch featur tensor fusion tensor fusion work attempt combin tensor readi reduc given moment time one reduct oper algorithm tensor fusion follow determin tensor readi reduc select first tensor fit horovod_fusion_threshold byte data type alloc fusion buffer size horovod_fusion_threshold alloc default fusion buffer size mb copi data select tensor fusion buffer execut allreduc oper fusion buffer copi data fusion buffer output tensor repeat tensor reduc cycl fusion buffer size adjust use fusionthresholdmb command line argument horovodrun codeblock bash horovodrun np fusionthresholdmb python trainpi set fusionthresholdmb zero disabl tensor fusion codeblock bash horovodrun np fusionthresholdmb python trainpi tweak time cycl defin millisecond use cycletimem command line argument codeblock bash horovodrun np cycletimem python trainpi inclusionmarkerenddonotremov horovod kera horovod support kera regular tensorflow similar way use horovod kera make follow modif train script run hvdinit raw html p pin gpu singl process typic setup one gpu per process set local rank first process server alloc first gpu second process alloc second gpu forth tensorflow v codeblock python config tfconfigproto configgpu_optionsvisible_device_list strhvdlocal_rank kset_sessiontfsessionconfigconfig tensorflow v codeblock python gpu tfconfigexperimentallist_physical_devicesgpu gpu gpu tfconfigexperimentalset_memory_growthgpu true gpu tfconfigexperimentalset_visible_devicesgpushvdlocal_rank gpu raw html p scale learn rate number worker effect batch size synchron distribut train scale number worker increas learn rate compens increas batch size raw html p wrap optim hvddistributedoptim distribut optim deleg gradient comput origin optim averag gradient use allreduc allgath appli averag gradient raw html p add hvdcallbacksbroadcastglobalvariablescallback broadcast initi variabl state rank process necessari ensur consist initi worker train start random weight restor checkpoint raw html p modifi code save checkpoint worker prevent worker corrupt accomplish guard model checkpoint code hvdrank raw html p note kera known issu httpsgithubcomfcholletkerasissues_ make worker alloc gpu server instead gpu assign local rank multipl gpu per server upgrad kera downgrad kera use kera bundl tensorflow must use tensorflow import kera instead import kera import horovodtensorflowkera hvd instead import horovodkera hvd import statement see full train simpl httpsgithubcomhorovodhorovodblobmasterexampleskeraskeras_mnistpy_ shown advanc httpsgithubcomhorovodhorovodblobmasterexampleskeraskeras_mnist_advancedpy_ exampl codeblock python __future__ import print_funct import kera kerasdataset import mnist kerasmodel import sequenti keraslay import dens dropout flatten keraslay import convd maxpoolingd kera import backend k import math import tensorflow tf import horovodkera hvd horovod initi horovod hvdinit horovod pin gpu use process local rank one gpu per process config tfconfigproto configgpu_optionsallow_growth true configgpu_optionsvisible_device_list strhvdlocal_rank kset_sessiontfsessionconfigconfig batch_siz num_class horovod adjust number epoch base number gpu epoch intmathceil hvdsize input imag dimens img_row img_col data shuffl split train test set x_train y_train x_test y_test mnistload_data kimage_data_format channels_first x_train x_trainreshapex_trainshap img_row img_col x_test x_testreshapex_testshap img_row img_col input_shap img_row img_col els x_train x_trainreshapex_trainshap img_row img_col x_test x_testreshapex_testshap img_row img_col input_shap img_row img_col x_train x_trainastypefloat x_test x_testastypefloat x_train x_test printx_train shape x_trainshap printx_trainshap train sampl printx_testshap test sampl convert class vector binari class matric y_train kerasutilsto_categoricaly_train num_class y_test kerasutilsto_categoricaly_test num_class model sequenti modeladdconvd kernel_s activationrelu input_shapeinput_shap modeladdconvd activationrelu modeladdmaxpoolingdpool_s modeladddropout modeladdflatten modeladddens activationrelu modeladddropout modeladddensenum_class activationsoftmax horovod adjust learn rate base number gpu opt kerasoptimizersadadelta hvdsize horovod add horovod distribut optim opt hvddistributedoptimizeropt modelcompilelosskeraslossescategorical_crossentropi optimizeropt metricsaccuraci callback horovod broadcast initi variabl state rank process necessari ensur consist initi worker train start random weight restor checkpoint hvdcallbacksbroadcastglobalvariablescallback horovod save checkpoint worker prevent worker corrupt hvdrank callbacksappendkerascallbacksmodelcheckpointcheckpointepochh modelfitx_train y_train batch_sizebatch_s callbackscallback epochsepoch verbos validation_datax_test y_test score modelevaluatex_test y_test verbos printtest loss score printtest accuraci score tensorflow v kera exampl mnist httpsgithubcomhorovodhorovodblobmasterexamplestensorflowtensorflow_keras_mnistpy_ exampl codeblock python import tensorflow tf import horovodtensorflowkera hvd initi horovod hvdinit pin gpu use process local rank one gpu per process gpu tfconfigexperimentallist_physical_devicesgpu gpu gpu tfconfigexperimentalset_memory_growthgpu true gpu tfconfigexperimentalset_visible_devicesgpushvdlocal_rank gpu build model dataset dataset model opt tfoptimizersadam hvdsize horovod add horovod distributedoptim opt hvddistributedoptimizeropt horovod specifi experimental_run_tf_functionfals ensur tensorflow use hvddistributedoptim comput gradient mnist_modelcompilelosstflossessparsecategoricalcrossentropi optimizeropt metricsaccuraci experimental_run_tf_functionfals callback horovod broadcast initi variabl state rank process necessari ensur consist initi worker train start random weight restor checkpoint hvdcallbacksbroadcastglobalvariablescallback horovod save checkpoint worker prevent worker corrupt hvdrank callbacksappendkerascallbacksmodelcheckpointcheckpointepochh modelfitdataset steps_per_epoch hvdsize callbackscallback epoch verbos hvdrank els includ contributorsrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov horovod spark horovodspark packag provid conveni wrapper around horovod make run distribut train job spark cluster easi situat train data origin spark enabl tight model design loop data process model train model evalu done spark provid two api run horovod spark high level estim api lower level run api use underli mechan launch horovod spark executor estim api abstract data process spark datafram deep learn dataset model train loop model checkpoint metric collect distribut train recommend use horovod spark estim use kera tfkera kera pytorch train want train directli spark datafram pyspark use standard gradient descent optim process train loop whatev reason estim api meet need run api offer finegrain control instal instal horovod usag spark use extra spark instal spark depend well codeblock bash pip instal horovodspark note horovod spark estim requir follow horovod pyspark includ list depend spark deep learn framework tensorflow pytorch horovod spark estim addit requir least one combin tensorflowgpu tensorflow kerasestim torch tensorboard torchestim torch pytorch_lightn lightningestim horovod spark estim horovod spark estim allow train deep neural network directli exist spark datafram leverag horovod abil scale across multipl worker without special code distribut train codeblock python tensorflow import kera import tensorflow tf import horovodsparkkera hvd model kerasmodelssequenti addkeraslayersdens input_dim addkeraslayersactivationtanh addkeraslayersdens addkeraslayersactivationsigmoid note unscal learn rate optim kerasoptimizerssgdlr loss binary_crossentropi store hdfsstoreuserusernameexperi keras_estim hvdkerasestim num_proc storestor modelmodel optimizeroptim lossloss feature_colsfeatur label_colsi batch_siz epoch keras_model keras_estimatorfittrain_df setoutputcolspredict predict_df keras_modeltransformtest_df estim hide complex glu spark datafram deep learn train script read data format interpret train framework distribut train use horovod user need provid kera pytorch model estim work fit datafram train estim return transform represent train model model transform use like spark ml transform make predict input datafram write new column output datafram estim use track experi histori model checkpoint hotstart retrain metric log tensorboard use estim store abstract store use persist train artifact includ intermedi represent train data horovod nativ support store hdf local filesystem petastorm httpsgithubcomuberpetastormblobmasterpetastormpytorchpyl base data loader use default user defin custom data loader overrid basedataload interfac async data loader mixin also ad top data loader endtoend exampl keras_spark_rossmann_estimatorpi script examplessparkkeraskeras_spark_rossmann_estimatorpy__ provid exampl endtoend data prepar train model rossmann store sale httpswwwkagglecomcrossmannstoresales__ kaggl competit inspir articl introduct deep learn tabular data httpswwwfastaicategoricalembeddings__ leverag code notebook referenc articl exampl split three part first part perform complic data preprocess initi set csv file provid competit gather commun second part defin kera model perform distribut train model use horovod spark third part perform predict use best model creat submiss file run exampl sure instal horovod spark codeblock bash wget httpsrawgithubusercontentcomhorovodhorovodmasterexamplessparkkeraskeras_spark_rossmann_estimatorpi wget httpfilesfastaipartlessonrossmanntgz tar zxvf rossmanntgz python keras_spark_rossmann_estimatorpi pytorch check pytorch_lightning_spark_mnistpi script examplessparkpytorchpytorch_lightning_spark_mnistpy__ use use lightn estim horovod backend train mnist model spark train exist parquet dataset data alreadi parquet format wish train horovod spark estim without need reprocess data spark use estimatorfit_on_parquet train directli exist parquet dataset codeblock python store hdfsstoretrain_pathuserusernametraining_dataset val_pathuserusernameval_dataset keras_estim hvdkerasestim num_proc storestor modelmodel optimizeroptim lossloss feature_colsfeatur label_colsi batch_siz epoch keras_model keras_estimatorfit_on_parquet result keras_model use way spark transform extract underli kera model use outsid spark codeblock python model keras_modelgetmodel pred modelpredictnpon dtypenpfloat approach work dataset creat use horovodsparkcommonutilprepare_data also work parquet file contain spark userdefin data type like densevector sparsevector recommend use prepare_data ensur data properli prepar train even exist dataset parquet format use prepare_data allow properli partit dataset number train process intend use well compress larg spars data column codeblock python store hdfsstoretrain_pathuserusernametraining_dataset val_pathuserusernameval_dataset utilprepare_datanum_process storestor dfdf feature_columnsfeatur label_columnsi valid compress_sparsetru keras_estim hvdkerasestim num_proc storestor modelmodel optimizeroptim lossloss feature_colsfeatur label_colsi batch_siz epoch keras_model keras_estimatorfit_on_parquet data prepar reus futur spark applic without need call utilprepare_data horovod spark run also use horovod spark run code would within ordinari train script use framework support horovod simpli write train logic within function use horovodsparkrun execut function parallel mpi top spark horovod spark use cloudpickl send train function worker execut captur local variabl train script notebook within train function similar use userdefin function pyspark toy exampl run horovod job spark provid codeblock bash pyspark pyspark welcom messag def fnmagic_numb import horovodtorch hvd hvdinit printhello rank local_rank size local_s magic_numb hvdrank hvdlocal_rank hvdsize hvdlocal_s magic_numb return hvdrank import horovodspark horovodsparkrunfn arg run process stage hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb hello rank local_rank size local_s magic_numb complet exampl found keras_spark_rossmann_runpi examplessparkkeraskeras_spark_rossmann_runpy__ show use low level horovodsparkrun api train model endtoend follow step codeblock bash wget httpsrawgithubusercontentcomhorovodhorovodmasterexamplessparkkeraskeras_spark_rossmann_runpi wget httpfilesfastaipartlessonrossmanntgz tar zxvf rossmanntgz python keras_spark_rossmann_runpi spark cluster setup deep learn workload tend differ resourc requir typic data process workload certain consider dl spark cluster setup gpu train gpu train one approach set separ gpu spark cluster configur executor cpu core gpu accomplish standalon mode follow codeblock bash echo export spark_worker_cor gpu pathtosparkconfsparkenvsh pathtosparksbinstartallsh approach turn sparktaskcpu set control gpu request per process default ongo spark httpsissuesapacheorgjirabrowsespark__ effort aim introduc gpuawar resourc schedul futur version spark cpu train cpu train one approach specifi sparktaskcpu set train session creation codeblock python conf sparkconfsetappnametrain setmastersparktrainingclust setsparktaskcpu spark sparksessionbuilderconfigconfconfgetorcr approach allow reus spark cluster data prepar train secur horovod spark use open mpi run horovod job spark secur open mpi implement sinc open mpi use encrypt commun capabl launch new process recommend use network level secur isol horovod job potenti attack environ knob horovod_spark_start_timeout set default timeout spark task spawn regist start run code executor spark task schedul ondemand take long time start may use increas timeout system level horovod databrick run horovod spark databrick creat store instanc dbf path one follow pattern dbf dbf filedbf codeblock python store storecreatedbfs_path explicitli use dbfslocalstor store dbfslocalstoredbfs_path dbfslocalstor use databrick file system dbf local file api aw httpsdocsdatabrickscomdatadatabricksfilesystemhtmllocalfileapis__ azur httpsdocsmicrosoftcomenusazuredatabricksdatadatabricksfilesystemlocalfileapis__ store intermedi data train artifact databrick preconfigur gpuawar schedul databrick runtim ml gpu see gpu schedul instruct aw httpsdocsdatabrickscomclustersgpuhtmlgpuscheduling__ azur httpsdocsmicrosoftcomenusazuredatabricksclustersgpugpuscheduling__ detail estim api horovod launch task worker gpu worker task pin gpu assign gpu spark run api function get_available_devic horovodsparktask return list assign gpu spark task get_available_devic call see keras_spark_rossmannpi examplessparkkeraskeras_spark_rossmannpy__ exampl use get_available_devic run api inclusionmarkerenddonotremov includ autotunerst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ dockerrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov run horovod page includ exampl open mpi use horovodrun check mpi document argument mpirun command system typic one gpu alloc per process server gpu run process horovodrun number process specifi np flag run machin gpu codeblock bash horovodrun np h localhost python trainpi run machin gpu codeblock bash horovodrun np h serverserverserverserv python trainpi also specifi host node host file exampl codeblock bash cat myhostfil aa slot bb slot cc slot exampl list host name aa bb cc mani slot slot indic mani process potenti execut node format mpirun command httpswwwopenmpiorgdocvmanmpirunphptoc__ run host specifi hostfil codeblock bash horovodrun np hostfil myhostfil python trainpi requir usag horovodrun requir one follow open mpi x spectrum mpi mpich openrt gloo intelr mpi mpi instal run horovodrun use gloo gloo depend come horovod automat requir cmake avail system time instal horovod wish use differ version mpi may still abl run horovod use mpirun mpirst directli failur due ssh issu host horovodrun execut must abl ssh host without prompt horovodrun fail permiss error verifi ssh everi server without enter password answer question like authent host hostnam ip address cant establish rsa key fingerprint xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx sure want continu connect yesno learn set passwordless authent see page httpwwwlinuxproblemorgart_html__ avoid authent host hostnam ip address cant establish prompt add host sshknown_host file use sshkeyscan codeblock bash sshkeyscan rsadsa server server sshknown_host advanc run horovod open mpi advanc case might want finegrain control option pass open mpi learn run horovod train directli use open mpi read run horovod open mpi mpirst_ run horovod intelr mpi horovodrun automat convert paramet format support intelr mpi mpirun set allow option includ np h ssh argument p intelr mpi mpirun support mca paramet set option via environ variabl httpssoftwareintelcomcontentwwwusendevelopdocumentationmpideveloperreferencelinuxenvironmentvariablereferencehtml__ addit inform refer intelr mpi offici document httpssoftwareintelcomcontentwwwusendevelopdocumentationmpideveloperreferencelinuxtopcommandreferencempiexechydraglobaloptionshtml__ inclusionmarkerenddonotremov includ elasticrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov horovod lsf page includ exampl run horovod lsf cluster horovodrun automat detect host name gpu lsf job lsf cluster support jsrun horovodrun use launcher otherwis default mpirun insid lsf batch file interact session need use codeblock bash horovodrun python trainpi horovod start process per gpu host lsf job also limit run subset job resourc exampl use gpu codeblock bash horovodrun np python trainpi still pass extra argument horovodrun exampl trigger cudaawar mpi codeblock bash horovodrun mpiargsgpu python trainpi inclusionmarkerenddonotremov includ troubleshootingrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov includ adasum_user_guiderst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov horovod document horovod improv speed scale resourc util deep learn train get start choos deep learn framework learn get start horovod raw html button classaccordiontensorflowbutton div classpanel pto use horovod tensorflow laptop ol lia hrefhttpswwwopenmpiorgfaqcategorybuildingeasybuildinstal open mpi anoth mpi implement li li youv instal tensorflow hrefhttpspypiorgprojecttensorflowpypia make sure codegcod installedbr youv instal tensorflow hrefhttpscondaiocondaa make sure codegxx_linuxcod conda packag instal li liinstal horovod pip packag codepip instal horovodcod liread hrefhttpshorovodreadthedocsioenlatesttensorflowhtmlhorovod tensorflowa best practic exampl li ol use hrefhttpshorovodreadthedocsioenlatestgpus_includehtmlhorovod gpusa hrefhttpshorovodreadthedocsioenlatestspark_includehtmlsparka hrefhttpshorovodreadthedocsioenlatestdocker_includehtmldockera hrefhttpsgithubcomsylabsexamplestreemastermachinelearninghorovodsingularitya kubernet hrefhttpsgithubcomkubeflowexamplestreemasterdemosyelp_demoks_appvendorkubeflowmpijobkubeflowa hrefhttpsgithubcomkubeflowmpioperatormpi operatora hrefhttpsgithubcomhelmchartstreemasterstablehorovodhelm charta hrefhttpsgithubcomibmffdltreemasteretcexampleshorovodffdla p div button classaccordionkerasbutton div classpanel pto use horovod kera laptop ol lia hrefhttpswwwopenmpiorgfaqcategorybuildingeasybuildinstal open mpi anoth mpi implement li li youv instal tensorflow hrefhttpspypiorgprojecttensorflowpypia make sure codegcod installedbr youv instal tensorflow hrefhttpscondaiocondaa make sure codegxx_linuxcod conda packag instal li liinstal horovod pip packag codepip instal horovodcod liread hrefhttpshorovodreadthedocsioenlatestkerashtmlhorovod kerasa best practic exampl li ol use hrefhttpshorovodreadthedocsioenlatestgpus_includehtmlhorovod gpusa hrefhttpshorovodreadthedocsioenlatestspark_includehtmlsparka hrefhttpshorovodreadthedocsioenlatestdocker_includehtmldockera hrefhttpsgithubcomsylabsexamplestreemastermachinelearninghorovodsingularitya kubernet hrefhttpsgithubcomkubeflowexamplestreemasterdemosyelp_demoks_appvendorkubeflowmpijobkubeflowa hrefhttpsgithubcomkubeflowmpioperatormpi operatora hrefhttpsgithubcomhelmchartstreemasterstablehorovodhelm charta hrefhttpsgithubcomibmffdltreemasteretcexampleshorovodffdla p div button classaccordionpytorchbutton div classpanel pto use horovod pytorch laptop ol lia hrefhttpswwwopenmpiorgfaqcategorybuildingeasybuildinstal open mpi anoth mpi implement li li youv instal pytorch hrefhttpspypiorgprojecttorchpypia make sure codegcod installedbr youv instal pytorch hrefhttpscondaiocondaa make sure codegxx_linuxcod conda packag instal li liinstal horovod pip packag codepip instal horovodcod liread hrefhttpshorovodreadthedocsioenlatestpytorchhtmlhorovod pytorcha best practic exampl li ol use hrefhttpshorovodreadthedocsioenlatestgpus_includehtmlhorovod gpusa hrefhttpshorovodreadthedocsioenlatestspark_includehtmlsparka hrefhttpshorovodreadthedocsioenlatestdocker_includehtmldockera hrefhttpsgithubcomsylabsexamplestreemastermachinelearninghorovodsingularitya kubernet hrefhttpsgithubcomkubeflowexamplestreemasterdemosyelp_demoks_appvendorkubeflowmpijobkubeflowa hrefhttpsgithubcomkubeflowmpioperatormpi operatora hrefhttpsgithubcomhelmchartstreemasterstablehorovodhelm charta hrefhttpsgithubcomibmffdltreemasteretcexampleshorovodffdla p div button classaccordionapach mxnetbutton div classpanel pto use horovod apach mxnet laptop ol lia hrefhttpswwwopenmpiorgfaqcategorybuildingeasybuildinstal open mpi anoth mpi implement li liinstal horovod pip packag codepip instal horovodcod liread hrefhttpshorovodreadthedocsioenlatestmxnethtmlhorovod mxneta best practic exampl li ol use hrefhttpshorovodreadthedocsioenlatestgpus_includehtmlhorovod gpusa hrefhttpshorovodreadthedocsioenlatestspark_includehtmlsparka hrefhttpshorovodreadthedocsioenlatestdocker_includehtmldockera hrefhttpsgithubcomsylabsexamplestreemastermachinelearninghorovodsingularitya kubernet hrefhttpsgithubcomkubeflowexamplestreemasterdemosyelp_demoks_appvendorkubeflowmpijobkubeflowa hrefhttpsgithubcomkubeflowmpioperatormpi operatora hrefhttpsgithubcomhelmchartstreemasterstablehorovodhelm charta hrefhttpsgithubcomibmffdltreemasteretcexampleshorovodffdla p div script var acc documentgetelementsbyclassnameaccordion var acclength acciaddeventlistenerclick function thisclasslisttoggleact var panel thisnextelements panelstylemaxheight panelstylemaxheight null els panelstylemaxheight panelscrollheight px script guid toctre maxdepth summary_includ concepts_includ install_includ api tensorflow xla kera pytorch mxnet running_includ elastic_includ benchmarks_includ inference_includ gpus_includ mpi_includ oneccl_includ conda_includ docker_includ spark_includ ray_includ lsf_includ tensorfusion_includ adasum_user_guide_includ timeline_includ hyperparameter_search_includ autotune_includ process_set_includ troubleshooting_includ contributors_includ indic tabl refgenindex refmodindex refsearch inclusionmarkerstartdonotremov horovod docker streamlin instal process publish refer dockerfil httpsgithubcomhorovodhorovodblobmasterdocker__ get start horovod minut contain includ horovod exampl httpsgithubcomhorovodhorovodtreemasterexamples__ exampl directori prebuilt docker contain horovod avail dockerhub httpshubdockercomrhorovodhorovod__ gpu cpu ray httpsrayio__ run singl machin contain built run use nvidiadock httpsgithubcomnvidianvidiadocker__ note replac horovodlatest specif httpshubdockercomrhorovodhorovodtags__ prebuild docker contain horovod instead build codeblock bash nvidiadock run horovodlatest rootccddexampl horovodrun np h localhost python keras_mnist_advancedpi dont run contain privileg mode may see follow messag codeblock bash acd read expect errno ignor messag run multipl machin describ simpl exampl involv share filesystem mntshare use common port number ssh daemon run contain mntsharessh would contain typic id_rsa authorized_key pair allow passwordless authent httpwwwlinuxproblemorgart_html__ note hard requir make exampl concis share filesystem replac rsync ssh configur code across machin common ssh port replac machinespecif port defin rootsshssh_config file primari worker codeblock bash host nvidiadock run networkhost v mntsharesshrootssh horovodlatest rootccddexampl horovodrun np h hosthosthosthost p python keras_mnist_advancedpi secondari worker codeblock bash host nvidiadock run networkhost v mntsharesshrootssh horovodlatest bash c usrsbinsshd p sleep infin codeblock bash host nvidiadock run networkhost v mntsharesshrootssh horovodlatest bash c usrsbinsshd p sleep infin codeblock bash host nvidiadock run networkhost v mntsharesshrootssh horovodlatest bash c usrsbinsshd p sleep infin ad mellanox rdma support mellanox nic recommend mount mellanox devic devinfiniband contain enabl ipc_lock capabl memori registr codeblock bash nvidiadock run networkhost v mntsharesshrootssh capaddipc_lock devicedevinfiniband horovodlatest rootccddexampl need specifi addit configur option primari secondari worker run contain differ port run situat without common ssh port eg multipl contain host configur sshconfig httpslinuxizecompostusingthesshconfigfile__ file assign custom host name port contain codeblock bash host host hostnam port host host hostnam port use horovodrun directli though contain separ host ip codeblock bash horovodrun np h hosthost python keras_mnist_advancedpi inclusionmarkerenddonotremov inclusionmarkerstartdonotremov analyz perform horovod abil record timelin activ call horovod timelin imag httpsuserimagesgithubusercontentcomedaaceaedaacpng alt horovod timelin record horovod timelin set timelinefilenam command line argument locat timelin file creat file record rank contain inform activ worker codeblock bash horovodrun np timelinefilenam pathtotimelinejson python trainpi open timelin file use chrometrac facil chrome httpswwwgooglecomchromebrowser__ browser exampl see tensor reduc two major phase tensor reduct negoti phase worker send rank signal theyr readi reduc given tensor worker report readi repres tick negotiate_allreduc bar see worker earli late immedi negoti rank send worker signal start reduc tensor process phase oper actual happen subdivid multipl subphas wait_for_data indic time taken wait gpu finish comput input allreduc allgath broadcast oper happen tensorflow tri smartli interleav schedul gpu comput applic situat horovod oper place gpu wait_for_other_tensor_data indic time taken wait gpu finish comput input oper part fusion batch queue happen reduct done nccl previou nccl oper finish yet memcpy_in_fusion_buff memcpy_out_fusion_buff indic time taken copi data fusion buffer nccl_allreduc mpi_allreduc mpi_allgath mpi_bcast indic time taken actual oper gpu cpu highlight whether oper perform use nccl pure mpi case horovod_hierarchical_allreduc nccl_allreduc becom sequenc subsequ nccl_reducescatt nccl_reduc memcpy_in_host_buff mpi_allreduc memcpy_out_host_buff nccl_allgath nccl_bcast ad cycl marker horovod perform work cycl cycl use aid tensor fusion httpsgithubcomhorovodhorovodblobmasterdocstensorfusionrst__ horovod abil record moment cycl start debug tensor fusion imag httpsuserimagesgithubusercontentcomffeabaceecfpng alt cycl marker sinc inform make timelin view crowd enabl default add cycl marker timelin set timelinemarkcycl flag codeblock bash horovodrun np timelinefilenam pathtotimelinejson timelinemarkcycl python trainpi inclusionmarkerenddonotremov includ benchmarksrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov inclusionmarkerstartdonotremov horovod instal guid requir gnu linux maco python g anoth compil support c cmake newer tensorflow pytorch mxnet option mpi best perform gpu nccl httpsdevelopernvidiacomnccl__ horovod unabl find cmake binari may need set horovod_cmak environ instal horovod support window framework build horovod tensorflow pytorch mxnet default horovod attempt build support least one must enabl horovod instal success ensur framework depend properli instal attempt instal horovod append extra argument identifi requir framework codeblock bash pip instal horovodtensorflowkeraspytorchmxnetspark addit specifi framework requir individu requir framework collect codeblock bash pip instal horovodallframework use build horovod part larger collect depend reli pip compil determin correct instal order tensorflow ensur horovod built tensorflow support enabl codeblock bash horovod_with_tensorflow pip instal horovodtensorflow skip tensorflow set horovod_without_tensorflow environ pytorch ensur horovod built pytorch support enabl codeblock bash horovod_with_pytorch pip instal horovodpytorch skip pytorch set horovod_without_pytorch environ mxnet ensur horovod built mxnet cpu support enabl codeblock bash horovod_with_mxnet pip instal horovodmxnet mxnet version work horovod mxnet earlier gcc incompat issu httpsgithubcomhorovodhorovodissues__ use mxnet later horovod later avoid incompat mxnet post miss mkldnn header work horovod use post post post respect mxnet post post avail mxnetcu mxnetcu skip mxnet set horovod_without_mxnet environ kera standalon kera support current avail tensorflow backend ensur horovod built kera support avail codeblock bash horovod_with_tensorflow pip instal horovodtensorflowkera plugin built kera tensorflow plugin must enabl order use horovod kera spark horovod use spark combin framework ensur horovod necessari requir order run top spark codeblock bash pip instal horovodspark control control use coordin work horovod process determin tensor process provid control implement mpi gloo default horovod attempt build support least one must enabl horovod instal success mpi mpi origin control horovod use mpirun launch worker process horovodrun use mpirun hood use mpi use horovod mpi instal open mpi httpswwwopenmpiorg_ anoth mpi implement learn instal open mpi page httpswwwopenmpiorgfaqcategorybuildingeasybuild_ note open mpi issu may caus hang recommend fix downgrad open mpi upgrad open mpi forc horovod instal mpi support set horovod_with_mpi environ forc horovod skip build mpi support set horovod_without_mpi mpi gloo enabl instal mpi default control gloo gloo recent control horovod requir addit depend besid cmake instal use control combin nccl gloo perform almost ident mpi standard benchmark forc horovod instal gloo support set horovod_with_gloo environ forc horovod skip build gloo support set horovod_without_gloo gloo mode use horovodrun launch worker process gloo requir use elast fault toler api horovod note maco user must instal libuv httpsgithubcomlibuvlibuv_ order use gloo codeblock bash brew instal libuv tensor oper run gpu optim perform recommend instal horovod nccl support follow horovod gpu gpusrst_ guid tensor data cpu use mpi gloo intel oneccl default framework use control use cpu oper overrid set horovod_cpu_oper environ nccl nccl support allreduc allgath broadcast alltoal oper enabl set horovod_gpu_operationsnccl instal nccl oper support nvidia cuda amd rocm gpu set horovod_gpu environ specifi build cuda rocm cuda assum specifi note alltoal requir nccl version mpi use mpi control mpi use nccl unavail tensor place host memori prior allreduc request case nccl unavail mpi shown outperform gloo cpu tensor oper mpi also use gpu oper recommend case see horovod gpu gpusrst_ detail gloo use gloo control gloo use place mpi cpu oper default oneccl oneccl intel librari acceler collect oper cpu see horovod intelr oneccl onecclrst_ detail set horovod_cpu_operationsccl use oneccl check build success instal horovod run codeblock bash horovodrun checkbuild everi featur success enabl mark x intend instal horovod featur list enabl reinstal horovod set appropri environ variabl diagnos failur codeblock bash pip uninstal horovod horovod_with_ pip instal nocachedir horovod instal horovod conda pip use conda instal pytorch tensorflow mxnet horovod well gpu depend nvidia cuda toolkit cudnn nccl etc see build conda environ gpu support horovod condarst_ environ variabl option environ variabl set configur instal process horovod possibl valu given curli bracket horovod_debug instal debug build horovod check assert disabl compil optim etc horovod_build_arch_flag addit c compil flag pass build architectur horovod_cuda_hom path cuda includ lib directori found horovod_build_cuda_cc_list list comput capabl build horovod cuda kernel exampl horovod_build_cuda_cc_list horovod_rocm_hom path rocm includ lib directori found horovod_nccl_hom path nccl includ lib directori found horovod_nccl_includ path nccl includ directori horovod_nccl_lib path nccl lib directori horovod_nccl_link share static mode link nccl librari default static cuda share rocm horovod_with_gloo requir horovod built gloo support enabl horovod_without_gloo skip build gloo support horovod_with_mpi requir horovod built mpi support enabl horovod_without_mpi skip build mpi support horovod_gpu cuda rocm framework use gpu oper horovod_gpu_oper nccl mpi framework use gpu tensor allreduc allgath broadcast horovod_gpu_allreduc nccl mpi framework use gpu tensor allreduc horovod_gpu_allgath nccl mpi framework use gpu tensor allgath horovod_gpu_broadcast nccl mpi framework use gpu tensor broadcast horovod_allow_mixed_gpu_impl allow horovod instal nccl allreduc mpi gpu allgath broadcast recommend due possibl deadlock horovod_cpu_oper mpi gloo ccl framework use cpu tensor allreduc allgath broadcast horovod_cmak path cmake binari use build gloo requir use mpi horovod_with_tensorflow requir horovod instal tensorflow support enabl horovod_without_tensorflow skip instal tensorflow support horovod_with_pytorch requir horovod instal pytorch support enabl horovod_without_pytorch skip instal pytorch support horovod_with_mxnet requir horovod instal mxnet support enabl horovod_without_mxnet skip instal mxnet support inclusionmarkerenddonotremov inclusionmarkerstartdonotremov process set concurr run collect oper horovod oper tensorflow pytorch mxnet featur process_set argument set differ process set may multipl subset world horovod process run distinct collect oper parallel besid horovod fundament oper like hvdallgath hvdallreduc hvdalltoal hvdbroadcast hvdgrouped_allreduc also mani highlevel util object hvddistributedoptim come support process set exampl consid build horovod model train four worker process two concurr allreduc oper even odd subset follow see three way configur horovod use even odd process set offer much flexibl need code exampl present tensorflow interfac support framework equival static process set codeblock python rank even_set hvdprocessset odd_set hvdprocessset hvdinitprocess_setseven_set odd_set p hvdglobal_process_set even_set odd_set printp processsetprocess_set_id rank mpi_commnon processsetprocess_set_id rank mpi_commnon processsetprocess_set_id rank mpi_commnon rank result hvdallreducetensor_for_even_rank process_seteven_set rank result hvdallreducetensor_for_odd_rank process_setodd_set initi horovod like configur process set chang without restart program use default global process set hvdglobal_process_set impact perform static process set mpi commun codeblock python rank mpipi import mpi comm mpicomm_world subcomm mpicomm_worldsplitcolormpicomm_worldrank keympicomm_worldrank split_process_set hvdprocesssetsubcomm hvdinitcomm process_setssplit_process_set p hvdglobal_process_set split_process_set printp processsetprocess_set_id rank mpi_commmpipympiintracomm object xfbdd processsetprocess_set_id rank mpi_commmpipympiintracomm object xfbeddfb split_process_set differ rank rank result hvdallreducetensor_for_even_rank process_setsplit_process_set rank result hvdallreducetensor_for_odd_rank process_setsplit_process_set alreadi use multipl mpi commun distribut program plug right dynam process set codeblock python rank hvdinitprocess_setsdynam altern set horovod_dynamic_process_set even_set hvdadd_process_set odd_set hvdadd_process_set p hvdglobal_process_set even_set odd_set printp processsetprocess_set_id rank mpi_commnon processsetprocess_set_id rank mpi_commnon processsetprocess_set_id rank mpi_commnon rank result hvdallreducetensor_for_even_rank process_seteven_set rank result hvdallreducetensor_for_odd_rank process_setodd_set flexibl setup achiev dynam process set process set regist deregist dynam time initi horovod via hvdadd_process_set hvdremove_process_set call function must made ident order process note dynam process set come slight extra synchron overhead inclusionmarkerenddonotremov inclusionmarkerstartdonotremov build conda environ gpu support horovod section describ build conda environ deep learn project use horovod enabl distribut train across multipl gpu either node spread across multupl node instal nvidia cuda toolkit instal nvidia cuda toolkit _ documentation_ recent version nvidia cuda toolkit support three deep learn framework current support horovod use cudatoolkit packag typic instal pytorch tensorflow apach mxnet gpu support use conda add appropri version cudatoolkit packag environmentyml file unfortun moment least cudatoolkit packag avail via conda includ nvidia cuda compil nvcc_ requir order build horovod extens pytorch tensorflow mxnet cudatoolkitdev packag cudatoolkitdev packag avail condaforg includ nvcc difficulti get packag consist instal properli avail build requir manual intervent accept licens agreement make build unsuit instal remot system critic function build seem work ubuntu flavor linux despit would encourag tri ad cudatoolkitdev environmentyml file see happen packag well maintain perhap becom stabl futur use nvcc_linux metapackag robust approach obtain nvcc still use conda manag depend instal nvidia cuda toolkit system instal metapackag nvcc_linux_ condaforg configur conda environ use nvcc instal system togeth cuda toolkit compon instal insid conda environ environmentyml file prefer specifi mani depend possibl conda environmentyml file specifi depend requirementstxt instal via pip avail via conda channel check horovod instal guide_ detail requir depend channel prioriti use recommend channel prioriti note condaforg prioriti default pytorch prioriti condaforg name null channel pytorch condaforg default depend thing worth note depend even though instal nvidia cuda toolkit manual still use conda manag requir cuda compon cudnn nccl option cupti use two metapackag cxxcompil nvcc_linux make sure suitabl c c compil instal result conda environ awar manual instal cuda toolkit horovod requir control librari coordin work variou horovod process typic mpi implement openmpi_ howev rather specifi openmpi packag directli instead opt mpipy_ conda packag provid cudaawar build openmpi horovod also support gloo_ collect commun librari use place mpi includ cmake insur horovod extens gloo built core requir depend complet environmentyml file avail github_ depend bokeh cmake insur gloo librari extens built cudnn cupti cxxcompil insur c c compil avail jupyterlab mpipi instal cudaawar openmpi nccl nodej nvcc_linux configur environ cudaawar pip pip mxnetcumkl mxnet instal prior horovod r filerequirementstxt python pytorch tensorboard tensorflowgpu torchvis requirementstxt file requirementstxt file pip depend includ horovod list instal addit horovod typic also use pip instal jupyterlab extens enabl gpu cpu resourc monitor via jupyterlabnvdashboard_ tensorboard support via jupytertensorboard_ horovod jupyterlabnvdashboard jupytertensorboard make sure horovod recompil environ rebuilt nobinaryhorovod note use nobinari option end file includ option ensur horovod rebuilt whenev conda environ rebuilt build conda environ ad necessari depend download via conda environmentyml file depend download via pip requirementstxt file creat conda environ subdirectori env project directori run follow command codeblock bash export env_prefixpwdenv export horovod_cuda_homecuda_hom export horovod_nccl_homeenv_prefix export horovod_gpu_operationsnccl conda env creat prefix env_prefix file environmentyml forc default horovod tri build extens detect framework see document environ variables_ detail addit environ variabl set prior build horovod new environ creat activ environ follow command codeblock bash conda activ env_prefix postbuild file wish use jupyterlab extens includ environmentyml requirementstxt file may need rebuild jupyterlab applic simplic typic includ instruct rebuild jupyterlab postbuild script script look like exampl horovod environ codeblock bash jupyt labextens instal nobuild jupyterlabnvdashboard jupyt labextens instal nobuild jupyterlab_tensorboard jupyt lab build use follow command sourc postbuild script codeblock bash conda activ env_prefix option environ alreadi activ postbuild list content conda environ see full list packag instal environ run follow command codeblock bash conda activ env_prefix option environ alreadi activ conda list verifi conda environ build conda environ check horovod built support deep learn framework tensorflow pytorch apach mxnet contol mpi gloo follow command codeblock bash conda activ env_prefix option environ alreadi activ horovodrun checkbuild see output similar follow horovod v avail framework x tensorflow x pytorch x mxnet avail control x mpi x gloo avail tensor oper x nccl ddl ccl x mpi x gloo wrap bash script typic wrap command shell script createcondaenvsh run shell script set horovod build variabl creat conda environ activ conda environ build jupyterlab addit extens codeblock bash binbash login set e export env_prefixpwdenv export horovod_cuda_homecuda_hom export horovod_nccl_homeenv_prefix export horovod_gpu_operationsnccl conda env creat prefix env_prefix file environmentyml forc conda activ env_prefix postbuild recommend put script insid bin directori project root directori run script project root directori follow codeblock bash bincreatecondaenvsh assum cuda_hom set properli updat conda environ add remov depend environmentyml file requirementstxt file environ alreadi creat recreat environ follow command codeblock bash conda env creat prefix env_prefix file environmentyml forc howev whenev add remov depend prefer rerun bash script rebuild conda environ jupyterlab codeblock bash bincreatecondaenvsh _nvidia cuda toolkit httpsdevelopernvidiacomcudadownloadarchiveupd _document httpsdocsnvidiacomcudaarch _nvidia cuda compil nvcc httpsdocsnvidiacomcudaarchivecudacompilerdrivernvccindexhtml _nvcc_linux httpsgithubcomcondaforgenvccfeedstock _instal guid httpshorovodreadthedocsioenlatestinstall_includehtml _openmpi httpswwwopenmpiorg _mpipi httpsmpipyreadthedocsioenst _gloo httpsgithubcomfacebookincubatorgloo _github httpsgithubcomkaustvislabhorovodgpudatascienceproject _jupyterlabnvdashboard httpsgithubcomrapidsaijupyterlabnvdashboard _jupytertensorboard httpsgithubcomlspvicjupyter_tensorboard _environ variabl httpshorovodreadthedocsioenlatestinstall_includehtmlenvironmentvari inclusionmarkerenddonotremoveoverview includ summaryrst startaft inclusionmarkerstartdonotremov endbefor inclusionmarkerenddonotremov api horovodtensorflow automodul horovodtensorflow automodul horovodtensorflowelast horovodtensorflowkera automodul horovodtensorflowkera automodul horovodtensorflowkerascallback specialmemb __init__ automodul horovodtensorflowkeraselast horovodkera automodul horovodkera automodul horovodkerascallback specialmemb __init__ automodul horovodkeraselast horovodtorch automodul horovodtorch automodul horovodtorchelast horovodmxnet automodul horovodmxnet horovodspark automodul horovodspark horovodsparkkera autoclass horovodsparkkeraskerasestim showinherit autoclass horovodsparkkeraskerasmodel showinherit horovodsparktorch autoclass horovodsparktorchtorchestim showinherit autoclass horovodsparktorchtorchmodel showinherit horovodsparkcommon autoclass horovodsparkcommonestimatorhorovodestim autoclass horovodsparkcommonestimatorhorovodmodel automodul horovodsparkcommonbackend showinherit automodul horovodsparkcommonstor showinherit _horovod_ray_api horovodray automodul horovodray horovodrun automodul horovodrun