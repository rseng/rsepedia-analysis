# NiTransforms
[![DOI](https://joss.theoj.org/papers/10.21105/joss.03459/status.svg)](https://doi.org/10.21105/joss.03459)
[![ISBI2020](https://img.shields.io/badge/doi-10.31219%2Fosf.io%2F8aq7b-blue.svg)](https://doi.org/10.31219/osf.io/8aq7b)
[![Deps & CI](https://github.com/poldracklab/nitransforms/actions/workflows/travis.yml/badge.svg)](https://github.com/poldracklab/nitransforms/actions/workflows/travis.yml)
[![CircleCI](https://circleci.com/gh/poldracklab/nitransforms.svg?style=svg)](https://circleci.com/gh/poldracklab/nitransforms)
[![codecov](https://codecov.io/gh/poldracklab/nitransforms/branch/master/graph/badge.svg)](https://codecov.io/gh/poldracklab/nitransforms)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/poldracklab/nitransforms/master?filepath=docs%2Fnotebooks%2F)
[![Docs](https://readthedocs.org/projects/nitransforms/badge/?version=latest)](http://nitransforms.readthedocs.io/en/latest/?badge=latest)

A development repo for [nipy/nibabel#656](https://github.com/nipy/nibabel/pull/656)

## About
Spatial transforms formalize mappings between coordinates of objects in biomedical images.
Transforms typically are the outcome of image registration methodologies, which estimate
the alignment between two images.
Image registration is a prominent task present in nearly all standard image processing
and analysis pipelines.
The proliferation of software implementations of image registration methodologies has
resulted in a spread of data structures and file formats used to preserve and communicate
transforms.
This segregation of formats precludes the compatibility between tools and endangers the
reproducibility of results.
We propose a software tool capable of converting between formats and resampling images
to apply transforms generated by the most popular neuroimaging packages and libraries
(AFNI, FSL, FreeSurfer, ITK, and SPM).
The proposed software is subject to continuous integration tests to check the
compatibility with each supported tool after every change to the code base.
Compatibility between software tools and imaging formats is a necessary bridge
to ensure the reproducibility of results and enable the optimization and evaluation
of current image processing and analysis workflows.

## Integration with *NiBabel*
*NiTransforms* started as a feature-repo spun off of *NiBabel*.
Shortly after starting with [nipy/nibabel#656](https://github.com/nipy/nibabel/pull/656), it became apparent that it was going to build up in a humongous PR nobody would be able to review as thoroughly as it would require.
Also, *NiTransforms* has many connections to BIDS/BIDS-Derivatives and its X5 format specification for transforms, which falls outside of the current scope of *NiBabel*.

The plan is to make it an isolated tool, and once it is pertinent, proceed with the integration into *NiBabel*.
Once this repository is ready for integration, we will define what can go into *NiBabel* (presumably everything, except perhaps some final details of the X5 implementation, although *NiBabel* will support the data structure at least logically).
This is to say that the chances that NiTransforms is integrated into NiBabel are high and scheduled to happen in ~2022 Q2.
# Community Guidelines

Nibabel and *NiTransforms* (a *NiBabel* feature-repo) are [NIPY](https://nipy.org) projects,
and we strive to adhere to the
[NIPY code of conduct](https://nipy.org/conduct.html), reproduced below.

The NIPY community is a community of practice devoted to the use of the Python programming language
in the analysis of neuroimaging data. The following code of conduct is a guideline for our behavior
as we participate in this community.

It is based on, and heavily inspired by a reading of the Python community code of conduct, the
Apache foundation code of conduct, the Debian code of conduct, and the Ten Principles of Burning
Man.

## The code of conduct for the NIPY community

The Neuroimaging in Python (NIPY) community is made up of members with a diverse set of skills,
personalities, background, and experiences. We welcome these differences because they are the
source of diverse ideas, solutions and decisions about our work. Decisions we make affect users,
colleagues, and through scientific results, the general public. We take these consequences
seriously when making decisions. When you are working with members of the community, we ask
you to follow these guidelines, which help steer our interactions and help keep NIPY a positive,
successful, and growing community.

### A member of the NIPY community is:

#### Open

Members of the community are open to collaboration. Be it on the reuse of data, on the
implementation of methods, on finding technical solutions, establishing best practices, and
otherwise. We are accepting of all who wish to take part in our activities, fostering an
environment where anyone can participate and everyone can make a difference.

#### Collaborative

Our work will be used by other people, and in turn we will depend on the work of others. When we
make something for the benefit of others, we are willing to explain to others how it works, so that
they can build on the work to make it even better. We are willing to provide constructive criticism
on the work of others and accept criticism of our own work, as the experiences and skill sets of
other members contribute to the whole of our efforts.

#### Inquisitive

Nobody knows everything! Asking questions early avoids many problems later, so questions are
encouraged, though they may be directed to the appropriate forum. Those who are asked should be
responsive and helpful, within the context of our shared goal of improving neuroimaging practice.

#### Considerate

Members of the community are considerate of their peers. We are thoughtful when addressing the
efforts of others, keeping in mind that often-times the labor was completed simply for the good of
the community. We are attentive in our communications, whether in person or online, and we are
tactful when approaching differing views.

#### Careful in the words we choose

We value courtesy, kindness and inclusiveness in all our interactions. Therefore, we take
responsibility for our own speech. In particular, we avoid:

 * Personal insults.
 * Violent threats or language directed against another person.
 * Sexist, racist, or otherwise discriminatory jokes and language.
 * Any form of sexual or violent material.
 * Sharing private content, such as emails sent privately or non-publicly, or unlogged forums such
   as IRC channel history.
 * Excessive or unnecessary profanity.
 * Repeated harassment of others. In general, if someone asks you to stop, then stop.
 * Advocating for, or encouraging, any of the above behaviour.

#### Concise

Keep in mind that what you write once will be read by many others. Writing a short email means
people can understand the conversation as efficiently as possible. Even short emails should always
strive to be empathetic, welcoming, friendly and patient. When a long explanation is necessary,
consider adding a summary.

Try to bring new ideas to a conversation, so that each message adds something unique to the
conversation. Keep in mind that, when using email, the rest of the thread still contains the other
messages with arguments that have already been made.

Try to stay on topic, especially in discussions that are already fairly long and complex.

#### Respectful

Members of the community are respectful. We are respectful of others, their positions, their
skills, their commitments, and their efforts. We are respectful of the volunteer and professional
efforts that permeate the NIPY community. We are respectful of the processes set forth in the
community, and we work within them. When we disagree, we are courteous and kind in raising our
issues.

## Incident Reporting

We put great value on respectful, friendly and helpful communication.

If you feel that any of our Nibabel communications lack respect, or are unfriendly or unhelpful,
please try the following steps:

* If you feel able, please let the person who has sent the email or comment that you found it
  disrespectful / unhelpful / unfriendly, and why;

* If you don't feel able to do that, or that didn't work, please contact Oscar Esteban directly
  by email (<code@oscaresteban.es>), and he will do his best to resolve it.
  If you don't feel comfortable contacting Oscar, please email Chris Markiewicz
  (<markiewicz@stanford.edu>) instead.

## Attribution

The vast majority of the above was taken from the NIPY Code of Conduct.
---
title: 'NiTransforms: A Python tool to read, represent, manipulate, and apply $n$-dimensional spatial transforms'
tags:
  - Python
  - neuroimaging
  - image processing
  - spatial transform
  - nibabel
authors:
  - name: Mathias Goncalves
    orcid: 0000-0002-7252-7771
    affiliation: 1
  - name: Christopher J. Markiewicz
    orcid: 0000-0002-6533-164X
    affiliation: "1, 2"
  - name: Stefano Moia
    orcid: 0000-0002-2553-3327
    affiliation: "4"
  - name: Satrajit S. Ghosh
    orcid: 0000-0002-5312-6729
    affiliation: "2, 3"
  - name: Russell A. Poldrack
    orcid: 0000-0001-6755-0259
    affiliation: 1
  - name: Oscar Esteban
    orcid: 0000-0001-8435-6191
    affiliation: 1
affiliations:
 - name: Department of Psychology, Stanford University, Stanford, CA, USA
   index: 1
 - name: McGovern Institute for Brain Research, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA
   index: 2
 - name: Department of Otolaryngology, Harvard Medical School, Boston, MA, USA
   index: 3
 - name: Basque Center on Cognition Brain and Language, San Sebastian, Spain
   index: 4
date: 04 November 2019
bibliography: nt.bib
---

# Introduction

Spatial transforms formalize mappings between coordinates of objects in biomedical images.
Transforms typically are the outcome of image registration methodologies, which estimate the alignment between two images.
Image registration is a prominent task present in almost any image processing workflow.

**Statement of need**. In neuroimaging, the proliferation of image registration software implementations has resulted in a disparate collection of structures and file formats used to preserve and communicate the transformation.
This assortment of formats presents the challenge of compatibility between tools and endangers the reproducibility of results.
Some tools are available that permit some conversions between formats, either within neuroimaging packages or standalone such as Convert3D [@yushkevich_open_nodate]. However, they are typically limited either in compatible packages and/or application coverage (e.g., only linear transforms).

**Summary**. _NiTransforms_ is a Python tool capable of reading and writing tranforms produced by the most popular neuroimaging software (AFNI [@cox_software_1997], FSL [@jenkinson_fsl_2012], FreeSurfer [@fischl_freesurfer_2012], ITK via ANTs [@avants_symmetric_2008], and SPM [@friston_statistical_2006]).
Additionally, the tool provides seamless conversion between these formats, as well as the ability of applying the transforms to other images.
The tool has already been integrated into _fMRIPrep_ [@esteban_fmriprep_2019], a popular neuroimaging preprocessing pipeline that leverages many of the neuroimaging software already mentioned.
_NiTransforms_ is inspired by _NiBabel_ [@brett_nibabel_2006], a Python package with a collection of tools to read, write and handle neuroimaging data, and will be included as a new module.

**Audience**. Computer vision researchers and experts using Python, developers of neuroimaging workflows built on AFNI, FSL, FreeSurfer, ITK/ANTs, or SPM, developers of neuroimaging visualization tools.

# Implementation
We first mathematically formulate the problem of spatial alignment of images and highlight common pitfalls.
We then justify the architectural design of _NiTransforms_ and describe the major elements of the implementation.

## Methods
Let $\vec{x}$ represent the coordinates of a point in the reference coordinate system $R$, and $\vec{x}'$ its projection on to another coordinate system $M$:

$T\colon R \subset \mathbb{R}^n \to M \subset \mathbb{R}^n$

$\vec{x} \mapsto \vec{x}' = f(\vec{x}).$

In an image registration problem, $M$ is a moving image from which we want to sample data in order to bring the image into spatial alignment with the reference image $R$.
Hence, $f$ here is the spatial transformation function that maps from coordinates in $R$ to coordinates in $M$.
There are a multiplicity of image registration algorithms and corresponding image transformation models to estimate linear and nonlinear transforms.

The problem has been traditionally confused by the need of _transforming_ or mapping one image (generally referred to as _moving_) into another that serves as reference, with the goal of _fusing_ the information from both.
An example of image fusion application would be the alignment of functional data from one individual's brain to the same individual's corresponding anatomical MRI scan for visualization.
Therefore, "applying a transform" entails two operations (\autoref{fig:resampling}): first, transforming the coordinates of the samples in the reference image $R$ to find their mapping $\vec{x}'$ on $M$ via $T\{\cdot\}$, and second an interpolation step, as $\vec{x}'$ will likely fall off-the-grid of the moving image $M$.
These two operations are confusing because, while the spatial transformation projects from $R$ to $M$, the data flows in reversed way after the interpolation of the values of $M$ at the mapped coordinates $\vec{x}'$.

![Resampling a 3D image via a spatial transform to fuse the information of one into another image. \label{fig:resampling}](https://github.com/poldracklab/nitransforms/raw/master/docs/_static/figure1-joss.png)

## Software Architecture

There are four main components within the tool: an `io` submodule to handle the structure of the various file formats, a `base` submodule where abstract classes are defined, a `linear` submodule implementing $n$-dimensional linear transforms, and a `nonlinear` submodule for both parametric and non-parametric nonlinear transforms.
Furthermore, _NiTranforms_ provides a straightforward _Application Programming Interface_ (API) that allows researchers to map point sets via transforms, as well as apply transforms (i.e., mapping the coordinates and interpolating the data) to data structures with ease.

To ensure the consistency and uniformity of internal operations, all transforms are defined using a left-handed coordinate system of physical coordinates.
In words from the neuroimaging domain, the coordinate system of transforms is _RAS+_ (or positive directions point to the Righthand for the first axis, Anterior for the second, and Superior for the third axis).
The internal representation of transform coordinates is the most relevant design decision, and implies that a conversion of coordinate system is necessary to correctly interpret transforms generated by other software.
When a transform that is defined in another coordinate system is loaded, it is automatically converted into _RAS+_ space.

_NiTransforms_ was developed using a test-driven development paradigm, with the
battery of tests being written prior to the software implementations.
Two categories of tests were used: unit tests and cross-tool comparison tests.
Unit tests evaluate the formal correctness of the implementation, while cross-tool
comparison tests assess the correct implementation of third-party software.
The testing suite is incorporated into a continuous integration framework, which assesses the continuity of the implementation along the development life and ensures that code changes and additions do not break existing functionalities.

# References
Contributing to *NiTransforms* (a *NiBabel* feature-repo)
=========================================================
Welcome to *NiBabel*, and the *NiTransforms* repository! We’re excited
you’re here and want to contribute.

Please see the `NiBabel Developer
Guidelines <https://nipy.org/nibabel/devel/devguide.html>`__ on our on
our `documentation website <https://nipy.org/nibabel>`__.

These guidelines are designed to make it as easy as possible to get
involved. If you have any questions that aren’t discussed in our
documentation, or it’s difficult to find what you’re looking for, please
let us know by opening an
`issue <https://github.com/poldracklab/fmriprep/issues>`__!
21.0.0 (September 10, 2021)
===========================
A first release of *NiTransforms*.
This release accompanies a corresponding `JOSS submission <https://doi.org/10.21105/joss.03459>`__.

  * FIX: Final edits to JOSS submission (#135)
  * FIX: Add mention to potential alternatives in JOSS submission (#132)
  * FIX: Misinterpretation of voxel ordering in LTAs (#129)
  * FIX: Suggested edits to the JOSS submission (#121)
  * FIX: Invalid DOI (#124)
  * FIX: Remove the ``--inv`` flag from regression ``mri_vol2vol`` regression test (#78)
  * FIX: Improve handling of optional fields in LTA (#65)
  * FIX: LTA conversions (#36)
  * ENH: Add more comprehensive comments to notebook (#134)
  * ENH: Add an ``.asaffine()`` member to ``TransformChain`` (#90)
  * ENH: Read (and apply) *ITK*/*ANTs*' composite HDF5 transforms (#79)
  * ENH: Improved testing of LTA handling - *ITK*-to-LTA, ``mri_concatenate_lta`` (#75)
  * ENH: Add *FS* transform regression (#74)
  * ENH: Add *ITK*-LTA conversion test (#66)
  * ENH: Support for transforms mappings (e.g., head-motion correction) (#59)
  * ENH: command line interface (#55)
  * ENH: Facilitate loading of displacements field transforms (#54)
  * ENH: First implementation of *AFNI* displacement fields (#50)
  * ENH: Base implementation of transforms chains (composition) (#43)
  * ENH: First implementation of loading and applying *ITK* displacements fields (#42)
  * ENH: Refactor of *AFNI* and *FSL* I/O with ``StringStructs`` (#39)
  * ENH: More comprehensive implementation of ITK affines I/O (#35)
  * ENH: Added some minimal test-cases to the Affine class (#33)
  * ENH: Rewrite load/save utilities for ITK's MatrixOffsetBased transforms in ``io`` (#31)
  * ENH: Rename ``resample()`` with ``apply()`` (#30)
  * ENH: Write tests pulling up the coverage of base submodule (#28)
  * ENH: Add tests and implementation for Displacements fields and refactor linear accordingly (#27)
  * ENH: Uber-refactor of code style, method names, etc. (#24)
  * ENH: Increase coverage of linear transforms code (#23)
  * ENH: FreeSurfer LTA file support (#17)
  * ENH: Use ``obliquity`` directly from nibabel (#18)
  * ENH: Setting up a battery of tests (#9)
  * ENH: Revise doctests and get them ready for more thorough testing. (#10)
  * DOC: Add *Zenodo* metadata record (#136)
  * DOC: Better document the *IPython* notebooks (#133)
  * DOC: Transfer ``CoC`` from *NiBabel* (#131)
  * DOC: Clarify integration plans with *NiBabel* in the ``README`` (#128)
  * DOC: Add contributing page to RTD (#130)
  * DOC: Add ``CONTRIBUTING.md`` file pointing at *NiBabel* (#127)
  * DOC: Add example notebooks to sphinx documentation (#126)
  * DOC: Add an *Installation* section (#122)
  * DOC: Display API per module (#120)
  * DOC: Add figure to JOSS draft / Add @smoia to author list (#61)
  * DOC: Initial JOSS draft (#47)
  * MAINT: Add imports of modules in ``__init__.py`` to workaround #91 (#92)
  * MAINT: Fix missing ``python3`` binary on CircleCI build job step (#85)
  * MAINT: Use ``setuptools_scm`` to manage versioning (#83)
  * MAINT: Split binary test-data out from gh repo (#84)
  * MAINT: Add Docker image/circle build (#80)
  * MAINT: Drop Python 3.5 (#77)
  * MAINT: Better config on ``setup.py`` (binary operator starting line) (#60)
  * MAINT: add docker build to travis matrix (#29)
  * MAINT: testing coverage (#16)
  * MAINT: pep8 complaints (#14)
  * MAINT: skip unfinished implementation tests (#15)
  * MAINT: pep8speaks (#13)
.. include:: ../CONTRIBUTING.rst
========
Examples
========

A collection of Jupyter Notebooks to serve as interactive tutorials.

.. toctree::
    :maxdepth: 1

    notebooks/01_preparing_images
    notebooks/02_afni_deoblique
    notebooks/isbi2020
-----------
What's new?
-----------

.. include:: ../CHANGES.rstInstallation
============
*NiTransforms* is distributed via *Pypi* and can easily be installed
within your Python distribution with::

  python -m pip install nitransforms

Alternatively, you can install the bleeding-edge version of the software
directly from the GitHub repo with::

  python -m pip install git+https://github.com/poldracklab/nitransforms.git@master

To verify the installation, you can run the following command::

  python -c "import nitransforms as nt; print(nt.__version__)"

You should see the version number.

Developers
----------
Advanced users and developers who plan to contribute with bugfixes, documentation,
etc. can first clone our Git repository::

  git clone https://github.com/poldracklab/nitransforms.git


and install the tool in *editable* mode::

  cd nitransforms
  python -m pip install -e .
.. include:: links.rst

NiTransforms
============
A development repo for `nipy/nibabel#656 <https://github.com/nipy/nibabel/pull/656>`__.

.. image:: https://img.shields.io/pypi/v/nitransforms.svg
  :target: https://pypi.python.org/pypi/nitransforms/
  :alt: Latest Version

.. image:: https://codecov.io/gh/poldracklab/nitransforms/branch/master/graph/badge.svg
  :target: https://codecov.io/gh/poldracklab/nitransforms

.. image:: https://circleci.com/gh/poldracklab/nitransforms.svg?style=svg
    :target: https://circleci.com/gh/poldracklab/nitransforms

.. image:: https://github.com/poldracklab/nitransforms/actions/workflows/travis.yml/badge.svg
    :target: https://github.com/poldracklab/nitransforms/actions

.. image:: https://img.shields.io/badge/doi-10.31219%2Fosf.io%2F8aq7b-blue.svg
    :target: https://doi.org/10.31219/osf.io/8aq7b

.. image:: https://mybinder.org/badge_logo.svg
    :target: https://mybinder.org/v2/gh/poldracklab/nitransforms/master?filepath=docs%2Fnotebooks%2F

About
-----
Spatial transforms formalize mappings between coordinates of objects in biomedical images.
Transforms typically are the outcome of image registration methodologies, which estimate
the alignment between two images.
Image registration is a prominent task present in nearly all standard image processing
and analysis pipelines.
The proliferation of software implementations of image registration methodologies has
resulted in a spread of data structures and file formats used to preserve and communicate
transforms.
This segregation of formats precludes the compatibility between tools and endangers the
reproducibility of results.
We propose a software tool capable of converting between formats and resampling images
to apply transforms generated by the most popular neuroimaging packages and libraries
(AFNI, FSL, FreeSurfer, ITK, and SPM).
The proposed software is subject to continuous integration tests to check the
compatibility with each supported tool after every change to the code base.
Compatibility between software tools and imaging formats is a necessary bridge
to ensure the reproducibility of results and enable the optimization and evaluation
of current image processing and analysis workflows.


Contents
--------

.. toctree::
    :maxdepth: 2

    installation
    examples
    contributing
    changes
    api
Library API (application program interface)
===========================================
Information on specific functions, classes, and methods for developers.

.. toctree::
   :maxdepth: 1

   _api/base
   _api/io
   _api/linear
   _api/manip
   _api/nonlinear
   _api/patched
=========================
Patched Nibabel Functions
=========================

.. automodule:: nitransforms.patched
    :members:
=============
Manipulations
=============

.. automodule:: nitransforms.manip
    :members:
=================
Linear Transforms
=================

.. automodule:: nitransforms.linear
    :members:
====================
Nonlinear Transforms
====================

.. automodule:: nitransforms.nonlinear
    :members:
====
Base
====

.. automodule:: nitransforms.base
    :members:
===
IO
===

Reading and writing of transform files.

--------
Base I/O
--------
.. automodule:: nitransforms.io.base
    :members:

-----------------
Tool Specific I/O
-----------------

^^^^
AFNI
^^^^
.. automodule:: nitransforms.io.afni
    :members:

^^^
FSL
^^^
.. automodule:: nitransforms.io.fsl
    :members:

^^^
ITK
^^^
.. automodule:: nitransforms.io.itk
    :members:

^^^^^^^^^^^^^^
FreeSurfer/LTA
^^^^^^^^^^^^^^
.. automodule:: nitransforms.io.lta
    :members:
