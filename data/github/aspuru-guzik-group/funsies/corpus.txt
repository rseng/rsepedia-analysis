funsi python librari execut engin build reproduc faulttoler distribut compos comput workflow workflow specifi pure python lightweight depend easi deploy comput cluster distribut system embed app firstclass support static analysi use mypyhttpmypylangorg check workflow workflow encod redi serverhttpsredisio execut use distribut job queue librari rqhttpspythonrqorg hash tree data structur enabl automat transpar cach increment comput sourc doc found herehttpsaspuruguzikgroupgithubiofunsi exampl funsi script found recip folderrecip instal use pip bash pip instal funsi enabl funsi cli tool well funsi python modul python support run workflow youll need redi server version x higher linux redi instal use conda bash conda instal redi pip bash pip instal redisserv system packag manag mac osx redi download use homebrew bash brew instal redi window support redi thirdparti packag obtain repositoryhttpsgithubcomtporadowskiredi test howev hello funsi run workflow three compon need connect python script describ workflow redi server hold workflow data worker process execut workflow funsi distribut three compon differ comput even connect differ time redi start use redisserv worker start use funsi worker workflow run use python run singl machin startfunsi script take care start databas worker bash startfunsi nopw worker exampl workflow script python funsi import fun reduc shell fun run shell command cmd shellsleep echo python one python reducesum output save hash address printfmi output save cmdstdouthash pythonhash workflow python run use python interpret bash python helloworldpi output save b aa fun context manag take care connect databas script execut immedi work done yet workflow lazili execut execut workflow trigger use hash use cli bash funsi execut b aa worker finish result print directli stdout use hash bash funsi cat b funsi cat aa also access within python step workflow etc shut databas worker also perform use cli bash funsi shutdown work design funsi inspir githttpsgitscmcombookenvgitinternalsgitobject ccachehttpsccachedev file variabl valu abstract provenancetrack dag structur basic file identifi entir base oper lead creation somewhat opinion design produc interest properti common workflow engin increment comput funsi automat transpar save input output file produc automat transpar checkpoint increment computinghttpsenwikipediaorgwikiincremental_comput rerun funsi script even differ machin perform comput beyond databas lookup modifi script rerun recomput chang result contrast eg make base modif date directli data histori robust chang workflow decentr workflow workflow element identifi base global index scheme make possibl gener workflow fulli dynam connect comput node merg compos dag differ databas dynam reparametr etc local file oper file encod redi instanc data directori local filesystem manag requir funsi worker even oper without perman data storag often case filedriven workflow use contain tmpfshttpsdocsdockercomstoragetmpf recov failur rais except python code worker failur miss output file error condit automat caught funsi worker provid fault toler workflow error log stderr full traceback recov databas step depend fail one propag error proven error dealt wherev appropri use techniqu function programminghttpsfsharpforfunandprofitcomrop exampl consid workflow first run cli program simul ought produc resultscsv file subsequ analyz use python function analyze_data python import funsi f sim fshellsimul datainp inpdatainpsom input outresultscsv final freduceanalyze_data simoutresultscsv normal python program analyze_data would need guard possibl resultscsv absent risk fatal except funsi script resultscsv produc replac instanc error track fail step workflow engin automat shortcircuit execut analyze_data instead forward error final way valu final provid direct error trace fail step furthermor mean analyze_data need error handl code output option error better dealt later step errorhandl approach heavili influenc resultt type rust program languagehttpsdocrustlangorgstdresult productionreadi warn funsi researchgrad code time funsi api fairli stabl howev user know databas dump yet fulli forward backwardcompat break chang like introduc new releas relat project funsi intend lightweight altern industri workflow engin apach airflowhttpsairflowapacheorg luigihttpsgithubcomspotifyluigi reli heavili awesom python librari rq libraryhttpsgithubcomrqrq loguruhttpsgithubcomdelganloguru clickhttpsclickpalletsprojectscom chevronhttpsgithubcomnoahmorrisonchevron inspir githttpsgitscmcombookenvgitinternalsgitobject ccachehttpsccachedev snakemakehttpssnakemakereadthedocsioenst targetshttpsgithubcomropenscitarget rainhttpsgithubcomsubstanticrain other comprehens list worfklow engin found herehttpsgithubcompditommasoawesomepipelin licens funsi provid mit licens contribut contribut welcom consult contributingcontributingmd file help pleas file issu bug document problem contribut funsi funsi free softwar project welcom everi kind contribut document bug report fix etc encount issu pleas fill report use github issu pagehttpsgithubcomaspuruguzikgroupfunsiesissu fix use pull request function githubhttpsgithubcomaspuruguzikgroupfunsiespul make sure commit given concis explanatori name limit file edit minim relev part alway run formatt comit describ instruct contributor repo ci workflow run test suit mypi lint etc test lint pass want run ci local push autom use nox local developmenthttpsnoxtheacodesenst instal nox python env use bash pip instal nox automat format code pass lint use bash nox rs fmt lint code run mypi type checker use bash nox rs lint nox rs mypi test run use nox rs test run test three python version instal test rather slow skip default run whole set use nox rs test cov youll need redi server instal avail path note nox take care instal packag pypi step shouldnt need anyth besid instal nox get work dev environ funsi format use blackhttpsgithubcompsfblack isorthttpspypiorgprojectisort run automat use nox describ importantli funsi static type program everi function boundari need annot note also code tri maintain much possibl function pure paradigm oper encod databas mean ad new function somewhat tricki find meddl intern describ pleas talk clavign first intern read code funsi particularli complex codebas yet fairli readabl basic summari intern architectur lowlevel workflow gener encod found _graphpyhttpsgithubcomaspuruguzikgroupfunsiesblobmastersrcfunsies_graphpi _funsiespyhttpsgithubcomaspuruguzikgroupfunsiesblobmastersrcfunsies_funsiespi former contain hash calcul getter setter data depend latter contain data structur encod oper data serial _serdespyhttpsgithubcomaspuruguzikgroupfunsiesblobmastersrcfunsies_serdespi lowest level workflow execut use runner function regist _runpyhttpsgithubcomaspuruguzikgroupfunsiesblobmastersrcfunsies_runpi call _runrun_op correct order execut well graph travers function comput _dagpyhttpsgithubcomaspuruguzikgroupfunsiesblobmastersrcfunsies_dagpi user function found uipyhttpsgithubcomaspuruguzikgroupfunsiesblobmastersrcfunsiesuipi fppyhttpsgithubcomaspuruguzikgroupfunsiesblobmastersrcfunsiesfppi other shell oper python oper etc consol entri point funsi cli command group _clipyhttpsgithubcomaspuruguzikgroupfunsiesblobmastersrcfunsies_clipi titl funsi minimalist distribut dynam workflow engin tag workflow python redi decentr comput chemistri author name cyril lavignecorrespond author orcid affili name alán aspuruguzik orcid affili affili name depart comput scienc univers toronto st georg st toronto ontario ms e canada index name chemic physic theori group depart chemistri univers toronto st georg st toronto ontario ms h canada index name vector institut artifici intellig univers ave suit toronto ontario mg canada index name lebov fellow canadian institut advanc research cifar univers ave toronto ontario mg canada index date april bibliographi paperbib summari largescal highthroughput comput investig increasingli common chemistri physic recent comput chemistri primarili perform use allinon monolith softwar packag smith aquilant kuhn apra barca romero howev limit individu program becom evid tackl complex multifacet problem increasingli common use multipl dispar softwar packag singl comput pipelin often stitch togeth use shell script languag bash use python interpret languag complex comput pipelin difficult scale autom often includ manual step signific humanintheloop tune shell script error often undetect compromis scientif result convers exceptionbas error handl standard approach python readili bring comput workflow halt except properli caught weimer funsi set python program modul describ execut analyz comput workflow firstclass support shell script includ lightweight decentr workflow engin back nosql store use funsi extern program pythonbas comput easili mix togeth error detect propag throughout comput automat transpar increment comput base hash tree data structur provid conveni environ iter prototyp comput expens workflow statement need modern workflow manag program use privat sector apach airflow uber cadenc robust extrem scalabl difficult deploy scientif workflow manag system mani compil awesome_pipelin systemat review molder_sustainable_ easier set highperform comput cluster tune need specif disciplin bioinformat machin learn includ exampl use configur file format yaml json etc packag tool exampl conda docker lockedin comput provid amazon web servic googl cloud storag format may common specif scientif field throughout greater commun group research program want avail lightweight workflow manag system could readili deploy new vari comput facil local workstat minim effort system support exist shellbas pythonbas script flexibl enough rapid prototyp way largescal comput campaign provid embedd solut bundl within softwar lavigne_automatic_ final look tool could integr data gener storag avoid common practic transform filesystem effect schemaless databas develop funsi address need featur implement funsi python librari set associ commandlin tool use funsi librari gener comput workflow describ lazili evalu python code oper funsi taken pure oper output entir sole determin input workflow orchestr use python manipul pointer yettobecalcul data workflow instruct transpar translat save graph element redi databas comput evalu initi user ask specif output valu task graph final output walk back way oper depend initi oper queu execut lightweight worker process instanti command line local remot machin connect redi databas start execut workflow oper worker check output alreadi cach execut associ function save output enqueu depend execut worker way entir comput graph evalu distribut decentr fashion without schedul manag program error workflow handl use function approach inspir rust klabnik_rust_ specif except propag workflow step cancel depend task without interrupt valid workflow branch provid easi error trace high degre fault toler main distinguish featur funsi hash tree structur use encod oper input causal hash approach use funsi also found snakemak molder_sustainable_ option compon defunct koji workflow system maymounkov_koji_ part nix packag manag dolstra_nix_ git version control system chacon_pro_ funsi replac filesystem oper hash address oper io oper depend track everi oper hash address comput hash valu depend hash identifi associ oper data way consist data depend strongli enforc chang data oper automat transpar propag chang singl depend caus rehash depend effect produc new workflow associ data need recomput altern data alreadi exist specif hash address gener oper produc hash way hash tree structur enabl transpar automat increment recomput use hash address also enabl decentr reli unlikeli hash collis stevens_first_ elimin central lock import advantag approach allow worker process gener workflow task dynam result dynam workflow collect use workflow descript provid reduc number output known compil time techniqu similar mapreduc dean_mapreduce_ publish one project pollic use earlier iter funsi use multipl ongo inquiri provid sever sampl workflow github focu comput chemistri quantum comput highperform comput infrastructur intend maintain funsi cours welcom collabor contributor around worldhttpsgithubcomaspuruguzikgroupfunsiesblobmastercontributingmd acknowledg acknowledg test earli user chertian ser kjell jorner gabriel do passo gome cl also thank chri crebold help set document page acknowledg defens advanc research project agenc darpa acceler molecular discoveri program cooper agreement hr date august content inform present work necessarili reflect posit polici govern ag thank dr ander g frøseth gener support ag also acknowledg gener support natur resourc canada canada research chair program thank comput canada provid comput resourc refer funsi workflow written pure python save redishttpsredisio distribut inmemori data store workflow execut perform use minim distribut queu librari rqhttpspythonrqorg workflow automat parallel comput increment commandlin tool provid allow funsi easili integr preexist shell workflow increment comput cach gener hash step requir gener file object workflow encod use merkl treehttpsenwikipediaorgwikimerkle_tre data structur similar use ccachehttpsccachedevmanualhtml_how_ccache_work increment comput distribut version control system mercurialhttpsericsinkcomvcbehtmlrepository_structurehtml workflow written pure python use set primit shell command use shell function python glue code encod py error handl use function program errorsresult monad inspir rusthttpsdocrustlangorgstdresult practic python code rais except shell command fail specifc branch without compromis execut whole workflow origin error readili trace funsi exampl show exampl funsi script use funsi slurm comput chemistryslurmconformersreadmemd implement mergesort funsi dynam workflowsillyreadmemd funsi slurm major reason funsi creat orchestr comput expens complic workflow highperform comput center effect funsi tri fill nich fullblown workflow engin like airflowhttpsairflowapacheorg hastili stitch togeth piec bash script gnu parallelhttpswwwgnuorgsoftwareparallel fortran recip describ integr funsi slurmhttpsslurmschedmdcomdocumentationhtml de facto standard resourc manag scientif comput cluster problem statement molecul usual repres simpl stick diagram obvious dont move paper give impress static that case real life molecul dynam entiti freeli flop around vacuum stabl geometri molecul potenti energi minima rapidli interconvert room temperatur call conform floppier molecul conform problem use funsi comput conform energi floppi molecul verifi conform interconvert room temperatur comput workflow comput workflow start smile represent alkan diol use openbabelhttpopenbabelorgwikimain_pag systemat find conform optim conform xtbhttpsgithubcomgrimmelabxtb sort output result json file entir workflow workflowpyworkflowpi workflow contain dynam workflow gener account fact number conform initi known shell command python function deploy execut deploy first setup conda environ bash conda creat n funsi conda instal c condaforg xtb openbabel conda instal redisserv pip instal funsi creat environ xtb openbabel funsi depend setup submit use standard slurm submiss scriptslurmsubmitsh bash sbatch slurmsubmitsh header submiss script modifi match slurm account submiss script instanti redi server start number worker individu comput node tell worker process find server run python workflow shutdown worker server line shell final step job dump imag redi databas resultsrdb imag includ temporari result run mock version comput simpli renam copi file dumprdb start server exampl bash cp resultsrdb dumprdb redisserv python workflowpi run workflow local without recomput anyth look comput graph use graphviz one simpli bash cp resultsrdb dumprdb redisserv funsi graph graphdot dot tpdf graphdot graphpdf gener graph shown heregraphpdf mergesort funsiesbas implementationmergesortpi mergesort algorithm use recurs quit possibl least effici way sort list integ parallel though demonstr quit effect dynam dag gener attach script sort random list integ requir nest workflow gener recurs dynam final graph rather interestinggraphpdf main challeng toy exampl termin recurs without explicitli extract funsi data euhm perform reason use error propag basic nest subworkflow rais stoprecurs except less element present stop recurs deeper get basic recurs nest mapreducehttpshadoopapacheorgdocscurrenthadoopmapreduceclienthadoopmapreduceclientcoremapreducetutorialhtml although rather silli similar approach could conceiv use largescal search problem use divideandconqu algorithmhttpsenwikipediaorgwikibisection_method also demonstr funsi use pure python problem