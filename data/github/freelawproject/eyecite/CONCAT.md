You can find our VDP here: https://free.law/vulnerability-disclosure-policy/
# Change Log

## Upcoming

The following changes are not yet released, but are code complete:

Features:
 - None yet

Changes:
 - None yet

Fixes:
 - Initial support for finding short cites with non-standard regexes, including fixing short cite extraction for `Mich.`, `N.Y.2d` and `Pa.`. 

## Current

**2.3.0 - 2021-09-23**

Features:
 - Greatly improved documentation
 - Autogenerated documentation

Changes:
 - This version lands one more iteration of the APIs to make them more consistent. Sorry. Hopefully this will be the last of its kind for a while. The need for these changes became obvious when we began generating documentation. The changes are all in name only, not in functionality. So: 1) the `annotate` function is renamed as `annotate_citations`; 2) The `find_citations` module has been renamed `find` (so, do `from eyecite.find import get_citations` instead of `from eyecite.find_citations import get_citations`); 3) The `cleaners` module is now named `clean`; and 4) The `clean_text` function has been moved from `utils` to `clean` (so, do `from eyecite.clean import clean_text` instead of `from eyecite.utils import clean_text`). 


**2.2.0 - 2021-06-04**

Features:
 - Adds support for parsing statutes and journals and includes new json files with associated regular expressions and data. This introduces `FullLawCitation` and `FullJournalCitation`.
 - Id and Supra citations now have a `metadata.parenethical` attribute, to mirror `FullCaseCitation` objects and make them more useful. [PR #71][71]
 - A new tool, `dump_citations()` is added to inspect extracted citations.
 - The readme is updated with a new tutorial.
 - We now use page-based heuristics while looking up the citation that a pin cite refers to. For example, if an opinion says:

    > 1 U.S. 200. blah blah. 2 We Missed This 20. blah blah. Id. at 22.
   
    We might miss the second citation for whatever reason. The pin cite refers to the second citation, not the first, and you can be sure of that because the first citation begins on page 200 and the pin cite references page 22. When resolving the pin cite, we will no longer link it up to the first citation.
   
    Similarly, an analysis of the Caselaw Access Project's dataset indicates that all but the longest ~300 cases are shorter than 150 pages, so we also now ignore pin cites that don't make sense according to that heuristic. For example, this (made up) pin cite is also likely wrong because it's overwhelmingly unlikely that `1 U.S. 200` is 632 pages long:

    > 1 U.S. 200 blah blah 1 U.S. 832
 
    The longest case in the Caselaw Access Project collection is [United States v. Philip Morris USA, Inc](https://cite.case.law/f-supp-2d/449/1/), at 986 pages, in case you were wondering. Figures. 
   
    [Issue #74][74], [PR #79][79].

Changes:
 - To harmonize the API while adding laws and journals, a large API reorganization was completed. See [PR 64][64] for discussion. Here are the details:
    - All of the metdata that we capture before and after each citation is now organized into a `metadata` object. Thus, if they make sense for the citation type, all of the following attributes are now in `some_citation.metadata`: `publisher`, `day`, `month`, `antecedent_guess`, `court`, `extra`, `defendant`, `plaintiff`, `parenthetical`, `pin_cite`.
    - The `canonical_reporter` attribute is removed from citation objects. It wasn't used much and was duplicated in `edition_guess.reporter.short_name`. Where applicable, use that instead going forward.
     - The `reporter_found` attribute is removed from citation objects in favor of `groups['reporter']`.
     - Similarly, the `volume` and `page` attributes are removed from citation objects in favor of `groups["volume"]`and `groups["page"]`.
     - The `reporter` attribute has been removed from citations and replaced with the `corrected_reporter()` method.
     - Similarly, the `base_citation()` method has been renamed as `corrected_citation()`, and the `formatted()` method has been renamed as `corrected_citation_full()`.
     - The `do_defendant` and `do_post_citation` arguments to `get_citations` have been removed. They're fast enough to just always do. No need to think about these further.\
     - The `resolve_fullcase_citation` parameter in the `resolve_citations` function has been renamed to `resolve_full_citation`.  

Fixes:
 - Support for reporter citations with `volume=None` is added. Some reporters don't use volumes, for example, "Bankr. L. Rep. (CCH) P12,345".
 - Upgrades courts-db subdependency to latest that provides lazy-loading. This should speed up imports of eyecite.

[64]: https://github.com/freelawproject/eyecite/pull/64
[71]: https://github.com/freelawproject/eyecite/pull/71
[74]: https://github.com/freelawproject/eyecite/issues/74
[79]: https://github.com/freelawproject/eyecite/pull/79


## Past

**2.1.0 - 2021-05-13**

Features:
 - Adds support for resolving id, supra, and short form citations into
   their targets. See readme for details on "Resolving Citations."
 - Pin cites are now matched across more citation types.
 - Summarizing parentheticals are now included in the match.

Changes:
 - The shape of various citation objects has changed to better handle pages and
   pin citations. See #61 for details.

Fixes:
 - Fixes crashing errors on some partial supra, id, and short form citations.
 - Fixes unbalanced tags created by annotation.
 - Fixes year parsing to move away from `isdigit`, which can capture 
   unicode superscript numbers like "123 U.S. 456 (196โด)"
 - Allow years all the way back to 1600 instead of 1754. Anybody got a citation
   from before then?
 - Page number matching is tightened to be much more strict about how it 
   matches Roman numerals. This change will prevent some citations from being 
   matched if they have extremely common Roman numerals. See #56 for a full 
   discussion.
   
**2.0.2** - Adds missing dependency to toml file, nukes setup.py and
requirements.txt. We're now fully in the poetry world.

**2.0.1** - Major rewrite to efficiently build and use hundreds of regular
expressions to parse the text, and to use merging algorithms to annotate it.
These changes bring better speed, accuracy, and flexibility to the library.

**2.0.0** - Broken, bad release process.

**1.1.0** - Standardize the `__eq__()` and `__hash__()` methods and remove the
unused fuzzy_hash() method.

**0.0.1** - Initial release with CL-compatible API.

**0.0.1 to 0.0.5** - Continuous deployment debugging
eyecite
==========

eyecite is an open source tool for extracting legal citations from text. It is used, among other things, to process millions of legal documents in the collections of `CourtListener <https://www.courtlistener.com/>`_ and Harvard's `Caselaw Access Project <https://case.law/>`_, and has been developed in collaboration with both projects.

eyecite recognizes a wide variety of citations commonly appearing in American legal decisions, including:

* full case: ``Bush v. Gore, 531 U.S. 98, 99-100 (2000)``
* short case: ``531 U.S., at 99``
* statutory: ``Mass. Gen. Laws ch. 1, ยง 2``
* law journal: ``1 Minn. L. Rev. 1``
* supra: ``Bush, supra, at 100``
* id.: ``Id., at 101``

All contributors, corrections, and additions are welcome!

Functionality
=============

eyecite offers four core functions:

* `Extraction <https://freelawproject.github.io/eyecite/find.html>`_: Recognize and extract citations from text, using a database that has been trained on over 55 million existing citations (see all of the citation patterns eyecite looks for over in `reporters_db <https://github.com/freelawproject/reporters-db>`_).
* `Aggregation <https://freelawproject.github.io/eyecite/resolve.html>`_: Aggregate citations with common references (e.g., `supra` and `id.` citations) based on their logical antecedents.
* `Annotation <https://freelawproject.github.io/eyecite/annotate.html>`_: Annotate citation-laden text with custom markup surrounding each citation, using a fast diffing algorithm.
* `Cleaning <https://freelawproject.github.io/eyecite/clean.html>`_: Clean and pre-process text for easy use with eyecite.

Read on below for how to get started quickly or for a short tutorial in using eyecite.

Contributions & Support
=======================

Please see the issues list on GitHub for things we need, or start a conversation if you have questions or need support.

If you are fixing bugs or adding features, before you make your first contribution, we'll need a signed contributor license agreement. See the template in the root of the repo for how to get that taken care of.

API
===
The API documentation is located here:

https://freelawproject.github.io/eyecite/

It is autogenerated whenever we release a new version. Unfortunately, for now we do not support old versions of the API documentation, but it can be browsed in the gh-pages branch if needed.


Quickstart
==========

Install eyecite::

    pip install eyecite


Here's a short example of extracting citations and their metadata from text using eyecite's main :code:`get_citations()` function::

    from eyecite import get_citations

    text = """
        Mass. Gen. Laws ch. 1, ยง 2 (West 1999) (barring ...).
        Foo v. Bar, 1 U.S. 2, 3-4 (1999) (overruling ...).
        Id. at 3.
        Foo, supra, at 5.
    """

    get_citations(text)

    # returns:
    [
        FullLawCitation(
            'Mass. Gen. Laws ch. 1, ยง 2',
            groups={'reporter': 'Mass. Gen. Laws', 'chapter': '1', 'section': '2'},
            metadata=Metadata(parenthetical='barring ...', pin_cite=None, year='1999', publisher='West', ...)
        ),
        FullCaseCitation(
            '1 U.S. 2',
            groups={'volume': '1', 'reporter': 'U.S.', 'page': '2'},
            metadata=Metadata(parenthetical='overruling ...', pin_cite='3-4', year='1999', court='scotus', plaintiff='Foo', defendant='Bar,', ...)
        ),
        IdCitation(
            'Id.',
            metadata=Metadata(pin_cite='at 3')
        ),
        SupraCitation(
            'supra,',
            metadata=Metadata(antecedent_guess='Foo', pin_cite='at 5', ...)
        )
    ]

Tutorial
==========

For a more full-featured walkthrough of how to use all of eyecite's functionality,
please see the `tutorial <TUTORIAL.ipynb>`_.

Documentation
=============

eyecite's full API is documented `here <https://freelawproject.github.io/eyecite/>`_, but here are details regarding its four core functions, its tokenization logic, and its debugging tools.

Extracting Citations
--------------------

:code:`get_citations()`, the main executable function, takes three parameters.

1. :code:`plain_text` ==> str: The text to parse. Should be cleaned first.
2. :code:`remove_ambiguous` ==> bool, default :code:`False`: Whether to remove citations
   that might refer to more than one reporter and can't be narrowed down by date.
3. :code:`tokenizer` ==> Tokenizer, default :code:`eyecite.tokenizers.default_tokenizer`: An instance of a Tokenizer object (see "Tokenizers" below).


Cleaning Input Text
-------------------

For a given citation text such as "... 1 Baldwin's Rep. 1 ...", eyecite expects that the text
will be "clean" before being passed to :code:`get_citation`. This means:

* Spaces will be single space characters, not multiple spaces or other whitespace.
* Quotes and hyphens will be standard quote and hyphen characters.
* No junk such as HTML tags inside the citation.

You can use :code:`clean_text` to help with this:

::

    from eyecite import clean_text, get_citations

    source_text = '<p>foo   1  U.S.  1   </p>'
    plain_text = clean_text(text, ['html', 'inline_whitespace', my_func])
    found_citations = get_citations(plain_text)

See the `Annotating Citations <#annotating-citations>`_ section for how to insert links into the original text using
citations extracted from the cleaned text.

:code:`clean_text` currently accepts these values as cleaners:

1. :code:`inline_whitespace`: replace all runs of tab and space characters with a single space character
2. :code:`all_whitespace`: replace all runs of any whitespace character with a single space character
3. :code:`underscores`: remove two or more underscores, a common error in text extracted from PDFs
4. :code:`html`: remove non-visible HTML content using the lxml library
5. Custom function: any function taking a string and returning a string.


Annotating Citations
--------------------

For simple plain text, you can insert links to citations using the :code:`annotate` function:

::

    from eyecite import get_citations, annotate

    plain_text = 'bob lissner v. test 1 U.S. 12, 347-348 (4th Cir. 1982)'
    citations = get_citations(plain_text)
    linked_text = annotate(plain_text, [[c.span(), "<a>", "</a>"] for c in citations])

    returns:
    'bob lissner v. test <a>1 U.S. 12</a>, 347-348 (4th Cir. 1982)'

Each citation returned by get_citations keeps track of where it was found in the source text.
As a result, :code:`annotate` must be called with the *same* cleaned text used by :code:`get_citations`
to extract citations. If you do not, the offsets returned by the citation's :code:`span` method will
not align with the text, and your annotations will be in the wrong place.

If you want to clean text and then insert annotations into the original text, you can pass
the original text in as :code:`source_text`:

::

    from eyecite import get_citations, annotate, clean_text

    source_text = '<p>bob lissner v. <i>test   1 U.S.</i> 12,   347-348 (4th Cir. 1982)</p>'
    plain_text = clean_text(source_text, ['html', 'inline_whitespace'])
    citations = get_citations(plain_text)
    linked_text = annotate(plain_text, [[c.span(), "<a>", "</a>"] for c in citations], source_text=source_text)

    returns:
    '<p>bob lissner v. <i>test   <a>1 U.S.</i> 12</a>,   347-348 (4th Cir. 1982)</p>'

The above example extracts citations from :code:`plain_text` and applies them to
:code:`source_text`, using a diffing algorithm to insert annotations in the correct locations
in the original text.

Wrapping HTML Tags
^^^^^^^^^^^^^^^^^^

Note that the above example includes mismatched HTML tags: "<a>1 U.S.</i> 12</a>".
To specify handling for unbalanced tags, use the :code:`unbalanced_tags` parameter:

* :code:`unbalanced_tags="skip"`: annotations that would result in unbalanced tags will not be inserted.
* :code:`unbalanced_tags="wrap"`: unbalanced tags will be wrapped, resulting in :code:`<a>1 U.S.</a></i><a> 12</a>`

Important: :code:`unbalanced_tags="wrap"` uses a simple regular expression and will only work for HTML where
angle brackets are properly escaped, such as the HTML emitted by :code:`lxml.html.tostring`. It is intended for
regularly formatted documents such as case text published by courts. It may have
unpredictable results for deliberately-constructed challenging inputs such as citations containing partial HTML
comments or :code:`<pre>` tags.

Customizing Annotation
^^^^^^^^^^^^^^^^^^^^^^

If inserting text before and after isn't sufficient, supply a callable under the :code:`annotator` parameter
that takes :code:`(before, span_text, after)` and returns the annotated text:

::

    def annotator(before, span_text, after):
        return before + span_text.lower() + after
    linked_text = annotate(plain_text, [[c.span(), "<a>", "</a>"] for c in citations], annotator=annotator)

    returns:
    'bob lissner v. test <a>1 u.s. 12</a>, 347-348 (4th Cir. 1982)'

Resolving Citations
-------------------

Once you have extracted citations from a document, you may wish to resolve them to their common references.
To do so, just pass the results of :code:`get_citations()` into :code:`resolve_citations()`. This function will
do its best to resolve each "full," "short form," "supra," and "id" citation to a common :code:`Resource` object,
returning a dictionary that maps resources to lists of associated citations:

::

    from eyecite import get_citations, resolve_citations

    text = 'first citation: 1 U.S. 12. second citation: 2 F.3d 2. third citation: Id.'
    found_citations = get_citations(text)
    resolved_citations = resolve_citations(found_citations)

    returns (pseudo):
    {
        <Resource object>: [FullCaseCitation('1 U.S. 12')],
        <Resource object>: [FullCaseCitation('2 F.3d 2'), IdCitation('Id.')]
    }

Importantly, eyecite performs these resolutions using only its immanent knowledge about each citation's
textual representation. If you want to perform more sophisticated resolution (e.g., by augmenting each
citation with information from a third-party API), simply pass custom :code:`resolve_id_citation()`,
:code:`resolve_supra_citation()`, :code:`resolve_shortcase_citation()`, and :code:`resolve_full_citation()`
functions to :code:`resolve_citations()` as keyword arguments. You can also configure those functions to
return a more complex resource object (such as a Django model), so long as that object inherits the
:code:`eyecite.models.ResourceType` type (which simply requires hashability). For example, you might implement
a custom full citation resolution function as follows, using the default resolution logic as a fallback:

::

    def my_resolve(full_cite):
        # special handling for resolution of known cases in our database
        resource = MyOpinion.objects.get(full_cite)
        if resource:
            return resource
        # allow normal clustering of other citations
        return resolve_full_citation(full_cite)

    resolve_citations(citations, resolve_full_citation=my_resolve)

    returns (pseudo):
    {
        <MyOpinion object>: [<full_cite>, <short_cite>, <id_cite>],
        <Resource object>: [<full cite>, <short cite>],
    }

Tokenizers
----------

Internally, eyecite works by applying a list of regular expressions to the source text to convert it to a list
of tokens:

::

    In [1]: from eyecite.tokenizers import default_tokenizer

    In [2]: list(default_tokenizer.tokenize("Foo v. Bar, 123 U.S. 456 (2016). Id. at 457."))
    Out[2]:
    ['Foo',
     StopWordToken(data='v.', ...),
     'Bar,',
     CitationToken(data='123 U.S. 456', volume='123', reporter='U.S.', page='456', ...),
     '(2016).',
     IdToken(data='Id.', ...),
     'at',
     '457.']

Tokens are then scanned to determine values like the citation year or case name for citation resolution.

Alternate tokenizers can be substituted by providing a tokenizer instance to :code:`get_citations()`:

::

    from eyecite.tokenizers import HyperscanTokenizer
    hyperscan_tokenizer = HyperscanTokenizer(cache_dir='.hyperscan')
    cites = get_citations(text, tokenizer=hyperscan_tokenizer)

test_FindTest.py includes a simplified example of using a custom tokenizer that uses modified
regular expressions to extract citations with OCR errors.

eyecite ships with two tokenizers:

AhocorasickTokenizer (default)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The default tokenizer uses the pyahocorasick library to filter down eyecite's list of
extractor regexes. It then performs extraction using the builtin :code:`re` library.

HyperscanTokenizer
^^^^^^^^^^^^^^^^^^

The alternate HyperscanTokenizer compiles all extraction regexes into a hyperscan database
so they can be extracted in a single pass. This is far faster than the default tokenizer
(exactly how much faster depends on how many citation formats are included in the target text),
but requires the optional :code:`hyperscan` dependency that has limited platform support.
See the "Installation" section for hyperscan installation instructions and limitations.

Compiling the hyperscan database takes several seconds, so short-running scripts may want to
provide a cache directory where the database can be stored. The directory should be writeable
only by the user:

::

    hyperscan_tokenizer = HyperscanTokenizer(cache_dir='.hyperscan')


Debugging
---------

If you want to see what metadata eyecite is able to extract for each citation, you can use :code:`dump_citations`.
This is primarily useful for developing eyecite, but may also be useful for exploring what data is available to you::

    In [1]: from eyecite import dump_citations, get_citations

    In [2]: text="Mass. Gen. Laws ch. 1, ยง 2. Foo v. Bar, 1 U.S. 2, 3-4 (1999). Id. at 3. Foo, supra, at 5."

    In [3]: cites=get_citations(text)

    In [4]: print(dump_citations(get_citations(text), text))
    FullLawCitation: Mass. Gen. Laws ch. 1, ยง 2. Foo v. Bar, 1 U.S. 2, 3-4 (1
      * groups
        * reporter='Mass. Gen. Laws'
        * chapter='1'
        * section='2'
    FullCaseCitation: Laws ch. 1, ยง 2. Foo v. Bar, 1 U.S. 2, 3-4 (1999). Id. at 3. Foo, s
      * groups
        * volume='1'
        * reporter='U.S.'
        * page='2'
      * metadata
        * pin_cite='3-4'
        * year='1999'
        * court='scotus'
        * plaintiff='Foo'
        * defendant='Bar,'
      * year=1999
    IdCitation: v. Bar, 1 U.S. 2, 3-4 (1999). Id. at 3. Foo, supra, at 5.
      * metadata
        * pin_cite='at 3'
    SupraCitation: 2, 3-4 (1999). Id. at 3. Foo, supra, at 5.
      * metadata
        * antecedent_guess='Foo'
        * pin_cite='at 5'

In the real terminal, the :code:`span()` of each extracted citation will be highlighted.
You can use the :code:`context_chars=30` parameter to control how much text is shown before and after.


Installation
============
Installing eyecite is easy.

::

    poetry add eyecite


Or via pip::

    pip install eyecite


Or install the latest dev version from github::

    pip install https://github.com/freelawproject/eyecite/archive/main.zip#egg=eyecite

Hyperscan installation
----------------------

To use :code:`HyperscanTokenizer` you must additionally install the python `hyperscan <https://pypi.org/project/hyperscan/>`_
library and its dependencies. **python-hyperscan officially supports only x86 linux,** though other configurations may be
possible.

Hyperscan installation example on x86 Ubuntu 20.04:

::

    apt install libhyperscan-dev
    pip install hyperscan

Hyperscan installation example on x86 Debian Buster:

::

    echo 'deb http://deb.debian.org/debian buster-backports main' > /etc/apt/sources.list.d/backports.list
    apt install -t buster-backports libhyperscan-dev
    pip install hyperscan

Hyperscan installation example with homebrew on x86 MacOS:

::

    brew install hyperscan
    pip install hyperscan


Deployment
==========

1. Update version info in :code:`pyproject.toml`.

For an automated deployment, tag the commit with vx.y.z, and push it to master.
An automated deploy and documentation update will be completed for you.

For a manual deployment, run:

::

    poetry publish --build

You will probably also need to push new documentation files to the gh-pages branch.

Testing
=======
eyecite comes with a robust test suite of different citation strings that it is equipped to handle. Run these tests as follows:

::

    python3 -m unittest discover -s tests -p 'test_*.py'

If you would like to create mock citation objects to assist you in writing your own local tests, import and use the following functions for convenience:

::

    from eyecite.test_factories import (
        case_citation,
        id_citation,
        nonopinion_citation,
        supra_citation,
    )


License
=======
This repository is available under the permissive BSD license, making it easy and safe to incorporate in your own libraries.

Pull and feature requests welcome. Online editing in GitHub is possible (and easy!).
