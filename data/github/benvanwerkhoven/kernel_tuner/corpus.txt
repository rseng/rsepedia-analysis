chang log notabl chang project document file project adher semant versioninghttpsemverorg unreleas ad new optim strategi dual anneal greedli il order greedi ml greedi ml support constant memori cupi backend remov altern bayesian optim strategi could use directli c wrapper modul specif hardli use ad support pytorch tensor input data type kernel support smem_arg run_kernel support lambda function string dynam share memori size new bayesian optim strategi chang option store kernel_str store_result improv report skip configur ad support lambda function instead list string restrict support lambda function instead list specifi grid divisor support lambda function instead tupl specifi problem_s function store top tune result function creat header file devic target store result support use tune result pythonkernel option control measur use observ support nvml tunabl paramet option simul autotun search exist cach file cupi backend support c templat cuda kernel support templat cuda kernel use pycuda backend document tunabl paramet vocabulari ad support loop unrol use param start loop_unroll_factor alway insert defin kernel_tun allow preprocessor ifdef kernel_tun support userdefin metric support choos optim start point x strategi chang compact output print termin sequenti runner run first kernel paramet space warm devic updat tutori demonstr use userdefin metric ad kernelbuild function includ kernel python applic smem_arg option dynam alloc share memori cuda kernel chang bugfix nvidia devic without intern current sensor chang fix output check custom verifi function call benchmark return multipl result time sophist implement genet algorithm strategi method option pass use strategy_opt ad bayesian optimizaton strategi use strategybayes_opt support kernel use textur memori cuda support measur energi consumpt cuda kernel option set strategy_opt pass strategi specif option option cach restart tune kernel configur cachefil remov python support may still work longer test python noodl parallel runner chang longer replac kernel name instanc string tune bugfix tempfil creation lead mani open file error ad minim fortran exampl basic fortran support particl swarm optim strategi use strategypso simul anneal strategi use strategysimulated_ann firefli algorithm strategi use strategyfirefly_algorithm genet algorithm strategi use strategygenetic_algorithm chang bugfix c backend byte array argument argument type mismatch throw warn instead except ad wrapper function wrap c function citat file zenodo doi gener releas chang bugfix use iter smaller instal procedur use extra eg cudaopencl option quiet make tune_kernel complet quiet extens updat document ad type check kernel argument answer list check reserv keyword tunabl paramt check whether thread block dimens specifi print unit measur time cuda opencl option print measur execut time chang bugfix instal scipi present bugfix gpu cleanup use noodl runner rework way string handl intern ad option set compil name use c backend chang activ free gpu memori tune bugfix grid use opencl ad support dynam parallel use pycuda option use differenti evolut optim global optim strategi basinhop minim chang option pass fraction sampl runner fix bug memset opencl backend ad parallel tune singl node use noodl runner option pass new default block dimens option pass python function code gener option pass custom function output verif chang devic kernel name print runner tune_kernel also return dict environ info use differ timer c vector add exampl chang chang scalar argument handl intern ad separ instal contribut guid chang allow nontupl problem_s grid chang default grid_div_i none block_size_i convert tutori jupyt notebook cuda backend print devic use similar opencl backend migrat nosetest pytest rewrot mani exampl save result json file ad full support grid includ option grid_div_z separ convolut exampl chang chang output format list dictionari ad option set compil option chang verbos also print debug output correct check fail restructur util function util core restructur code prepar differ strategi shorten output print tune_kernel allow numpi integ specifi problem size ad public roadmap requirementstxt exampl show gpu code unit test kernel tuner support pass list filenam instead kernel string runner take random sampl percent support opencl platform select support use tune paramet name problem size ad function type check argument kernel exampl convolut tune number stream devic interfac c function tune host code correct check kernel tune function run singl kernel instanc changelog file comput cartesian product process restrict main loop python compat code thank berend support constant memori argument cuda kernel use mock unittest report coverag codaci opencl support document page convolut matrix multipli exampl inspect devic properti runtim basic kernel tune function roadmap kernel tuner roadmap present overview featur current plan implement pleas note live document evolv prioriti grow shift version allow strategi tune metric time version multiobject optim version function implement version may alreadi implement earlier version tune kernel parallel set node gpu cluster function includ autotun kernel applic wish list thing would like implement current immedi demand interest let us know provid api analysi tune result tune compil option combin paramet exampl tune kernel use thread block reindex extend fortran support warn data type miss block size paramet etc turn c backend gener compil backend get_parameterized_kernel_sourc function return parameter kernel sourc inspect function gener wrapper kernel directli callingtest devic function notebook part kernel tuner document pageshttpsbenvanwerkhovengithubiokernel_tun materi belong instructorl tutori kernel tuner pleas see separ kernel tuner tutori repositoryhttpsgithubcombenvanwerkhovenkernel_tuner_tutori