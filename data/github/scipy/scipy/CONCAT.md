
pypocketfft version
-------------------

SciPy currently vendors [pypocketfft] at:

    commit bf2c431c21213b7c5e23c2f542009b0bd3ec1445
    Merge: 8234f5c 9c252b2
    Author: Martin Reinecke <martin@mpa-garching.mpg.de>
    Date:   Tue Oct 20 15:16:14 2020 +0200

        Merge branch 'good_size_keywords' into 'master'

        Handle keyword args in good_size

        See merge request mtr/pypocketfft!41

pypocketfft: https://gitlab.mpcdf.mpg.de/mtr/pypocketfft
pypocketfft
===========

This package provides Fast Fourier, trigonometric, and Hartley transforms with a
simple Python interface.

The central algorithms are derived from Paul Swarztrauber's FFTPACK code
(http://www.netlib.org/fftpack).

Features
--------
- supports fully complex and half-complex (i.e., complex-to-real and
  real-to-complex) FFTs, discrete sine/cosine transforms, and Hartley transforms
- achieves very high accuracy for all transforms
- supports multidimensional arrays and selection of the axes to be transformed
- supports single, double, and long double precision
- makes use of CPU vector instructions when performing 2-D and higher-dimensional
  transforms
- supports prime-length transforms without degrading to O(N**2) performance
- has optional OpenMP support for multidimensional transforms
# AMOS

A Portable Package for Bessel Functions of a Complex Argument
and Nonnegative Order

This algorithm is a package of subroutines for computing Bessel
functions and Airy functions.  The routines are updated
versions of those routines found in TOMS algorithm 644.

## Disclaimer

```
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
*                 ISSUED BY SANDIA LABORATORIES,
*                   A PRIME CONTRACTOR TO THE
*               UNITED STATES DEPARTMENT OF ENERGY
* * * * * * * * * * * * * *  NOTICE   * * * * * * * * * * * * * * *
* THIS REPORT WAS PREPARED AS AN ACCOUNT OF WORK SPONSORED BY THE
* UNITED STATES GOVERNMENT.  NEITHER THE UNITED STATES NOR THE
* UNITED STATES DEPARTMENT OF ENERGY, NOR ANY OF THEIR
* EMPLOYEES, NOR ANY OF THEIR CONTRACTORS, SUBCONTRACTORS, OR THEIR
* EMPLOYEES, MAKES ANY WARRANTY, EXPRESS OR IMPLIED, OR ASSUMES ANY
* LEGAL LIABILITY OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS
* OR USEFULNESS OF ANY INFORMATION, APPARATUS, PRODUCT OR PROCESS
* DISCLOSED, OR REPRESENTS THAT ITS USE WOULD NOT INFRINGE
* PRIVATELY OWNED RIGHTS.
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
* THIS CODE HAS BEEN APPROVED FOR UNLIMITED RELEASE.
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
```
This contains a few hacks to re-use BOOST C++ library
[tests data](https://github.com/boostorg/math/tree/develop/test) for
validating scipy.special functions.

convert.py
----------

This script parses the BOOST data and writes the data into a CVS text file.
For each data file, a subdirectory is created, as one boost data file (.ipp)
can have several test sets.

From the root of this repo
```
# Clone boostorg repo
git clone --depth=1 https://github.com/boostorg/math.git boostmath

# Remove existing data
rm -rf scipy/special/tests/data/boost/*

# Run the coverter script (potentially also update exclude regexes)
python scipy/special/utils/convert.py

# Verify all the new files are used in test_data.py
git diff --stat HEAD | grep "Bin 0"
git diff HEAD -- scipy/special/tests/test_data.py
```

It may be desirable to remove whitespace only changes (see
[#12357](https://github.com/scipy/scipy/pull/12357)) for instructions on that.
SciPy Code of Conduct
======

You can read our Code of Conduct by following [this link](../doc/source/dev/conduct/code_of_conduct.rst). 


Alternatively, you can find it under `scipy/doc/source/dev/conduct/code_of_conduct.rst`. 

<!-- 
Thanks for contributing a pull request! Please ensure that
your PR satisfies the checklist before submitting:
http://scipy.github.io/devdocs/dev/contributor/development_workflow.html#checklist-before-submitting-a-pr

Also, please name and describe your PR as you would write a
commit message:
http://scipy.github.io/devdocs/dev/contributor/development_workflow.html#writing-the-commit-message

Note that we are a team of volunteers; we appreciate your
patience during the review process.

Again, thanks for contributing!
-->

#### Reference issue
<!--Example: Closes gh-WXYZ.-->

#### What does this implement/fix?
<!--Please explain your changes.-->

#### Additional information
<!--Any additional information you think is important.-->
# SciPy Documentation

## How to build the docs

To build the html docs for local development, SciPy itself needs to be built so your
environment needs to be set up for that.  For details on that, see the
[Contributor Guide](http://scipy.github.io/devdocs/dev/contributor/contributor_toc.html#development-environment)).

Also ensure to initialize and update submodules (this pulls in the SciPy Sphinx
theme and `numpydoc`):
```
git submodule update --init
```

Now to build both SciPy itself and the docs, use:
```
python3 runtests.py --doc html
```

Alternatively, if you prefer to build SciPy and the docs separately rather
than use `runtests.py`:
```
python setup.py develop  # in the root of the repo
cd doc && make html-scipyorg
```

In case the SciPy version found by the above command is different from that of the
latest commit in the repo, you will see a message like:
```
installed scipy 5fd20ec1aa != current repo git version '35fd20ec1a'
```

This indicates that you're likely picking up the wrong SciPy install, check
with `python -c "import scipy; print(scipy.__file__)"`.

If the build is successful, you can open it in your browser with `make show`
(which will open `build/html-scipyorg/index.html`).


## Building pdf docs

To build the pdf docs, which requires a LaTeX install and can be more fiddly
to get to work, replace the doc build commands in the section above with:
```
python3 runtests.py --doc latex
```
or:
```
make latex
```

That will use Sphinx to generate the LaTeX sources. To then produce a pdf,
navigate to `doc/build/latex/` and run:
```
make all-pdf
```

That will produce a file `scipy-ref.pdf` in `build/latex/`.


## Building documentation for a release

For building all the documentation artifacts for a release, run:
```
make dist
```

This will build SciPy in-place (to ensure the version is correct), build html
and pdf docs as well as create a zip archive of the html docs that can easily
be redistributed.


## Layout of the docs in this repository

- `source` is where most of the content lives.
  - `dev` contains the contributor and developer guides as well as the governance
    docs and the code of conduct.
  - `tutorial` contains all tutorial content.
- `release` contains the release notes. Note that those normally should not be
  updated as part of a PR; we keep releases notes for the upcoming releases
  on the wiki of the main SciPy repo.=============================
SciPy pull request guidelines
=============================

Pull requests are always welcome, and the SciPy community appreciates
any help you give. Note that a code of conduct applies to all spaces
managed by the SciPy project, including issues and pull requests:
https://github.com/scipy/scipy/blob/main/doc/source/dev/conduct/code_of_conduct.rst.

When submitting a pull request, we ask you check the following:

1. **Unit tests**, **documentation**, and **code style** are in order.
   For details, please read
   https://github.com/scipy/scipy/blob/main/HACKING.rst.txt.

   It's also OK to submit work in progress if you're unsure of what
   this exactly means, in which case you'll likely be asked to make
   some further changes.

2. The contributed code will be **licensed under SciPy's license**,
   https://github.com/scipy/scipy/blob/main/LICENSE.txt.
   If you did not write the code yourself, you ensure the existing
   license is compatible and include the license information in the
   contributed files, or obtain a permission from the original
   author to relicense the contributed code.
.. raw:: html

    <p>
      <h1>
        <a href="https://docs.scipy.org/doc/scipy/reference/"><img valign="middle" src="doc/source/_static/logo.svg" height="50" height="50" alt="SciPy logo"/></a>
        SciPy
      </h1>
    </p>

.. image:: https://img.shields.io/circleci/project/github/scipy/scipy/main.svg?label=CircleCI
  :target: https://circleci.com/gh/scipy/scipy

.. image:: https://dev.azure.com/scipy-org/SciPy/_apis/build/status/scipy.scipy?branchName=main
  :target: https://dev.azure.com/scipy-org/SciPy/_build/latest?definitionId=1?branchName=main

.. image:: https://github.com/scipy/scipy/workflows/macOS%20tests/badge.svg?branch=main
  :target: https://github.com/scipy/scipy/actions?query=workflow%3A%22macOS+tests%22

.. image:: https://img.shields.io/pypi/dm/scipy.svg?label=Pypi%20downloads
  :target: https://pypi.org/project/scipy/

.. image:: https://img.shields.io/conda/dn/conda-forge/scipy.svg?label=Conda%20downloads
  :target: https://anaconda.org/conda-forge/scipy

.. image:: https://codecov.io/gh/scipy/scipy/branch/main/graph/badge.svg
  :target: https://codecov.io/gh/scipy/scipy

.. image:: https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg
  :target: https://stackoverflow.com/questions/tagged/scipy

.. image:: https://img.shields.io/badge/DOI-10.1038%2Fs41592--019--0686--2-blue
  :target: https://www.nature.com/articles/s41592-019-0686-2

SciPy (pronounced "Sigh Pie") is an open-source software for mathematics,
science, and engineering. It includes modules for statistics, optimization,
integration, linear algebra, Fourier transforms, signal and image processing,
ODE solvers, and more.

- **Website:** https://scipy.org
- **Documentation:** https://docs.scipy.org/
- **Mailing list:** https://scipy.org/mailing-lists/
- **Source code:** https://github.com/scipy/scipy
- **Contributing:** https://scipy.github.io/devdocs/dev/index.html
- **Bug reports:** https://github.com/scipy/scipy/issues
- **Code of Conduct:** https://scipy.github.io/devdocs/dev/conduct/code_of_conduct.html
- **Report a security vulnerability:** https://tidelift.com/docs/security
- **Citing in your work:** https://www.scipy.org/citing-scipy/

SciPy is built to work with
NumPy arrays, and provides many user-friendly and efficient numerical routines,
such as routines for numerical integration and optimization. Together, they
run on all popular operating systems, are quick to install, and are free of
charge. NumPy and SciPy are easy to use, but powerful enough to be depended
upon by some of the world's leading scientists and engineers. If you need to
manipulate numbers on a computer and display or publish the results, give
SciPy a try!

For the installation instructions, see `our install
guide <https://scipy.github.io/devdocs/getting_started.html#installation>`__.


Call for Contributions
----------------------

We appreciate and welcome contributions. Small improvements or fixes are always appreciated; issues labeled as "good
first issue" may be a good starting point. Have a look at `our contributing
guide <http://scipy.github.io/devdocs/dev/hacking.html>`__.

Writing code isn’t the only way to contribute to SciPy. You can also:

- review pull requests
- triage issues
- develop tutorials, presentations, and other educational materials
- maintain and improve `our website <https://github.com/scipy/scipy.org>`__
- develop graphic design for our brand assets and promotional materials
- help with outreach and onboard new contributors
- write grant proposals and help with other fundraising efforts

If you’re unsure where to start or how your skills fit in, reach out! You can
ask on the mailing list or here, on GitHub, by leaving a
comment on a relevant issue that is already open.

If you are new to contributing to open source, `this
guide <https://opensource.guide/how-to-contribute/>`__ helps explain why, what,
and how to get involved.

.. image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A
  :target: https://numfocus.org
..  -*- rst -*-

================
SciPy benchmarks
================

Benchmarking SciPy with Airspeed Velocity.


Usage
-----

Airspeed Velocity manages building and Python virtualenvs by itself,
unless told otherwise. Some of the benchmarking features in
``runtests.py`` also tell ASV to use the SciPy compiled by
``runtests.py``. To run the benchmarks, you do not need to install a
development version of SciPy to your current Python environment.

Run a benchmark against currently checked-out SciPy version (don't record the
result)::

    python runtests.py --bench sparse.Arithmetic

Compare change in benchmark results with another branch::

    python runtests.py --bench-compare main sparse.Arithmetic

Run benchmarks against the system-installed SciPy rather than rebuild::

    python runtests.py -n --bench sparse.Arithmetic

Run ASV commands directly (note, this will not set env vars for ``ccache``
and disabling BLAS/LAPACK multi-threading, as ``runtests.py`` does)::

    cd benchmarks
    asv run --skip-existing-commits --steps 10 ALL
    asv publish
    asv preview

More on how to use ``asv`` can be found in `ASV documentation`_
Command-line help is available as usual via ``asv --help`` and
``asv run --help``.

.. _ASV documentation: https://asv.readthedocs.io/


Writing benchmarks
------------------

See `ASV documentation`_ for the basics on how to write benchmarks.

Some things to consider:

- When importing things from SciPy on the top of the test files, do it as::

      try:
          from scipy.sparse.linalg import onenormest
      except ImportError:
          pass

  The benchmark files need to be importable also when benchmarking old versions
  of SciPy. The benchmarks themselves don't need any guarding against missing
  features --- only the top-level imports.

- Try to keep the runtime of the benchmark reasonable.

- Use ASV's ``time_`` methods for benchmarking times rather than cooking up
  time measurements via ``time.clock``, even if it requires some juggling when
  writing the benchmark.

- Preparing arrays etc., should generally be put in the ``setup`` method rather
  than the ``time_`` methods, to avoid counting preparation time together with
  the time of the benchmarked operation.

- Use ``run_monitored`` from ``common.py`` if you need to measure memory usage.

- Benchmark versioning: by default ``asv`` invalidates old results
  when there is any code change in the benchmark routine or in
  setup/setup_cache.

  This can be controlled manually by setting a fixed benchmark version
  number, using the ``version`` attribute. See `ASV documentation`_
  for details.

  If set manually, the value needs to be changed manually when old
  results should be invalidated. In case you want to preserve previous
  benchmark results when the benchmark did not previously have a
  manual ``version`` attribute, the automatically computed default
  values can be found in ``results/benchmark.json``.

- Benchmark attributes such as ``params`` and ``param_names`` must be
  the same regardless of whether some features are available, or
  e.g. SCIPY_XSLOW=1 is set.

  Instead, benchmarks that should not be run can be skipped by raising
  ``NotImplementedError`` in ``setup()``.
.. include:: ../release/1.6.0-notes.rst
.. include:: ../release/1.2.1-notes.rst
.. include:: ../release/0.16.1-notes.rst
.. include:: ../release/1.5.1-notes.rst
.. _installing-upgrading:

Installing and upgrading
========================

Information on how to install SciPy and/or the SciPy Stack (a larger set of
packages for scientific computing with Python) can be found at
https://scipy.org/install/.

It is recommended that users use a scientific Python distribution or binaries
for their platform.  If building from source is required, documentation about
that can be found at :doc:`building/index`.

If you already have SciPy installed and want to upgrade to a newer version, use
the same install mechanism as you have used to install SciPy before. Before
upgrading to a newer version, it is recommended to check that your own code
does not use any deprecated SciPy functionality.  To do so, run your code with
``python -Wd``.
.. include:: ../release/0.17.1-notes.rst
.. include:: ../release/0.9.0-notes.rst
.. include:: ../release/1.4.1-notes.rst
.. include:: ../release/0.17.0-notes.rst
.. include:: ../release/1.6.3-notes.rst
.. include:: ../release/1.3.0-notes.rst
.. include:: ../release/1.2.2-notes.rst
.. include:: ../release/1.0.1-notes.rst
.. include:: ../release/0.10.1-notes.rst
.. include:: ../release/0.16.0-notes.rst
.. include:: ../release/0.13.2-notes.rst
.. include:: ../release/0.18.0-notes.rst
.. include:: ../release/0.8.0-notes.rst
.. include:: ../release/0.7.1-notes.rst
.. include:: ../release/1.7.2-notes.rst
.. include:: ../release/0.12.0-notes.rst
.. include:: ../release/1.8.0-notes.rst
.. include:: ../release/0.14.1-notes.rst
.. include:: ../release/0.19.0-notes.rst
.. include:: ../release/0.18.1-notes.rst
.. include:: ../release/0.14.0-notes.rst
.. include:: ../release/0.11.0-notes.rst
.. include:: ../release/1.7.3-notes.rst
.. include:: ../release/1.3.3-notes.rst
.. _getting_started_ref:

***************
Getting started
***************

Installation
------------

.. panels::
    :card: + install-card
    :column: col-lg-6 col-md-6 col-sm-12 col-xs-12 p-3

    Working with conda?
    ^^^^^^^^^^^^^^^^^^^

    SciPy is part of the `Anaconda <https://docs.continuum.io/anaconda/>`__
    distribution and can be installed with Anaconda or Miniconda:

    ++++++++++++++++++++++

    .. code-block:: bash

        conda install scipy

    ---

    Prefer pip?
    ^^^^^^^^^^^

    SciPy can be installed via pip from `PyPI <https://pypi.org/project/scipy>`__.

    ++++

    .. code-block:: bash

        pip install scipy

    ---
    :column: col-12 p-3

    In-depth instructions?
    ^^^^^^^^^^^^^^^^^^^^^^

    Installing a specific version? Installing from source? Check the advanced
    installation page.

    .. container:: custom-button

        :ref:`Learn more <installing-upgrading>`

.. toctree::
   :maxdepth: 1
   :hidden:

   install_upgrade

Tutorials
---------

For a quick overview of SciPy functionality, see the :ref:`user guide<user_guide>`.

You can also refer to the :ref:`reference guide<scipy-api>` for an exhaustive
list of all what is possible with SciPy.
.. include:: ../release/1.5.3-notes.rst
.. include:: ../release/1.5.0-notes.rst
.. include:: ../release/1.5.4-notes.rst
.. include:: ../release/1.7.0-notes.rst
.. include:: ../release/0.12.1-notes.rst
.. include:: ../release/1.9.0-notes.rst
.. include:: ../release/1.6.1-notes.rst
.. template taken from Pandas

.. module:: scipy

*******************
SciPy documentation
*******************

**Date**: |today| **Version**: |version|

**Download documentation**: https://docs.scipy.org/doc/

**Useful links**:
`Install <https://scipy.org/install/>`__ |
`Source Repository <https://github.com/scipy/scipy>`__ |
`Issues & Ideas <https://github.com/scipy/scipy/issues>`__ |
`Q&A Support <https://stackoverflow.com/questions/tagged/scipy>`__ |
`Mailing List <https://scipy.org/mailing-lists>`__

**SciPy** (pronounced "Sigh Pie") is an open-source software for mathematics,
science, and engineering.

.. panels::
    :card: + intro-card text-center
    :column: col-lg-6 col-md-6 col-sm-6 col-xs-12 d-flex

    ---
    :img-top: _static/index_getting_started.png

    Getting started
    ^^^^^^^^^^^^^^^

    New to *SciPy*? Check out the getting started guides. They contain an
    introduction to *SciPy'* main concepts and links to additional tutorials.

    +++

    .. link-button:: getting_started_ref
            :type: ref
            :text: To the getting started guides
            :classes: btn-block btn-secondary stretched-link

    ---
    :img-top: _static/index_user_guide.png

    User guide
    ^^^^^^^^^^

    The user guide provides in-depth information on the
    key concepts of SciPy with useful background information and explanation.

    +++

    .. link-button:: user_guide
            :type: ref
            :text: To the user guide
            :classes: btn-block btn-secondary stretched-link

    ---
    :img-top: _static/index_api.png

    API reference
    ^^^^^^^^^^^^^

    The reference guide contains a detailed description of
    the SciPy API. The reference describes how the methods work and which parameters can
    be used. It assumes that you have an understanding of the key concepts.

    +++

    .. link-button:: scipy-api
            :type: ref
            :text: To the reference guide
            :classes: btn-block btn-secondary stretched-link

    ---
    :img-top: _static/index_contribute.png

    Developer guide
    ^^^^^^^^^^^^^^^

    Saw a typo in the documentation? Want to improve
    existing functionalities? The contributing guidelines will guide
    you through the process of improving SciPy.

    +++

    .. link-button:: scipy-development
            :type: ref
            :text: To the development guide
            :classes: btn-block btn-secondary stretched-link

.. toctree::
   :maxdepth: 1
   :hidden:

   Getting started <getting_started>
   User Guide <tutorial/index>
   API reference <reference/index>
   Development <dev/index>
   Release notes <release>
.. include:: ../release/0.13.0-notes.rst
.. include:: ../release/1.1.0-notes.rst
.. include:: ../release/0.7.0-notes.rst
.. include:: ../release/1.0.0-notes.rst
.. include:: ../release/1.3.2-notes.rst
.. include:: ../release/1.2.3-notes.rst
.. include:: ../release/1.4.0-notes.rst
.. include:: ../release/0.15.1-notes.rst
.. include:: ../release/0.7.2-notes.rst
.. include:: ../release/0.10.0-notes.rst
.. include:: ../release/0.15.0-notes.rst
.. include:: ../release/1.6.2-notes.rst
*************
Release Notes
*************

This is the list of changes to SciPy between each release. For full details,
see the `commit logs <https://github.com/scipy/scipy/commits/>`_.

.. toctree::
   :maxdepth: 1

   release.1.9.0
   release.1.8.0
   release.1.7.3
   release.1.7.2
   release.1.7.1
   release.1.7.0
   release.1.6.3
   release.1.6.2
   release.1.6.1
   release.1.6.0
   release.1.5.4
   release.1.5.3
   release.1.5.2
   release.1.5.1
   release.1.5.0
   release.1.4.1
   release.1.4.0
   release.1.3.3
   release.1.3.2
   release.1.3.1
   release.1.3.0
   release.1.2.3
   release.1.2.2
   release.1.2.1
   release.1.2.0
   release.1.1.0
   release.1.0.1
   release.1.0.0
   release.0.19.1
   release.0.19.0
   release.0.18.1
   release.0.18.0
   release.0.17.1
   release.0.17.0
   release.0.16.1
   release.0.16.0
   release.0.15.1
   release.0.15.0
   release.0.14.1
   release.0.14.0
   release.0.13.2
   release.0.13.1
   release.0.13.0
   release.0.12.1
   release.0.12.0
   release.0.11.0
   release.0.10.1
   release.0.10.0
   release.0.9.0
   release.0.8.0
   release.0.7.2
   release.0.7.1
   release.0.7.0
.. include:: ../release/1.5.2-notes.rst
.. include:: ../release/0.13.1-notes.rst
.. include:: ../release/1.3.1-notes.rst
.. include:: ../release/1.2.0-notes.rst
.. include:: ../release/1.7.1-notes.rst
.. include:: ../release/0.19.1-notes.rst
:orphan:

{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module }}

.. autoproperty:: {{ objname }}:orphan:

{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module }}

.. automethod:: {{ objname }}:orphan:

{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module }}

.. autoattribute:: {{ objname }}{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module }}

.. autoclass:: {{ objname }}
   :no-members:
   :no-inherited-members:
   :no-special-members:

  {% block methods %}
   .. HACK -- the point here is that we don't want this to appear in the output, but the autosummary should still generate the pages.
      .. autosummary::
         :toctree:
      {% for item in all_methods %}
         {%- if not item.startswith('_') or item in ['__call__', '__mul__', '__getitem__', '__len__'] %}
         {{ name }}.{{ item }}
         {%- endif -%}
      {%- endfor %}
      {% for item in inherited_members %}
         {%- if item in ['__call__', '__mul__', '__getitem__', '__len__'] %}
         {{ name }}.{{ item }}
         {%- endif -%}
      {%- endfor %}
  {% endblock %}

  {% block attributes %}
  {% if attributes %}
   .. HACK -- the point here is that we don't want this to appear in the output, but the autosummary should still generate the pages.
      .. autosummary::
         :toctree:
      {% for item in all_attributes %}
         {%- if not item.startswith('_') %}
         {{ name }}.{{ item }}
         {%- endif -%}
      {%- endfor %}
  {% endif %}
  {% endblock %}
{{ fullname }}
{{ underline }}

.. currentmodule:: {{ module }}

.. class:: {{ objname }}

This is an ndarray wrapper for a native MATLAB object. This class is not meant
to be instantiated directly, but can be used for type checking
:func:`scipy.io.loadmat` outputs.
Compressed Sparse Graph Routines (`scipy.sparse.csgraph`)
=========================================================

.. sectionauthor:: Jake Vanderplas <vanderplas@astro.washington.edu>

.. currentmodule:: scipy.sparse.csgraph


Example: Word Ladders
---------------------

A `Word Ladder <https://en.wikipedia.org/wiki/Word_ladder>`_ is a word game
invented by Lewis Carroll, in which players find paths between words by
switching one letter at a time. For example, one can link "ape" and "man"
in the following way:

.. math::
   {\rm ape \to apt \to ait \to bit \to big \to bag \to mag \to man}

Note that each step involves changing just one letter of the word. This is
just one possible path from "ape" to "man", but is it the shortest possible
path? If we desire to find the shortest word-ladder path between two given
words, the sparse graph submodule can help.

First, we need a list of valid words. Many operating systems have such a list
built in. For example, on linux, a word list can often be found at one of the
following locations::

    /usr/share/dict
    /var/lib/dict

Another easy source for words are the Scrabble word lists available at various
sites around the internet (search with your favorite search engine). We'll
first create this list. The system word lists consist of a file with one
word per line. The following should be modified to use the particular word
list you have available::

    >>> word_list = open('/usr/share/dict/words').readlines()
    >>> word_list = map(str.strip, word_list)

We want to look at words of length 3, so let's select just those words of the
correct length. We'll also eliminate words which start with upper-case
(proper nouns) or contain non-alphanumeric characters, like apostrophes and
hyphens. Finally, we'll make sure everything is lower-case for comparison
later::

    >>> word_list = [word for word in word_list if len(word) == 3]
    >>> word_list = [word for word in word_list if word[0].islower()]
    >>> word_list = [word for word in word_list if word.isalpha()]
    >>> word_list = list(map(str.lower, word_list))
    >>> len(word_list)
    586    # may vary

Now we have a list of 586 valid three-letter words (the exact number may
change depending on the particular list used). Each of these words will
become a node in our graph, and we will create edges connecting the nodes
associated with each pair of words which differs by only one letter.

There are efficient ways to do this, and inefficient ways to do this. To
do this as efficiently as possible, we're going to use some sophisticated
numpy array manipulation:

    >>> import numpy as np
    >>> word_list = np.asarray(word_list)
    >>> word_list.dtype   # these are unicode characters in Python 3
    dtype('<U3')
    >>> word_list.sort()  # sort for quick searching later

We have an array where each entry is three unicode characters long. We'd like
to find all pairs where exactly one character is different. We'll start by
converting each word to a 3-D vector:

    >>> word_bytes = np.ndarray((word_list.size, word_list.itemsize),
    ...                         dtype='uint8',
    ...                         buffer=word_list.data)
    >>> # each unicode character is four bytes long. We only need first byte
    >>> # we know that there are three characters in each word
    >>> word_bytes = word_bytes[:, ::word_list.itemsize//3]
    >>> word_bytes.shape
    (586, 3)    # may vary

Now, we'll use the
`Hamming distance <https://en.wikipedia.org/wiki/Hamming_distance>`_
between each point to determine which pairs of words are connected.
The Hamming distance measures the fraction of entries between two vectors
which differ: any two words with a Hamming distance equal to :math:`1/N`,
where :math:`N` is the number of letters, are connected in the word ladder::

    >>> from scipy.spatial.distance import pdist, squareform
    >>> from scipy.sparse import csr_matrix
    >>> hamming_dist = pdist(word_bytes, metric='hamming')
    >>> # there are three characters in each word
    >>> graph = csr_matrix(squareform(hamming_dist < 1.5 / 3))

When comparing the distances, we don't use an equality because this can be
unstable for floating point values. The inequality produces the desired
result, as long as no two entries of the word list are identical. Now, that our
graph is set up, we'll use a shortest path search to find the path between
any two words in the graph::

    >>> i1 = word_list.searchsorted('ape')
    >>> i2 = word_list.searchsorted('man')
    >>> word_list[i1]
    'ape'
    >>> word_list[i2]
    'man'

We need to check that these match, because if the words are not in the list,
that will not be the case. Now, all we need is to find the shortest path
between these two indices in the graph. We'll use
`Dijkstra's algorithm <https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm>`_,
because it allows us to find the path for just one node::

    >>> from scipy.sparse.csgraph import dijkstra
    >>> distances, predecessors = dijkstra(graph, indices=i1,
    ...                                    return_predecessors=True)
    >>> print(distances[i2])
    5.0    # may vary

So we see that the shortest path between "ape" and "man" contains only
five steps. We can use the predecessors returned by the algorithm to
reconstruct this path::

    >>> path = []
    >>> i = i2
    >>> while i != i1:
    ...     path.append(word_list[i])
    ...     i = predecessors[i]
    >>> path.append(word_list[i1])
    >>> print(path[::-1])
    ['ape', 'apt', 'opt', 'oat', 'mat', 'man']    # may vary

This is three fewer links than our initial example: the path from "ape" to "man"
is only five steps.

Using other tools in the module, we can answer other questions. For example,
are there three-letter words which are not linked in a word ladder? This
is a question of connected components in the graph::

    >>> from scipy.sparse.csgraph import connected_components
    >>> N_components, component_list = connected_components(graph)
    >>> print(N_components)
    15    # may vary

In this particular sample of three-letter words, there are 15 connected
components: that is, 15 distinct sets of words with no paths between the
sets. How many words are there in each of these sets? We can learn this from
the list of components::

    >>> [np.sum(component_list == i) for i in range(N_components)]
    [571, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    # may vary

There is one large connected set and 14 smaller ones. Let's look at the
words in the smaller ones::

    >>> [list(word_list[np.nonzero(component_list == i)]) for i in range(1, N_components)]
    [['aha'],    # may vary
     ['chi'],
     ['ebb'],
     ['ems', 'emu'],
     ['gnu'],
     ['ism'],
     ['khz'],
     ['nth'],
     ['ova'],
     ['qua'],
     ['ugh'],
     ['ups'],
     ['urn'],
     ['use']]

These are all the three-letter words which do not connect to others via a word
ladder.

We might also be curious about which words are maximally separated. Which
two words take the most links to connect? We can determine this by computing
the matrix of all shortest paths. Note that, by convention, the
distance between two non-connected points is reported to be infinity, so
we'll need to remove these before finding the maximum::

    >>> distances, predecessors = dijkstra(graph, return_predecessors=True)
    >>> max_distance = np.max(distances[~np.isinf(distances)])
    >>> print(max_distance)
    13.0    # may vary

So, there is at least one pair of words which takes 13 steps to get from one
to the other! Let's determine which these are::

    >>> i1, i2 = np.nonzero(distances == max_distance)
    >>> list(zip(word_list[i1], word_list[i2]))
    [('imp', 'ohm'),    # may vary
     ('imp', 'ohs'),
     ('ohm', 'imp'),
     ('ohm', 'ump'),
     ('ohs', 'imp'),
     ('ohs', 'ump'),
     ('ump', 'ohm'),
     ('ump', 'ohs')]

We see that there are two pairs of words which are maximally separated from
each other: 'imp' and 'ump' on the one hand, and 'ohm' and 'ohs' on the other.
We can find the connecting list in the same way as above::

    >>> path = []
    >>> i = i2[0]
    >>> while i != i1[0]:
    ...     path.append(word_list[i])
    ...     i = predecessors[i1[0], i]
    >>> path.append(word_list[i1[0]])
    >>> print(path[::-1])
    ['imp', 'amp', 'asp', 'ass', 'ads', 'add', 'aid', 'mid', 'mod', 'moo', 'too', 'tho', 'oho', 'ohm']    # may vary

This gives us the path we desired to see.

Word ladders are just one potential application of scipy's fast graph
algorithms for sparse matrices. Graph theory makes appearances in many
areas of mathematics, data analysis, and machine learning. The sparse graph
tools are flexible enough to handle many of these situations.
============
Introduction
============

.. contents::

.. currentmodule:: scipy

SciPy is a collection of mathematical algorithms and convenience
functions built on the NumPy extension of Python. It adds
significant power to the interactive Python session by providing the
user with high-level commands and classes for manipulating and
visualizing data. With SciPy, an interactive Python session
becomes a data-processing and system-prototyping environment rivaling
systems, such as MATLAB, IDL, Octave, R-Lab, and SciLab.

The additional benefit of basing SciPy on Python is that this also makes a
powerful programming language available for use in developing
sophisticated programs and specialized applications. Scientific
applications using SciPy benefit from the development of
additional modules in numerous niches of the software landscape by
developers across the world. Everything from parallel programming to
web and data-base subroutines and classes have been made available to
the Python programmer. All of this power is available in addition to
the mathematical libraries in SciPy.

This tutorial will acquaint the first-time user of SciPy with some of its most
important features. It assumes that the user has already installed the SciPy
package. Some general Python facility is also assumed, such as could be
acquired by working through the Python distribution's Tutorial. For further
introductory help the user is directed to the NumPy documentation.

For brevity and convenience, we will often assume that the main
packages (numpy, scipy, and matplotlib) have been imported as::

    >>> import numpy as np
    >>> import matplotlib as mpl
    >>> import matplotlib.pyplot as plt

These are the import conventions that our community has adopted
after discussion on public mailing lists.  You will see these
conventions used throughout NumPy and SciPy source code and
documentation.  While we obviously don't require you to follow
these conventions in your own code, it is highly recommended.

SciPy Organization
------------------

SciPy is organized into subpackages covering different scientific
computing domains. These are summarized in the following table:

==================  ======================================================
Subpackage          Description
==================  ======================================================
`cluster`           Clustering algorithms
`constants`         Physical and mathematical constants
`fftpack`           Fast Fourier Transform routines
`integrate`         Integration and ordinary differential equation solvers
`interpolate`       Interpolation and smoothing splines
`io`                Input and Output
`linalg`            Linear algebra
`ndimage`           N-dimensional image processing
`odr`               Orthogonal distance regression
`optimize`          Optimization and root-finding routines
`signal`            Signal processing
`sparse`            Sparse matrices and associated routines
`spatial`           Spatial data structures and algorithms
`special`           Special functions
`stats`             Statistical distributions and functions
==================  ======================================================

SciPy sub-packages need to be imported separately, for example::

    >>> from scipy import linalg, optimize

Because of their ubiquitousness, some of the functions in these
subpackages are also made available in the `scipy` namespace to ease
their use in interactive sessions and programs. In addition, many
basic array functions from :mod:`numpy` are also available at the
top-level of the :mod:`scipy` package. Before looking at the
sub-packages individually, we will first look at some of these common
functions.

Finding Documentation
---------------------

SciPy and NumPy have documentation versions in both HTML and PDF format
available at https://docs.scipy.org/, that cover nearly
all available functionality. However, this documentation is still
work-in-progress and some parts may be incomplete or sparse. As
we are a volunteer organization and depend on the community for
growth, your participation - everything from providing feedback to
improving the documentation and code - is welcome and actively
encouraged.

Python's documentation strings are used in SciPy for on-line
documentation. There are two methods for reading them and
getting help. One is Python's command :func:`help` in the `pydoc`
module. Entering this command with no arguments (i.e. ``>>> help`` )
launches an interactive help session that allows searching through the
keywords and modules available to all of Python. Secondly, running the command
`help(obj)` with an object as the argument displays that object's calling
signature, and documentation string.

The pydoc method of ``help`` is sophisticated but uses a pager to display
the text. Sometimes this can interfere with the terminal within which you are
running the interactive session. A numpy/scipy-specific help system
is also available under the command ``numpy.info``. The signature and
documentation string for the object passed to the ``help`` command are
printed to standard output (or to a writeable object passed as the
third argument). The second keyword argument of ``numpy.info`` defines
the maximum width of the line for printing. If a module is passed as
the argument to ``help`` then a list of the functions and classes defined
in that module is printed. For example:

.. literalinclude:: examples/1-1

Another useful command is ``dir``,
which can be used to look at the namespace of a module or package.
Linear Algebra (`scipy.linalg`)
===============================

.. sectionauthor:: Travis E. Oliphant

.. currentmodule:: scipy

When SciPy is built using the optimized ATLAS LAPACK and BLAS
libraries, it has very fast linear algebra capabilities. If you dig
deep enough, all of the raw LAPACK and BLAS libraries are available
for your use for even more speed. In this section, some easier-to-use
interfaces to these routines are described.

All of these linear algebra routines expect an object that can be
converted into a 2-D array. The output of these routines is
also a 2-D array.

scipy.linalg vs numpy.linalg
----------------------------

.. TODO: replace numpy.linalg HTML link with `numpy.linalg` once NumPy updates doc

:mod:`scipy.linalg` contains all the functions in
`numpy.linalg <https://www.numpy.org/devdocs/reference/routines.linalg.html>`__.
plus some other more advanced ones not contained in ``numpy.linalg``.

Another advantage of using ``scipy.linalg`` over ``numpy.linalg`` is that
it is always compiled with BLAS/LAPACK support, while for numpy this is
optional. Therefore, the scipy version might be faster depending on how
numpy was installed.

Therefore, unless you don't want to add ``scipy`` as a dependency to
your ``numpy`` program, use ``scipy.linalg`` instead of ``numpy.linalg``.


numpy.matrix vs 2-D numpy.ndarray
---------------------------------

The classes that represent matrices, and basic operations, such as
matrix multiplications and transpose are a part of ``numpy``.
For convenience, we summarize the differences between :class:`numpy.matrix`
and :class:`numpy.ndarray` here.

``numpy.matrix`` is matrix class that has a more convenient interface
than ``numpy.ndarray`` for matrix operations. This class supports, for
example, MATLAB-like creation syntax via the semicolon, has matrix
multiplication as default for the ``*`` operator, and contains ``I``
and ``T`` members that serve as shortcuts for inverse and transpose:

    >>> import numpy as np
    >>> A = np.mat('[1 2;3 4]')
    >>> A
    matrix([[1, 2],
            [3, 4]])
    >>> A.I
    matrix([[-2. ,  1. ],
            [ 1.5, -0.5]])
    >>> b = np.mat('[5 6]')
    >>> b
    matrix([[5, 6]])
    >>> b.T
    matrix([[5],
            [6]])
    >>> A*b.T
    matrix([[17],
            [39]])

Despite its convenience, the use of the ``numpy.matrix`` class is
discouraged, since it adds nothing that cannot be accomplished
with 2-D ``numpy.ndarray`` objects, and may lead to a confusion of which class
is being used. For example, the above code can be rewritten as:

    >>> import numpy as np
    >>> from scipy import linalg
    >>> A = np.array([[1,2],[3,4]])
    >>> A
    array([[1, 2],
          [3, 4]])
    >>> linalg.inv(A)
    array([[-2. ,  1. ],
          [ 1.5, -0.5]])
    >>> b = np.array([[5,6]]) #2D array
    >>> b
    array([[5, 6]])
    >>> b.T
    array([[5],
          [6]])
    >>> A*b #not matrix multiplication!
    array([[ 5, 12],
          [15, 24]])
    >>> A.dot(b.T) #matrix multiplication
    array([[17],
          [39]])
    >>> b = np.array([5,6]) #1D array
    >>> b
    array([5, 6])
    >>> b.T  #not matrix transpose!
    array([5, 6])
    >>> A.dot(b)  #does not matter for multiplication
    array([17, 39])

``scipy.linalg`` operations can be applied equally to
``numpy.matrix`` or to 2D ``numpy.ndarray`` objects.


Basic routines
--------------

Finding the inverse
^^^^^^^^^^^^^^^^^^^

The inverse of a matrix :math:`\mathbf{A}` is the matrix
:math:`\mathbf{B}`, such that :math:`\mathbf{AB}=\mathbf{I}`, where
:math:`\mathbf{I}` is the identity matrix consisting of ones down the
main diagonal.  Usually, :math:`\mathbf{B}` is denoted
:math:`\mathbf{B}=\mathbf{A}^{-1}` . In SciPy, the matrix inverse of
the NumPy array, A, is obtained using :obj:`linalg.inv` ``(A)``, or
using ``A.I`` if ``A`` is a Matrix. For example, let

.. math::

    \mathbf{A} = \left[\begin{array}{ccc} 1 & 3 & 5\\ 2 & 5 & 1\\ 2 & 3 & 8\end{array}\right],

then

.. math::

    \mathbf{A^{-1}} = \frac{1}{25}
        \left[\begin{array}{ccc} -37 & 9 & 22 \\
                                  14 & 2 & -9 \\
                                  4 & -3 & 1
              \end{array}\right] = %
         \left[\begin{array}{ccc} -1.48 & 0.36 & 0.88  \\
                                   0.56 & 0.08 & -0.36 \\
                                   0.16 & -0.12 & 0.04
               \end{array}\right].

The following example demonstrates this computation in SciPy

    >>> import numpy as np
    >>> from scipy import linalg
    >>> A = np.array([[1,3,5],[2,5,1],[2,3,8]])
    >>> A
    array([[1, 3, 5],
          [2, 5, 1],
          [2, 3, 8]])
    >>> linalg.inv(A)
    array([[-1.48,  0.36,  0.88],
          [ 0.56,  0.08, -0.36],
          [ 0.16, -0.12,  0.04]])
    >>> A.dot(linalg.inv(A)) #double check
    array([[  1.00000000e+00,  -1.11022302e-16,  -5.55111512e-17],
          [  3.05311332e-16,   1.00000000e+00,   1.87350135e-16],
          [  2.22044605e-16,  -1.11022302e-16,   1.00000000e+00]])

Solving a linear system
^^^^^^^^^^^^^^^^^^^^^^^

Solving linear systems of equations is straightforward using the scipy
command :obj:`linalg.solve`. This command expects an input matrix and
a right-hand side vector. The solution vector is then computed. An
option for entering a symmetric matrix is offered, which can speed up
the processing when applicable. As an example, suppose it is desired
to solve the following simultaneous equations:

.. math::
   :nowrap:

    \begin{eqnarray*} x + 3y + 5z & = & 10 \\
                      2x + 5y + z & = & 8  \\
                      2x + 3y + 8z & = & 3
    \end{eqnarray*}

We could find the solution vector using a matrix inverse:

.. math::

    \left[\begin{array}{c} x\\ y\\ z\end{array}\right]=\left[\begin{array}{ccc} 1 & 3 & 5\\ 2 & 5 & 1\\ 2 & 3 & 8\end{array}\right]^{-1}\left[\begin{array}{c} 10\\ 8\\ 3\end{array}\right]=\frac{1}{25}\left[\begin{array}{c} -232\\ 129\\ 19\end{array}\right]=\left[\begin{array}{c} -9.28\\ 5.16\\ 0.76\end{array}\right].

However, it is better to use the linalg.solve command, which can be
faster and more numerically stable. In this case, it, however, gives the
same answer as shown in the following example:

    >>> import numpy as np
    >>> from scipy import linalg
    >>> A = np.array([[1, 2], [3, 4]])
    >>> A
    array([[1, 2],
          [3, 4]])
    >>> b = np.array([[5], [6]])
    >>> b
    array([[5],
          [6]])
    >>> linalg.inv(A).dot(b)  # slow
    array([[-4. ],
          [ 4.5]])
    >>> A.dot(linalg.inv(A).dot(b)) - b  # check
    array([[  8.88178420e-16],
          [  2.66453526e-15]])
    >>> np.linalg.solve(A, b)  # fast
    array([[-4. ],
          [ 4.5]])
    >>> A.dot(np.linalg.solve(A, b)) - b  # check
    array([[ 0.],
          [ 0.]])


Finding the determinant
^^^^^^^^^^^^^^^^^^^^^^^

The determinant of a square matrix :math:`\mathbf{A}` is often denoted
:math:`\left|\mathbf{A}\right|` and is a quantity often used in linear
algebra. Suppose :math:`a_{ij}` are the elements of the matrix
:math:`\mathbf{A}` and let :math:`M_{ij}=\left|\mathbf{A}_{ij}\right|`
be the determinant of the matrix left by removing the
:math:`i^{\textrm{th}}` row and :math:`j^{\textrm{th}}` column from
:math:`\mathbf{A}` . Then, for any row :math:`i,`

.. math::

    \left|\mathbf{A}\right|=\sum_{j}\left(-1\right)^{i+j}a_{ij}M_{ij}.

This is a recursive way to define the determinant, where the base case
is defined by accepting that the determinant of a :math:`1\times1` matrix is the only matrix element. In SciPy the determinant can be
calculated with :obj:`linalg.det`. For example, the determinant of

.. math::

    \mathbf{A=}\left[\begin{array}{ccc} 1 & 3 & 5\\ 2 & 5 & 1\\ 2 & 3 & 8\end{array}\right]

is

.. math::
   :nowrap:

    \begin{eqnarray*} \left|\mathbf{A}\right| & = & 1\left|\begin{array}{cc} 5 & 1\\ 3 & 8\end{array}\right|-3\left|\begin{array}{cc} 2 & 1\\ 2 & 8\end{array}\right|+5\left|\begin{array}{cc} 2 & 5\\ 2 & 3\end{array}\right|\\  & = & 1\left(5\cdot8-3\cdot1\right)-3\left(2\cdot8-2\cdot1\right)+5\left(2\cdot3-2\cdot5\right)=-25.\end{eqnarray*}.

In SciPy, this is computed as shown in this example:

    >>> import numpy as np
    >>> from scipy import linalg
    >>> A = np.array([[1,2],[3,4]])
    >>> A
    array([[1, 2],
          [3, 4]])
    >>> linalg.det(A)
    -2.0


Computing norms
^^^^^^^^^^^^^^^

Matrix and vector norms can also be computed with SciPy. A wide range
of norm definitions are available using different parameters to the
order argument of :obj:`linalg.norm`. This function takes a rank-1
(vectors) or a rank-2 (matrices) array and an optional order argument
(default is 2). Based on these inputs, a vector or matrix norm of the
requested order is computed.

For vector *x*, the order parameter can be any real number including
``inf`` or ``-inf``. The computed norm is

.. math::

    \left\Vert \mathbf{x}\right\Vert =\left\{ \begin{array}{cc} \max\left|x_{i}\right| & \textrm{ord}=\textrm{inf}\\ \min\left|x_{i}\right| & \textrm{ord}=-\textrm{inf}\\ \left(\sum_{i}\left|x_{i}\right|^{\textrm{ord}}\right)^{1/\textrm{ord}} & \left|\textrm{ord}\right|<\infty.\end{array}\right.



For matrix :math:`\mathbf{A}`, the only valid values for norm are :math:`\pm2,\pm1,` :math:`\pm` inf, and 'fro' (or 'f') Thus,

.. math::

    \left\Vert \mathbf{A}\right\Vert =\left\{ \begin{array}{cc} \max_{i}\sum_{j}\left|a_{ij}\right| & \textrm{ord}=\textrm{inf}\\ \min_{i}\sum_{j}\left|a_{ij}\right| & \textrm{ord}=-\textrm{inf}\\ \max_{j}\sum_{i}\left|a_{ij}\right| & \textrm{ord}=1\\ \min_{j}\sum_{i}\left|a_{ij}\right| & \textrm{ord}=-1\\ \max\sigma_{i} & \textrm{ord}=2\\ \min\sigma_{i} & \textrm{ord}=-2\\ \sqrt{\textrm{trace}\left(\mathbf{A}^{H}\mathbf{A}\right)} & \textrm{ord}=\textrm{'fro'}\end{array}\right.

where :math:`\sigma_{i}` are the singular values of :math:`\mathbf{A}`.

Examples:

    >>> import numpy as np
    >>> from scipy import linalg
    >>> A=np.array([[1,2],[3,4]])
    >>> A
    array([[1, 2],
          [3, 4]])
    >>> linalg.norm(A)
    5.4772255750516612
    >>> linalg.norm(A,'fro') # frobenius norm is the default
    5.4772255750516612
    >>> linalg.norm(A,1) # L1 norm (max column sum)
    6
    >>> linalg.norm(A,-1)
    4
    >>> linalg.norm(A,np.inf) # L inf norm (max row sum)
    7


Solving linear least-squares problems and pseudo-inverses
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Linear least-squares problems occur in many branches of applied
mathematics. In this problem, a set of linear scaling coefficients is
sought that allows a model to fit the data. In particular, it is assumed
that data :math:`y_{i}` is related to data :math:`\mathbf{x}_{i}`
through a set of coefficients :math:`c_{j}` and model functions
:math:`f_{j}\left(\mathbf{x}_{i}\right)` via the model

.. math::

    y_{i}=\sum_{j}c_{j}f_{j}\left(\mathbf{x}_{i}\right)+\epsilon_{i},

where :math:`\epsilon_{i}` represents uncertainty in the data. The
strategy of least squares is to pick the coefficients :math:`c_{j}` to
minimize

.. math::

    J\left(\mathbf{c}\right)=\sum_{i}\left|y_{i}-\sum_{j}c_{j}f_{j}\left(x_{i}\right)\right|^{2}.



Theoretically, a global minimum will occur when

.. math::

    \frac{\partial J}{\partial c_{n}^{*}}=0=\sum_{i}\left(y_{i}-\sum_{j}c_{j}f_{j}\left(x_{i}\right)\right)\left(-f_{n}^{*}\left(x_{i}\right)\right)

or

.. math::
   :nowrap:

    \begin{eqnarray*} \sum_{j}c_{j}\sum_{i}f_{j}\left(x_{i}\right)f_{n}^{*}\left(x_{i}\right) & = & \sum_{i}y_{i}f_{n}^{*}\left(x_{i}\right)\\ \mathbf{A}^{H}\mathbf{Ac} & = & \mathbf{A}^{H}\mathbf{y}\end{eqnarray*},

where

.. math::

    \left\{ \mathbf{A}\right\} _{ij}=f_{j}\left(x_{i}\right).

When :math:`\mathbf{A^{H}A}` is invertible, then

.. math::

    \mathbf{c}=\left(\mathbf{A}^{H}\mathbf{A}\right)^{-1}\mathbf{A}^{H}\mathbf{y}=\mathbf{A}^{\dagger}\mathbf{y},

where :math:`\mathbf{A}^{\dagger}` is called the pseudo-inverse of
:math:`\mathbf{A}.` Notice that using this definition of
:math:`\mathbf{A}` the model can be written

.. math::

    \mathbf{y}=\mathbf{Ac}+\boldsymbol{\epsilon}.

The command :obj:`linalg.lstsq` will solve the linear least-squares
problem for :math:`\mathbf{c}` given :math:`\mathbf{A}` and
:math:`\mathbf{y}` . In addition, :obj:`linalg.pinv` or
:obj:`linalg.pinv2` (uses a different method based on singular value
decomposition) will find :math:`\mathbf{A}^{\dagger}` given
:math:`\mathbf{A}.`

The following example and figure demonstrate the use of
:obj:`linalg.lstsq` and :obj:`linalg.pinv` for solving a data-fitting
problem. The data shown below were generated using the model:

.. math::

    y_{i}=c_{1}e^{-x_{i}}+c_{2}x_{i},

where :math:`x_{i}=0.1i` for :math:`i=1\ldots10` , :math:`c_{1}=5`,
and :math:`c_{2}=4.` Noise is added to :math:`y_{i}` and the
coefficients :math:`c_{1}` and :math:`c_{2}` are estimated using
linear least squares.

.. plot::

   >>> import numpy as np
   >>> from scipy import linalg
   >>> import matplotlib.pyplot as plt
   >>> rng = np.random.default_rng()

   >>> c1, c2 = 5.0, 2.0
   >>> i = np.r_[1:11]
   >>> xi = 0.1*i
   >>> yi = c1*np.exp(-xi) + c2*xi
   >>> zi = yi + 0.05 * np.max(yi) * rng.standard_normal(len(yi))

   >>> A = np.c_[np.exp(-xi)[:, np.newaxis], xi[:, np.newaxis]]
   >>> c, resid, rank, sigma = linalg.lstsq(A, zi)

   >>> xi2 = np.r_[0.1:1.0:100j]
   >>> yi2 = c[0]*np.exp(-xi2) + c[1]*xi2

   >>> plt.plot(xi,zi,'x',xi2,yi2)
   >>> plt.axis([0,1.1,3.0,5.5])
   >>> plt.xlabel('$x_i$')
   >>> plt.title('Data fitting with linalg.lstsq')
   >>> plt.show()

..   :caption: Example of linear least-squares fit

Generalized inverse
^^^^^^^^^^^^^^^^^^^

The generalized inverse is calculated using the command
:obj:`linalg.pinv` or :obj:`linalg.pinv2`. These two commands differ
in how they compute the generalized inverse. The first uses the
linalg.lstsq algorithm, while the second uses singular value
decomposition. Let :math:`\mathbf{A}` be an :math:`M\times N` matrix,
then if :math:`M>N`, the generalized inverse is

.. math::

    \mathbf{A}^{\dagger}=\left(\mathbf{A}^{H}\mathbf{A}\right)^{-1}\mathbf{A}^{H},

while if :math:`M<N` matrix, the generalized inverse is

.. math::

    \mathbf{A}^{\#}=\mathbf{A}^{H}\left(\mathbf{A}\mathbf{A}^{H}\right)^{-1}.

In the case that :math:`M=N`, then

.. math::

    \mathbf{A}^{\dagger}=\mathbf{A}^{\#}=\mathbf{A}^{-1},

as long as :math:`\mathbf{A}` is invertible.


Decompositions
--------------

In many applications, it is useful to decompose a matrix using other
representations. There are several decompositions supported by SciPy.


Eigenvalues and eigenvectors
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The eigenvalue-eigenvector problem is one of the most commonly
employed linear algebra operations. In one popular form, the
eigenvalue-eigenvector problem is to find for some square matrix
:math:`\mathbf{A}` scalars :math:`\lambda` and corresponding vectors
:math:`\mathbf{v}`, such that

.. math::

    \mathbf{Av}=\lambda\mathbf{v}.

For an :math:`N\times N` matrix, there are :math:`N` (not necessarily
distinct) eigenvalues --- roots of the (characteristic) polynomial

.. math::

    \left|\mathbf{A}-\lambda\mathbf{I}\right|=0.

The eigenvectors, :math:`\mathbf{v}`, are also sometimes called right
eigenvectors to distinguish them from another set of left eigenvectors
that satisfy

.. math::

    \mathbf{v}_{L}^{H}\mathbf{A}=\lambda\mathbf{v}_{L}^{H}

or

.. math::

    \mathbf{A}^{H}\mathbf{v}_{L}=\lambda^{*}\mathbf{v}_{L}.

With its default optional arguments, the command :obj:`linalg.eig`
returns :math:`\lambda` and :math:`\mathbf{v}.` However, it can also
return :math:`\mathbf{v}_{L}` and just :math:`\lambda` by itself (
:obj:`linalg.eigvals` returns just :math:`\lambda` as well).

In addition, :obj:`linalg.eig` can also solve the more general eigenvalue problem

.. math::
   :nowrap:

    \begin{eqnarray*} \mathbf{Av} & = & \lambda\mathbf{Bv}\\ \mathbf{A}^{H}\mathbf{v}_{L} & = & \lambda^{*}\mathbf{B}^{H}\mathbf{v}_{L}\end{eqnarray*}

for square matrices :math:`\mathbf{A}` and :math:`\mathbf{B}.` The
standard eigenvalue problem is an example of the general eigenvalue
problem for :math:`\mathbf{B}=\mathbf{I}.` When a generalized
eigenvalue problem can be solved, it provides a decomposition of
:math:`\mathbf{A}` as

.. math::

    \mathbf{A}=\mathbf{BV}\boldsymbol{\Lambda}\mathbf{V}^{-1},

where :math:`\mathbf{V}` is the collection of eigenvectors into
columns and :math:`\boldsymbol{\Lambda}` is a diagonal matrix of
eigenvalues.

By definition, eigenvectors are only defined up to a constant scale
factor. In SciPy, the scaling factor for the eigenvectors is chosen so
that :math:`\left\Vert \mathbf{v}\right\Vert
^{2}=\sum_{i}v_{i}^{2}=1.`

As an example, consider finding the eigenvalues and eigenvectors of
the matrix

.. math::

    \mathbf{A}=\left[\begin{array}{ccc} 1 & 5 & 2\\ 2 & 4 & 1\\ 3 & 6 & 2\end{array}\right].

The characteristic polynomial is

.. math::
   :nowrap:

    \begin{eqnarray*} \left|\mathbf{A}-\lambda\mathbf{I}\right| & = & \left(1-\lambda\right)\left[\left(4-\lambda\right)\left(2-\lambda\right)-6\right]-\\  &  & 5\left[2\left(2-\lambda\right)-3\right]+2\left[12-3\left(4-\lambda\right)\right]\\  & = & -\lambda^{3}+7\lambda^{2}+8\lambda-3.\end{eqnarray*}

The roots of this polynomial are the eigenvalues of :math:`\mathbf{A}`:

.. math::
   :nowrap:

    \begin{eqnarray*} \lambda_{1} & = & 7.9579\\ \lambda_{2} & = & -1.2577\\ \lambda_{3} & = & 0.2997.\end{eqnarray*}

The eigenvectors corresponding to each eigenvalue can be found using
the original equation. The eigenvectors associated with these
eigenvalues can then be found.

    >>> import numpy as np
    >>> from scipy import linalg
    >>> A = np.array([[1, 2], [3, 4]])
    >>> la, v = linalg.eig(A)
    >>> l1, l2 = la
    >>> print(l1, l2)   # eigenvalues
    (-0.3722813232690143+0j) (5.372281323269014+0j)
    >>> print(v[:, 0])   # first eigenvector
    [-0.82456484  0.56576746]
    >>> print(v[:, 1])   # second eigenvector
    [-0.41597356 -0.90937671]
    >>> print(np.sum(abs(v**2), axis=0))  # eigenvectors are unitary
    [1. 1.]
    >>> v1 = np.array(v[:, 0]).T
    >>> print(linalg.norm(A.dot(v1) - l1*v1))  # check the computation
    3.23682852457e-16


Singular value decomposition
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Singular value decomposition (SVD) can be thought of as an extension of
the eigenvalue problem to matrices that are not square. Let
:math:`\mathbf{A}` be an :math:`M\times N` matrix with :math:`M` and
:math:`N` arbitrary. The matrices :math:`\mathbf{A}^{H}\mathbf{A}` and
:math:`\mathbf{A}\mathbf{A}^{H}` are square hermitian matrices [#]_ of
size :math:`N\times N` and :math:`M\times M`, respectively. It is known
that the eigenvalues of square hermitian matrices are real and
non-negative. In addition, there are at most
:math:`\min\left(M,N\right)` identical non-zero eigenvalues of
:math:`\mathbf{A}^{H}\mathbf{A}` and :math:`\mathbf{A}\mathbf{A}^{H}.`
Define these positive eigenvalues as :math:`\sigma_{i}^{2}.` The
square-root of these are called singular values of :math:`\mathbf{A}.`
The eigenvectors of :math:`\mathbf{A}^{H}\mathbf{A}` are collected by
columns into an :math:`N\times N` unitary [#]_ matrix
:math:`\mathbf{V}`, while the eigenvectors of
:math:`\mathbf{A}\mathbf{A}^{H}` are collected by columns in the
unitary matrix :math:`\mathbf{U}`, the singular values are collected
in an :math:`M\times N` zero matrix
:math:`\mathbf{\boldsymbol{\Sigma}}` with main diagonal entries set to
the singular values. Then

.. math::

    \mathbf{A=U}\boldsymbol{\Sigma}\mathbf{V}^{H}

is the singular value decomposition of :math:`\mathbf{A}.` Every
matrix has a singular value decomposition. Sometimes, the singular
values are called the spectrum of :math:`\mathbf{A}.` The command
:obj:`linalg.svd` will return :math:`\mathbf{U}` ,
:math:`\mathbf{V}^{H}`, and :math:`\sigma_{i}` as an array of the
singular values. To obtain the matrix :math:`\boldsymbol{\Sigma}`, use
:obj:`linalg.diagsvd`. The following example illustrates the use of
:obj:`linalg.svd`:

    >>> import numpy as np
    >>> from scipy import linalg
    >>> A = np.array([[1,2,3],[4,5,6]])
    >>> A
    array([[1, 2, 3],
          [4, 5, 6]])
    >>> M,N = A.shape
    >>> U,s,Vh = linalg.svd(A)
    >>> Sig = linalg.diagsvd(s,M,N)
    >>> U, Vh = U, Vh
    >>> U
    array([[-0.3863177 , -0.92236578],
          [-0.92236578,  0.3863177 ]])
    >>> Sig
    array([[ 9.508032  ,  0.        ,  0.        ],
          [ 0.        ,  0.77286964,  0.        ]])
    >>> Vh
    array([[-0.42866713, -0.56630692, -0.7039467 ],
          [ 0.80596391,  0.11238241, -0.58119908],
          [ 0.40824829, -0.81649658,  0.40824829]])
    >>> U.dot(Sig.dot(Vh)) #check computation
    array([[ 1.,  2.,  3.],
          [ 4.,  5.,  6.]])

.. [#] A hermitian matrix :math:`\mathbf{D}` satisfies :math:`\mathbf{D}^{H}=\mathbf{D}.`

.. [#] A unitary matrix :math:`\mathbf{D}` satisfies :math:`\mathbf{D}^{H}\mathbf{D}=\mathbf{I}=\mathbf{D}\mathbf{D}^{H}` so that :math:`\mathbf{D}^{-1}=\mathbf{D}^{H}.`


LU decomposition
^^^^^^^^^^^^^^^^

The LU decomposition finds a representation for the :math:`M\times N`
matrix :math:`\mathbf{A}` as

.. math::

    \mathbf{A}=\mathbf{P}\,\mathbf{L}\,\mathbf{U},

where :math:`\mathbf{P}` is an :math:`M\times M` permutation matrix (a
permutation of the rows of the identity matrix), :math:`\mathbf{L}` is
in :math:`M\times K` lower triangular or trapezoidal matrix (
:math:`K=\min\left(M,N\right)`) with unit-diagonal, and
:math:`\mathbf{U}` is an upper triangular or trapezoidal matrix. The
SciPy command for this decomposition is :obj:`linalg.lu`.

Such a decomposition is often useful for solving many simultaneous
equations where the left-hand side does not change but the right-hand
side does. For example, suppose we are going to solve

.. math::

    \mathbf{A}\mathbf{x}_{i}=\mathbf{b}_{i}

for many different :math:`\mathbf{b}_{i}`. The LU decomposition allows this to be written as

.. math::

    \mathbf{PLUx}_{i}=\mathbf{b}_{i}.

Because :math:`\mathbf{L}` is lower-triangular, the equation can be
solved for :math:`\mathbf{U}\mathbf{x}_{i}` and, finally,
:math:`\mathbf{x}_{i}` very rapidly using forward- and
back-substitution. An initial time spent factoring :math:`\mathbf{A}`
allows for very rapid solution of similar systems of equations in the
future. If the intent for performing LU decomposition is for solving
linear systems, then the command :obj:`linalg.lu_factor` should be used
followed by repeated applications of the command
:obj:`linalg.lu_solve` to solve the system for each new
right-hand side.


Cholesky decomposition
^^^^^^^^^^^^^^^^^^^^^^

Cholesky decomposition is a special case of LU decomposition
applicable to Hermitian positive definite matrices. When
:math:`\mathbf{A}=\mathbf{A}^{H}` and
:math:`\mathbf{x}^{H}\mathbf{Ax}\geq0` for all :math:`\mathbf{x}`,
then decompositions of :math:`\mathbf{A}` can be found so that

.. math::
   :nowrap:

    \begin{eqnarray*} \mathbf{A} & = & \mathbf{U}^{H}\mathbf{U}\\ \mathbf{A} & = & \mathbf{L}\mathbf{L}^{H}\end{eqnarray*},

where :math:`\mathbf{L}` is lower triangular and :math:`\mathbf{U}` is
upper triangular. Notice that :math:`\mathbf{L}=\mathbf{U}^{H}.` The
command :obj:`linalg.cholesky` computes the Cholesky
factorization. For using the Cholesky factorization to solve systems of
equations, there are also :obj:`linalg.cho_factor` and
:obj:`linalg.cho_solve` routines that work similarly to their LU
decomposition counterparts.


QR decomposition
^^^^^^^^^^^^^^^^

The QR decomposition (sometimes called a polar decomposition) works
for any :math:`M\times N` array and finds an :math:`M\times M` unitary
matrix :math:`\mathbf{Q}` and an :math:`M\times N` upper-trapezoidal
matrix :math:`\mathbf{R}`, such that

.. math::

    \mathbf{A=QR}.

Notice that if the SVD of :math:`\mathbf{A}` is known, then the QR decomposition can be found.

.. math::

    \mathbf{A}=\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^{H}=\mathbf{QR}

implies that :math:`\mathbf{Q}=\mathbf{U}` and
:math:`\mathbf{R}=\boldsymbol{\Sigma}\mathbf{V}^{H}.` Note, however,
that in SciPy independent algorithms are used to find QR and SVD
decompositions. The command for QR decomposition is :obj:`linalg.qr`.


Schur decomposition
^^^^^^^^^^^^^^^^^^^

For a square :math:`N\times N` matrix, :math:`\mathbf{A}`, the Schur
decomposition finds (not necessarily unique) matrices
:math:`\mathbf{T}` and :math:`\mathbf{Z}`, such that

.. math::

    \mathbf{A}=\mathbf{ZT}\mathbf{Z}^{H},

where :math:`\mathbf{Z}` is a unitary matrix and :math:`\mathbf{T}` is
either upper triangular or quasi upper triangular, depending on whether
or not a real Schur form or complex Schur form is requested.  For a
real Schur form both :math:`\mathbf{T}` and :math:`\mathbf{Z}` are
real-valued when :math:`\mathbf{A}` is real-valued. When
:math:`\mathbf{A}` is a real-valued matrix, the real Schur form is only
quasi upper triangular because :math:`2\times2` blocks extrude from
the main diagonal corresponding to any complex-valued
eigenvalues. The command :obj:`linalg.schur` finds the Schur
decomposition, while the command :obj:`linalg.rsf2csf` converts
:math:`\mathbf{T}` and :math:`\mathbf{Z}` from a real Schur form to a
complex Schur form. The Schur form is especially useful in calculating
functions of matrices.

The following example illustrates the Schur decomposition:

    >>> from scipy import linalg
    >>> A = np.mat('[1 3 2; 1 4 5; 2 3 6]')
    >>> T, Z = linalg.schur(A)
    >>> T1, Z1 = linalg.schur(A, 'complex')
    >>> T2, Z2 = linalg.rsf2csf(T, Z)
    >>> T
    array([[ 9.90012467,  1.78947961, -0.65498528],
           [ 0.        ,  0.54993766, -1.57754789],
           [ 0.        ,  0.51260928,  0.54993766]])
    >>> T2
    array([[ 9.90012467+0.00000000e+00j, -0.32436598+1.55463542e+00j,
            -0.88619748+5.69027615e-01j],
           [ 0.        +0.00000000e+00j,  0.54993766+8.99258408e-01j,
             1.06493862+3.05311332e-16j],
           [ 0.        +0.00000000e+00j,  0.        +0.00000000e+00j,
             0.54993766-8.99258408e-01j]])
    >>> abs(T1 - T2) # different
    array([[  1.06604538e-14,   2.06969555e+00,   1.69375747e+00],  # may vary
           [  0.00000000e+00,   1.33688556e-15,   4.74146496e-01],
           [  0.00000000e+00,   0.00000000e+00,   1.13220977e-15]])
    >>> abs(Z1 - Z2) # different
    array([[ 0.06833781,  0.88091091,  0.79568503],    # may vary
           [ 0.11857169,  0.44491892,  0.99594171],
           [ 0.12624999,  0.60264117,  0.77257633]])
    >>> T, Z, T1, Z1, T2, Z2 = map(np.mat,(T,Z,T1,Z1,T2,Z2))
    >>> abs(A - Z*T*Z.H)  # same
    matrix([[  5.55111512e-16,   1.77635684e-15,   2.22044605e-15],
            [  0.00000000e+00,   3.99680289e-15,   8.88178420e-16],
            [  1.11022302e-15,   4.44089210e-16,   3.55271368e-15]])
    >>> abs(A - Z1*T1*Z1.H)  # same
    matrix([[  4.26993904e-15,   6.21793362e-15,   8.00007092e-15],
            [  5.77945386e-15,   6.21798014e-15,   1.06653681e-14],
            [  7.16681444e-15,   8.90271058e-15,   1.77635764e-14]])
    >>> abs(A - Z2*T2*Z2.H)  # same
    matrix([[  6.02594127e-16,   1.77648931e-15,   2.22506907e-15],
            [  2.46275555e-16,   3.99684548e-15,   8.91642616e-16],
            [  8.88225111e-16,   8.88312432e-16,   4.44104848e-15]])


Interpolative decomposition
^^^^^^^^^^^^^^^^^^^^^^^^^^^

:mod:`scipy.linalg.interpolative` contains routines for computing the
interpolative decomposition (ID) of a matrix. For a matrix :math:`A
\in \mathbb{C}^{m \times n}` of rank :math:`k \leq \min \{ m, n \}`
this is a factorization

.. math::

  A \Pi =
  \begin{bmatrix}
   A \Pi_{1} & A \Pi_{2}
  \end{bmatrix} =
  A \Pi_{1}
  \begin{bmatrix}
   I & T
  \end{bmatrix},

where :math:`\Pi = [\Pi_{1}, \Pi_{2}]` is a permutation matrix with
:math:`\Pi_{1} \in \{ 0, 1 \}^{n \times k}`, i.e., :math:`A \Pi_{2} =
A \Pi_{1} T`. This can equivalently be written as :math:`A = BP`,
where :math:`B = A \Pi_{1}` and :math:`P = [I, T] \Pi^{\mathsf{T}}`
are the *skeleton* and *interpolation matrices*, respectively.

.. seealso:: `scipy.linalg.interpolative` --- for more information.


Matrix functions
----------------

Consider the function :math:`f\left(x\right)` with Taylor series expansion

.. math::

    f\left(x\right)=\sum_{k=0}^{\infty}\frac{f^{\left(k\right)}\left(0\right)}{k!}x^{k}.

A matrix function can be defined using this Taylor series for the
square matrix :math:`\mathbf{A}` as

.. math::

    f\left(\mathbf{A}\right)=\sum_{k=0}^{\infty}\frac{f^{\left(k\right)}\left(0\right)}{k!}\mathbf{A}^{k}.

While this serves as a useful representation of a matrix function, it
is rarely the best way to calculate a matrix function.


Exponential and logarithm functions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The matrix exponential is one of the more common matrix functions.
The preferred method for implementing the matrix exponential is to use
scaling and a Padé approximation for :math:`e^{x}`. This algorithm is
implemented as :obj:`linalg.expm`.

The inverse of the matrix exponential is the matrix logarithm defined
as the inverse of the matrix exponential:

.. math::

    \mathbf{A}\equiv\exp\left(\log\left(\mathbf{A}\right)\right).

The matrix logarithm can be obtained with :obj:`linalg.logm`.


Trigonometric functions
^^^^^^^^^^^^^^^^^^^^^^^

The trigonometric functions, :math:`\sin`, :math:`\cos`, and
:math:`\tan`, are implemented for matrices in :func:`linalg.sinm`,
:func:`linalg.cosm`, and :obj:`linalg.tanm`, respectively. The matrix
sine and cosine can be defined using Euler's identity as

.. math::
   :nowrap:

    \begin{eqnarray*} \sin\left(\mathbf{A}\right) & = & \frac{e^{j\mathbf{A}}-e^{-j\mathbf{A}}}{2j}\\ \cos\left(\mathbf{A}\right) & = & \frac{e^{j\mathbf{A}}+e^{-j\mathbf{A}}}{2}.\end{eqnarray*}

The tangent is

.. math::

    \tan\left(x\right)=\frac{\sin\left(x\right)}{\cos\left(x\right)}=\left[\cos\left(x\right)\right]^{-1}\sin\left(x\right)

and so the matrix tangent is defined as

.. math::

    \left[\cos\left(\mathbf{A}\right)\right]^{-1}\sin\left(\mathbf{A}\right).




Hyperbolic trigonometric functions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The hyperbolic trigonometric functions, :math:`\sinh`, :math:`\cosh`,
and :math:`\tanh`, can also be defined for matrices using the familiar
definitions:

.. math::
   :nowrap:

    \begin{eqnarray*} \sinh\left(\mathbf{A}\right) & = & \frac{e^{\mathbf{A}}-e^{-\mathbf{A}}}{2}\\ \cosh\left(\mathbf{A}\right) & = & \frac{e^{\mathbf{A}}+e^{-\mathbf{A}}}{2}\\ \tanh\left(\mathbf{A}\right) & = & \left[\cosh\left(\mathbf{A}\right)\right]^{-1}\sinh\left(\mathbf{A}\right).\end{eqnarray*}

These matrix functions can be found using :obj:`linalg.sinhm`,
:obj:`linalg.coshm`, and :obj:`linalg.tanhm`.


Arbitrary function
^^^^^^^^^^^^^^^^^^

Finally, any arbitrary function that takes one complex number and
returns a complex number can be called as a matrix function using the
command :obj:`linalg.funm`. This command takes the matrix and an
arbitrary Python function. It then implements an algorithm from Golub
and Van Loan's book "Matrix Computations" to compute the function applied
to the matrix using a Schur decomposition.  Note that *the function
needs to accept complex numbers* as input in order to work with this
algorithm. For example, the following code computes the zeroth-order
Bessel function applied to a matrix.

    >>> from scipy import special, linalg
    >>> rng = np.random.default_rng()
    >>> A = rng.random((3, 3))
    >>> B = linalg.funm(A, lambda x: special.jv(0, x))
    >>> A
    array([[0.06369197, 0.90647174, 0.98024544],
           [0.68752227, 0.5604377 , 0.49142032],
           [0.86754578, 0.9746787 , 0.37932682]])
    >>> B
    array([[ 0.6929219 , -0.29728805, -0.15930896],
           [-0.16226043,  0.71967826, -0.22709386],
           [-0.19945564, -0.33379957,  0.70259022]])
    >>> linalg.eigvals(A)
    array([ 1.94835336+0.j, -0.72219681+0.j, -0.22270006+0.j])
    >>> special.jv(0, linalg.eigvals(A))
    array([0.25375345+0.j, 0.87379738+0.j, 0.98763955+0.j])
    >>> linalg.eigvals(B)
    array([0.25375345+0.j, 0.87379738+0.j, 0.98763955+0.j])

Note how, by virtue of how matrix analytic functions are defined,
the Bessel function has acted on the matrix eigenvalues.


Special matrices
----------------

SciPy and NumPy provide several functions for creating special matrices
that are frequently used in engineering and science.

====================  =================================  =========================================================
Type                  Function                           Description
====================  =================================  =========================================================
block diagonal        `scipy.linalg.block_diag`          Create a block diagonal matrix from the provided arrays.
--------------------  ---------------------------------  ---------------------------------------------------------
circulant             `scipy.linalg.circulant`           Create a circulant matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
companion             `scipy.linalg.companion`           Create a companion matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
convolution           `scipy.linalg.convolution_matrix`  Create a convolution matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Discrete Fourier      `scipy.linalg.dft`                 Create a discrete Fourier transform matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Fiedler               `scipy.linalg.fiedler`             Create a symmetric Fiedler matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Fiedler Companion     `scipy.linalg.fiedler_companion`   Create a Fiedler companion matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Hadamard              `scipy.linalg.hadamard`            Create an Hadamard matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Hankel                `scipy.linalg.hankel`              Create a Hankel matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Helmert               `scipy.linalg.helmert`             Create a Helmert matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Hilbert               `scipy.linalg.hilbert`             Create a Hilbert matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Inverse Hilbert       `scipy.linalg.invhilbert`          Create the inverse of a Hilbert matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Leslie                `scipy.linalg.leslie`              Create a Leslie matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Pascal                `scipy.linalg.pascal`              Create a Pascal matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Inverse Pascal        `scipy.linalg.invpascal`           Create the inverse of a Pascal matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Toeplitz              `scipy.linalg.toeplitz`            Create a Toeplitz matrix.
--------------------  ---------------------------------  ---------------------------------------------------------
Van der Monde         `numpy.vander`                     Create a Van der Monde matrix.
====================  =================================  =========================================================


For examples of the use of these functions, see their respective docstrings.
Sparse eigenvalue problems with ARPACK
======================================

.. sectionauthor:: Jake Vanderplas <vanderplas@astro.washington.edu>

.. sectionauthor:: Matteo Ravasi  <matteoravasi@gmail.com>

.. currentmodule:: scipy.sparse.linalg


Introduction
------------
ARPACK [1]_ is a Fortran package which provides routines for quickly finding a few
eigenvalues/eigenvectors of large sparse matrices. In order to find these
solutions, it requires only left-multiplication by the matrix in question.
This operation is performed through a *reverse-communication* interface. The
result of this structure is that ARPACK is able to find eigenvalues and
eigenvectors of any linear function mapping a vector to a vector.

All of the functionality provided in ARPACK is contained within the two
high-level interfaces :func:`scipy.sparse.linalg.eigs` and
:func:`scipy.sparse.linalg.eigsh`. :func:`eigs`
provides interfaces for finding the
eigenvalues/vectors of real or complex nonsymmetric square matrices, while
:func:`eigsh` provides interfaces for real-symmetric or complex-hermitian
matrices.


Basic functionality
-------------------
ARPACK can solve either standard eigenvalue problems of the form

.. math::
   A \mathbf{x} = \lambda \mathbf{x}

or general eigenvalue problems of the form

.. math::
   A \mathbf{x} = \lambda M \mathbf{x}.

The power of ARPACK is that it can compute only a specified subset of
eigenvalue/eigenvector pairs. This is accomplished through the keyword
``which``. The following values of ``which`` are available:

* ``which = 'LM'`` : Eigenvalues with largest magnitude (``eigs``, ``eigsh``),
  that is, largest eigenvalues in the euclidean norm of complex numbers.
* ``which = 'SM'`` : Eigenvalues with smallest magnitude (``eigs``, ``eigsh``),
  that is, smallest eigenvalues in the euclidean norm of complex numbers.
* ``which = 'LR'`` : Eigenvalues with largest real part (``eigs``).
* ``which = 'SR'`` : Eigenvalues with smallest real part (``eigs``).
* ``which = 'LI'`` : Eigenvalues with largest imaginary part (``eigs``).
* ``which = 'SI'`` : Eigenvalues with smallest imaginary part (``eigs``).
* ``which = 'LA'`` : Eigenvalues with largest algebraic value (``eigsh``),
  that is, largest eigenvalues inclusive of any negative sign.
* ``which = 'SA'`` : Eigenvalues with smallest algebraic value (``eigsh``),
  that is, smallest eigenvalues inclusive of any negative sign.
* ``which = 'BE'`` : Eigenvalues from both ends of the spectrum (``eigsh``).

Note that ARPACK is generally better at finding extremal eigenvalues, that
is, eigenvalues with large magnitudes. In particular, using ``which = 'SM'``
may lead to slow execution time and/or anomalous results. A better approach
is to use *shift-invert mode*.


Shift-invert mode
-----------------
Shift-invert mode relies on the following observation. For the generalized
eigenvalue problem

.. math::
   A \mathbf{x} = \lambda M \mathbf{x},

it can be shown that

.. math::
   (A - \sigma M)^{-1} M \mathbf{x} = \nu \mathbf{x},

where

.. math::
   \nu = \frac{1}{\lambda - \sigma}.


Examples
--------
Imagine you'd like to find the smallest and largest eigenvalues and the
corresponding eigenvectors for a large matrix. ARPACK can handle many
forms of input: dense matrices ,such as `numpy.ndarray` instances, sparse
matrices, such as :func:`scipy.sparse.csr_matrix`, or a general linear operator
derived from :func:`scipy.sparse.linalg.LinearOperator`. For this example, for
simplicity, we'll construct a symmetric, positive-definite matrix.

    >>> import numpy as np
    >>> from scipy.linalg import eig, eigh
    >>> from scipy.sparse.linalg import eigs, eigsh
    >>> np.set_printoptions(suppress=True)
    >>> rng = np.random.default_rng()
    >>>
    >>> X = rng.random((100, 100)) - 0.5
    >>> X = np.dot(X, X.T)  # create a symmetric matrix

We now have a symmetric matrix ``X``, with which to test the routines. First,
compute a standard eigenvalue decomposition using ``eigh``:

    >>> evals_all, evecs_all = eigh(X)

As the dimension of ``X`` grows, this routine becomes very slow. Especially,
if only a few eigenvectors and eigenvalues are needed, ``ARPACK`` can be a
better option. First let's compute the largest eigenvalues (``which = 'LM'``)
of ``X`` and compare them to the known results:

    >>> evals_large, evecs_large = eigsh(X, 3, which='LM')
    >>> print(evals_all[-3:])
    [29.22435321 30.05590784 30.58591252]
    >>> print(evals_large)
    [29.22435321 30.05590784 30.58591252]
    >>> print(np.dot(evecs_large.T, evecs_all[:,-3:]))
    array([[-1.  0.  0.],       # may vary (signs)
           [ 0.  1.  0.],
           [-0.  0. -1.]])

The results are as expected. ARPACK recovers the desired eigenvalues and they
match the previously known results. Furthermore, the eigenvectors are
orthogonal, as we'd expect. Now, let's attempt to solve for the eigenvalues
with smallest magnitude:

   >>> evals_small, evecs_small = eigsh(X, 3, which='SM')
   Traceback (most recent call last):       # may vary (convergence)
   ...
   scipy.sparse.linalg._eigen.arpack.arpack.ArpackNoConvergence:
   ARPACK error -1: No convergence (1001 iterations, 0/3 eigenvectors converged)

Oops. We see that, as mentioned above, ``ARPACK`` is not quite as adept at
finding small eigenvalues. There are a few ways this problem can be
addressed. We could increase the tolerance (``tol``) to lead to faster
convergence:

    >>> evals_small, evecs_small = eigsh(X, 3, which='SM', tol=1E-2)
    >>> evals_all[:3]
    array([0.00053181, 0.00298319, 0.01387821])
    >>> evals_small
    array([0.00053181, 0.00298319, 0.01387821])
    >>> np.dot(evecs_small.T, evecs_all[:,:3])
    array([[ 0.99999999  0.00000024 -0.00000049],    # may vary (signs)
           [-0.00000023  0.99999999  0.00000056],
           [ 0.00000031 -0.00000037  0.99999852]])

This works, but we lose the precision in the results. Another option is
to increase the maximum number of iterations (``maxiter``) from 1000 to 5000:

    >>> evals_small, evecs_small = eigsh(X, 3, which='SM', maxiter=5000)
    >>> evals_all[:3]
    array([0.00053181, 0.00298319, 0.01387821])
    >>> evals_small
    array([0.00053181, 0.00298319, 0.01387821])
    >>> np.dot(evecs_small.T, evecs_all[:,:3])
    array([[ 1.  0.  0.],           # may vary (signs)
           [-0.  1.  0.],
           [ 0.  0. -1.]])

We get the results we'd hoped for, but the computation time is much longer.
Fortunately, ``ARPACK`` contains a mode that allows a quick determination of
non-external eigenvalues: *shift-invert mode*. As mentioned above, this
mode involves transforming the eigenvalue problem to an equivalent problem
with different eigenvalues. In this case, we hope to find eigenvalues near
zero, so we'll choose ``sigma = 0``. The transformed eigenvalues will
then satisfy :math:`\nu = 1/(\lambda - \sigma) = 1/\lambda`, so our
small eigenvalues :math:`\lambda` become large eigenvalues :math:`\nu`.

    >>> evals_small, evecs_small = eigsh(X, 3, sigma=0, which='LM')
    >>> evals_all[:3]
    array([0.00053181, 0.00298319, 0.01387821])
    >>> evals_small
    array([0.00053181, 0.00298319, 0.01387821])
    >>> np.dot(evecs_small.T, evecs_all[:,:3])
    array([[ 1.  0.  0.],    # may vary (signs)
           [ 0. -1. -0.],
           [-0. -0.  1.]])

We get the results we were hoping for, with much less computational time.
Note that the transformation from :math:`\nu \to \lambda` takes place
entirely in the background. The user need not worry about the details.

The shift-invert mode provides more than just a fast way to obtain a few
small eigenvalues. Say, you
desire to find internal eigenvalues and eigenvectors, e.g., those nearest to
:math:`\lambda = 1`. Simply set ``sigma = 1`` and ARPACK will take care of
the rest:

    >>> evals_mid, evecs_mid = eigsh(X, 3, sigma=1, which='LM')
    >>> i_sort = np.argsort(abs(1. / (1 - evals_all)))[-3:]
    >>> evals_all[i_sort]
    array([0.94164107, 1.05464515, 0.99090277])
    >>> evals_mid
    array([0.94164107, 0.99090277, 1.05464515])
    >>> print(np.dot(evecs_mid.T, evecs_all[:,i_sort]))
    array([[-0.  1.  0.],     # may vary (signs)
           [-0. -0.  1.],
           [ 1.  0.  0.]]

The eigenvalues come out in a different order, but they're all there.
Note that the shift-invert mode requires the internal solution of a matrix
inverse. This is taken care of automatically by ``eigsh`` and `eigs`,
but the operation can also be specified by the user. See the docstring of
:func:`scipy.sparse.linalg.eigsh` and
:func:`scipy.sparse.linalg.eigs` for details.


Use of LinearOperator
---------------------
We consider now the case where you'd like to avoid creating a dense matrix
and use :func:`scipy.sparse.linalg.LinearOperator` instead. Our first
linear operator applies element-wise multiplication between the input vector
and a vector :math:`\mathbf{d}` provided by the user to the operator itself.
This operator mimics a diagonal matrix with the elements of :math:`\mathbf{d}`
along the main diagonal and it has the main benefit that the forward and
adjoint operations are simple element-wise multiplications other
than matrix-vector multiplications. For a diagonal matrix, we expect the
eigenvalues to be equal to the elements along the main diagonal, in this case
:math:`\mathbf{d}`. The eigenvalues and eigenvectors obtained with ``eigsh``
are compared to those obtained by using ``eigh`` when applied to
the dense matrix:

   >>> from scipy.sparse.linalg import LinearOperator
   >>> class Diagonal(LinearOperator):
   ...     def __init__(self, diag, dtype='float32'):
   ...         self.diag = diag
   ...         self.shape = (len(self.diag), len(self.diag))
   ...         self.dtype = np.dtype(dtype)
   ...     def _matvec(self, x):
   ...         return self.diag*x
   ...     def _rmatvec(self, x):
   ...         return self.diag*x

   >>> N = 100
   >>> rng = np.random.default_rng()
   >>> d = rng.normal(0, 1, N).astype(np.float64)
   >>> D = np.diag(d)
   >>> Dop = Diagonal(d, dtype=np.float64)

   >>> evals_all, evecs_all = eigh(D)
   >>> evals_large, evecs_large = eigsh(Dop, 3, which='LA', maxiter=1e3)
   >>> evals_all[-3:]
   array([1.53092498, 1.77243671, 2.00582508])
   >>> evals_large
   array([1.53092498, 1.77243671, 2.00582508])
   >>> print(np.dot(evecs_large.T, evecs_all[:,-3:]))
   array([[-1.  0.  0.],     # may vary (signs)
          [-0. -1.  0.],
          [ 0.  0. -1.]]

In this case, we have created a quick and easy ``Diagonal`` operator.
The external library `PyLops <https://pylops.readthedocs.io>`_ provides
similar capabilities in the `Diagonal <https://pylops.readthedocs.io/en/
latest/api/generated/pylops.Diagonal.html#pylops.Diagonal>`_ operator,
as well as several other operators.

Finally, we consider a linear operator that mimics the application of a
first-derivative stencil. In this case, the operator is equivalent to a real
nonsymmetric matrix. Once again, we compare the estimated eigenvalues
and eigenvectors with those from a dense matrix that applies the
same first derivative to an input signal:

    >>> class FirstDerivative(LinearOperator):
    ...     def __init__(self, N, dtype='float32'):
    ...         self.N = N
    ...         self.shape = (self.N, self.N)
    ...         self.dtype = np.dtype(dtype)
    ...     def _matvec(self, x):
    ...         y = np.zeros(self.N, self.dtype)
    ...         y[1:-1] = (0.5*x[2:]-0.5*x[0:-2])
    ...         return y
    ...     def _rmatvec(self, x):
    ...         y = np.zeros(self.N, self.dtype)
    ...         y[0:-2] = y[0:-2] - (0.5*x[1:-1])
    ...         y[2:] = y[2:] + (0.5*x[1:-1])
    ...         return y

    >>> N = 21
    >>> D = np.diag(0.5*np.ones(N-1), k=1) - np.diag(0.5*np.ones(N-1), k=-1)
    >>> D[0] = D[-1] = 0 # take away edge effects
    >>> Dop = FirstDerivative(N, dtype=np.float64)

    >>> evals_all, evecs_all = eig(D)
    >>> evals_large, evecs_large = eigs(Dop, 4, which='LI')
    >>> evals_all_imag = evals_all.imag
    >>> isort_imag = np.argsort(np.abs(evals_all_imag))
    >>> evals_all_imag = evals_all_imag[isort_imag]
    >>> evals_large_imag = evals_large.imag
    >>> isort_imag = np.argsort(np.abs(evals_large_imag))
    >>> evals_large_imag = evals_large_imag[isort_imag]
    >>> evals_all_imag[-4:]
    array([-0.95105652, 0.95105652, -0.98768834, 0.98768834])
    >>> evals_large_imag
    array([0.95105652, -0.95105652, 0.98768834, -0.98768834])

Note that the eigenvalues of this operator are all imaginary. Moreover,
the keyword ``which='LI'`` of :func:`scipy.sparse.linalg.eigs` produces
the eigenvalues with largest absolute imaginary part (both
positive and negative). Again, a more advanced implementation of the
first-derivative operator is available in the
`PyLops <https://pylops.readthedocs.io>`_ library under the name of
`FirstDerivative <https://pylops.
readthedocs.io/en/latest/api/generated/pylops.FirstDerivative.html>`_
operator.


References
----------
.. [1] http://www.caam.rice.edu/software/ARPACK/
Integration (:mod:`scipy.integrate`)
====================================

.. sectionauthor:: Travis E. Oliphant

.. currentmodule:: scipy.integrate

The :mod:`scipy.integrate` sub-package provides several integration
techniques including an ordinary differential equation integrator. An
overview of the module is provided by the help command:

.. literalinclude:: examples/4-1


General integration (:func:`quad`)
----------------------------------

The function :obj:`quad` is provided to integrate a function of one
variable between two points. The points can be :math:`\pm\infty`
(:math:`\pm` ``inf``) to indicate infinite limits. For example,
suppose you wish to integrate a bessel function ``jv(2.5, x)`` along
the interval :math:`[0, 4.5].`

.. math::

    I=\int_{0}^{4.5}J_{2.5}\left(x\right)\, dx.


This could be computed using :obj:`quad`:

    >>> import scipy.integrate as integrate
    >>> import scipy.special as special
    >>> result = integrate.quad(lambda x: special.jv(2.5,x), 0, 4.5)
    >>> result
    (1.1178179380783249, 7.8663172481899801e-09)

    >>> from numpy import sqrt, sin, cos, pi
    >>> I = sqrt(2/pi)*(18.0/27*sqrt(2)*cos(4.5) - 4.0/27*sqrt(2)*sin(4.5) +
    ...                 sqrt(2*pi) * special.fresnel(3/sqrt(pi))[0])
    >>> I
    1.117817938088701

    >>> print(abs(result[0]-I))
    1.03761443881e-11

The first argument to quad is a "callable" Python object (i.e., a
function, method, or class instance). Notice the use of a lambda-
function in this case as the argument. The next two arguments are the
limits of integration. The return value is a tuple, with the first
element holding the estimated value of the integral and the second
element holding an upper bound on the error. Notice, that in this
case, the true value of this integral is

.. math::

    I=\sqrt{\frac{2}{\pi}}\left(\frac{18}{27}\sqrt{2}\cos\left(4.5\right)-\frac{4}{27}\sqrt{2}\sin\left(4.5\right)+\sqrt{2\pi}\textrm{Si}\left(\frac{3}{\sqrt{\pi}}\right)\right),

where

.. math::

    \textrm{Si}\left(x\right)=\int_{0}^{x}\sin\left(\frac{\pi}{2}t^{2}\right)\, dt.

is the Fresnel sine integral. Note that the numerically-computed integral is
within :math:`1.04\times10^{-11}` of the exact result --- well below the
reported error bound.


If the function to integrate takes additional parameters, they can be provided
in the `args` argument. Suppose that the following integral shall be calculated:

.. math::

    I(a,b)=\int_{0}^{1} ax^2+b \, dx.


This integral can be evaluated by using the following code:

>>> from scipy.integrate import quad
>>> def integrand(x, a, b):
...     return a*x**2 + b
...
>>> a = 2
>>> b = 1
>>> I = quad(integrand, 0, 1, args=(a,b))
>>> I
(1.6666666666666667, 1.8503717077085944e-14)


Infinite inputs are also allowed in :obj:`quad` by using :math:`\pm`
``inf`` as one of the arguments. For example, suppose that a numerical
value for the exponential integral:

.. math::

    E_{n}\left(x\right)=\int_{1}^{\infty}\frac{e^{-xt}}{t^{n}}\, dt.

is desired (and the fact that this integral can be computed as
``special.expn(n,x)`` is forgotten). The functionality of the function
:obj:`special.expn <scipy.special.expn>` can be replicated by defining a new function
``vec_expint`` based on the routine :obj:`quad`:

    >>> from scipy.integrate import quad
    >>> def integrand(t, n, x):
    ...     return np.exp(-x*t) / t**n
    ...

    >>> def expint(n, x):
    ...     return quad(integrand, 1, np.inf, args=(n, x))[0]
    ...

    >>> vec_expint = np.vectorize(expint)

    >>> vec_expint(3, np.arange(1.0, 4.0, 0.5))
    array([ 0.1097,  0.0567,  0.0301,  0.0163,  0.0089,  0.0049])
    >>> import scipy.special as special
    >>> special.expn(3, np.arange(1.0,4.0,0.5))
    array([ 0.1097,  0.0567,  0.0301,  0.0163,  0.0089,  0.0049])

The function which is integrated can even use the quad argument (though the
error bound may underestimate the error due to possible numerical error in the
integrand from the use of :obj:`quad` ). The integral in this case is

.. math::

    I_{n}=\int_{0}^{\infty}\int_{1}^{\infty}\frac{e^{-xt}}{t^{n}}\, dt\, dx=\frac{1}{n}.

>>> result = quad(lambda x: expint(3, x), 0, np.inf)
>>> print(result)
(0.33333333324560266, 2.8548934485373678e-09)

>>> I3 = 1.0/3.0
>>> print(I3)
0.333333333333

>>> print(I3 - result[0])
8.77306560731e-11

This last example shows that multiple integration can be handled using
repeated calls to :func:`quad`.


General multiple integration (:func:`dblquad`, :func:`tplquad`, :func:`nquad`)
------------------------------------------------------------------------------

The mechanics for double and triple integration have been wrapped up into the
functions :obj:`dblquad` and :obj:`tplquad`. These functions take the function
to  integrate and four, or six arguments, respectively. The limits of all
inner integrals need to be defined as functions.

An example of using double integration to compute several values of
:math:`I_{n}` is shown below:

    >>> from scipy.integrate import quad, dblquad
    >>> def I(n):
    ...     return dblquad(lambda t, x: np.exp(-x*t)/t**n, 0, np.inf, lambda x: 1, lambda x: np.inf)
    ...

    >>> print(I(4))
    (0.2500000000043577, 1.29830334693681e-08)
    >>> print(I(3))
    (0.33333333325010883, 1.3888461883425516e-08)
    >>> print(I(2))
    (0.4999999999985751, 1.3894083651858995e-08)


As example for non-constant limits consider the integral

.. math::

    I=\int_{y=0}^{1/2}\int_{x=0}^{1-2y} x y \, dx\, dy=\frac{1}{96}.


This integral can be evaluated using the expression below (Note the use of the
non-constant lambda functions for the upper limit of the inner integral):

>>> from scipy.integrate import dblquad
>>> area = dblquad(lambda x, y: x*y, 0, 0.5, lambda x: 0, lambda x: 1-2*x)
>>> area
(0.010416666666666668, 1.1564823173178715e-16)


For n-fold integration, scipy provides the function :obj:`nquad`. The
integration bounds are an iterable object: either a list of constant bounds,
or a list of functions for the non-constant integration bounds. The order of
integration (and therefore the bounds) is from the innermost integral to the
outermost one.

The integral from above

.. math::

    I_{n}=\int_{0}^{\infty}\int_{1}^{\infty}\frac{e^{-xt}}{t^{n}}\, dt\, dx=\frac{1}{n}

can be calculated as

>>> from scipy import integrate
>>> N = 5
>>> def f(t, x):
...    return np.exp(-x*t) / t**N
...
>>> integrate.nquad(f, [[1, np.inf],[0, np.inf]])
(0.20000000000002294, 1.2239614263187945e-08)

Note that the order of arguments for `f` must match the order of the
integration bounds; i.e., the inner integral with respect to :math:`t` is on
the interval :math:`[1, \infty]` and the outer integral with respect to
:math:`x` is on the interval :math:`[0, \infty]`.

Non-constant integration bounds can be treated in a similar manner; the
example from above

.. math::

    I=\int_{y=0}^{1/2}\int_{x=0}^{1-2y} x y \, dx\, dy=\frac{1}{96}.

can be evaluated by means of

>>> from scipy import integrate
>>> def f(x, y):
...     return x*y
...
>>> def bounds_y():
...     return [0, 0.5]
...
>>> def bounds_x(y):
...     return [0, 1-2*y]
...
>>> integrate.nquad(f, [bounds_x, bounds_y])
(0.010416666666666668, 4.101620128472366e-16)

which is the same result as before.

Gaussian quadrature
-------------------

A few functions are also provided in order to perform simple Gaussian
quadrature over a fixed interval. The first is :obj:`fixed_quad`, which
performs fixed-order Gaussian quadrature. The second function is
:obj:`quadrature`, which performs Gaussian quadrature of multiple
orders until the difference in the integral estimate is beneath some
tolerance supplied by the user. These functions both use the module
``scipy.special.orthogonal``, which can calculate the roots and quadrature
weights of a large variety of orthogonal polynomials (the polynomials
themselves are available as special functions returning instances of
the polynomial class --- e.g., :obj:`special.legendre <scipy.special.legendre>`).


Romberg Integration
-------------------

Romberg's method [WPR]_ is another method for numerically evaluating an
integral. See the help function for :func:`romberg` for further details.


Integrating using Samples
-------------------------

If the samples are equally-spaced and the number of samples available
is :math:`2^{k}+1` for some integer :math:`k`, then Romberg :obj:`romb`
integration can be used to obtain high-precision estimates of the
integral using the available samples. Romberg integration uses the
trapezoid rule at step-sizes related by a power of two and then
performs Richardson extrapolation on these estimates to approximate
the integral with a higher degree of accuracy.

In case of arbitrary spaced samples, the two functions :obj:`trapezoid`
and :obj:`simpson` are available. They are using Newton-Coates formulas
of order 1 and 2 respectively to perform integration. The trapezoidal rule
approximates the function as a straight line between adjacent points, while
Simpson's rule approximates the function between three adjacent points as a
parabola.

For an odd number of samples that are equally spaced Simpson's rule is exact
if the function is a polynomial of order 3 or less. If the samples are not
equally spaced, then the result is exact only if the function is a polynomial
of order 2 or less.

>>> import numpy as np
>>> def f1(x):
...    return x**2
...
>>> def f2(x):
...    return x**3
...
>>> x = np.array([1,3,4])
>>> y1 = f1(x)
>>> from scipy import integrate
>>> I1 = integrate.simpson(y1, x)
>>> print(I1)
21.0


This corresponds exactly to

.. math::

    \int_{1}^{4} x^2 \, dx = 21,

whereas integrating the second function

>>> y2 = f2(x)
>>> I2 = integrate.simpson(y2, x)
>>> print(I2)
61.5

does not correspond to

.. math::

    \int_{1}^{4} x^3 \, dx = 63.75

because the order of the polynomial in f2 is larger than two.

.. _quad-callbacks:

Faster integration using low-level callback functions
-----------------------------------------------------

A user desiring reduced integration times may pass a C function
pointer through `scipy.LowLevelCallable` to `quad`, `dblquad`,
`tplquad` or `nquad` and it will be integrated and return a result in
Python.  The performance increase here arises from two factors.  The
primary improvement is faster function evaluation, which is provided
by compilation of the function itself.  Additionally we have a speedup
provided by the removal of function calls between C and Python in
:obj:`quad`.  This method may provide a speed improvements of ~2x for
trivial functions such as sine but can produce a much more noticeable
improvements (10x+) for more complex functions.  This feature then, is
geared towards a user with numerically intensive integrations willing
to write a little C to reduce computation time significantly.

The approach can be used, for example, via `ctypes` in a few simple steps:

1.) Write an integrand function in C with the function signature
``double f(int n, double *x, void *user_data)``, where ``x`` is an
array containing the point the function f is evaluated at, and ``user_data``
to arbitrary additional data you want to provide.

.. code-block:: c

   /* testlib.c */
   double f(int n, double *x, void *user_data) {
       double c = *(double *)user_data;
       return c + x[0] - x[1] * x[2]; /* corresponds to c + x - y * z */
   }

2.) Now compile this file to a shared/dynamic library (a quick search will help
with this as it is OS-dependent). The user must link any math libraries,
etc., used.  On linux this looks like::

    $ gcc -shared -fPIC -o testlib.so testlib.c

The output library will be referred to as ``testlib.so``, but it may have a
different file extension. A library has now been created that can be loaded
into Python with `ctypes`.

3.) Load shared library into Python using `ctypes` and set ``restypes`` and
``argtypes`` - this allows SciPy to interpret the function correctly:

.. code:: python

   import os, ctypes
   from scipy import integrate, LowLevelCallable

   lib = ctypes.CDLL(os.path.abspath('testlib.so'))
   lib.f.restype = ctypes.c_double
   lib.f.argtypes = (ctypes.c_int, ctypes.POINTER(ctypes.c_double), ctypes.c_void_p)

   c = ctypes.c_double(1.0)
   user_data = ctypes.cast(ctypes.pointer(c), ctypes.c_void_p)

   func = LowLevelCallable(lib.f, user_data)

The last ``void *user_data`` in the function is optional and can be omitted
(both in the C function and ctypes argtypes) if not needed. Note that the
coordinates are passed in as an array of doubles rather than a separate argument.

4.) Now integrate the library function as normally, here using `nquad`:

>>> integrate.nquad(func, [[0, 10], [-10, 0], [-1, 1]])
(1200.0, 1.1102230246251565e-11)

The Python tuple is returned as expected in a reduced amount of time.  All
optional parameters can be used with this method including specifying
singularities, infinite bounds, etc.

Ordinary differential equations (:func:`solve_ivp`)
---------------------------------------------------

Integrating a set of ordinary differential equations (ODEs) given
initial conditions is another useful example. The function
:obj:`solve_ivp` is available in SciPy for integrating a first-order
vector differential equation:

.. math::

    \frac{d\mathbf{y}}{dt}=\mathbf{f}\left(\mathbf{y},t\right),

given initial conditions :math:`\mathbf{y}\left(0\right)=y_{0}`, where
:math:`\mathbf{y}` is a length :math:`N` vector and :math:`\mathbf{f}`
is a mapping from :math:`\mathcal{R}^{N}` to :math:`\mathcal{R}^{N}.`
A higher-order ordinary differential equation can always be reduced to
a differential equation of this type by introducing intermediate
derivatives into the :math:`\mathbf{y}` vector.

For example, suppose it is desired to find the solution to the
following second-order differential equation:

.. math::

    \frac{d^{2}w}{dz^{2}}-zw(z)=0

with initial conditions :math:`w\left(0\right)=\frac{1}{\sqrt[3]{3^{2}}\Gamma\left(\frac{2}{3}\right)}` and :math:`\left.\frac{dw}{dz}\right|_{z=0}=-\frac{1}{\sqrt[3]{3}\Gamma\left(\frac{1}{3}\right)}.` It is known that the solution to this differential equation with these
boundary conditions is the Airy function

.. math::

    w=\textrm{Ai}\left(z\right),

which gives a means to check the integrator using :func:`special.airy <scipy.special.airy>`.

First, convert this ODE into standard form by setting
:math:`\mathbf{y}=\left[\frac{dw}{dz},w\right]` and :math:`t=z`. Thus,
the differential equation becomes

.. math::

    \frac{d\mathbf{y}}{dt}=\left[\begin{array}{c} ty_{1}\\ y_{0}\end{array}\right]=\left[\begin{array}{cc} 0 & t\\ 1 & 0\end{array}\right]\left[\begin{array}{c} y_{0}\\ y_{1}\end{array}\right]=\left[\begin{array}{cc} 0 & t\\ 1 & 0\end{array}\right]\mathbf{y}.

In other words,

.. math::

    \mathbf{f}\left(\mathbf{y},t\right)=\mathbf{A}\left(t\right)\mathbf{y}.

As an interesting reminder, if :math:`\mathbf{A}\left(t\right)`
commutes with :math:`\int_{0}^{t}\mathbf{A}\left(\tau\right)\, d\tau`
under matrix multiplication, then this linear differential equation
has an exact solution using the matrix exponential:

.. math::

    \mathbf{y}\left(t\right)=\exp\left(\int_{0}^{t}\mathbf{A}\left(\tau\right)d\tau\right)\mathbf{y}\left(0\right),

However, in this case, :math:`\mathbf{A}\left(t\right)` and its integral do not commute.

This differential equation can be solved using the function :obj:`solve_ivp`.
It requires the derivative, *fprime*, the time span `[t_start, t_end]`
and the initial conditions vector, *y0*, as input arguments and returns
an object whose *y* field is an array with consecutive solution values as
columns. The initial conditions are therefore given in the first output column.

>>> from scipy.integrate import solve_ivp
>>> from scipy.special import gamma, airy
>>> y1_0 = +1 / 3**(2/3) / gamma(2/3)
>>> y0_0 = -1 / 3**(1/3) / gamma(1/3)
>>> y0 = [y0_0, y1_0]
>>> def func(t, y):
...     return [t*y[1],y[0]]
...
>>> t_span = [0, 4]
>>> sol1 = solve_ivp(func, t_span, y0)
>>> print("sol1.t: {}".format(sol1.t))
sol1.t:    [0.         0.10097672 1.04643602 1.91060117 2.49872472 3.08684827
 3.62692846 4.        ]

As it can be seen `solve_ivp` determines its time steps automatically if not
specified otherwise. To compare the solution of `solve_ivp` with the `airy`
function the time vector created by `solve_ivp` is passed to the `airy` function.

>>> print("sol1.y[1]: {}".format(sol1.y[1]))
sol1.y[1]: [0.35502805 0.328952   0.12801343 0.04008508 0.01601291 0.00623879
 0.00356316 0.00405982]
>>> print("airy(sol.t)[0]:  {}".format(airy(sol1.t)[0]))
airy(sol.t)[0]: [0.35502805 0.328952   0.12804768 0.03995804 0.01575943 0.00562799
 0.00201689 0.00095156]

The solution of `solve_ivp` with its standard parameters shows a big deviation
to the airy function. To minimize this deviation, relative and absolute
tolerances can be used.

>>> rtol, atol = (1e-8, 1e-8)
>>> sol2 = solve_ivp(func, t_span, y0, rtol=rtol, atol=atol)
>>> print("sol2.y[1][::6]: {}".format(sol2.y[1][0::6]))
sol2.y[1][::6]: [0.35502805 0.19145234 0.06368989 0.0205917  0.00554734 0.00106409]
>>> print("airy(sol2.t)[0][::6]: {}".format(airy(sol2.t)[0][::6]))
airy(sol2.t)[0][::6]: [0.35502805 0.19145234 0.06368989 0.0205917  0.00554733 0.00106406]

To specify user defined time points for the solution of `solve_ivp`, `solve_ivp`
offers two possibilities that can also be used complementarily. By passing the `t_eval`
option to the function call `solve_ivp` returns the solutions of these time points
of `t_eval` in its output.

>>> import numpy as np
>>> t = np.linspace(0, 4, 100)
>>> sol3 = solve_ivp(func, t_span, y0, t_eval=t)

If the jacobian matrix of function is known, it can be passed to the `solve_ivp`
to achieve better results. Please be aware however that the default integration method
`RK45` does not support jacobian matrices and thereby another integration method has
to be chosen. One of the integration methods that support a jacobian matrix is the for
example the `Radau` method of following example.

>>> def gradient(t, y):
...     return [[0,t], [1,0]]
>>> sol4 = solve_ivp(func, t_span, y0, method='Radau', jac=gradient)

Solving a system with a banded Jacobian matrix
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

`odeint` can be told that the Jacobian is *banded*.  For a large
system of differential equations that are known to be stiff, this
can improve performance significantly.

As an example, we'll solve the 1-D Gray-Scott partial
differential equations using the method of lines [MOL]_.  The Gray-Scott equations
for the functions :math:`u(x, t)` and :math:`v(x, t)` on the interval
:math:`x \in [0, L]` are

.. math::

    \begin{split}
    \frac{\partial u}{\partial t} = D_u \frac{\partial^2 u}{\partial x^2} - uv^2 + f(1-u) \\
    \frac{\partial v}{\partial t} = D_v \frac{\partial^2 v}{\partial x^2} + uv^2 - (f + k)v \\
    \end{split}

where :math:`D_u` and :math:`D_v` are the diffusion coefficients of the
components :math:`u` and :math:`v`, respectively, and :math:`f` and :math:`k`
are constants.  (For more information about the system, see
http://groups.csail.mit.edu/mac/projects/amorphous/GrayScott/)

We'll assume Neumann (i.e., "no flux") boundary conditions:

.. math::

    \frac{\partial u}{\partial x}(0,t) = 0, \quad
    \frac{\partial v}{\partial x}(0,t) = 0, \quad
    \frac{\partial u}{\partial x}(L,t) = 0, \quad
    \frac{\partial v}{\partial x}(L,t) = 0

To apply the method of lines, we discretize the :math:`x` variable by defining
the uniformly spaced grid of :math:`N` points :math:`\left\{x_0, x_1, \ldots, x_{N-1}\right\}`, with
:math:`x_0 = 0` and :math:`x_{N-1} = L`.
We define :math:`u_j(t) \equiv u(x_k, t)` and :math:`v_j(t) \equiv v(x_k, t)`, and
replace the :math:`x` derivatives with finite differences.  That is,

.. math::

    \frac{\partial^2 u}{\partial x^2}(x_j, t) \rightarrow
        \frac{u_{j-1}(t) - 2 u_{j}(t) + u_{j+1}(t)}{(\Delta x)^2}

We then have a system of :math:`2N` ordinary differential equations:

.. math::
   :label: interior

    \begin{split}
    \frac{du_j}{dt} = \frac{D_u}{(\Delta x)^2} \left(u_{j-1} - 2 u_{j} + u_{j+1}\right)
          -u_jv_j^2 + f(1 - u_j) \\
    \frac{dv_j}{dt} = \frac{D_v}{(\Delta x)^2} \left(v_{j-1} - 2 v_{j} + v_{j+1}\right)
          + u_jv_j^2 - (f + k)v_j
    \end{split}

For convenience, the :math:`(t)` arguments have been dropped.

To enforce the boundary conditions, we introduce "ghost" points
:math:`x_{-1}` and :math:`x_N`, and define :math:`u_{-1}(t) \equiv u_1(t)`,
:math:`u_N(t) \equiv u_{N-2}(t)`; :math:`v_{-1}(t)` and :math:`v_N(t)`
are defined analogously.

Then

.. math::
   :label: boundary0

    \begin{split}
    \frac{du_0}{dt} = \frac{D_u}{(\Delta x)^2} \left(2u_{1} - 2 u_{0}\right)
          -u_0v_0^2 + f(1 - u_0) \\
    \frac{dv_0}{dt} = \frac{D_v}{(\Delta x)^2} \left(2v_{1} - 2 v_{0}\right)
          + u_0v_0^2 - (f + k)v_0
    \end{split}

and

.. math::
   :label: boundaryL

    \begin{split}
    \frac{du_{N-1}}{dt} = \frac{D_u}{(\Delta x)^2} \left(2u_{N-2} - 2 u_{N-1}\right)
          -u_{N-1}v_{N-1}^2 + f(1 - u_{N-1}) \\
    \frac{dv_{N-1}}{dt} = \frac{D_v}{(\Delta x)^2} \left(2v_{N-2} - 2 v_{N-1}\right)
          + u_{N-1}v_{N-1}^2 - (f + k)v_{N-1}
    \end{split}

Our complete system of :math:`2N` ordinary differential equations is :eq:`interior`
for :math:`k = 1, 2, \ldots, N-2`, along with :eq:`boundary0` and :eq:`boundaryL`.

We can now starting implementing this system in code.  We must combine
:math:`\{u_k\}` and :math:`\{v_k\}` into a single vector of length :math:`2N`.
The two obvious choices are
:math:`\{u_0, u_1, \ldots, u_{N-1}, v_0, v_1, \ldots, v_{N-1}\}`
and
:math:`\{u_0, v_0, u_1, v_1, \ldots, u_{N-1}, v_{N-1}\}`.
Mathematically, it does not matter, but the choice affects how
efficiently `odeint` can solve the system.  The reason is in how
the order affects the pattern of the nonzero elements of the Jacobian matrix.


When the variables are ordered
as :math:`\{u_0, u_1, \ldots, u_{N-1}, v_0, v_1, \ldots, v_{N-1}\}`,
the pattern of nonzero elements of the Jacobian matrix is

.. math::

    \begin{smallmatrix}
       * & * & 0 & 0 & 0 & 0 & 0  &  * & 0 & 0 & 0 & 0 & 0 & 0 \\
       * & * & * & 0 & 0 & 0 & 0  &  0 & * & 0 & 0 & 0 & 0 & 0 \\
       0 & * & * & * & 0 & 0 & 0  &  0 & 0 & * & 0 & 0 & 0 & 0 \\
       0 & 0 & * & * & * & 0 & 0  &  0 & 0 & 0 & * & 0 & 0 & 0 \\
       0 & 0 & 0 & * & * & * & 0  &  0 & 0 & 0 & 0 & * & 0 & 0 \\
       0 & 0 & 0 & 0 & * & * & *  &  0 & 0 & 0 & 0 & 0 & * & 0 \\
       0 & 0 & 0 & 0 & 0 & * & *  &  0 & 0 & 0 & 0 & 0 & 0 & * \\
       * & 0 & 0 & 0 & 0 & 0 & 0  &  * & * & 0 & 0 & 0 & 0 & 0 \\
       0 & * & 0 & 0 & 0 & 0 & 0  &  * & * & * & 0 & 0 & 0 & 0 \\
       0 & 0 & * & 0 & 0 & 0 & 0  &  0 & * & * & * & 0 & 0 & 0 \\
       0 & 0 & 0 & * & 0 & 0 & 0  &  0 & 0 & * & * & * & 0 & 0 \\
       0 & 0 & 0 & 0 & * & 0 & 0  &  0 & 0 & 0 & * & * & * & 0 \\
       0 & 0 & 0 & 0 & 0 & * & 0  &  0 & 0 & 0 & 0 & * & * & * \\
       0 & 0 & 0 & 0 & 0 & 0 & *  &  0 & 0 & 0 & 0 & ) & * & * \\
    \end{smallmatrix}

The Jacobian pattern with variables interleaved
as :math:`\{u_0, v_0, u_1, v_1, \ldots, u_{N-1}, v_{N-1}\}` is

.. math::
    \begin{smallmatrix}
       * & * & * & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
       * & * & 0 & * & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
       * & 0 & * & * & * & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
       0 & * & * & * & 0 & * & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
       0 & 0 & * & 0 & * & * & * & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
       0 & 0 & 0 & * & * & * & 0 & * & 0 & 0 & 0 & 0 & 0 & 0 \\
       0 & 0 & 0 & 0 & * & 0 & * & * & * & 0 & 0 & 0 & 0 & 0 \\
       0 & 0 & 0 & 0 & 0 & * & * & * & 0 & * & 0 & 0 & 0 & 0 \\
       0 & 0 & 0 & 0 & 0 & 0 & * & 0 & * & * & * & 0 & 0 & 0 \\
       0 & 0 & 0 & 0 & 0 & 0 & 0 & * & * & * & 0 & * & 0 & 0 \\
       0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & * & 0 & * & * & * & 0 \\
       0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & * & * & * & 0 & * \\
       0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & * & 0 & * & * \\
       0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & * & * & * \\
    \end{smallmatrix}

In both cases, there are just five nontrivial diagonals, but
when the variables are interleaved, the bandwidth is much
smaller.
That is, the main diagonal and the two diagonals immediately
above and the two immediately below the main diagonal
are the nonzero diagonals.
This is important, because the inputs ``mu`` and ``ml``
of `odeint` are the upper and lower bandwidths of the
Jacobian matrix.  When the variables are interleaved,
``mu`` and ``ml`` are 2.  When the variables are stacked
with :math:`\{v_k\}` following :math:`\{u_k\}`, the upper
and lower bandwidths are :math:`N`.

With that decision made, we can write the function that
implements the system of differential equations.

First, we define the functions for the source and reaction
terms of the system::

    def G(u, v, f, k):
        return f * (1 - u) - u*v**2

    def H(u, v, f, k):
        return -(f + k) * v + u*v**2

Next, we define the function that computes the right-hand side
of the system of differential equations::

    def grayscott1d(y, t, f, k, Du, Dv, dx):
        """
        Differential equations for the 1-D Gray-Scott equations.

        The ODEs are derived using the method of lines.
        """
        # The vectors u and v are interleaved in y.  We define
        # views of u and v by slicing y.
        u = y[::2]
        v = y[1::2]

        # dydt is the return value of this function.
        dydt = np.empty_like(y)

        # Just like u and v are views of the interleaved vectors
        # in y, dudt and dvdt are views of the interleaved output
        # vectors in dydt.
        dudt = dydt[::2]
        dvdt = dydt[1::2]

        # Compute du/dt and dv/dt.  The end points and the interior points
        # are handled separately.
        dudt[0]    = G(u[0],    v[0],    f, k) + Du * (-2.0*u[0] + 2.0*u[1]) / dx**2
        dudt[1:-1] = G(u[1:-1], v[1:-1], f, k) + Du * np.diff(u,2) / dx**2
        dudt[-1]   = G(u[-1],   v[-1],   f, k) + Du * (- 2.0*u[-1] + 2.0*u[-2]) / dx**2
        dvdt[0]    = H(u[0],    v[0],    f, k) + Dv * (-2.0*v[0] + 2.0*v[1]) / dx**2
        dvdt[1:-1] = H(u[1:-1], v[1:-1], f, k) + Dv * np.diff(v,2) / dx**2
        dvdt[-1]   = H(u[-1],   v[-1],   f, k) + Dv * (-2.0*v[-1] + 2.0*v[-2]) / dx**2

        return dydt

We won't implement a function to compute the Jacobian, but we will tell
`odeint` that the Jacobian matrix is banded.  This allows the underlying
solver (LSODA) to avoid computing values that it knows are zero.  For a large
system, this improves the performance significantly, as demonstrated in the
following ipython session.

First, we define the required inputs::

    In [30]: rng = np.random.default_rng()

    In [31]: y0 = rng.standard_normal(5000)

    In [32]: t = np.linspace(0, 50, 11)

    In [33]: f = 0.024

    In [34]: k = 0.055

    In [35]: Du = 0.01

    In [36]: Dv = 0.005

    In [37]: dx = 0.025

Time the computation without taking advantage of the banded structure
of the Jacobian matrix::

    In [38]: %timeit sola = odeint(grayscott1d, y0, t, args=(f, k, Du, Dv, dx))
    1 loop, best of 3: 25.2 s per loop

Now set ``ml=2`` and ``mu=2``, so `odeint` knows that the Jacobian matrix
is banded::

    In [39]: %timeit solb = odeint(grayscott1d, y0, t, args=(f, k, Du, Dv, dx), ml=2, mu=2)
    10 loops, best of 3: 191 ms per loop

That is quite a bit faster!

Let's ensure that they have computed the same result::

    In [41]: np.allclose(sola, solb)
    Out[41]: True

References
~~~~~~~~~~

.. [WPR] https://en.wikipedia.org/wiki/Romberg's_method

.. [MOL] https://en.wikipedia.org/wiki/Method_of_lines
Fourier Transforms (:mod:`scipy.fft`)
=========================================

.. sectionauthor:: SciPy Developers

.. currentmodule:: scipy.fft

.. contents::


Fourier analysis is a method for expressing a function as a sum of periodic
components, and for recovering the signal from those components. When both
the function and its Fourier transform are replaced with discretized
counterparts, it is called the discrete Fourier transform (DFT). The DFT has
become a mainstay of numerical computing in part because of a very fast
algorithm for computing it, called the Fast Fourier Transform (FFT), which was
known to Gauss (1805) and was brought to light in its current form by Cooley
and Tukey [CT65]_. Press et al. [NR07]_ provide an accessible introduction to
Fourier analysis and its applications.


Fast Fourier transforms
-----------------------

1-D discrete Fourier transforms
___________________________________________

The FFT `y[k]` of length :math:`N` of the length-:math:`N` sequence `x[n]` is
defined as

.. math::

    y[k] = \sum_{n=0}^{N-1} e^{-2 \pi j \frac{k n}{N} } x[n] \, ,

and the inverse transform is defined as follows

.. math::

    x[n] = \frac{1}{N} \sum_{k=0}^{N-1} e^{2 \pi j \frac{k n}{N} } y[k] \, .

These transforms can be calculated by means of :func:`fft` and :func:`ifft`,
respectively, as shown in the following example.

>>> from scipy.fft import fft, ifft
>>> x = np.array([1.0, 2.0, 1.0, -1.0, 1.5])
>>> y = fft(x)
>>> y
array([ 4.5       +0.j        ,  2.08155948-1.65109876j,
       -1.83155948+1.60822041j, -1.83155948-1.60822041j,
        2.08155948+1.65109876j])
>>> yinv = ifft(y)
>>> yinv
array([ 1.0+0.j,  2.0+0.j,  1.0+0.j, -1.0+0.j,  1.5+0.j])


From the definition of the FFT it can be seen that

.. math::

    y[0] = \sum_{n=0}^{N-1} x[n] \, .

In the example

>>> np.sum(x)
4.5

which corresponds to :math:`y[0]`. For N even, the elements
:math:`y[1]...y[N/2-1]` contain the positive-frequency terms, and the elements
:math:`y[N/2]...y[N-1]` contain the negative-frequency terms, in order of
decreasingly negative frequency. For N odd, the elements
:math:`y[1]...y[(N-1)/2]` contain the positive-frequency terms, and the
elements :math:`y[(N+1)/2]...y[N-1]` contain the negative-frequency terms, in
order of decreasingly negative frequency.

In case the sequence x is real-valued, the values of :math:`y[n]` for positive
frequencies is the conjugate of the values :math:`y[n]` for negative
frequencies (because the spectrum is symmetric). Typically, only the FFT
corresponding to positive frequencies is plotted.

The example plots the FFT of the sum of two sines.

.. plot::

    >>> from scipy.fft import fft, fftfreq
    >>> # Number of sample points
    >>> N = 600
    >>> # sample spacing
    >>> T = 1.0 / 800.0
    >>> x = np.linspace(0.0, N*T, N, endpoint=False)
    >>> y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)
    >>> yf = fft(y)
    >>> xf = fftfreq(N, T)[:N//2]
    >>> import matplotlib.pyplot as plt
    >>> plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))
    >>> plt.grid()
    >>> plt.show()


The FFT input signal is inherently truncated. This truncation can be modeled
as multiplication of an infinite signal with a rectangular window function. In
the spectral domain this multiplication becomes convolution of the signal
spectrum with the window function spectrum, being of form :math:`\sin(x)/x`.
This convolution is the cause of an effect called spectral leakage (see
[WPW]_). Windowing the signal with a dedicated window function helps mitigate
spectral leakage. The example below uses a Blackman window from scipy.signal
and shows the effect of windowing (the zero component of the FFT has been
truncated for illustrative purposes).

.. plot::

    >>> from scipy.fft import fft, fftfreq
    >>> # Number of sample points
    >>> N = 600
    >>> # sample spacing
    >>> T = 1.0 / 800.0
    >>> x = np.linspace(0.0, N*T, N, endpoint=False)
    >>> y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)
    >>> yf = fft(y)
    >>> from scipy.signal import blackman
    >>> w = blackman(N)
    >>> ywf = fft(y*w)
    >>> xf = fftfreq(N, T)[:N//2]
    >>> import matplotlib.pyplot as plt
    >>> plt.semilogy(xf[1:N//2], 2.0/N * np.abs(yf[1:N//2]), '-b')
    >>> plt.semilogy(xf[1:N//2], 2.0/N * np.abs(ywf[1:N//2]), '-r')
    >>> plt.legend(['FFT', 'FFT w. window'])
    >>> plt.grid()
    >>> plt.show()


In case the sequence x is complex-valued, the spectrum is no longer symmetric.
To simplify working with the FFT functions, scipy provides the following two
helper functions.

The function :func:`fftfreq` returns the FFT sample frequency points.

>>> from scipy.fft import fftfreq
>>> freq = fftfreq(8, 0.125)
>>> freq
array([ 0., 1., 2., 3., -4., -3., -2., -1.])

In a similar spirit, the function :func:`fftshift` allows swapping the lower
and upper halves of a vector, so that it becomes suitable for display.

>>> from scipy.fft import fftshift
>>> x = np.arange(8)
>>> fftshift(x)
array([4, 5, 6, 7, 0, 1, 2, 3])

The example below plots the FFT of two complex exponentials; note the
asymmetric spectrum.

.. plot::

    >>> from scipy.fft import fft, fftfreq, fftshift
    >>> # number of signal points
    >>> N = 400
    >>> # sample spacing
    >>> T = 1.0 / 800.0
    >>> x = np.linspace(0.0, N*T, N, endpoint=False)
    >>> y = np.exp(50.0 * 1.j * 2.0*np.pi*x) + 0.5*np.exp(-80.0 * 1.j * 2.0*np.pi*x)
    >>> yf = fft(y)
    >>> xf = fftfreq(N, T)
    >>> xf = fftshift(xf)
    >>> yplot = fftshift(yf)
    >>> import matplotlib.pyplot as plt
    >>> plt.plot(xf, 1.0/N * np.abs(yplot))
    >>> plt.grid()
    >>> plt.show()


The function :func:`rfft` calculates the FFT of a real sequence and outputs the
complex FFT coefficients :math:`y[n]` for only half of the frequency range. The
remaining negative frequency components are implied by the Hermitian symmetry of
the FFT for a real input (``y[n] = conj(y[-n])``). In case of N being even:
:math:`[Re(y[0]) + 0j, y[1], ..., Re(y[N/2]) + 0j]`; in case of N being odd
:math:`[Re(y[0]) + 0j, y[1], ..., y[N/2]`. The terms shown explicitly as
:math:`Re(y[k]) + 0j` are restricted to be purely real since, by the hermitian
property, they are their own complex conjugate.

The corresponding function :func:`irfft` calculates the IFFT of the FFT
coefficients with this special ordering.

>>> from scipy.fft import fft, rfft, irfft
>>> x = np.array([1.0, 2.0, 1.0, -1.0, 1.5, 1.0])
>>> fft(x)
array([ 5.5 +0.j        ,  2.25-0.4330127j , -2.75-1.29903811j,
        1.5 +0.j        , -2.75+1.29903811j,  2.25+0.4330127j ])
>>> yr = rfft(x)
>>> yr
array([ 5.5 +0.j        ,  2.25-0.4330127j , -2.75-1.29903811j,
        1.5 +0.j        ])
>>> irfft(yr)
array([ 1. ,  2. ,  1. , -1. ,  1.5,  1. ])
>>> x = np.array([1.0, 2.0, 1.0, -1.0, 1.5])
>>> fft(x)
array([ 4.5       +0.j        ,  2.08155948-1.65109876j,
       -1.83155948+1.60822041j, -1.83155948-1.60822041j,
        2.08155948+1.65109876j])
>>> yr = rfft(x)
>>> yr
array([ 4.5       +0.j        ,  2.08155948-1.65109876j,
        -1.83155948+1.60822041j])

Notice that the :func:`rfft` of odd and even length signals are of the same shape.
By default, :func:`irfft` assumes the output signal should be of even length. And
so, for odd signals, it will give the wrong result:

>>> irfft(yr)
array([ 1.70788987,  2.40843925, -0.37366961,  0.75734049])

To recover the original odd-length signal, we **must** pass the output shape by
the `n` parameter.

>>> irfft(yr, n=len(x))
array([ 1. ,  2. ,  1. , -1. ,  1.5])



2- and N-D discrete Fourier transforms
_________________________________________________

The functions :func:`fft2` and :func:`ifft2` provide 2-D FFT and
IFFT, respectively. Similarly, :func:`fftn` and :func:`ifftn` provide
N-D FFT, and IFFT, respectively.

For real-input signals, similarly to :func:`rfft`, we have the functions
:func:`rfft2` and :func:`irfft2` for 2-D real transforms;
:func:`rfftn` and :func:`irfftn` for N-D real transforms.

The example below demonstrates a 2-D IFFT and plots the resulting
(2-D) time-domain signals.

.. plot::

    >>> from scipy.fft import ifftn
    >>> import matplotlib.pyplot as plt
    >>> import matplotlib.cm as cm
    >>> N = 30
    >>> f, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, sharex='col', sharey='row')
    >>> xf = np.zeros((N,N))
    >>> xf[0, 5] = 1
    >>> xf[0, N-5] = 1
    >>> Z = ifftn(xf)
    >>> ax1.imshow(xf, cmap=cm.Reds)
    >>> ax4.imshow(np.real(Z), cmap=cm.gray)
    >>> xf = np.zeros((N, N))
    >>> xf[5, 0] = 1
    >>> xf[N-5, 0] = 1
    >>> Z = ifftn(xf)
    >>> ax2.imshow(xf, cmap=cm.Reds)
    >>> ax5.imshow(np.real(Z), cmap=cm.gray)
    >>> xf = np.zeros((N, N))
    >>> xf[5, 10] = 1
    >>> xf[N-5, N-10] = 1
    >>> Z = ifftn(xf)
    >>> ax3.imshow(xf, cmap=cm.Reds)
    >>> ax6.imshow(np.real(Z), cmap=cm.gray)
    >>> plt.show()


Discrete Cosine Transforms
--------------------------

SciPy provides a DCT with the function :func:`dct` and a corresponding IDCT
with the function :func:`idct`. There are 8 types of the DCT [WPC]_, [Mak]_;
however, only the first 4 types are implemented in scipy. "The" DCT generally
refers to DCT type 2, and "the" Inverse DCT generally refers to DCT type 3. In
addition, the DCT coefficients can be normalized differently (for most types,
scipy provides ``None`` and ``ortho``). Two parameters of the dct/idct
function calls allow setting the DCT type and coefficient normalization.

For a single dimension array x, dct(x, norm='ortho') is equal to
MATLAB dct(x).


Type I DCT
__________

SciPy uses the following definition of the unnormalized DCT-I
(``norm=None``):

.. math::

    y[k] = x_0 + (-1)^k x_{N-1} + 2\sum_{n=1}^{N-2} x[n]
    \cos\left(\frac{\pi nk}{N-1}\right),
    \qquad 0 \le k < N.

Note that the DCT-I is only supported for input size > 1.

Type II DCT
___________

SciPy uses the following definition of the unnormalized DCT-II
(``norm=None``):

.. math::

    y[k] = 2 \sum_{n=0}^{N-1} x[n] \cos \left({\pi(2n+1)k \over 2N} \right)
    \qquad 0 \le k < N.

In case of the normalized DCT (``norm='ortho'``), the DCT coefficients
:math:`y[k]` are multiplied by a scaling factor `f`:

.. math::

    f = \begin{cases} \sqrt{1/(4N)}, & \text{if $k = 0$} \\    \sqrt{1/(2N)},
    & \text{otherwise} \end{cases} \, .

In this case, the DCT "base functions" :math:`\phi_k[n] = 2 f \cos
\left({\pi(2n+1)k \over 2N} \right)` become orthonormal:

.. math::

   \sum_{n=0}^{N-1} \phi_k[n] \phi_l[n] = \delta_{lk}.


Type III DCT
____________

SciPy uses the following definition of the unnormalized DCT-III
(``norm=None``):

.. math::

    y[k] = x_0 + 2 \sum_{n=1}^{N-1} x[n] \cos\left({\pi n(2k+1) \over 2N}\right)
    \qquad 0 \le k < N,

or, for ``norm='ortho'``:

.. math::

    y[k] = {x_0\over\sqrt{N}} + {2\over\sqrt{N}} \sum_{n=1}^{N-1} x[n]
    \cos\left({\pi n(2k+1) \over 2N}\right) \qquad 0 \le k < N.


Type IV DCT
___________

SciPy uses the following definition of the unnormalized DCT-IV
(``norm=None``):

.. math::

    y[k] = 2 \sum_{n=0}^{N-1} x[n] \cos\left({\pi (2n+1)(2k+1) \over 4N}\right)
    \qquad 0 \le k < N,

or, for ``norm='ortho'``:

.. math::

    y[k] = \sqrt{2\over N}\sum_{n=0}^{N-1} x[n] \cos\left({\pi (2n+1)(2k+1) \over 4N}\right)
    \qquad 0 \le k < N


DCT and IDCT
____________


The (unnormalized) DCT-III is the inverse of the (unnormalized) DCT-II, up to a
factor of `2N`. The orthonormalized DCT-III is exactly the inverse of the
orthonormalized DCT- II. The function :func:`idct` performs the mappings between
the DCT and IDCT types, as well as the correct normalization.

The following example shows the relation between DCT and IDCT for different
types and normalizations.

>>> from scipy.fft import dct, idct
>>> x = np.array([1.0, 2.0, 1.0, -1.0, 1.5])

The DCT-II and DCT-III are each other's inverses, so for an orthonormal transform
we return back to the original signal.

>>> dct(dct(x, type=2, norm='ortho'), type=3, norm='ortho')
array([ 1. ,  2. ,  1. , -1. ,  1.5])

Doing the same under default normalization, however, we pick up an extra scaling
factor of :math:`2N=10` since the forward transform is unnormalized.

>>> dct(dct(x, type=2), type=3)
array([ 10.,  20.,  10., -10.,  15.])

For this reason, we should use the function `idct` using the same type for both,
giving a correctly normalized result.

>>> # Normalized inverse: no scaling factor
>>> idct(dct(x, type=2), type=2)
array([ 1. ,  2. ,  1. , -1. ,  1.5])

Analogous results can be seen for the DCT-I, which is its own inverse up to a
factor of :math:`2(N-1)`.

>>> dct(dct(x, type=1, norm='ortho'), type=1, norm='ortho')
array([ 1. ,  2. ,  1. , -1. ,  1.5])
>>> # Unnormalized round-trip via DCT-I: scaling factor 2*(N-1) = 8
>>> dct(dct(x, type=1), type=1)
array([ 8. ,  16.,  8. , -8. ,  12.])
>>> # Normalized inverse: no scaling factor
>>> idct(dct(x, type=1), type=1)
array([ 1. ,  2. ,  1. , -1. ,  1.5])

And for the DCT-IV, which is also its own inverse up to a factor of :math:`2N`.

>>> dct(dct(x, type=4, norm='ortho'), type=4, norm='ortho')
array([ 1. ,  2. ,  1. , -1. ,  1.5])
>>> # Unnormalized round-trip via DCT-IV: scaling factor 2*N = 10
>>> dct(dct(x, type=4), type=4)
array([ 10.,  20.,  10., -10.,  15.])
>>> # Normalized inverse: no scaling factor
>>> idct(dct(x, type=4), type=4)
array([ 1. ,  2. ,  1. , -1. ,  1.5])

Example
_______

The DCT exhibits the "energy compaction property", meaning that for many
signals only the first few DCT coefficients have significant magnitude.
Zeroing out the other coefficients leads to a small reconstruction error, a
fact which is exploited in lossy signal compression (e.g. JPEG compression).

The example below shows a signal x and two reconstructions (:math:`x_{20}` and
:math:`x_{15}`) from the signal's DCT coefficients. The signal :math:`x_{20}`
is reconstructed from the first 20 DCT coefficients, :math:`x_{15}` is
reconstructed from the first 15 DCT coefficients. It can be seen that the
relative error of using 20 coefficients is still very small (~0.1%), but
provides a five-fold compression rate.


.. plot::

    >>> from scipy.fft import dct, idct
    >>> import matplotlib.pyplot as plt
    >>> N = 100
    >>> t = np.linspace(0,20,N, endpoint=False)
    >>> x = np.exp(-t/3)*np.cos(2*t)
    >>> y = dct(x, norm='ortho')
    >>> window = np.zeros(N)
    >>> window[:20] = 1
    >>> yr = idct(y*window, norm='ortho')
    >>> sum(abs(x-yr)**2) / sum(abs(x)**2)
    0.0009872817275276098
    >>> plt.plot(t, x, '-bx')
    >>> plt.plot(t, yr, 'ro')
    >>> window = np.zeros(N)
    >>> window[:15] = 1
    >>> yr = idct(y*window, norm='ortho')
    >>> sum(abs(x-yr)**2) / sum(abs(x)**2)
    0.06196643004256714
    >>> plt.plot(t, yr, 'g+')
    >>> plt.legend(['x', '$x_{20}$', '$x_{15}$'])
    >>> plt.grid()
    >>> plt.show()

Discrete Sine Transforms
------------------------

SciPy provides a DST [Mak]_ with the function :func:`dst` and a corresponding IDST
with the function :func:`idst`.

There are, theoretically, 8 types of the DST for different combinations of
even/odd boundary conditions and boundary offsets [WPS]_, only the first 4
types are implemented in scipy.

Type I DST
__________

DST-I assumes the input is odd around n=-1 and n=N. SciPy uses the following
definition of the unnormalized DST-I (``norm=None``):

.. math::

    y[k] = 2\sum_{n=0}^{N-1} x[n]  \sin\left( \pi {(n+1) (k+1)}\over{N+1}
    \right), \qquad 0 \le k < N.

Note also that the DST-I is only supported for input size > 1. The
(unnormalized) DST-I is its own inverse, up to a factor of `2(N+1)`.

Type II DST
___________

DST-II assumes the input is odd around n=-1/2 and even around n=N. SciPy uses
the following definition of the unnormalized DST-II (``norm=None``):

.. math::

    y[k] = 2 \sum_{n=0}^{N-1} x[n]  \sin\left( {\pi (n+1/2)(k+1)} \over N
    \right), \qquad 0 \le k < N.

Type III DST
____________

DST-III assumes the input is odd around n=-1 and even around n=N-1. SciPy uses
the following definition of the unnormalized DST-III (``norm=None``):

.. math::

    y[k] = (-1)^k x[N-1] + 2 \sum_{n=0}^{N-2} x[n] \sin \left( {\pi
    (n+1)(k+1/2)} \over N \right), \qquad 0 \le k < N.

Type IV DST
___________

SciPy uses the following definition of the unnormalized DST-IV
(``norm=None``):

.. math::

    y[k] = 2 \sum_{n=0}^{N-1} x[n] \sin\left({\pi (2n+1)(2k+1) \over 4N}\right)
    \qquad 0 \le k < N,

or, for ``norm='ortho'``:

.. math::

    y[k] = \sqrt{2\over N}\sum_{n=0}^{N-1} x[n] \sin\left({\pi (2n+1)(2k+1) \over 4N}\right)
    \qquad 0 \le k < N,


DST and IDST
____________


The following example shows the relation between DST and IDST for
different types and normalizations.

>>> from scipy.fft import dst, idst
>>> x = np.array([1.0, 2.0, 1.0, -1.0, 1.5])

The DST-II and DST-III are each other's inverses, so for an orthonormal transform
we return back to the original signal.

>>> dst(dst(x, type=2, norm='ortho'), type=3, norm='ortho')
array([ 1. ,  2. ,  1. , -1. ,  1.5])

Doing the same under default normalization, however, we pick up an extra scaling
factor of :math:`2N=10` since the forward transform is unnormalized.

>>> dst(dst(x, type=2), type=3)
array([ 10.,  20.,  10., -10.,  15.])

For this reason, we should use the function `idst` using the same type for both,
giving a correctly normalized result.

>>> idst(dst(x, type=2), type=2)
array([ 1. ,  2. ,  1. , -1. ,  1.5])

Analogous results can be seen for the DST-I, which is its own inverse up to a
factor of :math:`2(N-1)`.

>>> dst(dst(x, type=1, norm='ortho'), type=1, norm='ortho')
array([ 1. ,  2. ,  1. , -1. ,  1.5])
>>>  # scaling factor 2*(N+1) = 12
>>> dst(dst(x, type=1), type=1)
array([ 12.,  24.,  12., -12.,  18.])
>>>  # no scaling factor
>>> idst(dst(x, type=1), type=1)
array([ 1. ,  2. ,  1. , -1. ,  1.5])

And for the DST-IV, which is also its own inverse up to a factor of :math:`2N`.

>>> dst(dst(x, type=4, norm='ortho'), type=4, norm='ortho')
array([ 1. ,  2. ,  1. , -1. ,  1.5])
>>>  # scaling factor 2*N = 10
>>> dst(dst(x, type=4), type=4)
array([ 10.,  20.,  10., -10.,  15.])
>>>  # no scaling factor
>>> idst(dst(x, type=4), type=4)
array([ 1. ,  2. ,  1. , -1. ,  1.5])


Fast Hankel Transform
---------------------

SciPy provides the functions ``fht`` and ``ifht`` to perform the Fast
Hankel Transform (FHT) and its inverse (IFHT) on logarithmically-spaced input
arrays.

The FHT is the discretised version of the continuous Hankel transform defined
by [Ham00]_

.. math::

    A(k) = \int_{0}^{\infty} \! a(r) \, J_{\mu}(kr) \, k \, dr \;,

with :math:`J_{\mu}` the Bessel function of order :math:`\mu`. Under a change
of variables :math:`r \to \log r`, :math:`k \to \log k`, this becomes

.. math::

    A(e^{\log k})
    = \int_{0}^{\infty} \! a(e^{\log r}) \, J_{\mu}(e^{\log k + \log r})
                                        \, e^{\log k + \log r} \, d{\log r}

which is a convolution in logarithmic space. The FHT algorithm uses the FFT
to perform this convolution on discrete input data.

Care must be taken to minimise numerical ringing due to the circular nature
of FFT convolution. To ensure that the low-ringing condition [Ham00]_ holds,
the output array can be slightly shifted by an offset computed using the
``fhtoffset`` function.


References
----------

.. [CT65] Cooley, James W., and John W. Tukey, 1965, "An algorithm for the
        machine calculation of complex Fourier series," *Math. Comput.*
        19: 297-301.

.. [NR07] Press, W., Teukolsky, S., Vetterline, W.T., and Flannery, B.P.,
        2007, *Numerical Recipes: The Art of Scientific Computing*, ch.
        12-13.  Cambridge Univ. Press, Cambridge, UK.

.. [Mak] J. Makhoul, 1980, 'A Fast Cosine Transform in One and Two Dimensions',
       `IEEE Transactions on acoustics, speech and signal processing`
       vol. 28(1), pp. 27-34, :doi:`10.1109/TASSP.1980.1163351`

.. [Ham00] A. J. S. Hamilton, 2000, "Uncorrelated modes of the non-linear power
       spectrum", *MNRAS*, 312, 257. :doi:`10.1046/j.1365-8711.2000.03071.x`

.. [WPW] https://en.wikipedia.org/wiki/Window_function

.. [WPC] https://en.wikipedia.org/wiki/Discrete_cosine_transform

.. [WPS] https://en.wikipedia.org/wiki/Discrete_sine_transform
.. _qhulltutorial:

Spatial data structures and algorithms (`scipy.spatial`)
========================================================

.. currentmodule:: scipy.spatial

`scipy.spatial` can compute triangulations, Voronoi diagrams, and
convex hulls of a set of points, by leveraging the `Qhull
<http://qhull.org/>`__ library.

Moreover, it contains `KDTree` implementations for nearest-neighbor point
queries, and utilities for distance computations in various metrics.

Delaunay triangulations
-----------------------

The Delaunay triangulation is a subdivision of a set of points into a
non-overlapping set of triangles, such that no point is inside the
circumcircle of any triangle. In practice, such triangulations tend to
avoid triangles with small angles.

Delaunay triangulation can be computed using `scipy.spatial` as follows:

.. plot::

   >>> from scipy.spatial import Delaunay
   >>> points = np.array([[0, 0], [0, 1.1], [1, 0], [1, 1]])
   >>> tri = Delaunay(points)

   We can visualize it:

   >>> import matplotlib.pyplot as plt
   >>> plt.triplot(points[:,0], points[:,1], tri.simplices)
   >>> plt.plot(points[:,0], points[:,1], 'o')

   And add some further decorations:

   >>> for j, p in enumerate(points):
   ...     plt.text(p[0]-0.03, p[1]+0.03, j, ha='right') # label the points
   >>> for j, s in enumerate(tri.simplices):
   ...     p = points[s].mean(axis=0)
   ...     plt.text(p[0], p[1], '#%d' % j, ha='center') # label triangles
   >>> plt.xlim(-0.5, 1.5); plt.ylim(-0.5, 1.5)
   >>> plt.show()

The structure of the triangulation is encoded in the following way:
the ``simplices`` attribute contains the indices of the points in the
``points`` array that make up the triangle. For instance:

>>> i = 1
>>> tri.simplices[i,:]
array([3, 1, 0], dtype=int32)
>>> points[tri.simplices[i,:]]
array([[ 1. ,  1. ],
       [ 0. ,  1.1],
       [ 0. ,  0. ]])

Moreover, neighboring triangles can also be found:

>>> tri.neighbors[i]
array([-1,  0, -1], dtype=int32)

What this tells us is that this triangle has triangle #0 as a neighbor,
but no other neighbors. Moreover, it tells us that neighbor 0 is
opposite the vertex 1 of the triangle:

>>> points[tri.simplices[i, 1]]
array([ 0. ,  1.1])

Indeed, from the figure, we see that this is the case.

Qhull can also perform tessellations to simplices for
higher-dimensional point sets (for instance, subdivision into
tetrahedra in 3-D).


Coplanar points
^^^^^^^^^^^^^^^

It is important to note that not *all* points necessarily appear as
vertices of the triangulation, due to numerical precision issues in
forming the triangulation. Consider the above with a duplicated
point:

>>> points = np.array([[0, 0], [0, 1], [1, 0], [1, 1], [1, 1]])
>>> tri = Delaunay(points)
>>> np.unique(tri.simplices.ravel())
array([0, 1, 2, 3], dtype=int32)

Observe that point #4, which is a duplicate, does not occur as a
vertex of the triangulation. That this happened is recorded:

>>> tri.coplanar
array([[4, 0, 3]], dtype=int32)

This means that point 4 resides near triangle 0 and vertex 3, but is
not included in the triangulation.

Note that such degeneracies can occur not only because of duplicated
points, but also for more complicated geometrical reasons, even in
point sets that at first sight seem well-behaved.

However, Qhull has the "QJ" option, which instructs it to perturb the
input data randomly until degeneracies are resolved:

>>> tri = Delaunay(points, qhull_options="QJ Pp")
>>> points[tri.simplices]
array([[[1, 0],
        [1, 1],
        [0, 0]],
       [[1, 1],
        [1, 1],
        [1, 0]],
       [[1, 1],
        [0, 1],
        [0, 0]],
       [[0, 1],
        [1, 1],
        [1, 1]]])

Two new triangles appeared. However, we see that they are degenerate
and have zero area.


Convex hulls
------------

A convex hull is the smallest convex object containing all points in a
given point set.

These can be computed via the Qhull wrappers in `scipy.spatial` as
follows:

.. plot::

   >>> from scipy.spatial import ConvexHull
   >>> rng = np.random.default_rng()
   >>> points = rng.random((30, 2))   # 30 random points in 2-D
   >>> hull = ConvexHull(points)

   The convex hull is represented as a set of N 1-D simplices,
   which in 2-D means line segments. The storage scheme is exactly the
   same as for the simplices in the Delaunay triangulation discussed
   above.

   We can illustrate the above result:

   >>> import matplotlib.pyplot as plt
   >>> plt.plot(points[:,0], points[:,1], 'o')
   >>> for simplex in hull.simplices:
   ...     plt.plot(points[simplex,0], points[simplex,1], 'k-')
   >>> plt.show()

The same can be achieved with `scipy.spatial.convex_hull_plot_2d`.


Voronoi diagrams
----------------

A Voronoi diagram is a subdivision of the space into the nearest
neighborhoods of a given set of points.

There are two ways to approach this object using `scipy.spatial`.
First, one can use the `KDTree` to answer the question "which of the
points is closest to this one", and define the regions that way:

.. plot::

   >>> from scipy.spatial import KDTree
   >>> points = np.array([[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2],
   ...                    [2, 0], [2, 1], [2, 2]])
   >>> tree = KDTree(points)
   >>> tree.query([0.1, 0.1])
   (0.14142135623730953, 0)

   So the point ``(0.1, 0.1)`` belongs to region ``0``. In color:

   >>> x = np.linspace(-0.5, 2.5, 31)
   >>> y = np.linspace(-0.5, 2.5, 33)
   >>> xx, yy = np.meshgrid(x, y)
   >>> xy = np.c_[xx.ravel(), yy.ravel()]
   >>> import matplotlib.pyplot as plt
   >>> dx_half, dy_half = np.diff(x[:2])[0] / 2., np.diff(y[:2])[0] / 2.
   >>> x_edges = np.concatenate((x - dx_half, [x[-1] + dx_half]))
   >>> y_edges = np.concatenate((y - dy_half, [y[-1] + dy_half]))
   >>> plt.pcolormesh(x_edges, y_edges, tree.query(xy)[1].reshape(33, 31), shading='flat')
   >>> plt.plot(points[:,0], points[:,1], 'ko')
   >>> plt.show()

   This does not, however, give the Voronoi diagram as a geometrical
   object.

   The representation in terms of lines and points can be again
   obtained via the Qhull wrappers in `scipy.spatial`:

   >>> from scipy.spatial import Voronoi
   >>> vor = Voronoi(points)
   >>> vor.vertices
   array([[0.5, 0.5],
          [0.5, 1.5],
          [1.5, 0.5],
          [1.5, 1.5]])

   The Voronoi vertices denote the set of points forming the polygonal
   edges of the Voronoi regions. In this case, there are 9 different
   regions:

   >>> vor.regions
   [[], [-1, 0], [-1, 1], [1, -1, 0], [3, -1, 2], [-1, 3], [-1, 2], [0, 1, 3, 2], [2, -1, 0], [3, -1, 1]]

   Negative value ``-1`` again indicates a point at infinity. Indeed,
   only one of the regions, ``[0, 1, 3, 2]``, is bounded. Note here that
   due to similar numerical precision issues as in Delaunay triangulation
   above, there may be fewer Voronoi regions than input points.

   The ridges (lines in 2-D) separating the regions are described as a
   similar collection of simplices as the convex hull pieces:

   >>> vor.ridge_vertices
   [[-1, 0], [-1, 0], [-1, 1], [-1, 1], [0, 1], [-1, 3], [-1, 2], [2, 3], [-1, 3], [-1, 2], [1, 3], [0, 2]]

   These numbers present the indices of the Voronoi vertices making up the
   line segments. ``-1`` is again a point at infinity --- only 4 of
   the 12 lines are a bounded line segment, while others extend to
   infinity.

   The Voronoi ridges are perpendicular to the lines drawn between the
   input points. To which two points each ridge corresponds is also
   recorded:

   >>> vor.ridge_points
   array([[0, 3],
          [0, 1],
          [2, 5],
          [2, 1],
          [1, 4],
          [7, 8],
          [7, 6],
          [7, 4],
          [8, 5],
          [6, 3],
          [4, 5],
          [4, 3]], dtype=int32)

   This information, taken together, is enough to construct the full
   diagram.

   We can plot it as follows. First, the points and the Voronoi vertices:

   >>> plt.plot(points[:, 0], points[:, 1], 'o')
   >>> plt.plot(vor.vertices[:, 0], vor.vertices[:, 1], '*')
   >>> plt.xlim(-1, 3); plt.ylim(-1, 3)

   Plotting the finite line segments goes as for the convex hull,
   but now we have to guard for the infinite edges:

   >>> for simplex in vor.ridge_vertices:
   ...     simplex = np.asarray(simplex)
   ...     if np.all(simplex >= 0):
   ...         plt.plot(vor.vertices[simplex, 0], vor.vertices[simplex, 1], 'k-')

   The ridges extending to infinity require a bit more care:

   >>> center = points.mean(axis=0)
   >>> for pointidx, simplex in zip(vor.ridge_points, vor.ridge_vertices):
   ...     simplex = np.asarray(simplex)
   ...     if np.any(simplex < 0):
   ...         i = simplex[simplex >= 0][0] # finite end Voronoi vertex
   ...         t = points[pointidx[1]] - points[pointidx[0]]  # tangent
   ...         t = t / np.linalg.norm(t)
   ...         n = np.array([-t[1], t[0]]) # normal
   ...         midpoint = points[pointidx].mean(axis=0)
   ...         far_point = vor.vertices[i] + np.sign(np.dot(midpoint - center, n)) * n * 100
   ...         plt.plot([vor.vertices[i,0], far_point[0]],
   ...                  [vor.vertices[i,1], far_point[1]], 'k--')
   >>> plt.show()

This plot can also be created using `scipy.spatial.voronoi_plot_2d`.


Voronoi diagrams can be used to create interesting generative art.  Try playing
with the settings of this ``mandala`` function to create your own!

.. plot::

   >>> import numpy as np
   >>> from scipy import spatial
   >>> import matplotlib.pyplot as plt

   >>> def mandala(n_iter, n_points, radius):
   ...     """Creates a mandala figure using Voronoi tesselations.
   ...
   ...     Parameters
   ...     ----------
   ...     n_iter : int
   ...         Number of iterations, i.e. how many times the equidistant points will
   ...         be generated.
   ...     n_points : int
   ...         Number of points to draw per iteration.
   ...     radius : scalar
   ...         The radial expansion factor.
   ...
   ...     Returns
   ...     -------
   ...     fig : matplotlib.Figure instance
   ...
   ...     Notes
   ...     -----
   ...     This code is adapted from the work of Audrey Roy Greenfeld [1]_ and Carlos
   ...     Focil-Espinosa [2]_, who created beautiful mandalas with Python code.  That
   ...     code in turn was based on Antonio Sánchez Chinchón's R code [3]_.
   ...
   ...     References
   ...     ----------
   ...     .. [1] https://www.codemakesmehappy.com/2019/09/voronoi-mandalas.html
   ...
   ...     .. [2] https://github.com/CarlosFocil/mandalapy
   ...
   ...     .. [3] https://github.com/aschinchon/mandalas
   ...
   ...     """
   ...     fig = plt.figure(figsize=(10, 10))
   ...     ax = fig.add_subplot(111)
   ...     ax.set_axis_off()
   ...     ax.set_aspect('equal', adjustable='box')
   ...
   ...     angles = np.linspace(0, 2*np.pi * (1 - 1/n_points), num=n_points) + np.pi/2
   ...     # Starting from a single center point, add points iteratively
   ...     xy = np.array([[0, 0]])
   ...     for k in range(n_iter):
   ...         t1 = np.array([])
   ...         t2 = np.array([])
   ...         # Add `n_points` new points around each existing point in this iteration
   ...         for i in range(xy.shape[0]):
   ...             t1 = np.append(t1, xy[i, 0] + radius**k * np.cos(angles))
   ...             t2 = np.append(t2, xy[i, 1] + radius**k * np.sin(angles))
   ...
   ...         xy = np.column_stack((t1, t2))
   ...
   ...     # Create the Mandala figure via a Voronoi plot
   ...     spatial.voronoi_plot_2d(spatial.Voronoi(xy), ax=ax)
   ...
   ...     return fig

   >>> # Modify the following parameters in order to get different figures
   >>> n_iter = 3
   >>> n_points = 6
   >>> radius = 4

   >>> fig = mandala(n_iter, n_points, radius)
   >>> plt.show()
.. _user_guide:

****************
SciPy User Guide
****************

.. sectionauthor:: Travis E. Oliphant

.. raw:: latex

   \addtocontents{toc}{\protect\setcounter{tocdepth}{2}}

.. toctree::
   :maxdepth: 1

   general
   special
   integrate
   optimize
   interpolate
   fft
   signal
   linalg
   arpack
   csgraph
   spatial
   stats
   ndimage
   io

.. raw:: latex

   \addtocontents{toc}{\protect\setcounter{tocdepth}{1}}
File IO (:mod:`scipy.io`)
=========================

.. sectionauthor:: Matthew Brett

.. currentmodule:: scipy.io

.. seealso:: `NumPy IO routines <https://www.numpy.org/devdocs/reference/routines.io.html>`__

MATLAB files
------------

.. autosummary::

   loadmat
   savemat
   whosmat

The basic functions
```````````````````

We'll start by importing :mod:`scipy.io` and calling it ``sio`` for
convenience:

   >>> import scipy.io as sio

If you are using IPython, try tab-completing on ``sio``. Among the many
options, you will find::

   sio.loadmat
   sio.savemat
   sio.whosmat

These are the high-level functions you will most likely use when working
with MATLAB files. You'll also find::

   sio.matlab

This is the package from which ``loadmat``, ``savemat``, and ``whosmat``
are imported. Within ``sio.matlab``, you will find the ``mio`` module
This module contains the machinery that ``loadmat`` and ``savemat`` use.
From time to time you may find yourself re-using this machinery.

How do I start?
```````````````

You may have a ``.mat`` file that you want to read into SciPy. Or, you
want to pass some variables from SciPy / NumPy into MATLAB.

To save us using a MATLAB license, let's start in Octave_. Octave has
MATLAB-compatible save and load functions. Start Octave (``octave`` at
the command line for me):

.. sourcecode:: octave

  octave:1> a = 1:12
  a =

     1   2   3   4   5   6   7   8   9  10  11  12

  octave:2> a = reshape(a, [1 3 4])
  a =

  ans(:,:,1) =

     1   2   3

  ans(:,:,2) =

     4   5   6

  ans(:,:,3) =

     7   8   9

  ans(:,:,4) =

     10   11   12

  octave:3> save -6 octave_a.mat a % MATLAB 6 compatible
  octave:4> ls octave_a.mat
  octave_a.mat

Now, to Python:

  >>> mat_contents = sio.loadmat('octave_a.mat')
  >>> mat_contents
  {'a': array([[[  1.,   4.,   7.,  10.],
          [  2.,   5.,   8.,  11.],
          [  3.,   6.,   9.,  12.]]]),
   '__version__': '1.0',
   '__header__': 'MATLAB 5.0 MAT-file, written by
   Octave 3.6.3, 2013-02-17 21:02:11 UTC',
   '__globals__': []}
  >>> oct_a = mat_contents['a']
  >>> oct_a
  array([[[  1.,   4.,   7.,  10.],
          [  2.,   5.,   8.,  11.],
          [  3.,   6.,   9.,  12.]]])
  >>> oct_a.shape
  (1, 3, 4)

Now let's try the other way round:

  >>> import numpy as np
  >>> vect = np.arange(10)
  >>> vect.shape
  (10,)
  >>> sio.savemat('np_vector.mat', {'vect':vect})

Then back to Octave:

.. sourcecode:: octave

   octave:8> load np_vector.mat
   octave:9> vect
   vect =

     0  1  2  3  4  5  6  7  8  9

   octave:10> size(vect)
   ans =

       1   10

If you want to inspect the contents of a MATLAB file without reading the
data into memory, use the ``whosmat`` command:

   >>> sio.whosmat('octave_a.mat')
   [('a', (1, 3, 4), 'double')]

``whosmat`` returns a list of tuples, one for each array (or other object)
in the file. Each tuple contains the name, shape and data type of the
array.

MATLAB structs
``````````````

MATLAB structs are a little bit like Python dicts, except the field
names must be strings. Any MATLAB object can be a value of a field. As
for all objects in MATLAB, structs are, in fact, arrays of structs, where
a single struct is an array of shape (1, 1).

.. sourcecode:: octave

   octave:11> my_struct = struct('field1', 1, 'field2', 2)
   my_struct =
   {
     field1 =  1
     field2 =  2
   }

   octave:12> save -6 octave_struct.mat my_struct

We can load this in Python:

   >>> mat_contents = sio.loadmat('octave_struct.mat')
   >>> mat_contents
   {'my_struct': array([[([[1.0]], [[2.0]])]],
         dtype=[('field1', 'O'), ('field2', 'O')]), '__version__': '1.0', '__header__': 'MATLAB 5.0 MAT-file, written by Octave 3.6.3, 2013-02-17 21:23:14 UTC', '__globals__': []}
   >>> oct_struct = mat_contents['my_struct']
   >>> oct_struct.shape
   (1, 1)
   >>> val = oct_struct[0,0]
   >>> val
   ([[1.0]], [[2.0]])
   >>> val['field1']
   array([[ 1.]])
   >>> val['field2']
   array([[ 2.]])
   >>> val.dtype
   dtype([('field1', 'O'), ('field2', 'O')])

In the SciPy versions from 0.12.0, MATLAB structs come back as NumPy
structured arrays, with fields named for the struct fields. You can see
the field names in the ``dtype`` output above. Note also:

   >>> val = oct_struct[0,0]

and:

.. sourcecode:: octave

  octave:13> size(my_struct)
  ans =

     1   1

So, in MATLAB, the struct array must be at least 2-D, and we replicate
that when we read into SciPy. If you want all length 1 dimensions
squeezed out, try this:

   >>> mat_contents = sio.loadmat('octave_struct.mat', squeeze_me=True)
   >>> oct_struct = mat_contents['my_struct']
   >>> oct_struct.shape
   ()

Sometimes, it's more convenient to load the MATLAB structs as Python
objects rather than NumPy structured arrays - it can make the access
syntax in Python a bit more similar to that in MATLAB.  In order to do
this, use the ``struct_as_record=False`` parameter setting to ``loadmat``.

   >>> mat_contents = sio.loadmat('octave_struct.mat', struct_as_record=False)
   >>> oct_struct = mat_contents['my_struct']
   >>> oct_struct[0,0].field1
   array([[ 1.]])

``struct_as_record=False`` works nicely with ``squeeze_me``:

   >>> mat_contents = sio.loadmat('octave_struct.mat', struct_as_record=False, squeeze_me=True)
   >>> oct_struct = mat_contents['my_struct']
   >>> oct_struct.shape # but no - it's a scalar
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   AttributeError: 'mat_struct' object has no attribute 'shape'
   >>> type(oct_struct)
   <class 'scipy.io.matlab.mio5_params.mat_struct'>
   >>> oct_struct.field1
   1.0

Saving struct arrays can be done in various ways. One simple method is
to use dicts:

   >>> a_dict = {'field1': 0.5, 'field2': 'a string'}
   >>> sio.savemat('saved_struct.mat', {'a_dict': a_dict})

loaded as:

.. sourcecode:: octave

   octave:21> load saved_struct
   octave:22> a_dict
   a_dict =

     scalar structure containing the fields:

       field2 = a string
       field1 =  0.50000

You can also save structs back again to MATLAB (or Octave in our case)
like this:

   >>> dt = [('f1', 'f8'), ('f2', 'S10')]
   >>> arr = np.zeros((2,), dtype=dt)
   >>> arr
   array([(0.0, ''), (0.0, '')],
         dtype=[('f1', '<f8'), ('f2', 'S10')])
   >>> arr[0]['f1'] = 0.5
   >>> arr[0]['f2'] = 'python'
   >>> arr[1]['f1'] = 99
   >>> arr[1]['f2'] = 'not perl'
   >>> sio.savemat('np_struct_arr.mat', {'arr': arr})

MATLAB cell arrays
``````````````````

Cell arrays in MATLAB are rather like Python lists, in the sense that
the elements in the arrays can contain any type of MATLAB object. In
fact, they are most similar to NumPy object arrays, and that is how we
load them into NumPy.

.. sourcecode:: octave

   octave:14> my_cells = {1, [2, 3]}
   my_cells =
   {
     [1,1] =  1
     [1,2] =

        2   3

   }

   octave:15> save -6 octave_cells.mat my_cells

Back to Python:

   >>> mat_contents = sio.loadmat('octave_cells.mat')
   >>> oct_cells = mat_contents['my_cells']
   >>> print(oct_cells.dtype)
   object
   >>> val = oct_cells[0,0]
   >>> val
   array([[ 1.]])
   >>> print(val.dtype)
   float64

Saving to a MATLAB cell array just involves making a NumPy object array:

   >>> obj_arr = np.zeros((2,), dtype=np.object)
   >>> obj_arr[0] = 1
   >>> obj_arr[1] = 'a string'
   >>> obj_arr
   array([1, 'a string'], dtype=object)
   >>> sio.savemat('np_cells.mat', {'obj_arr':obj_arr})

.. sourcecode:: octave

   octave:16> load np_cells.mat
   octave:17> obj_arr
   obj_arr =
   {
     [1,1] = 1
     [2,1] = a string
   }

IDL files
---------

.. autosummary::

   readsav

Matrix Market files
-------------------

.. autosummary::

   mminfo
   mmread
   mmwrite

Wav sound files (:mod:`scipy.io.wavfile`)
-----------------------------------------

.. currentmodule:: scipy.io.wavfile

.. autosummary::

   read
   write

Arff files (:mod:`scipy.io.arff`)
---------------------------------

.. currentmodule:: scipy.io.arff

.. autosummary::

   loadarff

Netcdf
------

.. currentmodule:: scipy.io

.. autosummary::

   netcdf_file

Allows reading of  NetCDF files (version of pupynere_ package)

.. _pupynere: https://pypi.org/project/pupynere/
.. _octave: https://www.gnu.org/software/octave
.. _matlab: https://www.mathworks.com/
Optimization (:mod:`scipy.optimize`)
====================================

.. sectionauthor:: Travis E. Oliphant

.. sectionauthor:: Pauli Virtanen

.. sectionauthor:: Denis Laxalde

.. currentmodule:: scipy.optimize

.. contents::

The :mod:`scipy.optimize` package provides several commonly used
optimization algorithms. A detailed listing is available:
:mod:`scipy.optimize` (can also be found by ``help(scipy.optimize)``).


Unconstrained minimization of multivariate scalar functions (:func:`minimize`)
------------------------------------------------------------------------------

The :func:`minimize` function provides a common interface to unconstrained
and constrained minimization algorithms for multivariate scalar functions
in `scipy.optimize`. To demonstrate the minimization function, consider the
problem of minimizing the Rosenbrock function of :math:`N` variables:

.. math::

    f\left(\mathbf{x}\right)=\sum_{i=1}^{N-1}100\left(x_{i+1}-x_{i}^{2}\right)^{2}+\left(1-x_{i}\right)^{2}.

The minimum value of this function is 0 which is achieved when
:math:`x_{i}=1.`

Note that the Rosenbrock function and its derivatives are included in
`scipy.optimize`. The implementations shown in the following sections
provide examples of how to define an objective function as well as its
jacobian and hessian functions.

Nelder-Mead Simplex algorithm (``method='Nelder-Mead'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In the example below, the :func:`minimize` routine is used
with the *Nelder-Mead* simplex algorithm (selected through the ``method``
parameter):

    >>> import numpy as np
    >>> from scipy.optimize import minimize

    >>> def rosen(x):
    ...     """The Rosenbrock function"""
    ...     return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)

    >>> x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])
    >>> res = minimize(rosen, x0, method='nelder-mead',
    ...                options={'xatol': 1e-8, 'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 339
             Function evaluations: 571

    >>> print(res.x)
    [1. 1. 1. 1. 1.]

The simplex algorithm is probably the simplest way to minimize a fairly
well-behaved function. It requires only function evaluations and is a good
choice for simple minimization problems. However, because it does not use
any gradient evaluations, it may take longer to find the minimum.

Another optimization algorithm that needs only function calls to find
the minimum is *Powell*'s method available by setting ``method='powell'`` in
:func:`minimize`.


Broyden-Fletcher-Goldfarb-Shanno algorithm (``method='BFGS'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In order to converge more quickly to the solution, this routine uses
the gradient of the objective function. If the gradient is not given
by the user, then it is estimated using first-differences. The
Broyden-Fletcher-Goldfarb-Shanno (BFGS) method typically requires
fewer function calls than the simplex algorithm even when the gradient
must be estimated.

To demonstrate this algorithm, the Rosenbrock function is again used.
The gradient of the Rosenbrock function is the vector:

.. math::
   :nowrap:

    \begin{eqnarray*} \frac{\partial f}{\partial x_{j}} & = & \sum_{i=1}^{N}200\left(x_{i}-x_{i-1}^{2}\right)\left(\delta_{i,j}-2x_{i-1}\delta_{i-1,j}\right)-2\left(1-x_{i-1}\right)\delta_{i-1,j}.\\  & = & 200\left(x_{j}-x_{j-1}^{2}\right)-400x_{j}\left(x_{j+1}-x_{j}^{2}\right)-2\left(1-x_{j}\right).\end{eqnarray*}

This expression is valid for the interior derivatives. Special cases
are

.. math::
   :nowrap:

    \begin{eqnarray*} \frac{\partial f}{\partial x_{0}} & = & -400x_{0}\left(x_{1}-x_{0}^{2}\right)-2\left(1-x_{0}\right),\\ \frac{\partial f}{\partial x_{N-1}} & = & 200\left(x_{N-1}-x_{N-2}^{2}\right).\end{eqnarray*}

A Python function which computes this gradient is constructed by the
code-segment:

    >>> def rosen_der(x):
    ...     xm = x[1:-1]
    ...     xm_m1 = x[:-2]
    ...     xm_p1 = x[2:]
    ...     der = np.zeros_like(x)
    ...     der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)
    ...     der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])
    ...     der[-1] = 200*(x[-1]-x[-2]**2)
    ...     return der

This gradient information is specified in the :func:`minimize` function
through the ``jac`` parameter as illustrated below.


    >>> res = minimize(rosen, x0, method='BFGS', jac=rosen_der,
    ...                options={'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 51                     # may vary
             Function evaluations: 63
             Gradient evaluations: 63
    >>> res.x
    array([1., 1., 1., 1., 1.])


Newton-Conjugate-Gradient algorithm (``method='Newton-CG'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Newton-Conjugate Gradient algorithm is a modified Newton's
method and uses a conjugate gradient algorithm to (approximately) invert
the local Hessian [NW]_.  Newton's method is based on fitting the function
locally to a quadratic form:

.. math::

    f\left(\mathbf{x}\right)\approx f\left(\mathbf{x}_{0}\right)+\nabla f\left(\mathbf{x}_{0}\right)\cdot\left(\mathbf{x}-\mathbf{x}_{0}\right)+\frac{1}{2}\left(\mathbf{x}-\mathbf{x}_{0}\right)^{T}\mathbf{H}\left(\mathbf{x}_{0}\right)\left(\mathbf{x}-\mathbf{x}_{0}\right).

where :math:`\mathbf{H}\left(\mathbf{x}_{0}\right)` is a matrix of second-derivatives (the Hessian). If the Hessian is
positive definite then the local minimum of this function can be found
by setting the gradient of the quadratic form to zero, resulting in

.. math::

    \mathbf{x}_{\textrm{opt}}=\mathbf{x}_{0}-\mathbf{H}^{-1}\nabla f.

The inverse of the Hessian is evaluated using the conjugate-gradient
method. An example of employing this method to minimizing the
Rosenbrock function is given below. To take full advantage of the
Newton-CG method, a function which computes the Hessian must be
provided. The Hessian matrix itself does not need to be constructed,
only a vector which is the product of the Hessian with an arbitrary
vector needs to be available to the minimization routine. As a result,
the user can provide either a function to compute the Hessian matrix,
or a function to compute the product of the Hessian with an arbitrary
vector.


Full Hessian example:
"""""""""""""""""""""

The Hessian of the Rosenbrock function is

.. math::
   :nowrap:

    \begin{eqnarray*} H_{ij}=\frac{\partial^{2}f}{\partial x_{i}\partial x_{j}} & = & 200\left(\delta_{i,j}-2x_{i-1}\delta_{i-1,j}\right)-400x_{i}\left(\delta_{i+1,j}-2x_{i}\delta_{i,j}\right)-400\delta_{i,j}\left(x_{i+1}-x_{i}^{2}\right)+2\delta_{i,j},\\  & = & \left(202+1200x_{i}^{2}-400x_{i+1}\right)\delta_{i,j}-400x_{i}\delta_{i+1,j}-400x_{i-1}\delta_{i-1,j},\end{eqnarray*}

if :math:`i,j\in\left[1,N-2\right]` with :math:`i,j\in\left[0,N-1\right]` defining the :math:`N\times N` matrix. Other non-zero entries of the matrix are

.. math::
   :nowrap:

    \begin{eqnarray*} \frac{\partial^{2}f}{\partial x_{0}^{2}} & = & 1200x_{0}^{2}-400x_{1}+2,\\ \frac{\partial^{2}f}{\partial x_{0}\partial x_{1}}=\frac{\partial^{2}f}{\partial x_{1}\partial x_{0}} & = & -400x_{0},\\ \frac{\partial^{2}f}{\partial x_{N-1}\partial x_{N-2}}=\frac{\partial^{2}f}{\partial x_{N-2}\partial x_{N-1}} & = & -400x_{N-2},\\ \frac{\partial^{2}f}{\partial x_{N-1}^{2}} & = & 200.\end{eqnarray*}

For example, the Hessian when :math:`N=5` is

.. math::

    \mathbf{H}=\begin{bmatrix} 1200x_{0}^{2}-400x_{1}+2 & -400x_{0} & 0 & 0 & 0\\ -400x_{0} & 202+1200x_{1}^{2}-400x_{2} & -400x_{1} & 0 & 0\\ 0 & -400x_{1} & 202+1200x_{2}^{2}-400x_{3} & -400x_{2} & 0\\ 0 &  & -400x_{2} & 202+1200x_{3}^{2}-400x_{4} & -400x_{3}\\ 0 & 0 & 0 & -400x_{3} & 200\end{bmatrix}.

The code which computes this Hessian along with the code to minimize
the function using Newton-CG method is shown in the following example:

    >>> def rosen_hess(x):
    ...     x = np.asarray(x)
    ...     H = np.diag(-400*x[:-1],1) - np.diag(400*x[:-1],-1)
    ...     diagonal = np.zeros_like(x)
    ...     diagonal[0] = 1200*x[0]**2-400*x[1]+2
    ...     diagonal[-1] = 200
    ...     diagonal[1:-1] = 202 + 1200*x[1:-1]**2 - 400*x[2:]
    ...     H = H + np.diag(diagonal)
    ...     return H

    >>> res = minimize(rosen, x0, method='Newton-CG',
    ...                jac=rosen_der, hess=rosen_hess,
    ...                options={'xtol': 1e-8, 'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 19                       # may vary
             Function evaluations: 22
             Gradient evaluations: 19
             Hessian evaluations: 19
    >>> res.x
    array([1.,  1.,  1.,  1.,  1.])


Hessian product example:
""""""""""""""""""""""""

For larger minimization problems, storing the entire Hessian matrix can
consume considerable time and memory. The Newton-CG algorithm only needs
the product of the Hessian times an arbitrary vector. As a result, the user
can supply code to compute this product rather than the full Hessian by
giving a ``hess`` function which take the minimization vector as the first
argument and the arbitrary vector as the second argument (along with extra
arguments passed to the function to be minimized). If possible, using
Newton-CG with the Hessian product option is probably the fastest way to
minimize the function.

In this case, the product of the Rosenbrock Hessian with an arbitrary
vector is not difficult to compute. If :math:`\mathbf{p}` is the arbitrary
vector, then :math:`\mathbf{H}\left(\mathbf{x}\right)\mathbf{p}` has
elements:

.. math::

    \mathbf{H}\left(\mathbf{x}\right)\mathbf{p}=\begin{bmatrix} \left(1200x_{0}^{2}-400x_{1}+2\right)p_{0}-400x_{0}p_{1}\\ \vdots\\ -400x_{i-1}p_{i-1}+\left(202+1200x_{i}^{2}-400x_{i+1}\right)p_{i}-400x_{i}p_{i+1}\\ \vdots\\ -400x_{N-2}p_{N-2}+200p_{N-1}\end{bmatrix}.

Code which makes use of this Hessian product to minimize the
Rosenbrock function using :func:`minimize` follows:

    >>> def rosen_hess_p(x, p):
    ...     x = np.asarray(x)
    ...     Hp = np.zeros_like(x)
    ...     Hp[0] = (1200*x[0]**2 - 400*x[1] + 2)*p[0] - 400*x[0]*p[1]
    ...     Hp[1:-1] = -400*x[:-2]*p[:-2]+(202+1200*x[1:-1]**2-400*x[2:])*p[1:-1] \
    ...                -400*x[1:-1]*p[2:]
    ...     Hp[-1] = -400*x[-2]*p[-2] + 200*p[-1]
    ...     return Hp

    >>> res = minimize(rosen, x0, method='Newton-CG',
    ...                jac=rosen_der, hessp=rosen_hess_p,
    ...                options={'xtol': 1e-8, 'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 20                    # may vary
             Function evaluations: 23
             Gradient evaluations: 20
             Hessian evaluations: 44
    >>> res.x
    array([1., 1., 1., 1., 1.])


According to [NW]_ p. 170 the ``Newton-CG`` algorithm can be inefficient
when the Hessian is ill-conditioned because of the poor quality search directions
provided by the method in those situations. The method ``trust-ncg``,
according to the authors, deals more effectively with this problematic situation
and will be described next.

Trust-Region Newton-Conjugate-Gradient Algorithm (``method='trust-ncg'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The ``Newton-CG`` method is a line search method: it finds a direction
of search minimizing a quadratic approximation of the function and then uses
a line search algorithm to find the (nearly) optimal step size in that direction.
An alternative approach is to, first, fix the step size limit :math:`\Delta` and then find the
optimal step :math:`\mathbf{p}` inside the given trust-radius by solving
the following quadratic subproblem:

.. math::
   :nowrap:

   \begin{eqnarray*}
      \min_{\mathbf{p}} f\left(\mathbf{x}_{k}\right)+\nabla f\left(\mathbf{x}_{k}\right)\cdot\mathbf{p}+\frac{1}{2}\mathbf{p}^{T}\mathbf{H}\left(\mathbf{x}_{k}\right)\mathbf{p};&\\
      \text{subject to: } \|\mathbf{p}\|\le \Delta.&
    \end{eqnarray*}

The solution is then updated :math:`\mathbf{x}_{k+1} = \mathbf{x}_{k} + \mathbf{p}` and
the trust-radius :math:`\Delta` is adjusted according to the degree of agreement of the quadratic
model with the real function. This family of methods is known as trust-region methods.
The ``trust-ncg`` algorithm is a trust-region method that uses a conjugate gradient algorithm
to solve the trust-region subproblem [NW]_.


Full Hessian example:
"""""""""""""""""""""

    >>> res = minimize(rosen, x0, method='trust-ncg',
    ...                jac=rosen_der, hess=rosen_hess,
    ...                options={'gtol': 1e-8, 'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 20                    # may vary
             Function evaluations: 21
             Gradient evaluations: 20
             Hessian evaluations: 19
    >>> res.x
    array([1., 1., 1., 1., 1.])

Hessian product example:
""""""""""""""""""""""""

    >>> res = minimize(rosen, x0, method='trust-ncg',
    ...                jac=rosen_der, hessp=rosen_hess_p,
    ...                options={'gtol': 1e-8, 'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 20                    # may vary
             Function evaluations: 21
             Gradient evaluations: 20
             Hessian evaluations: 0
    >>> res.x
    array([1., 1., 1., 1., 1.])

Trust-Region Truncated Generalized Lanczos / Conjugate Gradient Algorithm (``method='trust-krylov'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Similar to the ``trust-ncg`` method, the ``trust-krylov`` method is a method
suitable for large-scale problems as it uses the hessian only as linear
operator by means of matrix-vector products.
It solves the quadratic subproblem more accurately than the ``trust-ncg``
method.

.. math::
   :nowrap:

   \begin{eqnarray*}
      \min_{\mathbf{p}} f\left(\mathbf{x}_{k}\right)+\nabla f\left(\mathbf{x}_{k}\right)\cdot\mathbf{p}+\frac{1}{2}\mathbf{p}^{T}\mathbf{H}\left(\mathbf{x}_{k}\right)\mathbf{p};&\\
      \text{subject to: } \|\mathbf{p}\|\le \Delta.&
    \end{eqnarray*}

This method wraps the [TRLIB]_ implementation of the [GLTR]_ method solving
exactly a trust-region subproblem restricted to a truncated Krylov subspace.
For indefinite problems it is usually better to use this method as it reduces
the number of nonlinear iterations at the expense of few more matrix-vector
products per subproblem solve in comparison to the ``trust-ncg`` method.

Full Hessian example:
"""""""""""""""""""""

    >>> res = minimize(rosen, x0, method='trust-krylov',
    ...                jac=rosen_der, hess=rosen_hess,
    ...                options={'gtol': 1e-8, 'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 19                    # may vary
             Function evaluations: 20
             Gradient evaluations: 20
             Hessian evaluations: 18
    >>> res.x
    array([1., 1., 1., 1., 1.])

Hessian product example:
""""""""""""""""""""""""

    >>> res = minimize(rosen, x0, method='trust-krylov',
    ...                jac=rosen_der, hessp=rosen_hess_p,
    ...                options={'gtol': 1e-8, 'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 19                    # may vary
             Function evaluations: 20
             Gradient evaluations: 20
             Hessian evaluations: 0
    >>> res.x
    array([1., 1., 1., 1., 1.])

.. [TRLIB] F. Lenders, C. Kirches, A. Potschka: "trlib: A vector-free
           implementation of the GLTR method for iterative solution of
           the trust region problem", :arxiv:`1611.04718`

.. [GLTR]  N. Gould, S. Lucidi, M. Roma, P. Toint: "Solving the
           Trust-Region Subproblem using the Lanczos Method",
           SIAM J. Optim., 9(2), 504--525, (1999).
           :doi:`10.1137/S1052623497322735`


Trust-Region Nearly Exact Algorithm (``method='trust-exact'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

All methods ``Newton-CG``, ``trust-ncg`` and ``trust-krylov`` are suitable for dealing with
large-scale problems (problems with thousands of variables). That is because the conjugate
gradient algorithm approximately solve the trust-region subproblem (or invert the Hessian)
by iterations without the explicit Hessian factorization. Since only the product of the Hessian
with an arbitrary vector is needed, the algorithm is specially suited for dealing
with sparse Hessians, allowing low storage requirements and significant time savings for
those sparse problems.

For medium-size problems, for which the storage and factorization cost of the Hessian are not critical,
it is possible to obtain a solution within fewer iteration by solving the trust-region subproblems
almost exactly. To achieve that, a certain nonlinear equations is solved iteratively for each quadratic
subproblem [CGT]_. This solution requires usually 3 or 4 Cholesky factorizations of the
Hessian matrix. As the result, the method converges in fewer number of iterations
and takes fewer evaluations of the objective function than the other implemented
trust-region methods. The Hessian product option is not supported by this algorithm. An
example using the Rosenbrock function follows:


    >>> res = minimize(rosen, x0, method='trust-exact',
    ...                jac=rosen_der, hess=rosen_hess,
    ...                options={'gtol': 1e-8, 'disp': True})
    Optimization terminated successfully.
             Current function value: 0.000000
             Iterations: 13                    # may vary
             Function evaluations: 14
             Gradient evaluations: 13
             Hessian evaluations: 14
    >>> res.x
    array([1., 1., 1., 1., 1.])


.. [NW] J. Nocedal, S.J. Wright "Numerical optimization."
	2nd edition. Springer Science (2006).
.. [CGT] Conn, A. R., Gould, N. I., & Toint, P. L.
        "Trust region methods". Siam. (2000). pp. 169-200.


.. _tutorial-sqlsp:

Constrained minimization of multivariate scalar functions (:func:`minimize`)
----------------------------------------------------------------------------

The :func:`minimize` function provides algorithms for constrained minimization,
namely ``'trust-constr'`` ,  ``'SLSQP'`` and ``'COBYLA'``. They require the constraints
to be defined using slightly different structures. The method ``'trust-constr'`` requires
the  constraints to be defined as a sequence of objects :func:`LinearConstraint` and
:func:`NonlinearConstraint`. Methods ``'SLSQP'`` and ``'COBYLA'``, on the other hand,
require constraints to be defined  as a sequence of dictionaries, with keys
``type``, ``fun`` and ``jac``.

As an example let us consider the constrained minimization of the Rosenbrock function:

.. math::
   :nowrap:

     \begin{eqnarray*} \min_{x_0, x_1} & ~~100\left(x_{1}-x_{0}^{2}\right)^{2}+\left(1-x_{0}\right)^{2} &\\
                     \text{subject to: } & x_0 + 2 x_1 \leq 1 & \\
		                         & x_0^2 + x_1 \leq 1  & \\
		                         & x_0^2 - x_1 \leq 1  & \\
					 & 2 x_0 + x_1 = 1 & \\
					 & 0 \leq  x_0  \leq 1 & \\
					 & -0.5 \leq  x_1  \leq 2.0. & \end{eqnarray*}

This optimization problem has the unique solution :math:`[x_0, x_1] = [0.4149,~ 0.1701]`,
for which only the first and fourth constraints are active.


Trust-Region Constrained Algorithm (``method='trust-constr'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The trust-region constrained method deals with constrained minimization problems of the form:

.. math::
   :nowrap:

     \begin{eqnarray*} \min_x & f(x) & \\
          \text{subject to: } & ~~~ c^l  \leq c(x) \leq c^u, &\\
           &  x^l  \leq x \leq x^u. & \end{eqnarray*}

When :math:`c^l_j = c^u_j` the method reads the :math:`j`-th constraint as an
equality constraint and deals with it accordingly. Besides that, one-sided constraint
can be specified by setting the upper or lower bound to ``np.inf`` with the appropriate sign.

The implementation is based on [EQSQP]_ for equality-constraint problems and on [TRIP]_
for problems with inequality constraints. Both are trust-region type algorithms suitable
for large-scale problems.


Defining Bounds Constraints:
""""""""""""""""""""""""""""

The bound constraints  :math:`0 \leq  x_0  \leq 1` and :math:`-0.5 \leq  x_1  \leq 2.0`
are defined using a :func:`Bounds` object.

    >>> from scipy.optimize import Bounds
    >>> bounds = Bounds([0, -0.5], [1.0, 2.0])

Defining Linear Constraints:
""""""""""""""""""""""""""""

The constraints :math:`x_0 + 2 x_1 \leq 1`
and :math:`2 x_0 + x_1 = 1` can be written in the linear constraint standard format:

.. math::
   :nowrap:

     \begin{equation*} \begin{bmatrix}-\infty \\1\end{bmatrix} \leq
      \begin{bmatrix} 1& 2 \\ 2& 1\end{bmatrix}
       \begin{bmatrix} x_0 \\x_1\end{bmatrix} \leq
        \begin{bmatrix} 1 \\ 1\end{bmatrix},\end{equation*}

and defined using a :func:`LinearConstraint` object.

    >>> from scipy.optimize import LinearConstraint
    >>> linear_constraint = LinearConstraint([[1, 2], [2, 1]], [-np.inf, 1], [1, 1])

Defining Nonlinear Constraints:
"""""""""""""""""""""""""""""""
The nonlinear constraint:

.. math::
   :nowrap:

     \begin{equation*} c(x) =
     \begin{bmatrix} x_0^2 + x_1 \\ x_0^2 - x_1\end{bmatrix}
      \leq
      \begin{bmatrix} 1 \\ 1\end{bmatrix}, \end{equation*}

with Jacobian matrix:

.. math::
   :nowrap:

     \begin{equation*} J(x) =
     \begin{bmatrix} 2x_0 & 1 \\ 2x_0 & -1\end{bmatrix},\end{equation*}

and linear combination of the Hessians:

.. math::
   :nowrap:

     \begin{equation*} H(x, v) = \sum_{i=0}^1 v_i \nabla^2 c_i(x) =
     v_0\begin{bmatrix} 2 & 0 \\ 0 & 0\end{bmatrix} +
     v_1\begin{bmatrix} 2 & 0 \\ 0 & 0\end{bmatrix},
     \end{equation*}

is defined using a :func:`NonlinearConstraint` object.

    >>> def cons_f(x):
    ...     return [x[0]**2 + x[1], x[0]**2 - x[1]]
    >>> def cons_J(x):
    ...     return [[2*x[0], 1], [2*x[0], -1]]
    >>> def cons_H(x, v):
    ...     return v[0]*np.array([[2, 0], [0, 0]]) + v[1]*np.array([[2, 0], [0, 0]])
    >>> from scipy.optimize import NonlinearConstraint
    >>> nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac=cons_J, hess=cons_H)

Alternatively, it is also possible to define the Hessian :math:`H(x, v)`
as a sparse matrix,

    >>> from scipy.sparse import csc_matrix
    >>> def cons_H_sparse(x, v):
    ...     return v[0]*csc_matrix([[2, 0], [0, 0]]) + v[1]*csc_matrix([[2, 0], [0, 0]])
    >>> nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1,
    ...                                            jac=cons_J, hess=cons_H_sparse)

or as a :obj:`~scipy.sparse.linalg.LinearOperator` object.

    >>> from scipy.sparse.linalg import LinearOperator
    >>> def cons_H_linear_operator(x, v):
    ...     def matvec(p):
    ...         return np.array([p[0]*2*(v[0]+v[1]), 0])
    ...     return LinearOperator((2, 2), matvec=matvec)
    >>> nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1,
    ...                                           jac=cons_J, hess=cons_H_linear_operator)

When the evaluation of the Hessian :math:`H(x, v)`
is difficult to implement or computationally infeasible, one may use :class:`HessianUpdateStrategy`.
Currently available strategies are :class:`BFGS` and :class:`SR1`.

    >>> from scipy.optimize import BFGS
    >>> nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac=cons_J, hess=BFGS())

Alternatively, the Hessian may be approximated using finite differences.

    >>> nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac=cons_J, hess='2-point')

The Jacobian of the constraints can be approximated by finite differences as well. In this case,
however, the Hessian cannot be computed with finite differences and needs to
be provided by the user or defined using :class:`HessianUpdateStrategy`.

    >>> nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac='2-point', hess=BFGS())


Solving the Optimization Problem:
"""""""""""""""""""""""""""""""""
The optimization problem is solved using:

    >>> x0 = np.array([0.5, 0])
    >>> res = minimize(rosen, x0, method='trust-constr', jac=rosen_der, hess=rosen_hess,
    ...                constraints=[linear_constraint, nonlinear_constraint],
    ...                options={'verbose': 1}, bounds=bounds)
    # may vary
    `gtol` termination condition is satisfied.
    Number of iterations: 12, function evaluations: 8, CG iterations: 7, optimality: 2.99e-09, constraint violation: 1.11e-16, execution time: 0.016 s.
    >>> print(res.x)
    [0.41494531 0.17010937]

When needed, the objective function Hessian can be defined using a :obj:`~scipy.sparse.linalg.LinearOperator` object,

    >>> def rosen_hess_linop(x):
    ...     def matvec(p):
    ...         return rosen_hess_p(x, p)
    ...     return LinearOperator((2, 2), matvec=matvec)
    >>> res = minimize(rosen, x0, method='trust-constr', jac=rosen_der, hess=rosen_hess_linop,
    ...                constraints=[linear_constraint, nonlinear_constraint],
    ...                options={'verbose': 1}, bounds=bounds)
    # may vary
    `gtol` termination condition is satisfied.
    Number of iterations: 12, function evaluations: 8, CG iterations: 7, optimality: 2.99e-09, constraint violation: 1.11e-16, execution time: 0.018 s.
    >>> print(res.x)
    [0.41494531 0.17010937]

or a Hessian-vector product through the parameter ``hessp``.

    >>> res = minimize(rosen, x0, method='trust-constr', jac=rosen_der, hessp=rosen_hess_p,
    ...                constraints=[linear_constraint, nonlinear_constraint],
    ...                options={'verbose': 1}, bounds=bounds)
    # may vary
    `gtol` termination condition is satisfied.
    Number of iterations: 12, function evaluations: 8, CG iterations: 7, optimality: 2.99e-09, constraint violation: 1.11e-16, execution time: 0.018 s.
    >>> print(res.x)
    [0.41494531 0.17010937]


Alternatively, the first and second derivatives of the objective function can be approximated.
For instance,  the Hessian can be approximated with :func:`SR1` quasi-Newton approximation
and the gradient with finite differences.

    >>> from scipy.optimize import SR1
    >>> res = minimize(rosen, x0, method='trust-constr',  jac="2-point", hess=SR1(),
    ...                constraints=[linear_constraint, nonlinear_constraint],
    ...                options={'verbose': 1}, bounds=bounds)
    # may vary
    `gtol` termination condition is satisfied.
    Number of iterations: 12, function evaluations: 24, CG iterations: 7, optimality: 4.48e-09, constraint violation: 0.00e+00, execution time: 0.016 s.
    >>> print(res.x)
    [0.41494531 0.17010937]


.. [TRIP] Byrd, Richard H., Mary E. Hribar, and Jorge Nocedal. 1999.
    An interior point algorithm for large-scale nonlinear  programming.
    SIAM Journal on Optimization 9.4: 877-900.
.. [EQSQP] Lalee, Marucha, Jorge Nocedal, and Todd Plantega. 1998. On the
    implementation of an algorithm for large-scale equality constrained
    optimization. SIAM Journal on Optimization 8.3: 682-706.

Sequential Least SQuares Programming (SLSQP) Algorithm (``method='SLSQP'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The SLSQP method deals with constrained minimization problems of the form:

.. math::
   :nowrap:

     \begin{eqnarray*} \min_x & f(x) \\
          \text{subject to: } & c_j(x) =  0  ,  &j \in \mathcal{E}\\
            & c_j(x) \geq 0  ,  &j \in \mathcal{I}\\
           &  \text{lb}_i  \leq x_i \leq \text{ub}_i , &i = 1,...,N. \end{eqnarray*}

Where :math:`\mathcal{E}` or :math:`\mathcal{I}` are sets of indices
containing equality and inequality constraints.

Both linear and nonlinear constraints are defined as dictionaries with keys ``type``, ``fun`` and ``jac``.

    >>> ineq_cons = {'type': 'ineq',
    ...              'fun' : lambda x: np.array([1 - x[0] - 2*x[1],
    ...                                          1 - x[0]**2 - x[1],
    ...                                          1 - x[0]**2 + x[1]]),
    ...              'jac' : lambda x: np.array([[-1.0, -2.0],
    ...                                          [-2*x[0], -1.0],
    ...                                          [-2*x[0], 1.0]])}
    >>> eq_cons = {'type': 'eq',
    ...            'fun' : lambda x: np.array([2*x[0] + x[1] - 1]),
    ...            'jac' : lambda x: np.array([2.0, 1.0])}


And the optimization problem is solved with:

    >>> x0 = np.array([0.5, 0])
    >>> res = minimize(rosen, x0, method='SLSQP', jac=rosen_der,
    ...                constraints=[eq_cons, ineq_cons], options={'ftol': 1e-9, 'disp': True},
    ...                bounds=bounds)
    # may vary
    Optimization terminated successfully.    (Exit mode 0)
                Current function value: 0.342717574857755
                Iterations: 5
                Function evaluations: 6
                Gradient evaluations: 5
    >>> print(res.x)
    [0.41494475 0.1701105 ]

Most of the options available for the method ``'trust-constr'`` are not available
for ``'SLSQP'``.

Global optimization
-------------------

Global optimization aims to find the global minimum of a function within given
bounds, in the presence of potentially many local minima. Typically, global
minimizers efficiently search the parameter space, while using a local
minimizer (e.g., :func:`minimize`) under the hood.  SciPy contains a
number of good global optimizers.  Here, we'll use those on the same objective
function, namely the (aptly named) ``eggholder`` function::

   >>> def eggholder(x):
   ...     return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))
   ...             -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47)))))

   >>> bounds = [(-512, 512), (-512, 512)]

This function looks like an egg carton::

   >>> import matplotlib.pyplot as plt
   >>> from mpl_toolkits.mplot3d import Axes3D

   >>> x = np.arange(-512, 513)
   >>> y = np.arange(-512, 513)
   >>> xgrid, ygrid = np.meshgrid(x, y)
   >>> xy = np.stack([xgrid, ygrid])

   >>> fig = plt.figure()
   >>> ax = fig.add_subplot(111, projection='3d')
   >>> ax.view_init(45, -45)
   >>> ax.plot_surface(xgrid, ygrid, eggholder(xy), cmap='terrain')
   >>> ax.set_xlabel('x')
   >>> ax.set_ylabel('y')
   >>> ax.set_zlabel('eggholder(x, y)')
   >>> plt.show()

.. plot:: tutorial/examples/optimize_global_2.py
   :align: center
   :include-source: 0

We now use the global optimizers to obtain the minimum and the function value
at the minimum. We'll store the results in a dictionary so we can compare
different optimization results later.

   >>> from scipy import optimize
   >>> results = dict()
   >>> results['shgo'] = optimize.shgo(eggholder, bounds)
   >>> results['shgo']
        fun: -935.3379515604197  # may vary
       funl: array([-935.33795156])
    message: 'Optimization terminated successfully.'
       nfev: 42
        nit: 2
      nlfev: 37
      nlhev: 0
      nljev: 9
    success: True
          x: array([439.48096952, 453.97740589])
         xl: array([[439.48096952, 453.97740589]])

   >>> results['DA'] = optimize.dual_annealing(eggholder, bounds)
   >>> results['DA']
        fun: -956.9182316237413  # may vary
    message: ['Maximum number of iteration reached']
       nfev: 4091
       nhev: 0
        nit: 1000
       njev: 0
          x: array([482.35324114, 432.87892901])

All optimizers return an ``OptimizeResult``, which in addition to the solution
contains information on the number of function evaluations, whether the
optimization was successful, and more.  For brevity, we won't show the full
output of the other optimizers::

   >>> results['DE'] = optimize.differential_evolution(eggholder, bounds)

:func:`shgo` has a second method, which returns all local minima rather than
only what it thinks is the global minimum::

   >>> results['shgo_sobol'] = optimize.shgo(eggholder, bounds, n=200, iters=5,
   ...                                       sampling_method='sobol')

We'll now plot all found minima on a heatmap of the function::

   >>> fig = plt.figure()
   >>> ax = fig.add_subplot(111)
   >>> im = ax.imshow(eggholder(xy), interpolation='bilinear', origin='lower',
   ...                cmap='gray')
   >>> ax.set_xlabel('x')
   >>> ax.set_ylabel('y')
   >>>
   >>> def plot_point(res, marker='o', color=None):
   ...     ax.plot(512+res.x[0], 512+res.x[1], marker=marker, color=color, ms=10)

   >>> plot_point(results['DE'], color='c')  # differential_evolution - cyan
   >>> plot_point(results['DA'], color='w')  # dual_annealing.        - white

   >>> # SHGO produces multiple minima, plot them all (with a smaller marker size)
   >>> plot_point(results['shgo'], color='r', marker='+')
   >>> plot_point(results['shgo_sobol'], color='r', marker='x')
   >>> for i in range(results['shgo_sobol'].xl.shape[0]):
   ...     ax.plot(512 + results['shgo_sobol'].xl[i, 0],
   ...             512 + results['shgo_sobol'].xl[i, 1],
   ...             'ro', ms=2)

   >>> ax.set_xlim([-4, 514*2])
   >>> ax.set_ylim([-4, 514*2])
   >>> plt.show()

.. plot:: tutorial/examples/optimize_global_1.py
   :align: center
   :include-source: 0

Least-squares minimization (:func:`least_squares`)
--------------------------------------------------

SciPy is capable of solving robustified bound-constrained nonlinear
least-squares problems:

.. math::
   :nowrap:

   \begin{align}
   &\min_\mathbf{x} \frac{1}{2} \sum_{i = 1}^m \rho\left(f_i(\mathbf{x})^2\right) \\
   &\text{subject to }\mathbf{lb} \leq \mathbf{x} \leq \mathbf{ub}
   \end{align}

Here :math:`f_i(\mathbf{x})` are smooth functions from
:math:`\mathbb{R}^n` to :math:`\mathbb{R}`, we refer to them as residuals.
The purpose of a scalar-valued function :math:`\rho(\cdot)` is to reduce the
influence of outlier residuals and contribute to robustness of the solution,
we refer to it as a loss function. A linear loss function gives a standard
least-squares problem. Additionally, constraints in a form of lower and upper
bounds on some of :math:`x_j` are allowed.

All methods specific to least-squares minimization utilize a :math:`m \times n`
matrix of partial derivatives called Jacobian and defined as
:math:`J_{ij} = \partial f_i / \partial x_j`. It is highly recommended to
compute this matrix analytically and pass it to :func:`least_squares`,
otherwise, it will be estimated by finite differences, which takes a lot of
additional time and can be very inaccurate in hard cases.

Function :func:`least_squares` can be used for fitting a function
:math:`\varphi(t; \mathbf{x})` to empirical data :math:`\{(t_i, y_i), i = 0, \ldots, m-1\}`.
To do this, one should simply precompute residuals as
:math:`f_i(\mathbf{x}) = w_i (\varphi(t_i; \mathbf{x}) - y_i)`, where :math:`w_i`
are weights assigned to each observation.

Example of solving a fitting problem
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Here we consider an enzymatic reaction [1]_. There are 11 residuals defined as

.. math::
    f_i(x) = \frac{x_0 (u_i^2 + u_i x_1)}{u_i^2 + u_i x_2 + x_3} - y_i, \quad i = 0, \ldots, 10,

where :math:`y_i` are measurement values and :math:`u_i` are values of
the independent variable. The unknown vector of parameters is
:math:`\mathbf{x} = (x_0, x_1, x_2, x_3)^T`. As was said previously, it is
recommended to compute Jacobian matrix in a closed form:

.. math::
   :nowrap:

    \begin{align}
    &J_{i0} = \frac{\partial f_i}{\partial x_0} = \frac{u_i^2 + u_i x_1}{u_i^2 + u_i x_2 + x_3} \\
    &J_{i1} = \frac{\partial f_i}{\partial x_1} = \frac{u_i x_0}{u_i^2 + u_i x_2 + x_3} \\
    &J_{i2} = \frac{\partial f_i}{\partial x_2} = -\frac{x_0 (u_i^2 + u_i x_1) u_i}{(u_i^2 + u_i x_2 + x_3)^2} \\
    &J_{i3} = \frac{\partial f_i}{\partial x_3} = -\frac{x_0 (u_i^2 + u_i x_1)}{(u_i^2 + u_i x_2 + x_3)^2}
    \end{align}

We are going to use the "hard" starting point defined in [2]_. To find a
physically meaningful solution, avoid potential division by zero and assure
convergence to the global minimum we impose constraints
:math:`0 \leq x_j \leq 100, j = 0, 1, 2, 3`.

The code below implements least-squares estimation of :math:`\mathbf{x}` and
finally plots the original data and the fitted model function:

.. plot::

    >>> from scipy.optimize import least_squares

    >>> def model(x, u):
    ...     return x[0] * (u ** 2 + x[1] * u) / (u ** 2 + x[2] * u + x[3])

    >>> def fun(x, u, y):
    ...     return model(x, u) - y

    >>> def jac(x, u, y):
    ...     J = np.empty((u.size, x.size))
    ...     den = u ** 2 + x[2] * u + x[3]
    ...     num = u ** 2 + x[1] * u
    ...     J[:, 0] = num / den
    ...     J[:, 1] = x[0] * u / den
    ...     J[:, 2] = -x[0] * num * u / den ** 2
    ...     J[:, 3] = -x[0] * num / den ** 2
    ...     return J

    >>> u = np.array([4.0, 2.0, 1.0, 5.0e-1, 2.5e-1, 1.67e-1, 1.25e-1, 1.0e-1,
    ...               8.33e-2, 7.14e-2, 6.25e-2])
    >>> y = np.array([1.957e-1, 1.947e-1, 1.735e-1, 1.6e-1, 8.44e-2, 6.27e-2,
    ...               4.56e-2, 3.42e-2, 3.23e-2, 2.35e-2, 2.46e-2])
    >>> x0 = np.array([2.5, 3.9, 4.15, 3.9])
    >>> res = least_squares(fun, x0, jac=jac, bounds=(0, 100), args=(u, y), verbose=1)
    # may vary
    `ftol` termination condition is satisfied.
    Function evaluations 130, initial cost 4.4383e+00, final cost 1.5375e-04, first-order optimality 4.92e-08.
    >>> res.x
    array([ 0.19280596,  0.19130423,  0.12306063,  0.13607247])

    >>> import matplotlib.pyplot as plt
    >>> u_test = np.linspace(0, 5)
    >>> y_test = model(res.x, u_test)
    >>> plt.plot(u, y, 'o', markersize=4, label='data')
    >>> plt.plot(u_test, y_test, label='fitted model')
    >>> plt.xlabel("u")
    >>> plt.ylabel("y")
    >>> plt.legend(loc='lower right')
    >>> plt.show()

.. [1] J. Kowalik and J. F. Morrison, “Analysis of kinetic data for allosteric enzyme reactions as
   a nonlinear regression problem”, Math. Biosci., vol. 2, pp. 57-66, 1968.
.. [2] B. M. Averick et al., “The MINPACK-2 Test Problem Collection”.

Further examples
^^^^^^^^^^^^^^^^

Three interactive examples below illustrate usage of :func:`least_squares` in
greater detail.

1. `Large-scale bundle adjustment in scipy <https://scipy-cookbook.readthedocs.io/items/bundle_adjustment.html>`_
   demonstrates large-scale capabilities of :func:`least_squares` and how to
   efficiently compute finite difference approximation of sparse Jacobian.
2. `Robust nonlinear regression in scipy <https://scipy-cookbook.readthedocs.io/items/robust_regression.html>`_
   shows how to handle outliers with a robust loss function in a nonlinear
   regression.
3. `Solving a discrete boundary-value problem in scipy <https://scipy-cookbook.readthedocs.io/items/discrete_bvp.html>`_
   examines how to solve a large system of equations and use bounds to achieve
   desired properties of the solution.

For the details about mathematical algorithms behind the implementation refer
to documentation of :func:`least_squares`.


Univariate function minimizers (:func:`minimize_scalar`)
--------------------------------------------------------

Often only the minimum of an univariate function (i.e., a function that
takes a scalar as input) is needed. In these circumstances, other
optimization techniques have been developed that can work faster. These are
accessible from the :func:`minimize_scalar` function, which proposes several
algorithms.


Unconstrained minimization (``method='brent'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

There are, actually, two methods that can be used to minimize an univariate
function: `brent` and `golden`, but `golden` is included only for academic
purposes and should rarely be used. These can be respectively selected
through the `method` parameter in :func:`minimize_scalar`. The `brent`
method uses Brent's algorithm for locating a minimum. Optimally, a bracket
(the `bracket` parameter) should be given which contains the minimum desired. A
bracket is a triple :math:`\left( a, b, c \right)` such that :math:`f
\left( a \right) > f \left( b \right) < f \left( c \right)` and :math:`a <
b < c` . If this is not given, then alternatively two starting points can
be chosen and a bracket will be found from these points using a simple
marching algorithm. If these two starting points are not provided, `0` and
`1` will be used (this may not be the right choice for your function and
result in an unexpected minimum being returned).

Here is an example:

    >>> from scipy.optimize import minimize_scalar
    >>> f = lambda x: (x - 2) * (x + 1)**2
    >>> res = minimize_scalar(f, method='brent')
    >>> print(res.x)
    1.0


Bounded minimization (``method='bounded'``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Very often, there are constraints that can be placed on the solution space
before minimization occurs. The `bounded` method in :func:`minimize_scalar`
is an example of a constrained minimization procedure that provides a
rudimentary interval constraint for scalar functions. The interval
constraint allows the minimization to occur only between two fixed
endpoints, specified using the mandatory `bounds` parameter.

For example, to find the minimum of :math:`J_{1}\left( x \right)` near
:math:`x=5` , :func:`minimize_scalar` can be called using the interval
:math:`\left[ 4, 7 \right]` as a constraint. The result is
:math:`x_{\textrm{min}}=5.3314` :

    >>> from scipy.special import j1
    >>> res = minimize_scalar(j1, bounds=(4, 7), method='bounded')
    >>> res.x
    5.33144184241


Custom minimizers
-----------------

Sometimes, it may be useful to use a custom method as a (multivariate
or univariate) minimizer, for example, when using some library wrappers
of :func:`minimize` (e.g., :func:`basinhopping`).

We can achieve that by, instead of passing a method name, passing
a callable (either a function or an object implementing a `__call__`
method) as the `method` parameter.

Let us consider an (admittedly rather virtual) need to use a trivial
custom multivariate minimization method that will just search the
neighborhood in each dimension independently with a fixed step size::

    >>> from scipy.optimize import OptimizeResult
    >>> def custmin(fun, x0, args=(), maxfev=None, stepsize=0.1,
    ...         maxiter=100, callback=None, **options):
    ...     bestx = x0
    ...     besty = fun(x0)
    ...     funcalls = 1
    ...     niter = 0
    ...     improved = True
    ...     stop = False
    ...
    ...     while improved and not stop and niter < maxiter:
    ...         improved = False
    ...         niter += 1
    ...         for dim in range(np.size(x0)):
    ...             for s in [bestx[dim] - stepsize, bestx[dim] + stepsize]:
    ...                 testx = np.copy(bestx)
    ...                 testx[dim] = s
    ...                 testy = fun(testx, *args)
    ...                 funcalls += 1
    ...                 if testy < besty:
    ...                     besty = testy
    ...                     bestx = testx
    ...                     improved = True
    ...             if callback is not None:
    ...                 callback(bestx)
    ...             if maxfev is not None and funcalls >= maxfev:
    ...                 stop = True
    ...                 break
    ...
    ...     return OptimizeResult(fun=besty, x=bestx, nit=niter,
    ...                           nfev=funcalls, success=(niter > 1))
    >>> x0 = [1.35, 0.9, 0.8, 1.1, 1.2]
    >>> res = minimize(rosen, x0, method=custmin, options=dict(stepsize=0.05))
    >>> res.x
    array([1., 1., 1., 1., 1.])

This will work just as well in case of univariate optimization::

    >>> def custmin(fun, bracket, args=(), maxfev=None, stepsize=0.1,
    ...         maxiter=100, callback=None, **options):
    ...     bestx = (bracket[1] + bracket[0]) / 2.0
    ...     besty = fun(bestx)
    ...     funcalls = 1
    ...     niter = 0
    ...     improved = True
    ...     stop = False
    ...
    ...     while improved and not stop and niter < maxiter:
    ...         improved = False
    ...         niter += 1
    ...         for testx in [bestx - stepsize, bestx + stepsize]:
    ...             testy = fun(testx, *args)
    ...             funcalls += 1
    ...             if testy < besty:
    ...                 besty = testy
    ...                 bestx = testx
    ...                 improved = True
    ...         if callback is not None:
    ...             callback(bestx)
    ...         if maxfev is not None and funcalls >= maxfev:
    ...             stop = True
    ...             break
    ...
    ...     return OptimizeResult(fun=besty, x=bestx, nit=niter,
    ...                           nfev=funcalls, success=(niter > 1))
    >>> def f(x):
    ...    return (x - 2)**2 * (x + 2)**2
    >>> res = minimize_scalar(f, bracket=(-3.5, 0), method=custmin,
    ...                       options=dict(stepsize = 0.05))
    >>> res.x
    -2.0


Root finding
------------

Scalar functions
^^^^^^^^^^^^^^^^

If one has a single-variable equation, there are multiple different root
finding algorithms that can be tried. Most of these algorithms require the
endpoints of an interval in which a root is expected (because the function
changes signs). In general, :obj:`brentq` is the best choice, but the other
methods may be useful in certain circumstances or for academic purposes.
When a bracket is not available, but one or more derivatives are available,
then :obj:`newton` (or ``halley``, ``secant``) may be applicable.
This is especially the case if the function is defined on a subset of the
complex plane, and the bracketing methods cannot be used.


Fixed-point solving
^^^^^^^^^^^^^^^^^^^

A problem closely related to finding the zeros of a function is the
problem of finding a fixed point of a function. A fixed point of a
function is the point at which evaluation of the function returns the
point: :math:`g\left(x\right)=x.` Clearly, the fixed point of :math:`g`
is the root of :math:`f\left(x\right)=g\left(x\right)-x.`
Equivalently, the root of :math:`f` is the fixed point of
:math:`g\left(x\right)=f\left(x\right)+x.` The routine
:obj:`fixed_point` provides a simple iterative method using Aitkens
sequence acceleration to estimate the fixed point of :math:`g` given a
starting point.

Sets of equations
^^^^^^^^^^^^^^^^^

Finding a root of a set of non-linear equations can be achieved using the
:func:`root` function. Several methods are available, amongst which ``hybr``
(the default) and ``lm``, which, respectively, use the hybrid method of Powell
and the Levenberg-Marquardt method from MINPACK.

The following example considers the single-variable transcendental
equation

.. math::

    x+2\cos\left(x\right)=0,

a root of which can be found as follows::

    >>> import numpy as np
    >>> from scipy.optimize import root
    >>> def func(x):
    ...     return x + 2 * np.cos(x)
    >>> sol = root(func, 0.3)
    >>> sol.x
    array([-1.02986653])
    >>> sol.fun
    array([ -6.66133815e-16])

Consider now a set of non-linear equations

.. math::
   :nowrap:

    \begin{eqnarray*}
    x_{0}\cos\left(x_{1}\right) & = & 4,\\
    x_{0}x_{1}-x_{1} & = & 5.
    \end{eqnarray*}

We define the objective function so that it also returns the Jacobian and
indicate this by setting the ``jac`` parameter to ``True``. Also, the
Levenberg-Marquardt solver is used here.

::

    >>> def func2(x):
    ...     f = [x[0] * np.cos(x[1]) - 4,
    ...          x[1]*x[0] - x[1] - 5]
    ...     df = np.array([[np.cos(x[1]), -x[0] * np.sin(x[1])],
    ...                    [x[1], x[0] - 1]])
    ...     return f, df
    >>> sol = root(func2, [1, 1], jac=True, method='lm')
    >>> sol.x
    array([ 6.50409711,  0.90841421])


Root finding for large problems
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Methods ``hybr`` and ``lm`` in :func:`root` cannot deal with a very large
number of variables (*N*), as they need to calculate and invert a dense *N
x N* Jacobian matrix on every Newton step. This becomes rather inefficient
when *N* grows.

Consider, for instance, the following problem: we need to solve the
following integrodifferential equation on the square
:math:`[0,1]\times[0,1]`:

.. math::

   (\partial_x^2 + \partial_y^2) P + 5 \left(\int_0^1\int_0^1\cosh(P)\,dx\,dy\right)^2 = 0

with the boundary condition :math:`P(x,1) = 1` on the upper edge and
:math:`P=0` elsewhere on the boundary of the square. This can be done
by approximating the continuous function *P* by its values on a grid,
:math:`P_{n,m}\approx{}P(n h, m h)`, with a small grid spacing
*h*. The derivatives and integrals can then be approximated; for
instance :math:`\partial_x^2 P(x,y)\approx{}(P(x+h,y) - 2 P(x,y) +
P(x-h,y))/h^2`. The problem is then equivalent to finding the root of
some function ``residual(P)``, where ``P`` is a vector of length
:math:`N_x N_y`.

Now, because :math:`N_x N_y` can be large, methods ``hybr`` or ``lm`` in
:func:`root` will take a long time to solve this problem. The solution can,
however, be found using one of the large-scale solvers, for example
``krylov``, ``broyden2``, or ``anderson``. These use what is known as the
inexact Newton method, which instead of computing the Jacobian matrix
exactly, forms an approximation for it.

The problem we have can now be solved as follows:

.. plot::

    import numpy as np
    from scipy.optimize import root
    from numpy import cosh, zeros_like, mgrid, zeros

    # parameters
    nx, ny = 75, 75
    hx, hy = 1./(nx-1), 1./(ny-1)

    P_left, P_right = 0, 0
    P_top, P_bottom = 1, 0

    def residual(P):
       d2x = zeros_like(P)
       d2y = zeros_like(P)

       d2x[1:-1] = (P[2:]   - 2*P[1:-1] + P[:-2]) / hx/hx
       d2x[0]    = (P[1]    - 2*P[0]    + P_left)/hx/hx
       d2x[-1]   = (P_right - 2*P[-1]   + P[-2])/hx/hx

       d2y[:,1:-1] = (P[:,2:] - 2*P[:,1:-1] + P[:,:-2])/hy/hy
       d2y[:,0]    = (P[:,1]  - 2*P[:,0]    + P_bottom)/hy/hy
       d2y[:,-1]   = (P_top   - 2*P[:,-1]   + P[:,-2])/hy/hy

       return d2x + d2y + 5*cosh(P).mean()**2

    # solve
    guess = zeros((nx, ny), float)
    sol = root(residual, guess, method='krylov', options={'disp': True})
    #sol = root(residual, guess, method='broyden2', options={'disp': True, 'max_rank': 50})
    #sol = root(residual, guess, method='anderson', options={'disp': True, 'M': 10})
    print('Residual: %g' % abs(residual(sol.x)).max())

    # visualize
    import matplotlib.pyplot as plt
    x, y = mgrid[0:1:(nx*1j), 0:1:(ny*1j)]
    plt.pcolormesh(x, y, sol.x, shading='gouraud')
    plt.colorbar()
    plt.show()


Still too slow? Preconditioning.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When looking for the zero of the functions :math:`f_i({\bf x}) = 0`,
*i = 1, 2, ..., N*, the ``krylov`` solver spends most of the
time inverting the Jacobian matrix,

.. math:: J_{ij} = \frac{\partial f_i}{\partial x_j} .

If you have an approximation for the inverse matrix
:math:`M\approx{}J^{-1}`, you can use it for *preconditioning* the
linear-inversion problem. The idea is that instead of solving
:math:`J{\bf s}={\bf y}` one solves :math:`MJ{\bf s}=M{\bf y}`: since
matrix :math:`MJ` is "closer" to the identity matrix than :math:`J`
is, the equation should be easier for the Krylov method to deal with.

The matrix *M* can be passed to :func:`root` with method ``krylov`` as an
option ``options['jac_options']['inner_M']``. It can be a (sparse) matrix
or a :obj:`scipy.sparse.linalg.LinearOperator` instance.

For the problem in the previous section, we note that the function to
solve consists of two parts: the first one is the application of the
Laplace operator, :math:`[\partial_x^2 + \partial_y^2] P`, and the second
is the integral. We can actually easily compute the Jacobian corresponding
to the Laplace operator part: we know that in 1-D

.. math::

   \partial_x^2 \approx \frac{1}{h_x^2} \begin{pmatrix}
   -2 & 1 & 0 & 0 \cdots \\
   1 & -2 & 1 & 0 \cdots \\
   0 & 1 & -2 & 1 \cdots \\
   \ldots
   \end{pmatrix}
   = h_x^{-2} L

so that the whole 2-D operator is represented by

.. math::

   J_1 = \partial_x^2 + \partial_y^2
   \simeq
   h_x^{-2} L \otimes I + h_y^{-2} I \otimes L

The matrix :math:`J_2` of the Jacobian corresponding to the integral
is more difficult to calculate, and since *all* of it entries are
nonzero, it will be difficult to invert. :math:`J_1` on the other hand
is a relatively simple matrix, and can be inverted by
:obj:`scipy.sparse.linalg.splu` (or the inverse can be approximated by
:obj:`scipy.sparse.linalg.spilu`). So we are content to take
:math:`M\approx{}J_1^{-1}` and hope for the best.

In the example below, we use the preconditioner :math:`M=J_1^{-1}`.

.. literalinclude:: examples/newton_krylov_preconditioning.py

Resulting run, first without preconditioning::

  0:  |F(x)| = 803.614; step 1; tol 0.000257947
  1:  |F(x)| = 345.912; step 1; tol 0.166755
  2:  |F(x)| = 139.159; step 1; tol 0.145657
  3:  |F(x)| = 27.3682; step 1; tol 0.0348109
  4:  |F(x)| = 1.03303; step 1; tol 0.00128227
  5:  |F(x)| = 0.0406634; step 1; tol 0.00139451
  6:  |F(x)| = 0.00344341; step 1; tol 0.00645373
  7:  |F(x)| = 0.000153671; step 1; tol 0.00179246
  8:  |F(x)| = 6.7424e-06; step 1; tol 0.00173256
  Residual 3.57078908664e-07
  Evaluations 317

and then with preconditioning::

  0:  |F(x)| = 136.993; step 1; tol 7.49599e-06
  1:  |F(x)| = 4.80983; step 1; tol 0.00110945
  2:  |F(x)| = 0.195942; step 1; tol 0.00149362
  3:  |F(x)| = 0.000563597; step 1; tol 7.44604e-06
  4:  |F(x)| = 1.00698e-09; step 1; tol 2.87308e-12
  Residual 9.29603061195e-11
  Evaluations 77

Using a preconditioner reduced the number of evaluations of the
``residual`` function by a factor of *4*. For problems where the
residual is expensive to compute, good preconditioning can be crucial
--- it can even decide whether the problem is solvable in practice or
not.

Preconditioning is an art, science, and industry. Here, we were lucky
in making a simple choice that worked reasonably well, but there is a
lot more depth to this topic than is shown here.

Linear programming (:func:`linprog`)
------------------------------------

The function :func:`linprog` can minimize a linear objective function
subject to linear equality and inequality constraints. This kind of
problem is well known as linear programming. Linear programming solves
problems of the following form:

.. math::

        \min_x \ & c^T x \\
        \mbox{such that} \ & A_{ub} x \leq b_{ub},\\
        & A_{eq} x = b_{eq},\\
        & l \leq x \leq u ,

where :math:`x` is a vector of decision variables; :math:`c`, :math:`b_{ub}`,
:math:`b_{eq}`, :math:`l`, and :math:`u` are vectors; and :math:`A_{ub}` and
:math:`A_{eq}` are matrices.

In this tutorial, we will try to solve a typical linear programming
problem using :func:`linprog`.

Linear programming example
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Consider the following simple linear programming problem:

.. math::
        \max_{x_1, x_2, x_3, x_4} \ & 29x_1 + 45x_2 \\
        \mbox{such that} \
        & x_1 -x_2 -3x_3 \leq 5\\
        & 2x_1 -3x_2 -7x_3 + 3x_4 \geq 10\\
        & 2x_1 + 8x_2 + x_3 = 60\\
        & 4x_1 + 4x_2 + x_4 = 60\\
        & 0 \leq x_0\\
        & 0 \leq x_1 \leq 5\\
        & x_2 \leq 0.5\\
        & -3 \leq x_3\\

We need some mathematical manipulations to convert the target problem to the form accepted by :func:`linprog`.

First of all, let's consider the objective function.
We want to maximize the objective
function, but :func:`linprog` can only accept a minimization problem. This is easily remedied by converting the maximize
:math:`29x_1 + 45x_2` to minimizing :math:`-29x_1 -45x_2`. Also, :math:`x_3, x_4` are not shown in the objective
function. That means the weights corresponding with :math:`x_3, x_4` are zero. So, the objective function can be
converted to:

.. math::
        \min_{x_1, x_2, x_3, x_4} \ -29x_1 -45x_2 + 0x_3 + 0x_4

If we define the vector of decision variables :math:`x = [x_1, x_2, x_3, x_4]^T`, the objective weights vector :math:`c` of :func:`linprog` in this problem
should be

.. math::
        c = [-29, -45, 0, 0]^T

Next, let's consider the two inequality constraints. The first one is a "less than" inequality, so it is already in the form accepted by `linprog`.
The second one is a "greater than" inequality, so we need to multiply both sides by :math:`-1` to convert it to a "less than" inequality.
Explicitly showing zero coefficients, we have:

.. math::
        x_1 -x_2 -3x_3 + 0x_4  &\leq 5\\
        -2x_1 + 3x_2 + 7x_3 - 3x_4 &\leq -10\\

These equations can be converted to matrix form:

.. math::
    A_{ub} x \leq b_{ub}\\

where

.. math::
   :nowrap:

    \begin{equation*} A_{ub} =
    \begin{bmatrix} 1 & -1 & -3 & 0 \\
                    -2 & 3 & 7 & -3
    \end{bmatrix}
    \end{equation*}

.. math::
   :nowrap:

    \begin{equation*} b_{ub} =
    \begin{bmatrix} 5 \\
                    -10
    \end{bmatrix}
    \end{equation*}

Next, let's consider the two equality constraints. Showing zero weights explicitly, these are:

.. math::
        2x_1 + 8x_2 + 1x_3 + 0x_4 &= 60\\
        4x_1 + 4x_2 + 0x_3 + 1x_4 &= 60\\

These equations can be converted to matrix form:

.. math::
    A_{eq} x = b_{eq}\\

where

.. math::
   :nowrap:

    \begin{equation*} A_{eq} =
    \begin{bmatrix} 2 & 8 & 1 & 0 \\
                    4 & 4 & 0 & 1
    \end{bmatrix}
    \end{equation*}

.. math::
   :nowrap:

    \begin{equation*} b_{eq} =
    \begin{bmatrix} 60 \\
                    60
    \end{bmatrix}
    \end{equation*}

Lastly, let's consider the separate inequality constraints on individual decision variables, which are known as
"box constraints" or "simple bounds". These constraints can be applied using the bounds argument of :func:`linprog`.
As noted in the :func:`linprog` documentation, the default value of bounds is ``(0, None)``, meaning that the
lower bound on each decision variable is 0, and the upper bound on each decision variable is infinity:
all the decision variables are non-negative. Our bounds are different, so we will need to specify the lower and upper bound on each
decision variable as a tuple and group these tuples into a list.


Finally, we can solve the transformed problem using :func:`linprog`.

::

    >>> import numpy as np
    >>> from scipy.optimize import linprog
    >>> c = np.array([-29.0, -45.0, 0.0, 0.0])
    >>> A_ub = np.array([[1.0, -1.0, -3.0, 0.0],
    ...                 [-2.0, 3.0, 7.0, -3.0]])
    >>> b_ub = np.array([5.0, -10.0])
    >>> A_eq = np.array([[2.0, 8.0, 1.0, 0.0],
    ...                 [4.0, 4.0, 0.0, 1.0]])
    >>> b_eq = np.array([60.0, 60.0])
    >>> x0_bounds = (0, None)
    >>> x1_bounds = (0, 5.0)
    >>> x2_bounds = (-np.inf, 0.5)  # +/- np.inf can be used instead of None
    >>> x3_bounds = (-3.0, None)
    >>> bounds = [x0_bounds, x1_bounds, x2_bounds, x3_bounds]
    >>> result = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)
    >>> print(result)
         con: array([15.5361242 , 16.61288005])  # may vary
         fun: -370.2321976308326  # may vary
     message: 'The algorithm terminated successfully and determined that the problem is infeasible.'
         nit: 6  # may vary
       slack: array([ 0.79314989, -1.76308532])  # may vary
      status: 2
     success: False
           x: array([ 6.60059391,  3.97366609, -0.52664076,  1.09007993])  # may vary

The result states that our problem is infeasible, meaning that there is no solution vector that satisfies all the
constraints. That doesn't necessarily mean we did anything wrong; some problems truly are infeasible.
Suppose, however, that we were to decide that our bound constraint on :math:`x_1` was too tight and that it could be loosened
to :math:`0 \leq x_1 \leq 6`. After adjusting our code ``x1_bounds = (0, 6)`` to reflect the change and executing it again:

::

    >>> x1_bounds = (0, 6)
    >>> bounds = [x0_bounds, x1_bounds, x2_bounds, x3_bounds]
    >>> result = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)
    >>> print(result)
        con: array([9.78840831e-09, 1.04662945e-08])  # may vary
        fun: -505.97435889013434  # may vary
    message: 'Optimization terminated successfully.'
        nit: 4  # may vary
      slack: array([ 6.52747190e-10, -2.26730279e-09])  # may vary
     status: 0
    success: True
          x: array([ 9.41025641,  5.17948718, -0.25641026,  1.64102564])  # may vary

The result shows the optimization was successful.
We can check the objective value (``result.fun``) is same as :math:`c^Tx`:

::

    >>> x = np.array(result.x)
    >>> print(c @ x)
    -505.97435889013434  # may vary

We can also check that all constraints are satisfied within reasonable tolerances:

::

    >>> print(b_ub - (A_ub @ x).flatten())  # this is equivalent to result.slack
    [ 6.52747190e-10, -2.26730279e-09]  # may vary
    >>> print(b_eq - (A_eq @ x).flatten())  # this is equivalent to result.con
    [ 9.78840831e-09, 1.04662945e-08]]  # may vary
    >>> print([0 <= result.x[0], 0 <= result.x[1] <= 6.0, result.x[2] <= 0.5, -3.0 <= result.x[3]])
    [True, True, True, True]

If we need greater accuracy, typically at the expense of speed, we can solve using the ``revised simplex`` method:

::

    >>> result = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='revised simplex')
    >>> print(result)
        con: array([0.00000000e+00, 7.10542736e-15])  # may vary
        fun: -505.97435897435895    # may vary
    message: 'Optimization terminated successfully.'
        nit: 5  # may vary
      slack: array([ 1.77635684e-15, -3.55271368e-15])  # may vary
     status: 0
    success: True
          x: array([ 9.41025641,  5.17948718, -0.25641026,  1.64102564])  # may vary

Assignment problems
-------------------

Linear sum assignment problem example
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Consider the problem of selecting students for a swimming medley relay team.
We have a table showing times for each swimming style of five students:

==========  ===========  ============  ===========  ===============================
 Student    backstroke   breaststroke  butterfly    freestyle
==========  ===========  ============  ===========  ===============================
 A          43.5           47.1         48.4        38.2
 B          45.5           42.1         49.6        36.8
 C          43.4           39.1         42.1        43.2
 D          46.5           44.1         44.5        41.2
 E          46.3           47.8         50.4        37.2
==========  ===========  ============  ===========  ===============================

We need to choose a student for each of the four swimming styles such that 
the total relay time is minimized.
This is a typical linear sum assignment problem. We can use :func:`linear_sum_assignment` to solve it.

The linear sum assignment problem is one of the most famous combinatorial optimization problems.
Given a "cost matrix" :math:`C`, the problem is to choose

- exactly one element from each row 
- without choosing more than one element from any column 
- such that the sum of the chosen elements is minimized

In other words, we need to assign each row to one column such that the sum of 
the corresponding entries is minimized.

Formally, let :math:`X` be a boolean matrix where :math:`X[i,j] = 1` iff row  :math:`i` is assigned to column :math:`j`.
Then the optimal assignment has cost

.. math::

    \min \sum_i \sum_j C_{i,j} X_{i,j}

The first step is to define the cost matrix.
In this example, we want to assign each swimming style to a student.
:func:`linear_sum_assignment` is able to assign each row of a cost matrix to a column.
Therefore, to form the cost matrix, the table above needs to be transposed so that the rows
correspond with swimming styles and the columns correspond with students:

::

    >>> import numpy as np
    >>> cost = np.array([[43.5, 45.5, 43.4, 46.5, 46.3],
    ...                  [47.1, 42.1, 39.1, 44.1, 47.8],
    ...                  [48.4, 49.6, 42.1, 44.5, 50.4],
    ...                  [38.2, 36.8, 43.2, 41.2, 37.2]])

We can solve the assignment problem with :func:`linear_sum_assignment`:

::

    >>> from scipy.optimize import linear_sum_assignment
    >>> row_ind, col_ind = linear_sum_assignment(cost)

The ``row_ind`` and ``col_ind`` are optimal assigned matrix indexes of the cost matrix:

::

    >>> row_ind
    array([0, 1, 2, 3])
    >>> col_ind
    array([0, 2, 3, 1])

The optimal assignment is:

::

    >>> styles = np.array(["backstroke", "breaststroke", "butterfly", "freestyle"])[row_ind]
    >>> students = np.array(["A", "B", "C", "D", "E"])[col_ind]
    >>> dict(zip(styles, students))
    {'backstroke': 'A', 'breaststroke': 'C', 'butterfly': 'D', 'freestyle': 'B'}

The optimal total medley time is:

::

    >>> cost[row_ind, col_ind].sum()
    163.89999999999998

Note that this result is not the same as the sum of the minimum times for each swimming style:

::

    >>> np.min(cost, axis=1).sum()
    161.39999999999998

because student "C" is the best swimmer in both "breaststroke" and "butterfly" style.
We cannot assign student "C" to both styles, so we assigned student C to the "breaststroke" style
and D to the "butterfly" style to minimize the total time.

.. rubric:: References

Some further reading and related software, such as Newton-Krylov [KK]_,
PETSc [PP]_, and PyAMG [AMG]_:

.. [KK] D.A. Knoll and D.E. Keyes, "Jacobian-free Newton-Krylov methods",
        J. Comp. Phys. 193, 357 (2004). :doi:`10.1016/j.jcp.2003.08.010`

.. [PP] PETSc https://www.mcs.anl.gov/petsc/ and its Python bindings
        https://bitbucket.org/petsc/petsc4py/

.. [AMG] PyAMG (algebraic multigrid preconditioners/solvers)
         https://github.com/pyamg/pyamg/issues
Statistics (`scipy.stats`)
==========================

.. sectionauthor:: Travis E. Oliphant
.. sectionauthor:: Josef Perktold
.. sectionauthor:: Nicky van Foreest
.. sectionauthor:: Sambit Panda
.. sectionauthor:: Pamphile T. Roy (@tupui)

.. currentmodule:: scipy

Introduction
------------

In this tutorial, we discuss many, but certainly not all, features of
``scipy.stats``. The intention here is to provide a user with a
working knowledge of this package. We refer to the
:ref:`reference manual <statsrefmanual>` for further details.

Note: This documentation is work in progress.

.. toctree::
   :maxdepth: 1

   stats/discrete
   stats/continuous
   stats/sampling


Random variables
----------------

There are two general distribution classes that have been implemented
for encapsulating :ref:`continuous random variables
<continuous-random-variables>` and :ref:`discrete random variables
<discrete-random-variables>`. Over 80 continuous random variables
(RVs) and 10 discrete random variables have been implemented using
these classes. Besides this, new routines and distributions can be
easily added by the end user. (If you create one, please contribute it.)

All of the statistics functions are located in the sub-package
:mod:`scipy.stats` and a fairly complete listing of these functions
can be obtained using ``info(stats)``. The list of the random
variables available can also be obtained from the docstring for the
stats sub-package.

In the discussion below, we mostly focus on continuous RVs. Nearly everything
also applies to discrete variables, but we point out some differences
here: :ref:`discrete_points_label`.

In the code samples below, we assume that the :mod:`scipy.stats` package
is imported as

    >>> from scipy import stats

and in some cases we assume that individual objects are imported as

    >>> from scipy.stats import norm

Getting help
^^^^^^^^^^^^

First of all, all distributions are accompanied with help
functions. To obtain just some basic information, we print the relevant
docstring: ``print(stats.norm.__doc__)``.

To find the support, i.e., upper and lower bounds of the distribution,
call:

    >>> print('bounds of distribution lower: %s, upper: %s' % norm.support())
    bounds of distribution lower: -inf, upper: inf

We can list all methods and properties of the distribution with
``dir(norm)``. As it turns out, some of the methods are private,
although they are not named as such (their names do not start
with a leading underscore), for example ``veccdf``, are only available
for internal calculation (those methods will give warnings when one tries to
use them, and will be removed at some point).

To obtain the *real* main methods, we list the methods of the frozen
distribution. (We explain the meaning of a `frozen` distribution
below).

    >>> rv = norm()
    >>> dir(rv)  # reformatted
    ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__',
     '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__',
     '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__',
     '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__',
     '__str__', '__subclasshook__', '__weakref__', 'a', 'args', 'b', 'cdf',
     'dist', 'entropy', 'expect', 'interval', 'isf', 'kwds', 'logcdf',
     'logpdf', 'logpmf', 'logsf', 'mean', 'median', 'moment', 'pdf', 'pmf',
     'ppf', 'random_state', 'rvs', 'sf', 'stats', 'std', 'var']

Finally, we can obtain the list of available distribution through
introspection:

    >>> dist_continu = [d for d in dir(stats) if
    ...                 isinstance(getattr(stats, d), stats.rv_continuous)]
    >>> dist_discrete = [d for d in dir(stats) if
    ...                  isinstance(getattr(stats, d), stats.rv_discrete)]
    >>> print('number of continuous distributions: %d' % len(dist_continu))
    number of continuous distributions: 104
    >>> print('number of discrete distributions:   %d' % len(dist_discrete))
    number of discrete distributions:   19

Common methods
^^^^^^^^^^^^^^

The main public methods for continuous  RVs are:

* rvs:   Random Variates
* pdf:   Probability Density Function
* cdf:   Cumulative Distribution Function
* sf:    Survival Function (1-CDF)
* ppf:   Percent Point Function (Inverse of CDF)
* isf:   Inverse Survival Function (Inverse of SF)
* stats: Return mean, variance, (Fisher's) skew, or (Fisher's) kurtosis
* moment: non-central moments of the distribution


Let's take a normal RV as an example.

    >>> norm.cdf(0)
    0.5

To compute the ``cdf`` at a number of points, we can pass a list or a numpy array.

    >>> norm.cdf([-1., 0, 1])
    array([ 0.15865525,  0.5,  0.84134475])
    >>> import numpy as np
    >>> norm.cdf(np.array([-1., 0, 1]))
    array([ 0.15865525,  0.5,  0.84134475])

Thus, the basic methods, such as `pdf`, `cdf`, and so on, are vectorized.

Other generally useful methods are supported too:

    >>> norm.mean(), norm.std(), norm.var()
    (0.0, 1.0, 1.0)
    >>> norm.stats(moments="mv")
    (array(0.0), array(1.0))

To find the median of a distribution, we can use the percent point
function ``ppf``, which is the inverse of the ``cdf``:

    >>> norm.ppf(0.5)
    0.0

To generate a sequence of random variates, use the ``size`` keyword
argument:

    >>> norm.rvs(size=3)
    array([-0.35687759,  1.34347647, -0.11710531])   # random

Don't think that ``norm.rvs(5)`` generates 5 variates:

    >>> norm.rvs(5)
    5.471435163732493  # random

Here, ``5`` with no keyword is being interpreted as the first possible
keyword argument, ``loc``, which is the first of a pair of keyword arguments
taken by all continuous distributions.
This brings us to the topic of the next subsection.

Random number generation
^^^^^^^^^^^^^^^^^^^^^^^^

Drawing random numbers relies on generators from `numpy.random` package.
In the examples above, the specific stream of
random numbers is not reproducible across runs. To achieve reproducibility,
you can explicitly *seed* a random number generator. In NumPy, a generator
is an instance of `numpy.random.Generator`. Here is the canonical way to create
a generator:

    >>> from numpy.random import default_rng
    >>> rng = default_rng()

And fixing the seed can be done like this:

    >>> # do NOT copy this value
    >>> rng = default_rng(301439351238479871608357552876690613766)

.. warning:: Do not use this number or common values such as 0. Using just a
             small set of seeds to instantiate larger state spaces means that
             there are some initial states that are impossible to reach. This
             creates some biases if everyone uses such values. A good way to
             get a seed is to use a `numpy.random.SeedSequence`:

             >>> from numpy.random import SeedSequence
             >>> print(SeedSequence().entropy)
             301439351238479871608357552876690613766  # random

The `random_state` parameter in distributions accepts an instance of
`numpy.random.Generator` class, or an integer, which is then used to
seed an internal ``Generator`` object:

    >>> norm.rvs(size=5, random_state=rng)
    array([ 0.47143516, -1.19097569,  1.43270697, -0.3126519 , -0.72058873])  # random

For further info, see `NumPy's documentation
<https://numpy.org/doc/stable/reference/random/index.html>`__.

To learn more about the random number samplers implemented in SciPy, see
:ref:`non-uniform random number sampling tutorial
<non-uniform-random-number-sampling>` and :ref:`quasi monte carlo tutorial
<quasi-monte-carlo>`

Shifting and scaling
^^^^^^^^^^^^^^^^^^^^

All continuous distributions take ``loc`` and ``scale`` as keyword
parameters to adjust the location and scale of the distribution,
e.g., for the standard normal distribution, the location is the mean and
the scale is the standard deviation.

    >>> norm.stats(loc=3, scale=4, moments="mv")
    (array(3.0), array(16.0))

In many cases, the standardized distribution for a random variable ``X``
is obtained through the transformation ``(X - loc) / scale``. The
default values are ``loc = 0`` and ``scale = 1``.

Smart use of ``loc`` and ``scale`` can help modify the standard
distributions in many ways. To illustrate the scaling further, the
``cdf`` of an exponentially distributed RV with mean :math:`1/\lambda`
is given by

.. math::

    F(x) = 1 - \exp(-\lambda x)

By applying the scaling rule above, it can be seen that by
taking ``scale  = 1./lambda`` we get the proper scale.

    >>> from scipy.stats import expon
    >>> expon.mean(scale=3.)
    3.0

.. note:: Distributions that take shape parameters may
   require more than simple application of ``loc`` and/or
   ``scale`` to achieve the desired form. For example, the
   distribution of 2-D vector lengths given a constant vector
   of length :math:`R` perturbed by independent N(0, :math:`\sigma^2`)
   deviations in each component is
   rice(:math:`R/\sigma`, scale= :math:`\sigma`). The first argument
   is a shape parameter that needs to be scaled along with :math:`x`.

The uniform distribution is also interesting:

    >>> from scipy.stats import uniform
    >>> uniform.cdf([0, 1, 2, 3, 4, 5], loc=1, scale=4)
    array([ 0.  ,  0.  ,  0.25,  0.5 ,  0.75,  1.  ])


Finally, recall from the previous paragraph that we are left with the
problem of the meaning of ``norm.rvs(5)``. As it turns out, calling a
distribution like this, the first argument, i.e., the 5, gets passed
to set the ``loc`` parameter. Let's see:

    >>> np.mean(norm.rvs(5, size=500))
    5.0098355106969992  # random

Thus, to explain the output of the example of the last section:
``norm.rvs(5)`` generates a single normally distributed random variate with
mean ``loc=5``, because of the default ``size=1``.

We recommend that you set ``loc`` and ``scale`` parameters explicitly, by
passing the values as keywords rather than as arguments. Repetition
can be minimized when calling more than one method of a given RV by
using the technique of `Freezing a Distribution`_, as explained below.


Shape parameters
^^^^^^^^^^^^^^^^

While a general continuous random variable can be shifted and scaled
with the ``loc`` and ``scale`` parameters, some distributions require
additional shape parameters. For instance, the gamma distribution with density

.. math::

    \gamma(x, a) = \frac{\lambda (\lambda x)^{a-1}}{\Gamma(a)} e^{-\lambda x}\;,

requires the shape parameter :math:`a`. Observe that setting
:math:`\lambda` can be obtained by setting the ``scale`` keyword to
:math:`1/\lambda`.

Let's check the number and name of the shape parameters of the gamma
distribution. (We know from the above that this should be 1.)

    >>> from scipy.stats import gamma
    >>> gamma.numargs
    1
    >>> gamma.shapes
    'a'

Now, we set the value of the shape variable to 1 to obtain the
exponential distribution, so that we compare easily whether we get the
results we expect.

    >>> gamma(1, scale=2.).stats(moments="mv")
    (array(2.0), array(4.0))

Notice that we can also specify shape parameters as keywords:

   >>> gamma(a=1, scale=2.).stats(moments="mv")
   (array(2.0), array(4.0))


Freezing a distribution
^^^^^^^^^^^^^^^^^^^^^^^

Passing the ``loc`` and ``scale`` keywords time and again can become
quite bothersome. The concept of `freezing` a RV is used to
solve such problems.

    >>> rv = gamma(1, scale=2.)

By using ``rv`` we no longer have to include the scale or the shape
parameters anymore. Thus, distributions can be used in one of two
ways, either by passing all distribution parameters to each method
call (such as we did earlier) or by freezing the parameters for the
instance of the distribution. Let us check this:

    >>> rv.mean(), rv.std()
    (2.0, 2.0)

This is, indeed, what we should get.


Broadcasting
^^^^^^^^^^^^

The basic methods ``pdf``, and so on, satisfy the usual numpy broadcasting rules. For
example, we can calculate the critical values for the upper tail of
the t distribution for different probabilities and degrees of freedom.

    >>> stats.t.isf([0.1, 0.05, 0.01], [[10], [11]])
    array([[ 1.37218364,  1.81246112,  2.76376946],
           [ 1.36343032,  1.79588482,  2.71807918]])

Here, the first row contains the critical values for 10 degrees of freedom
and the second row for 11 degrees of freedom (d.o.f.). Thus, the
broadcasting rules give the same result of calling ``isf`` twice:

    >>> stats.t.isf([0.1, 0.05, 0.01], 10)
    array([ 1.37218364,  1.81246112,  2.76376946])
    >>> stats.t.isf([0.1, 0.05, 0.01], 11)
    array([ 1.36343032,  1.79588482,  2.71807918])

If the array with probabilities, i.e., ``[0.1, 0.05, 0.01]`` and the
array of degrees of freedom i.e., ``[10, 11, 12]``, have the same
array shape, then element-wise matching is used. As an example, we can
obtain the 10% tail for 10 d.o.f., the 5% tail for 11 d.o.f. and the
1% tail for 12 d.o.f. by calling

    >>> stats.t.isf([0.1, 0.05, 0.01], [10, 11, 12])
    array([ 1.37218364,  1.79588482,  2.68099799])


.. _discrete_points_label:

Specific points for discrete distributions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Discrete distributions have mostly the same basic methods as the
continuous distributions. However ``pdf`` is replaced by the probability
mass function ``pmf``, no estimation methods, such as fit, are
available, and ``scale`` is not a valid keyword parameter. The
location parameter, keyword ``loc``, can still be used to shift the
distribution.

The computation of the cdf requires some extra attention. In the case
of continuous distribution, the cumulative distribution function is, in
most standard cases, strictly monotonic increasing in the bounds (a,b)
and has, therefore, a unique inverse. The cdf of a discrete
distribution, however, is a step function, hence the inverse cdf,
i.e., the percent point function, requires a different definition:

::

    ppf(q) = min{x : cdf(x) >= q, x integer}

For further info, see the docs `here
<https://docs.scipy.org/doc/scipy/reference/tutorial/stats/discrete.html#percent-point-function-inverse-cdf>`__.


We can look at the hypergeometric distribution as an example

    >>> from scipy.stats import hypergeom
    >>> [M, n, N] = [20, 7, 12]

If we use the cdf at some integer points and then evaluate the ppf at those
cdf values, we get the initial integers back, for example

    >>> x = np.arange(4) * 2
    >>> x
    array([0, 2, 4, 6])
    >>> prb = hypergeom.cdf(x, M, n, N)
    >>> prb
    array([  1.03199174e-04,   5.21155831e-02,   6.08359133e-01,
             9.89783282e-01])
    >>> hypergeom.ppf(prb, M, n, N)
    array([ 0.,  2.,  4.,  6.])

If we use values that are not at the kinks of the cdf step function, we get
the next higher integer back:

    >>> hypergeom.ppf(prb + 1e-8, M, n, N)
    array([ 1.,  3.,  5.,  7.])
    >>> hypergeom.ppf(prb - 1e-8, M, n, N)
    array([ 0.,  2.,  4.,  6.])


Fitting distributions
^^^^^^^^^^^^^^^^^^^^^

The main additional methods of the not frozen distribution are related
to the estimation of distribution parameters:

* fit:   maximum likelihood estimation of distribution parameters, including location
         and scale
* fit_loc_scale: estimation of location and scale when shape parameters are given
* nnlf:  negative log likelihood function
* expect: calculate the expectation of a function against the pdf or pmf


.. _performance_issues_label:

Performance issues and cautionary remarks
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The performance of the individual methods, in terms of speed, varies
widely by distribution and method. The results of a method are
obtained in one of two ways: either by explicit calculation, or by a
generic algorithm that is independent of the specific distribution.

Explicit calculation, on the one hand, requires that the method is
directly specified for the given distribution, either through analytic
formulas or through special functions in ``scipy.special`` or
``numpy.random`` for ``rvs``. These are usually relatively fast
calculations.

The generic methods, on the other hand, are used if the distribution
does not specify any explicit calculation. To define a distribution,
only one of pdf or cdf is necessary; all other methods can be derived
using numeric integration and root finding. However, these indirect
methods can be `very` slow. As an example, ``rgh =
stats.gausshyper.rvs(0.5, 2, 2, 2, size=100)`` creates random
variables in a very indirect way and takes about 19 seconds for 100
random variables on my computer, while one million random variables
from the standard normal or from the t distribution take just above
one second.


Remaining issues
^^^^^^^^^^^^^^^^

The distributions in ``scipy.stats`` have recently been corrected and improved
and gained a considerable test suite; however, a few issues remain:

* The distributions have been tested over some range of parameters;
  however, in some corner ranges, a few incorrect results may remain.
* The maximum likelihood estimation in `fit` does not work with
  default starting parameters for all distributions and the user
  needs to supply good starting parameters. Also, for some
  distribution using a maximum likelihood estimator might
  inherently not be the best choice.


Building specific distributions
-------------------------------

The next examples shows how to build your own distributions. Further
examples show the usage of the distributions and some statistical
tests.


Making a continuous distribution, i.e., subclassing ``rv_continuous``
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Making continuous distributions is fairly simple.

    >>> from scipy import stats
    >>> class deterministic_gen(stats.rv_continuous):
    ...     def _cdf(self, x):
    ...         return np.where(x < 0, 0., 1.)
    ...     def _stats(self):
    ...         return 0., 0., 0., 0.

    >>> deterministic = deterministic_gen(name="deterministic")
    >>> deterministic.cdf(np.arange(-3, 3, 0.5))
    array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.])

Interestingly,  the ``pdf`` is now computed automatically:

    >>> deterministic.pdf(np.arange(-3, 3, 0.5))
    array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
             0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
             5.83333333e+04,   4.16333634e-12,   4.16333634e-12,
             4.16333634e-12,   4.16333634e-12,   4.16333634e-12])


Be aware of the performance issues mentioned in
:ref:`performance_issues_label`. The computation of unspecified
common methods can become very slow, since only general methods are
called, which, by their very nature, cannot use any specific
information about the distribution. Thus, as a cautionary example:

    >>> from scipy.integrate import quad
    >>> quad(deterministic.pdf, -1e-1, 1e-1)
    (4.163336342344337e-13, 0.0)

But this is not correct: the integral over this pdf should be 1. Let's make the
integration interval smaller:

    >>> quad(deterministic.pdf, -1e-3, 1e-3)  # warning removed
    (1.000076872229173, 0.0010625571718182458)

This looks better. However, the problem originated from the fact that
the pdf is not specified in the class definition of the deterministic
distribution.


Subclassing ``rv_discrete``
^^^^^^^^^^^^^^^^^^^^^^^^^^^

In the following, we use `stats.rv_discrete` to generate a discrete
distribution that has the probabilities of the truncated normal for the
intervals centered around the integers.

**General info**

From the docstring of rv_discrete, ``help(stats.rv_discrete)``,

  "You can construct an arbitrary discrete rv where P{X=xk} = pk by
  passing to the rv_discrete initialization method (through the values=
  keyword) a tuple of sequences (xk, pk) which describes only those
  values of X (xk) that occur with nonzero probability (pk)."

Next to this, there are some further requirements for this approach to
work:

* The keyword `name` is required.
* The support points of the distribution xk have to be integers.
* The number of significant digits (decimals) needs to be specified.

In fact, if the last two requirements are not satisfied, an exception
may be raised or the resulting numbers may be incorrect.

**An example**

Let's do the work. First:

    >>> npoints = 20   # number of integer support points of the distribution minus 1
    >>> npointsh = npoints // 2
    >>> npointsf = float(npoints)
    >>> nbound = 4   # bounds for the truncated normal
    >>> normbound = (1+1/npointsf) * nbound   # actual bounds of truncated normal
    >>> grid = np.arange(-npointsh, npointsh+2, 1)   # integer grid
    >>> gridlimitsnorm = (grid-0.5) / npointsh * nbound   # bin limits for the truncnorm
    >>> gridlimits = grid - 0.5   # used later in the analysis
    >>> grid = grid[:-1]
    >>> probs = np.diff(stats.truncnorm.cdf(gridlimitsnorm, -normbound, normbound))
    >>> gridint = grid

And, finally, we can subclass ``rv_discrete``:

    >>> normdiscrete = stats.rv_discrete(values=(gridint,
    ...              np.round(probs, decimals=7)), name='normdiscrete')

Now that we have defined the distribution, we have access to all
common methods of discrete distributions.

    >>> print('mean = %6.4f, variance = %6.4f, skew = %6.4f, kurtosis = %6.4f' %
    ...       normdiscrete.stats(moments='mvsk'))
    mean = -0.0000, variance = 6.3302, skew = 0.0000, kurtosis = -0.0076

    >>> nd_std = np.sqrt(normdiscrete.stats(moments='v'))

**Testing the implementation**

Let's generate a random sample and compare observed frequencies with
the probabilities.

    >>> n_sample = 500
    >>> rvs = normdiscrete.rvs(size=n_sample)
    >>> f, l = np.histogram(rvs, bins=gridlimits)
    >>> sfreq = np.vstack([gridint, f, probs*n_sample]).T
    >>> print(sfreq)
    [[-1.00000000e+01  0.00000000e+00  2.95019349e-02]  # random
     [-9.00000000e+00  0.00000000e+00  1.32294142e-01]
     [-8.00000000e+00  0.00000000e+00  5.06497902e-01]
     [-7.00000000e+00  2.00000000e+00  1.65568919e+00]
     [-6.00000000e+00  1.00000000e+00  4.62125309e+00]
     [-5.00000000e+00  9.00000000e+00  1.10137298e+01]
     [-4.00000000e+00  2.60000000e+01  2.24137683e+01]
     [-3.00000000e+00  3.70000000e+01  3.89503370e+01]
     [-2.00000000e+00  5.10000000e+01  5.78004747e+01]
     [-1.00000000e+00  7.10000000e+01  7.32455414e+01]
     [ 0.00000000e+00  7.40000000e+01  7.92618251e+01]
     [ 1.00000000e+00  8.90000000e+01  7.32455414e+01]
     [ 2.00000000e+00  5.50000000e+01  5.78004747e+01]
     [ 3.00000000e+00  5.00000000e+01  3.89503370e+01]
     [ 4.00000000e+00  1.70000000e+01  2.24137683e+01]
     [ 5.00000000e+00  1.10000000e+01  1.10137298e+01]
     [ 6.00000000e+00  4.00000000e+00  4.62125309e+00]
     [ 7.00000000e+00  3.00000000e+00  1.65568919e+00]
     [ 8.00000000e+00  0.00000000e+00  5.06497902e-01]
     [ 9.00000000e+00  0.00000000e+00  1.32294142e-01]
     [ 1.00000000e+01  0.00000000e+00  2.95019349e-02]]


.. plot:: tutorial/examples/normdiscr_plot1.py
   :align: center
   :include-source: 0


.. plot:: tutorial/examples/normdiscr_plot2.py
   :align: center
   :include-source: 0


Next, we can test whether our sample was generated by our norm-discrete
distribution. This also verifies whether the random numbers were generated
correctly.

The chisquare test requires that there are a minimum number of observations
in each bin. We combine the tail bins into larger bins so that they contain
enough observations.

    >>> f2 = np.hstack([f[:5].sum(), f[5:-5], f[-5:].sum()])
    >>> p2 = np.hstack([probs[:5].sum(), probs[5:-5], probs[-5:].sum()])
    >>> ch2, pval = stats.chisquare(f2, p2*n_sample)

    >>> print('chisquare for normdiscrete: chi2 = %6.3f pvalue = %6.4f' % (ch2, pval))
    chisquare for normdiscrete: chi2 = 12.466 pvalue = 0.4090  # random

The pvalue in this case is high, so we can be quite confident that
our random sample was actually generated by the distribution.


Analysing one sample
--------------------

First, we create some random variables. We set a seed so that in each run
we get identical results to look at. As an example we take a sample from
the Student t distribution:

    >>> x = stats.t.rvs(10, size=1000)

Here, we set the required shape parameter of the t distribution, which
in statistics corresponds to the degrees of freedom, to 10. Using size=1000 means
that our sample consists of 1000 independently drawn (pseudo) random numbers.
Since we did not specify the keyword arguments `loc` and `scale`, those are
set to their default values zero and one.

Descriptive statistics
^^^^^^^^^^^^^^^^^^^^^^

`x` is a numpy array, and we have direct access to all array methods, e.g.,

    >>> print(x.min())   # equivalent to np.min(x)
    -3.78975572422  # random
    >>> print(x.max())   # equivalent to np.max(x)
    5.26327732981  # random
    >>> print(x.mean())  # equivalent to np.mean(x)
    0.0140610663985  # random
    >>> print(x.var())   # equivalent to np.var(x))
    1.28899386208  # random

How do the sample properties compare to their theoretical counterparts?

    >>> m, v, s, k = stats.t.stats(10, moments='mvsk')
    >>> n, (smin, smax), sm, sv, ss, sk = stats.describe(x)

    >>> sstr = '%-14s mean = %6.4f, variance = %6.4f, skew = %6.4f, kurtosis = %6.4f'
    >>> print(sstr % ('distribution:', m, v, s ,k))
    distribution:  mean = 0.0000, variance = 1.2500, skew = 0.0000, kurtosis = 1.0000  # random
    >>> print(sstr % ('sample:', sm, sv, ss, sk))
    sample:        mean = 0.0141, variance = 1.2903, skew = 0.2165, kurtosis = 1.0556  # random

Note: `stats.describe` uses the unbiased estimator for the variance, while
np.var is the biased estimator.


For our sample the sample statistics differ a by a small amount from
their theoretical counterparts.


T-test and KS-test
^^^^^^^^^^^^^^^^^^

We can use the t-test to test whether the mean of our sample differs
in a statistically significant way from the theoretical expectation.

    >>> print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(x, m))
    t-statistic =  0.391 pvalue = 0.6955  # random

The pvalue is 0.7, this means that with an alpha error of, for
example, 10%, we cannot reject the hypothesis that the sample mean
is equal to zero, the expectation of the standard t-distribution.


As an exercise, we can calculate our ttest also directly without
using the provided function, which should give us the same answer,
and so it does:

    >>> tt = (sm-m)/np.sqrt(sv/float(n))  # t-statistic for mean
    >>> pval = stats.t.sf(np.abs(tt), n-1)*2  # two-sided pvalue = Prob(abs(t)>tt)
    >>> print('t-statistic = %6.3f pvalue = %6.4f' % (tt, pval))
    t-statistic =  0.391 pvalue = 0.6955  # random

The Kolmogorov-Smirnov test can be used to test the hypothesis that
the sample comes from the standard t-distribution

    >>> print('KS-statistic D = %6.3f pvalue = %6.4f' % stats.kstest(x, 't', (10,)))
    KS-statistic D =  0.016 pvalue = 0.9571  # random

Again, the p-value is high enough that we cannot reject the
hypothesis that the random sample really is distributed according to the
t-distribution. In real applications, we don't know what the
underlying distribution is. If we perform the Kolmogorov-Smirnov
test of our sample against the standard normal distribution, then we
also cannot reject the hypothesis that our sample was generated by the
normal distribution given that, in this example, the p-value is almost 40%.

    >>> print('KS-statistic D = %6.3f pvalue = %6.4f' % stats.kstest(x, 'norm'))
    KS-statistic D =  0.028 pvalue = 0.3918  # random

However, the standard normal distribution has a variance of 1, while our
sample has a variance of 1.29. If we standardize our sample and test it
against the normal distribution, then the p-value is again large enough
that we cannot reject the hypothesis that the sample came form the
normal distribution.

    >>> d, pval = stats.kstest((x-x.mean())/x.std(), 'norm')
    >>> print('KS-statistic D = %6.3f pvalue = %6.4f' % (d, pval))
    KS-statistic D =  0.032 pvalue = 0.2397  # random

Note: The Kolmogorov-Smirnov test assumes that we test against a
distribution with given parameters, since, in the last case, we
estimated mean and variance, this assumption is violated and the
distribution of the test statistic, on which the p-value is based, is
not correct.

Tails of the distribution
^^^^^^^^^^^^^^^^^^^^^^^^^

Finally, we can check the upper tail of the distribution. We can use
the percent point function ppf, which is the inverse of the cdf
function, to obtain the critical values, or, more directly, we can use
the inverse of the survival function

    >>> crit01, crit05, crit10 = stats.t.ppf([1-0.01, 1-0.05, 1-0.10], 10)
    >>> print('critical values from ppf at 1%%, 5%% and 10%% %8.4f %8.4f %8.4f' % (crit01, crit05, crit10))
    critical values from ppf at 1%, 5% and 10%   2.7638   1.8125   1.3722
    >>> print('critical values from isf at 1%%, 5%% and 10%% %8.4f %8.4f %8.4f' % tuple(stats.t.isf([0.01,0.05,0.10],10)))
    critical values from isf at 1%, 5% and 10%   2.7638   1.8125   1.3722

    >>> freq01 = np.sum(x>crit01) / float(n) * 100
    >>> freq05 = np.sum(x>crit05) / float(n) * 100
    >>> freq10 = np.sum(x>crit10) / float(n) * 100
    >>> print('sample %%-frequency at 1%%, 5%% and 10%% tail %8.4f %8.4f %8.4f' % (freq01, freq05, freq10))
    sample %-frequency at 1%, 5% and 10% tail   1.4000   5.8000  10.5000  # random

In all three cases, our sample has more weight in the top tail than the
underlying distribution.
We can briefly check a larger sample to see if we get a closer match. In this
case, the empirical frequency is quite close to the theoretical probability,
but if we repeat this several times, the fluctuations are still pretty large.

    >>> freq05l = np.sum(stats.t.rvs(10, size=10000) > crit05) / 10000.0 * 100
    >>> print('larger sample %%-frequency at 5%% tail %8.4f' % freq05l)
    larger sample %-frequency at 5% tail   4.8000  # random

We can also compare it with the tail of the normal distribution, which
has less weight in the tails:

    >>> print('tail prob. of normal at 1%%, 5%% and 10%% %8.4f %8.4f %8.4f' %
    ...       tuple(stats.norm.sf([crit01, crit05, crit10])*100))
    tail prob. of normal at 1%, 5% and 10%   0.2857   3.4957   8.5003

The chisquare test can be used to test whether for a finite number of bins,
the observed frequencies differ significantly from the probabilities of the
hypothesized distribution.

    >>> quantiles = [0.0, 0.01, 0.05, 0.1, 1-0.10, 1-0.05, 1-0.01, 1.0]
    >>> crit = stats.t.ppf(quantiles, 10)
    >>> crit
    array([       -inf, -2.76376946, -1.81246112, -1.37218364,  1.37218364,
            1.81246112,  2.76376946,         inf])
    >>> n_sample = x.size
    >>> freqcount = np.histogram(x, bins=crit)[0]
    >>> tprob = np.diff(quantiles)
    >>> nprob = np.diff(stats.norm.cdf(crit))
    >>> tch, tpval = stats.chisquare(freqcount, tprob*n_sample)
    >>> nch, npval = stats.chisquare(freqcount, nprob*n_sample)
    >>> print('chisquare for t:      chi2 = %6.2f pvalue = %6.4f' % (tch, tpval))
    chisquare for t:      chi2 =  2.30 pvalue = 0.8901  # random
    >>> print('chisquare for normal: chi2 = %6.2f pvalue = %6.4f' % (nch, npval))
    chisquare for normal: chi2 = 64.60 pvalue = 0.0000  # random

We see that the standard normal distribution is clearly rejected, while the
standard t-distribution cannot be rejected. Since the variance of our sample
differs from both standard distributions, we can again redo the test taking
the estimate for scale and location into account.

The fit method of the distributions can be used to estimate the parameters
of the distribution, and the test is repeated using probabilities of the
estimated distribution.

    >>> tdof, tloc, tscale = stats.t.fit(x)
    >>> nloc, nscale = stats.norm.fit(x)
    >>> tprob = np.diff(stats.t.cdf(crit, tdof, loc=tloc, scale=tscale))
    >>> nprob = np.diff(stats.norm.cdf(crit, loc=nloc, scale=nscale))
    >>> tch, tpval = stats.chisquare(freqcount, tprob*n_sample)
    >>> nch, npval = stats.chisquare(freqcount, nprob*n_sample)
    >>> print('chisquare for t:      chi2 = %6.2f pvalue = %6.4f' % (tch, tpval))
    chisquare for t:      chi2 =  1.58 pvalue = 0.9542  # random
    >>> print('chisquare for normal: chi2 = %6.2f pvalue = %6.4f' % (nch, npval))
    chisquare for normal: chi2 = 11.08 pvalue = 0.0858  # random

Taking account of the estimated parameters, we can still reject the
hypothesis that our sample came from a normal distribution (at the 5% level),
but again, with a p-value of 0.95, we cannot reject the t-distribution.


Special tests for normal distributions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Since the normal distribution is the most common distribution in statistics,
there are several additional functions available to test whether a sample
could have been drawn from a normal distribution.

First, we can test if skew and kurtosis of our sample differ significantly from
those of a normal distribution:

    >>> print('normal skewtest teststat = %6.3f pvalue = %6.4f' % stats.skewtest(x))
    normal skewtest teststat =  2.785 pvalue = 0.0054  # random
    >>> print('normal kurtosistest teststat = %6.3f pvalue = %6.4f' % stats.kurtosistest(x))
    normal kurtosistest teststat =  4.757 pvalue = 0.0000  # random

These two tests are combined in the normality test

    >>> print('normaltest teststat = %6.3f pvalue = %6.4f' % stats.normaltest(x))
    normaltest teststat = 30.379 pvalue = 0.0000  # random

In all three tests, the p-values are very low and we can reject the hypothesis
that the our sample has skew and kurtosis of the normal distribution.

Since skew and kurtosis of our sample are based on central moments, we get
exactly the same results if we test the standardized sample:

    >>> print('normaltest teststat = %6.3f pvalue = %6.4f' %
    ...       stats.normaltest((x-x.mean())/x.std()))
    normaltest teststat = 30.379 pvalue = 0.0000  # random

Because normality is rejected so strongly, we can check whether the
normaltest gives reasonable results for other cases:

    >>> print('normaltest teststat = %6.3f pvalue = %6.4f' %
    ...       stats.normaltest(stats.t.rvs(10, size=100)))
    normaltest teststat =  4.698 pvalue = 0.0955  # random
    >>> print('normaltest teststat = %6.3f pvalue = %6.4f' %
    ...              stats.normaltest(stats.norm.rvs(size=1000)))
    normaltest teststat =  0.613 pvalue = 0.7361  # random

When testing for normality of a small sample of t-distributed observations
and a large sample of normal-distributed observations, then in neither case
can we reject the null hypothesis that the sample comes from a normal
distribution. In the first case, this is because the test is not powerful
enough to distinguish a t and a normally distributed random variable in a
small sample.


Comparing two samples
---------------------

In the following, we are given two samples, which can come either from the
same or from different distribution, and we want to test whether these
samples have the same statistical properties.


Comparing means
^^^^^^^^^^^^^^^

Test with sample with identical means:

    >>> rvs1 = stats.norm.rvs(loc=5, scale=10, size=500)
    >>> rvs2 = stats.norm.rvs(loc=5, scale=10, size=500)
    >>> stats.ttest_ind(rvs1, rvs2)
    Ttest_indResult(statistic=-0.5489036175088705, pvalue=0.5831943748663959)  # random

Test with sample with different means:

    >>> rvs3 = stats.norm.rvs(loc=8, scale=10, size=500)
    >>> stats.ttest_ind(rvs1, rvs3)
    Ttest_indResult(statistic=-4.533414290175026, pvalue=6.507128186389019e-06)  # random

Kolmogorov-Smirnov test for two samples ks_2samp
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For the example, where both samples are drawn from the same distribution,
we cannot reject the null hypothesis, since the pvalue is high

    >>> stats.ks_2samp(rvs1, rvs2)
    KstestResult(statistic=0.026, pvalue=0.9959527565364388)  # random

In the second example, with different location, i.e., means, we can
reject the null hypothesis, since the pvalue is below 1%

    >>> stats.ks_2samp(rvs1, rvs3)
    KstestResult(statistic=0.114, pvalue=0.00299005061044668)  # random

Kernel density estimation
-------------------------

A common task in statistics is to estimate the probability density function
(PDF) of a random variable from a set of data samples. This task is called
density estimation. The most well-known tool to do this is the histogram.
A histogram is a useful tool for visualization (mainly because everyone
understands it), but doesn't use the available data very efficiently. Kernel
density estimation (KDE) is a more efficient tool for the same task. The
:func:`~stats.gaussian_kde` estimator can be used to estimate the PDF of univariate as
well as multivariate data. It works best if the data is unimodal.


Univariate estimation
^^^^^^^^^^^^^^^^^^^^^

We start with a minimal amount of data in order to see how :func:`~stats.gaussian_kde`
works and what the different options for bandwidth selection do. The data
sampled from the PDF are shown as blue dashes at the bottom of the figure (this
is called a rug plot):

.. plot::

    >>> from scipy import stats
    >>> import matplotlib.pyplot as plt

    >>> x1 = np.array([-7, -5, 1, 4, 5], dtype=np.float64)
    >>> kde1 = stats.gaussian_kde(x1)
    >>> kde2 = stats.gaussian_kde(x1, bw_method='silverman')

    >>> fig = plt.figure()
    >>> ax = fig.add_subplot(111)

    >>> ax.plot(x1, np.zeros(x1.shape), 'b+', ms=20)  # rug plot
    >>> x_eval = np.linspace(-10, 10, num=200)
    >>> ax.plot(x_eval, kde1(x_eval), 'k-', label="Scott's Rule")
    >>> ax.plot(x_eval, kde2(x_eval), 'r-', label="Silverman's Rule")

    >>> plt.show()

We see that there is very little difference between Scott's Rule and
Silverman's Rule, and that the bandwidth selection with a limited amount of
data is probably a bit too wide. We can define our own bandwidth function to
get a less smoothed-out result.

    >>> def my_kde_bandwidth(obj, fac=1./5):
    ...     """We use Scott's Rule, multiplied by a constant factor."""
    ...     return np.power(obj.n, -1./(obj.d+4)) * fac

    >>> fig = plt.figure()
    >>> ax = fig.add_subplot(111)

    >>> ax.plot(x1, np.zeros(x1.shape), 'b+', ms=20)  # rug plot
    >>> kde3 = stats.gaussian_kde(x1, bw_method=my_kde_bandwidth)
    >>> ax.plot(x_eval, kde3(x_eval), 'g-', label="With smaller BW")

    >>> plt.show()

.. plot:: tutorial/stats/plots/kde_plot2.py
   :align: center
   :include-source: 0

We see that if we set bandwidth to be very narrow, the obtained estimate for
the probability density function (PDF) is simply the sum of Gaussians around
each data point.

We now take a more realistic example and look at the difference between the
two available bandwidth selection rules. Those rules are known to work well
for (close to) normal distributions, but even for unimodal distributions that
are quite strongly non-normal they work reasonably well. As a non-normal
distribution we take a Student's T distribution with 5 degrees of freedom.

.. plot:: tutorial/stats/plots/kde_plot3.py
   :align: center
   :include-source: 1

We now take a look at a bimodal distribution with one wider and one narrower
Gaussian feature. We expect that this will be a more difficult density to
approximate, due to the different bandwidths required to accurately resolve
each feature.

    >>> from functools import partial

    >>> loc1, scale1, size1 = (-2, 1, 175)
    >>> loc2, scale2, size2 = (2, 0.2, 50)
    >>> x2 = np.concatenate([np.random.normal(loc=loc1, scale=scale1, size=size1),
    ...                      np.random.normal(loc=loc2, scale=scale2, size=size2)])

    >>> x_eval = np.linspace(x2.min() - 1, x2.max() + 1, 500)

    >>> kde = stats.gaussian_kde(x2)
    >>> kde2 = stats.gaussian_kde(x2, bw_method='silverman')
    >>> kde3 = stats.gaussian_kde(x2, bw_method=partial(my_kde_bandwidth, fac=0.2))
    >>> kde4 = stats.gaussian_kde(x2, bw_method=partial(my_kde_bandwidth, fac=0.5))

    >>> pdf = stats.norm.pdf
    >>> bimodal_pdf = pdf(x_eval, loc=loc1, scale=scale1) * float(size1) / x2.size + \
    ...               pdf(x_eval, loc=loc2, scale=scale2) * float(size2) / x2.size

    >>> fig = plt.figure(figsize=(8, 6))
    >>> ax = fig.add_subplot(111)

    >>> ax.plot(x2, np.zeros(x2.shape), 'b+', ms=12)
    >>> ax.plot(x_eval, kde(x_eval), 'k-', label="Scott's Rule")
    >>> ax.plot(x_eval, kde2(x_eval), 'b-', label="Silverman's Rule")
    >>> ax.plot(x_eval, kde3(x_eval), 'g-', label="Scott * 0.2")
    >>> ax.plot(x_eval, kde4(x_eval), 'c-', label="Scott * 0.5")
    >>> ax.plot(x_eval, bimodal_pdf, 'r--', label="Actual PDF")

    >>> ax.set_xlim([x_eval.min(), x_eval.max()])
    >>> ax.legend(loc=2)
    >>> ax.set_xlabel('x')
    >>> ax.set_ylabel('Density')
    >>> plt.show()

.. plot:: tutorial/stats/plots/kde_plot4.py
   :align: center
   :include-source: 0

As expected, the KDE is not as close to the true PDF as we would like due to
the different characteristic size of the two features of the bimodal
distribution. By halving the default bandwidth (``Scott * 0.5``), we can do
somewhat better, while using a factor 5 smaller bandwidth than the default
doesn't smooth enough. What we really need, though, in this case, is a
non-uniform (adaptive) bandwidth.


Multivariate estimation
^^^^^^^^^^^^^^^^^^^^^^^

With :func:`~stats.gaussian_kde` we can perform multivariate, as well as univariate
estimation. We demonstrate the bivariate case. First, we generate some random
data with a model in which the two variates are correlated.

    >>> def measure(n):
    ...     """Measurement model, return two coupled measurements."""
    ...     m1 = np.random.normal(size=n)
    ...     m2 = np.random.normal(scale=0.5, size=n)
    ...     return m1+m2, m1-m2

    >>> m1, m2 = measure(2000)
    >>> xmin = m1.min()
    >>> xmax = m1.max()
    >>> ymin = m2.min()
    >>> ymax = m2.max()

Then we apply the KDE to the data:

    >>> X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]
    >>> positions = np.vstack([X.ravel(), Y.ravel()])
    >>> values = np.vstack([m1, m2])
    >>> kernel = stats.gaussian_kde(values)
    >>> Z = np.reshape(kernel.evaluate(positions).T, X.shape)

Finally, we plot the estimated bivariate distribution as a colormap and plot
the individual data points on top.

    >>> fig = plt.figure(figsize=(8, 6))
    >>> ax = fig.add_subplot(111)

    >>> ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,
    ...           extent=[xmin, xmax, ymin, ymax])
    >>> ax.plot(m1, m2, 'k.', markersize=2)

    >>> ax.set_xlim([xmin, xmax])
    >>> ax.set_ylim([ymin, ymax])

    >>> plt.show()

.. plot:: tutorial/stats/plots/kde_plot5.py
   :align: center
   :include-source: 0


Multiscale Graph Correlation (MGC)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

With :func:`~stats.multiscale_graphcorr`, we can test for independence on high
dimensional and nonlinear data. Before we start, let's import some useful
packages:

    >>> import numpy as np
    >>> import matplotlib.pyplot as plt; plt.style.use('classic')
    >>> from scipy.stats import multiscale_graphcorr

Let's use a custom plotting function to plot the data relationship:

    >>> def mgc_plot(x, y, sim_name, mgc_dict=None, only_viz=False,
    ...              only_mgc=False):
    ...     """Plot sim and MGC-plot"""
    ...     if not only_mgc:
    ...         # simulation
    ...         plt.figure(figsize=(8, 8))
    ...         ax = plt.gca()
    ...         ax.set_title(sim_name + " Simulation", fontsize=20)
    ...         ax.scatter(x, y)
    ...         ax.set_xlabel('X', fontsize=15)
    ...         ax.set_ylabel('Y', fontsize=15)
    ...         ax.axis('equal')
    ...         ax.tick_params(axis="x", labelsize=15)
    ...         ax.tick_params(axis="y", labelsize=15)
    ...         plt.show()
    ...     if not only_viz:
    ...         # local correlation map
    ...         plt.figure(figsize=(8,8))
    ...         ax = plt.gca()
    ...         mgc_map = mgc_dict["mgc_map"]
    ...         # draw heatmap
    ...         ax.set_title("Local Correlation Map", fontsize=20)
    ...         im = ax.imshow(mgc_map, cmap='YlGnBu')
    ...         # colorbar
    ...         cbar = ax.figure.colorbar(im, ax=ax)
    ...         cbar.ax.set_ylabel("", rotation=-90, va="bottom")
    ...         ax.invert_yaxis()
    ...         # Turn spines off and create white grid.
    ...         for edge, spine in ax.spines.items():
    ...             spine.set_visible(False)
    ...         # optimal scale
    ...         opt_scale = mgc_dict["opt_scale"]
    ...         ax.scatter(opt_scale[0], opt_scale[1],
    ...                    marker='X', s=200, color='red')
    ...         # other formatting
    ...         ax.tick_params(bottom="off", left="off")
    ...         ax.set_xlabel('#Neighbors for X', fontsize=15)
    ...         ax.set_ylabel('#Neighbors for Y', fontsize=15)
    ...         ax.tick_params(axis="x", labelsize=15)
    ...         ax.tick_params(axis="y", labelsize=15)
    ...         ax.set_xlim(0, 100)
    ...         ax.set_ylim(0, 100)
    ...         plt.show()

Let's look at some linear data first:

    >>> rng = np.random.default_rng()
    >>> x = np.linspace(-1, 1, num=100)
    >>> y = x + 0.3 * rng.random(x.size)

The simulation relationship can be plotted below:

    >>> mgc_plot(x, y, "Linear", only_viz=True)

.. plot:: tutorial/stats/plots/mgc_plot1.py
   :align: center
   :include-source: 0

Now, we can see the test statistic, p-value, and MGC map visualized below. The
optimal scale is shown on the map as a red "x":

    >>> stat, pvalue, mgc_dict = multiscale_graphcorr(x, y)
    >>> print("MGC test statistic: ", round(stat, 1))
    MGC test statistic:  1.0
    >>> print("P-value: ", round(pvalue, 1))
    P-value:  0.0
    >>> mgc_plot(x, y, "Linear", mgc_dict, only_mgc=True)

.. plot:: tutorial/stats/plots/mgc_plot2.py
   :align: center
   :include-source: 0

It is clear from here, that MGC is able to determine a relationship between the
input data matrices because the p-value is very low and the MGC test statistic
is relatively high. The MGC-map indicates a **strongly linear relationship**.
Intuitively, this is because having more neighbors will help in identifying a
linear relationship between :math:`x` and :math:`y`. The optimal scale in this
case is **equivalent to the global scale**, marked by a red spot on the map.

The same can be done for nonlinear data sets. The following :math:`x` and
:math:`y` arrays are derived from a nonlinear simulation:

    >>> unif = np.array(rng.uniform(0, 5, size=100))
    >>> x = unif * np.cos(np.pi * unif)
    >>> y = unif * np.sin(np.pi * unif) + 0.4 * rng.random(x.size)

The simulation relationship can be plotted below:

    >>> mgc_plot(x, y, "Spiral", only_viz=True)

.. plot:: tutorial/stats/plots/mgc_plot3.py
   :align: center
   :include-source: 0

Now, we can see the test statistic, p-value, and MGC map visualized below. The
optimal scale is shown on the map as a red "x":

    >>> stat, pvalue, mgc_dict = multiscale_graphcorr(x, y)
    >>> print("MGC test statistic: ", round(stat, 1))
    MGC test statistic:  0.2  # random
    >>> print("P-value: ", round(pvalue, 1))
    P-value:  0.0
    >>> mgc_plot(x, y, "Spiral", mgc_dict, only_mgc=True)

.. plot:: tutorial/stats/plots/mgc_plot4.py
   :align: center
   :include-source: 0

It is clear from here, that MGC is able to determine a relationship again
because the p-value is very low and the MGC test statistic is relatively high.
The MGC-map indicates a **strongly nonlinear relationship**. The optimal scale
in this case is **equivalent to the local scale**, marked by a red spot on the
map.

.. _quasi-monte-carlo:

Quasi-Monte Carlo
-----------------

Before talking about Quasi-Monte Carlo (QMC), a quick introduction about Monte
Carlo (MC). MC methods, or MC experiments, are a broad class of
computational algorithms that rely on repeated random sampling to obtain
numerical results. The underlying concept is to use randomness to solve
problems that might be deterministic in principle. They are often used in
physical and mathematical problems and are most useful when it is difficult or
impossible to use other approaches. MC methods are mainly used in
three problem classes: optimization, numerical integration, and generating
draws from a probability distribution.

Generating random numbers with specific properties is a more complex problem
than it sounds. Simple MC methods are designed to sample points to be
independent and identically distributed (IID). But generating multiple sets
of random points can produce radically different results.

.. plot:: tutorial/stats/plots/qmc_plot_mc.py
   :align: center
   :include-source: 0

In both cases in the plot above, points are generated randomly without any
knowledge about previously drawn points. It is clear that some regions of
the space are left unexplored - which can cause problems in simulations as a
particular set of points might trigger a totally different behaviour.

A great benefit of MC is that it has known convergence properties.
Let's look at the mean of the squared sum in 5 dimensions:

.. math::

    f(\mathbf{x}) = \left( \sum_{j=1}^{5}x_j \right)^2,

with :math:`x_j \sim \mathcal{U}(0,1)`. It has a known mean value,
:math:`\mu = 5/3+5(5-1)/4`. Using MC sampling, we
can compute that mean numerically, and the approximation error follows a
theoretical rate of :math:`O(n^{-1/2})`.

.. plot:: tutorial/stats/plots/qmc_plot_conv_mc.py
   :align: center
   :include-source: 0

Although the convergence is ensured, practitioners tend to want to have an
exploration process which is more deterministic. With normal MC, a seed can be
used to have a repeatable process. But fixing the seed would break the
convergence property: a given seed could work for a given class of problem
and break for another one.

What is commonly done to walk through the space in a deterministic manner, is
to use a regular grid spanning all parameter dimensions, also called a
saturated design. Let’s consider the unit-hypercube, with all bounds ranging
from 0 to 1. Now, having a distance of 0.1 between points, the number of points
required to fill the unit interval would be 10. In a 2-dimensional hypercube
the same spacing would require 100, and in 3 dimensions 1,000 points. As the
number of dimensions grows, the number of experiments which is required to fill
the space rises exponentially as the dimensionality of the space increases.
This exponential growth is called "the curse of dimensionality".

    >>> import numpy as np
    >>> disc = 10
    >>> x1 = np.linspace(0, 1, disc)
    >>> x2 = np.linspace(0, 1, disc)
    >>> x3 = np.linspace(0, 1, disc)
    >>> x1, x2, x3 = np.meshgrid(x1, x2, x3)

.. plot:: tutorial/stats/plots/qmc_plot_curse.py
   :align: center
   :include-source: 0

To mitigate this issue, QMC methods have been designed. They are
deterministic, have a good coverage of the space and some of them can be
continued and retain good properties.
The main difference with MC methods is that the points are not IID but they
know about previous points. Hence, some methods are also referred to as
sequences.

.. plot:: tutorial/stats/plots/qmc_plot_mc_qmc.py
   :align: center
   :include-source: 0

This figure presents 2 sets of 256 points. The design of the left is a plain
MC whereas the design of the right is a QMC design using the *Sobol'* method.
We clearly see that the QMC version is more uniform. The points sample better
near the boundaries and there are less clusters or gaps.

One way to assess the uniformity is to use a measure called the discrepancy.
Here the discrepancy of *Sobol'* points is better than crude MC.

Coming back to the computation of the mean, QMC methods also have better rates
of convergence for the error. They can achieve :math:`O(n^{-1})` for this
function, and even better rates on very smooth functions. This figure shows
that the *Sobol'* method has a rate of :math:`O(n^{-1})`:

.. plot:: tutorial/stats/plots/qmc_plot_conv_mc_sobol.py
   :align: center
   :include-source: 0

We refer to the documentation of :mod:`scipy.stats.qmc` for
more mathematical details.

Calculate the discrepancy
^^^^^^^^^^^^^^^^^^^^^^^^^

Let's consider two sets of points. From the figure below, it is clear that
the design on the left covers more of the space than the design on the right.
This can be quantified using a :func:`~stats.qmc.discrepancy` measure.
The lower the discrepancy, the more uniform a sample is.

    >>> import numpy as np
    >>> from scipy.stats import qmc
    >>> space_1 = np.array([[1, 3], [2, 6], [3, 2], [4, 5], [5, 1], [6, 4]])
    >>> space_2 = np.array([[1, 5], [2, 4], [3, 3], [4, 2], [5, 1], [6, 6]])
    >>> l_bounds = [0.5, 0.5]
    >>> u_bounds = [6.5, 6.5]
    >>> space_1 = qmc.scale(space_1, l_bounds, u_bounds, reverse=True)
    >>> space_2 = qmc.scale(space_2, l_bounds, u_bounds, reverse=True)
    >>> qmc.discrepancy(space_1)
    0.008142039609053464
    >>> qmc.discrepancy(space_2)
    0.010456854423869011

.. plot:: tutorial/stats/plots/qmc_plot_discrepancy.py
   :align: center
   :include-source: 0

Using a QMC engine
^^^^^^^^^^^^^^^^^^

Several QMC samplers/engines are implemented. Here we look at two of the most
used QMC methods: :class:`~stats.qmc.Sobol` and :class:`~stats.qmc.Halton`
sequences.

.. plot:: tutorial/stats/plots/qmc_plot_sobol_halton.py
   :align: center
   :include-source: 1

.. warning:: QMC methods require particular care and the user must read the
   documentation to avoid common pitfalls. *Sobol'* for instance requires a
   number of points following a power of 2. Also, thinning, burning or other
   point selection can break the properties of the sequence and result in a
   set of points which would not be better than MC.

QMC engines are state-aware. Meaning that you can continue the sequence,
skip some points, or reset it. Let's take 5 points from
:class:`~stats.qmc.Halton`. And then ask for a second set of 5 points:

    >>> from scipy.stats import qmc
    >>> engine = qmc.Halton(d=2)
    >>> engine.random(5)
    array([[0.22166437, 0.07980522],  # random
           [0.72166437, 0.93165708],
           [0.47166437, 0.41313856],
           [0.97166437, 0.19091633],
           [0.01853937, 0.74647189]])
    >>> engine.random(5)
    array([[0.51853937, 0.52424967],  # random
           [0.26853937, 0.30202745],
           [0.76853937, 0.857583  ],
           [0.14353937, 0.63536078],
           [0.64353937, 0.01807683]])

Now we reset the sequence. Asking for 5 points leads to the same first 5
points:

    >>> engine.reset()
    >>> engine.random(5)
    array([[0.22166437, 0.07980522],  # random
           [0.72166437, 0.93165708],
           [0.47166437, 0.41313856],
           [0.97166437, 0.19091633],
           [0.01853937, 0.74647189]])

And here we advance the sequence to get the same second set of 5 points:

    >>> engine.reset()
    >>> engine.fast_forward(5)
    >>> engine.random(5)
    array([[0.51853937, 0.52424967],  # random
           [0.26853937, 0.30202745],
           [0.76853937, 0.857583  ],
           [0.14353937, 0.63536078],
           [0.64353937, 0.01807683]])

.. note:: By default, both :class:`~stats.qmc.Sobol` and
   :class:`~stats.qmc.Halton` are scrambled. The convergence properties are
   better, and it prevents the appearance of fringes or noticeable patterns
   of points in high dimensions. There should be no practical reason not to
   use the scrambled version.

Making a QMC engine, i.e., subclassing ``QMCEngine``
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To make your own :class:`~stats.qmc.QMCEngine`, a few methods have to be
defined. Following is an example wrapping `numpy.random.Generator`.

    >>> import numpy as np
    >>> from scipy.stats import qmc
    >>> class RandomEngine(qmc.QMCEngine):
    ...     def __init__(self, d, seed=None):
    ...         super().__init__(d=d, seed=seed)
    ...         self.rng = np.random.default_rng(self.rng_seed)
    ...
    ...
    ...     def random(self, n=1):
    ...         self.num_generated += n
    ...         return self.rng.random((n, self.d))
    ...
    ...
    ...     def reset(self):
    ...         self.rng = np.random.default_rng(self.rng_seed)
    ...         self.num_generated = 0
    ...         return self
    ...
    ...
    ...     def fast_forward(self, n):
    ...         self.random(n)
    ...         return self

Then we use it as any other QMC engine:

    >>> engine = RandomEngine(2)
    >>> engine.random(5)
    array([[0.22733602, 0.31675834],  # random
           [0.79736546, 0.67625467],
           [0.39110955, 0.33281393],
           [0.59830875, 0.18673419],
           [0.67275604, 0.94180287]])
    >>> engine.reset()
    >>> engine.random(5)
    array([[0.22733602, 0.31675834],  # random
           [0.79736546, 0.67625467],
           [0.39110955, 0.33281393],
           [0.59830875, 0.18673419],
           [0.67275604, 0.94180287]])

Guidelines on using QMC
^^^^^^^^^^^^^^^^^^^^^^^

* QMC has rules! Be sure to read the documentation or you might have no
  benefit over MC.
* Use :class:`~stats.qmc.Sobol` if you need **exactly** :math:`2^m` points.
* :class:`~stats.qmc.Halton` allows to sample, or skip, an arbitrary number of
  points. This is at the cost of a slower rate of convergence than *Sobol'*.
* Never remove the first points of the sequence. It will destroy the
  properties.
* Scrambling is always better.
* If you use LHS based methods, you cannot add points without losing the LHS
  properties. (There are some methods to do so, but this is not implemented.)
Signal Processing (`scipy.signal`)
==================================

.. sectionauthor:: Travis E. Oliphant

.. sectionauthor:: Pim Schellart

.. currentmodule:: scipy.signal

The signal processing toolbox currently contains some filtering
functions, a limited set of filter design tools, and a few B-spline
interpolation algorithms for 1- and 2-D data. While the
B-spline algorithms could technically be placed under the
interpolation category, they are included here because they only work
with equally-spaced data and make heavy use of filter-theory and
transfer-function formalism to provide a fast B-spline transform. To
understand this section, you will need to understand that a signal in
SciPy is an array of real or complex numbers.

.. _tutorial-signal-bsplines:

B-splines
---------

A B-spline is an approximation of a continuous function over a finite-
domain in terms of B-spline coefficients and knot points. If the knot-
points are equally spaced with spacing :math:`\Delta x`, then the B-spline
approximation to a 1-D function is the finite-basis expansion.

.. math::


    y\left(x\right)\approx\sum_{j}c_{j}\beta^{o}\left(\frac{x}{\Delta x}-j\right).

In two dimensions with knot-spacing :math:`\Delta x` and :math:`\Delta y`, the
function representation is

.. math::

    z\left(x,y\right)\approx\sum_{j}\sum_{k}c_{jk}\beta^{o}\left(\frac{x}{\Delta x}-j\right)\beta^{o}\left(\frac{y}{\Delta y}-k\right).

In these expressions, :math:`\beta^{o}\left(\cdot\right)` is the space-limited
B-spline basis function of order :math:`o`. The requirement of equally-spaced
knot-points and equally-spaced data points, allows the development of fast
(inverse-filtering) algorithms for determining the coefficients, :math:`c_{j}`,
from sample-values, :math:`y_{n}`. Unlike the general spline interpolation
algorithms, these algorithms can quickly find the spline coefficients for large
images.

The advantage of representing a set of samples via B-spline basis
functions is that continuous-domain operators (derivatives, re-
sampling, integral, etc.), which assume that the data samples are drawn
from an underlying continuous function, can be computed with relative
ease from the spline coefficients. For example, the second derivative
of a spline is

.. math::

    y{}^{\prime\prime}\left(x\right)=\frac{1}{\Delta x^{2}}\sum_{j}c_{j}\beta^{o\prime\prime}\left(\frac{x}{\Delta x}-j\right).

Using the property of B-splines that

.. math::

    \frac{d^{2}\beta^{o}\left(w\right)}{dw^{2}}=\beta^{o-2}\left(w+1\right)-2\beta^{o-2}\left(w\right)+\beta^{o-2}\left(w-1\right),

it can be seen that

.. math::

    y^{\prime\prime}\left(x\right)=\frac{1}{\Delta x^{2}}\sum_{j}c_{j}\left[\beta^{o-2}\left(\frac{x}{\Delta x}-j+1\right)-2\beta^{o-2}\left(\frac{x}{\Delta x}-j\right)+\beta^{o-2}\left(\frac{x}{\Delta x}-j-1\right)\right].

If :math:`o=3`, then at the sample points:

.. math::
   :nowrap:

    \begin{eqnarray*} \Delta x^{2}\left.y^{\prime}\left(x\right)\right|_{x=n\Delta x} & = & \sum_{j}c_{j}\delta_{n-j+1}-2c_{j}\delta_{n-j}+c_{j}\delta_{n-j-1},\\  & = & c_{n+1}-2c_{n}+c_{n-1}.\end{eqnarray*}

Thus, the second-derivative signal can be easily calculated from the spline
fit. If desired, smoothing splines can be found to make the second derivative
less sensitive to random errors.

The savvy reader will have already noticed that the data samples are related
to the knot coefficients via a convolution operator, so that simple
convolution with the sampled B-spline function recovers the original data from
the spline coefficients. The output of convolutions can change depending on
how the boundaries are handled (this becomes increasingly more important as the
number of dimensions in the dataset increases). The algorithms relating to
B-splines in the signal-processing subpackage assume mirror-symmetric
boundary conditions. Thus, spline coefficients are computed based on that
assumption, and data-samples can be recovered exactly from the spline
coefficients by assuming them to be mirror-symmetric also.

Currently the package provides functions for determining second- and third-
order cubic spline coefficients from equally-spaced samples in one and two
dimensions (:func:`qspline1d`, :func:`qspline2d`, :func:`cspline1d`,
:func:`cspline2d`). The package also supplies a function ( :func:`bspline` )
for evaluating the B-spline basis function, :math:`\beta^{o}\left(x\right)` for
arbitrary order and :math:`x.` For large :math:`o`, the B-spline basis
function can be approximated well by a zero-mean Gaussian function with
standard-deviation equal to :math:`\sigma_{o}=\left(o+1\right)/12` :

.. math::

    \beta^{o}\left(x\right)\approx\frac{1}{\sqrt{2\pi\sigma_{o}^{2}}}\exp\left(-\frac{x^{2}}{2\sigma_{o}}\right).

A function to compute this Gaussian for arbitrary :math:`x` and :math:`o` is
also available ( :func:`gauss_spline` ). The following code and figure use
spline-filtering to compute an edge-image (the second derivative of a smoothed
spline) of a raccoon's face, which is an array returned by the command :func:`scipy.misc.face`.
The command :func:`sepfir2d` was used to apply a separable 2-D FIR
filter with mirror-symmetric boundary conditions to the spline coefficients.
This function is ideally-suited for reconstructing samples from spline
coefficients and is faster than :func:`convolve2d`, which convolves arbitrary
2-D filters and allows for choosing mirror-symmetric boundary
conditions.

.. plot::

   >>> import numpy as np
   >>> from scipy import signal, misc
   >>> import matplotlib.pyplot as plt

   >>> image = misc.face(gray=True).astype(np.float32)
   >>> derfilt = np.array([1.0, -2, 1.0], dtype=np.float32)
   >>> ck = signal.cspline2d(image, 8.0)
   >>> deriv = (signal.sepfir2d(ck, derfilt, [1]) +
   ...          signal.sepfir2d(ck, [1], derfilt))

   Alternatively, we could have done::

       laplacian = np.array([[0,1,0], [1,-4,1], [0,1,0]], dtype=np.float32)
       deriv2 = signal.convolve2d(ck,laplacian,mode='same',boundary='symm')

   >>> plt.figure()
   >>> plt.imshow(image)
   >>> plt.gray()
   >>> plt.title('Original image')
   >>> plt.show()

   >>> plt.figure()
   >>> plt.imshow(deriv)
   >>> plt.gray()
   >>> plt.title('Output of spline edge filter')
   >>> plt.show()

..   :caption: Example of using smoothing splines to filter images.


Filtering
---------

Filtering is a generic name for any system that modifies an input
signal in some way. In SciPy, a signal can be thought of as a NumPy
array. There are different kinds of filters for different kinds of
operations. There are two broad kinds of filtering operations: linear
and non-linear. Linear filters can always be reduced to multiplication
of the flattened NumPy array by an appropriate matrix resulting in
another flattened NumPy array. Of course, this is not usually the best
way to compute the filter, as the matrices and vectors involved may be
huge. For example, filtering a :math:`512 \times 512` image with this
method would require multiplication of a :math:`512^2 \times 512^2`
matrix with a :math:`512^2` vector. Just trying to store the
:math:`512^2 \times 512^2` matrix using a standard NumPy array would
require :math:`68,719,476,736` elements. At 4 bytes per element this
would require :math:`256\textrm{GB}` of memory. In most applications,
most of the elements of this matrix are zero and a different method
for computing the output of the filter is employed.


Convolution/Correlation
^^^^^^^^^^^^^^^^^^^^^^^

Many linear filters also have the property of shift-invariance. This
means that the filtering operation is the same at different locations
in the signal and it implies that the filtering matrix can be
constructed from knowledge of one row (or column) of the matrix alone.
In this case, the matrix multiplication can be accomplished using
Fourier transforms.

Let :math:`x\left[n\right]` define a 1-D signal indexed by the
integer :math:`n.` Full convolution of two 1-D signals can be
expressed as

.. math::

    y\left[n\right]=\sum_{k=-\infty}^{\infty}x\left[k\right]h\left[n-k\right].

This equation can only be implemented directly if we limit the
sequences to finite-support sequences that can be stored in a
computer, choose :math:`n=0` to be the starting point of both
sequences, let :math:`K+1` be that value for which
:math:`x\left[n\right]=0` for all :math:`n\geq K+1` and :math:`M+1` be
that value for which :math:`h\left[n\right]=0` for all :math:`n\geq M+1`,
then the discrete convolution expression is

.. math::

    y\left[n\right]=\sum_{k=\max\left(n-M,0\right)}^{\min\left(n,K\right)}x\left[k\right]h\left[n-k\right].

For convenience, assume :math:`K\geq M.` Then, more explicitly, the output of
this operation is

.. math::
   :nowrap:

    \begin{eqnarray*} y\left[0\right] & = & x\left[0\right]h\left[0\right]\\ y\left[1\right] & = & x\left[0\right]h\left[1\right]+x\left[1\right]h\left[0\right]\\ y\left[2\right] & = & x\left[0\right]h\left[2\right]+x\left[1\right]h\left[1\right]+x\left[2\right]h\left[0\right]\\ \vdots & \vdots & \vdots\\ y\left[M\right] & = & x\left[0\right]h\left[M\right]+x\left[1\right]h\left[M-1\right]+\cdots+x\left[M\right]h\left[0\right]\\ y\left[M+1\right] & = & x\left[1\right]h\left[M\right]+x\left[2\right]h\left[M-1\right]+\cdots+x\left[M+1\right]h\left[0\right]\\ \vdots & \vdots & \vdots\\ y\left[K\right] & = & x\left[K-M\right]h\left[M\right]+\cdots+x\left[K\right]h\left[0\right]\\ y\left[K+1\right] & = & x\left[K+1-M\right]h\left[M\right]+\cdots+x\left[K\right]h\left[1\right]\\ \vdots & \vdots & \vdots\\ y\left[K+M-1\right] & = & x\left[K-1\right]h\left[M\right]+x\left[K\right]h\left[M-1\right]\\ y\left[K+M\right] & = & x\left[K\right]h\left[M\right].\end{eqnarray*}

Thus, the full discrete convolution of two finite sequences of lengths
:math:`K+1` and :math:`M+1`, respectively, results in a finite sequence of length
:math:`K+M+1=\left(K+1\right)+\left(M+1\right)-1.`

1-D convolution is implemented in SciPy with the function
:func:`convolve`. This function takes as inputs the signals :math:`x,`
:math:`h`, and two optional flags 'mode' and 'method', and returns the signal
:math:`y.`

The first optional flag, 'mode', allows for the specification of which part of the
output signal to return. The default value of 'full' returns the entire signal.
If the flag has a value of 'same', then only the middle :math:`K` values are
returned, starting at :math:`y\left[\left\lfloor \frac{M-1}{2}\right\rfloor
\right]`, so that the output has the same length as the first input. If the flag
has a value of 'valid', then only the middle
:math:`K-M+1=\left(K+1\right)-\left(M+1\right)+1` output values are returned,
where :math:`z` depends on all of the values of the smallest input from
:math:`h\left[0\right]` to :math:`h\left[M\right].` In other words, only the
values :math:`y\left[M\right]` to :math:`y\left[K\right]` inclusive are
returned.

The second optional flag, 'method', determines how the convolution is computed,
either through the Fourier transform approach with :func:`fftconvolve` or
through the direct method. By default, it selects the expected faster method.
The Fourier transform method has order :math:`O(N\log N)`, while the direct
method has order :math:`O(N^2)`. Depending on the big O constant and the value
of :math:`N`, one of these two methods may be faster. The default value, 'auto',
performs a rough calculation and chooses the expected faster method, while the
values 'direct' and 'fft' force computation with the other two methods.

The code below shows a simple example for convolution of 2 sequences:

>>> x = np.array([1.0, 2.0, 3.0])
>>> h = np.array([0.0, 1.0, 0.0, 0.0, 0.0])
>>> signal.convolve(x, h)
array([ 0.,  1.,  2.,  3.,  0.,  0.,  0.])
>>> signal.convolve(x, h, 'same')
array([ 2.,  3.,  0.])


This same function :func:`convolve` can actually take N-D
arrays as inputs and will return the N-D convolution of the
two arrays, as is shown in the code example below. The same input flags are
available for that case as well.


>>> x = np.array([[1., 1., 0., 0.], [1., 1., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]])
>>> h = np.array([[1., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 0.]])
>>> signal.convolve(x, h)
array([[ 1.,  1.,  0.,  0.,  0.,  0.,  0.],
       [ 1.,  1.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  1.,  1.,  0.,  0.,  0.],
       [ 0.,  0.,  1.,  1.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.]])

Correlation is very similar to convolution except that the minus sign
becomes a plus sign. Thus,

.. math::

    w\left[n\right]=\sum_{k=-\infty}^{\infty}y\left[k\right]x\left[n+k\right],

is the (cross) correlation of the signals :math:`y` and :math:`x.` For
finite-length signals with :math:`y\left[n\right]=0` outside of the range
:math:`\left[0,K\right]` and :math:`x\left[n\right]=0` outside of the range
:math:`\left[0,M\right],` the summation can simplify to

.. math::

    w\left[n\right]=\sum_{k=\max\left(0,-n\right)}^{\min\left(K,M-n\right)}y\left[k\right]x\left[n+k\right].

Assuming again that :math:`K\geq M`, this is

.. math::
   :nowrap:

    \begin{eqnarray*} w\left[-K\right] & = & y\left[K\right]x\left[0\right]\\ w\left[-K+1\right] & = & y\left[K-1\right]x\left[0\right]+y\left[K\right]x\left[1\right]\\ \vdots & \vdots & \vdots\\ w\left[M-K\right] & = & y\left[K-M\right]x\left[0\right]+y\left[K-M+1\right]x\left[1\right]+\cdots+y\left[K\right]x\left[M\right]\\ w\left[M-K+1\right] & = & y\left[K-M-1\right]x\left[0\right]+\cdots+y\left[K-1\right]x\left[M\right]\\ \vdots & \vdots & \vdots\\ w\left[-1\right] & = & y\left[1\right]x\left[0\right]+y\left[2\right]x\left[1\right]+\cdots+y\left[M+1\right]x\left[M\right]\\ w\left[0\right] & = & y\left[0\right]x\left[0\right]+y\left[1\right]x\left[1\right]+\cdots+y\left[M\right]x\left[M\right]\\ w\left[1\right] & = & y\left[0\right]x\left[1\right]+y\left[1\right]x\left[2\right]+\cdots+y\left[M-1\right]x\left[M\right]\\ w\left[2\right] & = & y\left[0\right]x\left[2\right]+y\left[1\right]x\left[3\right]+\cdots+y\left[M-2\right]x\left[M\right]\\ \vdots & \vdots & \vdots\\ w\left[M-1\right] & = & y\left[0\right]x\left[M-1\right]+y\left[1\right]x\left[M\right]\\ w\left[M\right] & = & y\left[0\right]x\left[M\right].\end{eqnarray*}


The SciPy function :func:`correlate` implements this operation. Equivalent
flags are available for this operation to return the full :math:`K+M+1` length
sequence ('full') or a sequence with the same size as the largest sequence
starting at :math:`w\left[-K+\left\lfloor \frac{M-1}{2}\right\rfloor \right]`
('same') or a sequence where the values depend on all the values of the
smallest sequence ('valid'). This final option returns the :math:`K-M+1`
values :math:`w\left[M-K\right]` to :math:`w\left[0\right]` inclusive.



The function :func:`correlate` can also take arbitrary N-D arrays as input
and return the N-D convolution of the two arrays on output.

When :math:`N=2,` :func:`correlate` and/or :func:`convolve` can be used
to construct arbitrary image filters to perform actions such as blurring,
enhancing, and edge-detection for an image.



.. plot::

   >>> import numpy as np
   >>> from scipy import signal, misc
   >>> import matplotlib.pyplot as plt

   >>> image = misc.face(gray=True)
   >>> w = np.zeros((50, 50))
   >>> w[0][0] = 1.0
   >>> w[49][25] = 1.0
   >>> image_new = signal.fftconvolve(image, w)

   >>> plt.figure()
   >>> plt.imshow(image)
   >>> plt.gray()
   >>> plt.title('Original image')
   >>> plt.show()

   >>> plt.figure()
   >>> plt.imshow(image_new)
   >>> plt.gray()
   >>> plt.title('Filtered image')
   >>> plt.show()


Calculating the convolution in the time domain as above is mainly used for
filtering when one of the signals is much smaller than the other ( :math:`K\gg
M` ), otherwise linear filtering is more efficiently calculated in the
frequency domain provided by the function :func:`fftconvolve`. By default,
:func:`convolve` estimates the fastest method using :func:`choose_conv_method`.

If the filter function :math:`w[n,m]` can be factored according to

.. math::

  h[n, m] = h_1[n] h_2[m],

convolution can be calculated by means of the function :func:`sepfir2d`. As an
example, we consider a Gaussian filter :func:`~scipy.signal.windows.gaussian`

.. math::

  h[n, m] \propto e^{-x^2-y^2} = e^{-x^2} e^{-y^2},

which is often used for blurring.

.. plot::

   >>> import numpy as np
   >>> from scipy import signal, misc
   >>> import matplotlib.pyplot as plt

   >>> image = misc.ascent()
   >>> w = signal.windows.gaussian(51, 10.0)
   >>> image_new = signal.sepfir2d(image, w, w)

   >>> plt.figure()
   >>> plt.imshow(image)
   >>> plt.gray()
   >>> plt.title('Original image')
   >>> plt.show()

   >>> plt.figure()
   >>> plt.imshow(image_new)
   >>> plt.gray()
   >>> plt.title('Filtered image')
   >>> plt.show()



Difference-equation filtering
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A general class of linear 1-D filters (that includes convolution
filters) are filters described by the difference equation

.. math::

    \sum_{k=0}^{N}a_{k}y\left[n-k\right]=\sum_{k=0}^{M}b_{k}x\left[n-k\right],

where :math:`x\left[n\right]` is the input sequence and
:math:`y\left[n\right]` is the output sequence. If we assume initial rest so
that :math:`y\left[n\right]=0` for :math:`n<0`, then this kind of filter can
be implemented using convolution. However, the convolution filter sequence
:math:`h\left[n\right]` could be infinite if :math:`a_{k}\neq0` for
:math:`k\geq1.` In addition, this general class of linear filter allows
initial conditions to be placed on :math:`y\left[n\right]` for :math:`n<0`
resulting in a filter that cannot be expressed using convolution.

The difference equation filter can be thought of as finding
:math:`y\left[n\right]` recursively in terms of its previous values

.. math::

    a_{0}y\left[n\right]=-a_{1}y\left[n-1\right]-\cdots-a_{N}y\left[n-N\right]+\cdots+b_{0}x\left[n\right]+\cdots+b_{M}x\left[n-M\right].

Often, :math:`a_{0}=1` is chosen for normalization. The implementation in SciPy
of this general difference equation filter is a little more complicated than
would be implied by the previous equation. It is implemented so that only one
signal needs to be delayed. The actual implementation equations are (assuming
:math:`a_{0}=1` ):

.. math::
   :nowrap:

    \begin{eqnarray*} y\left[n\right] & = & b_{0}x\left[n\right]+z_{0}\left[n-1\right]\\ z_{0}\left[n\right] & = & b_{1}x\left[n\right]+z_{1}\left[n-1\right]-a_{1}y\left[n\right]\\ z_{1}\left[n\right] & = & b_{2}x\left[n\right]+z_{2}\left[n-1\right]-a_{2}y\left[n\right]\\ \vdots & \vdots & \vdots\\ z_{K-2}\left[n\right] & = & b_{K-1}x\left[n\right]+z_{K-1}\left[n-1\right]-a_{K-1}y\left[n\right]\\ z_{K-1}\left[n\right] & = & b_{K}x\left[n\right]-a_{K}y\left[n\right],\end{eqnarray*}

where :math:`K=\max\left(N,M\right).` Note that :math:`b_{K}=0` if :math:`K>M`
and :math:`a_{K}=0` if :math:`K>N.` In this way, the output at time :math:`n`
depends only on the input at time :math:`n` and the value of :math:`z_{0}` at
the previous time. This can always be calculated as long as the :math:`K`
values :math:`z_{0}\left[n-1\right]\ldots z_{K-1}\left[n-1\right]` are
computed and stored at each time step.

The difference-equation filter is called using the command :func:`lfilter` in
SciPy. This command takes as inputs the vector :math:`b,` the vector,
:math:`a,` a signal :math:`x` and returns the vector :math:`y` (the same
length as :math:`x` ) computed using the equation given above. If :math:`x` is
N-D, then the filter is computed along the axis provided.
If desired, initial conditions providing the values of
:math:`z_{0}\left[-1\right]` to :math:`z_{K-1}\left[-1\right]` can be provided
or else it will be assumed that they are all zero. If initial conditions are
provided, then the final conditions on the intermediate variables are also
returned. These could be used, for example, to restart the calculation in the
same state.

Sometimes, it is more convenient to express the initial conditions in terms of
the signals :math:`x\left[n\right]` and :math:`y\left[n\right].` In other
words, perhaps you have the values of :math:`x\left[-M\right]` to
:math:`x\left[-1\right]` and the values of :math:`y\left[-N\right]` to
:math:`y\left[-1\right]` and would like to determine what values of
:math:`z_{m}\left[-1\right]` should be delivered as initial conditions to the
difference-equation filter. It is not difficult to show that, for :math:`0\leq
m<K,`

.. math::

    z_{m}\left[n\right]=\sum_{p=0}^{K-m-1}\left(b_{m+p+1}x\left[n-p\right]-a_{m+p+1}y\left[n-p\right]\right).

Using this formula, we can find the initial-condition vector
:math:`z_{0}\left[-1\right]` to :math:`z_{K-1}\left[-1\right]` given initial
conditions on :math:`y` (and :math:`x` ). The command :func:`lfiltic` performs
this function.

As an example, consider the following system:

.. math::

  y[n] = \frac{1}{2} x[n] + \frac{1}{4} x[n-1] + \frac{1}{3} y[n-1]

The code calculates the signal :math:`y[n]` for a given signal :math:`x[n]`;
first for initial conditions :math:`y[-1] = 0` (default case), then for
:math:`y[-1] = 2` by means of :func:`lfiltic`.

>>> import numpy as np
>>> from scipy import signal

>>> x = np.array([1., 0., 0., 0.])
>>> b = np.array([1.0/2, 1.0/4])
>>> a = np.array([1.0, -1.0/3])
>>> signal.lfilter(b, a, x)
array([0.5, 0.41666667, 0.13888889, 0.0462963])
>>> zi = signal.lfiltic(b, a, y=[2.])
>>> signal.lfilter(b, a, x, zi=zi)
(array([ 1.16666667,  0.63888889,  0.21296296,  0.07098765]), array([0.02366]))

Note that the output signal :math:`y[n]` has the same length as the length as
the input signal :math:`x[n]`.


Analysis of Linear Systems
""""""""""""""""""""""""""

Linear system described a linear-difference equation can be fully described by
the coefficient vectors :math:`a` and :math:`b` as was done above; an alternative
representation is to provide a factor :math:`k`, :math:`N_z` zeros :math:`z_k`
and :math:`N_p` poles :math:`p_k`, respectively, to describe the system by
means of its transfer function :math:`H(z)`, according to

.. math::

   H(z) = k \frac{ (z-z_1)(z-z_2)...(z-z_{N_z})}{ (z-p_1)(z-p_2)...(z-p_{N_p})}.

This alternative representation can be obtained with the scipy function
:func:`tf2zpk`; the inverse is provided by :func:`zpk2tf`.

For the above example we have

>>> b = np.array([1.0/2, 1.0/4])
>>> a = np.array([1.0, -1.0/3])
>>> signal.tf2zpk(b, a)
(array([-0.5]), array([ 0.33333333]), 0.5)

i.e., the system has a zero at :math:`z=-1/2` and a pole at :math:`z=1/3`.

The scipy function :func:`freqz` allows calculation of the frequency response
of a system described by the coefficients :math:`a_k` and :math:`b_k`. See the
help of the :func:`freqz` function for a comprehensive example.


Filter Design
^^^^^^^^^^^^^

Time-discrete filters can be classified into finite response (FIR) filters and
infinite response (IIR) filters. FIR filters can provide a linear phase
response, whereas IIR filters cannot. SciPy provides functions
for designing both types of filters.

FIR Filter
""""""""""

The function :func:`firwin` designs filters according to the window method.
Depending on the provided arguments, the function returns different filter
types (e.g., low-pass, band-pass...).

The example below designs a low-pass and a band-stop filter, respectively.

.. plot::

   >>> import numpy as np
   >>> import scipy.signal as signal
   >>> import matplotlib.pyplot as plt

   >>> b1 = signal.firwin(40, 0.5)
   >>> b2 = signal.firwin(41, [0.3, 0.8])
   >>> w1, h1 = signal.freqz(b1)
   >>> w2, h2 = signal.freqz(b2)

   >>> plt.title('Digital filter frequency response')
   >>> plt.plot(w1, 20*np.log10(np.abs(h1)), 'b')
   >>> plt.plot(w2, 20*np.log10(np.abs(h2)), 'r')
   >>> plt.ylabel('Amplitude Response (dB)')
   >>> plt.xlabel('Frequency (rad/sample)')
   >>> plt.grid()
   >>> plt.show()

Note that :func:`firwin` uses, per default, a normalized frequency defined such
that the value :math:`1` corresponds to the Nyquist frequency, whereas the
function :func:`freqz` is defined such that the value :math:`\pi` corresponds
to the Nyquist frequency.


The function :func:`firwin2` allows design of almost arbitrary frequency
responses by specifying an array of corner frequencies and corresponding
gains, respectively.

The example below designs a filter with such an arbitrary amplitude response.

.. plot::

   >>> import numpy as np
   >>> import scipy.signal as signal
   >>> import matplotlib.pyplot as plt

   >>> b = signal.firwin2(150, [0.0, 0.3, 0.6, 1.0], [1.0, 2.0, 0.5, 0.0])
   >>> w, h = signal.freqz(b)

   >>> plt.title('Digital filter frequency response')
   >>> plt.plot(w, np.abs(h))
   >>> plt.title('Digital filter frequency response')
   >>> plt.ylabel('Amplitude Response')
   >>> plt.xlabel('Frequency (rad/sample)')
   >>> plt.grid()
   >>> plt.show()

Note the linear scaling of the y-axis and the different definition of the
Nyquist frequency in :func:`firwin2` and :func:`freqz` (as explained above).


IIR Filter
""""""""""

SciPy provides two functions to directly design IIR :func:`iirdesign` and
:func:`iirfilter`, where the filter type (e.g., elliptic) is passed as an
argument and several more filter design functions for specific filter types,
e.g., :func:`ellip`.

The example below designs an elliptic low-pass filter with defined pass-band
and stop-band ripple, respectively. Note the much lower filter order (order 4)
compared with the FIR filters from the examples above in order to reach the same
stop-band attenuation of :math:`\approx 60` dB.

.. plot::

   >>> import numpy as np
   >>> import scipy.signal as signal
   >>> import matplotlib.pyplot as plt

   >>> b, a = signal.iirfilter(4, Wn=0.2, rp=5, rs=60, btype='lowpass', ftype='ellip')
   >>> w, h = signal.freqz(b, a)

   >>> plt.title('Digital filter frequency response')
   >>> plt.plot(w, 20*np.log10(np.abs(h)))
   >>> plt.title('Digital filter frequency response')
   >>> plt.ylabel('Amplitude Response [dB]')
   >>> plt.xlabel('Frequency (rad/sample)')
   >>> plt.grid()
   >>> plt.show()

Filter Coefficients
"""""""""""""""""""

Filter coefficients can be stored in several different formats:

* 'ba' or 'tf' = transfer function coefficients
* 'zpk' = zeros, poles, and overall gain
* 'ss' = state-space system representation
* 'sos' = transfer function coefficients of second-order sections

Functions, such as :func:`tf2zpk` and :func:`zpk2ss`, can convert between them.

Transfer function representation
********************************

The ``ba`` or ``tf`` format is a 2-tuple ``(b, a)`` representing a transfer
function, where `b` is a length ``M+1`` array of coefficients of the `M`-order
numerator polynomial, and `a` is a length ``N+1`` array of coefficients of the
`N`-order denominator, as positive, descending powers of the transfer function
variable. So the tuple of :math:`b = [b_0, b_1, ..., b_M]` and
:math:`a =[a_0, a_1, ..., a_N]` can represent an analog filter of the form:

.. math::

    H(s) = \frac
    {b_0 s^M + b_1 s^{(M-1)} + \cdots + b_M}
    {a_0 s^N + a_1 s^{(N-1)} + \cdots + a_N}
    = \frac
    {\sum_{i=0}^M b_i s^{(M-i)}}
    {\sum_{i=0}^N a_i s^{(N-i)}}

or a discrete-time filter of the form:

.. math::

    H(z) = \frac
    {b_0 z^M + b_1 z^{(M-1)} + \cdots + b_M}
    {a_0 z^N + a_1 z^{(N-1)} + \cdots + a_N}
    = \frac
    {\sum_{i=0}^M b_i z^{(M-i)}}
    {\sum_{i=0}^N a_i z^{(N-i)}}.

This "positive powers" form is found more commonly in controls
engineering.  If `M` and `N` are equal (which is true for all filters
generated by the bilinear transform), then this happens to be equivalent
to the "negative powers" discrete-time form preferred in DSP:

.. math::

    H(z) = \frac
    {b_0 + b_1 z^{-1} + \cdots + b_M z^{-M}}
    {a_0 + a_1 z^{-1} + \cdots + a_N z^{-N}}
    = \frac
    {\sum_{i=0}^M b_i z^{-i}}
    {\sum_{i=0}^N a_i z^{-i}}.

Although this is true for common filters, remember that this is not true
in the general case. If `M` and `N` are not equal, the discrete-time
transfer function coefficients must first be converted to the "positive
powers" form before finding the poles and zeros.

This representation suffers from numerical error at higher orders, so other
formats are preferred when possible.

Zeros and poles representation
******************************

The ``zpk`` format is a 3-tuple ``(z, p, k)``, where `z` is an `M`-length
array of the complex zeros of the transfer function
:math:`z = [z_0, z_1, ..., z_{M-1}]`, `p` is an `N`-length array of the
complex poles of the transfer function :math:`p = [p_0, p_1, ..., p_{N-1}]`,
and `k` is a scalar gain.  These represent the digital transfer function:

.. math::
    H(z) = k \cdot \frac
    {(z - z_0) (z - z_1) \cdots (z - z_{(M-1)})}
    {(z - p_0) (z - p_1) \cdots (z - p_{(N-1)})}
    = k \frac
    {\prod_{i=0}^{M-1} (z - z_i)}
    {\prod_{i=0}^{N-1} (z - p_i)}

or the analog transfer function:

.. math::
    H(s) = k \cdot \frac
    {(s - z_0) (s - z_1) \cdots (s - z_{(M-1)})}
    {(s - p_0) (s - p_1) \cdots (s - p_{(N-1)})}
    = k \frac
    {\prod_{i=0}^{M-1} (s - z_i)}
    {\prod_{i=0}^{N-1} (s - p_i)}.

Although the sets of roots are stored as ordered NumPy arrays, their ordering
does not matter: ``([-1, -2], [-3, -4], 1)`` is the same filter as
``([-2, -1], [-4, -3], 1)``.

State-space system representation
*********************************

The ``ss`` format is a 4-tuple of arrays ``(A, B, C, D)`` representing the
state-space of an `N`-order digital/discrete-time system of the form:

.. math::
    \mathbf{x}[k+1] = A \mathbf{x}[k] + B \mathbf{u}[k]\\
    \mathbf{y}[k] = C \mathbf{x}[k] + D \mathbf{u}[k]

or a continuous/analog system of the form:

.. math::
    \dot{\mathbf{x}}(t) = A \mathbf{x}(t) + B \mathbf{u}(t)\\
    \mathbf{y}(t) = C \mathbf{x}(t) + D \mathbf{u}(t),

with `P` inputs, `Q` outputs and `N` state variables, where:

- `x` is the state vector
- `y` is the output vector of length `Q`
- `u` is the input vector of length `P`
- `A` is the state matrix, with shape ``(N, N)``
- `B` is the input matrix with shape ``(N, P)``
- `C` is the output matrix with shape ``(Q, N)``
- `D` is the feedthrough or feedforward matrix with shape ``(Q, P)``.  (In
  cases where the system does not have a direct feedthrough, all values in
  `D` are zero.)

State-space is the most general representation and the only one that allows
for multiple-input, multiple-output (MIMO) systems. There are multiple
state-space representations for a given transfer function. Specifically, the
"controllable canonical form" and "observable canonical form" have the same
coefficients as the ``tf`` representation, and, therefore, suffer from the same
numerical errors.

Second-order sections representation
************************************

The ``sos`` format is a single 2-D array of shape ``(n_sections, 6)``,
representing a sequence of second-order transfer functions which, when
cascaded in series, realize a higher-order filter with minimal numerical
error. Each row corresponds to a second-order ``tf`` representation, with
the first three columns providing the numerator coefficients and the last
three providing the denominator coefficients:

.. math::
    [b_0, b_1, b_2, a_0, a_1, a_2]

The coefficients are typically normalized, such that :math:`a_0` is always 1.
The section order is usually not important with floating-point computation;
the filter output will be the same, regardless of the order.

Filter transformations
""""""""""""""""""""""

The IIR filter design functions first generate a prototype analog low-pass filter
with a normalized cutoff frequency of 1 rad/sec. This is then transformed into
other frequencies and band types using the following substitutions:

============= ====================================================================
Type                          Transformation
============= ====================================================================
:func:`lp2lp` :math:`s \rightarrow \frac{s}{\omega_0}`
:func:`lp2hp` :math:`s \rightarrow \frac{\omega_0}{s}`
:func:`lp2bp` :math:`s \rightarrow \frac{s^2 + {\omega_0}^2}{s \cdot \mathrm{BW}}`
:func:`lp2bs` :math:`s \rightarrow \frac{s \cdot \mathrm{BW}}{s^2 + {\omega_0}^2}`
============= ====================================================================

Here, :math:`\omega_0` is the new cutoff or center frequency, and
:math:`\mathrm{BW}` is the bandwidth.  These preserve symmetry on a logarithmic
frequency axis.

To convert the transformed analog filter into a digital filter, the
:func:`bilinear` transform is used, which makes the following substitution:

.. math::
    s \rightarrow \frac{2}{T} \frac{z - 1}{z + 1},

where T is the sampling time (the inverse of the sampling frequency).

Other filters
^^^^^^^^^^^^^

The signal processing package provides many more filters as well.


Median Filter
"""""""""""""

A median filter is commonly applied when noise is markedly non-Gaussian or
when it is desired to preserve edges. The median filter works by sorting all
of the array pixel values in a rectangular region surrounding the point of
interest. The sample median of this list of neighborhood pixel values is used
as the value for the output array. The sample median is the middle-array value
in a sorted list of neighborhood values. If there are an even number of
elements in the neighborhood, then the average of the middle two values is
used as the median. A general purpose median filter that works on
N-D arrays is :func:`medfilt`. A specialized version that works
only for 2-D arrays is available as :func:`medfilt2d`.


Order Filter
""""""""""""

A median filter is a specific example of a more general class of filters
called order filters. To compute the output at a particular pixel, all order
filters use the array values in a region surrounding that pixel. These array
values are sorted and then one of them is selected as the output value. For
the median filter, the sample median of the list of array values is used as
the output. A general-order filter allows the user to select which of the
sorted values will be used as the output. So, for example, one could choose to
pick the maximum in the list or the minimum. The order filter takes an
additional argument besides the input array and the region mask that specifies
which of the elements in the sorted list of neighbor array values should be
used as the output. The command to perform an order filter is
:func:`order_filter`.


Wiener filter
"""""""""""""

The Wiener filter is a simple deblurring filter for denoising images. This is
not the Wiener filter commonly described in image-reconstruction problems but,
instead, it is a simple, local-mean filter. Let :math:`x` be the input signal,
then the output is

.. math::

    y=\left\{ \begin{array}{cc} \frac{\sigma^{2}}{\sigma_{x}^{2}}m_{x}+\left(1-\frac{\sigma^{2}}{\sigma_{x}^{2}}\right)x & \sigma_{x}^{2}\geq\sigma^{2},\\ m_{x} & \sigma_{x}^{2}<\sigma^{2},\end{array}\right.

where :math:`m_{x}` is the local estimate of the mean and
:math:`\sigma_{x}^{2}` is the local estimate of the variance. The window for
these estimates is an optional input parameter (default is :math:`3\times3` ).
The parameter :math:`\sigma^{2}` is a threshold noise parameter. If
:math:`\sigma` is not given, then it is estimated as the average of the local
variances.


Hilbert filter
""""""""""""""

The Hilbert transform constructs the complex-valued analytic signal
from a real signal. For example, if :math:`x=\cos\omega n`, then
:math:`y=\textrm{hilbert}\left(x\right)` would return (except near the
edges) :math:`y=\exp\left(j\omega n\right).` In the frequency domain,
the hilbert transform performs

.. math::

    Y=X\cdot H,

where :math:`H` is :math:`2` for positive frequencies, :math:`0` for negative
frequencies, and :math:`1` for zero-frequencies.


Analog Filter Design
^^^^^^^^^^^^^^^^^^^^

The functions :func:`iirdesign`, :func:`iirfilter`, and the filter design
functions for specific filter types (e.g., :func:`ellip`) all have a flag
`analog`, which allows the design of analog filters as well.

The example below designs an analog (IIR) filter, obtains via :func:`tf2zpk`
the poles and zeros and plots them in the complex s-plane. The zeros at
:math:`\omega \approx 150` and :math:`\omega \approx 300` can be clearly seen
in the amplitude response.


.. plot::

   >>> import numpy as np
   >>> import scipy.signal as signal
   >>> import matplotlib.pyplot as plt

   >>> b, a = signal.iirdesign(wp=100, ws=200, gpass=2.0, gstop=40., analog=True)
   >>> w, h = signal.freqs(b, a)

   >>> plt.title('Analog filter frequency response')
   >>> plt.plot(w, 20*np.log10(np.abs(h)))
   >>> plt.ylabel('Amplitude Response [dB]')
   >>> plt.xlabel('Frequency')
   >>> plt.grid()
   >>> plt.show()


   >>> z, p, k = signal.tf2zpk(b, a)

   >>> plt.plot(np.real(z), np.imag(z), 'xb')
   >>> plt.plot(np.real(p), np.imag(p), 'or')
   >>> plt.legend(['Zeros', 'Poles'], loc=2)

   >>> plt.title('Pole / Zero Plot')
   >>> plt.ylabel('Real')
   >>> plt.xlabel('Imaginary')
   >>> plt.grid()
   >>> plt.show()



Spectral Analysis
------------------

Periodogram Measurements
^^^^^^^^^^^^^^^^^^^^^^^^

The scipy function :func:`periodogram` provides a method to estimate the
spectral density using the periodogram method.

The example below calculates the periodogram of a sine signal in white
Gaussian noise.

.. plot::

   >>> import numpy as np
   >>> import scipy.signal as signal
   >>> import matplotlib.pyplot as plt

   >>> fs = 10e3
   >>> N = 1e5
   >>> amp = 2*np.sqrt(2)
   >>> freq = 1270.0
   >>> noise_power = 0.001 * fs / 2
   >>> time = np.arange(N) / fs
   >>> x = amp*np.sin(2*np.pi*freq*time)
   >>> x += np.random.normal(scale=np.sqrt(noise_power), size=time.shape)

   >>> f, Pper_spec = signal.periodogram(x, fs, 'flattop', scaling='spectrum')

   >>> plt.semilogy(f, Pper_spec)
   >>> plt.xlabel('frequency [Hz]')
   >>> plt.ylabel('PSD')
   >>> plt.grid()
   >>> plt.show()



Spectral Analysis using Welch's Method
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

An improved method, especially with respect to noise immunity, is Welch's
method, which is implemented by the scipy function :func:`welch`.

The example below estimates the spectrum using Welch's method and uses the
same parameters as the example above. Note the much smoother noise floor of
the spectrogram.


.. plot::

   >>> import numpy as np
   >>> import scipy.signal as signal
   >>> import matplotlib.pyplot as plt

   >>> fs = 10e3
   >>> N = 1e5
   >>> amp = 2*np.sqrt(2)
   >>> freq = 1270.0
   >>> noise_power = 0.001 * fs / 2
   >>> time = np.arange(N) / fs
   >>> x = amp*np.sin(2*np.pi*freq*time)
   >>> x += np.random.normal(scale=np.sqrt(noise_power), size=time.shape)

   >>> f, Pwelch_spec = signal.welch(x, fs, scaling='spectrum')

   >>> plt.semilogy(f, Pwelch_spec)
   >>> plt.xlabel('frequency [Hz]')
   >>> plt.ylabel('PSD')
   >>> plt.grid()
   >>> plt.show()


Lomb-Scargle Periodograms (:func:`lombscargle`)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Least-squares spectral analysis (LSSA) [1]_ [2]_ is a method of estimating a frequency
spectrum, based on a least-squares fit of sinusoids to data samples, similar
to Fourier analysis. Fourier analysis, the most used spectral method in
science, generally boosts long-periodic noise in long-gapped records; LSSA
mitigates such problems.


The Lomb-Scargle method performs spectral analysis on unevenly-sampled data and
is known to be a powerful way to find, and test the significance of, weak
periodic signals.

For a time series comprising :math:`N_{t}` measurements :math:`X_{j}\equiv
X(t_{j})` sampled at times :math:`t_{j}`, where :math:`(j = 1, \ldots, N_{t})`,
assumed to have been scaled and shifted, such that its mean is zero and its
variance is unity, the normalized Lomb-Scargle periodogram at frequency
:math:`f` is

.. math::

    P_{n}(f) \frac{1}{2}\left\{\frac{\left[\sum_{j}^{N_{t}}X_{j}\cos\omega(t_{j}-\tau)\right]^{2}}{\sum_{j}^{N_{t}}\cos^{2}\omega(t_{j}-\tau)}+\frac{\left[\sum_{j}^{N_{t}}X_{j}\sin\omega(t_{j}-\tau)\right]^{2}}{\sum_{j}^{N_{t}}\sin^{2}\omega(t_{j}-\tau)}\right\}.

Here, :math:`\omega \equiv 2\pi f` is the angular frequency. The frequency-dependent
time offset :math:`\tau` is given by

.. math::

    \tan 2\omega\tau = \frac{\sum_{j}^{N_{t}}\sin 2\omega t_{j}}{\sum_{j}^{N_{t}}\cos 2\omega t_{j}}.

The :func:`lombscargle` function calculates the periodogram using a slightly
modified algorithm due to Townsend [3]_, which allows the periodogram to be
calculated using only a single pass through the input arrays for each
frequency.

The equation is refactored as:

.. math::

    P_{n}(f) = \frac{1}{2}\left[\frac{(c_{\tau}XC + s_{\tau}XS)^{2}}{c_{\tau}^{2}CC + 2c_{\tau}s_{\tau}CS + s_{\tau}^{2}SS} + \frac{(c_{\tau}XS - s_{\tau}XC)^{2}}{c_{\tau}^{2}SS - 2c_{\tau}s_{\tau}CS + s_{\tau}^{2}CC}\right]

and

.. math::

    \tan 2\omega\tau = \frac{2CS}{CC-SS}.

Here,

.. math::

    c_{\tau} = \cos\omega\tau,\qquad s_{\tau} = \sin\omega\tau,

while the sums are

.. math::

    XC &= \sum_{j}^{N_{t}} X_{j}\cos\omega t_{j}\\
    XS &= \sum_{j}^{N_{t}} X_{j}\sin\omega t_{j}\\
    CC &= \sum_{j}^{N_{t}} \cos^{2}\omega t_{j}\\
    SS &= \sum_{j}^{N_{t}} \sin^{2}\omega t_{j}\\
    CS &= \sum_{j}^{N_{t}} \cos\omega t_{j}\sin\omega t_{j}.

This requires :math:`N_{f}(2N_{t}+3)` trigonometric function evaluations
giving a factor of :math:`\sim 2` speed increase over the straightforward
implementation.


Detrend
-------

SciPy provides the function :func:`detrend` to remove a constant or linear
trend in a data series in order to see effect of higher order.

The example below removes the constant and linear trend of a second-order
polynomial time series and plots the remaining signal components.

.. plot::

   >>> import numpy as np
   >>> import scipy.signal as signal
   >>> import matplotlib.pyplot as plt

   >>> t = np.linspace(-10, 10, 20)
   >>> y = 1 + t + 0.01*t**2
   >>> yconst = signal.detrend(y, type='constant')
   >>> ylin = signal.detrend(y, type='linear')

   >>> plt.plot(t, y, '-rx')
   >>> plt.plot(t, yconst, '-bo')
   >>> plt.plot(t, ylin, '-k+')
   >>> plt.grid()
   >>> plt.legend(['signal', 'const. detrend', 'linear detrend'])
   >>> plt.show()




..
.. Filter design
.. -------------
..
..
.. Finite-impulse response design
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Infinite-impulse response design
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Analog filter frequency response
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Digital filter frequency response
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Linear Time-Invariant Systems
.. -----------------------------
..
..
.. LTI Object
.. ^^^^^^^^^^
..
..
.. Continuous-Time Simulation
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Step response
.. ^^^^^^^^^^^^^
..
..
.. Impulse response
.. ^^^^^^^^^^^^^^^^
..
..
.. Input/Output
.. ============
..
..
.. Binary
.. ------
..
..
.. Arbitrary binary input and output (fopen)
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Read and write Matlab .mat files
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Saving workspace
.. ^^^^^^^^^^^^^^^^
..
..
.. Text-file
.. ---------
..
..
.. Read text-files (read_array)
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Write a text-file (write_array)
.. ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..
..
.. Fourier Transforms
.. ==================
..
..
.. 1-D
.. ---------------
..
..
.. 2-D
.. ---------------
..
..
.. N-D
.. -------------
..
..
.. Shifting
.. --------
..
..
.. Sample frequencies
.. ------------------
..
..
.. Hilbert transform
.. -----------------
..
..
.. Tilbert transform
.. -----------------


.. rubric:: References

Some further reading and related software:

.. [1] N.R. Lomb "Least-squares frequency analysis of unequally spaced
       data", Astrophysics and Space Science, vol 39, pp. 447-462, 1976

.. [2] J.D. Scargle "Studies in astronomical time series analysis. II -
       Statistical aspects of spectral analysis of unevenly spaced data",
       The Astrophysical Journal, vol 263, pp. 835-853, 1982

.. [3] R.H.D. Townsend, "Fast calculation of the Lomb-Scargle
       periodogram using graphics processing units.", The Astrophysical
       Journal Supplement Series, vol 191, pp. 247-253, 2010
Special functions (:mod:`scipy.special`)
========================================

.. currentmodule:: scipy.special

The main feature of the :mod:`scipy.special` package is the definition of
numerous special functions of mathematical physics. Available
functions include airy, elliptic, bessel, gamma, beta, hypergeometric,
parabolic cylinder, mathieu, spheroidal wave, struve, and
kelvin. There are also some low-level stats functions that are not
intended for general use as an easier interface to these functions is
provided by the ``stats`` module. Most of these functions can take
array arguments and return array results following the same
broadcasting rules as other math functions in Numerical Python. Many
of these functions also accept complex numbers as input. For a
complete list of the available functions with a one-line description
type ``>>> help(special).`` Each function also has its own
documentation accessible using help.  If you don't see a function you
need, consider writing it and contributing it to the library. You can
write the function in either C, Fortran, or Python. Look in the source
code of the library for examples of each of these kinds of functions.


Bessel functions of real order(:func:`jv`, :func:`jn_zeros`)
------------------------------------------------------------

Bessel functions are a family of solutions to Bessel's differential equation
with real or complex order alpha:

.. math::
   x^2 \frac{d^2 y}{dx^2} + x \frac{dy}{dx} + (x^2 - \alpha^2)y = 0

Among other uses, these functions arise in wave propagation problems, such as
the vibrational modes of a thin drum head.  Here is an example of a circular
drum head anchored at the edge:

.. plot::

   >>> from scipy import special
   >>> def drumhead_height(n, k, distance, angle, t):
   ...    kth_zero = special.jn_zeros(n, k)[-1]
   ...    return np.cos(t) * np.cos(n*angle) * special.jn(n, distance*kth_zero)
   >>> theta = np.r_[0:2*np.pi:50j]
   >>> radius = np.r_[0:1:50j]
   >>> x = np.array([r * np.cos(theta) for r in radius])
   >>> y = np.array([r * np.sin(theta) for r in radius])
   >>> z = np.array([drumhead_height(1, 1, r, theta, 0.5) for r in radius])

   >>> import matplotlib.pyplot as plt
   >>> fig = plt.figure()
   >>> ax = fig.add_axes(rect=(0, 0.05, 0.95, 0.95), projection='3d')
   >>> ax.plot_surface(x, y, z, rstride=1, cstride=1, cmap='RdBu_r', vmin=-0.5, vmax=0.5)
   >>> ax.set_xlabel('X')
   >>> ax.set_ylabel('Y')
   >>> ax.set_xticks(np.arange(-1, 1.1, 0.5))
   >>> ax.set_yticks(np.arange(-1, 1.1, 0.5))
   >>> ax.set_zlabel('Z')
   >>> plt.show()

..   :caption: Vibrating drum head using
..             :obj:`scipy.special.jn`


Cython Bindings for Special Functions (:mod:`scipy.special.cython_special`)
---------------------------------------------------------------------------

.. highlight:: cython

SciPy also offers Cython bindings for scalar, typed versions of many
of the functions in special. The following Cython code gives a simple
example of how to use these functions::

  cimport scipy.special.cython_special as csc

  cdef:
      double x = 1
      double complex z = 1 + 1j
      double si, ci, rgam
      double complex cgam

  rgam = csc.gamma(x)
  print(rgam)
  cgam = csc.gamma(z)
  print(cgam)
  csc.sici(x, &si, &ci)
  print(si, ci)

(See the `Cython documentation`_ for help with compiling Cython.) In
the example the function ``csc.gamma`` works essentially like its
ufunc counterpart `gamma`, though it takes C types as arguments
instead of NumPy arrays. Note, in particular, that the function is
overloaded to support real and complex arguments; the correct variant
is selected at compile time. The function ``csc.sici`` works slightly
differently from `sici`; for the ufunc we could write ``ai, bi =
sici(x)``, whereas in the Cython version multiple return values are
passed as pointers. It might help to think of this as analogous to
calling a ufunc with an output array: ``sici(x, out=(si, ci))``.

There are two potential advantages to using the Cython bindings:

- they avoid Python function overhead
- they do not require the Python Global Interpreter Lock (GIL)

The following sections discuss how to use these advantages to
potentially speed up your code, though, of course, one should always
profile the code first to make sure putting in the extra effort will
be worth it.

Avoiding Python Function Overhead
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For the ufuncs in special, Python function overhead is avoided by
vectorizing, that is, by passing an array to the function. Typically,
this approach works quite well, but sometimes it is more convenient to
call a special function on scalar inputs inside a loop, for example,
when implementing your own ufunc. In this case, the Python function
overhead can become significant. Consider the following example::

  import scipy.special as sc
  cimport scipy.special.cython_special as csc

  def python_tight_loop():
      cdef:
          int n
          double x = 1

      for n in range(100):
          sc.jv(n, x)

  def cython_tight_loop():
      cdef:
          int n
          double x = 1

      for n in range(100):
          csc.jv(n, x)

On one computer ``python_tight_loop`` took about 131 microseconds to
run and ``cython_tight_loop`` took about 18.2 microseconds to
run. Obviously this example is contrived: one could just call
``special.jv(np.arange(100), 1)`` and get results just as fast as in
``cython_tight_loop``. The point is that if Python function overhead
becomes significant in your code, then the Cython bindings might be
useful.

Releasing the GIL
^^^^^^^^^^^^^^^^^

One often needs to evaluate a special function at many points, and
typically the evaluations are trivially parallelizable. Since the
Cython bindings do not require the GIL, it is easy to run them in
parallel using Cython's ``prange`` function. For example, suppose that
we wanted to compute the fundamental solution to the Helmholtz
equation:

.. math::

   \Delta_x G(x, y) + k^2G(x, y) = \delta(x - y),

where :math:`k` is the wavenumber and :math:`\delta` is the Dirac
delta function. It is known that in two dimensions the unique
(radiating) solution is

.. math::

   G(x, y) = \frac{i}{4}H_0^{(1)}(k|x - y|),

where :math:`H_0^{(1)}` is the Hankel function of the first kind,
i.e., the function `hankel1`. The following example shows how we could
compute this function in parallel::

  from libc.math cimport fabs
  cimport cython
  from cython.parallel cimport prange

  import numpy as np
  import scipy.special as sc
  cimport scipy.special.cython_special as csc

  def serial_G(k, x, y):
      return 0.25j*sc.hankel1(0, k*np.abs(x - y))

  @cython.boundscheck(False)
  @cython.wraparound(False)
  cdef void _parallel_G(double k, double[:,:] x, double[:,:] y,
                        double complex[:,:] out) nogil:
      cdef int i, j

      for i in prange(x.shape[0]):
          for j in range(y.shape[0]):
              out[i,j] = 0.25j*csc.hankel1(0, k*fabs(x[i,j] - y[i,j]))

  def parallel_G(k, x, y):
      out = np.empty_like(x, dtype='complex128')
      _parallel_G(k, x, y, out)
      return out

(For help with compiling parallel code in Cython see `here`_.) If the
above Cython code is in a file ``test.pyx``, then we can write an
informal benchmark which compares the parallel and serial versions of
the function::

  import timeit

  import numpy as np

  from test import serial_G, parallel_G

  def main():
      k = 1
      x, y = np.linspace(-100, 100, 1000), np.linspace(-100, 100, 1000)
      x, y = np.meshgrid(x, y)

      def serial():
          serial_G(k, x, y)

      def parallel():
          parallel_G(k, x, y)

      time_serial = timeit.timeit(serial, number=3)
      time_parallel = timeit.timeit(parallel, number=3)
      print("Serial method took {:.3} seconds".format(time_serial))
      print("Parallel method took {:.3} seconds".format(time_parallel))

  if __name__ == "__main__":
      main()

On one quad-core computer the serial method took 1.29 seconds and the
parallel method took 0.29 seconds.


Functions not in :mod:`scipy.special`
-------------------------------------

.. highlight:: python

Some functions are not included in special because they are
straightforward to implement with existing functions in NumPy and
SciPy. To prevent reinventing the wheel, this section provides
implementations of several such functions, which hopefully illustrate
how to handle similar functions. In all examples NumPy is imported as
``np`` and special is imported as ``sc``.

The `binary entropy function`_::

  def binary_entropy(x):
      return -(sc.xlogy(x, x) + sc.xlog1py(1 - x, -x))/np.log(2)

A rectangular step function on [0, 1]::

  def step(x):
      return 0.5*(np.sign(x) + np.sign(1 - x))

Translating and scaling can be used to get an arbitrary step function.

The `ramp function`_::

  def ramp(x):
      return np.maximum(0, x)


.. _Cython documentation: http://docs.cython.org/en/latest/src/reference/compilation.html

.. _here: http://docs.cython.org/en/latest/src/userguide/parallelism.html#compiling

.. _`binary entropy function`: https://en.wikipedia.org/wiki/Binary_entropy_function

.. _`ramp function`: https://en.wikipedia.org/wiki/Ramp_function
========================================
Interpolation (:mod:`scipy.interpolate`)
========================================

.. sectionauthor:: Travis E. Oliphant

.. sectionauthor:: Pauli Virtanen

.. currentmodule:: scipy.interpolate

.. contents::

There are several general interpolation facilities available in SciPy,
for data in 1, 2, and higher dimensions:

- A class representing an interpolant (:class:`interp1d`) in 1-D,
  offering several interpolation methods.

- Convenience function :func:`griddata` offering a simple interface to
  interpolation in N dimensions (N = 1, 2, 3, 4, ...).
  Object-oriented interface for the underlying routines is also
  available.

- Functions for 1- and 2-D (smoothed) cubic-spline
  interpolation, based on the FORTRAN library FITPACK. They are both
  procedural and object-oriented interfaces for the FITPACK library.

- Interpolation using radial basis functions.


1-D interpolation (:class:`interp1d`)
=====================================

The `interp1d` class in `scipy.interpolate` is a convenient method to
create a function based on fixed data points, which can be evaluated
anywhere within the domain defined by the given data using linear
interpolation. An instance of this class is created by passing the 1-D
vectors comprising the data. The instance of this class defines a
__call__ method and can therefore by treated like a function which
interpolates between known data values to obtain unknown values (it
also has a docstring for help). Behavior at the boundary can be
specified at instantiation time. The following example demonstrates
its use, for linear and cubic spline interpolation:

.. plot::

   >>> from scipy.interpolate import interp1d

   >>> x = np.linspace(0, 10, num=11, endpoint=True)
   >>> y = np.cos(-x**2/9.0)
   >>> f = interp1d(x, y)
   >>> f2 = interp1d(x, y, kind='cubic')

   >>> xnew = np.linspace(0, 10, num=41, endpoint=True)
   >>> import matplotlib.pyplot as plt
   >>> plt.plot(x, y, 'o', xnew, f(xnew), '-', xnew, f2(xnew), '--')
   >>> plt.legend(['data', 'linear', 'cubic'], loc='best')
   >>> plt.show()

..   :caption: One-dimensional interpolation using the
..             class :obj:`interpolate.interp1d` with
..             kind equals `linear` and `cubic`.


Another set of interpolations in `interp1d` is `nearest`, `previous`, and
`next`, where they return the nearest, previous, or next point along the
x-axis. Nearest and next can be thought of as a special case of a causal
interpolating filter. The following example demonstrates their use, using the
same data as in the previous example:

.. plot::

   >>> from scipy.interpolate import interp1d

   >>> x = np.linspace(0, 10, num=11, endpoint=True)
   >>> y = np.cos(-x**2/9.0)
   >>> f1 = interp1d(x, y, kind='nearest')
   >>> f2 = interp1d(x, y, kind='previous')
   >>> f3 = interp1d(x, y, kind='next')

   >>> xnew = np.linspace(0, 10, num=1001, endpoint=True)
   >>> import matplotlib.pyplot as plt
   >>> plt.plot(x, y, 'o')
   >>> plt.plot(xnew, f1(xnew), '-', xnew, f2(xnew), '--', xnew, f3(xnew), ':')
   >>> plt.legend(['data', 'nearest', 'previous', 'next'], loc='best')
   >>> plt.show()

..   :caption: One-dimensional interpolation using the
..             class :obj:`interpolate.interp1d` with
..             kind equals `nearest`, `previous`, and
..             `next`.


Multivariate data interpolation (:func:`griddata`)
==================================================

Suppose you have multidimensional data, for instance, for an underlying
function *f(x, y)* you only know the values at points *(x[i], y[i])*
that do not form a regular grid.

.. plot::

    Suppose we want to interpolate the 2-D function

    >>> def func(x, y):
    ...     return x*(1-x)*np.cos(4*np.pi*x) * np.sin(4*np.pi*y**2)**2

    on a grid in [0, 1]x[0, 1]

    >>> grid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]

    but we only know its values at 1000 data points:

    >>> rng = np.random.default_rng()
    >>> points = rng.random((1000, 2))
    >>> values = func(points[:,0], points[:,1])

    This can be done with `griddata` -- below, we try out all of the
    interpolation methods:

    >>> from scipy.interpolate import griddata
    >>> grid_z0 = griddata(points, values, (grid_x, grid_y), method='nearest')
    >>> grid_z1 = griddata(points, values, (grid_x, grid_y), method='linear')
    >>> grid_z2 = griddata(points, values, (grid_x, grid_y), method='cubic')

    One can see that the exact result is reproduced by all of the
    methods to some degree, but for this smooth function the piecewise
    cubic interpolant gives the best results:

    >>> import matplotlib.pyplot as plt
    >>> plt.subplot(221)
    >>> plt.imshow(func(grid_x, grid_y).T, extent=(0,1,0,1), origin='lower')
    >>> plt.plot(points[:,0], points[:,1], 'k.', ms=1)
    >>> plt.title('Original')
    >>> plt.subplot(222)
    >>> plt.imshow(grid_z0.T, extent=(0,1,0,1), origin='lower')
    >>> plt.title('Nearest')
    >>> plt.subplot(223)
    >>> plt.imshow(grid_z1.T, extent=(0,1,0,1), origin='lower')
    >>> plt.title('Linear')
    >>> plt.subplot(224)
    >>> plt.imshow(grid_z2.T, extent=(0,1,0,1), origin='lower')
    >>> plt.title('Cubic')
    >>> plt.gcf().set_size_inches(6, 6)
    >>> plt.show()


Spline interpolation
====================

.. _tutorial-interpolate_splXXX:

Spline interpolation in 1-D: Procedural (interpolate.splXXX)
------------------------------------------------------------

Spline interpolation requires two essential steps: (1) a spline
representation of the curve is computed, and (2) the spline is
evaluated at the desired points. In order to find the spline
representation, there are two different ways to represent a curve and
obtain (smoothing) spline coefficients: directly and parametrically.
The direct method finds the spline representation of a curve in a 2-D
plane using the function :obj:`splrep`. The
first two arguments are the only ones required, and these provide the
:math:`x` and :math:`y` components of the curve. The normal output is
a 3-tuple, :math:`\left(t,c,k\right)` , containing the knot-points,
:math:`t` , the coefficients :math:`c` and the order :math:`k` of the
spline. The default spline order is cubic, but this can be changed
with the input keyword, *k.*

For curves in N-D space the function
:obj:`splprep` allows defining the curve
parametrically. For this function only 1 input argument is
required. This input is a list of :math:`N`-arrays representing the
curve in N-D space. The length of each array is the
number of curve points, and each array provides one component of the
N-D data point. The parameter variable is given
with the keyword argument, *u,*, which defaults to an equally-spaced
monotonic sequence between :math:`0` and :math:`1` . The default
output consists of two objects: a 3-tuple, :math:`\left(t,c,k\right)`
, containing the spline representation and the parameter variable
:math:`u.`

The keyword argument, *s* , is used to specify the amount of smoothing
to perform during the spline fit. The default value of :math:`s` is
:math:`s=m-\sqrt{2m}` where :math:`m` is the number of data-points
being fit. Therefore, **if no smoothing is desired a value of**
:math:`\mathbf{s}=0` **should be passed to the routines.**

Once the spline representation of the data has been determined,
functions are available for evaluating the spline
(:func:`splev`) and its derivatives
(:func:`splev`, :func:`spalde`) at any point
and the integral of the spline between any two points (
:func:`splint`). In addition, for cubic splines ( :math:`k=3`
) with 8 or more knots, the roots of the spline can be estimated (
:func:`sproot`). These functions are demonstrated in the
example that follows.

.. plot::

   >>> import numpy as np
   >>> import matplotlib.pyplot as plt
   >>> from scipy import interpolate

   Cubic-spline

   >>> x = np.arange(0, 2*np.pi+np.pi/4, 2*np.pi/8)
   >>> y = np.sin(x)
   >>> tck = interpolate.splrep(x, y, s=0)
   >>> xnew = np.arange(0, 2*np.pi, np.pi/50)
   >>> ynew = interpolate.splev(xnew, tck, der=0)

   >>> plt.figure()
   >>> plt.plot(x, y, 'x', xnew, ynew, xnew, np.sin(xnew), x, y, 'b')
   >>> plt.legend(['Linear', 'Cubic Spline', 'True'])
   >>> plt.axis([-0.05, 6.33, -1.05, 1.05])
   >>> plt.title('Cubic-spline interpolation')
   >>> plt.show()

   Derivative of spline

   >>> yder = interpolate.splev(xnew, tck, der=1)
   >>> plt.figure()
   >>> plt.plot(xnew, yder, xnew, np.cos(xnew),'--')
   >>> plt.legend(['Cubic Spline', 'True'])
   >>> plt.axis([-0.05, 6.33, -1.05, 1.05])
   >>> plt.title('Derivative estimation from spline')
   >>> plt.show()

   All derivatives of spline

   >>> yders = interpolate.spalde(xnew, tck)
   >>> plt.figure()
   >>> for i in range(len(yders[0])):
   ...    plt.plot(xnew, [d[i] for d in yders], '--', label=f"{i} derivative")
   >>> plt.legend()
   >>> plt.axis([-0.05, 6.33, -1.05, 1.05])
   >>> plt.title('All derivatives of a B-spline')
   >>> plt.show()

   Integral of spline

   >>> def integ(x, tck, constant=-1):
   ...     x = np.atleast_1d(x)
   ...     out = np.zeros(x.shape, dtype=x.dtype)
   ...     for n in range(len(out)):
   ...         out[n] = interpolate.splint(0, x[n], tck)
   ...     out += constant
   ...     return out

   >>> yint = integ(xnew, tck)
   >>> plt.figure()
   >>> plt.plot(xnew, yint, xnew, -np.cos(xnew), '--')
   >>> plt.legend(['Cubic Spline', 'True'])
   >>> plt.axis([-0.05, 6.33, -1.05, 1.05])
   >>> plt.title('Integral estimation from spline')
   >>> plt.show()

   Roots of spline

   >>> interpolate.sproot(tck)
   array([3.1416])  # may vary

   Notice that `sproot` may fail to find an obvious solution at the edge of the
   approximation interval, :math:`x = 0`. If we define the spline on a slightly
   larger interval, we recover both roots :math:`x = 0` and :math:`x = 2\pi`:

   >>> x = np.linspace(-np.pi/4, 2.*np.pi + np.pi/4, 21)
   >>> y = np.sin(x)
   >>> tck = interpolate.splrep(x, y, s=0)
   >>> interpolate.sproot(tck)
   array([0., 3.1416])

   Parametric spline

   >>> t = np.arange(0, 1.1, .1)
   >>> x = np.sin(2*np.pi*t)
   >>> y = np.cos(2*np.pi*t)
   >>> tck, u = interpolate.splprep([x, y], s=0)
   >>> unew = np.arange(0, 1.01, 0.01)
   >>> out = interpolate.splev(unew, tck)
   >>> plt.figure()
   >>> plt.plot(x, y, 'x', out[0], out[1], np.sin(2*np.pi*unew), np.cos(2*np.pi*unew), x, y, 'b')
   >>> plt.legend(['Linear', 'Cubic Spline', 'True'])
   >>> plt.axis([-1.05, 1.05, -1.05, 1.05])
   >>> plt.title('Spline of parametrically-defined curve')
   >>> plt.show()

Spline interpolation in 1-d: Object-oriented (:class:`UnivariateSpline`)
------------------------------------------------------------------------

The spline-fitting capabilities described above are also available via
an objected-oriented interface.  The 1-D splines are
objects of the `UnivariateSpline` class, and are created with the
:math:`x` and :math:`y` components of the curve provided as arguments
to the constructor.  The class defines :meth:`__call__ <UnivariateSpline.__call__>`, allowing the object
to be called with the x-axis values, at which the spline should be
evaluated, returning the interpolated y-values.  This is shown in
the example below for the subclass `InterpolatedUnivariateSpline`.
The :meth:`integral <UnivariateSpline.integral>`,
:meth:`derivatives <UnivariateSpline.derivatives>`, and
:meth:`roots <UnivariateSpline.roots>` methods are also available
on `UnivariateSpline` objects, allowing definite integrals,
derivatives, and roots to be computed for the spline.

The UnivariateSpline class can also be used to smooth data by
providing a non-zero value of the smoothing parameter `s`, with the
same meaning as the `s` keyword of the :obj:`splrep` function
described above.  This results in a spline that has fewer knots
than the number of data points, and hence is no longer strictly
an interpolating spline, but rather a smoothing spline.  If this
is not desired, the `InterpolatedUnivariateSpline` class is available.
It is a subclass of `UnivariateSpline` that always passes through all
points (equivalent to forcing the smoothing parameter to 0). This
class is demonstrated in the example below.

The `LSQUnivariateSpline` class is the other subclass of `UnivariateSpline`.
It allows the user to specify the number and location of internal
knots explicitly with the parameter `t`.  This allows for the creation
of customized splines with non-linear spacing, to interpolate in
some domains and smooth in others, or change the character of the
spline.


.. plot::

   >>> import numpy as np
   >>> import matplotlib.pyplot as plt
   >>> from scipy import interpolate

   InterpolatedUnivariateSpline

   >>> x = np.arange(0, 2*np.pi+np.pi/4, 2*np.pi/8)
   >>> y = np.sin(x)
   >>> s = interpolate.InterpolatedUnivariateSpline(x, y)
   >>> xnew = np.arange(0, 2*np.pi, np.pi/50)
   >>> ynew = s(xnew)

   >>> plt.figure()
   >>> plt.plot(x, y, 'x', xnew, ynew, xnew, np.sin(xnew), x, y, 'b')
   >>> plt.legend(['Linear', 'InterpolatedUnivariateSpline', 'True'])
   >>> plt.axis([-0.05, 6.33, -1.05, 1.05])
   >>> plt.title('InterpolatedUnivariateSpline')
   >>> plt.show()

   LSQUnivarateSpline with non-uniform knots

   >>> t = [np.pi/2-.1, np.pi/2+.1, 3*np.pi/2-.1, 3*np.pi/2+.1]
   >>> s = interpolate.LSQUnivariateSpline(x, y, t, k=2)
   >>> ynew = s(xnew)

   >>> plt.figure()
   >>> plt.plot(x, y, 'x', xnew, ynew, xnew, np.sin(xnew), x, y, 'b')
   >>> plt.legend(['Linear', 'LSQUnivariateSpline', 'True'])
   >>> plt.axis([-0.05, 6.33, -1.05, 1.05])
   >>> plt.title('Spline with Specified Interior Knots')
   >>> plt.show()

.. _tutorial-interpolate_2d_spline:

2-D spline representation: Procedural (:func:`bisplrep`)
--------------------------------------------------------------------

For (smooth) spline-fitting to a 2-D surface, the function
:func:`bisplrep` is available. This function takes as required inputs
the **1-D** arrays *x*, *y*, and *z*, which represent points on the
surface :math:`z=f\left(x,y\right).` The default output is a list
:math:`\left[tx,ty,c,kx,ky\right]` whose entries represent
respectively, the components of the knot positions, the coefficients
of the spline, and the order of the spline in each coordinate. It is
convenient to hold this list in a single object, *tck,* so that it can
be passed easily to the function :obj:`bisplev`. The
keyword, *s* , can be used to change the amount of smoothing performed
on the data while determining the appropriate spline. The default
value is :math:`s=m-\sqrt{2m}`, where :math:`m` is the number of data
points in the *x, y,* and *z* vectors. As a result, if no smoothing is
desired, then :math:`s=0` should be passed to
:obj:`bisplrep`.

To evaluate the 2-D spline and its partial derivatives
(up to the order of the spline), the function
:obj:`bisplev` is required. This function takes as the
first two arguments **two 1-D arrays** whose cross-product specifies
the domain over which to evaluate the spline. The third argument is
the *tck* list returned from :obj:`bisplrep`. If desired,
the fourth and fifth arguments provide the orders of the partial
derivative in the :math:`x` and :math:`y` direction, respectively.

It is important to note that 2-D interpolation should not
be used to find the spline representation of images. The algorithm
used is not amenable to large numbers of input points. The signal-processing
toolbox contains more appropriate algorithms for finding
the spline representation of an image. The 2-D
interpolation commands are intended for use when interpolating a 2-D
function as shown in the example that follows. This
example uses the :obj:`mgrid <numpy.mgrid>` command in NumPy which is
useful for defining a "mesh-grid" in many dimensions. (See also the
:obj:`ogrid <numpy.ogrid>` command if the full-mesh is not
needed). The number of output arguments and the number of dimensions
of each argument is determined by the number of indexing objects
passed in :obj:`mgrid <numpy.mgrid>`.

.. plot::

   >>> import numpy as np
   >>> from scipy import interpolate
   >>> import matplotlib.pyplot as plt

   Define function over a sparse 20x20 grid

   >>> x_edges, y_edges = np.mgrid[-1:1:21j, -1:1:21j]
   >>> x = x_edges[:-1, :-1] + np.diff(x_edges[:2, 0])[0] / 2.
   >>> y = y_edges[:-1, :-1] + np.diff(y_edges[0, :2])[0] / 2.
   >>> z = (x+y) * np.exp(-6.0*(x*x+y*y))

   >>> plt.figure()
   >>> lims = dict(cmap='RdBu_r', vmin=-0.25, vmax=0.25)
   >>> plt.pcolormesh(x_edges, y_edges, z, shading='flat', **lims)
   >>> plt.colorbar()
   >>> plt.title("Sparsely sampled function.")
   >>> plt.show()

   Interpolate function over a new 70x70 grid

   >>> xnew_edges, ynew_edges = np.mgrid[-1:1:71j, -1:1:71j]
   >>> xnew = xnew_edges[:-1, :-1] + np.diff(xnew_edges[:2, 0])[0] / 2.
   >>> ynew = ynew_edges[:-1, :-1] + np.diff(ynew_edges[0, :2])[0] / 2.
   >>> tck = interpolate.bisplrep(x, y, z, s=0)
   >>> znew = interpolate.bisplev(xnew[:,0], ynew[0,:], tck)

   >>> plt.figure()
   >>> plt.pcolormesh(xnew_edges, ynew_edges, znew, shading='flat', **lims)
   >>> plt.colorbar()
   >>> plt.title("Interpolated function.")
   >>> plt.show()

..   :caption: Example of a 2-D spline interpolation.


2-D spline representation: Object-oriented (:class:`BivariateSpline`)
---------------------------------------------------------------------------------

The :class:`BivariateSpline` class is the 2-D analog of the
:class:`UnivariateSpline` class.  It and its subclasses implement
the FITPACK functions described above in an object-oriented fashion,
allowing objects to be instantiated that can be called to compute
the spline value by passing in the two coordinates as the two
arguments.


Using radial basis functions for smoothing/interpolation
========================================================

Radial basis functions can be used for smoothing/interpolating scattered
data in N dimensions, but should be used with caution for extrapolation
outside of the observed data range.

1-D Example
-----------

This example compares the usage of the `Rbf` and `UnivariateSpline` classes
from the scipy.interpolate module.

.. plot::

    >>> import numpy as np
    >>> from scipy.interpolate import Rbf, InterpolatedUnivariateSpline
    >>> import matplotlib.pyplot as plt

    >>> # setup data
    >>> x = np.linspace(0, 10, 9)
    >>> y = np.sin(x)
    >>> xi = np.linspace(0, 10, 101)

    >>> # use fitpack2 method
    >>> ius = InterpolatedUnivariateSpline(x, y)
    >>> yi = ius(xi)

    >>> plt.subplot(2, 1, 1)
    >>> plt.plot(x, y, 'bo')
    >>> plt.plot(xi, yi, 'g')
    >>> plt.plot(xi, np.sin(xi), 'r')
    >>> plt.title('Interpolation using univariate spline')

    >>> # use RBF method
    >>> rbf = Rbf(x, y)
    >>> fi = rbf(xi)

    >>> plt.subplot(2, 1, 2)
    >>> plt.plot(x, y, 'bo')
    >>> plt.plot(xi, fi, 'g')
    >>> plt.plot(xi, np.sin(xi), 'r')
    >>> plt.title('Interpolation using RBF - multiquadrics')
    >>> plt.show()

..   :caption: Example of a 1-D RBF interpolation.

2-D Example
-----------

This example shows how to interpolate scattered 2-D data:

.. plot::

    >>> import numpy as np
    >>> from scipy.interpolate import Rbf
    >>> import matplotlib.pyplot as plt
    >>> from matplotlib import cm

    >>> # 2-d tests - setup scattered data
    >>> rng = np.random.default_rng()
    >>> x = rng.random(100)*4.0-2.0
    >>> y = rng.random(100)*4.0-2.0
    >>> z = x*np.exp(-x**2-y**2)
    >>> edges = np.linspace(-2.0, 2.0, 101)
    >>> centers = edges[:-1] + np.diff(edges[:2])[0] / 2.
    >>> XI, YI = np.meshgrid(centers, centers)

    >>> # use RBF
    >>> rbf = Rbf(x, y, z, epsilon=2)
    >>> ZI = rbf(XI, YI)

    >>> # plot the result
    >>> plt.subplot(1, 1, 1)
    >>> X_edges, Y_edges = np.meshgrid(edges, edges)
    >>> lims = dict(cmap='RdBu_r', vmin=-0.4, vmax=0.4)
    >>> plt.pcolormesh(X_edges, Y_edges, ZI, shading='flat', **lims)
    >>> plt.scatter(x, y, 100, z, edgecolor='w', lw=0.1, **lims)
    >>> plt.title('RBF interpolation - multiquadrics')
    >>> plt.xlim(-2, 2)
    >>> plt.ylim(-2, 2)
    >>> plt.colorbar()
Multidimensional image processing (`scipy.ndimage`)
====================================================

.. moduleauthor:: Peter Verveer <verveer@users.sourceforge.net>

.. currentmodule:: scipy.ndimage

.. _ndimage-introduction:

Introduction
------------

Image processing and analysis are generally seen as operations on
2-D arrays of values. There are, however, a number of
fields where images of higher dimensionality must be analyzed. Good
examples of these are medical imaging and biological imaging.
:mod:`numpy` is suited very well for this type of applications due to
its inherent multidimensional nature. The :mod:`scipy.ndimage`
packages provides a number of general image processing and analysis
functions that are designed to operate with arrays of arbitrary
dimensionality. The packages currently includes: functions for
linear and non-linear filtering, binary morphology, B-spline
interpolation, and object measurements.

.. _ndimage-properties-shared-by-all-functions:

Properties shared by all functions
----------------------------------

All functions share some common properties. Notably, all functions
allow the specification of an output array with the *output*
argument. With this argument, you can specify an array that will be
changed in-place with the result with the operation. In this case,
the result is not returned. Usually, using the *output* argument is
more efficient, since an existing array is used to store the
result.

The type of arrays returned is dependent on the type of operation,
but it is, in most cases, equal to the type of the input. If,
however, the *output* argument is used, the type of the result is
equal to the type of the specified output argument. If no output
argument is given, it is still possible to specify what the result
of the output should be. This is done by simply assigning the
desired `numpy` type object to the output argument. For example:

.. code:: python

    >>> from scipy.ndimage import correlate
    >>> correlate(np.arange(10), [1, 2.5])
    array([ 0,  2,  6,  9, 13, 16, 20, 23, 27, 30])
    >>> correlate(np.arange(10), [1, 2.5], output=np.float64)
    array([  0. ,   2.5,   6. ,   9.5,  13. ,  16.5,  20. ,  23.5,  27. ,  30.5])

.. _ndimage-filter-functions:

Filter functions
----------------

The functions described in this section all perform some type of spatial
filtering of the input array: the elements in the output are some function
of the values in the neighborhood of the corresponding input element. We refer
to this neighborhood of elements as the filter kernel, which is often
rectangular in shape but may also have an arbitrary footprint. Many
of the functions described below allow you to define the footprint
of the kernel by passing a mask through the *footprint* parameter.
For example, a cross-shaped kernel can be defined as follows:

.. code:: python

    >>> footprint = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
    >>> footprint
    array([[0, 1, 0],
           [1, 1, 1],
           [0, 1, 0]])

Usually, the origin of the kernel is at the center calculated by
dividing the dimensions of the kernel shape by two. For instance,
the origin of a 1-D kernel of length three is at the
second element. Take, for example, the correlation of a
1-D array with a filter of length 3 consisting of
ones:

.. code:: python

    >>> from scipy.ndimage import correlate1d
    >>> a = [0, 0, 0, 1, 0, 0, 0]
    >>> correlate1d(a, [1, 1, 1])
    array([0, 0, 1, 1, 1, 0, 0])

Sometimes, it is convenient to choose a different origin for the
kernel. For this reason, most functions support the *origin*
parameter, which gives the origin of the filter relative to its
center. For example:

.. code:: python

    >>> a = [0, 0, 0, 1, 0, 0, 0]
    >>> correlate1d(a, [1, 1, 1], origin = -1)
    array([0, 1, 1, 1, 0, 0, 0])

The effect is a shift of the result towards the left. This feature
will not be needed very often, but it may be useful, especially for
filters that have an even size. A good example is the calculation
of backward and forward differences:

.. code:: python

    >>> a = [0, 0, 1, 1, 1, 0, 0]
    >>> correlate1d(a, [-1, 1])               # backward difference
    array([ 0,  0,  1,  0,  0, -1,  0])
    >>> correlate1d(a, [-1, 1], origin = -1)  # forward difference
    array([ 0,  1,  0,  0, -1,  0,  0])

We could also have calculated the forward difference as follows:

.. code:: python

    >>> correlate1d(a, [0, -1, 1])
    array([ 0,  1,  0,  0, -1,  0,  0])

However, using the origin parameter instead of a larger kernel is
more efficient. For multidimensional kernels, *origin* can be a
number, in which case the origin is assumed to be equal along all
axes, or a sequence giving the origin along each axis.

Since the output elements are a function of elements in the
neighborhood of the input elements, the borders of the array need to
be dealt with appropriately by providing the values outside the
borders. This is done by assuming that the arrays are extended beyond
their boundaries according to certain boundary conditions. In the
functions described below, the boundary conditions can be selected
using the *mode* parameter, which must be a string with the name of the
boundary condition. The following boundary conditions are currently
supported:

 ==========   ====================================   ====================
  **mode**              **description**                  **example**
 ==========   ====================================   ====================
 "nearest"    use the value at the boundary          [1 2 3]->[1 1 2 3 3]
 "wrap"       periodically replicate the array       [1 2 3]->[3 1 2 3 1]
 "reflect"    reflect the array at the boundary      [1 2 3]->[1 1 2 3 3]
 "mirror"     mirror the array at the boundary       [1 2 3]->[2 1 2 3 2]
 "constant"   use a constant value, default is 0.0   [1 2 3]->[0 1 2 3 0]
 ==========   ====================================   ====================

The following synonyms are also supported for consistency with the
interpolation routines:

 ===============   =========================
     **mode**           **description**
 ===============   =========================
 "grid-constant"   equivalent to "constant"*
 "grid-mirror"     equivalent to "reflect"
 "grid-wrap"       equivalent to "wrap"
 ===============   =========================

\* "grid-constant" and "constant" are equivalent for filtering operations, but
have different behavior in interpolation functions. For API consistency, the
filtering functions accept either name.

The "constant" mode is special since it needs an additional parameter to
specify the constant value that should be used.

Note that modes mirror and reflect differ only in whether the sample at the
boundary is repeated upon reflection. For mode mirror, the point of symmetry is
exactly at the final sample, so that value is not repeated. This mode is also
known as whole-sample symmetric since the point of symmetry falls on the final
sample. Similarly, reflect is often refered to as half-sample symmetric as the
point of symmetry is half a sample beyond the array boundary.

.. note::

   The easiest way to implement such boundary conditions would be to
   copy the data to a larger array and extend the data at the borders
   according to the boundary conditions. For large arrays and large
   filter kernels, this would be very memory consuming, and the
   functions described below, therefore, use a different approach that
   does not require allocating large temporary buffers.

Correlation and convolution
^^^^^^^^^^^^^^^^^^^^^^^^^^^

- The :func:`correlate1d` function calculates a 1-D
  correlation along the given axis. The lines of the array along the
  given axis are correlated with the given *weights*. The *weights*
  parameter must be a 1-D sequence of numbers.

- The function :func:`correlate` implements multidimensional
  correlation of the input array with a given kernel.

- The :func:`convolve1d` function calculates a 1-D
  convolution along the given axis. The lines of the array along the
  given axis are convoluted with the given *weights*. The *weights*
  parameter must be a 1-D sequence of numbers.

- The function :func:`convolve` implements multidimensional
  convolution of the input array with a given kernel.

  .. note::

     A convolution is essentially a correlation after mirroring the
     kernel. As a result, the *origin* parameter behaves differently
     than in the case of a correlation: the results is shifted in the
     opposite direction.

.. _ndimage-filter-functions-smoothing:

Smoothing filters
^^^^^^^^^^^^^^^^^

- The :func:`gaussian_filter1d` function implements a 1-D
  Gaussian filter. The standard deviation of the Gaussian filter is
  passed through the parameter *sigma*. Setting *order* = 0
  corresponds to convolution with a Gaussian kernel. An order of 1, 2,
  or 3 corresponds to convolution with the first, second, or third
  derivatives of a Gaussian. Higher-order derivatives are not
  implemented. 



- The :func:`gaussian_filter` function implements a multidimensional
  Gaussian filter. The standard deviations of the Gaussian filter
  along each axis are passed through the parameter *sigma* as a
  sequence or numbers. If *sigma* is not a sequence but a single
  number, the standard deviation of the filter is equal along all
  directions. The order of the filter can be specified separately for
  each axis. An order of 0 corresponds to convolution with a Gaussian
  kernel. An order of 1, 2, or 3 corresponds to convolution with the
  first, second, or third derivatives of a Gaussian. Higher-order
  derivatives are not implemented. The *order* parameter must be a
  number, to specify the same order for all axes, or a sequence of
  numbers to specify a different order for each axis. The example below
  shows the filter applied on test data with different values of *sigma*.
  The *order* parameter is kept at 0. 

  .. plot:: tutorial/examples/gaussian_filter_plot1.py
      :align: center
      :include-source: 0

  .. note::

     The multidimensional filter is implemented as a sequence of
     1-D Gaussian filters. The intermediate arrays are
     stored in the same data type as the output. Therefore, for
     output types with a lower precision, the results may be imprecise
     because intermediate results may be stored with insufficient
     precision. This can be prevented by specifying a more precise
     output type.

- The :func:`uniform_filter1d` function calculates a 1-D
  uniform filter of the given *size* along the given axis.

- The :func:`uniform_filter` implements a multidimensional uniform
  filter. The sizes of the uniform filter are given for each axis as a
  sequence of integers by the *size* parameter. If *size* is not a
  sequence, but a single number, the sizes along all axes are assumed
  to be equal.

  .. note::

     The multidimensional filter is implemented as a sequence of
     1-D uniform filters. The intermediate arrays are
     stored in the same data type as the output. Therefore, for output
     types with a lower precision, the results may be imprecise
     because intermediate results may be stored with insufficient
     precision. This can be prevented by specifying a more precise
     output type.

Filters based on order statistics
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

- The :func:`minimum_filter1d` function calculates a 1-D
  minimum filter of the given *size* along the given axis.

- The :func:`maximum_filter1d` function calculates a 1-D
  maximum filter of the given *size* along the given axis.

- The :func:`minimum_filter` function calculates a multidimensional
  minimum filter. Either the sizes of a rectangular kernel or the
  footprint of the kernel must be provided. The *size* parameter, if
  provided, must be a sequence of sizes or a single number, in which
  case the size of the filter is assumed to be equal along each axis.
  The *footprint*, if provided, must be an array that defines the
  shape of the kernel by its non-zero elements.

- The :func:`maximum_filter` function calculates a multidimensional
  maximum filter. Either the sizes of a rectangular kernel or the
  footprint of the kernel must be provided. The *size* parameter, if
  provided, must be a sequence of sizes or a single number, in which
  case the size of the filter is assumed to be equal along each axis.
  The *footprint*, if provided, must be an array that defines the
  shape of the kernel by its non-zero elements.

- The :func:`rank_filter` function calculates a multidimensional rank
  filter. The *rank* may be less than zero, i.e., *rank* = -1
  indicates the largest element. Either the sizes of a rectangular
  kernel or the footprint of the kernel must be provided. The *size*
  parameter, if provided, must be a sequence of sizes or a single
  number, in which case the size of the filter is assumed to be equal
  along each axis. The *footprint*, if provided, must be an array that
  defines the shape of the kernel by its non-zero elements.

- The :func:`percentile_filter` function calculates a multidimensional
  percentile filter. The *percentile* may be less than zero, i.e.,
  *percentile* = -20 equals *percentile* = 80. Either the sizes of a
  rectangular kernel or the footprint of the kernel must be provided.
  The *size* parameter, if provided, must be a sequence of sizes or a
  single number, in which case the size of the filter is assumed to be
  equal along each axis. The *footprint*, if provided, must be an
  array that defines the shape of the kernel by its non-zero elements.

- The :func:`median_filter` function calculates a multidimensional
  median filter. Either the sizes of a rectangular kernel or the
  footprint of the kernel must be provided. The *size* parameter, if
  provided, must be a sequence of sizes or a single number, in which
  case the size of the filter is assumed to be equal along each
  axis. The *footprint* if provided, must be an array that defines the
  shape of the kernel by its non-zero elements.

Derivatives
^^^^^^^^^^^

Derivative filters can be constructed in several ways. The function
:func:`gaussian_filter1d`, described in
:ref:`ndimage-filter-functions-smoothing`, can be used to calculate
derivatives along a given axis using the *order* parameter. Other
derivative filters are the Prewitt and Sobel filters:

- The :func:`prewitt` function calculates a derivative along the given
  axis.
- The :func:`sobel` function calculates a derivative along the given
  axis.

The Laplace filter is calculated by the sum of the second derivatives
along all axes. Thus, different Laplace filters can be constructed
using different second-derivative functions. Therefore, we provide a
general function that takes a function argument to calculate the
second derivative along a given direction.

- The function :func:`generic_laplace` calculates a Laplace filter
  using the function passed through ``derivative2`` to calculate
  second derivatives. The function ``derivative2`` should have the
  following signature

  .. code:: python

     derivative2(input, axis, output, mode, cval, *extra_arguments, **extra_keywords)

  It should calculate the second derivative along the dimension
  *axis*. If *output* is not ``None``, it should use that for the
  output and return ``None``, otherwise it should return the
  result. *mode*, *cval* have the usual meaning.

  The *extra_arguments* and *extra_keywords* arguments can be used
  to pass a tuple of extra arguments and a dictionary of named
  arguments that are passed to ``derivative2`` at each call.

  For example

  .. code:: python

     >>> def d2(input, axis, output, mode, cval):
     ...     return correlate1d(input, [1, -2, 1], axis, output, mode, cval, 0)
     ...
     >>> a = np.zeros((5, 5))
     >>> a[2, 2] = 1
     >>> from scipy.ndimage import generic_laplace
     >>> generic_laplace(a, d2)
     array([[ 0.,  0.,  0.,  0.,  0.],
	    [ 0.,  0.,  1.,  0.,  0.],
	    [ 0.,  1., -4.,  1.,  0.],
            [ 0.,  0.,  1.,  0.,  0.],
            [ 0.,  0.,  0.,  0.,  0.]])

  To demonstrate the use of the *extra_arguments* argument, we could do

  .. code:: python

     >>> def d2(input, axis, output, mode, cval, weights):
     ...     return correlate1d(input, weights, axis, output, mode, cval, 0,)
     ...
     >>> a = np.zeros((5, 5))
     >>> a[2, 2] = 1
     >>> generic_laplace(a, d2, extra_arguments = ([1, -2, 1],))
     array([[ 0.,  0.,  0.,  0.,  0.],
	    [ 0.,  0.,  1.,  0.,  0.],
            [ 0.,  1., -4.,  1.,  0.],
            [ 0.,  0.,  1.,  0.,  0.],
            [ 0.,  0.,  0.,  0.,  0.]])

  or

  .. code:: python

     >>> generic_laplace(a, d2, extra_keywords = {'weights': [1, -2, 1]})
     array([[ 0.,  0.,  0.,  0.,  0.],
	    [ 0.,  0.,  1.,  0.,  0.],
	    [ 0.,  1., -4.,  1.,  0.],
	    [ 0.,  0.,  1.,  0.,  0.],
	    [ 0.,  0.,  0.,  0.,  0.]])

The following two functions are implemented using
:func:`generic_laplace` by providing appropriate functions for the
second-derivative function:

- The function :func:`laplace` calculates the Laplace using discrete
  differentiation for the second derivative (i.e., convolution with
  ``[1, -2, 1]``).

- The function :func:`gaussian_laplace` calculates the Laplace filter
  using :func:`gaussian_filter` to calculate the second
  derivatives. The standard deviations of the Gaussian filter along
  each axis are passed through the parameter *sigma* as a sequence or
  numbers. If *sigma* is not a sequence but a single number, the
  standard deviation of the filter is equal along all directions.

The gradient magnitude is defined as the square root of the sum of the
squares of the gradients in all directions. Similar to the generic
Laplace function, there is a :func:`generic_gradient_magnitude`
function that calculates the gradient magnitude of an array.

- The function :func:`generic_gradient_magnitude` calculates a
  gradient magnitude using the function passed through
  ``derivative`` to calculate first derivatives. The function
  ``derivative`` should have the following signature

  .. code:: python

     derivative(input, axis, output, mode, cval, *extra_arguments, **extra_keywords)

  It should calculate the derivative along the dimension *axis*. If
  *output* is not ``None``, it should use that for the output and return
  ``None``, otherwise it should return the result. *mode*, *cval* have the
  usual meaning.

  The *extra_arguments* and *extra_keywords* arguments can be used to
  pass a tuple of extra arguments and a dictionary of named arguments
  that are passed to *derivative* at each call.

  For example, the :func:`sobel` function fits the required signature

  .. code:: python

     >>> a = np.zeros((5, 5))
     >>> a[2, 2] = 1
     >>> from scipy.ndimage import sobel, generic_gradient_magnitude
     >>> generic_gradient_magnitude(a, sobel)
     array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],
	    [ 0.        ,  1.41421356,  2.        ,  1.41421356,  0.        ],
            [ 0.        ,  2.        ,  0.        ,  2.        ,  0.        ],
            [ 0.        ,  1.41421356,  2.        ,  1.41421356,  0.        ],
            [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])

  See the documentation of :func:`generic_laplace` for examples of
  using the *extra_arguments* and *extra_keywords* arguments.

The :func:`sobel` and :func:`prewitt` functions fit the required
signature and can, therefore, be used directly with
:func:`generic_gradient_magnitude`.

- The function :func:`gaussian_gradient_magnitude` calculates the
  gradient magnitude using :func:`gaussian_filter` to calculate the
  first derivatives. The standard deviations of the Gaussian filter
  along each axis are passed through the parameter *sigma* as a
  sequence or numbers. If *sigma* is not a sequence but a single
  number, the standard deviation of the filter is equal along all
  directions.

.. _ndimage-genericfilters:

Generic filter functions
^^^^^^^^^^^^^^^^^^^^^^^^

To implement filter functions, generic functions can be used that
accept a callable object that implements the filtering operation. The
iteration over the input and output arrays is handled by these generic
functions, along with such details as the implementation of the
boundary conditions. Only a callable object implementing a callback
function that does the actual filtering work must be provided. The
callback function can also be written in C and passed using a
:c:type:`PyCapsule` (see :ref:`ndimage-ccallbacks` for more
information).

- The :func:`generic_filter1d` function implements a generic
  1-D filter function, where the actual filtering
  operation must be supplied as a python function (or other callable
  object). The :func:`generic_filter1d` function iterates over the
  lines of an array and calls ``function`` at each line. The
  arguments that are passed to ``function`` are 1-D
  arrays of the ``numpy.float64`` type. The first contains the values
  of the current line. It is extended at the beginning and the end,
  according to the *filter_size* and *origin* arguments. The second
  array should be modified in-place to provide the output values of
  the line. For example, consider a correlation along one dimension:

  .. code:: python

     >>> a = np.arange(12).reshape(3,4)
     >>> correlate1d(a, [1, 2, 3])
     array([[ 3,  8, 14, 17],
	    [27, 32, 38, 41],
            [51, 56, 62, 65]])

  The same operation can be implemented using :func:`generic_filter1d`,
  as follows:

  .. code:: python

     >>> def fnc(iline, oline):
     ...     oline[...] = iline[:-2] + 2 * iline[1:-1] + 3 * iline[2:]
     ...
     >>> from scipy.ndimage import generic_filter1d
     >>> generic_filter1d(a, fnc, 3)
     array([[ 3,  8, 14, 17],
	    [27, 32, 38, 41],
            [51, 56, 62, 65]])

  Here, the origin of the kernel was (by default) assumed to be in the
  middle of the filter of length 3. Therefore, each input line had been
  extended by one value at the beginning and at the end, before the
  function was called.

  Optionally, extra arguments can be defined and passed to the filter
  function. The *extra_arguments* and *extra_keywords* arguments can
  be used to pass a tuple of extra arguments and/or a dictionary of
  named arguments that are passed to derivative at each call. For
  example, we can pass the parameters of our filter as an argument

  .. code:: python

     >>> def fnc(iline, oline, a, b):
     ...     oline[...] = iline[:-2] + a * iline[1:-1] + b * iline[2:]
     ...
     >>> generic_filter1d(a, fnc, 3, extra_arguments = (2, 3))
     array([[ 3,  8, 14, 17],
	    [27, 32, 38, 41],
            [51, 56, 62, 65]])

  or

  .. code:: python

     >>> generic_filter1d(a, fnc, 3, extra_keywords = {'a':2, 'b':3})
     array([[ 3,  8, 14, 17],
	    [27, 32, 38, 41],
            [51, 56, 62, 65]])

- The :func:`generic_filter` function implements a generic filter
  function, where the actual filtering operation must be supplied as a
  python function (or other callable object). The
  :func:`generic_filter` function iterates over the array and calls
  ``function`` at each element. The argument of ``function``
  is a 1-D array of the ``numpy.float64`` type that
  contains the values around the current element that are within the
  footprint of the filter. The function should return a single value
  that can be converted to a double precision number. For example,
  consider a correlation:

  .. code:: python

     >>> a = np.arange(12).reshape(3,4)
     >>> correlate(a, [[1, 0], [0, 3]])
     array([[ 0,  3,  7, 11],
	    [12, 15, 19, 23],
            [28, 31, 35, 39]])

  The same operation can be implemented using *generic_filter*, as
  follows:

  .. code:: python

     >>> def fnc(buffer):
     ...     return (buffer * np.array([1, 3])).sum()
     ...
     >>> from scipy.ndimage import generic_filter
     >>> generic_filter(a, fnc, footprint = [[1, 0], [0, 1]])
     array([[ 0,  3,  7, 11],
	    [12, 15, 19, 23],
            [28, 31, 35, 39]])

  Here, a kernel footprint was specified that contains only two
  elements. Therefore, the filter function receives a buffer of length
  equal to two, which was multiplied with the proper weights and the
  result summed.

  When calling :func:`generic_filter`, either the sizes of a
  rectangular kernel or the footprint of the kernel must be
  provided. The *size* parameter, if provided, must be a sequence of
  sizes or a single number, in which case the size of the filter is
  assumed to be equal along each axis. The *footprint*, if provided,
  must be an array that defines the shape of the kernel by its
  non-zero elements.

  Optionally, extra arguments can be defined and passed to the filter
  function. The *extra_arguments* and *extra_keywords* arguments can
  be used to pass a tuple of extra arguments and/or a dictionary of
  named arguments that are passed to derivative at each call. For
  example, we can pass the parameters of our filter as an argument

  .. code:: python

     >>> def fnc(buffer, weights):
     ...     weights = np.asarray(weights)
     ...     return (buffer * weights).sum()
     ...
     >>> generic_filter(a, fnc, footprint = [[1, 0], [0, 1]], extra_arguments = ([1, 3],))
     array([[ 0,  3,  7, 11],
	    [12, 15, 19, 23],
            [28, 31, 35, 39]])

  or

  .. code:: python

     >>> generic_filter(a, fnc, footprint = [[1, 0], [0, 1]], extra_keywords= {'weights': [1, 3]})
     array([[ 0,  3,  7, 11],
	    [12, 15, 19, 23],
	    [28, 31, 35, 39]])

These functions iterate over the lines or elements starting at the
last axis, i.e., the last index changes the fastest. This order of
iteration is guaranteed for the case that it is important to adapt the
filter depending on spatial location. Here is an example of using a
class that implements the filter and keeps track of the current
coordinates while iterating. It performs the same filter operation as
described above for :func:`generic_filter`, but additionally prints
the current coordinates:

.. code:: python

   >>> a = np.arange(12).reshape(3,4)
   >>>
   >>> class fnc_class:
   ...     def __init__(self, shape):
   ...         # store the shape:
   ...         self.shape = shape
   ...         # initialize the coordinates:
   ...         self.coordinates = [0] * len(shape)
   ...
   ...     def filter(self, buffer):
   ...         result = (buffer * np.array([1, 3])).sum()
   ...         print(self.coordinates)
   ...         # calculate the next coordinates:
   ...         axes = list(range(len(self.shape)))
   ...         axes.reverse()
   ...         for jj in axes:
   ...             if self.coordinates[jj] < self.shape[jj] - 1:
   ...                 self.coordinates[jj] += 1
   ...                 break
   ...             else:
   ...                 self.coordinates[jj] = 0
   ...         return result
   ...
   >>> fnc = fnc_class(shape = (3,4))
   >>> generic_filter(a, fnc.filter, footprint = [[1, 0], [0, 1]])
   [0, 0]
   [0, 1]
   [0, 2]
   [0, 3]
   [1, 0]
   [1, 1]
   [1, 2]
   [1, 3]
   [2, 0]
   [2, 1]
   [2, 2]
   [2, 3]
   array([[ 0,  3,  7, 11],
	  [12, 15, 19, 23],
	  [28, 31, 35, 39]])

For the :func:`generic_filter1d` function, the same approach works,
except that this function does not iterate over the axis that is being
filtered. The example for :func:`generic_filter1d` then becomes this:

.. code:: python

   >>> a = np.arange(12).reshape(3,4)
   >>>
   >>> class fnc1d_class:
   ...     def __init__(self, shape, axis = -1):
   ...         # store the filter axis:
   ...         self.axis = axis
   ...         # store the shape:
   ...         self.shape = shape
   ...         # initialize the coordinates:
   ...         self.coordinates = [0] * len(shape)
   ...
   ...     def filter(self, iline, oline):
   ...         oline[...] = iline[:-2] + 2 * iline[1:-1] + 3 * iline[2:]
   ...         print(self.coordinates)
   ...         # calculate the next coordinates:
   ...         axes = list(range(len(self.shape)))
   ...         # skip the filter axis:
   ...         del axes[self.axis]
   ...         axes.reverse()
   ...         for jj in axes:
   ...             if self.coordinates[jj] < self.shape[jj] - 1:
   ...                 self.coordinates[jj] += 1
   ...                 break
   ...             else:
   ...                 self.coordinates[jj] = 0
   ...
   >>> fnc = fnc1d_class(shape = (3,4))
   >>> generic_filter1d(a, fnc.filter, 3)
   [0, 0]
   [1, 0]
   [2, 0]
   array([[ 3,  8, 14, 17],
	  [27, 32, 38, 41],
          [51, 56, 62, 65]])

Fourier domain filters
^^^^^^^^^^^^^^^^^^^^^^

The functions described in this section perform filtering
operations in the Fourier domain. Thus, the input array of such a
function should be compatible with an inverse Fourier transform
function, such as the functions from the :mod:`numpy.fft` module. We,
therefore, have to deal with arrays that may be the result of a real
or a complex Fourier transform. In the case of a real Fourier
transform, only half of the of the symmetric complex transform is
stored. Additionally, it needs to be known what the length of the
axis was that was transformed by the real fft. The functions
described here provide a parameter *n* that, in the case of a real
transform, must be equal to the length of the real transform axis
before transformation. If this parameter is less than zero, it is
assumed that the input array was the result of a complex Fourier
transform. The parameter *axis* can be used to indicate along which
axis the real transform was executed.

- The :func:`fourier_shift` function multiplies the input array with
  the multidimensional Fourier transform of a shift operation for the
  given shift. The *shift* parameter is a sequence of shifts for each
  dimension or a single value for all dimensions.

- The :func:`fourier_gaussian` function multiplies the input array
  with the multidimensional Fourier transform of a Gaussian filter
  with given standard deviations *sigma*. The *sigma* parameter is a
  sequence of values for each dimension or a single value for all
  dimensions.

- The :func:`fourier_uniform` function multiplies the input array with
  the multidimensional Fourier transform of a uniform filter with
  given sizes *size*. The *size* parameter is a sequence of values
  for each dimension or a single value for all dimensions.

- The :func:`fourier_ellipsoid` function multiplies the input array
  with the multidimensional Fourier transform of an elliptically-shaped
  filter with given sizes *size*. The *size* parameter is a sequence
  of values for each dimension or a single value for all dimensions.
  This function is only implemented for dimensions 1, 2, and 3.

.. _ndimage-interpolation:

Interpolation functions
-----------------------

This section describes various interpolation functions that are based
on B-spline theory. A good introduction to B-splines can be found
in [1]_ with detailed algorithms for image interpolation given in [5]_.

Spline pre-filters
^^^^^^^^^^^^^^^^^^

Interpolation using splines of an order larger than 1 requires a
pre-filtering step. The interpolation functions described in section
:ref:`ndimage-interpolation` apply pre-filtering by calling
:func:`spline_filter`, but they can be instructed not to do this by
setting the *prefilter* keyword equal to False. This is useful if more
than one interpolation operation is done on the same array. In this
case, it is more efficient to do the pre-filtering only once and use a
pre-filtered array as the input of the interpolation functions. The
following two functions implement the pre-filtering:

- The :func:`spline_filter1d` function calculates a 1-D
  spline filter along the given axis. An output array can optionally
  be provided. The order of the spline must be larger than 1 and less
  than 6.

- The :func:`spline_filter` function calculates a multidimensional
  spline filter.

  .. note::

     The multidimensional filter is implemented as a sequence of
     1-D spline filters. The intermediate arrays are
     stored in the same data type as the output. Therefore, if an
     output with a limited precision is requested, the results may be
     imprecise because intermediate results may be stored with
     insufficient precision. This can be prevented by specifying a
     output type of high precision.

.. _ndimage-interpolation-modes:

Interpolation boundary handling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The interpolation functions all employ spline interpolation to effect some
type of geometric transformation of the input array. This requires a
mapping of the output coordinates to the input coordinates, and
therefore, the possibility arises that input values outside the
boundaries may be needed. This problem is solved in the same way as
described in :ref:`ndimage-filter-functions` for the multidimensional
filter functions. Therefore, these functions all support a *mode*
parameter that determines how the boundaries are handled, and a *cval*
parameter that gives a constant value in case that the 'constant' mode
is used. The behavior of all modes, including at non-integer locations is
illustrated below. Note the boundaries are not handled the same for all modes;
`reflect` (aka `grid-mirror`) and `grid-wrap` involve symmetry or repetition
about a point that is half way between image samples (dashed vertical lines)
while modes `mirror` and `wrap` treat the image as if it's extent ends exactly
at the first and last sample point rather than 0.5 samples past it.

.. plot:: tutorial/examples/plot_boundary_modes.py
   :include-source: False

The coordinates of image samples fall on integer sampling locations
in the range from 0 to ``shape[i] - 1`` along each axis, ``i``. The figure
below illustrates the interpolation of a point at location ``(3.7, 3.3)``
within an image of shape ``(7, 7)``. For an interpolation of order ``n``,
``n + 1`` samples are involved along each axis. The filled circles
illustrate the sampling locations involved in the interpolation of the value at
the location of the red x.

.. plot:: tutorial/examples/plot_interp_grid.py
   :include-source: False


Interpolation functions
^^^^^^^^^^^^^^^^^^^^^^^

- The :func:`geometric_transform` function applies an arbitrary
  geometric transform to the input. The given *mapping* function is
  called at each point in the output to find the corresponding
  coordinates in the input. *mapping* must be a callable object that
  accepts a tuple of length equal to the output array rank and returns
  the corresponding input coordinates as a tuple of length equal to
  the input array rank. The output shape and output type can
  optionally be provided. If not given, they are equal to the input
  shape and type.

  For example:

  .. code:: python

     >>> a = np.arange(12).reshape(4,3).astype(np.float64)
     >>> def shift_func(output_coordinates):
     ...     return (output_coordinates[0] - 0.5, output_coordinates[1] - 0.5)
     ...
     >>> from scipy.ndimage import geometric_transform
     >>> geometric_transform(a, shift_func)
     array([[ 0.    ,  0.    ,  0.    ],
	    [ 0.    ,  1.3625,  2.7375],
            [ 0.    ,  4.8125,  6.1875],
            [ 0.    ,  8.2625,  9.6375]])

  Optionally, extra arguments can be defined and passed to the filter
  function. The *extra_arguments* and *extra_keywords* arguments can
  be used to pass a tuple of extra arguments and/or a dictionary of
  named arguments that are passed to derivative at each call. For
  example, we can pass the shifts in our example as arguments

  .. code:: python

     >>> def shift_func(output_coordinates, s0, s1):
     ...     return (output_coordinates[0] - s0, output_coordinates[1] - s1)
     ...
     >>> geometric_transform(a, shift_func, extra_arguments = (0.5, 0.5))
     array([[ 0.    ,  0.    ,  0.    ],
	    [ 0.    ,  1.3625,  2.7375],
            [ 0.    ,  4.8125,  6.1875],
            [ 0.    ,  8.2625,  9.6375]])

  or

  .. code:: python

     >>> geometric_transform(a, shift_func, extra_keywords = {'s0': 0.5, 's1': 0.5})
     array([[ 0.    ,  0.    ,  0.    ],
	    [ 0.    ,  1.3625,  2.7375],
	    [ 0.    ,  4.8125,  6.1875],
	    [ 0.    ,  8.2625,  9.6375]])

  .. note::

     The mapping function can also be written in C and passed using a
     `scipy.LowLevelCallable`. See :ref:`ndimage-ccallbacks` for more
     information.

- The function :func:`map_coordinates` applies an arbitrary coordinate
  transformation using the given array of coordinates. The shape of
  the output is derived from that of the coordinate array by dropping
  the first axis. The parameter *coordinates* is used to find for each
  point in the output the corresponding coordinates in the input. The
  values of *coordinates* along the first axis are the coordinates in
  the input array at which the output value is found. (See also the
  numarray `coordinates` function.) Since the coordinates may be non-
  integer coordinates, the value of the input at these coordinates is
  determined by spline interpolation of the requested order.

  Here is an example that interpolates a 2D array at ``(0.5, 0.5)`` and
  ``(1, 2)``:

  .. code:: python

     >>> a = np.arange(12).reshape(4,3).astype(np.float64)
     >>> a
     array([[  0.,   1.,   2.],
	    [  3.,   4.,   5.],
	    [  6.,   7.,   8.],
	    [  9.,  10.,  11.]])
     >>> from scipy.ndimage import map_coordinates
     >>> map_coordinates(a, [[0.5, 2], [0.5, 1]])
     array([ 1.3625,  7.])

- The :func:`affine_transform` function applies an affine
  transformation to the input array. The given transformation *matrix*
  and *offset* are used to find for each point in the output the
  corresponding coordinates in the input. The value of the input at
  the calculated coordinates is determined by spline interpolation of
  the requested order. The transformation *matrix* must be
  2-D or can also be given as a 1-D sequence
  or array. In the latter case, it is assumed that the matrix is
  diagonal. A more efficient interpolation algorithm is then applied
  that exploits the separability of the problem. The output shape and
  output type can optionally be provided. If not given, they are equal
  to the input shape and type.

- The :func:`shift` function returns a shifted version of the input,
  using spline interpolation of the requested *order*.

- The :func:`zoom` function returns a rescaled version of the input,
  using spline interpolation of the requested *order*.

- The :func:`rotate` function returns the input array rotated in the
  plane defined by the two axes given by the parameter *axes*, using
  spline interpolation of the requested *order*. The angle must be
  given in degrees. If *reshape* is true, then the size of the output
  array is adapted to contain the rotated input.

.. _ndimage-morphology:

Morphology
----------

.. _ndimage-binary-morphology:

Binary morphology
^^^^^^^^^^^^^^^^^

- The :func:`generate_binary_structure` functions generates a binary
  structuring element for use in binary morphology operations. The
  *rank* of the structure must be provided. The size of the structure
  that is returned is equal to three in each direction. The value of
  each element is equal to one if the square of the Euclidean distance
  from the element to the center is less than or equal to
  *connectivity*. For instance, 2-D 4-connected and
  8-connected structures are generated as follows:

  .. code:: python

     >>> from scipy.ndimage import generate_binary_structure
     >>> generate_binary_structure(2, 1)
     array([[False,  True, False],
	    [ True,  True,  True],
            [False,  True, False]], dtype=bool)
     >>> generate_binary_structure(2, 2)
     array([[ True,  True,  True],
	    [ True,  True,  True],
            [ True,  True,  True]], dtype=bool)

This is a viusal presentation of `generate_binary_structure` in 3D:

  .. plot:: tutorial/examples/ndimage/3D_binary_structure.py
      :align: center
      :include-source: 0

Most binary morphology functions can be expressed in terms of the
basic operations erosion and dilation, which can be seen here:

  .. plot:: tutorial/examples/morphology_binary_dilation_erosion.py
      :align: center
      :include-source: 0

- The :func:`binary_erosion` function implements binary erosion of
  arrays of arbitrary rank with the given structuring element. The
  origin parameter controls the placement of the structuring element,
  as described in :ref:`ndimage-filter-functions`. If no structuring
  element is provided, an element with connectivity equal to one is
  generated using :func:`generate_binary_structure`. The
  *border_value* parameter gives the value of the array outside
  boundaries. The erosion is repeated *iterations* times. If
  *iterations* is less than one, the erosion is repeated until the
  result does not change anymore. If a *mask* array is given, only
  those elements with a true value at the corresponding mask element
  are modified at each iteration.

- The :func:`binary_dilation` function implements binary dilation of
  arrays of arbitrary rank with the given structuring element. The
  origin parameter controls the placement of the structuring element,
  as described in :ref:`ndimage-filter-functions`. If no structuring
  element is provided, an element with connectivity equal to one is
  generated using :func:`generate_binary_structure`. The
  *border_value* parameter gives the value of the array outside
  boundaries. The dilation is repeated *iterations* times. If
  *iterations* is less than one, the dilation is repeated until the
  result does not change anymore. If a *mask* array is given, only
  those elements with a true value at the corresponding mask element
  are modified at each iteration.

Here is an example of using :func:`binary_dilation` to find all elements
that touch the border, by repeatedly dilating an empty array from
the border using the data array as the mask:

.. code:: python

   >>> struct = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
   >>> a = np.array([[1,0,0,0,0], [1,1,0,1,0], [0,0,1,1,0], [0,0,0,0,0]])
   >>> a
   array([[1, 0, 0, 0, 0],
	  [1, 1, 0, 1, 0],
          [0, 0, 1, 1, 0],
          [0, 0, 0, 0, 0]])
   >>> from scipy.ndimage import binary_dilation
   >>> binary_dilation(np.zeros(a.shape), struct, -1, a, border_value=1)
   array([[ True, False, False, False, False],
	  [ True,  True, False, False, False],
          [False, False, False, False, False],
          [False, False, False, False, False]], dtype=bool)

The :func:`binary_erosion` and :func:`binary_dilation` functions both
have an *iterations* parameter, which allows the erosion or dilation to
be repeated a number of times. Repeating an erosion or a dilation with
a given structure *n* times is equivalent to an erosion or a dilation
with a structure that is *n-1* times dilated with itself. A function
is provided that allows the calculation of a structure that is dilated
a number of times with itself:

- The :func:`iterate_structure` function returns a structure by dilation
  of the input structure *iteration* - 1 times with itself.

  For instance:

  .. code:: python

     >>> struct = generate_binary_structure(2, 1)
     >>> struct
     array([[False,  True, False],
	    [ True,  True,  True],
	    [False,  True, False]], dtype=bool)
     >>> from scipy.ndimage import iterate_structure
     >>> iterate_structure(struct, 2)
     array([[False, False,  True, False, False],
	    [False,  True,  True,  True, False],
	    [ True,  True,  True,  True,  True],
	    [False,  True,  True,  True, False],
            [False, False,  True, False, False]], dtype=bool)

     If the origin of the original structure is equal to 0, then it is
     also equal to 0 for the iterated structure. If not, the origin
     must also be adapted if the equivalent of the *iterations*
     erosions or dilations must be achieved with the iterated
     structure. The adapted origin is simply obtained by multiplying
     with the number of iterations. For convenience, the
     :func:`iterate_structure` also returns the adapted origin if the
     *origin* parameter is not ``None``:

     .. code:: python

	>>> iterate_structure(struct, 2, -1)
	(array([[False, False,  True, False, False],
	        [False,  True,  True,  True, False],
		[ True,  True,  True,  True,  True],
		[False,  True,  True,  True, False],
		[False, False,  True, False, False]], dtype=bool), [-2, -2])

Other morphology operations can be defined in terms of erosion and
dilation. The following functions provide a few of these operations
for convenience:

- The :func:`binary_opening` function implements binary opening of
  arrays of arbitrary rank with the given structuring element. Binary
  opening is equivalent to a binary erosion followed by a binary
  dilation with the same structuring element. The origin parameter
  controls the placement of the structuring element, as described in
  :ref:`ndimage-filter-functions`. If no structuring element is
  provided, an element with connectivity equal to one is generated
  using :func:`generate_binary_structure`. The *iterations* parameter
  gives the number of erosions that is performed followed by the same
  number of dilations.

- The :func:`binary_closing` function implements binary closing of
  arrays of arbitrary rank with the given structuring element. Binary
  closing is equivalent to a binary dilation followed by a binary
  erosion with the same structuring element. The origin parameter
  controls the placement of the structuring element, as described in
  :ref:`ndimage-filter-functions`. If no structuring element is
  provided, an element with connectivity equal to one is generated
  using :func:`generate_binary_structure`. The *iterations* parameter
  gives the number of dilations that is performed followed by the same
  number of erosions.

- The :func:`binary_fill_holes` function is used to close holes in
  objects in a binary image, where the structure defines the
  connectivity of the holes. The origin parameter controls the
  placement of the structuring element, as described in
  :ref:`ndimage-filter-functions`. If no structuring element is
  provided, an element with connectivity equal to one is generated
  using :func:`generate_binary_structure`.

- The :func:`binary_hit_or_miss` function implements a binary
  hit-or-miss transform of arrays of arbitrary rank with the given
  structuring elements. The hit-or-miss transform is calculated by
  erosion of the input with the first structure, erosion of the
  logical *not* of the input with the second structure, followed by
  the logical *and* of these two erosions. The origin parameters
  control the placement of the structuring elements, as described in
  :ref:`ndimage-filter-functions`. If *origin2* equals ``None``, it is set
  equal to the *origin1* parameter. If the first structuring element
  is not provided, a structuring element with connectivity equal to
  one is generated using :func:`generate_binary_structure`. If
  *structure2* is not provided, it is set equal to the logical *not*
  of *structure1*.

.. _ndimage-grey-morphology:

Grey-scale morphology
^^^^^^^^^^^^^^^^^^^^^

Grey-scale morphology operations are the equivalents of binary
morphology operations that operate on arrays with arbitrary values.
Below, we describe the grey-scale equivalents of erosion, dilation,
opening and closing. These operations are implemented in a similar
fashion as the filters described in :ref:`ndimage-filter-functions`,
and we refer to this section for the description of filter kernels and
footprints, and the handling of array borders. The grey-scale
morphology operations optionally take a *structure* parameter that
gives the values of the structuring element. If this parameter is not
given, the structuring element is assumed to be flat with a value equal
to zero. The shape of the structure can optionally be defined by the
*footprint* parameter. If this parameter is not given, the structure
is assumed to be rectangular, with sizes equal to the dimensions of
the *structure* array, or by the *size* parameter if *structure* is
not given. The *size* parameter is only used if both *structure* and
*footprint* are not given, in which case the structuring element is
assumed to be rectangular and flat with the dimensions given by
*size*. The *size* parameter, if provided, must be a sequence of sizes
or a single number in which case the size of the filter is assumed to
be equal along each axis. The *footprint* parameter, if provided, must
be an array that defines the shape of the kernel by its non-zero
elements.

Similarly to binary erosion and dilation, there are operations for
grey-scale erosion and dilation:

- The :func:`grey_erosion` function calculates a multidimensional
  grey-scale erosion.

- The :func:`grey_dilation` function calculates a multidimensional
  grey-scale dilation.

Grey-scale opening and closing operations can be defined similarly to
their binary counterparts:

- The :func:`grey_opening` function implements grey-scale opening of
  arrays of arbitrary rank. Grey-scale opening is equivalent to a
  grey-scale erosion followed by a grey-scale dilation.

- The :func:`grey_closing` function implements grey-scale closing of
  arrays of arbitrary rank. Grey-scale opening is equivalent to a
  grey-scale dilation followed by a grey-scale erosion.

- The :func:`morphological_gradient` function implements a grey-scale
  morphological gradient of arrays of arbitrary rank. The grey-scale
  morphological gradient is equal to the difference of a grey-scale
  dilation and a grey-scale erosion.

- The :func:`morphological_laplace` function implements a grey-scale
  morphological laplace of arrays of arbitrary rank. The grey-scale
  morphological laplace is equal to the sum of a grey-scale dilation
  and a grey-scale erosion minus twice the input.

- The :func:`white_tophat` function implements a white top-hat filter
  of arrays of arbitrary rank. The white top-hat is equal to the
  difference of the input and a grey-scale opening.

- The :func:`black_tophat` function implements a black top-hat filter
  of arrays of arbitrary rank. The black top-hat is equal to the
  difference of a grey-scale closing and the input.

.. _ndimage-distance-transforms:

Distance transforms
-------------------

Distance transforms are used to calculate the minimum distance from
each element of an object to the background. The following functions
implement distance transforms for three different distance metrics:
Euclidean, city block, and chessboard distances.

- The function :func:`distance_transform_cdt` uses a chamfer type
  algorithm to calculate the distance transform of the input, by
  replacing each object element (defined by values larger than zero)
  with the shortest distance to the background (all non-object
  elements). The structure determines the type of chamfering that is
  done. If the structure is equal to 'cityblock', a structure is
  generated using :func:`generate_binary_structure` with a squared
  distance equal to 1. If the structure is equal to 'chessboard', a
  structure is generated using :func:`generate_binary_structure` with
  a squared distance equal to the rank of the array. These choices
  correspond to the common interpretations of the city block and the
  chessboard distance metrics in two dimensions.

  In addition to the distance transform, the feature transform can be
  calculated. In this case, the index of the closest background element
  is returned along the first axis of the result. The
  *return_distances*, and *return_indices* flags can be used to
  indicate if the distance transform, the feature transform, or both
  must be returned.

  The *distances* and *indices* arguments can be used to give optional
  output arrays that must be of the correct size and type (both
  ``numpy.int32``). The basics of the algorithm used to implement this
  function are described in [2]_.

- The function :func:`distance_transform_edt` calculates the exact
  Euclidean distance transform of the input, by replacing each object
  element (defined by values larger than zero) with the shortest
  Euclidean distance to the background (all non-object elements).

  In addition to the distance transform, the feature transform can be
  calculated. In this case, the index of the closest background element
  is returned along the first axis of the result. The
  *return_distances* and *return_indices* flags can be used to
  indicate if the distance transform, the feature transform, or both
  must be returned.

  Optionally, the sampling along each axis can be given by the
  *sampling* parameter, which should be a sequence of length equal to
  the input rank, or a single number in which the sampling is assumed
  to be equal along all axes.

  The *distances* and *indices* arguments can be used to give optional
  output arrays that must be of the correct size and type
  (``numpy.float64`` and ``numpy.int32``).The algorithm used to
  implement this function is described in [3]_.

- The function :func:`distance_transform_bf` uses a brute-force
  algorithm to calculate the distance transform of the input, by
  replacing each object element (defined by values larger than zero)
  with the shortest distance to the background (all non-object
  elements). The metric must be one of "euclidean", "cityblock", or
  "chessboard".

  In addition to the distance transform, the feature transform can be
  calculated. In this case, the index of the closest background element
  is returned along the first axis of the result. The
  *return_distances* and *return_indices* flags can be used to
  indicate if the distance transform, the feature transform, or both
  must be returned.

  Optionally, the sampling along each axis can be given by the
  *sampling* parameter, which should be a sequence of length equal to
  the input rank, or a single number in which the sampling is assumed
  to be equal along all axes. This parameter is only used in the case
  of the Euclidean distance transform.

  The *distances* and *indices* arguments can be used to give optional
  output arrays that must be of the correct size and type
  (``numpy.float64`` and ``numpy.int32``).

  .. note::

     This function uses a slow brute-force algorithm, the function
     :func:`distance_transform_cdt` can be used to more efficiently
     calculate city block and chessboard distance transforms. The
     function :func:`distance_transform_edt` can be used to more
     efficiently calculate the exact Euclidean distance transform.

Segmentation and labeling
-------------------------

Segmentation is the process of separating objects of interest from
the background. The most simple approach is, probably, intensity
thresholding, which is easily done with :mod:`numpy` functions:

.. code:: python

   >>> a = np.array([[1,2,2,1,1,0],
   ...               [0,2,3,1,2,0],
   ...               [1,1,1,3,3,2],
   ...               [1,1,1,1,2,1]])
   >>> np.where(a > 1, 1, 0)
   array([[0, 1, 1, 0, 0, 0],
	  [0, 1, 1, 0, 1, 0],
	  [0, 0, 0, 1, 1, 1],
	  [0, 0, 0, 0, 1, 0]])

The result is a binary image, in which the individual objects still
need to be identified and labeled. The function :func:`label`
generates an array where each object is assigned a unique number:

- The :func:`label` function generates an array where the objects in
  the input are labeled with an integer index. It returns a tuple
  consisting of the array of object labels and the number of objects
  found, unless the *output* parameter is given, in which case only
  the number of objects is returned. The connectivity of the objects
  is defined by a structuring element. For instance, in 2D
  using a 4-connected structuring element gives:

  .. code:: python

     >>> a = np.array([[0,1,1,0,0,0],[0,1,1,0,1,0],[0,0,0,1,1,1],[0,0,0,0,1,0]])
     >>> s = [[0, 1, 0], [1,1,1], [0,1,0]]
     >>> from scipy.ndimage import label
     >>> label(a, s)
     (array([[0, 1, 1, 0, 0, 0],
	     [0, 1, 1, 0, 2, 0],
	     [0, 0, 0, 2, 2, 2],
	     [0, 0, 0, 0, 2, 0]]), 2)

  These two objects are not connected because there is no way in which
  we can place the structuring element, such that it overlaps with both
  objects. However, an 8-connected structuring element results in only
  a single object:

  .. code:: python

     >>> a = np.array([[0,1,1,0,0,0],[0,1,1,0,1,0],[0,0,0,1,1,1],[0,0,0,0,1,0]])
     >>> s = [[1,1,1], [1,1,1], [1,1,1]]
     >>> label(a, s)[0]
     array([[0, 1, 1, 0, 0, 0],
	    [0, 1, 1, 0, 1, 0],
            [0, 0, 0, 1, 1, 1],
            [0, 0, 0, 0, 1, 0]])

  If no structuring element is provided, one is generated by calling
  :func:`generate_binary_structure` (see
  :ref:`ndimage-binary-morphology`) using a connectivity of one (which
  in 2D is the 4-connected structure of the first example). The input
  can be of any type, any value not equal to zero is taken to be part
  of an object. This is useful if you need to 're-label' an array of
  object indices, for instance, after removing unwanted objects. Just
  apply the label function again to the index array. For instance:

  .. code:: python

     >>> l, n = label([1, 0, 1, 0, 1])
     >>> l
     array([1, 0, 2, 0, 3])
     >>> l = np.where(l != 2, l, 0)
     >>> l
     array([1, 0, 0, 0, 3])
     >>> label(l)[0]
     array([1, 0, 0, 0, 2])

  .. note::

     The structuring element used by :func:`label` is assumed to be
     symmetric.

There is a large number of other approaches for segmentation, for
instance, from an estimation of the borders of the objects that can be
obtained by derivative filters. One such approach is
watershed segmentation. The function :func:`watershed_ift` generates
an array where each object is assigned a unique label, from an array
that localizes the object borders, generated, for instance, by a
gradient magnitude filter. It uses an array containing initial markers
for the objects:

- The :func:`watershed_ift` function applies a watershed from markers
  algorithm, using Image Foresting Transform, as described in
  [4]_.

- The inputs of this function are the array to which the transform is
  applied, and an array of markers that designate the objects by a
  unique label, where any non-zero value is a marker. For instance:

  .. code:: python

     >>> input = np.array([[0, 0, 0, 0, 0, 0, 0],
     ...                   [0, 1, 1, 1, 1, 1, 0],
     ...                   [0, 1, 0, 0, 0, 1, 0],
     ...                   [0, 1, 0, 0, 0, 1, 0],
     ...                   [0, 1, 0, 0, 0, 1, 0],
     ...                   [0, 1, 1, 1, 1, 1, 0],
     ...                   [0, 0, 0, 0, 0, 0, 0]], np.uint8)
     >>> markers = np.array([[1, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 2, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0]], np.int8)
     >>> from scipy.ndimage import watershed_ift
     >>> watershed_ift(input, markers)
     array([[1, 1, 1, 1, 1, 1, 1],
	    [1, 1, 2, 2, 2, 1, 1],
            [1, 2, 2, 2, 2, 2, 1],
            [1, 2, 2, 2, 2, 2, 1],
            [1, 2, 2, 2, 2, 2, 1],
            [1, 1, 2, 2, 2, 1, 1],
            [1, 1, 1, 1, 1, 1, 1]], dtype=int8)

  Here, two markers were used to designate an object (*marker* = 2) and
  the background (*marker* = 1). The order in which these are
  processed is arbitrary: moving the marker for the background to the
  lower-right corner of the array yields a different result:

  .. code:: python

     >>> markers = np.array([[0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 2, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 1]], np.int8)
     >>> watershed_ift(input, markers)
     array([[1, 1, 1, 1, 1, 1, 1],
	    [1, 1, 1, 1, 1, 1, 1],
	    [1, 1, 2, 2, 2, 1, 1],
	    [1, 1, 2, 2, 2, 1, 1],
            [1, 1, 2, 2, 2, 1, 1],
            [1, 1, 1, 1, 1, 1, 1],
            [1, 1, 1, 1, 1, 1, 1]], dtype=int8)

  The result is that the object (*marker* = 2) is smaller because the
  second marker was processed earlier. This may not be the desired
  effect if the first marker was supposed to designate a background
  object. Therefore, :func:`watershed_ift` treats markers with a
  negative value explicitly as background markers and processes them
  after the normal markers. For instance, replacing the first marker
  by a negative marker gives a result similar to the first example:

  .. code:: python

     >>> markers = np.array([[0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 2, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, 0],
     ...                     [0, 0, 0, 0, 0, 0, -1]], np.int8)
     >>> watershed_ift(input, markers)
     array([[-1, -1, -1, -1, -1, -1, -1],
	    [-1, -1,  2,  2,  2, -1, -1],
	    [-1,  2,  2,  2,  2,  2, -1],
	    [-1,  2,  2,  2,  2,  2, -1],
            [-1,  2,  2,  2,  2,  2, -1],
            [-1, -1,  2,  2,  2, -1, -1],
            [-1, -1, -1, -1, -1, -1, -1]], dtype=int8)

  The connectivity of the objects is defined by a structuring
  element. If no structuring element is provided, one is generated by
  calling :func:`generate_binary_structure` (see
  :ref:`ndimage-binary-morphology`) using a connectivity of one (which
  in 2D is a 4-connected structure.) For example, using an 8-connected
  structure with the last example yields a different object:

  .. code:: python

     >>> watershed_ift(input, markers,
     ...               structure = [[1,1,1], [1,1,1], [1,1,1]])
     array([[-1, -1, -1, -1, -1, -1, -1],
	    [-1,  2,  2,  2,  2,  2, -1],
            [-1,  2,  2,  2,  2,  2, -1],
            [-1,  2,  2,  2,  2,  2, -1],
            [-1,  2,  2,  2,  2,  2, -1],
            [-1,  2,  2,  2,  2,  2, -1],
            [-1, -1, -1, -1, -1, -1, -1]], dtype=int8)

  .. note::

     The implementation of :func:`watershed_ift` limits the data types
     of the input to ``numpy.uint8`` and ``numpy.uint16``.

.. _ndimage-object-measurements:

Object measurements
-------------------

Given an array of labeled objects, the properties of the individual
objects can be measured. The :func:`find_objects` function can be used
to generate a list of slices that for each object, give the
smallest sub-array that fully contains the object:

- The :func:`find_objects` function finds all objects in a labeled
  array and returns a list of slices that correspond to the smallest
  regions in the array that contains the object.

  For instance:

  .. code:: python

     >>> a = np.array([[0,1,1,0,0,0],[0,1,1,0,1,0],[0,0,0,1,1,1],[0,0,0,0,1,0]])
     >>> l, n = label(a)
     >>> from scipy.ndimage import find_objects
     >>> f = find_objects(l)
     >>> a[f[0]]
     array([[1, 1],
	    [1, 1]])
     >>> a[f[1]]
     array([[0, 1, 0],
	    [1, 1, 1],
	    [0, 1, 0]])

  The function :func:`find_objects` returns slices for all objects,
  unless the *max_label* parameter is larger then zero, in which case
  only the first *max_label* objects are returned. If an index is
  missing in the *label* array, ``None`` is return instead of a
  slice. For example:

  .. code:: python

     >>> from scipy.ndimage import find_objects
     >>> find_objects([1, 0, 3, 4], max_label = 3)
     [(slice(0, 1, None),), None, (slice(2, 3, None),)]

The list of slices generated by :func:`find_objects` is useful to find
the position and dimensions of the objects in the array, but can also
be used to perform measurements on the individual objects. Say, we want
to find the sum of the intensities of an object in image:

.. code:: python

   >>> image = np.arange(4 * 6).reshape(4, 6)
   >>> mask = np.array([[0,1,1,0,0,0],[0,1,1,0,1,0],[0,0,0,1,1,1],[0,0,0,0,1,0]])
   >>> labels = label(mask)[0]
   >>> slices = find_objects(labels)

Then we can calculate the sum of the elements in the second object:

.. code:: python

   >>> np.where(labels[slices[1]] == 2, image[slices[1]], 0).sum()
   80

That is, however, not particularly efficient and may also be more
complicated for other types of measurements. Therefore, a few
measurements functions are defined that accept the array of object
labels and the index of the object to be measured. For instance,
calculating the sum of the intensities can be done by:

.. code:: python

   >>> from scipy.ndimage import sum as ndi_sum
   >>> ndi_sum(image, labels, 2)
   80

For large arrays and small objects, it is more efficient to call the
measurement functions after slicing the array:

.. code:: python

   >>> ndi_sum(image[slices[1]], labels[slices[1]], 2)
   80

Alternatively, we can do the measurements for a number of labels with
a single function call, returning a list of results. For instance, to
measure the sum of the values of the background and the second object
in our example, we give a list of labels:

.. code:: python

   >>> ndi_sum(image, labels, [0, 2])
   array([178.0, 80.0])

The measurement functions described below all support the *index*
parameter to indicate which object(s) should be measured. The default
value of *index* is ``None``. This indicates that all elements where the
label is larger than zero should be treated as a single object and
measured. Thus, in this case the *labels* array is treated as a mask
defined by the elements that are larger than zero. If *index* is a
number or a sequence of numbers it gives the labels of the objects
that are measured. If *index* is a sequence, a list of the results is
returned. Functions that return more than one result return their
result as a tuple if *index* is a single number, or as a tuple of
lists if *index* is a sequence.

- The :func:`sum` function calculates the sum of the elements of the
  object with label(s) given by *index*, using the *labels* array for
  the object labels. If *index* is ``None``, all elements with a
  non-zero label value are treated as a single object. If *label* is
  ``None``, all elements of *input* are used in the calculation.

- The :func:`mean` function calculates the mean of the elements of the
  object with label(s) given by *index*, using the *labels* array for
  the object labels. If *index* is ``None``, all elements with a
  non-zero label value are treated as a single object. If *label* is
  ``None``, all elements of *input* are used in the calculation.

- The :func:`variance` function calculates the variance of the
  elements of the object with label(s) given by *index*, using the
  *labels* array for the object labels. If *index* is ``None``, all
  elements with a non-zero label value are treated as a single
  object. If *label* is ``None``, all elements of *input* are used in
  the calculation.

- The :func:`standard_deviation` function calculates the standard
  deviation of the elements of the object with label(s) given by
  *index*, using the *labels* array for the object labels. If *index*
  is ``None``, all elements with a non-zero label value are treated as
  a single object. If *label* is ``None``, all elements of *input* are
  used in the calculation.

- The :func:`minimum` function calculates the minimum of the elements
  of the object with label(s) given by *index*, using the *labels*
  array for the object labels. If *index* is ``None``, all elements
  with a non-zero label value are treated as a single object. If
  *label* is ``None``, all elements of *input* are used in the
  calculation.

- The :func:`maximum` function calculates the maximum of the elements
  of the object with label(s) given by *index*, using the *labels*
  array for the object labels. If *index* is ``None``, all elements
  with a non-zero label value are treated as a single object. If
  *label* is ``None``, all elements of *input* are used in the
  calculation.

- The :func:`minimum_position` function calculates the position of the
  minimum of the elements of the object with label(s) given by
  *index*, using the *labels* array for the object labels. If *index*
  is ``None``, all elements with a non-zero label value are treated as
  a single object. If *label* is ``None``, all elements of *input* are
  used in the calculation.

- The :func:`maximum_position` function calculates the position of the
  maximum of the elements of the object with label(s) given by
  *index*, using the *labels* array for the object labels. If *index*
  is ``None``, all elements with a non-zero label value are treated as
  a single object. If *label* is ``None``, all elements of *input* are
  used in the calculation.

- The :func:`extrema` function calculates the minimum, the maximum,
  and their positions, of the elements of the object with label(s)
  given by *index*, using the *labels* array for the object labels. If
  *index* is ``None``, all elements with a non-zero label value are
  treated as a single object. If *label* is ``None``, all elements of
  *input* are used in the calculation. The result is a tuple giving
  the minimum, the maximum, the position of the minimum, and the
  position of the maximum. The result is the same as a tuple formed by
  the results of the functions *minimum*, *maximum*,
  *minimum_position*, and *maximum_position* that are described above.

- The :func:`center_of_mass` function calculates the center of mass of
  the object with label(s) given by *index*, using the *labels*
  array for the object labels. If *index* is ``None``, all elements
  with a non-zero label value are treated as a single object. If
  *label* is ``None``, all elements of *input* are used in the
  calculation.

- The :func:`histogram` function calculates a histogram of the
  object with label(s) given by *index*, using the *labels* array for
  the object labels. If *index* is ``None``, all elements with a
  non-zero label value are treated as a single object. If *label* is
  ``None``, all elements of *input* are used in the calculation.
  Histograms are defined by their minimum (*min*), maximum (*max*), and
  the number of bins (*bins*). They are returned as 1-D
  arrays of type ``numpy.int32``.

.. _ndimage-ccallbacks:

Extending :mod:`scipy.ndimage` in C
-----------------------------------

A few functions in :mod:`scipy.ndimage` take a callback argument. This
can be either a python function or a `scipy.LowLevelCallable` containing a
pointer to a C function. Using a C function will generally be more
efficient, since it avoids the overhead of calling a python function on
many elements of an array. To use a C function, you must write a C
extension that contains the callback function and a Python function
that returns a `scipy.LowLevelCallable` containing a pointer to the
callback.

An example of a function that supports callbacks is
:func:`geometric_transform`, which accepts a callback function that
defines a mapping from all output coordinates to corresponding
coordinates in the input array. Consider the following python example,
which uses :func:`geometric_transform` to implement a shift function.

.. code:: python

   from scipy import ndimage

   def transform(output_coordinates, shift):
       input_coordinates = output_coordinates[0] - shift, output_coordinates[1] - shift
       return input_coordinates

   im = np.arange(12).reshape(4, 3).astype(np.float64)
   shift = 0.5
   print(ndimage.geometric_transform(im, transform, extra_arguments=(shift,)))

We can also implement the callback function with the following C code:

.. code:: c

   /* example.c */

   #include <Python.h>
   #include <numpy/npy_common.h>

   static int
   _transform(npy_intp *output_coordinates, double *input_coordinates,
              int output_rank, int input_rank, void *user_data)
   {
       npy_intp i;
       double shift = *(double *)user_data;

       for (i = 0; i < input_rank; i++) {
           input_coordinates[i] = output_coordinates[i] - shift;
       }
       return 1;
   }

   static char *transform_signature = "int (npy_intp *, double *, int, int, void *)";

   static PyObject *
   py_get_transform(PyObject *obj, PyObject *args)
   {
       if (!PyArg_ParseTuple(args, "")) return NULL;
       return PyCapsule_New(_transform, transform_signature, NULL);
   }

   static PyMethodDef ExampleMethods[] = {
       {"get_transform", (PyCFunction)py_get_transform, METH_VARARGS, ""},
       {NULL, NULL, 0, NULL}
   };

   /* Initialize the module */
   static struct PyModuleDef example = {
       PyModuleDef_HEAD_INIT,
       "example",
       NULL,
       -1,
       ExampleMethods,
       NULL,
       NULL,
       NULL,
       NULL
   };

   PyMODINIT_FUNC
   PyInit_example(void)
   {
       return PyModule_Create(&example);
   }

More information on writing Python extension modules can be found
`here`__. If the C code is in the file ``example.c``, then it can be
compiled with the following ``setup.py``,

__ https://docs.python.org/2/extending/extending.html

.. code:: python

   from distutils.core import setup, Extension
   import numpy

   shift = Extension('example',
                     ['example.c'],
                     include_dirs=[numpy.get_include()]
   )

   setup(name='example',
         ext_modules=[shift]
   )

and now running the script

.. code:: python

   import ctypes
   import numpy as np
   from scipy import ndimage, LowLevelCallable

   from example import get_transform

   shift = 0.5

   user_data = ctypes.c_double(shift)
   ptr = ctypes.cast(ctypes.pointer(user_data), ctypes.c_void_p)
   callback = LowLevelCallable(get_transform(), ptr)
   im = np.arange(12).reshape(4, 3).astype(np.float64)
   print(ndimage.geometric_transform(im, callback))

produces the same result as the original python script.

In the C version, ``_transform`` is the callback function and the
parameters ``output_coordinates`` and ``input_coordinates`` play the
same role as they do in the python version, while ``output_rank`` and
``input_rank`` provide the equivalents of ``len(output_coordinates)``
and ``len(input_coordinates)``. The variable ``shift`` is passed
through ``user_data`` instead of
``extra_arguments``. Finally, the C callback function returns an integer
status, which is one upon success and zero otherwise.

The function ``py_transform`` wraps the callback function in a
:c:type:`PyCapsule`. The main steps are:

- Initialize a :c:type:`PyCapsule`. The first argument is a pointer to
  the callback function.

- The second argument is the function signature, which must match exactly
  the one expected by :mod:`~scipy.ndimage`.

- Above, we used  `scipy.LowLevelCallable` to specify ``user_data``
  that we generated with `ctypes`.

  A different approach would be to supply the data in the capsule context,
  that can be set by `PyCapsule_SetContext` and omit specifying
  ``user_data`` in `scipy.LowLevelCallable`. However, in this approach we would
  need to deal with allocation/freeing of the data --- freeing the data
  after the capsule has been destroyed can be done by specifying a non-NULL
  callback function in the third argument of `PyCapsule_New`.

C callback functions for :mod:`~scipy.ndimage` all follow this scheme. The
next section lists the :mod:`~scipy.ndimage` functions that accept a C
callback function and gives the prototype of the function.

.. seealso::

   The functions that support low-level callback arguments are:

   `generic_filter`, `generic_filter1d`, `geometric_transform`

Below, we show alternative ways to write the code, using Numba_, Cython_,
ctypes_, or cffi_ instead of writing wrapper code in C.

.. _Numba: https://numba.pydata.org/
.. _Cython: https://cython.org/
.. _ctypes: https://docs.python.org/3/library/ctypes.html
.. _cffi: https://cffi.readthedocs.io/

.. rubric:: Numba

Numba_ provides a way to write low-level functions easily in Python.
We can write the above using Numba as:

.. code:: python

   # example.py
   import numpy as np
   import ctypes
   from scipy import ndimage, LowLevelCallable
   from numba import cfunc, types, carray

   @cfunc(types.intc(types.CPointer(types.intp),
                     types.CPointer(types.double),
                     types.intc,
                     types.intc,
                     types.voidptr))
   def transform(output_coordinates_ptr, input_coordinates_ptr,
                 output_rank, input_rank, user_data):
       input_coordinates = carray(input_coordinates_ptr, (input_rank,))
       output_coordinates = carray(output_coordinates_ptr, (output_rank,))
       shift = carray(user_data, (1,), types.double)[0]

       for i in range(input_rank):
           input_coordinates[i] = output_coordinates[i] - shift

       return 1

   shift = 0.5

   # Then call the function
   user_data = ctypes.c_double(shift)
   ptr = ctypes.cast(ctypes.pointer(user_data), ctypes.c_void_p)
   callback = LowLevelCallable(transform.ctypes, ptr)

   im = np.arange(12).reshape(4, 3).astype(np.float64)
   print(ndimage.geometric_transform(im, callback))


.. rubric:: Cython

Functionally the same code as above can be written in Cython with
somewhat less boilerplate as follows:

.. code:: cython

   # example.pyx

   from numpy cimport npy_intp as intp

   cdef api int transform(intp *output_coordinates, double *input_coordinates,
                          int output_rank, int input_rank, void *user_data):
       cdef intp i
       cdef double shift = (<double *>user_data)[0]

       for i in range(input_rank):
           input_coordinates[i] = output_coordinates[i] - shift
       return 1

.. code:: python

   # script.py

   import ctypes
   import numpy as np
   from scipy import ndimage, LowLevelCallable

   import example

   shift = 0.5

   user_data = ctypes.c_double(shift)
   ptr = ctypes.cast(ctypes.pointer(user_data), ctypes.c_void_p)
   callback = LowLevelCallable.from_cython(example, "transform", ptr)
   im = np.arange(12).reshape(4, 3).astype(np.float64)
   print(ndimage.geometric_transform(im, callback))


.. rubric:: cffi

With cffi_, you can interface with a C function residing in a shared
library (DLL). First, we need to write the shared library, which we do
in C --- this example is for Linux/OSX:

.. code:: c

   /*
     example.c
     Needs to be compiled with "gcc -std=c99 -shared -fPIC -o example.so example.c"
     or similar
    */

   #include <stdint.h>

   int
   _transform(intptr_t *output_coordinates, double *input_coordinates,
              int output_rank, int input_rank, void *user_data)
   {
       int i;
       double shift = *(double *)user_data;

       for (i = 0; i < input_rank; i++) {
           input_coordinates[i] = output_coordinates[i] - shift;
       }
       return 1;
   }

The Python code calling the library is:

.. code:: python

   import os
   import numpy as np
   from scipy import ndimage, LowLevelCallable
   import cffi

   # Construct the FFI object, and copypaste the function declaration
   ffi = cffi.FFI()
   ffi.cdef("""
   int _transform(intptr_t *output_coordinates, double *input_coordinates,
                  int output_rank, int input_rank, void *user_data);
   """)

   # Open library
   lib = ffi.dlopen(os.path.abspath("example.so"))

   # Do the function call
   user_data = ffi.new('double *', 0.5)
   callback = LowLevelCallable(lib._transform, user_data)
   im = np.arange(12).reshape(4, 3).astype(np.float64)
   print(ndimage.geometric_transform(im, callback))

You can find more information in the cffi_ documentation.

.. rubric:: ctypes

With *ctypes*, the C code and the compilation of the so/DLL is as for
cffi above.  The Python code is different:

.. code:: python

   # script.py

   import os
   import ctypes
   import numpy as np
   from scipy import ndimage, LowLevelCallable

   lib = ctypes.CDLL(os.path.abspath('example.so'))

   shift = 0.5

   user_data = ctypes.c_double(shift)
   ptr = ctypes.cast(ctypes.pointer(user_data), ctypes.c_void_p)

   # Ctypes has no built-in intptr type, so override the signature
   # instead of trying to get it via ctypes
   callback = LowLevelCallable(lib._transform, ptr,
       "int _transform(intptr_t *, double *, int, int, void *)")

   # Perform the call
   im = np.arange(12).reshape(4, 3).astype(np.float64)
   print(ndimage.geometric_transform(im, callback))

You can find more information in the ctypes_ documentation.


References
----------

.. [1] M. Unser, "Splines: A Perfect Fit for Signal and Image
       Processing," IEEE Signal Processing Magazine, vol. 16, no. 6, pp.
       22-38, November 1999.

.. [2] G. Borgefors, "Distance transformations in arbitrary
       dimensions.", Computer Vision, Graphics, and Image Processing,
       27:321-345, 1984.

.. [3] C. R. Maurer, Jr., R. Qi, and V. Raghavan, "A linear time
       algorithm for computing exact euclidean distance transforms of
       binary images in arbitrary dimensions." IEEE Trans. PAMI 25,
       265-270, 2003.

.. [4] A. X. Falcão, J. Stolfi, and R. A. Lotufo. "The image foresting
       transform: Theory, algorithms, and applications." IEEE Trans.
       PAMI 26, 19-29. 2004.

.. [5] T. Briand and P. Monasse, "Theory and Practice of Image B-Spline
       Interpolation", Image Processing On Line, 8, pp. 99–141, 2018.
       https://doi.org/10.5201/ipol.2018.221

.. _continuous-lomax:

Pareto Second Kind (Lomax) Distribution
=======================================

This is Pareto of the first kind with :math:`L=-1.0` .  There is one shape parameter
:math:`c>0` and support :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{c}{\left(1+x\right)^{c+1}}\\ F\left(x;c\right) & = & 1-\frac{1}{\left(1+x\right)^{c}}\\ G\left(q;c\right) & = & \left(1-q\right)^{-1/c}-1\end{eqnarray*}

.. math::

     h\left[X\right]=\frac{1}{c}+1-\log\left(c\right).

Implementation: `scipy.stats.lomax`

.. _continuous-alpha:

Alpha Distribution
==================

One shape parameter :math:`\alpha>0` (parameter :math:`\beta` in DATAPLOT
is a scale-parameter). The support for the standard form is :math:`x>0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\alpha\right) & = & \frac{1}{x^{2}\Phi\left(\alpha\right)\sqrt{2\pi}}\exp\left(-\frac{1}{2}\left(\alpha-\frac{1}{x}\right)^{2}\right)\\ F\left(x;\alpha\right) & = & \frac{\Phi\left(\alpha-\frac{1}{x}\right)}{\Phi\left(\alpha\right)}\\ G\left(q;\alpha\right) & = & \left[\alpha-\Phi^{-1}\left(q\Phi\left(\alpha\right)\right)\right]^{-1}\end{eqnarray*}

.. math::

     M\left(t\right)=\frac{1}{\Phi\left(a\right)\sqrt{2\pi}}\int_{0}^{\infty}\frac{e^{xt}}{x^{2}}\exp\left(-\frac{1}{2}\left(\alpha-\frac{1}{x}\right)^{2}\right)dx

No moments?

.. math::

     l_{\mathbf{x}}\left(\alpha\right)=N\log\left[\Phi\left(\alpha\right)\sqrt{2\pi}\right]+2N\overline{\log\mathbf{x}}+\frac{N}{2}\alpha^{2}-\alpha\overline{\mathbf{x}^{-1}}+\frac{1}{2}\overline{\mathbf{x}^{-2}}

Implementation: `scipy.stats.alpha`

.. _continuous-gompertz:

Gompertz (Truncated Gumbel) Distribution
========================================

For :math:`x\geq0` and :math:`c>0` . In JKB the two shape parameters :math:`b,a` are reduced to the single shape-parameter :math:`c=b/a` . As :math:`a` is just a scale parameter when :math:`a\neq0` . If :math:`a=0,` the distribution reduces to the exponential distribution scaled by :math:`1/b.` Thus, the standard form is given as

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & ce^{x}\exp\left(-c\left(e^{x}-1\right)\right)\\
    F\left(x;c\right) & = & 1-\exp\left(-c\left(e^{x}-1\right)\right)\\
    G\left(q;c\right) & = & \log\left(1-\frac{1}{c}\log\left(1-q\right)\right)\end{eqnarray*}

.. math::

     h\left[X\right]=1-\log\left(c\right)-e^{c}\mathrm{Ei}\left(1,c\right),

where

.. math::

     \mathrm{Ei}\left(n,x\right)=\int_{1}^{\infty}t^{-n}\exp\left(-xt\right)dt

Implementation: `scipy.stats.gompertz`

.. _discrete-planck:

Planck (discrete exponential) Distribution
==========================================

Named Planck because of its relationship to the black-body problem he
solved.

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;\lambda\right) & = & \left(1-e^{-\lambda}\right)e^{-\lambda k}\quad k\lambda\geq0\\ F\left(x;\lambda\right) & = & 1-e^{-\lambda\left(\left\lfloor x\right\rfloor +1\right)}\quad x\lambda\geq0\\ G\left(q;\lambda\right) & = & \left\lceil -\frac{1}{\lambda}\log\left[1-q\right]-1\right\rceil .\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{1}{e^{\lambda}-1}\\ \mu_{2} & = & \frac{e^{-\lambda}}{\left(1-e^{-\lambda}\right)^{2}}\\ \gamma_{1} & = & 2\cosh\left(\frac{\lambda}{2}\right)\\ \gamma_{2} & = & 4+2\cosh\left(\lambda\right)\end{eqnarray*}

.. math::

    M\left(t\right)=\frac{1-e^{-\lambda}}{1-e^{t-\lambda}}

.. math::

    h\left[X\right]=\frac{\lambda e^{-\lambda}}{1-e^{-\lambda}}-\log\left(1-e^{-\lambda}\right)

Implementation: `scipy.stats.planck`

.. _discrete-nbinom:

Negative Binomial Distribution
==============================

The negative binomial random variable with parameters :math:`n` and :math:`p\in\left(0,1\right)` can be defined as the number of *extra* independent trials (beyond :math:`n` ) required to accumulate a total of :math:`n` successes where the probability of a success on each trial is :math:`p.` Equivalently, this random variable is the number of failures
encountered while accumulating :math:`n` successes during independent trials of an experiment that succeeds
with probability :math:`p.` Thus,

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;n,p\right) & = & \left(\begin{array}{c} k+n-1\\ n-1\end{array}\right)p^{n}\left(1-p\right)^{k}\quad k\geq0\\ F\left(x;n,p\right) & = & \sum_{i=0}^{\left\lfloor x\right\rfloor }\left(\begin{array}{c} i+n-1\\ i\end{array}\right)p^{n}\left(1-p\right)^{i}\quad x\geq0\\  & = & I_{p}\left(n,\left\lfloor x\right\rfloor +1\right)\quad x\geq0\\ \mu & = & n\frac{1-p}{p}\\ \mu_{2} & = & n\frac{1-p}{p^{2}}\\ \gamma_{1} & = & \frac{2-p}{\sqrt{n\left(1-p\right)}}\\ \gamma_{2} & = & \frac{p^{2}+6\left(1-p\right)}{n\left(1-p\right)}.\end{eqnarray*}

Recall that :math:`I_{p}\left(a,b\right)` is the incomplete beta integral.

Implementation: `scipy.stats.nbinom`

.. _continuous-kstwobign:

KStwobign Distribution
======================

This is the limiting distribution of the normalized maximum absolute differences between an
empirical distribution function, computed from :math:`n` samples or observations,
and a comparison (or target) cumulative distribution function.  (``ksone`` is the distribution
of the unnormalized positive differences, :math:`D_n^+`.)

Writing :math:`D_n = \sup_t \left|F_{empirical,n}(t) - F_{target}(t)\right|`,
the normalization factor is :math:`\sqrt{n}`, and ``kstwobign`` is the limiting distribution
of the :math:`\sqrt{n} D_n` values as :math:`n\rightarrow\infty`.

Note that :math:`D_n=\max(D_n^+, D_n^-)`, but :math:`D_n^+` and :math:`D_n^-` are not independent.

``kstwobign`` can also be used with the differences between two empirical distribution functions,
for sets of observations with :math:`m` and :math:`n` samples respectively,
where :math:`m` and :math:`n` are "big".
Writing :math:`D_{m,n} = \sup_t \left|F_{1,m}(t)-F_{2,n}(t)\right|`,  where
:math:`F_{1,m}` and :math:`F_{2,n}` are the two empirical distribution functions, then
``kstwobign`` is also the limiting distribution of the :math:`\sqrt{\left(\frac{mn}{m+n}\right)D_{m,n}}` values,
as :math:`m,n\rightarrow\infty` and :math:`m/n\rightarrow a \ne 0, \infty`.

There are no shape parameters, and the support is :math:`x\in\left[0,\infty\right)`.


.. math::
    :nowrap:

    \begin{eqnarray*}  F\left(x\right) & = & 1 - 2 \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2}\\
    & = & \frac{\sqrt{2\pi}}{x} \sum_{k=1}^{\infty} e^{-(2k-1)^2 \pi^2/(8x^2)}\\
    & = & 1 - \textrm{scipy.special.kolmogorov}(n, x) \\
    f\left(x\right) & = & 8x \sum_{k=1}^{\infty} (-1)^{k-1} k^2 e^{-2k^2 x^2} \end{eqnarray*}


References
----------

-  "Kolmogorov-Smirnov test", Wikipedia
   https://en.wikipedia.org/wiki/Kolmogorov-Smirnov_test

-  Kolmogoroff, A. "Confidence Limits for an Unknown Distribution Function.""
   *Ann. Math. Statist.* 12 (1941), no. 4, 461--463.

-  Smirnov, N. "On the estimation of the discrepancy between empirical curves of distribution for two independent samples"
   *Bull. Math. Univ. Moscou.*, 2 (1039), 2-26.

-  Feller, W. "On the Kolmogorov-Smirnov Limit Theorems for Empirical Distributions."
   *Ann. Math. Statist.* 19 (1948), no. 2, 177--189. and "Errata"  *Ann. Math. Statist.* 21 (1950), no. 2, 301--302.


Implementation: `scipy.stats.kstwobign`

.. _continuous-gausshyper:

Gauss Hypergeometric Distribution
=================================

The four shape parameters are :math:`\alpha>0`, :math:`\beta>0`,
:math:`-\infty < \gamma < \infty`, and :math:`z > -1`.
The support is :math:`x\in\left[0,1\right]`.

.. math::

     \text{Let }C=\frac{1}{B\left(\alpha,\beta\right)\,_{2}F_{1}\left(\gamma,\alpha;\alpha+\beta;-z\right)}

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\alpha,\beta,\gamma,z\right) & = & Cx^{\alpha-1}\frac{\left(1-x\right)^{\beta-1}}{\left(1+zx\right)^{\gamma}}\\ \mu_{n}^{\prime} & = & \frac{B\left(n+\alpha,\beta\right)}{B\left(\alpha,\beta\right)}\frac{\,_{2}F_{1}\left(\gamma,\alpha+n;\alpha+\beta+n;-z\right)}{\,_{2}F_{1}\left(\gamma,\alpha;\alpha+\beta;-z\right)}\end{eqnarray*}

Implementation: `scipy.stats.gausshyper`

.. _discrete-hypergeom:

Hypergeometric Distribution
===========================

The hypergeometric random variable with parameters :math:`\left(M,n,N\right)` counts the number of "good "objects in a sample of size :math:`N` chosen without replacement from a population of :math:`M` objects where :math:`n` is the number of "good "objects in the total population.

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;N,n,M\right) & = & \frac{\left(\begin{array}{c} n\\ k\end{array}\right)\left(\begin{array}{c} M-n\\ N-k\end{array}\right)}{\left(\begin{array}{c} M\\ N\end{array}\right)}\quad N-\left(M-n\right)\leq k\leq\min\left(n,N\right)\\ F\left(x;N,n,M\right) & = & \sum_{k=0}^{\left\lfloor x\right\rfloor }\frac{\left(\begin{array}{c} m\\ k\end{array}\right)\left(\begin{array}{c} N-m\\ n-k\end{array}\right)}{\left(\begin{array}{c} N\\ n\end{array}\right)},\\ \mu & = & \frac{nN}{M}\\ \mu_{2} & = & \frac{nN\left(M-n\right)\left(M-N\right)}{M^{2}\left(M-1\right)}\\ \gamma_{1} & = & \frac{\left(M-2n\right)\left(M-2N\right)}{M-2}\sqrt{\frac{M-1}{nN\left(M-m\right)\left(M-n\right)}}\\ \gamma_{2} & = & \frac{g\left(N,n,M\right)}{nN\left(M-n\right)\left(M-3\right)\left(M-2\right)\left(N-M\right)}\end{eqnarray*}

where (defining :math:`m=M-n` )

.. math::
   :nowrap:

    \begin{eqnarray*} g\left(N,n,M\right) & = & m^{3}-m^{5}+3m^{2}n-6m^{3}n+m^{4}n+3mn^{2}\\  &  & -12m^{2}n^{2}+8m^{3}n^{2}+n^{3}-6mn^{3}+8m^{2}n^{3}\\  &  & +mn^{4}-n^{5}-6m^{3}N+6m^{4}N+18m^{2}nN\\  &  & -6m^{3}nN+18mn^{2}N-24m^{2}n^{2}N-6n^{3}N\\  &  & -6mn^{3}N+6n^{4}N+6m^{2}N^{2}-6m^{3}N^{2}-24mnN^{2}\\  &  & +12m^{2}nN^{2}+6n^{2}N^{2}+12mn^{2}N^{2}-6n^{3}N^{2}.\end{eqnarray*}

Implementation: `scipy.stats.hypergeom`

.. _continuous-logistic:

Logistic (Sech-squared) Distribution
====================================

A special case of the Generalized Logistic distribution with :math:`c=1`.
The support is :math:`x \in \mathbb{R}`.

This distribution function has a direct connection with the Fermi-Dirac
distribution via its survival function. I.e. ``scipy.stats.logistic.sf`` is
equivalent to the Fermi-Dirac distribution.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{\exp\left(-x\right)}{\left(1+\exp\left(-x\right)\right)^{2}}\\
    F\left(x\right) & = & \frac{1}{1+\exp\left(-x\right)}\\
    G\left(q\right) & = & -\log\left(1/q-1\right)\\
    S\left(x\right) & = & n_F(x)=\frac{1}{1+\exp\left(x\right)}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \gamma+\psi_{0}\left(1\right)=0\\
    \mu_{2} & = & \frac{\pi^{2}}{6}+\psi_{1}\left(1\right)=\frac{\pi^{2}}{3}\\
    \gamma_{1} & = & \frac{\psi_{2}\left(1\right)+2\zeta\left(3\right)}{\mu_{2}^{3/2}}=0\\
    \gamma_{2} & = & \frac{\left(\frac{\pi^{4}}{15}+\psi_{3}\left(1\right)\right)}{\mu_{2}^{2}}=\frac{6}{5}\\
    m_{d} & = & \log1=0\\
    m_{n} & = & -\log\left(2-1\right)=0\end{eqnarray*}

where :math:`\psi_m` is the polygamma function :math:`\psi_m(z) = \frac{d^{m+1}}{dz^{m+1}} \log(\Gamma(z))`.

.. math::

     h\left[X\right]=1.

Implementation: `scipy.stats.logistic`

.. _continuous-laplace:

Laplace (Double Exponential, Bilateral Exponential) Distribution
================================================================

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{1}{2}e^{-\left|x\right|}\\ F\left(x\right) & = & \left\{ \begin{array}{ccc} \frac{1}{2}e^{x} &  & x\leq0\\ 1-\frac{1}{2}e^{-x} &  & x>0\end{array}\right.\\ G\left(q\right) & = & \left\{ \begin{array}{ccc} \log\left(2q\right) &  & q\leq\frac{1}{2}\\ -\log\left(2-2q\right) &  & q>\frac{1}{2}\end{array}\right.\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} m_{d}=m_{n}=\mu & = & 0\\ \mu_{2} & = & 2\\ \gamma_{1} & = & 0\\ \gamma_{2} & = & 3\end{eqnarray*}

The ML estimator of the location parameter is

.. math::

     \hat{L}=\mathrm{median}\left(X_{i}\right)

where :math:`X_{i}` is a sequence of :math:`N` mutually independent Laplace RV's and the median is some number
between the :math:`\frac{1}{2}N\mathrm{th}` and the :math:`(N/2+1)\mathrm{th}` order statistic ( *e.g.* take the average of these two) when :math:`N` is even. Also,

.. math::

     \hat{S}=\frac{1}{N}\sum_{j=1}^{N}\left|X_{j}-\hat{L}\right|.

Replace :math:`\hat{L}` with :math:`L` if it is known. If :math:`L` is known then this estimator is distributed as :math:`\left(2N\right)^{-1}S\cdot\chi_{2N}^{2}` .

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & \log\left(2e\right)\\  & \approx & 1.6931471805599453094.\end{eqnarray*}

Implementation: `scipy.stats.laplace`

.. _continuous-burr:

Burr Distribution
=================

There are two shape parameters :math:`c,d > 0` and the support is :math:`x \in [0,\infty)`.

.. math::
   :nowrap:

    \begin{eqnarray*} \textrm{Let }k & = & \Gamma\left(d\right)\Gamma\left(1-\frac{2}{c}\right)\Gamma\left(\frac{2}{c}+d\right)-\Gamma^{2}\left(1-\frac{1}{c}\right)\Gamma^{2}\left(\frac{1}{c}+d\right)\\
    f\left(x;c,d\right) & = & \frac{cd}{x^{c+1}\left(1+x^{-c}\right)^{d+1}} \\
    F\left(x;c,d\right) & = & \left(1+x^{-c}\right)^{-d}\\
    G\left(q;c,d\right) & = & \left(q^{-1/d}-1\right)^{-1/c}\\
    \mu & = & \frac{\Gamma\left(1-\frac{1}{c}\right)\Gamma\left(\frac{1}{c}+d\right)}{\Gamma\left(d\right)}\\
    \mu_{2} & = & \frac{k}{\Gamma^{2}\left(d\right)}\\
    \gamma_{1} & = & \frac{1}{\sqrt{k^{3}}}\left[2\Gamma^{3}\left(1-\frac{1}{c}\right)\Gamma^{3}\left(\frac{1}{c}+d\right)+\Gamma^{2}\left(d\right)\Gamma\left(1-\frac{3}{c}\right)\Gamma\left(\frac{3}{c}+d\right)\right.\\
     &  & \left.-3\Gamma\left(d\right)\Gamma\left(1-\frac{2}{c}\right)\Gamma\left(1-\frac{1}{c}\right)\Gamma\left(\frac{1}{c}+d\right)\Gamma\left(\frac{2}{c}+d\right)\right]\\
    \gamma_{2} & = & -3+\frac{1}{k^{2}}\left[6\Gamma\left(d\right)\Gamma\left(1-\frac{2}{c}\right)\Gamma^{2}\left(1-\frac{1}{c}\right)\Gamma^{2}\left(\frac{1}{c}+d\right)\Gamma\left(\frac{2}{c}+d\right)\right.\\
     &  & -3\Gamma^{4}\left(1-\frac{1}{c}\right)\Gamma^{4}\left(\frac{1}{c}+d\right)+\Gamma^{3}\left(d\right)\Gamma\left(1-\frac{4}{c}\right)\Gamma\left(\frac{4}{c}+d\right)\\
      &  & \left.-4\Gamma^{2}\left(d\right)\Gamma\left(1-\frac{3}{c}\right)\Gamma\left(1-\frac{1}{c}\right)\Gamma\left(\frac{1}{c}+d\right)\Gamma\left(\frac{3}{c}+d\right)\right]\\
    m_{d} & = & \left(\frac{cd-1}{c+1}\right)^{1/c}\,\text{if }\quad cd>1 \text{, otherwise }\quad 0\\
    m_{n} & = & \left(2^{1/d}-1\right)^{-1/c}\end{eqnarray*}

Implementation: `scipy.stats.burr`

.. _continuous-nct:

Noncentral t Distribution
=========================

The distribution of the ratio

.. math::

     \frac{U+\lambda}{\chi_{\nu}/\sqrt{\nu}}

where :math:`U` and :math:`\chi_{\nu}` are independent and distributed as a standard normal and chi with :math:`\nu` degrees of freedom. Note :math:`\lambda>0` and :math:`\nu>0` .

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\lambda,\nu\right) & = & \frac{\nu^{\nu/2}\Gamma\left(\nu+1\right)}{2^{\nu}e^{\lambda^{2}/2}\left(\nu+x^{2}\right)^{\nu/2}\Gamma\left(\nu/2\right)}\\
     &  & \times\left\{ \frac{\sqrt{2}\lambda x\,_{1}F_{1}\left(\frac{\nu}{2}+1;\frac{3}{2};\frac{\lambda^{2}x^{2}}{2\left(\nu+x^{2}\right)}\right)}{\left(\nu+x^{2}\right)\Gamma\left(\frac{\nu+1}{2}\right)}\right.\\
     &  & -\left.\frac{\,_{1}F_{1}\left(\frac{\nu+1}{2};\frac{1}{2};\frac{\lambda^{2}x^{2}}{2\left(\nu+x^{2}\right)}\right)}{\sqrt{\nu+x^{2}}\Gamma\left(\frac{\nu}{2}+1\right)}\right\} \\
     & = & \frac{\Gamma\left(\nu+1\right)}{2^{\left(\nu-1\right)/2}\sqrt{\pi\nu}\Gamma\left(\nu/2\right)}\exp\left[-\frac{\nu\lambda^{2}}{\nu+x^{2}}\right]\\
     &  & \times\left(\frac{\nu}{\nu+x^{2}}\right)^{\left(\nu-1\right)/2}Hh_{\nu}\left(-\frac{\lambda x}{\sqrt{\nu+x^{2}}}\right)\\
     F\left(x;\lambda,\nu\right) & = & \left\{
                                  \begin{array}{cc}
                                    {\tilde{F}}_{{\nu ,\mu }}(x) & x\geq0 \\
                                    1 - {\tilde{F}}_{{\nu ,-\mu }}(x) & x<0
                                    \end{array}
                                 \right. \\
    \text{where} \\
     {\tilde{F}}_{{\nu ,\mu }}(x) & = & \Phi (-\mu )+{\frac{1}{2}}\sum _{{j=0}}^{\infty }\left[p_{j}I_{y}\left(j+{\frac{1}{2}},{\frac{\nu }{2}}\right)+q_{j}I_{y}\left(j+1,{\frac{\nu }{2}}\right)\right]\\
     y & = & \frac{x^2}{x^2+\nu}\\
     p_{j} & = & \frac{e^{\left( -\frac{\mu^2}{2} \right)} }{j!} \left(\frac{\mu^2}{2}\right)^{j}\\
     q_{j} & = & {\frac{\mu e^{\left( -\frac{\mu^2}{2} \right)} } {\sqrt{2}\Gamma(j+3/2)}} \left({\frac{\mu^2}{2}}\right)^{j} \end{eqnarray*}

where :math:`I_{y}(a,b)` is the regularized incomplete beta function and
Airy's Hh function is :math:`Hh_{\nu}(x)=\frac{1}{\Gamma(\nu+1)}\int_0^\infty t^\nu e^{\frac{-(t+x)^2}{2}}dt`.

Implementation: `scipy.stats.nct`

.. _continuous-genhalflogistic:

Generalized Half-Logistic Distribution
======================================

One shape parameter :math:`c>0` and support :math:`x\in\left[0,1/c\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{2\left(1-cx\right)^{\frac{1}{c}-1}}{\left(1+\left(1-cx\right)^{1/c}\right)^{2}}\\
    F\left(x;c\right) & = & \frac{1-\left(1-cx\right)^{1/c}}{1+\left(1-cx\right)^{1/c}}\\
    G\left(q;c\right) & = & \frac{1}{c}\left[1-\left(\frac{1-q}{1+q}\right)^{c}\right]\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & 2-\left(2c+1\right)\log2.\end{eqnarray*}

Implementation: `scipy.stats.genhalflogistic`

.. _continuous-cauchy:

Cauchy Distribution
===================

The support is :math:`x\in\mathbb{R}`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{1}{\pi\left(1+x^{2}\right)}\\
    F\left(x\right) & = & \frac{1}{2}+\frac{1}{\pi}\tan^{-1}x\\
    G\left(q\right) & = & \tan\left(\pi q-\frac{\pi}{2}\right)\\
    m_{d} & = & 0\\
    m_{n} & = & 0\end{eqnarray*}

No finite moments. This is the :math:`t` distribution with one degree of
freedom.

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & \log\left(4\pi\right)\\  & \approx & 2.5310242469692907930.\end{eqnarray*}

Implementation: `scipy.stats.cauchy`

.. _continuous-gumbel_l:

Gumbel Left-skewed (for minimum order statistic) Distribution
=============================================================

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \exp\left(x-e^{x}\right)\\ F\left(x\right) & = & 1-\exp\left(-e^{x}\right)\\ G\left(q\right) & = & \log\left(-\log\left(1-q\right)\right)\end{eqnarray*}

.. math::

     M\left(t\right)=\Gamma\left(1+t\right)

Note, that :math:`\mu` is negative the mean for the right-skewed distribution. Similar for
median and mode. All other moments are the same.

.. math::

     h\left[X\right]\approx1.0608407169541684911.

Implementation: `scipy.stats.gumbel_l`

.. _sampling-dgt:

Discrete Guide Table (DGT)
==========================

.. currentmodule:: scipy.stats.sampling

* Required: probability vector (PV) or the PMF along with a finite domain
* Speed:

    * Set-up: slow (linear with the vector-length)
    * Sampling: very fast


DGT samples from arbitrary but finite probability vectors. Random numbers
are generated by the inversion method, i.e.

1. Generate a random number U ~ U(0,1).
2. Find smallest integer I such that F(I) = P(X<=I) >= U.

Step (2) is the crucial step. Using sequential search requires O(E(X))
comparisons, where E(X) is the expectation of the distribution. Indexed
search, however, uses a guide table to jump to some I' <= I near I to find
X in constant time. Indeed the expected number of comparisons is reduced to
2, when the guide table has the same size as the probability vector
(this is the default). For larger guide tables this number becomes smaller
(but is always larger than 1), for smaller tables it becomes larger.

On the other hand the setup time for guide table is O(N), where N denotes
the length of the probability vector (for size 1 no preprocessing is
required). Moreover, for very large guide tables memory effects might even
reduce the speed of the algorithm. So we do not recommend to use guide
tables that are more than three times larger than the given probability
vector. If only a few random numbers have to be generated, (much) smaller
table sizes are better. The size of the guide table relative to the length
of the given probability vector can be set by the `guide_factor` parameter:

    >>> import numpy as np
    >>> from scipy.stats.sampling import DiscreteGuideTable
    >>>
    >>> pv = [0.18, 0.02, 0.8]
    >>> urng = np.random.default_rng()
    >>> rng = DiscreteGuideTable(pv, random_state=urng)
    >>> rng.rvs()
    2

By default, the probability vector is indexed starting at 0. However, this
can be changed by passing a ``domain`` parameter. When ``domain`` is given
in combination with the PV, it has the effect of relocating the
distribution from ``(0, len(pv))`` to ``(domain[0], domain[0] + len(pv))``.
``domain[1]`` is ignored in this case.

    >>> rng = DiscreteGuideTable(pv, random_state=urng, domain=(10, 13))
    >>> rng.rvs()
    10

The method also works when no probability vector but a PMF is given.
In that case, a bounded (finite) domain must also be given either by
passing the ``domain`` parameter explicitly or by providing a ``support``
method in the distribution object:

    >>> class Distribution:
    ...     def __init__(self, c):
    ...             self.c = c
    ...     def pmf(self, x):
    ...             return x ** self.c
    ...     def support(self):
    ...             return 0, 10
    ...
    >>> dist = Distribution(2)
    >>> rng = DiscreteGuideTable(dist, random_state=urng)
    >>> rng.rvs()
    9

.. note:: As :class:`~DiscreteGuideTable` expects PMF with signature
          ``def pmf(self, x: float) -> float``, it first vectorizes the
          PMF using ``np.vectorize`` and then evaluates it over all the
          points in the domain. But if the PMF is already vectorized,
          it is much faster to just evaluate it at each point in the domain
          and pass the obtained PV instead along with the domain.
          For example, ``pmf`` methods of SciPy's discrete distributions
          are vectorized and a PV can be obtained by doing:

          >>> from scipy.stats import binom
          >>> from scipy.stats.sampling import DiscreteGuideTable
          >>> dist = binom(10, 0.2)  # distribution object
          >>> domain = dist.support()  # the domain of your distribution
          >>> x = np.arange(domain[0], domain[1] + 1)
          >>> pv = dist.pmf(x)
          >>> rng = DiscreteGuideTable(pv, domain=domain)

          Domain is required here to relocate the distribution

The size of the guide table relative to the probability vector may be set using
the ``guide_factor`` parameter. Larger guide tables result in faster generation
time but require a more expensive setup.

    >>> guide_factor = 2
    >>> rng = DiscreteGuideTable(pv, random_state=urng, guide_factor=guide_factor)
    >>> rng.rvs()
    2

Unfortunately, the PPF is rarely available in closed form or too slow when
available. The user only has to provide the probability vector and the 
PPF (inverse CDF) can be evaluated using ``ppf`` method. This 
method calculates the (exact) PPF of the given distribution.

For example to calculate the PPF of a binomial distribution with :math:`n=4` and
:math:`p=0.1`: we can set up a guide table as follows:

    >>> n, p = 4, 0.1
    >>> dist = stats.binom(n, p)
    >>> rng = DiscreteGuideTable(dist, random_state=42)
    >>> rng.ppf(0.5)
    0.0

Please see [1]_ and [2]_ for more details on this method.

References
----------

.. [1] UNU.RAN reference manual, Section 5.8.4,
       "DGT - (Discrete) Guide Table method (indexed search)"
       https://statmath.wu.ac.at/unuran/doc/unuran.html#DGT

.. [2] H.C. Chen and Y. Asau (1974). On generating random variates from an
       empirical distribution, AIIE Trans. 6, pp. 163-166.

.. _discrete-dlaplace:

Discrete Laplacian Distribution
===============================

Defined over all integers for :math:`a>0`

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k\right) & = & \tanh\left(\frac{a}{2}\right)e^{-a\left|k\right|},\\ F\left(x\right) & = & \left\{ \begin{array}{cc} \frac{e^{a\left(\left\lfloor x\right\rfloor +1\right)}}{e^{a}+1} & \left\lfloor x\right\rfloor <0,\\ 1-\frac{e^{-a\left\lfloor x\right\rfloor }}{e^{a}+1} & \left\lfloor x\right\rfloor \geq0.\end{array}\right.\\ G\left(q\right) & = & \left\{ \begin{array}{cc} \left\lceil \frac{1}{a}\log\left[q\left(e^{a}+1\right)\right]-1\right\rceil  & q<\frac{1}{1+e^{-a}},\\ \left\lceil -\frac{1}{a}\log\left[\left(1-q\right)\left(1+e^{a}\right)\right]\right\rceil  & q\geq\frac{1}{1+e^{-a}}.\end{array}\right.\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} M\left(t\right) & = & \tanh\left(\frac{a}{2}\right)\sum_{k=-\infty}^{\infty}e^{tk}e^{-a\left|k\right|}\\  & = & C\left(1+\sum_{k=1}^{\infty}e^{-\left(t+a\right)k}+\sum_{1}^{\infty}e^{\left(t-a\right)k}\right)\\  & = & \tanh\left(\frac{a}{2}\right)\left(1+\frac{e^{-\left(t+a\right)}}{1-e^{-\left(t+a\right)}}+\frac{e^{t-a}}{1-e^{t-a}}\right)\\  & = & \frac{\tanh\left(\frac{a}{2}\right)\sinh a}{\cosh a-\cosh t}.\end{eqnarray*}

Thus,

.. math::

    \mu_{n}^{\prime}=M^{\left(n\right)}\left(0\right)=\left[1+\left(-1\right)^{n}\right]\textrm{Li}_{-n}\left(e^{-a}\right)

where :math:`\textrm{Li}_{-n}\left(z\right)` is the polylogarithm function of order :math:`-n` evaluated at :math:`z.`

.. math::

    h\left[X\right]=-\log\left(\tanh\left(\frac{a}{2}\right)\right)+\frac{a}{\sinh a}

Implementation: `scipy.stats.dlaplace`

.. _continuous-levy_l:

Left-skewed Lévy Distribution
==============================

Special case of Lévy-stable distribution with :math:`\alpha=\frac{1}{2}` and
:math:`\beta=-1`. The support is :math:`x\leq0` . In standard form

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{1}{\left|x\right|\sqrt{2\pi\left|x\right|}}\exp\left(-\frac{1}{2\left|x\right|}\right)\\ F\left(x\right) & = & 2\Phi\left(\frac{1}{\sqrt{\left|x\right|}}\right)-1\\ G\left(q\right) & = & -\left[\Phi^{-1}\left(\frac{q+1}{2}\right)\right]^{-2}.\end{eqnarray*}

No moments.

Implementation: `scipy.stats.levy_l`

.. _continuous-loglaplace:

Log Double Exponential (Log-Laplace) Distribution
=================================================

One shape parameter :math:`c>0`.   The support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*}
        f\left(x;c\right) & = & \left\{
                                    \begin{array}{ccc}
                                        \frac{c}{2}x^{c-1} &  & 0 < x < 1 \\
                                        \frac{c}{2}x^{-c-1} &  & x \geq 1
                                    \end{array}
                                \right. \\
        F\left(x;c\right) & = & \left\{
                                    \begin{array}{ccc}
                                        \frac{1}{2}x^{c} &  & 0 < x < 1 \\
                                        1-\frac{1}{2}x^{-c} &  & x \geq 1
                                    \end{array}
                                \right. \\
        G\left(q;c\right) & = & \left\{
                                    \begin{array}{ccc}
                                        \left(2q\right)^{1/c} &  & 0 \leq q < \frac{1}{2} \\
                                        \left(2-2q\right)^{-1/c} &  & \frac{1}{2} \leq q \leq 1
                                    \end{array}
                                \right.
    \end{eqnarray*}

.. math::

     h\left[X\right]=\log\left(\frac{2e}{c}\right)


Implementation: `scipy.stats.loglaplace`

.. _continuous-invgamma:

Inverted Gamma Distribution
===========================

Special case of the generalized Gamma distribution with :math:`c=-1` and :math:`a>0` and support :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a\right) & = & \frac{x^{-a-1}}{\Gamma\left(a\right)}\exp\left(-\frac{1}{x}\right)\\
    F\left(x;a\right) & = & \frac{\Gamma\left(a,\frac{1}{x}\right)}{\Gamma\left(a\right)}\\
    G\left(q;a\right) & = & \left\{ \Gamma^{-1}\left(a,\Gamma\left(a\right)q\right)\right\} ^{-1}\end{eqnarray*}

.. math::

     \mu_{n}^{\prime}=\frac{\Gamma\left(a-n\right)}{\Gamma\left(a\right)}\quad a>n

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{1}{a-1}\quad a>1\\
    \mu_{2} & = & \frac{1}{\left(a-2\right)\left(a-1\right)}-\mu^{2}\quad a>2\\
    \gamma_{1} & = & \frac{\frac{1}{\left(a-3\right)\left(a-2\right)\left(a-1\right)}-3\mu\mu_{2}-\mu^{3}}{\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{\frac{1}{\left(a-4\right)\left(a-3\right)\left(a-2\right)\left(a-1\right)}-4\mu\mu_{3}-6\mu^{2}\mu_{2}-\mu^{4}}{\mu_{2}^{2}}-3\end{eqnarray*}

.. math::

     m_{d}=\frac{1}{a+1}

.. math::

     h\left[X\right]=a-\left(a+1\right)\psi\left(a\right)+\log\Gamma\left(a\right).

where :math:`\Psi` is the digamma function :math:`\psi(z) = \frac{d}{dz} \log(\Gamma(z))`.

Implementation: `scipy.stats.invgamma`

.. _continuous-wrapcauchy:

Wrapped Cauchy Distribution
===========================

There is one shape parameter :math:`c\in\left(0,1\right)` with support :math:`x\in\left[0,2\pi\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{1-c^{2}}{2\pi\left(1+c^{2}-2c\cos x\right)}\\
    g_{c}\left(x\right) & = & \frac{1}{\pi}\arctan\left(\frac{1+c}{1-c}\tan\left(\frac{x}{2}\right)\right)\\
    r_{c}\left(q\right) & = & 2\arctan\left(\frac{1-c}{1+c}\tan\left(\pi q\right)\right)\\
    F\left(x;c\right) & = & \left\{
          \begin{array}{ccc}
            g_{c}\left(x\right) &  & 0\leq x<\pi\\
            1-g_{c}\left(2\pi-x\right) &  & \pi\leq x\leq2\pi
          \end{array}
          \right.\\
   G\left(q;c\right) & = & \left\{
          \begin{array}{ccc}
            r_{c}\left(q\right) &  & 0\leq q<\frac{1}{2}\\
            2\pi-r_{c}\left(1-q\right) &  & \frac{1}{2}\leq q\leq1
          \end{array}
          \right.\end{eqnarray*}

.. math::

     h\left[X\right]=\log\left(2\pi\left(1-c^{2}\right)\right).

Implementation: `scipy.stats.wrapcauchy`

.. _continuous-wald:

Wald Distribution
=================

Special case of the Inverse Normal with shape parameter set to :math:`1.0`. It has support :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{1}{\sqrt{2\pi x^{3}}}\exp\left(-\frac{\left(x-1\right)^{2}}{2x}\right).\\ F\left(x\right) & = & \Phi\left(\frac{x-1}{\sqrt{x}}\right)+\exp\left(2\right)\Phi\left(-\frac{x+1}{\sqrt{x}}\right)\\ G\left(q;\mu\right) & = & F^{-1}\left(q;\mu\right)\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & 1\\ \mu_{2} & = & 1\\ \gamma_{1} & = & 3\\ \gamma_{2} & = & 15\\ m_{d} & = & \frac{1}{2}\left(\sqrt{13}-3\right)\end{eqnarray*}

Implementation: `scipy.stats.wald`

.. _continuous-hypsecant:

Hyperbolic Secant Distribution
==============================

Related to the logistic distribution and used in lifetime analysis.
Standard form is (defined over all :math:`x` )

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{1}{\pi}\mathrm{sech}\left(x\right)\\
    F\left(x\right) & = & \frac{2}{\pi}\arctan\left(e^{x}\right)\\
    G\left(q\right) & = & \log\left(\tan\left(\frac{\pi}{2}q\right)\right)\end{eqnarray*}

.. math::

     M\left(t\right)=\sec\left(\frac{\pi}{2}t\right)

.. math::
   :nowrap:

   \begin{eqnarray*} \mu_{n}^{\prime} & = & \frac{1+\left(-1\right)^{n}}{2\pi2^{2n}}n!\left[\zeta\left(n+1,\frac{1}{4}\right)-\zeta\left(n+1,\frac{3}{4}\right)\right]\\
    & = & \left\{
      \begin{array}{cc}
        0 & n \text{ odd}\\
        C_{n/2}\frac{\pi^{n}}{2^{n}} & n \text{ even}
      \end{array}
    \right.\end{eqnarray*}

where :math:`C_{m}` is an integer given by

.. math::
   :nowrap:

    \begin{eqnarray*} C_{m} & = & \frac{\left(2m\right)!\left[\zeta\left(2m+1,\frac{1}{4}\right)-\zeta\left(2m+1,\frac{3}{4}\right)\right]}{\pi^{2m+1}2^{2m}}\\
     & = & 4\left(-1\right)^{m-1}\frac{16^{m}}{2m+1}B_{2m+1}\left(\frac{1}{4}\right)\end{eqnarray*}

where :math:`B_{2m+1}\left(\frac{1}{4}\right)` is the Bernoulli polynomial of order :math:`2m+1` evaluated at :math:`1/4.` Thus

.. math::

     \mu_{n}^{\prime}=\left\{
       \begin{array}{cc}
        0 & n \text{ odd}\\
        4\left(-1\right)^{n/2-1}\frac{\left(2\pi\right)^{n}}{n+1}B_{n+1}\left(\frac{1}{4}\right) & n \text{ even}
      \end{array}
      \right.

.. math::
   :nowrap:

    \begin{eqnarray*} m_{d}=m_{n}=\mu & = & 0\\
    \mu_{2} & = & \frac{\pi^{2}}{4}\\
    \gamma_{1} & = & 0\\
    \gamma_{2} & = & 2\end{eqnarray*}

.. math::

     h\left[X\right]=\log\left(2\pi\right).

Implementation: `scipy.stats.hypsecant`

.. _continuous-invweibull:

Inverted Weibull Distribution
=============================

There is one shape parameter :math:`c>0` and the support is  :math:`x\geq0` . Then

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & cx^{-c-1}\exp\left(-x^{-c}\right)\\ F\left(x;c\right) & = & \exp\left(-x^{-c}\right)\\ G\left(q;c\right) & = & \left(-\log q\right)^{-1/c}\end{eqnarray*}

.. math::

     h\left[X\right]=1+\gamma+\frac{\gamma}{c}-\log\left(c\right)

where :math:`\gamma` is Euler's constant.

Implementation: `scipy.stats.invweibull`

.. _continuous-beta:

Beta Distribution
=================

There are two shape parameters :math:`a,b > 0` and the support is :math:`x\in[0,1]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a,b\right) & = & \frac{\Gamma\left(a+b\right)}{\Gamma\left(a\right)\Gamma\left(b\right)}x^{a-1}\left(1-x\right)^{b-1} \\
    F\left(x;a,b\right) & = & \int_{0}^{x}f\left(y;a,b\right)dy=I\left(x;a,b\right)\\
    G\left(q;a,b\right) & = & I^{-1}\left(q;a,b\right)\\
    M\left(t\right) & = & \frac{\Gamma\left(a\right)\Gamma\left(b\right)}{\Gamma\left(a+b\right)}\,_{1}F_{1}\left(a;a+b;t\right)\\
    \mu & = & \frac{a}{a+b}\\
    \mu_{2} & = & \frac{ab\left(a+b+1\right)}{\left(a+b\right)^{2}}\\
    \gamma_{1} & = & 2\frac{b-a}{a+b+2}\sqrt{\frac{a+b+1}{ab}}\\
    \gamma_{2} & = & \frac{6\left(a^{3}+a^{2}\left(1-2b\right)+b^{2}\left(b+1\right)-2ab\left(b+2\right)\right)}{ab\left(a+b+2\right)\left(a+b+3\right)}\\
    m_{d} & = & \frac{\left(a-1\right)}{\left(a+b-2\right)}\, a+b\neq2\end{eqnarray*}

where :math:`I\left(x;a,b\right)` is the regularized incomplete Beta function.  :math:`f\left(x;a,1\right)` is also called the Power-function distribution.

.. math::

     l_{\mathbf{x}}\left(a,b\right)=-N\log\Gamma\left(a+b\right)+N\log\Gamma\left(a\right)+N\log\Gamma\left(b\right)-N\left(a-1\right)\overline{\log\mathbf{x}}-N\left(b-1\right)\overline{\log\left(1-\mathbf{x}\right)}

Implementation: `scipy.stats.beta`

.. _continuous-dweibull:

Double Weibull Distribution
===========================

This is a signed form of the Weibull distribution. There is one shape parameter :math:`c>0`.  Support is :math:`x\in\mathbb{R}`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{c}{2}\left|x\right|^{c-1}\exp\left(-\left|x\right|^{c}\right)\\
    F\left(x;c\right) & = & \left\{
        \begin{array}{ccc}
          \frac{1}{2}\exp\left(-\left|x\right|^{c}\right) &  & x\leq0\\
          1-\frac{1}{2}\exp\left(-\left|x\right|^{c}\right) &  & x>0
        \end{array}
        \right.\\
    G\left(q;c\right) & = & \left\{
        \begin{array}{ccc}
          -\log^{1/c}\left(\frac{1}{2q}\right) &  & q\leq\frac{1}{2}\\
          \log^{1/c}\left(\frac{1}{2q-1}\right) &  & q>\frac{1}{2}
        \end{array}
       \right.\end{eqnarray*}

.. math::

    \mu_{n}^{\prime}=\mu_{n}=\begin{cases}
      \Gamma\left(1+\frac{n}{c}\right) & n\text{ even}\\
      0 & n\text{ odd}
    \end{cases}

.. math::
   :nowrap:

    \begin{eqnarray*} m_{n}=\mu & = & 0\\
    \mu_{2} & = & \Gamma\left(\frac{c+2}{c}\right)\\
    \gamma_{1} & = & 0\\
    \gamma_{2} & = & \frac{\Gamma\left(1+\frac{4}{c}\right)}{\Gamma^{2}\left(1+\frac{2}{c}\right)}\\
    m_{d} & = & \text{NA bimodal}\end{eqnarray*}

Implementation: `scipy.stats.dweibull`
.. _sampling-pinv:

Polynomial interpolation based INVersion of CDF (PINV)
======================================================

.. currentmodule:: scipy.stats.sampling

* Required: PDF
* Optional: CDF, mode, center
* Speed:

  * Set-up: (very) slow
  * Sampling: (very) fast

Polynomial interpolation based INVersion of CDF (PINV) is an inversion method
that only requires the density function to sample from a distribution. It is
based on Polynomial interpolation of the PPF and Gauss-Lobatto integration
of the PDF. It provides control over the interpolation error and integration
error. Its primary purpose is to provide very fast sampling which is nearly
the same for any given distribution at the cost of moderate to slow setup
time. It is the fastest known inversion method for the fixed-parameter case.

The inversion method is the simplest and most flexible to sample nonuniform
random variates. For a target distribution with CDF :math:`F` and a uniform
random variate :math:`U` sampled from :math:`\text{Uniform}(0, 1)`, a random
variate X is generated by transforming the uniform random variate :math:`U`
using the PPF (inverse CDF) of the distribution:

.. math::
    X = F^{-1}(U)

This method is suitable for stochastic simulations because of its advantages.
Some of the most attractive are:

* It preserves the structural properties of the uniform random number sampler.
* Transforms a uniform random variate :math:`U` one-to-one into non-uniform
  random variates :math:`X`.
* Easy and efficient sampling from truncated distributions.

Unfortunately, the PPF is rarely available in closed form or too slow when
available. For many distributions, the CDF is also not easy to obtain. This
method addresses both the shortcomings. The user only has to provide the PDF
and optionally a point near the mode (called "center") together with the size
of the maximal acceptable error. It uses a combination of an adaptive and a
simple Gauss-Lobatto quadrature to obtain the CDF and Newton's interpolation
to obtain the PPF. The method is not exact, as it only produces random
variates of the approximated distribution. Nevertheless, the maximal tolerated
approximation error can be set close to the machine precision. The concept of
u-error is used to measure and control the error. It is defined as:

.. math::
    \epsilon_{u}(u) = | u - F\left(F^{-1}_{a}(u)\right) |

where :math:`u \in (0, 1)` is a quantile where we want to measure the error
and :math:`F^{-1}_a` is the approximated PPF of the given distribution.

The maximal u-error is the criterion for approximation errors when calculating
the CDF and PPF numerically. The maximal tolerated u-error of an algorithm is
called the u-resolution of the algorithm and denoted by :math:`\epsilon_{u}`:

.. math::
    \sup_{u \in (0,1)} | u - F\left(F^{-1}_{a}(u)\right) | \le \epsilon_{u}

The main advantage of the u-error is that it can be easily computed if the CDF
is available. We refer to [1]_ for a more detailed discussion.

Also, the method only works for bounded distributions. In case of infinite
tails, the ends of the tails are cut off such that the area under them is
less than or equal to :math:`0.05\epsilon_{u}`.

There are some restrictions for the given distribution:

* The support of the distribution (i.e., the region where the PDF is strictly
  positive) must be connected. In practice this means, that the region where
  PDF is "not too small" must be connected. Unimodal densities satisfy this
  condition. If this condition is violated then the domain of the distribution
  might be truncated.
* When the PDF is integrated numerically, then the given PDF must be
  continuous and should be smooth.
* The PDF must be bounded.
* The algorithm has problems when the distribution has heavy tails (as then
  the inverse CDF becomes very steep at 0 or 1) and the requested u-resolution
  is very small. E.g., the Cauchy distribution is likely to show this problem
  when the requested u-resolution is less than 1.e-12.

.. warning::
    This method does not work for densities with constant parts (e.g.
    `uniform` distribution) and segmentation faults if such a density is
    passed to the constructor. It is recommended to use the
    `composition method <https://statmath.wu.ac.at/software/unuran/doc/unuran.html#Composition>`__
    to sample from such distributions.

Following four steps are carried out by the algorithm during setup:

* Computing the end points of the distribution: If a finite support is given,
  this step is skipped. Otherwise, the ends of the tails are cut off such that
  the area under them is less than or equal to :math:`0.05\epsilon_{u}`.
* The domain is divided into subintervals to compute the CDF and PPF.
* The CDF is computed using Gauss-Lobatto quadrature such that the integration
  error is at most :math:`0.05I_{0}\epsilon_{u}` where :math:`I_{0}` is
  approximately the total area under the PDF.
* The PPF is computed using Newton's interpolating formula with maximum
  interpolation error :math:`0.9\epsilon_{u}`.

To initialize the generator to sample from a standard normal distribution, do:

    >>> from scipy.stats.sampling import NumericalInversePolynomial
    >>> class StandardNormal:
    ...     def pdf(self, x):
    ...         return np.exp(-0.5 * x*x)
    ...
    >>> dist = StandardNormal()
    >>> urng = np.random.default_rng()
    >>> rng = NumericalInversePolynomial(dist, random_state=urng)

The generator has been setup and we can start sampling from our distribution:

    >>> rng.rvs((5, 3))
    array([[-1.52449963,  1.31933688,  2.05884468],
           [ 0.48883931,  0.15207903, -0.02150773],
           [ 1.11486463,  1.95449597, -0.30724928],
           [ 0.9854643 ,  0.29867424,  0.7560304 ],
           [-0.61776203,  0.16033378, -1.00933003]])

We can look at the histogram of the random variates to check how well they fit
our distribution:

.. plot::

    >>> import matplotlib.pyplot as plt
    >>> from scipy.stats import norm
    >>> from scipy.stats.sampling import NumericalInversePolynomial
    >>> class StandardNormal:
    ...     def pdf(self, x):
    ...         return np.exp(-0.5 * x*x)
    ...
    >>> dist = StandardNormal()
    >>> urng = np.random.default_rng()
    >>> rng = NumericalInversePolynomial(dist, random_state=urng)
    >>> rvs = rng.rvs(10000)
    >>> x = np.linspace(rvs.min()-0.1, rvs.max()+0.1, num=10000)
    >>> fx = norm.pdf(x)
    >>> plt.plot(x, fx, "r-", label="pdf")
    >>> plt.hist(rvs, bins=50, density=True, alpha=0.8, label="rvs")
    >>> plt.xlabel("x")
    >>> plt.ylabel("PDF(x)")
    >>> plt.title("Samples drawn using PINV method.")
    >>> plt.legend()
    >>> plt.show()

The maximum tolerated error (i.e. u-resolution) can be changed by passing the
``u_resolution`` keyword during initialization:

    >>> rng = NumericalInversePolynomial(dist, u_resolution=1e-12,
    ...                                  random_state=urng)

This leads to a more accurate approximation of the PPF and the
generated RVs follow the exact distribution more closely. Although, note
that it comes at the cost of an expensive setup.

The setup time mainly depends on the number of times the PDF is evaluated.
It is more costly for PDFs that are difficult to evaluate. Note that we can
ignore the normalization constant to speed up the evaluations of the PDF.
PDF evaluations increase during setup for small values of ``u_resolution``.

    >>> from scipy.stats.sampling import NumericalInversePolynomial
    >>> class StandardNormal:
    ...     def __init__(self):
    ...         self.callbacks = 0
    ...     def pdf(self, x):
    ...         self.callbacks += 1
    ...         return np.exp(-0.5 * x*x)
    ... 
    >>> dist = StandardNormal()
    >>> urng = np.random.default_rng()
    >>> # u_resolution = 10^-8
    >>> # => less PDF evaluations required
    >>> # => faster setup
    >>> rng = NumericalInversePolynomial(dist, u_resolution=1e-8,
    ...                                  random_state=urng)
    >>> dist.callbacks
    4095
    >>> dist.callbacks = 0  # reset the number of callbacks
    >>> # u_resolution = 10^-10 (default)
    >>> # => more PDF evaluations required
    >>> # => slow setup
    >>> rng = NumericalInversePolynomial(dist, u_resolution=1e-10,
    ...                                  random_state=urng)
    >>> dist.callbacks
    11454
    >>> dist.callbacks = 0  # reset the number of callbacks
    >>> # u_resolution = 10^-12
    >>> # => lots of PDF evaluations required
    >>> # => very slow setup
    >>> rng = NumericalInversePolynomial(dist, u_resolution=1e-12,
    ...                                  random_state=urng)
    13902

As we can see, the number of PDF evaluations required is very high and a
fast PDF is critical to the algorithm. Though, this helps reduce the number
of subintervals required to achieve the error goal which saves memory and
makes sampling fast. `NumericalInverseHermite` is a similar inversion method
that inverts the CDF based on Hermite interpolation and provides control
over the maximum tolerated error via u-resolution. But it makes use of a lot
more intervals compared to `NumericalInversePolynomial`:

    >>> from scipy.stats.sampling import NumericalInverseHermite
    >>> # NumericalInverseHermite accepts a `tol` parameter to set the
    >>> # u-resolution of the generator.
    >>> rng_hermite = NumericalInverseHermite(norm(), tol=1e-12)
    >>> rng_hermite.intervals
    3000
    >>> rng_poly = NumericalInversePolynomial(norm(), u_resolution=1e-12)
    >>> rng_poly.intervals
    252

When exact CDF of a distribution is available, one can estimate the u-error
achieved by the algorithm by calling the
:func:`~NumericalInversePolynomial.u_error` method:

    >>> from scipy.special import ndtr
    >>> class StandardNormal:
    ...     def pdf(self, x):
    ...         return np.exp(-0.5 * x*x)
    ...     def cdf(self, x):
    ...         return ndtr(x)
    ... 
    >>> dist = StandardNormal()
    >>> urng = np.random.default_rng()
    >>> rng = NumericalInversePolynomial(dist, random_state=urng)
    >>> rng.u_error(sample_size=100_000)
    UError(max_error=8.785949745515609e-11, mean_absolute_error=2.9307548109436816e-11)

:func:`~NumericalInversePolynomial.u_error` runs a monte carlo simulation with
a given number of samples to estimate the u-error. In the above example,
100,000 samples are used by the simulation to approximate the u-error. It
returns the maximum u-error (``max_error``) and the mean absolute u-error
(``mean_absolute_error``) in a ``UError`` namedtuple. As we can see,
``max_error`` is below the default ``u_resolution`` (``1e-10``).

It is also possible to evaluate the PPF of the given distribution once the
generator is initialized:

    >>> rng.ppf(0.975)
    1.959963985701268
    >>> norm.ppf(0.975)
    1.959963984540054

We can use this, for example, to check the maximum and mean absolute u-error:

    >>> u = np.linspace(0.001, 0.999, num=1_000_000)
    >>> u_errors = np.abs(u - dist.cdf(rng.ppf(u)))
    >>> u_errors.max()
    8.78600525666684e-11
    >>> u_errors.mean()
    2.9321444940323206e-11

The approximate PPF method provided by the generator is much faster to
evaluate than the exact PPF of the distribution.

During setup, a table of CDF points is stored that can be used to approximate the
CDF once the generator has been created:

    >>> rng.cdf(1.959963984540054)
    0.9750000000042454
    >>> norm.cdf(1.959963984540054)
    0.975

We can use this to check if the integration error while computing the CDF
exceeds :math:`0.05I_{0}\epsilon_{u}`. Here :math:`I_0` is
:math:`\sqrt{2\pi}` (the normalization constant for the standard normal
distribution):

    >>> x = np.linspace(-10, 10, num=100_000)
    >>> x_error = np.abs(dist.cdf(x) - rng.cdf(x))
    >>> x_error.max()
    4.506062190046123e-12
    >>> I0 = np.sqrt(2*np.pi)
    >>> max_integration_error = 0.05 * I0 * 1e-10
    >>> x_error.max() <= max_integration_error
    True

The CDF table computed during setup is used to evaluate the CDF and only some
further fine-tuning is required. This reduces the calls to the PDF but as the
fine-tuning step uses the simple Gauss-Lobatto quadrature, the PDF is called
several times, slowing down the computation.

References
----------

.. [1] Derflinger, Gerhard, Wolfgang Hörmann, and Josef Leydold. "Random variate
       generation by numerical inversion when only the density is known." ACM
       Transactions on Modeling and Computer Simulation (TOMACS) 20.4 (2010): 1-25.

.. _continuous-foldnorm:

Folded Normal Distribution
==========================

If :math:`Z` is Normal with mean :math:`L` and :math:`\sigma=S` , then :math:`\left|Z\right|` is a folded normal with shape parameter :math:`c=\left|L\right|/S` , location parameter :math:`0` and scale parameter :math:`S` . This is a special case of the non-central chi distribution with one-
degree of freedom and non-centrality parameter :math:`c^{2}.` Note that :math:`c\geq0` . The standard form of the folded normal is

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \sqrt{\frac{2}{\pi}}\cosh\left(cx\right)\exp\left(-\frac{x^{2}+c^{2}}{2}\right)\\
    F\left(x;c\right) & = & \Phi\left(x-c\right)-\Phi\left(-x-c\right)=\Phi\left(x-c\right)+\Phi\left(x+c\right)-1\\
    G\left(q;c\right) & = & F^{-1}\left(q;c\right)\\
    M\left(t\right) & = & \exp\left(\frac{t}{2}\left(t-2c\right)\right) \left(1+e^{2ct}\right)\\
    k & = & \mathrm{erf}\left(\frac{c}{\sqrt{2}}\right)\\
    p & = & \exp\left(-\frac{c^{2}}{2}\right)\\
    \mu & = & \sqrt{\frac{2}{\pi}}p+ck\\
    \mu_{2} & = & c^{2}+1-\mu^{2}\\
    \gamma_{1} & = & \frac{\sqrt{\frac{2}{\pi}}p^{3}\left(4-\frac{\pi}{p^{2}}\left(2c^{2}+1\right)\right)+2ck\left(6p^{2}+3cpk\sqrt{2\pi}+\pi c\left(k^{2}-1\right)\right)}{\pi\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{c^{4}+6c^{2}+3+6\left(c^{2}+1\right)\mu^{2}-3\mu^{4}-4p\mu\left(\sqrt{\frac{2}{\pi}}\left(c^{2}+2\right)+\frac{ck}{p}\left(c^{2}+3\right)\right)}{\mu_{2}^{2}}\end{eqnarray*}

Implementation: `scipy.stats.foldnorm`

.. _continuous-genexpon:

Generalized Exponential Distribution
====================================

Three positive shape parameters :math:`a,b,c>0` with support :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a,b,c\right) & = & \left(a+b\left(1-e^{-cx}\right)\right)\exp\left(ax-bx+\frac{b}{c}\left(1-e^{-cx}\right)\right)\\
    F\left(x;a,b,c\right) & = & 1-\exp\left(ax-bx+\frac{b}{c}\left(1-e^{-cx}\right)\right)\\
    G\left(q;a,b,c\right) & = & F^{-1}\end{eqnarray*}

Implementation: `scipy.stats.genexpon`
.. _continuous-trapezoid:

Trapezoidal Distribution
========================

Two shape parameters :math:`c\in[0,1], d\in[0, 1]` giving the distances to the
first and second modes as a percentage of the total extent of
the non-zero portion. The location parameter is the start of the non-
zero portion, and the scale-parameter is the width of the non-zero
portion. In standard form we have :math:`x\in\left[0,1\right].`

.. math::
   :nowrap:

    \begin{eqnarray*}
        u(c, d) & = & \frac{2}{d - c + 1} \\
        f\left(x;c, d\right) & = & \left\{
                                    \begin{array}{ccc}
                                        \frac{ux}{c} &  & x < c \\
                                        u & & c\leq x \leq d \\
                                        u\frac{1-x}{1-d} &  & x > d \\
                                    \end{array}
                                \right.\\
        F\left(x;c, d\right) & = & \left\{
                                    \begin{array}{ccc}
                                        \frac{ux^{2}}{2c} &  & x < c \\
                                        \frac{uc}{2} + u(x-c) &  & c\leq x \leq d \\
                                        1 - \frac{u(1 - x)^2}{2(1 - d)} &  & x > d \\
                                    \end{array}
                                \right.\\
        G\left(q;c, d\right) & = & \left\{
                                    \begin{array}{ccc}
                                        \sqrt{qc(d-c+1)} &  & q < c \\
                                        \frac{q}{u}+ \frac{c}{2} &  & q \leq d \\
                                        1 - \sqrt{\frac{2(1 - q) (1 - d)}{u}} &  & q > d \\
                                    \end{array}
                                \right.
    \end{eqnarray*}


Implementation: `scipy.stats.trapezoid`

.. _continuous-gamma:

Gamma Distribution
==================

The standard form for the gamma distribution is :math:`\left(\alpha>0\right)` valid for :math:`x\geq0` .

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\alpha\right) & = & \frac{1}{\Gamma\left(\alpha\right)}x^{\alpha-1}e^{-x}\\
    F\left(x;\alpha\right) & = & \frac{\gamma\left(\alpha,x\right)}{\Gamma(\alpha)}\\
    G\left(q;\alpha\right) & = & \gamma^{-1}\left(\alpha,q\Gamma(\alpha)\right)\end{eqnarray*}

where :math:`\gamma` is the lower incomplete gamma function, :math:`\gamma\left(s, x\right) = \int_0^x t^{s-1} e^{-t} dt`.

.. math::

     M\left(t\right)=\frac{1}{\left(1-t\right)^{\alpha}}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \alpha\\
    \mu_{2} & = & \alpha\\
    \gamma_{1} & = & \frac{2}{\sqrt{\alpha}}\\
    \gamma_{2} & = & \frac{6}{\alpha}\\
    m_{d} & = & \alpha-1\end{eqnarray*}

.. math::

     h\left[X\right]=\Psi\left(a\right)\left[1-a\right]+a+\log\Gamma\left(a\right)

where

.. math::

     \Psi\left(a\right)=\frac{\Gamma^{\prime}\left(a\right)}{\Gamma\left(a\right)}.

Implementation: `scipy.stats.gamma`

.. _continuous-loggamma:

Log Gamma Distribution
======================

A single shape parameter :math:`c>0` . The support is :math:`x\in\mathbb{R}`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{\exp\left(cx-e^{x}\right)}{\Gamma\left(c\right)}\\
    F\left(x;c\right) & = & \frac{\gamma\left(c,e^{x}\right)}{\Gamma\left(c\right)}\\
    G\left(q;c\right) & = & \log\left(\gamma^{-1}\left(c,q\Gamma\left(c\right)\right)\right)\end{eqnarray*}

where :math:`\gamma` is the lower incomplete gamma function, :math:`\gamma\left(s, x\right) = \int_0^x t^{s-1} e^{-t} dt`.

.. math::

     \mu_{n}^{\prime}=\int_{0}^{\infty}\left[\log y\right]^{n}y^{c-1}\exp\left(-y\right)dy.

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \mu_{1}^{\prime}\\
    \mu_{2} & = & \mu_{2}^{\prime}-\mu^{2}\\
    \gamma_{1} & = & \frac{\mu_{3}^{\prime}-3\mu\mu_{2}-\mu^{3}}{\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{\mu_{4}^{\prime}-4\mu\mu_{3}-6\mu^{2}\mu_{2}-\mu^{4}}{\mu_{2}^{2}}-3\end{eqnarray*}

Implementation: `scipy.stats.loggamma`

.. _continuous-rice:

Rice Distribution
=================

There is one shape parameter :math:`b\geq0` (the "distance from the origin") and the support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;b\right) & = & x\exp\left(-\frac{x^{2}+b^{2}}{2}\right)I_{0}\left(xb\right)\\
    F\left(x;b\right) & = & \int_{0}^{x}\alpha\exp\left(-\frac{\alpha^{2}+b^{2}}{2}\right)I_{0}\left(\alpha b\right)d\alpha\end{eqnarray*}

were  :math:`I_{0}(y)` is the modified Bessel function of the first kind of order 0.

.. math::

     \mu_{n}^{\prime}=\sqrt{2^{n}}\Gamma\left(1+\frac{n}{2}\right)\,_{1}F_{1}\left(-\frac{n}{2};1;-\frac{b^{2}}{2}\right)

Implementation: `scipy.stats.rice`

.. _discrete-nhypergeom:

Negative Hypergeometric Distribution
====================================

Consider a box containing :math:`M` balls: :math:`n` red and :math:`M-n` blue. We randomly sample balls from the box, one at a time and *without* replacement, until we have picked :math:`r` blue balls. `nhypergeom` is the distribution of the number of red balls :math:`k` we have picked.

.. math::
   :nowrap:

    \begin{eqnarray*}
    p(k;M,n,r) & = & \frac{\left(\begin{array}{c} k+r-1\\ k\end{array}\right)\left(\begin{array}{c} M-r-k\\ n-k\end{array}\right)}{\left(\begin{array}{c} M\\ n\end{array}\right)}\quad 0 \leq k \leq M-n,\\
    F(x;M,n,r) & = & \sum_{k=0}^{\left\lfloor x\right\rfloor }p\left(k;M,n,r\right),\\
    \mu & = & \frac{rn}{M-n+1},\\
    \mu_{2} & = & \frac{rn(M+1)}{(M-n+1)(M-n+2)}\left(1-\frac{r}{M-n+1}\right)
    \end{eqnarray*}

for :math:`k \in 0, 1, 2, ..., n`, where the binomial coefficients are defined as,

.. math::
   :nowrap:

    \begin{eqnarray*} \binom{n}{k} \equiv \frac{n!}{k! (n - k)!} \end{eqnarray*}

The cumulative distribution, survivor function, hazard function, cumulative hazard function, inverse distribution function, moment generating function, and characteristic function on the support of :math:`k` are mathematically intractable.

Implementation: `scipy.stats.nhypergeom`

.. _continuous-halflogistic:

Half-Logistic Distribution
==========================

In the limit as :math:`c\rightarrow\infty` for the generalized half-logistic we have the half-logistic defined
over :math:`x\geq0.` Also, the distribution of :math:`\left|X\right|` where :math:`X` has logistic distribution.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{2e^{-x}}{\left(1+e^{-x}\right)^{2}}=\frac{1}{2}\mathrm{sech}^{2}\left(\frac{x}{2}\right)\\
    F\left(x\right) & = & \frac{1-e^{-x}}{1+e^{-x}}=\tanh\left(\frac{x}{2}\right)\\
    G\left(q\right) & = & \log\left(\frac{1+q}{1-q}\right)=2\mathrm{arctanh}\left(q\right)\end{eqnarray*}

.. math::

     M\left(t\right)=1-t\psi_{0}\left(\frac{1}{2}-\frac{t}{2}\right)+t\psi_{0}\left(1-\frac{t}{2}\right)

where :math:`\psi_m` is the polygamma function :math:`\psi_m(z) = \frac{d^{m+1}}{dz^{m+1}} \log(\Gamma(z))`.


.. math::

     \mu_{n}^{\prime}=2\left(1-2^{1-n}\right)n!\zeta\left(n\right)\quad n\neq1

.. math::
   :nowrap:

    \begin{eqnarray*} \mu_{1}^{\prime} & = & 2\log\left(2\right)\\
    \mu_{2}^{\prime} & = & 2\zeta\left(2\right)=\frac{\pi^{2}}{3}\\
    \mu_{3}^{\prime} & = & 9\zeta\left(3\right)\\
    \mu_{4}^{\prime} & = & 42\zeta\left(4\right)=\frac{7\pi^{4}}{15}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & 2-\log\left(2\right)\\  & \approx & 1.3068528194400546906.\end{eqnarray*}

Implementation: `scipy.stats.halflogistic`

.. _sampling-dau:

Discrete Alias Urn (DAU)
========================

.. currentmodule:: scipy.stats.sampling

* Required: probability vector (PV) or the PMF along with a finite domain
* Speed:

    * Set-up: slow (linear with the vector-length)
    * Sampling: very fast 


DAU samples from distributions with arbitrary but finite probability vectors
(PV) of length N. The algorithm is based on an ingenious method by A.J.
Walker and requires a table of size (at least) N. It needs one random number
and only one comparison for each generated random variate. The setup time for
constructing the tables is O(N).

    >>> import numpy as np
    >>> from scipy.stats.sampling import DiscreteAliasUrn
    >>> 
    >>> pv = [0.18, 0.02, 0.8]
    >>> urng = np.random.default_rng()
    >>> rng = DiscreteAliasUrn(pv, random_state=urng)
    >>> rng.rvs()
    0

By default, the probability vector is indexed starting at 0. However, this
can be changed by passing a ``domain`` parameter. When ``domain`` is given
in combination with the PV, it has the effect of relocating the
distribution from ``(0, len(pv))`` to ``(domain[0]``, ``domain[0] + len(pv))``.
``domain[1]`` is ignored in this case.

   >>> rng = DiscreteAliasUrn(pv, domain=(10, 13), random_state=urng)
   >>> rng.rvs()
   12

The method also works when no probability vector but a PMF is given.
In that case, a bounded (finite) domain must also be given either by
passing the ``domain`` parameter explicitly or by providing a ``support``
method in the distribution object:

    >>> class Distribution:
    ...     def __init__(self, c):
    ...         self.c = c
    ...     def pmf(self, x):
    ...         return x**self.c
    ...     def support(self):
    ...         return (0, 10)
    ... 
    >>> dist = Distribution(2)
    >>> rng = DiscreteAliasUrn(dist, random_state=urng)
    >>> rng.rvs()
    10

.. plot::

    >>> import matplotlib.pyplot as plt
    >>> from scipy.stats.sampling import DiscreteAliasUrn
    >>> class Distribution:
    ...     def __init__(self, c):
    ...         self.c = c
    ...     def pmf(self, x):
    ...         return x**self.c
    ...     def support(self):
    ...         return (0, 10)
    ... 
    >>> dist = Distribution(2)
    >>> urng = np.random.default_rng()
    >>> rng = DiscreteAliasUrn(dist, random_state=urng)
    >>> rvs = rng.rvs(1000)
    >>> fig = plt.figure()
    >>> ax = fig.add_subplot(111)
    >>> x = np.arange(1, 11)
    >>> fx = dist.pmf(x)
    >>> fx = fx / fx.sum()
    >>> ax.plot(x, fx, 'bo', label='true distribution')
    >>> ax.vlines(x, 0, fx, lw=2)
    >>> ax.hist(rvs, bins=np.r_[x, 11]-0.5, density=True, alpha=0.5, color='r',
    ...         label='samples')
    >>> ax.set_xlabel('x')
    >>> ax.set_ylabel('PMF(x)')
    >>> ax.set_title('Discrete Alias Urn Samples')
    >>> plt.legend()
    >>> plt.show()

.. note:: As :class:`~DiscreteAliasUrn` expects PMF with signature
          ``def pmf(self, x: float) -> float``, it first vectorizes the
          PMF using ``np.vectorize`` and then evaluates it over all the
          points in the domain. But if the PMF is already vectorized,
          it is much faster to just evaluate it at each point in the domain
          and pass the obtained PV instead along with the domain.
          For example, ``pmf`` methods of SciPy's discrete distributions
          are vectorized and a PV can be obtained by doing:

          >>> from scipy.stats import binom
          >>> from scipy.stats.sampling import DiscreteAliasUrn
          >>> dist = binom(10, 0.2)  # distribution object
          >>> domain = dist.support()  # the domain of your distribution
          >>> x = np.arange(domain[0], domain[1] + 1)
          >>> pv = dist.pmf(x)
          >>> rng = DiscreteAliasUrn(pv, domain=domain)

          Domain is required here to relocate the distribution.

The performance can be slightly influenced by setting the size of the used
table which can be changed by passing a ``urn_factor`` parameter.

    >>> # use a table twice the length of PV.
    >>> urn_factor = 2
    >>> rng = DiscreteAliasUrn(pv, urn_factor=urn_factor, random_state=urng)
    >>> rng.rvs()
    2

.. note:: It is recommended to keep this parameter under 2.

Please see [1]_ and [2]_ for more details on this method.


References
----------

.. [1] UNU.RAN reference manual, Section 5.8.2,
       "DAU - (Discrete) Alias-Urn method",
       http://statmath.wu.ac.at/software/unuran/doc/unuran.html#DAU
.. [2] A.J. Walker (1977). An efficient method for generating discrete
       random variables with general distributions, ACM Trans. Math.
       Software 3, pp. 253-256.

.. _continuous-genextreme:

Generalized Extreme Value Distribution
======================================

Extreme value distributions with one shape parameter :math:`c`.

If :math:`c>0`, the support is :math:`-\infty<x\leq1/c.`  If :math:`c<0`, the support is :math:`\frac{1}{c}\leq x<\infty.`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \exp\left(-\left(1-cx\right)^{1/c}\right)\left(1-cx\right)^{1/c-1}\\
    F\left(x;c\right) & = & \exp\left(-\left(1-cx\right)^{1/c}\right)\\
    G\left(q;c\right) & = & \frac{1}{c}\left(1-\left(-\log q\right)^{c}\right)\end{eqnarray*}

.. math::

     \mu_{n}^{\prime}=\frac{1}{c^{n}} \sum_{k=0}^{n} \binom{n}{k} \left(-1\right)^{k}\Gamma\left(ck+1\right)\quad\text{if } cn>-1

So,

.. math::
   :nowrap:

    \begin{eqnarray*} \mu_{1}^{\prime} & = & \frac{1}{c}\left(1-\Gamma\left(1+c\right)\right)\quad c>-1\\
    \mu_{2}^{\prime} & = & \frac{1}{c^{2}}\left(1-2\Gamma\left(1+c\right)+\Gamma\left(1+2c\right)\right)\quad c>-\frac{1}{2}\\
    \mu_{3}^{\prime} & = & \frac{1}{c^{3}}\left(1-3\Gamma\left(1+c\right)+3\Gamma\left(1+2c\right)-\Gamma\left(1+3c\right)\right)\quad c>-\frac{1}{3}\\
    \mu_{4}^{\prime} & = & \frac{1}{c^{4}}\left(1-4\Gamma\left(1+c\right)+6\Gamma\left(1+2c\right)-4\Gamma\left(1+3c\right)+\Gamma\left(1+4c\right)\right)\quad c>-\frac{1}{4}\end{eqnarray*}


For :math:`c=0` the distribution is the same as the (left-skewed) Gumbel distribution, and the support is :math:`\mathbb{R}`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;0\right) & = & \exp\left(-e^{-x}\right)e^{-x}\\
    F\left(x;0\right) & = & \exp\left(-e^{-x}\right)\\
    G\left(q;0\right) & = & -\log\left(-\log q\right)\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \gamma=-\psi_{0}\left(1\right)\\
    \mu_{2} & = & \frac{\pi^{2}}{6}\\
    \gamma_{1} & = & \frac{12\sqrt{6}}{\pi^{3}}\zeta\left(3\right)\\
    \gamma_{2} & = & \frac{12}{5}\end{eqnarray*}

Implementation: `scipy.stats.genextreme`

.. _continuous-recipinvgauss:

Reciprocal Inverse Gaussian Distribution
========================================

The pdf is found from the inverse gaussian (IG), :math:`f_{RIG}\left(x;\mu\right)=\frac{1}{x^{2}}f_{IG}\left(\frac{1}{x};\mu\right)` defined for :math:`x\geq0` as

.. math::
   :nowrap:

    \begin{eqnarray*} f_{IG}\left(x;\mu\right) & = & \frac{1}{\sqrt{2\pi x^{3}}}\exp\left(-\frac{\left(x-\mu\right)^{2}}{2x\mu^{2}}\right).\\ F_{IG}\left(x;\mu\right) & = & \Phi\left(\frac{1}{\sqrt{x}}\frac{x-\mu}{\mu}\right)+\exp\left(\frac{2}{\mu}\right)\Phi\left(-\frac{1}{\sqrt{x}}\frac{x+\mu}{\mu}\right)\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} f_{RIG}\left(x;\mu\right) & = & \frac{1}{\sqrt{2\pi x}}\exp\left(-\frac{\left(1-\mu x\right)^{2}}{2x\mu^{2}}\right)\\ F_{RIG}\left(x;\mu\right) & = & 1-F_{IG}\left(\frac{1}{x},\mu\right)\\  & = & 1-\Phi\left(\frac{1}{\sqrt{x}}\frac{1-\mu x}{\mu}\right)-\exp\left(\frac{2}{\mu}\right)\Phi\left(-\frac{1}{\sqrt{x}}\frac{1+\mu x}{\mu}\right)\end{eqnarray*}

Implementation: `scipy.stats.recipinvgauss`

.. _continuous-chi2:

Chi-squared Distribution
========================

This is the gamma distribution with :math:`L=0.0` and :math:`S=2.0` and :math:`\alpha=\nu/2` where :math:`\nu` is called the degrees of freedom. If :math:`Z_{1}\ldots Z_{\nu}` are all standard normal distributions, then :math:`W=\sum_{k}Z_{k}^{2}` has (standard) chi-square distribution with :math:`\nu` degrees of freedom.

The standard form (most often used in standard form only) has support :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\alpha\right) & = & \frac{1}{2\Gamma\left(\frac{\nu}{2}\right)}\left(\frac{x}{2}\right)^{\nu/2-1}e^{-x/2}\\
    F\left(x;\alpha\right) & = & \frac{\gamma\left(\frac{\nu}{2},\frac{x}{2}\right)}{\Gamma(\frac{\nu}{2})}\\
    G\left(q;\alpha\right) & = & 2\gamma^{-1}\left(\frac{\nu}{2},q{\Gamma(\frac{\nu}{2})}\right)\end{eqnarray*}

where :math:`\gamma` is the lower incomplete gamma function, :math:`\gamma\left(s, x\right) = \int_0^x t^{s-1} e^{-t} dt`.

.. math::

     M\left(t\right)=\frac{\Gamma\left(\frac{\nu}{2}\right)}{\left(\frac{1}{2}-t\right)^{\nu/2}}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \nu\\
    \mu_{2} & = & 2\nu\\
    \gamma_{1} & = & \frac{2\sqrt{2}}{\sqrt{\nu}}\\
    \gamma_{2} & = & \frac{12}{\nu}\\
    m_{d} & = & \frac{\nu}{2}-1\end{eqnarray*}

Implementation: `scipy.stats.chi2`

.. _continuous-f:

Fratio (or F) Distribution
==========================

The distribution of :math:`\left(X_{1}/X_{2}\right)\left(\nu_{2}/\nu_{1}\right)`
if :math:`X_{1}` is chi-squared with :math:`v_{1}` degrees of freedom
and :math:`X_{2}` is chi-squared with :math:`v_{2}` degrees of freedom.
The support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\nu_{1},\nu_{2}\right) & = & \frac{\nu_{2}^{\nu_{2}/2}\nu_{1}^{\nu_{1}/2}x^{\nu_{1}/2-1}}{\left(\nu_{2}+\nu_{1}x\right)^{\left(\nu_{1}+\nu_{2}\right)/2}B\left(\frac{\nu_{1}}{2},\frac{\nu_{2}}{2}\right)}\\
    F\left(x;v_{1},v_{2}\right) & = & I\left(\frac{\nu_{1}x}{\nu_{2}+\nu_{1}x}; \frac{\nu_{1}}{2},\frac{\nu_{2}}{2}\right)\\
    G\left(q;\nu_{1},\nu_{2}\right) & = & \left(\frac{\nu_{2}} {I^{-1}\left(q; \nu_{1}/2,\nu_{2}/2\right)}-\frac{\nu_{1}}{\nu_{2}}\right)^{-1}\\
    \mu & = & \frac{\nu_{2}}{\nu_{2}-2}\quad\textrm{for }\nu_{2}>2\\
    \mu_{2} & = & \frac{2\nu_{2}^{2}\left(\nu_{1}+\nu_{2}-2\right)}{\nu_{1}\left(\nu_{2}-2\right)^{2}\left(\nu_{2}-4\right)}\quad\textrm{for } v_{2}>4\\
    \gamma_{1} & = & \frac{2\left(2\nu_{1}+\nu_{2}-2\right)}{\nu_{2}-6}\sqrt{\frac{2\left(\nu_{2}-4\right)}{\nu_{1}\left(\nu_{1}+\nu_{2}-2\right)}}\quad\textrm{for }\nu_{2}>6\\
    \gamma_{2} & = & \frac{3\left(8+\left(\nu_{2}-6\right)\gamma_{1}^{2}\right)}{2\nu-16}\quad\textrm{for }\nu_{2}>8\end{eqnarray*}

where :math:`I\left(x;a,b\right)=I_{x}\left(a,b\right)` is the regularized incomplete Beta function.

Implementation: `scipy.stats.f`

.. _continuous-johnsonsb:

Johnson SB Distribution
=======================

There are two shape parameters :math:`a\in\mathbb{R}` and :math:`b>0`, and the support is :math:`x\in\left[0,1\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a,b\right) & = & \frac{b}{x\left(1-x\right)}\phi\left(a+b\log\frac{x}{1-x}\right)\\
    F\left(x;a,b\right) & = & \Phi\left(a+b\log\frac{x}{1-x}\right)\\
    G\left(q;a,b\right) & = & \frac{1}{1+\exp\left(-\frac{1}{b}\left(\Phi^{-1}\left(q\right)-a\right)\right)}\end{eqnarray*}

Implementation: `scipy.stats.johnsonsb`

.. _discrete-binom:

Binomial Distribution
=====================

A binomial random variable with parameters :math:`\left(n,p\right)` can be described as the sum of :math:`n` independent Bernoulli random variables of parameter :math:`p;`

.. math::

    Y=\sum_{i=1}^{n}X_{i}.

Therefore, this random variable counts the number of successes in :math:`n` independent trials of a random experiment where the probability of
success is :math:`p.`

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;n,p\right) & = & \left(\begin{array}{c} n\\ k\end{array}\right)p^{k}\left(1-p\right)^{n-k}\,\, k\in\left\{ 0,1,\ldots n\right\} ,\\ F\left(x;n,p\right) & = & \sum_{k\leq x}\left(\begin{array}{c} n\\ k\end{array}\right)p^{k}\left(1-p\right)^{n-k}=I_{1-p}\left(n-\left\lfloor x\right\rfloor ,\left\lfloor x\right\rfloor +1\right)\quad x\geq0\end{eqnarray*}

where the incomplete beta integral is

.. math::

    I_{x}\left(a,b\right)=\frac{\Gamma\left(a+b\right)}{\Gamma\left(a\right)\Gamma\left(b\right)}\int_{0}^{x}t^{a-1}\left(1-t\right)^{b-1}dt.

Now

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & np\\ \mu_{2} & = & np\left(1-p\right)\\ \gamma_{1} & = & \frac{1-2p}{\sqrt{np\left(1-p\right)}}\\ \gamma_{2} & = & \frac{1-6p\left(1-p\right)}{np\left(1-p\right)}.\end{eqnarray*}

.. math::

    M\left(t\right)=\left[1-p\left(1-e^{t}\right)\right]^{n}

Implementation: `scipy.stats.binom`

.. _continuous-arcsine:

Arcsine Distribution
====================

Defined over :math:`x\in\left[0,1\right]`.  To get the definition presented in Johnson, Kotz, and Balakrishnan, substitute :math:`x=\frac{u+1}{2}.` i.e. :math:`L=-1` and :math:`S=2.`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{1}{\pi\sqrt{x\left(1-x\right)}}\\ F\left(x\right) & = & \frac{2}{\pi}\arcsin\left(\sqrt{x}\right)\\ G\left(q\right) & = & \sin^{2}\left(\frac{\pi}{2}q\right)\end{eqnarray*}

.. math::

     M\left(t\right)=1 + \sum_{k=1}^\infty \left( \prod_{r=0}^{k-1} \frac{2r + 1}{2r+2} \right) \frac{t^k}{k!}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu_{n}^{\prime} & = & \frac{1}{\pi}\int_{0}^{1} x^{n-1/2}\left(1-x\right)^{-1/2} dx\\
     & = & \frac{1}{\pi}B\left(\frac{1}{2},n+\frac{1}{2}\right)=\frac{\left(2n-1\right)!!}{2^{n}n!}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{1}{2}\\ \mu_{2} & = & \frac{1}{8}\\ \gamma_{1} & = & 0\\ \gamma_{2} & = & -\frac{3}{2}\end{eqnarray*}

.. math::

     h\left[X\right] = \log(\frac{\pi}{4}) \approx-0.24156447527049044468

.. math::

     l_{\mathbf{x}}\left(\cdot\right)=N\log\pi+\frac{N}{2}\overline{\log\mathbf{x}}+\frac{N}{2}\overline{\log\left(1-\mathbf{x}\right)}

References
----------

- Norman Johnson, Samuel Kotz, and N. Balakrishnan, Continuous Univariate Distributions, second edition, Volumes I and II, Wiley & Sons, 1994.

- "Arcsine Distribution", Wikipedia, https://en.wikipedia.org/wiki/Arcsine_distribution

Implementation: `scipy.stats.arcsine`

.. _continuous-genpareto:

Generalized Pareto Distribution
===============================

There is one shape parameter :math:`c\neq0`.  The support is :math:`x\geq0` if :math:`c>0`,
and :math:`0\leq x<\frac{1}{\left|c\right|}` if :math:`c` is negative.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \left(1+cx\right)^{-1-\frac{1}{c}}\\
    F\left(x;c\right) & = & 1-\frac{1}{\left(1+cx\right)^{1/c}}\\
    G\left(q;c\right) & = & \frac{1}{c}\left[\left(\frac{1}{1-q}\right)^{c}-1\right]\end{eqnarray*}

.. Comment Is it \gamma\left(-\frac{1}{c},-\frac{t}{c}\right) or \Gamma\left(-\frac{1}{c},-\frac{t}{c}\right) below?


.. math::

    M\left(t\right) = \left\{
      \begin{array}{cc}
        \left(-\frac{t}{c}\right)^{\frac{1}{c}}
        e^{-\frac{t}{c}}
        \left[
        \Gamma\left(1-\frac{1}{c}\right)
        + \left(\gamma\left(-\frac{1}{c},-\frac{t}{c}\right) / \Gamma\left(\frac{1}{-c}\right)\right)
          - \pi\csc\left(\frac{\pi}{c}\right)/\Gamma\left(\frac{1}{c}\right)
          \right] & c>0\\
        \left(
        \frac{\left|c\right|}{t}\right)^{1/\left|c\right|}
        \Gamma\left(\frac{1}{\left|c\right|}, \frac{t}{\left|c\right|}\right)
        \frac{1}{\Gamma\left(\frac{1}{|c|}\right)}
         & c<0
      \end{array}
      \right.

.. math::

     \mu_{n}^{\prime}=\frac{\left(-1\right)^{n}}{c^{n}}\sum_{k=0}^{n}\binom{n}{k}\frac{\left(-1\right)^{k}}{1-ck}\quad \text{ if }cn<1

.. math::
   :nowrap:

    \begin{eqnarray*} \mu_{1}^{\prime} & = & \frac{1}{1-c}\quad c<1\\
    \mu_{2}^{\prime} & = & \frac{2}{\left(1-2c\right)\left(1-c\right)}\quad c<\frac{1}{2}\\
    \mu_{3}^{\prime} & = & \frac{6}{\left(1-c\right)\left(1-2c\right)\left(1-3c\right)}\quad c<\frac{1}{3}\\
    \mu_{4}^{\prime} & = & \frac{24}{\left(1-c\right)\left(1-2c\right)\left(1-3c\right)\left(1-4c\right)}\quad c<\frac{1}{4}\end{eqnarray*}

Thus,

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \mu_{1}^{\prime}\\
    \mu_{2} & = & \mu_{2}^{\prime}-\mu^{2}\\
    \gamma_{1} & = & \frac{\mu_{3}^{\prime}-3\mu\mu_{2}-\mu^{3}}{\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{\mu_{4}^{\prime}-4\mu\mu_{3}-6\mu^{2}\mu_{2}-\mu^{4}}{\mu_{2}^{2}}-3\end{eqnarray*}

.. math::

     h\left[X\right]=1+c\quad c>0

Implementation: `scipy.stats.genpareto`

.. _continuous-powernorm:

Power Normal Distribution
=========================

A generalization of the normal distribution, with one shape parameter :math:`c>0` and support :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & c\phi\left(x\right)\left(\Phi\left(-x\right)\right)^{c-1}\\
    F\left(x;c\right) & = & 1-\left(\Phi\left(-x\right)\right)^{c}\\
    G\left(q;c\right) & = & -\Phi^{-1}\left(\left(1-q\right)^{1/c}\right)\end{eqnarray*}

.. math::

     \mu_{n}^{\prime}=\left(-1\right)^{n}\int_{0}^{1}\left[\Phi^{-1}\left(y^{1/c}\right)\right]^{n}dy

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \mu_{1}^{\prime}\\ \mu_{2} & = & \mu_{2}^{\prime}-\mu^{2}\\ \gamma_{1} & = & \frac{\mu_{3}^{\prime}-3\mu\mu_{2}-\mu^{3}}{\mu_{2}^{3/2}}\\ \gamma_{2} & = & \frac{\mu_{4}^{\prime}-4\mu\mu_{3}-6\mu^{2}\mu_{2}-\mu^{4}}{\mu_{2}^{2}}-3\end{eqnarray*}

For :math:`c=1` this reduces to the normal distribution.

Implementation: `scipy.stats.powernorm`

.. _continuous-norminvgauss:

Normal Inverse Gaussian Distribution
==============================================

The probability density function is given by:

.. math::
	:nowrap:

	\begin{eqnarray*}
	        f(x; a, b) = \frac{a \exp\left(\sqrt{a^2 - b^2} + b x \right)}{\pi \sqrt{1 + x^2}} \, K_1\left(a * \sqrt{1 + x^2}\right),
	\end{eqnarray*}

where :math:`x` is a real number, the parameter :math:`a` is the tail heaviness and :math:`b` is the asymmetry parameter satisfying :math:`a > 0` and :math:`|b| \leq a`. :math:`K_1` is the modified Bessel function of second kind (`scipy.special.k1`).

A normal inverse Gaussian random variable with parameters :math:`a` and :math:`b` can be expressed  as :math:`X = b V + \sqrt(V) X` where :math:`X` is `norm(0,1)` and :math:`V` is `invgauss(mu=1/sqrt(a**2 - b**2))`. Hence, the normal inverse Gaussian distribution is a special case of normal variance-mean mixtures.

Another common parametrization of the distribution is given by the following expression of the pdf:

.. math::
	:nowrap:

	\begin{eqnarray*}
        g(x, \alpha, \beta, \delta, \mu) = \frac{\alpha\delta K_1 \left(\alpha\sqrt{\delta^2 + (x - \mu)^2}\right)}{\pi \sqrt{\delta^2 + (x - \mu)^2}} \,
        e^{\delta \sqrt{\alpha^2 - \beta^2} + \beta (x - \mu)}
	\end{eqnarray*}

In SciPy, this corresponds to :math:`a = \alpha \delta, b = \beta  \delta, \text{loc} = \mu, \text{scale}=\delta`.


Implementation: `scipy.stats.norminvgauss`

.. _continuous-pareto:

Pareto Distribution
===================

One shape parameter :math:`b>0` and support :math:`x\geq1`. The standard form is

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;b\right) & = & \frac{b}{x^{b+1}}\\ F\left(x;b\right) & = & 1-\frac{1}{x^{b}}\\ G\left(q;b\right) & = & \left(1-q\right)^{-1/b}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{b}{b-1}\quad b>1\\ \mu_{2} & = & \frac{b}{\left(b-2\right)\left(b-1\right)^{2}}\quad b>2\\ \gamma_{1} & = & \frac{2\left(b+1\right)\sqrt{b-2}}{\left(b-3\right)\sqrt{b}}\quad b>3\\ \gamma_{2} & = & \frac{6\left(b^{3}+b^{2}-6b-2\right)}{b\left(b^{2}-7b+12\right)}\quad b>4\end{eqnarray*}

.. math::

     h\left(X\right)=\frac{1}{c}+1-\log\left(c\right)

Implementation: `scipy.stats.pareto`

.. _discrete-zipfian:

Zipfian Distribution
========================

A random variable has the Zipfian distribution with parameters
:math:`s \ge 0` and :math:`N \in \{1, 2, 3, \dots\}` if its probability
mass function is given by

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k; s, N \right) & = & \frac{1}{H_{N, s}k^{s}}\quad k \in \{1, 2, \dots, n-1, n\} \end{eqnarray*}

where

.. math::

    H_{N, s}=\sum_{n=1}^{N}\frac{1}{n^{s}}

is the :math:`N`:sup:`th` generalized harmonic number of order
:math:`s`. Other functions of this distribution are

.. math::
   :nowrap:

    \begin{eqnarray*}
     F\left(x; s, N\right) & = & \frac{H_{k, s}}{H_{N, s}}, \\
    \mu & = & \frac{H_{N, s-1}}{H_{N, s}},\\
    \mu_{2} & = & \frac{H_{N, s-2}}{H_{N, s}} - \frac{H^2_{N, s-1}}{H^2_{N, s}},\\
    \gamma_1 & = & \frac{\frac{H_{N, s-3}}{H_{N, s}} - 3 \frac{H_{N, s-1}H_{N, s-2}}{H_{N, s}^2} + 2\frac{H_{N, s-1}^3}{H_{N, s}^3}}{\left(\frac{H_{N, s-2}H_{N, s}- H_{N, s-1}^2}{H_{N, s}^2}\right)^{\frac{3}{2}}}, \mbox{and}\\
    \gamma_2 & = & \frac{H_{N, s}^3 H_{N, s-4} - 4 H_{N, s}^2 H_{N, s-1} H_{N, s-3} + 6 H_{N, s} H_{N, s-1}^2 H_{N, s-2} - 3 H_{N, s-1}^4}{\left(H_{N, s-2} H_{N, s} - H_{N, s-1}^2 \right)^2}.
    \end{eqnarray*}

References
----------
-  "Zipf's Law", Wikipedia, https://en.wikipedia.org/wiki/Zipf%27s_law
-  Larry Leemis, "Zipf Distribution", Univariate Distribution Relationships. http://www.math.wm.edu/~leemis/chart/UDR/PDFs/Zipf.pdf

Implementation: `scipy.stats.zipfian`
.. _continuous-studentized_range:

Studentized Range Distribution
==============================
This distribution has two shape parameters, :math:`k>1` and :math:`\nu>0`, and the support is :math:`x \geq 0`.

.. math::
   :nowrap:

    \begin{eqnarray*}
    f(x; k, \nu) = \frac{k(k-1)\nu^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}
    \int_{0}^{\infty} \int_{-\infty}^{\infty} s^{\nu} e^{-\nu s^2/2} \phi(z) \phi(sx + z)
    [\Phi(sx + z) - \Phi(z)]^{k-2} \,dz \,ds
    \end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*}
    F(q; k, \nu) = \frac{k\nu^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}
    \int_{0}^{\infty} \int_{-\infty}^{\infty} s^{\nu-1} e^{-\nu s^2/2} \phi(z)
    [\Phi(sq + z) - \Phi(z)]^{k-1} \,dz \,ds
    \end{eqnarray*}

Note: :math:`\phi(z)` and :math:`\Phi(z)` represent the normal PDF and normal CDF, respectively.

When :math:`\nu` exceeds 100,000, the asymptopic approximation of :math:`F(x; k, \nu=\infty)` is used:

.. math::
   :nowrap:

    \begin{eqnarray*}
    F(x; k, \nu=\infty) = k \int_{-\infty}^{\infty} \phi(z)
    [\Phi(x + z) - \Phi(z)]^{k-1} \,dz
    \end{eqnarray*}


Implementation: `scipy.stats.studentized_range`

.. _discrete-logser:

Logarithmic (Log-Series, Series) Distribution
=============================================

The logarithmic distribution with parameter :math:`p` has a probability mass function with terms proportional to the Taylor
series expansion of :math:`\log\left(1-p\right)`

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;p\right) & = & -\frac{p^{k}}{k\log\left(1-p\right)}\quad k\geq1\\ F\left(x;p\right) & = & -\frac{1}{\log\left(1-p\right)}\sum_{k=1}^{\left\lfloor x\right\rfloor }\frac{p^{k}}{k}=1+\frac{p^{1+\left\lfloor x\right\rfloor }\Phi\left(p,1,1+\left\lfloor x\right\rfloor \right)}{\log\left(1-p\right)}\end{eqnarray*}

where

.. math::

    \Phi\left(z,s,a\right)=\sum_{k=0}^{\infty}\frac{z^{k}}{\left(a+k\right)^{s}}

is the Lerch Transcendent. Also define :math:`r=\log\left(1-p\right)`

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & -\frac{p}{\left(1-p\right)r}\\ \mu_{2} & = & -\frac{p\left[p+r\right]}{\left(1-p\right)^{2}r^{2}}\\ \gamma_{1} & = & -\frac{2p^{2}+3pr+\left(1+p\right)r^{2}}{r\left(p+r\right)\sqrt{-p\left(p+r\right)}}r\\ \gamma_{2} & = & -\frac{6p^{3}+12p^{2}r+p\left(4p+7\right)r^{2}+\left(p^{2}+4p+1\right)r^{3}}{p\left(p+r\right)^{2}}.\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} M\left(t\right) & = & -\frac{1}{\log\left(1-p\right)}\sum_{k=1}^{\infty}\frac{e^{tk}p^{k}}{k}\\  & = & \frac{\log\left(1-pe^{t}\right)}{\log\left(1-p\right)}\end{eqnarray*}

Thus,

.. math::

    \mu_{n}^{\prime}=\left.M^{\left(n\right)}\left(t\right)\right|_{t=0}=\left.\frac{\textrm{Li}_{1-n}\left(pe^{t}\right)}{\log\left(1-p\right)}\right|_{t=0}=-\frac{\textrm{Li}_{1-n}\left(p\right)}{\log\left(1-p\right)}.

Implementation: `scipy.stats.logser`

.. _continuous-fisk:

Fisk (Log Logistic) Distribution
================================

Special case of the Burr distribution with :math:`d=1`.
There is are one shape parameter :math:`c > 0` and the support is :math:`x \in [0,\infty)`.

.. math::
   :nowrap:

    \begin{eqnarray*}\textrm{Let }k & = & \Gamma\left(1-\frac{2}{c}\right)\Gamma\left(\frac{2}{c}+1\right)-\Gamma^{2}\left(1-\frac{1}{c}\right)\Gamma^{2}\left(\frac{1}{c}+1\right)\\
    f\left(x;c,d\right) & = & \frac{cx^{c-1}}{\left(1+x^{c}\right)^{2}} \\
    F\left(x;c,d\right) & = & \left(1+x^{-c}\right)^{-1}\\
    G\left(q;c,d\right) & = & \left(q^{-1}-1\right)^{-1/c}\\
    \mu & = & \Gamma\left(1-\frac{1}{c}\right)\Gamma\left(\frac{1}{c}+1\right)\\
    \mu_{2} & = & k\\
    \gamma_{1} & = & \frac{1}{\sqrt{k^{3}}}\left[2\Gamma^{3}\left(1-\frac{1}{c}\right)\Gamma^{3}\left(\frac{1}{c}+1\right)+\Gamma\left(1-\frac{3}{c}\right)\Gamma\left(\frac{3}{c}+1\right)\right.\\  &  & \left.-3\Gamma\left(1-\frac{2}{c}\right)\Gamma\left(1-\frac{1}{c}\right)\Gamma\left(\frac{1}{c}+1\right)\Gamma\left(\frac{2}{c}+1\right)\right]\\
    \gamma_{2} & = & -3+\frac{1}{k^{2}}\left[6\Gamma\left(1-\frac{2}{c}\right)\Gamma^{2}\left(1-\frac{1}{c}\right)\Gamma^{2}\left(\frac{1}{c}+1\right)\Gamma\left(\frac{2}{c}+1\right)\right.\\  &  & -3\Gamma^{4}\left(1-\frac{1}{c}\right)\Gamma^{4}\left(\frac{1}{c}+1\right)+\Gamma\left(1-\frac{4}{c}\right)\Gamma\left(\frac{4}{c}+1\right)\\  &  & \left.-4\Gamma\left(1-\frac{3}{c}\right)\Gamma\left(1-\frac{1}{c}\right)\Gamma\left(\frac{1}{c}+1\right)\Gamma\left(\frac{3}{c}+1\right)\right]\\
    m_{d} & = & \left(\frac{c-1}{c+1}\right)^{1/c}\, \text{if }c>1, \text{otherwise } 0\\
    m_{n} & = & 1\\
    h\left[X\right] & = & 2-\log c\end{eqnarray*}


Implementation: `scipy.stats.fisk`

.. _sampling-tdr:

Transformed Density Rejection (TDR)
===================================

.. currentmodule:: scipy.stats.sampling

* Required: T-concave PDF, dPDF
* Optional: mode, center
* Speed:

  * Set-up: slow
  * Sampling: fast 


TDR is an acceptance/rejection method that uses the concavity of a transformed
density to construct hat function and squeezes automatically. Such PDFs are
called T-concave. Currently the following transformations are implemented:

.. math::

    c = 0.: T(x) &= \log(x)\\
    c = -0.5: T(x) &= \frac{1}{\sqrt{x}} \text{ (Default)}

In addition to the PDF, it also requires the derivative of the PDF w.r.t ``x``
(i.e. the variate). These functions must be present as methods of a python
object which can then be passed to the generators to instantiate their object.
The variant that is implemented uses squeezes proportional to hat function ([1]_).

An example of using this method is shown below:

    >>> from scipy.stats.sampling import TransformedDensityRejection
    >>> from scipy.stats import norm
    >>> 
    >>> class StandardNormal:
    ...     def pdf(self, x):
    ...         # note that the normalization constant is not required
    ...         return np.exp(-0.5 * x*x)
    ...     def dpdf(self, x):
    ...         return -x * np.exp(-0.5 * x*x)
    ... 
    >>> dist = StandardNormal()
    >>> 
    >>> urng = np.random.default_rng()
    >>> rng = TransformedDensityRejection(dist, random_state=urng)
    >>> rng.rvs()
    -1.526829048388144

In the above example, we have used the TDR method to sample from the standard
normal distribution. Note that we can drop the normalization constant while
computing the PDF. This usually helps speed up the sampling stage. Also, note
that the PDF doesn't need to be vectorized. It should accept and return a
scalar.

It is also possible to evaluate the inverse of the CDF of the hat distribution
directly using the ``ppf_hat`` method.

    >>> rng.ppf_hat(0.5)
    -0.00018050266342362759
    >>> norm.ppf(0.5)
    0.0
    >>> u = np.linspace(0, 1, num=10)
    >>> rng.ppf_hat(u)
    array([       -inf, -1.22227372, -0.7656556 , -0.43135731, -0.14002921,
            0.13966423,  0.43096141,  0.76517113,  1.22185606,         inf])
    >>> norm.ppf(u)
    array([       -inf, -1.22064035, -0.76470967, -0.4307273 , -0.1397103 ,
            0.1397103 ,  0.4307273 ,  0.76470967,  1.22064035,         inf])

Apart from the PPF method, other attributes can be accessed
to see how well the generator fits the given distribution. These are:

* 'squeeze_hat_ratio': (area below squeeze) / (area below hat) for the generator. It
  is a number between 0 and 1. Closer to 1 means that the hat and the squeeze
  functions tightly envelop the distribution and fewer PDF evaluations are
  required to generate samples. The expected number of evaluations of the
  density is bounded by ``(1/squeeze_hat_ratio) - 1`` per sample. By default, it is
  kept above 0.99 but that can be changed by passing a ``max_squeeze_hat_ratio``
  parameter.
* 'hat_area': area below the hat for the generator.
* 'squeeze_area': area below the squeeze for the generator.

    >>> rng.squeeze_hat_ratio
    0.9947024204884917
    >>> rng.hat_area
    2.510253139791547
    >>> rng.squeeze_area
    2.4969548741894876
    >>> rng.squeeze_hat_ratio == rng.squeeze_area / rng.hat_area
    True

The distribution can be truncated by passing a domain parameter:

    >>> urng = np.random.default_rng()
    >>> rng = TransformedDensityRejection(dist, domain=[0, 1], random_state=urng)
    >>> rng.rvs(10)
    array([0.05452512, 0.97251362, 0.49955877, 0.82789729, 0.33048885,
           0.55558548, 0.23168323, 0.13423275, 0.73176575, 0.35739799])

If the domain is not specified, the ``support`` method of the ``dist`` object
is used to determine the domain:

    >>> class StandardNormal:
    ...     def pdf(self, x):
    ...         return np.exp(-0.5 * x*x)
    ...     def dpdf(self, x):
    ...         return -x * np.exp(-0.5 * x*x)
    ...     def support(self):
    ...         return -np.inf, np.inf
    ... 
    >>> dist = StandardNormal()
    >>> 
    >>> urng = np.random.default_rng()
    >>> rng = TransformedDensityRejection(dist, random_state=urng)
    >>> rng.rvs(10)
    array([-1.52682905,  2.06206883,  0.15205036,  1.11587367, -0.30775562,
           0.29879802, -0.61858268, -1.01049115,  0.78853694, -0.23060766])

If the ``dist`` object does not provide a ``support`` method, the domain
is assumed to be ``(-np.inf, np.inf)``.

To increase ``squeeze_hat_ratio``, pass ``max_squeeze_hat_ratio``:

    >>> dist = StandardNormal()
    >>> rng = TransformedDensityRejection(dist, max_squeeze_hat_ratio=0.999,
    ...                                   random_state=urng)
    >>> rng.squeeze_hat_ratio
    0.999364900465214

Let's see how this affects the callbacks to the PDF method of the
distribution:

    >>> from copy import copy
    >>> class StandardNormal:
    ...     def __init__(self):
    ...         self.callbacks = 0
    ...     def pdf(self, x):
    ...         self.callbacks += 1
    ...         return np.exp(-0.5 * x*x)
    ...     def dpdf(self, x):
    ...         return -x * np.exp(-0.5 * x*x)
    ... 
    >>> dist1 = StandardNormal()
    >>> urng1 = np.random.default_rng()
    >>> urng2 = copy(urng1)
    >>> rng1 = TransformedDensityRejection(dist1, random_state=urng1)
    >>> dist1.callbacks  # evaluations during setup
    139
    >>> dist1.callbacks = 0  # don't consider evaluations during setup
    >>> rvs = rng1.rvs(100000)
    >>> dist1.callbacks  # evaluations during sampling
    527
    >>> dist2 = StandardNormal()
    >>> # use the same stream of uniform random numbers
    >>> rng2 = TransformedDensityRejection(dist2, max_squeeze_hat_ratio=0.999,
    ...                                    random_state=urng2)
    >>> dist2.callbacks  # evaluations during setup
    467
    >>> dist2.callbacks = 0  # don't consider evaluations during setup
    >>> rvs = rng2.rvs(100000)
    >>> dist2.callbacks  # evaluations during sampling
    84

As we can see, far fewer PDF evaluations are required during sampling when
we increase the ``squeeze_hat_ratio``. The PPF-hat function is also more accurate:

    >>> abs(norm.ppf(0.975) - rng1.ppf_hat(0.975))
    0.0027054565421578136
    >>> abs(norm.ppf(0.975) - rng2.ppf_hat(0.975))
    0.00047824084476300044

Though, notice that this comes at the cost of increased PDF evaluations
during setup.

For densities with modes not close to 0, it is suggested to set either the
mode or the center of the distribution by passing ``mode`` or ``center``
parameters. The latter is the approximate location of the mode or the mean
of the distribution. This location provides some information about the main
part of the PDF and is used to avoid numerical problems.

    >>> # mode = 0 for our distribution
    >>> # if exact mode is not available, pass 'center' parameter instead
    >>> rng = TransformedDensityRejection(dist, mode=0.)

By default, the method uses 30 construction points to construct the hat.
This can be changed by passing a ``construction_points`` parameter which
can either be an array of construction points or an integer representing
the number of construction points to use.

    >>> rng = TransformedDensityRejection(dist,
    ...                                   construction_points=[-5, 0, 5])

This method accepts many other set-up parameters. See the documentation for
an exclusive list. More information of the parameters and the method can be
found in `Section 5.3.16 of the UNU.RAN user manual
<http://statmath.wu.ac.at/software/unuran/doc/unuran.html#TDR>`__.


Please see [1]_ and [2]_ for more details on this method.


References
----------

.. [1] UNU.RAN reference manual, Section 5.3.16,
       "TDR - Transformed Density Rejection",
       http://statmath.wu.ac.at/software/unuran/doc/unuran.html#TDR
.. [2] Hörmann, Wolfgang. "A rejection technique for sampling from
       T-concave distributions." ACM Transactions on Mathematical
       Software (TOMS) 21.2 (1995): 182-193


.. _continuous-ncf:

Noncentral F Distribution
=========================

The distribution of :math:`\left(X_{1}/X_{2}\right)\left(\nu_{2}/\nu_{1}\right)`
if :math:`X_{1}` is non-central chi-squared with :math:`\nu_{1}` degrees of
freedom and parameter :math:`\lambda`, and :math:`X_{2}` is chi-squared with
:math:`\nu_{2}` degrees of freedom.

There are 3 shape parameters: the degrees of freedom :math:`\nu_{1}>0` and
:math:`\nu_{2}>0`; and :math:`\lambda\geq 0`.


.. math::
   :nowrap:

    \begin{eqnarray*}
        f\left(x;\lambda,\nu_{1},\nu_{2}\right)
        & = &
        \exp\left[\frac{\lambda}{2} +
                  \frac{\left(\lambda\nu_{1}x\right)}
                  {2\left(\nu_{1}x+\nu_{2}\right)}
            \right]
        \nu_{1}^{\nu_{1}/2}\nu_{2}^{\nu_{2}/2}x^{\nu_{1}/2-1} \\
        &  &
        \times\left(\nu_{2}+\nu_{1}x\right)^{-\left(\nu_{1}+\nu_{2}\right)/2}
        \frac{\Gamma\left(\frac{\nu_{1}}{2}\right)
              \Gamma\left(1+\frac{\nu_{2}}{2}\right)
              L_{\nu_{2}/2}^{\nu_{1}/2-1}
                \left(-\frac{\lambda\nu_{1}x}
                            {2\left(\nu_{1}x+\nu_{2}\right)}\right)}
             {B\left(\frac{\nu_{1}}{2},\frac{\nu_{2}}{2}\right)
              \Gamma\left(\frac{\nu_{1}+\nu_{2}}{2}\right)}
    \end{eqnarray*}

where :math:`L_{\nu_{2}/2}^{\nu_{1}/2-1}(x)` is an associated Laguerre
polynomial.

If :math:`\lambda=0`, the distribution becomes equivalent to the Fisher
distribution with :math:`\nu_{1}` and :math:`\nu_{2}` degrees of freedom.

Implementation: `scipy.stats.ncf`

.. _continuous-kstwo:

KStwo Distribution
==================

This is the distribution of the maximum absolute differences between an
empirical distribution function, computed from :math:`n` samples or observations,
and a comparison (or target) cumulative distribution function, which is
assumed to be continuous.
(The "two" in the name is because this is the two-sided difference.
``ksone`` is the distribution of the positive differences, :math:`D_n^+`,
hence it concerns one-sided differences.
``kstwobign`` is the limiting
distribution of the *normalized* maximum absolute differences :math:`\sqrt{n} D_n`.)


Writing :math:`D_n = \sup_t \left|F_{empirical,n}(t)-F_{target}(t)\right|`,
``kstwo`` is the distribution of the :math:`D_n` values.


``kstwo`` can also be used with the differences between two empirical distribution functions,
for sets of observations with :math:`m` and :math:`n` samples respectively.
Writing :math:`D_{m,n} = \sup_t \left|F_{1,m}(t)-F_{2,n}(t)\right|`,  where
:math:`F_{1,m}` and :math:`F_{2,n}` are the two empirical distribution functions, then
:math:`Pr(D_{m,n} \le x) \approx Pr(D_N \le x)` under appropriate conditions,
where :math:`N = \sqrt{\left(\frac{mn}{m+n}\right)}`.


There is one shape parameter :math:`n`, a positive integer, and the support is :math:`x\in\left[0,1\right]`.

The implementation follows Simard & L'Ecuyer, which combines exact algorithms of Durbin and Pomeranz
with asymptotic estimates of Li-Chien, Pelz and Good to compute the CDF with 5-15 accurate digits.

Examples
--------

>>> from scipy.stats import kstwo

Show the probability of a gap at least as big as 0, 0.5 and 1.0 for a sample of size 5

>>> kstwo.sf([0, 0.5, 1.0], 5)
array([1.   , 0.112, 0.   ])

Compare a sample of size 5 drawn from a source N(0.5, 1) distribution against
a target N(0, 1) CDF.

>>> from scipy.stats import norm
>>> n = 5
>>> gendist = norm(0.5, 1)       # Normal distribution, mean 0.5, stddev 1
>>> x = np.sort(gendist.rvs(size=n, random_state=np.random.default_rng()))
>>> x
array([-1.59113056, -0.66335147,  0.54791569,  0.78009321,  1.27641365])
>>> target = norm(0, 1)
>>> cdfs = target.cdf(x)
>>> cdfs
array([0.0557901 , 0.25355274, 0.7081251 , 0.78233199, 0.89909533])
# Construct the Empirical CDF and the K-S statistics (Dn+, Dn-, Dn)
>>> ecdfs = np.arange(n+1, dtype=float)/n
>>> cols = np.column_stack([x, ecdfs[1:], cdfs, cdfs - ecdfs[:n], ecdfs[1:] - cdfs])
>>> np.set_printoptions(precision=3)
>>> cols
array([[-1.591,  0.2  ,  0.056,  0.056,  0.144],
       [-0.663,  0.4  ,  0.254,  0.054,  0.146],
       [ 0.548,  0.6  ,  0.708,  0.308, -0.108],
       [ 0.78 ,  0.8  ,  0.782,  0.182,  0.018],
       [ 1.276,  1.   ,  0.899,  0.099,  0.101]])
>>> gaps = cols[:, -2:]
>>> Dnpm = np.max(gaps, axis=0)
>>> Dn = np.max(Dnpm)
>>> iminus, iplus = np.argmax(gaps, axis=0)
>>> print('Dn- = %f (at x=%.2f)' % (Dnpm[0], x[iminus]))
Dn- = 0.308125 (at x=0.55)
>>> print('Dn+ = %f (at x=%.2f)' % (Dnpm[1], x[iplus]))
Dn+ = 0.146447 (at x=-0.66)
>>> print('Dn  = %f' % (Dn))
Dn  = 0.308125

>>> probs = kstwo.sf(Dn, n)
>>> print(chr(10).join(['For a sample of size %d drawn from a N(0, 1) distribution:' % n,
...      ' Kolmogorov-Smirnov 2-sided n=%d: Prob(Dn >= %f) = %.4f' % (n, Dn, probs)]))
For a sample of size 5 drawn from a N(0, 1) distribution:
 Kolmogorov-Smirnov 2-sided n=5: Prob(Dn >= 0.308125) = 0.6319

Plot the Empirical CDF against the target N(0, 1) CDF

>>> import matplotlib.pyplot as plt
>>> plt.step(np.concatenate([[-3], x]), ecdfs, where='post', label='Empirical CDF')
>>> x3 = np.linspace(-3, 3, 100)
>>> plt.plot(x3, target.cdf(x3), label='CDF for N(0, 1)')
>>> plt.ylim([0, 1]); plt.grid(True); plt.legend();
>>> plt.vlines([x[iminus]], ecdfs[iminus], cdfs[iminus], color='r', linestyle='solid', lw=4)
>>> plt.vlines([x[iplus]], cdfs[iplus], ecdfs[iplus+1], color='m', linestyle='solid', lw=4)
>>> plt.annotate('Dn-', xy=(x[iminus], (ecdfs[iminus]+ cdfs[iminus])/2),
...              xytext=(x[iminus]+1, (ecdfs[iminus]+ cdfs[iminus])/2 - 0.02),
...              arrowprops=dict(facecolor='white', edgecolor='r', shrink=0.05), size=15, color='r');
>>> plt.annotate('Dn+', xy=(x[iplus], (ecdfs[iplus+1]+ cdfs[iplus])/2),
...             xytext=(x[iplus]-2, (ecdfs[iplus+1]+ cdfs[iplus])/2 - 0.02),
...             arrowprops=dict(facecolor='white', edgecolor='m', shrink=0.05), size=15, color='m');
>>> plt.show()


References
----------

-  "Kolmogorov-Smirnov test", Wikipedia
   https://en.wikipedia.org/wiki/Kolmogorov-Smirnov_test

-  Durbin J. "The Probability that the Sample Distribution Function Lies Between Two
   Parallel Straight Lines." *Ann. Math. Statist*., 39 (1968) 39, 398-411.

-  Pomeranz J.  "Exact Cumulative Distribution of the Kolmogorov-Smirnov Statistic for
   Small Samples (Algorithm 487)."  *Communications of the ACM*, 17(12), (1974) 703-704.

-  Li-Chien, C.  "On the exact distribution of the statistics of A. N. Kolmogorov and
   their asymptotic expansion."  *Acta Matematica Sinica*, 6, (1956) 55-81.

-  Pelz W, Good IJ. "Approximating the Lower Tail-areas of the Kolmogorov-Smirnov One-sample
   Statistic." *Journal of the Royal Statistical Society*, Series B, (1976) 38(2), 152-156.

-  Simard, R., L'Ecuyer, P. "Computing the Two-Sided Kolmogorov-Smirnov Distribution",
   *Journal of Statistical Software*, Vol 39, (2011) 11.

Implementation: `scipy.stats.kstwo`

.. _continuous-truncnorm:

Truncated Normal Distribution
=============================

A normal distribution restricted to lie within a certain range given
by two parameters :math:`A` and :math:`B` . Notice that this :math:`A` and :math:`B` correspond to the bounds on :math:`x` in standard form. For :math:`x\in\left[A,B\right]` we get

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;A,B\right) & = & \frac{\phi\left(x\right)}{\Phi\left(B\right)-\Phi\left(A\right)}\\
    F\left(x;A,B\right) & = & \frac{\Phi\left(x\right)-\Phi\left(A\right)}{\Phi\left(B\right)-\Phi\left(A\right)}\\
    G\left(q;A,B\right) & = & \Phi^{-1}\left(q\Phi\left(B\right)+\Phi\left(A\right)\left(1-q\right)\right)\end{eqnarray*}

where

.. math::
   :nowrap:

    \begin{eqnarray*} \phi\left(x\right) & = & \frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}\\
    \Phi\left(x\right) & = & \int_{-\infty}^{x}\phi\left(u\right)du.\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{\phi\left(A\right)-\phi\left(B\right)}{\Phi\left(B\right)-\Phi\left(A\right)}\\
    \mu_{2} & = & 1+\frac{A\phi\left(A\right)-B\phi\left(B\right)}{\Phi\left(B\right)-\Phi\left(A\right)}-\left(\frac{\phi\left(A\right)-\phi\left(B\right)}{\Phi\left(B\right)-\Phi\left(A\right)}\right)^{2}\end{eqnarray*}

Implementation: `scipy.stats.truncnorm`

.. _continuous-fatiguelife:

Fatigue Life (Birnbaum-Saunders) Distribution
=============================================

This distribution's pdf is the average of the inverse-Gaussian :math:`\left(\mu=1\right)` and reciprocal inverse-Gaussian pdf :math:`\left(\mu=1\right)` .
We follow the notation of JKB here with :math:`\beta=S.` There is one shape parameter :math:`c>0`, and the support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{x+1}{2c\sqrt{2\pi x^{3}}}\exp\left(-\frac{\left(x-1\right)^{2}}{2xc^{2}}\right)\\
    F\left(x;c\right) & = & \Phi\left(\frac{1}{c}\left(\sqrt{x}-\frac{1}{\sqrt{x}}\right)\right)\\
    G\left(q;c\right) & = & \frac{1}{4}\left[c\Phi^{-1}\left(q\right)+\sqrt{c^{2}\left(\Phi^{-1}\left(q\right)\right)^{2}+4}\right]^{2}\end{eqnarray*}

.. math::

     M\left(t\right)=c\sqrt{2\pi}\exp\left(\frac{1}{c^{2}}\left(1-\sqrt{1-2c^{2}t}\right)\right) \left(1+\frac{1}{\sqrt{1-2c^{2}t}}\right)

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{c^{2}}{2}+1\\
    \mu_{2} & = & c^{2}\left(\frac{5}{4}c^{2}+1\right)\\
    \gamma_{1} & = & \frac{4c\sqrt{11c^{2}+6}}{\left(5c^{2}+4\right)^{3/2}}\\
    \gamma_{2} & = & \frac{6c^{2}\left(93c^{2}+41\right)}{\left(5c^{2}+4\right)^{2}}\end{eqnarray*}

Implementation: `scipy.stats.fatiguelife`

.. _continuous-johnsonsu:

Johnson SU Distribution
=======================

There are two shape parameters :math:`a\in\mathbb{R}` and :math:`b>0`, and the support is :math:`x\in\mathbb{R}`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a,b\right) & = & \frac{b}{\sqrt{x^{2}+1}}\phi\left(a+b\log\left(x+\sqrt{x^{2}+1}\right)\right)\\
    F\left(x;a,b\right) & = & \Phi\left(a+b\log\left(x+\sqrt{x^{2}+1}\right)\right)\\
    G\left(q;a,b\right) & = & \sinh\left(\frac{\Phi^{-1}\left(q\right)-a}{b}\right)\end{eqnarray*}

Implementation: `scipy.stats.johnsonsu`

.. _continuous-levy:

Lévy Distribution
==================

A special case of Lévy-stable distributions with :math:`\alpha=\frac{1}{2}`
and :math:`\beta=1` and support :math:`x\geq0`.  In standard form it is defined for :math:`x>0` as

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{1}{x\sqrt{2\pi x}}\exp\left(-\frac{1}{2x}\right)\\ F\left(x\right) & = & 2\left[1-\Phi\left(\frac{1}{\sqrt{x}}\right)\right]\\ G\left(q\right) & = & \left[\Phi^{-1}\left(1-\frac{q}{2}\right)\right]^{-2}.\end{eqnarray*}

It has no finite moments.

Implementation: `scipy.stats.levy`

.. _continuous-powerlaw:

Power-function Distribution
===========================

A special case of the beta distribution with :math:`b=1`. There is one
shape parameter :math:`a>0` and support :math:`x\in\left[0,1\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a\right) & = & ax^{a-1}\\ F\left(x;a\right) & = & x^{a}\\ G\left(q;a\right) & = & q^{1/a}\\ \mu & = & \frac{a}{a+1}\\ \mu_{2} & = & \frac{a\left(a+2\right)}{\left(a+1\right)^{2}}\\ \gamma_{1} & = & 2\left(1-a\right)\sqrt{\frac{a+2}{a\left(a+3\right)}}\\ \gamma_{2} & = & \frac{6\left(a^{3}-a^{2}-6a+2\right)}{a\left(a+3\right)\left(a+4\right)}\\ m_{d} & = & 1\end{eqnarray*}

.. math::

     h\left[X\right]=1-\frac{1}{a}-\log\left(a\right)

Implementation: `scipy.stats.powerlaw`

.. _continuous-triang:

Triangular Distribution
=======================

One shape parameter :math:`c\in[0,1]` giving the distance to the peak as a percentage of the total extent of
the non-zero portion. The location parameter is the start of the non-
zero portion, and the scale-parameter is the width of the non-zero
portion. In standard form we have :math:`x\in\left[0,1\right].`

.. math::
   :nowrap:

    \begin{eqnarray*}
        f\left(x;c\right) & = & \left\{
                                    \begin{array}{ccc}
                                        2\frac{x}{c} &  & x < c \\
                                        2\frac{1-x}{1-c} &  & x \geq c
                                    \end{array}
                                \right.\\
        F\left(x;c\right) & = & \left\{
                                    \begin{array}{ccc}
                                        \frac{x^{2}}{c} &  & x < c \\
                                        \frac{x^{2}-2x+c}{c-1} &  & x \geq c
                                    \end{array}
                                \right.\\
        G\left(q;c\right) & = & \left\{
                                    \begin{array}{ccc}
                                        \sqrt{cq} &  & q < c \\
                                        1-\sqrt{\left(1-c\right)\left(1-q\right)} &  & q \geq c
                                    \end{array}
                                \right.
    \end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{c}{3}+\frac{1}{3}\\ \mu_{2} & = & \frac{1-c+c^{2}}{18}\\ \gamma_{1} & = & \frac{\sqrt{2}\left(2c-1\right)\left(c+1\right)\left(c-2\right)}{5\left(1-c+c^{2}\right)^{3/2}}\\ \gamma_{2} & = & -\frac{3}{5}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} h\left(X\right) & = & \log\left(\frac{1}{2}\sqrt{e}\right)\\  & \approx & -0.19314718055994530942.\end{eqnarray*}

Implementation: `scipy.stats.triang`

.. _discrete-betabinom:

Beta-Binomial Distribution
==========================

The beta-binomial distribution is a binomial distribution with a probability of success `p` that follows a beta distribution. The probability mass function for `betabinom`, defined for :math:`0 \leq k \leq n`, is:

.. math::

    f(k; n, a, b) = \binom{n}{k} \frac{B(k + a, n - k + b)}{B(a, b)}

for ``k`` in ``{0, 1,..., n}``, where :math:`B(a, b)` is the Beta function.

In the limiting case of :math:`a = b = 1`, the beta-binomial distribution reduces to a discrete uniform distribution:

.. math::

    f(k; n, 1, 1) = \frac{1}{n + 1}

In the limiting case of :math:`n = 1`, the beta-binomial distribution reduces to a Bernoulli distribution with the shape parameter :math:`p = a / (a + b)`:

.. math::

    f(k; 1, a, b) = \begin{cases}a / (a + b) & \text{if}\; k = 0 \\b / (a + b) & \text{if}\; k = 1\end{cases}

Implementation: `scipy.stats.betabinom`

.. _continuous-norm:

Normal Distribution
===================

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{e^{-x^{2}/2}}{\sqrt{2\pi}}\\
    F\left(x\right) & = & \Phi\left(x\right)=\frac{1}{2}+\frac{1}{2}\mathrm{erf}\left(\frac{x}{\sqrt{2}}\right)\\
    G\left(q\right) & = & \Phi^{-1}\left(q\right)\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} m_{d}=m_{n}=\mu & = & 0\\
    \mu_{2} & = & 1\\
    \gamma_{1} & = & 0\\
    \gamma_{2} & = & 0\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & \log\left(\sqrt{2\pi e}\right)\\
    & \approx & 1.4189385332046727418\end{eqnarray*}

Implementation: `scipy.stats.norm`

.. _continuous-halfnorm:

HalfNormal Distribution
=======================

This is a special case of the chi distribution with :math:`L=a` and :math:`S=b` and :math:`\nu=1.` This is also a special case of the folded normal with shape parameter :math:`c=0` and :math:`S=S.` If :math:`Z` is (standard) normally distributed then, :math:`\left|Z\right|` is half-normal. The standard form is

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \sqrt{\frac{2}{\pi}}e^{-x^{2}/2}\\
    F\left(x\right) & = & 2\Phi\left(x\right)-1\\
    G\left(q\right) & = & \Phi^{-1}\left(\frac{1+q}{2}\right)\end{eqnarray*}

.. math::

     M\left(t\right)=\sqrt{2\pi}e^{t^{2}/2}\Phi\left(t\right)

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \sqrt{\frac{2}{\pi}}\\
    \mu_{2} & = & 1-\frac{2}{\pi}\\
    \gamma_{1} & = & \frac{\sqrt{2}\left(4-\pi\right)}{\left(\pi-2\right)^{3/2}}\\
    \gamma_{2} & = & \frac{8\left(\pi-3\right)}{\left(\pi-2\right)^{2}}\\
    m_{d} & = & 0\\
    m_{n} & = & \Phi^{-1}\left(\frac{3}{4}\right)\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & \log\left(\sqrt{\frac{\pi e}{2}}\right)\\  & \approx & 0.72579135264472743239.\end{eqnarray*}

Implementation: `scipy.stats.halfnorm`

.. _discrete-boltzmann:

Boltzmann (truncated Planck) Distribution
=========================================

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;N,\lambda\right) & = & \frac{1-e^{-\lambda}}{1-e^{-\lambda N}}\exp\left(-\lambda k\right)\quad k\in\left\{ 0,1,\ldots,N-1\right\} \\ F\left(x;N,\lambda\right) & = & \left\{ \begin{array}{cc} 0 & x<0\\ \frac{1-\exp\left[-\lambda\left(\left\lfloor x\right\rfloor +1\right)\right]}{1-\exp\left(-\lambda N\right)} & 0\leq x\leq N-1\\ 1 & x\geq N-1\end{array}\right.\\ G\left(q,\lambda\right) & = & \left\lceil -\frac{1}{\lambda}\log\left[1-q\left(1-e^{-\lambda N}\right)\right]-1\right\rceil \end{eqnarray*}

Define :math:`z=e^{-\lambda}`

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{z}{1-z}-\frac{Nz^{N}}{1-z^{N}}\\ \mu_{2} & = & \frac{z}{\left(1-z\right)^{2}}-\frac{N^{2}z^{N}}{\left(1-z^{N}\right)^{2}}\\ \gamma_{1} & = & \frac{z\left(1+z\right)\left(\frac{1-z^{N}}{1-z}\right)^{3}-N^{3}z^{N}\left(1+z^{N}\right)}{\left[z\left(\frac{1-z^{N}}{1-z}\right)^{2}-N^{2}z^{N}\right]^{3/2}}\\ \gamma_{2} & = & \frac{z\left(1+4z+z^{2}\right)\left(\frac{1-z^{N}}{1-z}\right)^{4}-N^{4}z^{N}\left(1+4z^{N}+z^{2N}\right)}{\left[z\left(\frac{1-z^{N}}{1-z}\right)^{2}-N^{2}z^{N}\right]^{2}}\end{eqnarray*}

.. math::

    M\left(t\right)=\frac{1-e^{N\left(t-\lambda\right)}}{1-e^{t-\lambda}}\frac{1-e^{-\lambda}}{1-e^{-\lambda N}}

Implementation: `scipy.stats.boltzmann`

.. _continuous-betaprime:

Beta Prime Distribution
=======================

There are two shape parameters :math:`a,b > 0` and the support is :math:`x \in [0,\infty)`.
Note the CDF evaluation uses Eq. 3.194.1 on pg. 313 of Gradshteyn & Ryzhik (sixth edition).

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\alpha,\beta\right) & = & \frac{\Gamma\left(\alpha+\beta\right)}{\Gamma\left(\alpha\right)\Gamma\left(\beta\right)}x^{\alpha-1}\left(1+x\right)^{-\alpha-\beta}\\
    F\left(x;\alpha,\beta\right) & = & \frac{\Gamma\left(\alpha+\beta\right)}{\alpha\Gamma\left(\alpha\right)\Gamma\left(\beta\right)}x^{\alpha}\,_{2}F_{1}\left(\alpha+\beta,\alpha;1+\alpha;-x\right)\\
    G\left(q;\alpha,\beta\right) & = & F^{-1}\left(x;\alpha,\beta\right)\end{eqnarray*}

.. math::

    \mu_{n}^{\prime}=\left\{
      \begin{array}{ccc}
        \frac{\Gamma\left(n+\alpha\right)\Gamma\left(\beta-n\right)}{\Gamma\left(\alpha\right)\Gamma\left(\beta\right)}=\frac{\left(\alpha\right)_{n}}{\left(\beta-n\right)_{n}} &  & \beta>n\\
        \infty &  & \mathrm{otherwise}
      \end{array}\right.

Therefore,

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{\alpha}{\beta-1}\quad\textrm{for }\beta>1\\
    \mu_{2} & = & \frac{\alpha\left(\alpha+1\right)}{\left(\beta-2\right)\left(\beta-1\right)}-\frac{\alpha^{2}}{\left(\beta-1\right)^{2}}\quad\textrm{for }\beta>2\\
    \gamma_{1} & = & \frac{\frac{\alpha\left(\alpha+1\right)\left(\alpha+2\right)}{\left(\beta-3\right)\left(\beta-2\right)\left(\beta-1\right)}-3\mu\mu_{2}-\mu^{3}}{\mu_{2}^{3/2}}\quad\textrm{for }\beta>3\\
    \gamma_{2} & = & \frac{\mu_{4}}{\mu_{2}^{2}}-3\\
    \mu_{4} & = & \frac{\alpha\left(\alpha+1\right)\left(\alpha+2\right)\left(\alpha+3\right)}{\left(\beta-4\right)\left(\beta-3\right)\left(\beta-2\right)\left(\beta-1\right)}-4\mu\mu_{3}-6\mu^{2}\mu_{2}-\mu^{4}\quad\textrm{for }\beta>4\end{eqnarray*}

Implementation: `scipy.stats.betaprime`

.. _continuous-halfcauchy:

HalfCauchy Distribution
=======================

If :math:`Z` is Hyperbolic Secant distributed then :math:`e^{Z}` is
Half-Cauchy distributed. Also, if :math:`W` is (standard) Cauchy
distributed, then :math:`\left|W\right|` is Half-Cauchy distributed.
Special case of the Folded Cauchy distribution with :math:`c=0.`
The support is :math:`x\geq0`. The standard form is

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{2}{\pi\left(1+x^{2}\right)} \\
    F\left(x\right) & = & \frac{2}{\pi}\arctan\left(x\right)\\
    G\left(q\right) & = & \tan\left(\frac{\pi}{2}q\right)\end{eqnarray*}

.. math::

     M\left(t\right)=\cos t+\frac{2}{\pi}\left[\mathrm{Si}\left(t\right)\cos t-\mathrm{Ci}\left(\mathrm{-}t\right)\sin t\right]

where :math:`\mathrm{Si}(t)=\int_0^t \frac{\sin x}{x} dx`, :math:`\mathrm{Ci}(t)=-\int_t^\infty \frac{\cos x}{x} dx`.

.. math::
   :nowrap:

    \begin{eqnarray*} m_{d} & = & 0\\
    m_{n} & = & \tan\left(\frac{\pi}{4}\right)\end{eqnarray*}

No moments, as the integrals diverge.


.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & \log\left(2\pi\right)\\  & \approx & 1.8378770664093454836.\end{eqnarray*}

Implementation: `scipy.stats.halfcauchy`

.. _continuous-cosine:

Cosine Distribution
===================

Approximation to the normal distribution.  The support is :math:`\left[-\pi,\pi\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{1}{2\pi}\left(1+\cos x\right)\\
    F\left(x\right) & = & \frac{1}{2\pi}\left(\pi+x+\sin x\right)\\
    G\left(q\right) & = & F^{-1}\left(q\right)\\
    M\left(t\right) & = & \frac{\sinh\left(\pi t\right)}{\pi t\left(1+t^{2}\right)}\\
    \mu=m_{d}=m_{n} & = & 0\\
    \mu_{2} & = & \frac{\pi^{2}}{3}-2\\
    \gamma_{1} & = & 0\\
    \gamma_{2} & = & \frac{-6\left(\pi^{4}-90\right)}{5\left(\pi^{2}-6\right)^{2}}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & \log\left(4\pi\right)-1\\
    & \approx & 1.5310242469692907930.\end{eqnarray*}

Implementation: `scipy.stats.cosine`

.. _discrete-randint:

Discrete Uniform (randint) Distribution
=======================================

The discrete uniform distribution with parameters :math:`\left(a,b\right)` constructs a random variable that has an equal probability of being
any one of the integers in the half-open range :math:`[a,b)`. If :math:`a` is not given it is assumed to be zero and the only parameter is :math:`b`. Therefore,

.. math::
   :nowrap:

    \begin{eqnarray*}
        p\left(k,a,b\right) & = & \frac{1}{b-a} \quad a \leq k < b \\
        F\left(x;a,b\right) & = & \frac{\left\lfloor x\right\rfloor -a}{b-a} \quad a \leq x \leq b \\
        G\left(q;a,b\right) & = & \left\lceil q\left(b-a\right)+a\right\rceil \\
        \mu & = & \frac{b+a-1}{2}\\
        \mu_{2} & = & \frac{\left(b-a-1\right)\left(b-a+1\right)}{12}\\
        \gamma_{1} & = & 0 \\
        \gamma_{2} & = & -\frac{6}{5}\frac{\left(b-a\right)^{2}+1}{\left(b-a-1\right)\left(b-a+1\right)}.
    \end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*}
        M\left(t\right) & = & \frac{1}{b-a}\sum_{k=a}^{b-1}e^{tk}\\
                        & = & \frac{e^{bt}-e^{at}}{\left(b-a\right)\left(e^{t}-1\right)}
    \end{eqnarray*}

Implementation: `scipy.stats.randint`
.. _discrete-random-variables:


==================================
Discrete Statistical Distributions
==================================

Discrete random variables take on only a countable number of values.
The commonly used distributions are included in SciPy and described in
this document. Each discrete distribution can take one extra integer
parameter: :math:`L.` The relationship between the general distribution
:math:`p` and the standard distribution :math:`p_{0}` is

.. math::

    p\left(x\right) = p_{0}\left(x-L\right)

which allows for shifting of the input. When a distribution generator
is initialized, the discrete distribution can either specify the
beginning and ending (integer) values :math:`a` and :math:`b` which must be such that

.. math::

    p_{0}\left(x\right) = 0\quad x < a \textrm{ or } x > b

in which case, it is assumed that the pdf function is specified on the
integers :math:`a+mk\leq b` where :math:`k` is a non-negative integer ( :math:`0,1,2,\ldots` ) and :math:`m` is a positive integer multiplier. Alternatively, the two lists :math:`x_{k}` and :math:`p\left(x_{k}\right)` can be provided directly in which case a dictionary is set up
internally to evaluate probabilities and generate random variates.


Probability Mass Function (PMF)
-------------------------------

The probability mass function of a random variable X is defined as the
probability that the random variable takes on a particular value.

.. math::

    p\left(x_{k}\right)=P\left[X=x_{k}\right]

This is also sometimes called the probability density function,
although technically

.. math::

    f\left(x\right)=\sum_{k}p\left(x_{k}\right)\delta\left(x-x_{k}\right)

is the probability density function for a discrete distribution [#]_ .

.. [#]
    XXX: Unknown layout Plain Layout: Note that we will be using :math:`p` to represent the probability mass function and a parameter (a
    XXX: probability). The usage should be obvious from context.


Cumulative Distribution Function (CDF)
--------------------------------------

The cumulative distribution function is

.. math::

    F\left(x\right)=P\left[X\leq x\right]=\sum_{x_{k}\leq x}p\left(x_{k}\right)

and is also useful to be able to compute. Note that

.. math::

    F\left(x_{k}\right)-F\left(x_{k-1}\right)=p\left(x_{k}\right)


Survival Function
-----------------

The survival function is just

.. math::

    S\left(x\right)=1-F\left(x\right)=P\left[X>k\right]

the probability that the random variable is strictly larger than :math:`k` .

.. _discrete-ppf:

Percent Point Function (Inverse CDF)
------------------------------------

The percent point function is the inverse of the cumulative
distribution function and is

.. math::

    G\left(q\right)=F^{-1}\left(q\right)

for discrete distributions, this must be modified for cases where
there is no :math:`x_{k}` such that :math:`F\left(x_{k}\right)=q.` In these cases we choose :math:`G\left(q\right)` to be the smallest value :math:`x_{k}=G\left(q\right)` for which :math:`F\left(x_{k}\right)\geq q` . If :math:`q=0` then we define :math:`G\left(0\right)=a-1` . This definition allows random variates to be defined in the same way
as with continuous rv's using the inverse cdf on a uniform
distribution to generate random variates.


Inverse survival function
-------------------------

The inverse survival function is the inverse of the survival function

.. math::

    Z\left(\alpha\right)=S^{-1}\left(\alpha\right)=G\left(1-\alpha\right)

and is thus the smallest non-negative integer :math:`k` for which :math:`F\left(k\right)\geq1-\alpha` or the smallest non-negative integer :math:`k` for which :math:`S\left(k\right)\leq\alpha.`


Hazard functions
----------------

If desired, the hazard function and the cumulative hazard function
could be defined as

.. math::

    h\left(x_{k}\right)=\frac{p\left(x_{k}\right)}{1-F\left(x_{k}\right)}

and

.. math::

    H\left(x\right)=\sum_{x_{k}\leq x}h\left(x_{k}\right)=\sum_{x_{k}\leq x}\frac{F\left(x_{k}\right)-F\left(x_{k-1}\right)}{1-F\left(x_{k}\right)}.


Moments
-------

Non-central moments are defined using the PDF

.. math::

    \mu_{m}^{\prime}=E\left[X^{m}\right]=\sum_{k}x_{k}^{m}p\left(x_{k}\right).

Central moments are computed similarly :math:`\mu=\mu_{1}^{\prime}`

.. math::
   :nowrap:

    \begin{eqnarray*} \mu_{m}=E\left[\left(X-\mu\right)^{m}\right] & = & \sum_{k}\left(x_{k}-\mu\right)^{m}p\left(x_{k}\right)\\  & = & \sum_{k=0}^{m}\left(-1\right)^{m-k}\left(\begin{array}{c} m\\ k\end{array}\right)\mu^{m-k}\mu_{k}^{\prime}\end{eqnarray*}

The mean is the first moment

.. math::

    \mu=\mu_{1}^{\prime}=E\left[X\right]=\sum_{k}x_{k}p\left(x_{k}\right)

the variance is the second central moment

.. math::

    \mu_{2}=E\left[\left(X-\mu\right)^{2}\right]=\sum_{x_{k}}x_{k}^{2}p\left(x_{k}\right)-\mu^{2}.

Skewness is defined as

.. math::

    \gamma_{1}=\frac{\mu_{3}}{\mu_{2}^{3/2}}

while (Fisher) kurtosis is

.. math::

    \gamma_{2}=\frac{\mu_{4}}{\mu_{2}^{2}}-3,

so that a normal distribution has a kurtosis of zero.


Moment generating function
--------------------------

The moment generating function is defined as

.. math::

    M_{X}\left(t\right)=E\left[e^{Xt}\right]=\sum_{x_{k}}e^{x_{k}t}p\left(x_{k}\right)

Moments are found as the derivatives of the moment generating function
evaluated at :math:`0.`


Fitting data
------------

To fit data to a distribution, maximizing the likelihood function is
common. Alternatively, some distributions have well-known minimum
variance unbiased estimators. These will be chosen by default, but the
likelihood function will always be available for minimizing.

If :math:`f_{i}\left(k;\boldsymbol{\theta}\right)` is the PDF of a random-variable where :math:`\boldsymbol{\theta}` is a vector of parameters ( *e.g.* :math:`L` and :math:`S` ), then for a collection of :math:`N` independent samples from this distribution, the joint distribution the
random vector :math:`\mathbf{k}` is

.. math::

    f\left(\mathbf{k};\boldsymbol{\theta}\right)=\prod_{i=1}^{N}f_{i}\left(k_{i};\boldsymbol{\theta}\right).

The maximum likelihood estimate of the parameters :math:`\boldsymbol{\theta}` are the parameters which maximize this function with :math:`\mathbf{x}` fixed and given by the data:

.. math::
   :nowrap:

    \begin{eqnarray*} \hat{\boldsymbol{\theta}} & = & \arg\max_{\boldsymbol{\theta}}f\left(\mathbf{k};\boldsymbol{\theta}\right)\\  & = & \arg\min_{\boldsymbol{\theta}}l_{\mathbf{k}}\left(\boldsymbol{\theta}\right).\end{eqnarray*}

Where

.. math::
   :nowrap:

    \begin{eqnarray*} l_{\mathbf{k}}\left(\boldsymbol{\theta}\right) & = & -\sum_{i=1}^{N}\log f\left(k_{i};\boldsymbol{\theta}\right)\\  & = & -N\overline{\log f\left(k_{i};\boldsymbol{\theta}\right)}\end{eqnarray*}


Standard notation for mean
--------------------------

We will use

.. math::

    \overline{y\left(\mathbf{x}\right)}=\frac{1}{N}\sum_{i=1}^{N}y\left(x_{i}\right)

where :math:`N` should be clear from context.


Combinations
------------

Note that

.. math::

    k!=k\cdot\left(k-1\right)\cdot\left(k-2\right)\cdot\cdots\cdot1=\Gamma\left(k+1\right)

and has special cases of

.. math::
   :nowrap:

    \begin{eqnarray*} 0! & \equiv & 1\\ k! & \equiv & 0\quad k<0\end{eqnarray*}

and

.. math::

    \left(\begin{array}{c} n\\ k\end{array}\right)=\frac{n!}{\left(n-k\right)!k!}.

If :math:`n<0` or :math:`k<0` or :math:`k>n` we define :math:`\left(\begin{array}{c} n\\ k\end{array}\right)=0`



Discrete Distributions in `scipy.stats`
---------------------------------------
.. toctree::
   :maxdepth: 1

   discrete_bernoulli
   discrete_betabinom
   discrete_binom
   discrete_boltzmann
   discrete_planck
   discrete_poisson
   discrete_geom
   discrete_nbinom
   discrete_hypergeom
   discrete_nchypergeom_fisher
   discrete_nchypergeom_wallenius
   discrete_nhypergeom
   discrete_zipf
   discrete_zipfian
   discrete_logser
   discrete_randint
   discrete_dlaplace
   discrete_yulesimon

.. _continuous-anglit:

Anglit Distribution
===================

Defined over :math:`x\in\left[-\frac{\pi}{4},\frac{\pi}{4}\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \sin\left(2x+\frac{\pi}{2}\right)=\cos\left(2x\right)\\ F\left(x\right) & = & \sin^{2}\left(x+\frac{\pi}{4}\right)\\ G\left(q\right) & = & \arcsin\left(\sqrt{q}\right)-\frac{\pi}{4}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & 0\\ \mu_{2} & = & \frac{\pi^{2}}{16}-\frac{1}{2}\\ \gamma_{1} & = & 0\\ \gamma_{2} & = & -2\frac{\pi^{4}-96}{\left(\pi^{2}-8\right)^{2}}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & 1-\log2\\  & \approx & 0.30685281944005469058\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} M\left(t\right) & = & \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}}\cos\left(2x\right)e^{xt}dx\\  & = & \frac{4\cosh\left(\frac{\pi t}{4}\right)}{t^{2}+4}\end{eqnarray*}

.. math::

     l_{\mathbf{x}}\left(\cdot\right)=-N\overline{\log\left[\cos\left(2\mathbf{x}\right)\right]}

Implementation: `scipy.stats.anglit`
.. _non-uniform-random-number-sampling:

=====================================================
Universal Non-Uniform Random Number Sampling in SciPy
=====================================================

.. currentmodule:: scipy.stats.sampling

SciPy provides an interface to many universal non-uniform random number
generators to sample random variates from a wide variety of univariate
continuous and discrete distributions. Implementations of a fast C library
called `UNU.RAN <http://statmath.wu.ac.at/software/unuran/>`__ are used
for speed and performance. Please look at
`UNU.RAN's documentation <http://statmath.wu.ac.at/software/unuran/doc/unuran.html>`__
for an in-depth explanation of these methods. It is heavily referred to
for writing this tutorial and the documentation of all the generators.


Introduction
------------

Random variate generation is the small field of research that deals with
algorithms to generate random variates from various distributions. It is
common to assume that a uniform random number generator is available.
This is a program that produces a sequence of independent and identically
distributed continuous U(0,1) random variates (i.e. uniform random variates
on the interval (0,1)). Of course, real-world computers can never generate
ideal random numbers and they cannot produce numbers of arbitrary precision
but state-of-the-art uniform random number generators come close to this
aim. Thus random variate generation deals with the problem of transforming
such a sequence of U(0,1) random numbers into non-uniform random variates.
These methods are universal and work in a black-box fashion.

Some methods to do that are:

* The Inversion method: When the inverse :math:`F^{-1}` of the cumulative
  distribution function is known, then random variate generation is easy.
  We just generate a uniformly U(0,1) distributed random number U and
  return :math:`X = F^{-1}(U)`. As closed form solutions for the inverse
  are rarely available, one usually needs to rely on approximations of
  the inverse (e.g. :class:`~scipy.special.ndtri`,
  :class:`~scipy.special.stdtrit`). In general, the implementation of special
  functions is quite slow compared to the inversion methods in UNU.RAN.
* The Rejection Method: The rejection method, often called
  acceptance-rejection method, has been suggested by John von Neumann in
  1951 [1]_. It involves computing an upper bound to the PDF (also called the
  hat function) and using the inversion method to generate a random
  variate, say Y, from this bound. Then a uniform random number can be
  drawn between 0 to the value of the upper bound at Y. If this number
  is less than the PDF at Y, return the sample otherwise reject it. See
  :class:`~TransformedDensityRejection`.
* The Ratio-of-Uniforms Method: This is a type of acceptance-rejection
  method which is uses minimal bounding rectangles to construct the hat
  function. See `scipy.stats.rvs_ratio_uniforms`.
* Inversion for Discrete Distributions: The difference compared to the
  continuous case is that :math:`F` is now a step-function. To realize
  this in a computer, a search algorithm is used, the simplest of which
  is *sequential search*. A uniform random number is generated from
  U(0, 1) and probabilities are summed until the cumulative probability
  exceeds the uniform random number. The index at which this happens is
  the required random variate and is returned.


More details on these algorithms can be found in the `appendix of the UNU.RAN
user manual <http://statmath.wu.ac.at/software/unuran/doc/unuran.html#RVG>`__.


When generating random variates of a distribution, two factors are important
to determine the speed of a generator: the setup step and the actual sampling.
Depending on the situation, different generators can be optimal. For example,
if one repeatedly needs to draw large samples from a given distribution with
a fixed shape parameter, a slow setup is acceptable if the sampling is fast.
This is called the fixed parameter case. If one aims to generate samples of
a distribution for different shape parameters (the varying parameter case),
an expensive setup that needs to be repeated for each parameter would lead
to very poor performance. In such a situation, a fast setup is crucial to
achieve good performance. An overview of the setup and sampling speed of the
different methods is shown in the table below.

.. _unuran-methods-summary:

=====================================  ===============  ===============  ===========  ==============
Methods for continuous distributions   Required Inputs  Optional Inputs  Setup Speed  Sampling Speed
=====================================  ===============  ===============  ===========  ==============
:class:`~TransformedDensityRejection`  pdf, dpdf        none             slow         fast
:class:`~NumericalInverseHermite`      cdf              pdf, dpdf        (very) slow  (very) fast
:class:`~NumericalInversePolynomial`   pdf              cdf              (very) slow  (very) fast
:class:`~SimpleRatioUniforms`          pdf              none             fast         slow
=====================================  ===============  ===============  ===========  ==============

where

* pdf: probability density function
* dpdf: derivative of the pdf
* cdf: cumulative distribution function


=====================================  ===============  ===============  ===========  ==============
Methods for discrete distributions     Required Inputs  Optional Inputs  Setup Speed  Sampling Speed
=====================================  ===============  ===============  ===========  ==============
:class:`~DiscreteAliasUrn`             pv               pmf              slow         very fast
:class:`~DiscreteGuideTable`           pv               pmf              slow         very fast
=====================================  ===============  ===============  ===========  ==============

where

* pv: probability vector
* pmf: probability mass function


For more details on the generators implemented in UNU.RAN, please refer to [2]_ and [3]_.

Basic concepts of the Interface
-------------------------------

Every generator needs to be set up before one can start sampling from it.
This can be done by instantiating an object of that class. Most of the
generators take a distribution object as input which contains the implementation
of required methods like PDF, CDF, etc. In addition to the distribution
object, one can also pass parameters used to set up the generator. It is also
possible to truncate the distributions using a ``domain`` parameter.  All
generators need a stream of uniform random numbers that are transformed into
random variates of the given distribution. This is done by passing a ``random_state``
parameter with a NumPy BitGenerator as the uniform random number generator.
``random_state`` can either be a integer, `np.random.Generator`,
or `np.random.RandomState`.

.. warning:: Use of NumPy < 1.19.0 is discouraged as it doesn't have a fast
             Cython API for generating uniform random numbers and might be
             too slow for practical use.

All the generators have a common ``rvs`` method that can be used to draw
samples from the given distribution.

An example of this interface is shown below:

    >>> from scipy.stats.sampling import TransformedDensityRejection
    >>> from math import exp
    >>> 
    >>> class StandardNormal:
    ...     def pdf(self, x: float) -> float:
    ...         # note that the normalization constant isn't required
    ...         return exp(-0.5 * x*x)
    ...     def dpdf(self, x: float) -> float:
    ...         return -x * exp(-0.5 * x*x)
    ... 
    >>> dist = StandardNormal()
    >>> 
    >>> urng = np.random.default_rng()
    >>> rng = TransformedDensityRejection(dist, random_state=urng)

As shown in the example, we first initialize a distribution object that
contains an implementation of the methods required by the generator. In
our case, we use the :class:`~TransformedDensityRejection` (TDR) method
which requires a PDF and its derivative w.r.t. ``x`` (i.e. the variate).

.. note:: Note that the methods of the distribution (i.e. ``pdf``,
          ``dpdf``, etc) need not be vectorized. They should
          accept and return floats.

.. note:: One can also pass the SciPy distributions as arguments. However,
          note that the object doesn't always have all the information
          required by some generators like the derivative of PDF for the
          TDR method. Relying on SciPy distributions might also reduce
          performance due to the vectorization of the methods like
          ``pdf`` and ``cdf``. In both cases, one can implement a
          custom distribution object that contains all the required
          methods and that is not vectorized as shown in the example
          above.

In the above example, we have set up an object of the
:class:`~TransformedDensityRejection` method to sample from a
standard normal distribution. Now, we can start sampling from our
distribution by calling the ``rvs`` method:

    >>> rng.rvs()
    -1.526829048388144
    >>> rng.rvs((5, 3))
    array([[ 2.06206883,  0.15205036,  1.11587367],
           [-0.30775562,  0.29879802, -0.61858268],
           [-1.01049115,  0.78853694, -0.23060766],
           [-0.60954752,  0.29071797, -0.57167182],
           [ 0.9331694 , -0.95605208,  1.72195199]])

We can also check that the samples are drawn from the correct distribution
by visualizing the histogram of the samples:

.. plot::

    >>> import matplotlib.pyplot as plt
    >>> from scipy.stats import norm
    >>> from scipy.stats.sampling import TransformedDensityRejection
    >>> from math import exp
    >>> 
    >>> class StandardNormal:
    ...     def pdf(self, x: float) -> float:
    ...         # note that the normalization constant isn't required
    ...         return exp(-0.5 * x*x)
    ...     def dpdf(self, x: float) -> float:
    ...         return -x * exp(-0.5 * x*x)
    ... 
    >>> 
    >>> dist = StandardNormal()
    >>> urng = np.random.default_rng()
    >>> rng = TransformedDensityRejection(dist, random_state=urng)
    >>> rvs = rng.rvs(size=1000)
    >>> x = np.linspace(rvs.min()-0.1, rvs.max()+0.1, num=1000)
    >>> fx = norm.pdf(x)
    >>> plt.plot(x, fx, 'r-', lw=2, label='true distribution')
    >>> plt.hist(rvs, bins=20, density=True, alpha=0.8, label='random variates')
    >>> plt.xlabel('x')
    >>> plt.ylabel('PDF(x)')
    >>> plt.title('Transformed Density Rejection Samples')
    >>> plt.legend()
    >>> plt.show()

.. note:: Please note the difference between the `rvs` method of the
          distributions present in :mod:`scipy.stats` and the one provided
          by these generators. UNU.RAN generators must be considered
          independent in a sense that they will generally produce a different
          stream of random numbers than the one produced by the equivalent
          distribution in :mod:`scipy.stats` for any seed. The implementation
          of `rvs` in `scipy.stats.rv_continuous` usually relies on the NumPy
          module `np.random` for well-known distributions (e.g., for the normal
          distribution, the beta distribution) and transformations of other
          distributions (e.g., normal inverse Gaussian `scipy.stats.norminvgauss` and the
          lognormal `scipy.stats.lognorm` distribution). If no specific method is implemented,
          `scipy.stats.rv_continuous` defaults to a numerical inversion method of the CDF
          that is very slow. As UNU.RAN transforms uniform random numbers
          differently than SciPy or NumPy, the resulting stream of RVs is
          different even for the same stream of uniform random numbers. For
          example, the random number stream of SciPy's ``scipy.stats.norm`` and UNU.RAN's
          :class:`~TransformedDensityRejection` would not be the same even for
          the same ``random_state``:

          >>> from scipy.stats.sampling import norm, TransformedDensityRejection
          >>> from copy import copy
          >>> dist = StandardNormal()
          >>> urng1 = np.random.default_rng()
          >>> urng1_copy = copy(urng1)
          >>> rng = TransformedDensityRejection(dist, random_state=urng1)
          >>> rng.rvs()
          -1.526829048388144
          >>> norm.rvs(random_state=urng1_copy)
          1.3194816698862635

We can pass a ``domain`` parameter to truncate the distribution:

    >>> rng = TransformedDensityRejection(dist, domain=(-1, 1), random_state=urng)
    >>> rng.rvs((5, 3))
    array([[-0.99865691,  0.38104014,  0.31633526],
           [ 0.88433909, -0.45181849,  0.78574461],
           [ 0.3337244 ,  0.12924307,  0.40499404],
           [-0.51865761,  0.43252222, -0.6514866 ],
           [-0.82666174,  0.71525582,  0.49006743]])

Invalid and bad arguments are handled either by SciPy or by UNU.RAN. The
latter throws a :class:`~UNURANError` that follows a common format:

``UNURANError: [objid: <object id>] <error code>: <reason> => <type of error>``

where:

* ``<object id>`` is the ID of the object given by UNU.RAN
* ``<error code>`` is an error code representing a type of error.
* ``<reason>`` is the reason why the error occurred.
* ``<type of error>`` is a short description of the type of error.

The ``<reason>`` shows what caused the error. This, by itself, should contain
enough information to help debug the error. In addition, ``<error id>`` and
``<type of error>`` can be used to investigate different classes of error in
UNU.RAN. A complete list of all the error codes and their descriptions can be
found in the `Section 8.4 of the UNU.RAN user manual
<http://statmath.wu.ac.at/software/unuran/doc/unuran.html#Errno>`__.

An example of an error generated by UNU.RAN is shown below:

``UNURANError: [objid: TDR.003] 50 : PDF(x) < 0.! => (generator) (possible) invalid data``

This shows that UNU.RAN failed to initialize an object with ID ``TDR.003``
because the PDF was < 0. i.e. negative. This falls under the type
"possible invalid data for the generator" and has error code 50.

Warnings thrown by UNU.RAN also follow the same format.


Generators in :mod:`scipy.stats.sampling`
-----------------------------------------
.. toctree::
   :maxdepth: 1

   sampling_tdr
   sampling_dau
   sampling_pinv
   sampling_dgt
   sampling_hinv
   sampling_srou


References
~~~~~~~~~~

.. [1] Von Neumann, John. "13. various techniques used in connection with
       random digits." Appl. Math Ser 12.36-38 (1951): 3.

.. [2] UNU.RAN User Manual, https://statmath.wu.ac.at/unuran/doc/unuran.html

.. [3] Leydold, Josef, Wolfgang Hörmann, and Halis Sak. "An R Interface to
       the UNU.RAN Library for Universal Random Variate Generators.",
       https://cran.r-project.org/web/packages/Runuran/vignettes/Runuran.pdf

.. _continuous-gennorm:

Generalized Normal Distribution
===============================

This distribution is also known as the exponential power distribution. It has
a single shape parameter :math:`\beta>0`. It reduces to a number of common
distributions.

Functions
---------

.. math::
    :nowrap:

    \begin{eqnarray*} f\left(x; \beta\right) & = &\frac{\beta}{2\Gamma(1/\beta)} e^{-\left|x\right|^{\beta}} \end{eqnarray*}

.. math::
    :nowrap:

    \begin{eqnarray*} F\left(x; \beta\right) & = & \frac{1}{2} + \mathrm{sgn}\left(x\right) \frac{\gamma\left(1/\beta, x^{\beta}\right)}{2\Gamma\left(1/\beta\right)} \end{eqnarray*}
     
:math:`\gamma` is the lower incomplete gamma function. 
:math:`\gamma\left(s, x\right) = \int_0^x t^{s-1} e^{-t} dt`.

.. math::
    :nowrap:

    \begin{eqnarray*} h\left[X; \beta\right] = \frac{1}{\beta} - \log\left(\frac{\beta}{2\Gamma\left(1/\beta\right)}\right)\end{eqnarray*}

Moments
-------

.. math::
   :nowrap:

    \begin{eqnarray*}
    \mu & = & 0 \\
    m_{n} & = & 0 \\
    m_{d} & = & 0 \\
    \mu_2 &  = & \frac{\Gamma\left(3/\beta\right)}{\gamma\left(1/\beta\right)} \\
    \gamma_1 & = & 0 \\
    \gamma_2 & = & \frac{\Gamma\left(5/\beta\right) \Gamma\left(1/\beta\right)}{\Gamma\left(3/\beta\right)^2} - 3 \\
    \end{eqnarray*}


Special Cases
-------------
* Laplace distribution (:math:`\beta = 1`)
* Normal distribution with :math:`\mu_2 = 1/2` (:math:`\beta = 2`)
* Uniform distribution over the interval :math:`[-1, 1]`
  (:math:`\beta \rightarrow \infty`)

Sources
-------
* https://en.wikipedia.org/wiki/Generalized_normal_distribution#Version_1
* https://en.wikipedia.org/wiki/Incomplete_gamma_function#Lower_incomplete_Gamma_function

Implementation: `scipy.stats.gennorm`

.. _continuous-gumbel_r:

Gumbel (LogWeibull, Fisher-Tippetts, Type I Extreme Value) Distribution
=======================================================================

One of a class of extreme value distributions (right-skewed).

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \exp\left(-\left(x+e^{-x}\right)\right)\\ F\left(x\right) & = & \exp\left(-e^{-x}\right)\\ G\left(q\right) & = & -\log\left(-\log\left(q\right)\right)\end{eqnarray*}

.. math::

     M\left(t\right)=\Gamma\left(1-t\right)

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \gamma=-\psi_{0}\left(1\right)\\ \mu_{2} & = & \frac{\pi^{2}}{6}\\ \gamma_{1} & = & \frac{12\sqrt{6}}{\pi^{3}}\zeta\left(3\right)\\ \gamma_{2} & = & \frac{12}{5}\\ m_{d} & = & 0\\ m_{n} & = & -\log\left(\log2\right)\end{eqnarray*}

.. math::

     h\left[X\right]\approx1.0608407169541684911

Implementation: `scipy.stats.gumbel_r`

.. _continuous-tukeylambda:

Tukey-Lambda Distribution
=========================

There is one shape parameter :math:`\lambda`.  The support is :math:`x\in\mathbb{R}`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\lambda\right) & = & F^{\prime}\left(x;\lambda\right)=\frac{1}{G^{\prime}\left(F\left(x;\lambda\right);\lambda\right)}=\frac{1}{F^{\lambda-1}\left(x;\lambda\right)+\left[1-F\left(x;\lambda\right)\right]^{\lambda-1}}\\ F\left(x;\lambda\right) & = & G^{-1}\left(x;\lambda\right)\\ G\left(p;\lambda\right) & = & \frac{p^{\lambda}-\left(1-p\right)^{\lambda}}{\lambda}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & 0\\ \mu_{2} & = & \int_{0}^{1}G^{2}\left(p;\lambda\right)dp\\  & = & \frac{2\Gamma\left(\lambda+\frac{3}{2}\right)-\lambda4^{-\lambda}\sqrt{\pi}\Gamma\left(\lambda\right)\left(1-2\lambda\right)}{\lambda^{2}\left(1+2\lambda\right)\Gamma\left(\lambda+\frac{3}{2}\right)}\\ \gamma_{1} & = & 0\\ \gamma_{2} & = & \frac{\mu_{4}}{\mu_{2}^{2}}-3\\ \mu_{4} & = & \frac{3\Gamma\left(\lambda\right)\Gamma\left(\lambda+\frac{1}{2}\right)2^{-2\lambda}}{\lambda^{3}\Gamma\left(2\lambda+\frac{3}{2}\right)}+\frac{2}{\lambda^{4}\left(1+4\lambda\right)}\\  &  & -\frac{2\sqrt{3}\Gamma\left(\lambda\right)2^{-6\lambda}3^{3\lambda}\Gamma\left(\lambda+\frac{1}{3}\right)\Gamma\left(\lambda+\frac{2}{3}\right)}{\lambda^{3}\Gamma\left(2\lambda+\frac{3}{2}\right)\Gamma\left(\lambda+\frac{1}{2}\right)}.\end{eqnarray*}

Notice that the :math:`\lim_{\lambda\rightarrow0}G\left(p;\lambda\right)=\log\left(p/\left(1-p\right)\right)`

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & \int_{0}^{1}\log\left[G^{\prime}\left(p\right)\right]dp\\  & = & \int_{0}^{1}\log\left[p^{\lambda-1}+\left(1-p\right)^{\lambda-1}\right]dp.\end{eqnarray*}

Implementation: `scipy.stats.tukeylambda`

.. _continuous-expon:

Exponential Distribution
========================

This is a special case of the Gamma (and Erlang) distributions with
shape parameter :math:`\left(\alpha=1\right)` and the same location and scale parameters. The standard form is
therefore ( :math:`x\geq0` )

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & e^{-x}\\
    F\left(x\right) & = & \gamma\left(1,x\right) = 1-e^{-x}\\
    G\left(q\right) & = & -\log\left(1-q\right)\end{eqnarray*}

.. math::

     \mu_{n}^{\prime}=n!

.. math::

     M\left(t\right)=\frac{1}{1-t}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & 1\\ \mu_{2} & = & 1\\ \gamma_{1} & = & 2\\ \gamma_{2} & = & 6\\ m_{d} & = & 0\end{eqnarray*}

.. math::

     h\left[X\right]=1.

Implementation: `scipy.stats.expon`

.. _continuous-burr12:

Burr12 Distribution
===================

There are two shape parameters :math:`c,d > 0` and the support is :math:`x \in [0,\infty)`.
The Burr12 distribution is also known as the Singh-Maddala distribution.



.. math::
   :nowrap:

    \begin{eqnarray*}
    f\left(x;c,d\right) & = & {cd} \frac{x^{c-1}} {\left(1+x^{c}\right)^{d+1}} \\
    F\left(x;c,d\right) & = & 1 - \left(1+x^{c}\right)^{-d}\\
    G\left(q;c,d\right) & = & \left((1-q)^{-1/d}-1\right)^{-1/c}\\
    S\left(x;c,d\right) & = & \left(1+x^{c}\right)^{-d}\\
    \mu & = & d \,  B\left(d-\frac{1}{c}, 1+\frac{1}{c}\right)\\
    \mu_{n} & = & d \, B\left(d-\frac{n}{c}, 1+\frac{n}{c}\right)\\
    m_{d} & = & \left(\frac{c-1}{c d + 1}\right)^{1/c} \,\text{if }\quad c>1 \text{, otherwise }\quad 0\\
    m_{n} & = & \left(2^{1/d}-1\right)^{-1/c}
    \end{eqnarray*}

where :math:`B(a, b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}` is the Beta function.

Implementation: `scipy.stats.burr12`

.. _continuous-mielke:

Mielke's Beta-Kappa Distribution
================================

A generalized F distribution. Two shape parameters
:math:`\kappa` and :math:`\theta`, with support :math:`x\geq0`.
The :math:`\beta` in the DATAPLOT reference is a scale parameter.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\kappa,\theta\right) & = & \frac{\kappa x^{\kappa-1}}{\left(1+x^{\theta}\right)^{1+\frac{\kappa}{\theta}}}\\ F\left(x;\kappa,\theta\right) & = & \frac{x^{\kappa}}{\left(1+x^{\theta}\right)^{\kappa/\theta}}\\ G\left(q;\kappa,\theta\right) & = & \left(\frac{q^{\theta/\kappa}}{1-q^{\theta/\kappa}}\right)^{1/\theta}\end{eqnarray*}

Implementation: `scipy.stats.mielke`

.. _continuous-ksone:

KSone Distribution
==================


This is the distribution of maximum positive differences between an
empirical distribution function, computed from :math:`n` samples or observations,
and a comparison (or target) cumulative distribution function.

Writing :math:`D_n^+ = \sup_t \left(F_{empirical,n}(t)-F_{target}(t)\right)`,
``ksone`` is the distribution of the :math:`D_n^+` values.
(The distribution of :math:`D_n^- = \sup_t \left(F_{target}(t)-F_{empirical,n}(t)\right)`
differences follows the same distribution, so ``ksone`` can be used for one-sided tests on either side.)


There is one shape parameter :math:`n`, a positive integer, and the support is :math:`x\in\left[0,1\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} F\left(n, x\right) & = & 1 - \sum_{j=0}^{\lfloor n(1-x)\rfloor} \dbinom{n}{j} x \left(x+\frac{j}{n}\right)^{j-1} \left(1-x-\frac{j}{n}\right)^{n-j}\\
    & = & 1 - \textrm{scipy.special.smirnov}(n, x) \\
    \lim_{n \rightarrow\infty} F\left(n, \frac{x}{\sqrt n}\right) & = & e^{-2 x^2} \end{eqnarray*}


References
----------

-  "Kolmogorov-Smirnov test", Wikipedia
   https://en.wikipedia.org/wiki/Kolmogorov-Smirnov_test

-  Birnbaum, Z. W.; Tingey, Fred H. "One-Sided Confidence Contours for Probability Distribution Functions."
   *Ann. Math. Statist*. 22 (1951), no. 4, 592--596.


Implementation: `scipy.stats.ksone`

.. _discrete-bernoulli:

Bernoulli Distribution
======================

A Bernoulli random variable of parameter :math:`p` takes one of only two values :math:`X=0` or :math:`X=1` . The probability of success ( :math:`X=1` ) is :math:`p` , and the probability of failure ( :math:`X=0` ) is :math:`1-p.` It can be thought of as a binomial random variable with :math:`n=1` . The PMF is :math:`p\left(k\right)=0` for :math:`k\neq0,1` and

.. math::
   :nowrap:

    \begin{eqnarray*}
        p\left(k;p\right) & = & \begin{cases} 1-p & k=0\\ p & k=1\end{cases}\\
        F\left(x;p\right) & = & \begin{cases} 0 & x<0\\ 1-p & 0\le x<1\\ 1 & 1\leq x\end{cases}\\
        G\left(q;p\right) & = & \begin{cases} 0 & 0\leq q<1-p\\ 1 & 1-p\leq q\leq1\end{cases}\\
        \mu & = & p\\ \mu_{2} & = & p\left(1-p\right)\\
        \gamma_{3} & = & \frac{1-2p}{\sqrt{p\left(1-p\right)}}\\
        \gamma_{4} & = & \frac{1-6p\left(1-p\right)}{p\left(1-p\right)}
    \end{eqnarray*}

.. math::

    M\left(t\right) = 1-p\left(1-e^{t}\right)

.. math::

    \mu_{m}^{\prime}=p

.. math::

    h\left[X\right]=p\log p+\left(1-p\right)\log\left(1-p\right)

Implementation: `scipy.stats.bernoulli`

.. _continuous-chi:

Chi Distribution
================

Generated by taking the (positive) square-root of chi-squared
variates. The one shape parameter is :math:`\nu`, a positive integer, the degrees of freedom.
The support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\nu\right) & = & \frac{x^{\nu-1}e^{-x^{2}/2}}{2^{\nu/2-1}\Gamma\left(\frac{\nu}{2}\right)}\\
    F\left(x;\nu\right) & = & \frac{\gamma\left(\frac{\nu}{2},\frac{x^{2}}{2}\right)}{\Gamma(\frac{\nu}{2})}\\
    G\left(q;\nu\right) & = & \sqrt{2\gamma^{-1}\left(\frac{\nu}{2},q\Gamma(\frac{\nu}{2})\right)}\\
    M\left(t\right) & = & \Gamma\left(\frac{v}{2}\right)\,_{1}F_{1}\left(\frac{v}{2};\frac{1}{2};\frac{t^{2}}{2}\right)+\frac{t}{\sqrt{2}}\Gamma\left(\frac{1+\nu}{2}\right)\,_{1}F_{1}\left(\frac{1+\nu}{2};\frac{3}{2};\frac{t^{2}}{2}\right)\\
    \mu & = & \frac{\sqrt{2}\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)}\\
    \mu_{2} & = & \nu-\mu^{2}\\
    \gamma_{1} & = & \frac{2\mu^{3}+\mu\left(1-2\nu\right)}{\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{2\nu\left(1-\nu\right)-6\mu^{4}+4\mu^{2}\left(2\nu-1\right)}{\mu_{2}^{2}}\\
    m_{d} & = & \sqrt{\nu-1}\quad\nu\geq1\\
    m_{n} & = & \sqrt{2\gamma^{-1}\left(\frac{\nu}{2},\frac{1}{2}{\Gamma(\frac{\nu}{2})}\right)}\end{eqnarray*}

Implementation: `scipy.stats.chi`

.. _continuous-gilbrat:

Gilbrat Distribution
====================

Special case of the log-normal with :math:`\sigma=1` and :math:`S=1.0`, typically also :math:`L=0.0`.)

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\sigma\right) & = & \frac{1}{x\sqrt{2\pi}}\exp\left(-\frac{1}{2}\left(\log x\right)^{2}\right)\\
    F\left(x;\sigma\right) & = & \Phi\left(\log x\right)=\frac{1}{2}\left(1+\mathrm{erf}\left(\frac{\log x}{\sqrt{2}}\right)\right)\\
    G\left(q;\sigma\right) & = & \exp\left( \Phi^{-1}\left(q\right)\right) \end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \sqrt{e}\\
    \mu_{2} & = & e\left[e-1\right]\\
    \gamma_{1} & = & \sqrt{e-1}\left(2+e\right)\\
    \gamma_{2} & = & e^{4}+2e^{3}+3e^{2}-6\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} h\left[X\right] & = & \log\left(\sqrt{2\pi e}\right)\\
     & \approx & 1.4189385332046727418\end{eqnarray*}

Implementation: `scipy.stats.gilbrat`

.. _continuous-weibull_max:

Weibull Maximum Extreme Value Distribution
==========================================

Defined for :math:`x<0` and :math:`c>0` .

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & c\left(-x\right)^{c-1}\exp\left(-\left(-x\right)^{c}\right)\\ F\left(x;c\right) & = & \exp\left(-\left(-x\right)^{c}\right)\\ G\left(q;c\right) & = & -\left(-\log q\right)^{1/c}\end{eqnarray*}

The mean is the negative of the right-skewed Frechet distribution
given above, and the other statistical parameters can be computed from

.. math::

     \mu_{n}^{\prime}=\left(-1\right)^{n}\Gamma\left(1+\frac{n}{c}\right).

.. math::
   :nowrap:

    \begin{eqnarray*}
        \mu & = & -\Gamma\left(1+\frac{1}{c}\right) \\
        \mu_{2} & = & \Gamma\left(1+\frac{2}{c}\right) -
                      \Gamma^{2}\left(1+\frac{1}{c}\right) \\
        \gamma_{1} & = & -\frac{\Gamma\left(1+\frac{3}{c}\right) -
                                3\Gamma\left(1+\frac{2}{c}\right)\Gamma\left(1+\frac{1}{c}\right) +
                                2\Gamma^{3}\left(1+\frac{1}{c}\right)}
                               {\mu_{2}^{3/2}} \\
        \gamma_{2} & = & \frac{\Gamma\left(1+\frac{4}{c}\right) -
                               4\Gamma\left(1+\frac{1}{c}\right)\Gamma\left(1+\frac{3}{c}\right) +
                               6\Gamma^{2}\left(1+\frac{1}{c}\right)\Gamma\left(1+\frac{2}{c}\right) -
                               3\Gamma^{4}\left(1+\frac{1}{c}\right)}
                              {\mu_{2}^{2}} - 3 \\
        m_{d} & = & \begin{cases}
                        -\left(\frac{c-1}{c}\right)^{\frac{1}{c}} & \text{if}\; c > 1 \\
                        0 & \text{if}\; c <= 1
                    \end{cases} \\
        m_{n} & = & -\ln\left(2\right)^{\frac{1}{c}}
    \end{eqnarray*}

.. math::

     h\left[X\right]=-\frac{\gamma}{c}-\log\left(c\right)+\gamma+1

where :math:`\gamma` is Euler's constant and equal to

.. math::

     \gamma\approx0.57721566490153286061.

Implementation: `scipy.stats.weibull_max`

.. _continuous-powerlognorm:

Power Log Normal Distribution
=============================

A generalization of the log-normal distribution with shape parameters :math:`\sigma>0`, :math:`c>0` and support :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\sigma,c\right) & = & \frac{c}{x\sigma}\phi\left(\frac{\log x}{\sigma}\right)\left(\Phi\left(-\frac{\log x}{\sigma}\right)\right)^{c-1}\\
    F\left(x;\sigma,c\right) & = & 1-\left(\Phi\left(-\frac{\log x}{\sigma}\right)\right)^{c}\\
    G\left(q;\sigma,c\right) & = & \exp\left(-\sigma\Phi^{-1}\left(\left(1-q\right)^{1/c}\right)\right)\end{eqnarray*}

.. math::

     \mu_{n}^{\prime}=\int_{0}^{1}\exp\left(-n\sigma\Phi^{-1}\left(y^{1/c}\right)\right)dy

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \mu_{1}^{\prime}\\
    \mu_{2} & = & \mu_{2}^{\prime}-\mu^{2}\\
    \gamma_{1} & = & \frac{\mu_{3}^{\prime}-3\mu\mu_{2}-\mu^{3}}{\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{\mu_{4}^{\prime}-4\mu\mu_{3}-6\mu^{2}\mu_{2}-\mu^{4}}{\mu_{2}^{2}}-3\end{eqnarray*}

This distribution reduces to the log-normal distribution when :math:`c=1.`

Implementation: `scipy.stats.powerlognorm`

.. _discrete-nchypergeom-wallenius:

Wallenius' Noncentral Hypergeometric Distribution
=================================================

A random variable has Wallenius' Noncentral Hypergeometric distribution with
parameters

:math:`M \in {\mathbb N}`,
:math:`n \in [0, M]`,
:math:`N \in [0, M]`,
:math:`\omega > 0`,

if its probability mass function is given by

.. math::

    p(x; N, n, M) = \binom{n}{x} \binom{M - n}{N-x}\int_0^1 \left(1-t^{\omega/D}\right)^x\left(1-t^{1/D}\right)^{N-x} dt

for
:math:`x \in [x_l, x_u]`,
where
:math:`x_l = \max(0, N - (M - n))`,
:math:`x_u = \min(N, n)`,

.. math::

    D = \omega(n - x) + ((M - n)-(N-x)),

and the binomial coefficients are

.. math::

    \binom{n}{k} \equiv \frac{n!}{k! (n - k)!}.

References
----------
-  Agner Fog, "Biased Urn Theory", https://cran.r-project.org/web/packages/BiasedUrn/vignettes/UrnTheory.pdf
-  "Wallenius' noncentral hypergeometric distribution", Wikipedia, https://en.wikipedia.org/wiki/Wallenius'_noncentral_hypergeometric_distribution

Implementation: `scipy.stats.nchypergeom_wallenius`

.. _continuous-gengamma:

Generalized Gamma Distribution
==============================

A general probability form that reduces to many common distributions.
There are two shape parameters :math:`a>0` and :math:`c\neq0`.
The support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a,c\right) & = & \frac{\left|c\right|x^{ca-1}}{\Gamma\left(a\right)}\exp\left(-x^{c}\right)\\
    F\left(x;a,c\right) & = &
      \left\{
        \begin{array}{cc}
          \frac{\gamma\left(a,x^{c}\right)}{\Gamma\left(a\right)} & c>0\\
          1-\frac{\gamma\left(a,x^{c}\right)}{\Gamma\left(a\right)} & c<0
        \end{array}
      \right. \\
    G\left(q;a,c\right) & = &
      \left\{
        \begin{array}{cc}
          \gamma^{-1} \left(a, \Gamma\left(a\right) q \right)^{1/c} &  c>0 \\
          \gamma^{-1} \left(a, \Gamma\left(a\right) \left(1-q\right) \right)^{1/c} & c<0
        \end{array}
      \right. \end{eqnarray*}

where :math:`\gamma` is the lower incomplete gamma function, :math:`\gamma\left(s, x\right) = \int_0^x t^{s-1} e^{-t} dt`.


.. math::
   :nowrap:

    \begin{eqnarray*}  \mu_{n}^{\prime} & = & \frac{\Gamma\left(a+\frac{n}{c}\right)}{\Gamma\left(a\right)}\\
    \mu & = & \frac{\Gamma\left(a+\frac{1}{c}\right)}{\Gamma\left(a\right)}\\
    \mu_{2} & = & \frac{\Gamma\left(a+\frac{2}{c}\right)}{\Gamma\left(a\right)}-\mu^{2}\\
    \gamma_{1} & = & \frac{\Gamma\left(a+\frac{3}{c}\right)/\Gamma\left(a\right)-3\mu\mu_{2}-\mu^{3}}{\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{\Gamma\left(a+\frac{4}{c}\right)/\Gamma\left(a\right)-4\mu\mu_{3}-6\mu^{2}\mu_{2}-\mu^{4}}{\mu_{2}^{2}}-3\\
    m_{d} & = & \left(\frac{ac-1}{c}\right)^{1/c}\end{eqnarray*}

Special cases are Weibull :math:`\left(a=1\right)`, half-normal :math:`\left(a=1/2,c=2\right)` and ordinary gamma distributions :math:`c=1.`
If :math:`c=-1` then it is the inverted gamma distribution.

.. math::

     h\left[X\right]=a-a\Psi\left(a\right)+\frac{1}{c}\Psi\left(a\right)+\log\Gamma\left(a\right)-\log\left|c\right|.

Implementation: `scipy.stats.gengamma`

.. _continuous-t:

Student t Distribution
======================

There is one shape parameter :math:`\nu>0` and the support is :math:`x\in\mathbb{R}`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\nu\right) & = & \frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\pi\nu}\Gamma\left(\frac{\nu}{2}\right)\left[1+\frac{x^{2}}{\nu}\right]^{\frac{\nu+1}{2}}}\\
    F\left(x;\nu\right) & = &
      \left\{
        \begin{array}{ccc}
          \frac{1}{2}I\left(\frac{\nu}{\nu+x^{2}}; \frac{\nu}{2},\frac{1}{2}\right) &  & x\leq0\\
          1-\frac{1}{2}I\left(\frac{\nu}{\nu+x^{2}}; \frac{\nu}{2},\frac{1}{2}\right) &  & x\geq0
        \end{array}
      \right.\\
    G\left(q;\nu\right) & = & \left\{
      \begin{array}{ccc}
        -\sqrt{\frac{\nu}{I^{-1}\left(2q; \frac{\nu}{2},\frac{1}{2}\right)}-\nu} &  & q\leq\frac{1}{2}\\
        \sqrt{\frac{\nu}{I^{-1}\left(2-2q; \frac{\nu}{2},\frac{1}{2}\right)}-\nu} &  & q\geq\frac{1}{2}
      \end{array}
      \right. \end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} m_{n}=m_{d}=\mu & = & 0\\
    \mu_{2} & = & \frac{\nu}{\nu-2}\quad\nu>2\\
    \gamma_{1} & = & 0\quad\nu>3\\
    \gamma_{2} & = & \frac{6}{\nu-4}\quad\nu>4\end{eqnarray*}

where :math:`I\left(x; a,b\right)` is the incomplete beta integral and :math:`I^{-1}\left(I\left(x; a,b\right); a,b\right)=x`.
As :math:`\nu\rightarrow\infty,` this distribution approaches the standard normal distribution.

.. math::

     h\left[X\right]=\frac{\nu+1}{2} \left[\psi \left(\frac{1+\nu}{2} \right) -\psi \left(\frac{\nu}{2} \right) \right] + \ln \left[ \sqrt{\nu} B \left( \frac{\nu}{2}, \frac{1}{2} \right) \right]

where :math:`\psi(x)` is the digamma function and :math:`B(x, y)` is the
beta function.

References
----------

- "Student's t-distribution", Wikipedia, https://en.wikipedia.org/wiki/Student%27s_t-distribution

Implementation: `scipy.stats.t`

.. _continuous-geninvgauss:

Generalized Inverse Gaussian Distribution
=========================================

The probability density function is given by:

.. math::
	:nowrap:
	
	\begin{eqnarray*}
	        f(x; p, b) = x^{p-1} \exp(-b(x + 1/x)/2) / (2 K_p(b)),
	\end{eqnarray*}

where :math:`x > 0` is a real number and the parameters :math:`p, b` satisfy :math:`b > 0`. :math:`K_v` is the modified Bessel function of second kind of order :math:`v` (`scipy.special.kv`).

If `X` is `geninvgauss(p, b)`, then the distribution of `1/X` is `geninvgauss(-p, b)`. The inverse Gaussian distribution (`scipy.stats.invgauss`) is a special case with p=-1/2. 

Implementation: `scipy.stats.geninvgauss`

.. _continuous-truncexpon:

Truncated Exponential Distribution
==================================

This is an exponential distribution defined only over a certain region :math:`0\leq x\leq B` . In standard form this is

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;B\right) & = & \frac{e^{-x}}{1-e^{-B}}\\ F\left(x;B\right) & = & \frac{1-e^{-x}}{1-e^{-B}}\\ G\left(q;B\right) & = & -\log\left(1-q+qe^{-B}\right)\end{eqnarray*}

.. math::

     \mu_{n}^{\prime}=\Gamma\left(1+n\right)-\Gamma\left(1+n,B\right)

.. math::

     h\left[X\right]=\log\left(e^{B}-1\right)+\frac{1+e^{B}\left(B-1\right)}{1-e^{B}}.

Implementation: `scipy.stats.truncexpon`

.. _continuous-rayleigh:

Rayleigh Distribution
=====================

This is a special case of the Chi distribution with :math:`L=0.0` and :math:`\nu=2` (no location parameter is generally used), the mode of the
distribution is :math:`S.`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(r\right) & = & re^{-r^{2}/2}\\
    F\left(r\right) & = & 1-e^{-r^{2}/2}\\
    G\left(q\right) & = & \sqrt{-2\log\left(1-q\right)}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \sqrt{\frac{\pi}{2}}\\
    \mu_{2} & = & \frac{4-\pi}{2}\\
    \gamma_{1} & = & \frac{2\left(\pi-3\right)\sqrt{\pi}}{\left(4-\pi\right)^{3/2}}\\
    \gamma_{2} & = & \frac{24\pi-6\pi^{2}-16}{\left(4-\pi\right)^{2}}\\
    m_{d} & = & 1\\ m_{n} & = & \sqrt{2\log\left(2\right)}\end{eqnarray*}

.. math::

     h\left[X\right]=\frac{\gamma}{2}+\log\left(\frac{e}{\sqrt{2}}\right).

.. math::

     \mu_{n}^{\prime}=\sqrt{2^{n}}\Gamma\left(\frac{n}{2}+1\right)

Implementation: `scipy.stats.rayleigh`

.. _discrete-yulesimon:

Yule-Simon Distribution
========================

A Yule-Simon random variable with parameter :math:`\alpha>0`
can be represented as a mixture of
exponential random variates. To see this write :math:`W` as an exponential
random variate with rate :math:`\rho` and a Geometric random variate :math:`K`
with probability :math:`1-exp(-W)` then :math:`K` marginally has a Yule-Simon
distribution. The latent variable representation described above is used for
random variate generation.

.. math::
   :nowrap:

    \begin{eqnarray*}
    p \left( k; \alpha \right) & = & \alpha \frac{\Gamma\left(k\right)\Gamma\left(\alpha + 1\right)}{\Gamma\left(k+\alpha+1\right)} \\
    F \left( k; \alpha \right) & = &  1 - \frac{ k \Gamma\left(k\right)\Gamma\left(\alpha + 1\right)}{\Gamma\left(k+\alpha+1\right)}
    \end{eqnarray*}

for :math:`k = 1,2,...`.

Now

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{\alpha}{\alpha-1}\\
    \mu_{2} & = &  \frac{\alpha^2}{\left(\alpha-1\right)^2\left( \alpha - 2 \right)}\\
    \gamma_{1} & = & \frac{ \sqrt{\left( \alpha - 2 \right)} \left( \alpha + 1 \right)^2}{ \alpha  \left( \alpha - 3 \right)}\\
    \gamma_{2} & = & \frac{ \left(\alpha + 3\right) + \left(\alpha^3 - 49\alpha - 22\right)}{\alpha \left(\alpha - 4\right)\left(\alpha - 3 \right) }
    \end{eqnarray*}

for :math:`\alpha>1` otherwise the mean is infinite and the variance does not exist.
For the variance, :math:`\alpha>2` otherwise the variance does not exist.
Similarly, for the skewness and
kurtosis to be finite, :math:`\alpha>3` and :math:`\alpha>4` respectively.


Implementation: `scipy.stats.yulesimon`
.. _continuous-skew-cauchy:

Skewed Cauchy Distribution
==========================

This distribution is a generalization of the Cauchy distribution. It
has a single shape parameter :math:`-1 < a < 1` that skews the distribution.
The special case :math:`a=0` yields the Cauchy distribution.

Functions
---------

.. math::
   :nowrap:

    \begin{eqnarray*}
    f(x, a) & = & \frac{1}{\pi \left(\frac{x^2}{\left(a x + 1 \right)^2} + 1 \right)},\quad x\ge0; \\
                 & = & \frac{1}{\pi \left(\frac{x^2}{\left(-a x + 1 \right)^2} + 1 \right)},\quad x<0. \\
    F(x, a) & = & \frac{1 - a}{2} + \frac{1 + a}{\pi} \arctan\left(\frac{x}{1 + a} \right),\quad x\ge0; \\
                 & = & \frac{1 - a}{2} + \frac{1 - a}{\pi} \arctan\left(\frac{x}{1 - a} \right),\quad x<0.
    \end{eqnarray*}

The mean, variance, skewness, and kurtosis are all undefined.

References
----------

-  "Skewed generalized *t* distribution", Wikipedia
   https://en.wikipedia.org/wiki/Skewed_generalized_t_distribution#Skewed_Cauchy_distribution

Implementation: `scipy.stats.skewcauchy`

.. _continuous-bradford:

Bradford Distribution
=====================

There is one shape parameter, :math:`c>0`, and the support is :math:`x\in [0,1]`.

.. math::
   :nowrap:

    \begin{eqnarray*} \textrm{Let } k & = & \log\left(1+c\right)\\
    \textrm{Then}\\
    f\left(x;c\right) & = & \frac{c}{k\left(1+cx\right)}\\
    F\left(x;c\right) & = & \frac{\log\left(1+cx\right)}{k}\\
    G\left(q\; c\right) & = & \frac{\left(1+c\right)^{q}-1}{c}\\
    M\left(t\right) & = & \frac{1}{k}e^{-t/c}\left[\mathrm{Ei}\left(t+\frac{t}{c}\right)-\mathrm{Ei}\left(\frac{t}{c}\right)\right]\\
    \mu & = & \frac{c-k}{ck}\\
    \mu_{2} & = & \frac{\left(c+2\right)k-2c}{2ck^{2}}\\
    \gamma_{1} & = & \frac{\sqrt{2}\left(12c^{2}-9kc\left(c+2\right)+2k^{2}\left(c\left(c+3\right)+3\right)\right)}{\sqrt{c\left(c\left(k-2\right)+2k\right)}\left(3c\left(k-2\right)+6k\right)}\\
    \gamma_{2} & = & \frac{c^{3}\left(k-3\right)\left(k\left(3k-16\right)+24\right)+12kc^{2}\left(k-4\right)\left(k-3\right)+6ck^{2}\left(3k-14\right)+12k^{3}}{3c\left(c\left(k-2\right)+2k\right)^{2}}\\
    m_{d} & = & 0\\
    m_{n} & = & \sqrt{1+c}-1\\
    h\left[X\right]& = & \frac{1}{2}\log\left(1+c\right)-\log\left(\frac{c}{\log\left(1+c\right)}\right)\end{eqnarray*}

where :math:`\mathrm{Ei}\left(\mathrm{z}\right)` is the exponential integral function.

Implementation: `scipy.stats.bradford`

.. _continuous-foldcauchy:

Folded Cauchy Distribution
==========================

This formula can be expressed in terms of the standard formulas for
the Cauchy distribution (call the cdf :math:`C\left(x\right)` and
the pdf :math:`d\left(x\right)` ).
If :math:`Y` is cauchy then :math:`\left|Y\right|` is folded cauchy.
There is one shape parameter :math:`c` and the support is :math:`x\geq0.`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{1}{\pi\left(1+\left(x-c\right)^{2}\right)}+\frac{1}{\pi\left(1+\left(x+c\right)^{2}\right)}\\
    F\left(x;c\right) & = & \frac{1}{\pi}\tan^{-1}\left(x-c\right)+\frac{1}{\pi}\tan^{-1}\left(x+c\right)\\
    G\left(q;c\right) & = & F^{-1}\left(q;c\right)\end{eqnarray*}

No moments

Implementation: `scipy.stats.foldcauchy`

.. _continuous-nakagami:

Nakagami Distribution
=====================

Generalization of the chi distribution. Shape parameter is :math:`\nu>0.` The support is :math:`x\geq0.`

.. math::
   :nowrap:

    \begin{eqnarray*}
    f\left(x;\nu\right) & = & \frac{2\nu^{\nu}}{\Gamma\left(\nu\right)}x^{2\nu-1}\exp\left(-\nu x^{2}\right)\\
    F\left(x;\nu\right) & = & \frac{\gamma\left(\nu,\nu x^{2}\right)}{\Gamma\left(\nu\right)}\\
    G\left(q;\nu\right) & = & \sqrt{\frac{1}{\nu}\gamma^{-1}\left(\nu,q{\Gamma\left(\nu\right)}\right)}
    \end{eqnarray*}

where :math:`\gamma` is the lower incomplete gamma function, :math:`\gamma\left(\nu, x\right) = \int_0^x t^{\nu-1} e^{-t} dt`.

.. math::
   :nowrap:

    \begin{eqnarray*}
    \mu & = & \frac{\Gamma\left(\nu+\frac{1}{2}\right)}{\sqrt{\nu}\Gamma\left(\nu\right)}\\
    \mu_{2} & = & \left[1-\mu^{2}\right]\\
    \gamma_{1} & = & \frac{\mu\left(1-4v\mu_{2}\right)}{2\nu\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{-6\mu^{4}\nu+\left(8\nu-2\right)\mu^{2}-2\nu+1}{\nu\mu_{2}^{2}}
    \end{eqnarray*}

Implementation: `scipy.stats.nakagami`


MLE of the Nakagami Distribution in SciPy (:code:`nakagami.fit`)
----------------------------------------------------------------

The probability density function of the :code:`nakagami` distribution in SciPy is

.. math::
   :nowrap:

    \begin{equation}
    f(x; \nu, \mu, \sigma) = 2 \frac{\nu^\nu}{ \sigma \Gamma(\nu)}\left(\frac{x-\mu}{\sigma}\right)^{2\nu - 1} \exp\left(-\nu \left(\frac{x-\mu}{\sigma}\right)^2 \right),\tag{1}
    \end{equation}

for :math:`x` such that :math:`\frac{x-\mu}{\sigma} \geq 0`, where :math:`\nu \geq \frac{1}{2}` is the shape parameter,
:math:`\mu` is the location, and :math:`\sigma` is the scale.

The log-likelihood function is therefore

.. math::
   :nowrap:

    \begin{equation}
    l(\nu, \mu, \sigma) = \sum_{i = 1}^{N} \log \left( 2 \frac{\nu^\nu}{ \sigma\Gamma(\nu)}\left(\frac{x_i-\mu}{\sigma}\right)^{2\nu - 1} \exp\left(-\nu \left(\frac{x_i-\mu}{\sigma}\right)^2 \right) \right),\tag{2}
    \end{equation}

which can be expanded as

.. math::
   :nowrap:

    \begin{equation}
    l(\nu, \mu, \sigma) = N \log(2) + N\nu \log(\nu) - N\log\left(\Gamma(\nu)\right) - 2N \nu \log(\sigma) + \left(2 \nu - 1 \right) \sum_{i=1}^N  \log(x_i - \mu) - \nu \sigma^{-2} \sum_{i=1}^N \left(x_i-\mu\right)^2, \tag{3}
    \end{equation}

Leaving supports constraints out, the first-order condition for optimality on the likelihood derivatives gives estimates of parameters:

.. math::
   :nowrap:

    \begin{align}
    \frac{\partial l}{\partial \nu}(\nu, \mu, \sigma) &= N\left(1 + \log(\nu) - \psi^{(0)}(\nu)\right) + 2 \sum_{i=1}^N \log \left( \frac{x_i - \mu}{\sigma} \right) - \sum_{i=1}^N \left( \frac{x_i - \mu}{\sigma} \right)^2  = 0
    \text{,} \tag{4}\\
    \frac{\partial l}{\partial \mu}(\nu, \mu, \sigma) &= (1 - 2 \nu) \sum_{i=1}^N \frac{1}{x_i-\mu} + \frac{2\nu}{\sigma^2} \sum_{i=1}^N x_i-\mu = 0
    \text{, and} \tag{5}\\
    \frac{\partial l}{\partial \sigma}(\nu, \mu, \sigma) &= -2 N \nu \frac{1}{\sigma} + 2 \nu \sigma^{-3} \sum_{i=1}^N \left(x_i-\mu\right)^2 = 0
    \text{,}\tag{6}
    \end{align}

where :math:`\psi^{(0)}` is the polygamma function of order :math:`0`; i.e. :math:`\psi^{(0)}(\nu) = \frac{d}{d\nu} \log \Gamma(\nu)`.

However, the support of the distribution is the values of :math:`x` for which :math:`\frac{x-\mu}{\sigma} \geq 0`, and this provides an additional constraint that

.. math::
   :nowrap:

    \begin{equation}
    \mu \leq \min_i{x_i}.\tag{7}
    \end{equation}

For :math:`\nu = \frac{1}{2}`, the partial derivative of the log-likelihood with respect to :math:`\mu` reduces to:

.. math::
   :nowrap:

    \begin{equation}
    \frac{\partial l}{\partial \mu}(\nu, \mu, \sigma) = {\sigma^2} \sum_{i=1}^N (x_i-\mu),
    \end{equation}

which is positive when the support constraint is satisfied. Because the partial derivative with respect to :math:`\mu`
is positive, increasing :math:`\mu` increases the log-likelihood, and therefore the constraint is active at the maximum likelihood estimate for :math:`\mu`

.. math::
   :nowrap:

    \begin{equation}
    \mu = \min_i{x_i}, \quad \nu = \frac{1}{2}. \tag{8}
    \end{equation}

For :math:`\nu` sufficiently greater than :math:`\frac{1}{2}`, the likelihood equation :math:`\frac{\partial l}{\partial \mu}(\nu, \mu, \sigma)=0` has a solution, and this solution provides the maximum likelihood estimate for :math:`\mu`. In either case, however, the condition :math:`\mu = \min_i{x_i}` provides a reasonable initial guess for numerical optimization.

Furthermore, the likelihood equation for :math:`\sigma` can be solved explicitly, and it provides the maximum likelihood estimate

.. math::
   :nowrap:

    \begin{equation}
    \sigma = \sqrt{ \frac{\sum_{i=1}^N \left(x_i-\mu\right)^2}{N}}. \tag{9}
    \end{equation}

Hence, the :code:`_fitstart` method for :code:`nakagami` uses

.. math::
   :nowrap:

    \begin{align}
    \mu_0 &= \min_i{x_i} \,
    \text{and} \\
    \sigma_0 &= \sqrt{ \frac{\sum_{i=1}^N \left(x_i-\mu_0\right)^2}{N}}
    \end{align}

as initial guesses for numerical optimization accordingly.
.. _continuous-exponweib:

Exponentiated Weibull Distribution
==================================

Two positive shape parameters :math:`a,c>0`, and the support is :math:`x\in\left[0,\infty\right)`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a,c\right) & = & ac\left[1-\exp\left(-x^{c}\right)\right]^{a-1}\exp\left(-x^{c}\right)x^{c-1}\\ F\left(x;a,c\right) & = & \left[1-\exp\left(-x^{c}\right)\right]^{a}\\ G\left(q;a,c\right) & = & \left[-\log\left(1-q^{1/a}\right)\right]^{1/c}\end{eqnarray*}

Implementation: `scipy.stats.exponweib`

.. _discrete-zipf:

Zipf (Zeta) Distribution
========================

A random variable has the zeta distribution (also called the zipf
distribution) with parameter :math:`\alpha>1` if it's probability mass function is given by

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;\alpha\right) & = & \frac{1}{\zeta\left(\alpha\right)k^{\alpha}}\quad k\geq1\end{eqnarray*}

where

.. math::

    \zeta\left(\alpha\right)=\sum_{n=1}^{\infty}\frac{1}{n^{\alpha}}

is the Riemann zeta function. Other functions of this distribution are

.. math::
   :nowrap:

    \begin{eqnarray*} F\left(x;\alpha\right) & = & \frac{1}{\zeta\left(\alpha\right)}\sum_{k=1}^{\left\lfloor x\right\rfloor }\frac{1}{k^{\alpha}}\\ \mu & = & \frac{\zeta_{1}}{\zeta_{0}}\quad\alpha>2\\ \mu_{2} & = & \frac{\zeta_{2}\zeta_{0}-\zeta_{1}^{2}}{\zeta_{0}^{2}}\quad\alpha>3\\ \gamma_{1} & = & \frac{\zeta_{3}\zeta_{0}^{2}-3\zeta_{0}\zeta_{1}\zeta_{2}+2\zeta_{1}^{3}}{\left[\zeta_{2}\zeta_{0}-\zeta_{1}^{2}\right]^{3/2}}\quad\alpha>4\\ \gamma_{2} & = & \frac{\zeta_{4}\zeta_{0}^{3}-4\zeta_{3}\zeta_{1}\zeta_{0}^{2}+12\zeta_{2}\zeta_{1}^{2}\zeta_{0}-6\zeta_{1}^{4}-3\zeta_{2}^{2}\zeta_{0}^{2}}{\left(\zeta_{2}\zeta_{0}-\zeta_{1}^{2}\right)^{2}}.\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} M\left(t\right) & = & \frac{\textrm{Li}_{\alpha}\left(e^{t}\right)}{\zeta\left(\alpha\right)}\end{eqnarray*}

where :math:`\zeta_{i}=\zeta\left(\alpha-i\right)` and :math:`\textrm{Li}_{n}\left(z\right)` is the :math:`n^{\textrm{th}}` polylogarithm function of :math:`z` defined as

.. math::

    \textrm{Li}_{n}\left(z\right)\equiv\sum_{k=1}^{\infty}\frac{z^{k}}{k^{n}}

.. math::

    \mu_{n}^{\prime}=\left.M^{\left(n\right)}\left(t\right)\right|_{t=0}=\left.\frac{\textrm{Li}_{\alpha-n}\left(e^{t}\right)}{\zeta\left(a\right)}\right|_{t=0}=\frac{\zeta\left(\alpha-n\right)}{\zeta\left(\alpha\right)}

Implementation: `scipy.stats.zipf`
.. _sampling-srou:

Simple Ratio-of-Uniforms (SROU)
===============================

.. currentmodule:: scipy.stats.sampling

* Required: PDF, area under PDF if different than 1
* Optional: mode, CDF at mode
* Speed:

  * Set-up: fast
  * Sampling: slow

SROU is based on the ratio-of-uniforms method that uses universal inequalities for constructing
a (universal) bounding rectangle. It works for T-concave distributions with T(x) = -1/sqrt(x).

    >>> from scipy.stats.sampling import SimpleRatioUniforms

Suppose we have the normal distribution:

    >>> class StdNorm:
    ...     def pdf(self, x):
    ...         return np.exp(-0.5 * x**2)

Notice that the PDF doesn't integrate to 1. We can either pass the exact
area under the PDF during initialization of the generator or an upper
bound to the exact area under the PDF. Also, it is recommended to pass
the mode of the distribution to speed up the setup:

    >>> urng = np.random.default_rng()
    >>> dist = StdNorm()
    >>> rng = SimpleRatioUniforms(dist, mode=0,
    ...                           pdf_area=np.sqrt(2*np.pi),
    ...                           random_state=urng)

Now, we can use the `rvs` method to generate samples from the distribution:

    >>> rvs = rng.rvs(10)

If the CDF at mode is avaialble, it can be set to improve the performace of `rvs`:

    >>> from scipy.stats import norm
    >>> rng = SimpleRatioUniforms(dist, mode=0,
    ...                           pdf_area=np.sqrt(2*np.pi),
    ...                           cdf_at_mode=norm.cdf(0),
    ...                           random_state=urng)
    >>> rvs = rng.rvs(1000)

We can check that the samples are from the given distribution by visualizing
its histogram:

.. plot::

    >>> from scipy.stats.sampling import SimpleRatioUniforms
    >>> from scipy.stats import norm
    >>> import matplotlib.pyplot as plt
    >>> class StdNorm:
    ...     def pdf(self, x):
    ...         return np.exp(-0.5 * x**2)
    ... 
    >>> urng = np.random.default_rng()
    >>> dist = StdNorm()
    >>> rng = SimpleRatioUniforms(dist, mode=0,
    ...                           pdf_area=np.sqrt(2*np.pi),
    ...                           cdf_at_mode=norm.cdf(0),
    ...                           random_state=urng)
    >>> rvs = rng.rvs(1000)
    >>> x = np.linspace(rvs.min()-0.1, rvs.max()+0.1, 1000)
    >>> fx = 1/np.sqrt(2*np.pi) * dist.pdf(x)
    >>> fig, ax = plt.subplots()
    >>> ax.plot(x, fx, 'r-', lw=2, label='true distribution')
    >>> ax.hist(rvs, bins=10, density=True, alpha=0.8, label='random variates')
    >>> ax.set_xlabel('x')
    >>> ax.set_ylabel('PDF(x)')
    >>> ax.set_title('Simple Ratio-of-Uniforms Samples')
    >>> ax.legend()
    >>> plt.show()

The main advantage of the method is a fast setup. This can be beneficial if one
repeatedly needs to generate small to moderate samples of a distribution with
different shape parameters. In such a situation, the setup step of
`sampling.NumericalInverseHermite` or `sampling.NumericalInversePolynomial` will
lead to poor performance. As an example, assume we are interested to generate
100 samples for the Gamma distribution with 1000 different shape parameters
given by `np.arange(1.5, 5, 1000)`.

    >>> import math
    >>> class GammaDist:
    ...     def __init__(self, p):
    ...         self.p = p
    ...     def pdf(self, x):
    ...         return x**(self.p-1) * np.exp(-x)
    ...
    >>> urng = np.random.default_rng()
    >>> p = np.arange(1.5, 5, 1000)
    >>> res = np.empty((1000, 100))
    >>> for i in range(1000):
    ...     dist = GammaDist(p[i])
    ...     rng = SimpleRatioUniforms(dist, mode=p[i]-1,
    ...                               pdf_area=math.gamma(p[i]),
    ...                               random_state=urng)
    ...     with np.suppress_warnings() as sup:
    ...         sup.filter(RuntimeWarning, "invalid value encountered in double_scalars")
    ...         sup.filter(RuntimeWarning, "overflow encountered in exp")
    ...         res[i] = rng.rvs(100)

See [1]_, [2]_, and [3]_ for more details.

References
----------
.. [1] UNU.RAN reference manual, Section 5.3.16,
       "SROU - Simple Ratio-of-Uniforms method",
       http://statmath.wu.ac.at/software/unuran/doc/unuran.html#SROU
.. [2] Leydold, Josef. "A simple universal generator for continuous and
       discrete univariate T-concave distributions." ACM Transactions on
       Mathematical Software (TOMS) 27.1 (2001): 66-82
.. [3] Leydold, Josef. "Short universal generators via generalized ratio-of-uniforms
       method." Mathematics of Computation 72.243 (2003): 1453-1471

.. _continuous-vonmises:

Von Mises Distribution
======================

There is one shape parameter :math:`\kappa>0`, with support :math:`x\in\left[-\pi,\pi\right]`.
For values of :math:`\kappa<100` the PDF and CDF formulas below are used. Otherwise, a normal
approximation with variance :math:`1/\kappa` is used.
[Note that the PDF and CDF functions below are periodic with period :math:`2\pi`.
If an input outside :math:`x\in\left[-\pi,\pi\right]` is given, it is converted
to the equivalent angle in this range.]


.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\kappa\right) & = & \frac{e^{\kappa\cos x}}{2\pi I_{0}\left(\kappa\right)}\\
    F\left(x;\kappa\right) & = & \frac{1}{2} + \frac{x}{2\pi} + \sum_{k=1}^{\infty}\frac{I_{k}\left(\kappa\right)\sin\left(kx\right)}{I_{0}\left(\kappa\right)\pi k}\\
    G\left(q; \kappa\right) & = & F^{-1}\left(x;\kappa\right)\end{eqnarray*}


where  :math:`I_{k}(\kappa)` is a modified Bessel function of the first kind.

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & 0\\
    \mu_{2} & = & \int_{-\pi}^{\pi}x^{2}f\left(x;\kappa\right)dx\\
    \gamma_{1} & = & 0\\
    \gamma_{2} & = & \frac{\int_{-\pi}^{\pi}x^{4}f\left(x;\kappa\right)dx}{\mu_{2}^{2}}-3\end{eqnarray*}

This can be used for defining circular variance.

Implementation: `scipy.stats.vonmises`

.. _continuous-weibull_min:

Weibull Minimum Extreme Value Distribution
==========================================

A type of extreme-value distribution with a lower bound. Defined for :math:`x>0` and :math:`c>0`

.. math::
   :nowrap:

    \begin{eqnarray*}
        f\left(x;c\right) & = & cx^{c-1}\exp\left(-x^{c}\right) \\
        F\left(x;c\right) & = & 1 - \exp\left(-x^{c}\right) \\
        G\left(q;c\right) & = & \left[-\log\left(1-q\right)\right]^{1/c}
    \end{eqnarray*}

.. math::

     \mu_{n}^{\prime}=\Gamma\left(1+\frac{n}{c}\right)

.. math::
   :nowrap:

    \begin{eqnarray*}
        \mu & = & \Gamma\left(1+\frac{1}{c}\right) \\
        \mu_{2} & = & \Gamma\left(1+\frac{2}{c}\right) -
                      \Gamma^{2}\left(1+\frac{1}{c}\right) \\
        \gamma_{1} & = & \frac{\Gamma\left(1+\frac{3}{c}\right) -
                               3\Gamma\left(1+\frac{2}{c}\right)\Gamma\left(1+\frac{1}{c}\right) +
                               2\Gamma^{3}\left(1+\frac{1}{c}\right)}
                              {\mu_{2}^{3/2}} \\
        \gamma_{2} & = & \frac{\Gamma\left(1+\frac{4}{c}\right) -
                               4\Gamma\left(1+\frac{1}{c}\right)\Gamma\left(1+\frac{3}{c}\right) +
                               6\Gamma^{2}\left(1+\frac{1}{c}\right)\Gamma\left(1+\frac{2}{c}\right) -
                               3\Gamma^{4}\left(1+\frac{1}{c}\right)}
                              {\mu_{2}^{2}} - 3 \\
        m_{d} & = & \begin{cases}
                        \left(\frac{c-1}{c}\right)^{\frac{1}{c}} & \text{if}\; c > 1 \\
                        0 & \text{if}\; c <= 1
                    \end{cases} \\
        m_{n} & = & \ln\left(2\right)^{\frac{1}{c}}
    \end{eqnarray*}

.. math::

     h\left[X\right]=-\frac{\gamma}{c}-\log\left(c\right)+\gamma+1

where :math:`\gamma` is Euler's constant and equal to

.. math::

     \gamma\approx0.57721566490153286061.

Implementation: `scipy.stats.weibull_min`
.. _continuous-laplace-asymmetric:

Asymmetric Laplace Distribution
================================================================

This distribution is a generalization of the Laplace distribution. It
has a single shape parameter :math:`\kappa>0` that species the
distribution's asymmetry. The special case :math:`\kappa=1` yields the
Laplace distribution.

Functions
---------

.. math::
   :nowrap:

    \begin{eqnarray*}
    F(x, \kappa) & = & 1-\frac{\kappa^{-1}}{\kappa+\kappa^{-1}}\exp(-x\kappa),\quad x\ge0; \\
                 & = & \frac{\kappa}{\kappa+\kappa^{-1}}\exp(x/\kappa),\quad x<0. \\
    f(x, \kappa) & = & \frac{1}{\kappa+\kappa^{-1}}\exp(-x\kappa),\quad x\ge0; \\
                 & = & \frac{1}{\kappa+\kappa^{-1}}\exp(x/\kappa),\quad x<0.
    \end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*}
    \mu & = & \kappa^{-1}-\kappa\\
    \mu_2 & = & \kappa^{-2}+\kappa^2\\
    \gamma_1 & = & \frac{2(1-\kappa^6)}{(1+\kappa^4)^{3/2}}\\
    \gamma_2 & = & \frac{6(1+\kappa^8)}{(1+\kappa^4)^2}
    \end{eqnarray*}


References
----------

-  "Asymmetric Laplace distribution", Wikipedia
   https://en.wikipedia.org/wiki/Asymmetric_Laplace_distribution

-  Kozubowski TJ and Podgórski K, "A Multivariate and Asymmetric
   Generalization of Laplace Distribution," *Computational Statistics*
   15, 531--540 (2000). :doi:`10.1007/PL00022717`


Implementation: `scipy.stats.laplace_asymmetric`

.. _continuous-erlang:

Erlang Distribution
===================

This is just the Gamma distribution with shape parameter :math:`\alpha=n` an integer.

Implementation: `scipy.stats.erlang`

.. _continuous-maxwell:

Maxwell Distribution
====================

This is a special case of the Chi distribution with :math:`L=0` and :math:`S=\frac{1}{\sqrt{a}}` and :math:`\nu=3.`
The support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \sqrt{\frac{2}{\pi}}x^{2}e^{-x^{2}/2}\\
    F\left(x\right) & = & \frac{\gamma\left(\frac{3}{2},\frac{x^2}{2}\right)}{\Gamma(\frac{3}{2})}\\
    G\left(q\right) & = & \sqrt{2\gamma^{-1}\left(\frac{3}{2},q\Gamma(\frac{3}{2})\right)}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & 2\sqrt{\frac{2}{\pi}}\\
    \mu_{2} & = & 3-\frac{8}{\pi}\\
    \gamma_{1} & = & \sqrt{2}\frac{32-10\pi}{\left(3\pi-8\right)^{3/2}}\\
    \gamma_{2} & = & \frac{-12\pi^{2}+160\pi-384}{\left(3\pi-8\right)^{2}}\\
    m_{d} & = & \sqrt{2}\\
    m_{n} & = & \sqrt{2\gamma^{-1}\left(\frac{3}{2},\frac{1}{2}\Gamma(\frac{3}{2})\right)}\end{eqnarray*}

.. math::

     h\left[X\right]=\log\left(\sqrt{\frac{2\pi}{e}}\right)+\gamma.

Implementation: `scipy.stats.maxwell`

.. _continuous-uniform:

Uniform Distribution
====================

Standard form :math:`x\in\left[0,1\right].` In general form, the lower limit is :math:`L,` the upper limit is :math:`S+L.`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & 1\\ F\left(x\right) & = & x\\ G\left(q\right) & = & q\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \frac{1}{2}\\ \mu_{2} & = & \frac{1}{12}\\ \gamma_{1} & = & 0\\ \gamma_{2} & = & -\frac{6}{5}\end{eqnarray*}

.. math::

     h\left[X\right]=0

Implementation: `scipy.stats.uniform`

.. _continuous-dgamma:

Double Gamma Distribution
=========================

The double gamma is the signed version of the Gamma distribution. For :math:`\alpha>0:`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\alpha\right) & = & \frac{1}{2\Gamma\left(\alpha\right)}\left|x\right|^{\alpha-1}e^{-\left|x\right|}\\
    F\left(x;\alpha\right) & = & \left\{
      \begin{array}{ccc}
        \frac{1}{2}-\frac{\gamma\left(\alpha,\left|x\right|\right)}{2\Gamma\left(\alpha\right)} &  & x\leq0\\
        \frac{1}{2}+\frac{\gamma\left(\alpha,\left|x\right|\right)}{2\Gamma\left(\alpha\right)} &  & x>0
      \end{array}
    \right.\\
    G\left(q;\alpha\right) & = & \left\{
      \begin{array}{ccc}
        -\gamma^{-1}\left(\alpha,\left|2q-1\right|\Gamma\left(\alpha\right)\right) &  & q\leq\frac{1}{2}\\
        \gamma^{-1}\left(\alpha,\left|2q-1\right|\Gamma\left(\alpha\right)\right) &  & q>\frac{1}{2}
      \end{array}
    \right.\end{eqnarray*}

.. math::

     M\left(t\right)=\frac{1}{2\left(1-t\right)^{a}}+\frac{1}{2\left(1+t\right)^{a}}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu=m_{n} & = & 0\\
    \mu_{2} & = & \alpha\left(\alpha+1\right)\\
    \gamma_{1} & = & 0\\
    \gamma_{2} & = & \frac{\left(\alpha+2\right)\left(\alpha+3\right)}{\alpha\left(\alpha+1\right)}-3\\
    m_{d} & = & \mathrm{NA}\end{eqnarray*}

Implementation: `scipy.stats.dgamma`

.. _discrete-geom:

Geometric Distribution
======================

The geometric random variable with parameter :math:`p\in\left(0,1\right)` can be defined as the number of trials required to obtain a success
where the probability of success on each trial is :math:`p` . Thus,

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;p\right) & = & \left(1-p\right)^{k-1}p\quad k\geq1\\ F\left(x;p\right) & = & 1-\left(1-p\right)^{\left\lfloor x\right\rfloor }\quad x\geq1\\ G\left(q;p\right) & = & \left\lceil \frac{\log\left(1-q\right)}{\log\left(1-p\right)}\right\rceil \\ \mu & = & \frac{1}{p}\\ \mu_{2} & = & \frac{1-p}{p^{2}}\\ \gamma_{1} & = & \frac{2-p}{\sqrt{1-p}}\\ \gamma_{2} & = & \frac{p^{2}-6p+6}{1-p}.\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} M\left(t\right) & = & \frac{p}{e^{-t}-\left(1-p\right)}\end{eqnarray*}

Implementation: `scipy.stats.geom`

.. _continuous-rdist:

R-distribution Distribution
===========================

A general-purpose distribution with a variety of shapes controlled by one shape parameter :math:`c>0.`
The support of the standard distribution is :math:`x\in\left[-1,1\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{\left(1-x^{2}\right)^{c/2-1}}{B\left(\frac{1}{2},\frac{c}{2}\right)}\\ F\left(x;c\right) & = & \frac{1}{2}+\frac{x}{B\left(\frac{1}{2},\frac{c}{2}\right)}\,_{2}F_{1}\left(\frac{1}{2},1-\frac{c}{2};\frac{3}{2};x^{2}\right)\end{eqnarray*}

.. math::

     \mu_{n}^{\prime}=\frac{\left(1+\left(-1\right)^{n}\right)}{2}B\left(\frac{n+1}{2},\frac{c}{2}\right)

The R-distribution with parameter :math:`n` is the distribution of the
correlation coefficient of a random sample of size :math:`n` drawn from a
bivariate normal distribution with :math:`\rho=0.` The mean of the standard
distribution is always zero and as the sample size grows, the distribution's
mass concentrates more closely about this mean.

Implementation: `scipy.stats.rdist`

.. _continuous-genhyperbolic:

Generalized Hyperbolic Distribution
===================================

The Generalized Hyperbolic Distribution is defined as the normal variance-mean mixture with Generalized Inverse Gaussian distribution as the mixing distribution.
The "hyperbolic" characterization refers to the fact that the shape of the log-probability distribution can be described as a hyperbola. Hyperbolic distributions are sometime referred to as semi-fat tailed because their probability density decrease slower than "sub-hyperbolic" distributions (e.g. normal distribution, whose log-probability decreases quadratically), but faster than other "extreme value" distributions (e.g. `pareto` distribution, whose log-probability decreases logarithmically).

Functions
---------

Different parameterizations exist in the literature; SciPy implements the "4th parametrization" in Prause (1999).

.. math::
   :nowrap:

    \begin{eqnarray*}
        f(x, p, a, b) & = &
        \frac{(a^2 - b^2)^{p/2}}
        {\sqrt{2\pi}a^{p-0.5}
        K_p\Big(\sqrt{a^2 - b^2}\Big)}
        e^{bx} \times \frac{K_{p - 1/2}
        (a \sqrt{1 + x^2})}
        {(\sqrt{1 + x^2})^{1/2 - p}}
    \end{eqnarray*}

for:

-  :math:`x, p \in ( - \infty; \infty)`
-  :math:`|b| < a` if :math:`p \ge 0`
-  :math:`|b| \le a` if :math:`p < 0`
-  :math:`K_{p}(.)` denotes the modified Bessel function of the second kind and order :math:`p` (`scipy.special.kn`)

The probability density above is defined in the "standardized" form. To shift and/or scale the distribution use the :math:`\text{loc}` and :math:`\text{scale}` parameters. Specifically, :math:`f(x, p, a, b, \text{loc}, \text{scale})` is identically equivalent to :math:`\frac{1}{\text{scale}}f(y, p, a, b)` with :math:`y = \frac{1}{\text{scale}}(x - \text{loc})`.

This parameterization derives from the original :math:`(\lambda, \alpha, \beta, \delta, \mu)` parameterization in  Barndorff (1978) by setting:

-  :math:`\lambda = p`
-  :math:`\alpha = \frac{a}{\delta} = \frac{\hat{\alpha}}{\delta}`
-  :math:`\beta = \frac{b}{\delta} = \frac{\hat{\beta}}{\delta}`
-  :math:`\delta = \text{scale}`
-  :math:`\mu = \text{location}`


Random variates for the `scipy.stats.genhyperbolic` can be efficiently sampled from the above-mentioned normal variance-mean mixture where `scipy.stats.geninvgauss` is parametrized as :math:`GIG\Big(p = p, b = \sqrt{\hat{\alpha}^2 - \hat{\beta}^2}, \text{loc} = \text{location}, \text{scale} = \frac{1}{\sqrt{\hat{\alpha}^2 - \hat{\beta}^2}}\Big)` so that: :math:`GH(p, \hat{\alpha}, \hat{\beta}) = \hat{\beta} \cdot GIG + \sqrt{GIG} \cdot N(0,1)`


The "generalized" characterization suggests the fact that this distribution is a superclass of several other probability distribution, for instance:

-  :math:`f(p = -\nu/2,  a = 0, b = 0, \text{loc} = 0, \text{scale} = \sqrt{\nu})` has a Student's t-distribution (`scipy.stats.t`) with :math:`\nu` degrees of freedom.
-  :math:`f(p = 1, a = \hat{\alpha}, b = \hat{\beta}, \text{loc} = \mu, \text{scale} = \delta)` has a Hyperbolic Distribution.
-  :math:`f(p = - 1/2, a = \hat{\alpha}, b = \hat{\beta}, \text{loc} = \mu, \text{scale} = \delta)` has a Normal Inverse Gaussian Distribution (`scipy.stats.norminvgauss`).
-  :math:`f(p = 1, a = \delta, b = 0, loc = \mu, \text{scale} = \delta)` has a Laplace Distribution (`scipy.stats.laplace`) for :math:`\delta \rightarrow 0`


Examples
--------

It is useful to understand how the parameters affect the shape of the distribution. While it is fairly straightforward to interpret the meaning of :math:`b` as the skewness, understanding the difference between :math:`a` and :math:`p` is not as obvious, as both affect the kurtosis of the distribution. :math:`a` can be interpreted as the speed of the decay of the probability density (where :math:`a > 1` the asymptotic decay is faster than :math:`log_e` and vice versa) or - equivalently - as the slope of the log-probability hyperbola asymptote (where :math:`a > 1` decay is faster than :math:`|1|` and vice versa). :math:`p` can be seen as the width of the shoulders of the probability density distribution (where :math:`p < 1` results in narrow shoulders and vice versa) or - equivalently - as the shape of the log-probability hyperbola, which is convex for :math:`p < 1` and concave otherwise.

.. code-block:: python

    import numpy as np
    from matplotlib import pyplot as plt
    from scipy import stats
    
    p, a, b, loc, scale = 1, 1, 0, 0, 1
    x = np.linspace(-10, 10, 100)
    
    # plot GH for different values of p
    plt.figure(0)
    plt.title("Generalized Hyperbolic | -10 < p < 10")
    plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            label = 'GH(p=1, a=1, b=0, loc=0, scale=1)')
    plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            color = 'red', alpha = 0.5, label='GH(p>1, a=1, b=0, loc=0, scale=1)')
    [plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            color = 'red', alpha = 0.1) for p in np.linspace(1, 10, 10)]
    plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            color = 'blue', alpha = 0.5, label='GH(p<1, a=1, b=0, loc=0, scale=1)')
    [plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            color = 'blue', alpha = 0.1) for p in np.linspace(-10, 1, 10)]
    plt.plot(x, stats.norm.pdf(x, loc, scale), label = 'N(loc=0, scale=1)')
    plt.plot(x, stats.laplace.pdf(x, loc, scale), label = 'Laplace(loc=0, scale=1)')
    plt.plot(x, stats.pareto.pdf(x+1, 1, loc, scale), label = 'Pareto(a=1, loc=0, scale=1)')
    plt.ylim(1e-15, 1e2)
    plt.yscale('log')
    plt.legend(bbox_to_anchor=(1.1, 1))
    plt.subplots_adjust(right=0.5)
    
    # plot GH for different values of a
    plt.figure(1)
    plt.title("Generalized Hyperbolic | 0 < a < 10")
    plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            label = 'GH(p=1, a=1, b=0, loc=0, scale=1)')
    plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            color = 'blue', alpha = 0.5, label='GH(p=1, a>1, b=0, loc=0, scale=1)')
    [plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            color = 'blue', alpha = 0.1) for a in np.linspace(1, 10, 10)]
    plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            color = 'red', alpha = 0.5, label='GH(p=1, 0<a<1, b=0, loc=0, scale=1)')
    [plt.plot(x, stats.genhyperbolic.pdf(x, p, a, b, loc, scale),
            color = 'red', alpha = 0.1) for a in np.linspace(0, 1, 10)]
    plt.plot(x, stats.norm.pdf(x, loc, scale),  label = 'N(loc=0, scale=1)')
    plt.plot(x, stats.laplace.pdf(x, loc, scale), label = 'Laplace(loc=0, scale=1)')
    plt.plot(x, stats.pareto.pdf(x+1, 1, loc, scale), label = 'Pareto(a=1, loc=0, scale=1)')
    plt.ylim(1e-15, 1e2)
    plt.yscale('log')
    plt.legend(bbox_to_anchor=(1.1, 1))
    plt.subplots_adjust(right=0.5)
    
    plt.show()

References
----------

-  Normal Variance-Mean Mixture
   https://en.wikipedia.org/wiki/Normal_variance-mean_mixture

-  Generalized Hyperbolic Distribution
   https://en.wikipedia.org/wiki/Generalised_hyperbolic_distribution

-  O. Barndorff-Nielsen, "Hyperbolic Distributions and Distributions
   on Hyperbolae", Scandinavian Journal of Statistics, Vol. 5(3),
   pp. 151-157, 1978. https://www.jstor.org/stable/4615705

-  Eberlein E., Prause K. (2002) The Generalized Hyperbolic Model:
   Financial Derivatives and Risk Measures. In: Geman H., Madan D.,
   Pliska S.R., Vorst T. (eds) Mathematical Finance - Bachelier
   Congress 2000. Springer Finance. Springer, Berlin, Heidelberg.
   https://doi.org/10.1007/978-3-662-12429-1_12

-  Scott, David J, Würtz, Diethelm, Dong, Christine and Tran,
   Thanh Tam, (2009), Moments of the generalized hyperbolic
   distribution, MPRA Paper, University Library of Munich, Germany,
   https://EconPapers.repec.org/RePEc:pra:mprapa:19081.

Implementation: `scipy.stats.genhyperbolic`

.. _continuous-invgauss:

Inverse Normal (Inverse Gaussian) Distribution
==============================================

The standard form involves the shape parameter :math:`\mu` (in most
definitions, :math:`L=0.0` is used). (In terms of the regress
documentation :math:`\mu=A/B` ) and :math:`B=S` and :math:`L` is not
a parameter in that distribution. A standard form is :math:`x>0`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\mu\right) & = & \frac{1}{\sqrt{2\pi x^{3}}}\exp\left(-\frac{\left(x-\mu\right)^{2}}{2x\mu^{2}}\right).\\
    F\left(x;\mu\right) & = & \Phi\left(\frac{1}{\sqrt{x}}\frac{x-\mu}{\mu}\right)+\exp\left(\frac{2}{\mu}\right)\Phi\left(-\frac{1}{\sqrt{x}}\frac{x+\mu}{\mu}\right)\\
    G\left(q;\mu\right) & = & F^{-1}\left(q;\mu\right)\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \mu\\
    \mu_{2} & = & \mu^{3}\\
    \gamma_{1} & = & 3\sqrt{\mu}\\
    \gamma_{2} & = & 15\mu\\
    m_{d} & = & \frac{\mu}{2}\left(\sqrt{9\mu^{2}+4}-3\mu\right)\end{eqnarray*}

This is related to the canonical form or JKB "two-parameter" inverse
Gaussian when written in it's full form with scale parameter
:math:`S` and location parameter :math:`L` by taking
:math:`L=0` and :math:`S\equiv\lambda,` then :math:`\mu S` is equal to
:math:`\mu_{2}` where :math:`\mu_{2}` is the parameter used by JKB.
We prefer this form because of it's consistent use of the scale parameter.
Notice that in JKB the skew :math:`\left(\sqrt{\beta_{1}}\right)` and the
kurtosis ( :math:`\beta_{2}-3` ) are both functions only of
:math:`\mu_{2}/\lambda=\mu S/S=\mu` as shown here, while the variance
and mean of the standard form here are transformed appropriately.

Implementation: `scipy.stats.invgauss`

.. _discrete-nchypergeom-fisher:

Fisher's Noncentral Hypergeometric Distribution
===============================================

A random variable has Fisher's Noncentral Hypergeometric distribution with
parameters

:math:`M \in {\mathbb N}`,
:math:`n \in [0, M]`,
:math:`N \in [0, M]`,
:math:`\omega > 0`,

if its probability mass function is given by

.. math::

    p(x; M, n, N, \omega) = \frac{\binom{n}{x}\binom{M - n}{N-x}\omega^x}{P_0},

for
:math:`x \in [x_l, x_u]`,
where
:math:`x_l = \max(0, N - (M - n))`,
:math:`x_u = \min(N, n)`,

.. math::

    P_k = \sum_{y=x_l}^{x_u} \binom{n}{y} \binom{M - n}{N-y} \omega^y y^k,

and the binomial coefficients are

.. math::

    \binom{n}{k} \equiv \frac{n!}{k! (n - k)!}.

Other functions of this distribution are

.. math::
   :nowrap:

    \begin{eqnarray*}
    \mu & = & \frac{P_0}{P_1},\\
    \mu_{2} & = & \frac{P_2}{P_0} - \left(\frac{P_1}{P_0}\right)^2,\\
    \end{eqnarray*}

References
----------
-  Agner Fog, "Biased Urn Theory", https://cran.r-project.org/web/packages/BiasedUrn/vignettes/UrnTheory.pdf
-  "Fisher's noncentral hypergeometric distribution", Wikipedia, https://en.wikipedia.org/wiki/Fisher's_noncentral_hypergeometric_distribution

Implementation: `scipy.stats.nchypergeom_fisher`

.. _continuous-lognorm:

Log Normal (Cobb-Douglass) Distribution
=======================================

Has one shape parameter :math:`\sigma` >0. (Notice that the "Regress" :math:`A=\log S` where :math:`S` is the scale parameter and :math:`A` is the mean of the underlying normal distribution).
The support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\sigma\right) & = & \frac{1}{\sigma x\sqrt{2\pi}}\exp\left(-\frac{1}{2}\left(\frac{\log x}{\sigma}\right)^{2}\right)\\
    F\left(x;\sigma\right) & = & \Phi\left(\frac{\log x}{\sigma}\right)\\
    G\left(q;\sigma\right) & = & \exp\left( \sigma\Phi^{-1}\left(q\right)\right) \end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \exp\left(\sigma^{2}/2\right)\\
    \mu_{2} & = & \exp\left(\sigma^{2}\right)\left[\exp\left(\sigma^{2}\right)-1\right]\\
    \gamma_{1} & = & \sqrt{p-1}\left(2+p\right)\\
    \gamma_{2} & = & p^{4}+2p^{3}+3p^{2}-6\quad\quad p=e^{\sigma^{2}}\end{eqnarray*}

Notice that using JKB notation we have :math:`\theta=L,` :math:`\zeta=\log S` and we have given the so-called antilognormal form of the
distribution. This is more consistent with the location, scale
parameter description of general probability distributions.

.. math::

     h\left[X\right]=\frac{1}{2}\left[1+\log\left(2\pi\right)+2\log\left(\sigma\right)\right].

Also, note that if :math:`X` is a log-normally distributed random-variable with :math:`L=0` and :math:`S` and shape parameter :math:`\sigma.` Then, :math:`\log X` is normally distributed with variance :math:`\sigma^{2}` and mean :math:`\log S.`

Implementation: `scipy.stats.lognorm`

.. _continuous-loguniform:

Log-Uniform Distribution
========================

This random variable is log-uniform. That is, if ``loguniform(10**-1, 10**1)``
is specified, ``0.1``, ``1``, ``10`` are all equally likely.

There are two shape parameters :math:`a,b>0` and the support is :math:`x\in\left[a,b\right]`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;a,b\right) & = & \frac{1}{x\log\left(b/a\right)}\\ F\left(x;a,b\right) & = & \frac{\log\left(x/a\right)}{\log\left(b/a\right)}\\ G\left(q;a,b\right) & = & a\exp\left(q\log\left(b/a\right)\right)=a\left(\frac{b}{a}\right)^{q}\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} d & = & \log\left(a/b\right)\\ \mu & = & \frac{a-b}{d}\\ \mu_{2} & = & \mu\frac{a+b}{2}-\mu^{2}=\frac{\left(a-b\right)\left[a\left(d-2\right)+b\left(d+2\right)\right]}{2d^{2}}\\ \gamma_{1} & = & \frac{\sqrt{2}\left[12d\left(a-b\right)^{2}+d^{2}\left(a^{2}\left(2d-9\right)+2abd+b^{2}\left(2d+9\right)\right)\right]}{3d\sqrt{a-b}\left[a\left(d-2\right)+b\left(d+2\right)\right]^{3/2}}\\ \gamma_{2} & = & \frac{-36\left(a-b\right)^{3}+36d\left(a-b\right)^{2}\left(a+b\right)-16d^{2}\left(a^{3}-b^{3}\right)+3d^{3}\left(a^{2}+b^{2}\right)\left(a+b\right)}{3\left(a-b\right)\left[a\left(d-2\right)+b\left(d+2\right)\right]^{2}}-3\\ m_{d} & = & a\\ m_{n} & = & \sqrt{ab}\end{eqnarray*}

.. math::

     h\left[X\right]=\frac{1}{2}\log\left(ab\right)+\log\left[\log\left(\frac{b}{a}\right)\right].

Implementation: `scipy.stats.loguniform`.

.. _discrete-poisson:

Poisson Distribution
====================

The Poisson random variable counts the number of successes in :math:`n` independent Bernoulli trials in the limit as :math:`n\rightarrow\infty` and :math:`p\rightarrow0` where the probability of success in each trial is :math:`p` and :math:`np=\lambda\geq0` is a constant. It can be used to approximate the Binomial random
variable or in its own right to count the number of events that occur
in the interval :math:`\left[0,t\right]` for a process satisfying certain "sparsity" constraints. The functions are:

.. math::
   :nowrap:

    \begin{eqnarray*} p\left(k;\lambda\right) & = & e^{-\lambda}\frac{\lambda^{k}}{k!}\quad k\geq0,\\ F\left(x;\lambda\right) & = & \sum_{n=0}^{\left\lfloor x\right\rfloor }e^{-\lambda}\frac{\lambda^{n}}{n!}=\frac{1}{\Gamma\left(\left\lfloor x\right\rfloor +1\right)}\int_{\lambda}^{\infty}t^{\left\lfloor x\right\rfloor }e^{-t}dt,\\ \mu & = & \lambda\\ \mu_{2} & = & \lambda\\ \gamma_{1} & = & \frac{1}{\sqrt{\lambda}}\\ \gamma_{2} & = & \frac{1}{\lambda}.\end{eqnarray*}

.. math::

    M\left(t\right)=\exp\left[\lambda\left(e^{t}-1\right)\right].

Implementation: `scipy.stats.poisson`
.. _sampling-hinv:

Hermite interpolation based INVersion of CDF (HINV)
===================================================

.. currentmodule:: scipy.stats.sampling

* Required: CDF
* Optional: PDF, dPDF
* Speed:

  * Set-up: (very) slow
  * Sampling: (very) fast

HINV is a variant of numerical inversion, where the inverse CDF is approximated using
Hermite interpolation, i.e., the interval [0,1] is split into several intervals and
in each interval the inverse CDF is approximated by polynomials constructed by means
of values of the CDF and PDF at interval boundaries. This makes it possible to improve
the accuracy by splitting a particular interval without recomputations in unaffected
intervals. Three types of splines are implemented: linear, cubic, and quintic
interpolation. For linear interpolation only the CDF is required. Cubic interpolation
also requires PDF and quintic interpolation PDF and its derivative.

These splines have to be computed in a setup step. However, it only works for
distributions with bounded domain; for distributions with unbounded domain the tails
are chopped off such that the probability for the tail regions is small compared to
the given u-resolution.

The method is not exact, as it only produces random variates of the approximated
distribution. Nevertheless, the maximal numerical error in "u-direction" (i.e.
``|U - CDF(X)|`` where ``X`` is the approximate percentile corresponding to the
quantile ``U`` i.e. ``X = approx_ppf(U)``) can be set to the
required resolution (within machine precision). Notice that very small values of
the u-resolution are possible but may increase the cost for the setup step.

`NumericalInverseHermite` approximates the inverse of a continuous
statistical distribution's CDF with a Hermite spline. Order of the
hermite spline can be specified by passing the `order` parameter.

As described in [1]_, it begins by evaluating the distribution's PDF and
CDF at a mesh of quantiles ``x`` within the distribution's support.
It uses the results to fit a Hermite spline ``H`` such that
``H(p) == x``, where ``p`` is the array of percentiles corresponding
with the quantiles ``x``. Therefore, the spline approximates the inverse
of the distribution's CDF to machine precision at the percentiles ``p``,
but typically, the spline will not be as accurate at the midpoints between
the percentile points::

    p_mid = (p[:-1] + p[1:])/2

so the mesh of quantiles is refined as needed to reduce the maximum
"u-error"::

    u_error = np.max(np.abs(dist.cdf(H(p_mid)) - p_mid))

below the specified tolerance `u_resolution`. Refinement stops when the required
tolerance is achieved or when the number of mesh intervals after the next
refinement could exceed the maximum allowed number of intervals (100000).

    >>> from scipy.stats.sampling import NumericalInverseHermite
    >>> from scipy.stats import norm, genexpon
    >>> from scipy.special import ndtr

To create a generator to sample from the standard normal distribution, do:

    >>> class StandardNormal:
    ...     def pdf(self, x):
    ...        return 1/np.sqrt(2*np.pi) * np.exp(-x**2 / 2)
    ...     def cdf(self, x):
    ...        return ndtr(x)
    ... 
    >>> dist = StandardNormal()
    >>> urng = np.random.default_rng()
    >>> rng = NumericalInverseHermite(dist, random_state=urng)

The `NumericalInverseHermite` has a method that approximates the PPF of the
distribution.

    >>> rng = NumericalInverseHermite(dist)
    >>> p = np.linspace(0.01, 0.99, 99) # percentiles from 1% to 99%
    >>> np.allclose(rng.ppf(p), norm.ppf(p))
    True

Depending on the implementation of the distribution's random sampling
method, the random variates generated may be nearly identical, given
the same random state.

    >>> dist = genexpon(9, 16, 3)
    >>> rng = NumericalInverseHermite(dist)
    >>> # `seed` ensures identical random streams are used by each `rvs` method
    >>> seed = 500072020
    >>> rvs1 = dist.rvs(size=100, random_state=np.random.default_rng(seed))
    >>> rvs2 = rng.rvs(size=100, random_state=np.random.default_rng(seed))
    >>> np.allclose(rvs1, rvs2)
    True

To check that the random variates closely follow the given distribution, we can
look at its histogram:

    >>> dist = StandardNormal()
    >>> urng = np.random.default_rng()
    >>> rng = NumericalInverseHermite(dist, random_state=urng)
    >>> rvs = rng.rvs(10000)
    >>> x = np.linspace(rvs.min()-0.1, rvs.max()+0.1, 1000)
    >>> fx = norm.pdf(x)
    >>> plt.plot(x, fx, 'r-', lw=2, label='true distribution')
    >>> plt.hist(rvs, bins=20, density=True, alpha=0.8, label='random variates')
    >>> plt.xlabel('x')
    >>> plt.ylabel('PDF(x)')
    >>> plt.title('Numerical Inverse Hermite Samples')
    >>> plt.legend()
    >>> plt.show()

.. plot:: tutorial/stats/plots/hinv_plot.py
   :align: center
   :include-source: 0

Given the derivative of the PDF w.r.t the variate (i.e. ``x``), we can use
quintic Hermite interpolation to approximate the PPF by passing the `order`
parameter:

    >>> class StandardNormal:
    ...     def pdf(self, x):
    ...        return 1/np.sqrt(2*np.pi) * np.exp(-x**2 / 2)
    ...     def dpdf(self, x):
    ...        return -1/np.sqrt(2*np.pi) * x * np.exp(-x**2 / 2)
    ...     def cdf(self, x):
    ...        return ndtr(x)
    ... 
    >>> dist = StandardNormal()
    >>> urng = np.random.default_rng()
    >>> rng = NumericalInverseHermite(dist, order=5, random_state=urng)

Higher orders result in a fewer number of intervals:

    >>> rng3 = NumericalInverseHermite(dist, order=3)
    >>> rng5 = NumericalInverseHermite(dist, order=5)
    >>> rng3.intervals, rng5.intervals
    (3000, 522)

The u-error can be estimated by calling the `u_error` method. It runs a small
Monte-Carlo simulation to estimate the u-error. By default, 100,000 samples are
used. This can be changed by passing the `sample_size` argument:

    >>> rng1 = NumericalInverseHermite(dist, u_resolution=1e-10)
    >>> rng1.u_error(sample_size=1000000)  # uses one million samples
    UError(max_error=9.53167544892608e-11, mean_absolute_error=2.2450136432146864e-11)

This returns a namedtuple which contains the maximum u-error and the mean
absolute u-error.

The u-error can be reduced by decreasing the u-resolution (maximum allowed u-error):

    >>> rng2 = NumericalInverseHermite(dist, u_resolution=1e-13)
    >>> rng2.u_error(sample_size=1000000)
    UError(max_error=9.32027892364129e-14, mean_absolute_error=1.5194172675685075e-14)

Note that this comes at the cost of computation time as a result of the increased
setup time and number of intervals.

    >>> rng1.intervals
    1022
    >>> rng2.intervals
    5687
    >>> from timeit import timeit
    >>> f = lambda: NumericalInverseHermite(dist, u_resolution=1e-10)
    >>> timeit(f, number=1)
    0.017409582000254886  # may vary
    >>> f = lambda: NumericalInverseHermite(dist, u_resolution=1e-13)
    >>> timeit(f, number=1)
    0.08671202100003939  # may vary

See [1]_ and [2]_ for more details on this method.

References
----------

.. [1] Hörmann, Wolfgang, and Josef Leydold. "Continuous random variate
       generation by fast numerical inversion." ACM Transactions on
       Modeling and Computer Simulation (TOMACS) 13.4 (2003): 347-362.
.. [2] UNU.RAN reference manual, Section 5.3.5,
       "HINV - Hermite interpolation based INVersion of CDF",
       https://statmath.wu.ac.at/software/unuran/doc/unuran.html#HINV

.. _continuous-exponpow:

Exponential Power Distribution
==============================

One positive shape parameter :math:`b`. The support is :math:`x\geq0.`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;b\right) & = & ebx^{b-1}\exp\left(x^{b}-e^{x^{b}}\right)\\
    F\left(x;b\right) & = & 1-\exp\left(1-e^{x^{b}}\right)\\
    G\left(q;b\right) & = & \log\left(1-\log\left(1-q\right)\right)^{1/b}\end{eqnarray*}

Implementation: `scipy.stats.exponpow`

.. _continuous-ncx2:

Noncentral chi-squared Distribution
===================================

The distribution of :math:`\sum_{i=1}^{\nu}\left(Z_{i}+\delta_{i}\right)^{2}`
where :math:`Z_{i}` are independent standard normal variables and
:math:`\delta_{i}` are constants.
:math:`\lambda=\sum_{i=1}^{\nu}\delta_{i}^{2}>0.`
(In communications it is called the Marcum-Q function).
It can be thought of as a Generalized Rayleigh-Rice distribution.

The two shape parameters are :math:`\nu`, a positive integer, and :math:`\lambda`,
a positive real number.  The support is :math:`x\geq0`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;\nu,\lambda\right) & = & e^{-\left(\lambda+x\right)/2}\frac{1}{2}\left(\frac{x}{\lambda}\right)^{\left(\nu-2\right)/4}I_{\left(\nu-2\right)/2}\left(\sqrt{\lambda x}\right)\\
    F\left(x;\nu,\lambda\right) & = & \sum_{j=0}^{\infty}\left\{ \frac{\left(\lambda/2\right)^{j}}{j!}e^{-\lambda/2}\right\} \mathrm{Pr}\left[\chi_{\nu+2j}^{2}\leq x\right]\\
    G\left(q;\nu,\lambda\right) & = & F^{-1}\left(q;\nu,\lambda\right)\\
    \mu & = & \nu+\lambda\\
    \mu_{2} & = & 2\left(\nu+2\lambda\right)\\
    \gamma_{1} & = & \frac{\sqrt{8}\left(\nu+3\lambda\right)}{\left(\nu+2\lambda\right)^{3/2}}\\
    \gamma_{2} & = & \frac{12\left(\nu+4\lambda\right)}{\left(\nu+2\lambda\right)^{2}}\end{eqnarray*}

where  :math:`I_{\nu }(y)` is a modified Bessel function of the first kind.


References
----------

-  "Noncentral chi-squared distribution", Wikipedia
   https://en.wikipedia.org/wiki/Noncentral_chi-squared_distribution

Implementation: `scipy.stats.ncx2`
.. _continuous-random-variables:

====================================
Continuous Statistical Distributions
====================================

Overview
========

All distributions will have location (L) and Scale (S) parameters
along with any shape parameters needed, the names for the shape
parameters will vary. Standard form for the distributions will be
given where :math:`L=0.0` and :math:`S=1.0.` The nonstandard forms can be obtained for the various functions using
(note :math:`U` is a standard uniform random variate).


======================================  =============================================================================  =========================================================================================================================================
Function Name                           Standard Function                                                              Transformation
======================================  =============================================================================  =========================================================================================================================================
Cumulative Distribution Function (CDF)  :math:`F\left(x\right)`                                                        :math:`F\left(x;L,S\right)=F\left(\frac{\left(x-L\right)}{S}\right)`
Probability Density Function (PDF)      :math:`f\left(x\right)=F^{\prime}\left(x\right)`                               :math:`f\left(x;L,S\right)=\frac{1}{S}f\left(\frac{\left(x-L\right)}{S}\right)`
Percent Point Function (PPF)            :math:`G\left(q\right)=F^{-1}\left(q\right)`                                   :math:`G\left(q;L,S\right)=L+SG\left(q\right)`
Probability Sparsity Function (PSF)     :math:`g\left(q\right)=G^{\prime}\left(q\right)`                               :math:`g\left(q;L,S\right)=Sg\left(q\right)`
Hazard Function (HF)                    :math:`h_{a}\left(x\right)=\frac{f\left(x\right)}{1-F\left(x\right)}`          :math:`h_{a}\left(x;L,S\right)=\frac{1}{S}h_{a}\left(\frac{\left(x-L\right)}{S}\right)`
Cumulative Hazard Function (CHF)        :math:`H_{a}\left(x\right)=` :math:`\log\frac{1}{1-F\left(x\right)}`           :math:`H_{a}\left(x;L,S\right)=H_{a}\left(\frac{\left(x-L\right)}{S}\right)`
Survival Function (SF)                  :math:`S\left(x\right)=1-F\left(x\right)`                                      :math:`S\left(x;L,S\right)=S\left(\frac{\left(x-L\right)}{S}\right)`
Inverse Survival Function (ISF)         :math:`Z\left(\alpha\right)=S^{-1}\left(\alpha\right)=G\left(1-\alpha\right)`  :math:`Z\left(\alpha;L,S\right)=L+SZ\left(\alpha\right)`
Moment Generating Function (MGF)        :math:`M_{Y}\left(t\right)=E\left[e^{Yt}\right]`                               :math:`M_{X}\left(t\right)=e^{Lt}M_{Y}\left(St\right)`
Random Variates                         :math:`Y=G\left(U\right)`                                                      :math:`X=L+SY`
(Differential) Entropy                  :math:`h\left[Y\right]=-\int f\left(y\right)\log f\left(y\right)dy`            :math:`h\left[X\right]=h\left[Y\right]+\log S`
(Non-central) Moments                   :math:`\mu_{n}^{\prime}=E\left[Y^{n}\right]`                                   :math:`E\left[X^{n}\right]=L^{n}\sum_{k=0}^{N}\left(\begin{array}{c} n\\ k\end{array}\right)\left(\frac{S}{L}\right)^{k}\mu_{k}^{\prime}`
Central Moments                         :math:`\mu_{n}=E\left[\left(Y-\mu\right)^{n}\right]`                           :math:`E\left[\left(X-\mu_{X}\right)^{n}\right]=S^{n}\mu_{n}`
mean (mode, median), var                :math:`\mu,\,\mu_{2}`                                                          :math:`L+S\mu,\, S^{2}\mu_{2}`
skewness                                :math:`\gamma_{1}=\frac{\mu_{3}}{\left(\mu_{2}\right)^{3/2}}`                  :math:`\gamma_{1}`
kurtosis                                :math:`\gamma_{2}=\frac{\mu_{4}}{\left(\mu_{2}\right)^{2}}-3`                  :math:`\gamma_{2}`
======================================  =============================================================================  =========================================================================================================================================


Moments
-------

Non-central moments are defined using the PDF

.. math::

   \mu_{n}^{\prime}=\int_{-\infty}^{\infty}x^{n}f\left(x\right)dx.

Note, that these can always be computed using the PPF. Substitute :math:`x=G\left(q\right)` in the above equation and get

.. math::

   \mu_{n}^{\prime}=\int_{0}^{1}G^{n}\left(q\right)dq

which may be easier to compute numerically. Note that :math:`q=F\left(x\right)` so that :math:`dq=f\left(x\right)dx.` Central moments are computed similarly :math:`\mu=\mu_{1}^{\prime}`

.. math::
   :nowrap:

    \begin{eqnarray*} \mu_{n} & = & \int_{-\infty}^{\infty}\left(x-\mu\right)^{n}f\left(x\right)dx\\  & = & \int_{0}^{1}\left(G\left(q\right)-\mu\right)^{n}dq\\  & = & \sum_{k=0}^{n}\left(\begin{array}{c} n\\ k\end{array}\right)\left(-\mu\right)^{k}\mu_{n-k}^{\prime}\end{eqnarray*}

In particular

.. math::
   :nowrap:

    \begin{eqnarray*} \mu_{3} & = & \mu_{3}^{\prime}-3\mu\mu_{2}^{\prime}+2\mu^{3}\\  & = & \mu_{3}^{\prime}-3\mu\mu_{2}-\mu^{3}\\ \mu_{4} & = & \mu_{4}^{\prime}-4\mu\mu_{3}^{\prime}+6\mu^{2}\mu_{2}^{\prime}-3\mu^{4}\\  & = & \mu_{4}^{\prime}-4\mu\mu_{3}-6\mu^{2}\mu_{2}-\mu^{4}\end{eqnarray*}

Skewness is defined as

.. math::

     \gamma_{1}=\sqrt{\beta_{1}}=\frac{\mu_{3}}{\mu_{2}^{3/2}}

while (Fisher) kurtosis is

.. math::

     \gamma_{2}=\frac{\mu_{4}}{\mu_{2}^{2}}-3,

so that a normal distribution has a kurtosis of zero.


Median and mode
---------------

The median, :math:`m_{n}` is defined as the point at which half of the density is on one side
and half on the other. In other words, :math:`F\left(m_{n}\right)=\frac{1}{2}` so that

.. math::

     m_{n}=G\left(\frac{1}{2}\right).

In addition, the mode, :math:`m_{d}` , is defined as the value for which the probability density function
reaches it's peak

.. math::

     m_{d}=\arg\max_{x}f\left(x\right).


Fitting data
------------

To fit data to a distribution, maximizing the likelihood function is
common. Alternatively, some distributions have well-known minimum
variance unbiased estimators. These will be chosen by default, but the
likelihood function will always be available for minimizing.

If :math:`f\left(x;\boldsymbol{\theta}\right)` is the PDF of a random-variable where :math:`\boldsymbol{\theta}` is a vector of parameters ( *e.g.* :math:`L` and :math:`S` ), then for a collection of :math:`N` independent samples from this distribution, the joint distribution the
random vector :math:`\mathbf{x}` is

.. math::

     f\left(\mathbf{x};\boldsymbol{\theta}\right)=\prod_{i=1}^{N}f\left(x_{i};\boldsymbol{\theta}\right).

The maximum likelihood estimate of the parameters :math:`\boldsymbol{\theta}` are the parameters which maximize this function with :math:`\mathbf{x}` fixed and given by the data:

.. math::
   :nowrap:

    \begin{eqnarray*} \boldsymbol{\theta}_{es} & = & \arg\max_{\boldsymbol{\theta}}f\left(\mathbf{x};\boldsymbol{\theta}\right)\\  & = & \arg\min_{\boldsymbol{\theta}}l_{\mathbf{x}}\left(\boldsymbol{\theta}\right).\end{eqnarray*}

Where

.. math::
   :nowrap:

    \begin{eqnarray*} l_{\mathbf{x}}\left(\boldsymbol{\theta}\right) & = & -\sum_{i=1}^{N}\log f\left(x_{i};\boldsymbol{\theta}\right)\\  & = & -N\overline{\log f\left(x_{i};\boldsymbol{\theta}\right)}\end{eqnarray*}

Note that if :math:`\boldsymbol{\theta}` includes only shape parameters, the location and scale-parameters can
be fit by replacing :math:`x_{i}` with :math:`\left(x_{i}-L\right)/S` in the log-likelihood function adding :math:`N\log S` and minimizing, thus

.. math::
   :nowrap:

    \begin{eqnarray*} l_{\mathbf{x}}\left(L,S;\boldsymbol{\theta}\right) & = & N\log S-\sum_{i=1}^{N}\log f\left(\frac{x_{i}-L}{S};\boldsymbol{\theta}\right)\\  & = & N\log S+l_{\frac{\mathbf{x}-S}{L}}\left(\boldsymbol{\theta}\right)\end{eqnarray*}

If desired, sample estimates for :math:`L` and :math:`S` (not necessarily maximum likelihood estimates) can be obtained from
samples estimates of the mean and variance using

.. math::
   :nowrap:

    \begin{eqnarray*} \hat{S} & = & \sqrt{\frac{\hat{\mu}_{2}}{\mu_{2}}}\\ \hat{L} & = & \hat{\mu}-\hat{S}\mu\end{eqnarray*}

where :math:`\mu` and :math:`\mu_{2}` are assumed known as the mean and variance of the **untransformed** distribution (when :math:`L=0` and :math:`S=1` ) and

.. math::
   :nowrap:

    \begin{eqnarray*} \hat{\mu} & = & \frac{1}{N}\sum_{i=1}^{N}x_{i}=\bar{\mathbf{x}}\\ \hat{\mu}_{2} & = & \frac{1}{N-1}\sum_{i=1}^{N}\left(x_{i}-\hat{\mu}\right)^{2}=\frac{N}{N-1}\overline{\left(\mathbf{x}-\bar{\mathbf{x}}\right)^{2}}\end{eqnarray*}


Standard notation for mean
--------------------------

We will use

.. math::

    \overline{y\left(\mathbf{x}\right)}=\frac{1}{N}\sum_{i=1}^{N}y\left(x_{i}\right)

where :math:`N` should be clear from context as the number of samples :math:`x_{i}`

References
----------

-  Documentation for ranlib, rv2, cdflib

-  Eric Weisstein's world of mathematics http://mathworld.wolfram.com/,
   http://mathworld.wolfram.com/topics/StatisticalDistributions.html

-  Documentation to Regress+ by Michael McLaughlin item Engineering and
   Statistics Handbook (NIST),
   https://www.itl.nist.gov/div898/handbook/

-  Documentation for DATAPLOT from NIST,
   https://www.itl.nist.gov/div898/software/dataplot/distribu.htm

-  Norman Johnson, Samuel Kotz, and N. Balakrishnan Continuous
   Univariate Distributions, second edition, Volumes I and II, Wiley &
   Sons, 1994.


In the tutorials several special functions appear repeatedly and are listed here.

===============================================================  ======================================================================================  =============================================================================================================================
Symbol                                                           Description                                                                             Definition
===============================================================  ======================================================================================  =============================================================================================================================
:math:`\gamma\left(s, x\right)`                                  lower incomplete Gamma function                                                         :math:`\int_0^x t^{s-1} e^{-t} dt`
:math:`\Gamma\left(s, x\right)`                                  upper incomplete Gamma function                                                         :math:`\int_x^\infty t^{s-1} e^{-t} dt`
:math:`B\left(x;a,b\right)`                                      incomplete Beta function                                                                :math:`\int_{0}^{x} t^{a-1}\left(1-t\right)^{b-1} dt`
:math:`I\left(x;a,b\right)`                                      regularized incomplete Beta function                                                    :math:`\frac{\Gamma\left(a+b\right)}{\Gamma\left(a\right)\Gamma\left(b\right)} \int_{0}^{x} t^{a-1}\left(1-t\right)^{b-1} dt`
:math:`\phi\left(x\right)`                                       PDF for normal distribution                                                             :math:`\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}`
:math:`\Phi\left(x\right)`                                       CDF for normal distribution                                                             :math:`\int_{-\infty}^{x}\phi\left(t\right) dt = \frac{1}{2}+\frac{1}{2}\mathrm{erf}\left(\frac{x}{\sqrt{2}}\right)`
:math:`\psi\left(z\right)`                                       digamma function                                                                        :math:`\frac{d}{dz} \log\left(\Gamma\left(z\right)\right)`
:math:`\psi_{n}\left(z\right)`                                   polygamma function                                                                      :math:`\frac{d^{n+1}}{dz^{n+1}}\log\left(\Gamma\left(z\right)\right)`
:math:`I_{\nu}\left(y\right)`                                    modified Bessel function of the first kind
:math:`\mathrm{Ei}(\mathrm{z})`                                  exponential integral                                                                    :math:`-\int_{-x}^\infty \frac{e^{-t}}{t} dt`
:math:`\zeta\left(n\right)`                                      Riemann zeta function                                                                   :math:`\sum_{k=1}^{\infty} \frac{1}{k^{n}}`
:math:`\zeta\left(n,z\right)`                                    Hurwitz zeta function                                                                   :math:`\sum_{k=0}^{\infty} \frac{1}{\left(k+z\right)^{n}}`
:math:`\,{}_{p}F_{q}(a_{1},\ldots,a_{p};b_{1},\ldots,b_{q};z)`   Hypergeometric function                                                                 :math:`\sum_{n=0}^{\infty} {\frac{(a_{1})_{n}\cdots(a_{p})_{n}}{(b_{1})_{n}\cdots(b_{q})_{n}}} \,{\frac{z^{n}}{n!}}`
===============================================================  ======================================================================================  =============================================================================================================================


Continuous Distributions in `scipy.stats`
-----------------------------------------
.. toctree::
   :maxdepth: 1

   continuous_alpha
   continuous_anglit
   continuous_arcsine
   continuous_beta
   continuous_betaprime
   continuous_bradford
   continuous_burr
   continuous_burr12
   continuous_cauchy
   continuous_skewcauchy
   continuous_chi
   continuous_chi2
   continuous_cosine
   continuous_dgamma
   continuous_dweibull
   continuous_erlang
   continuous_expon
   continuous_exponweib
   continuous_exponpow
   continuous_fatiguelife
   continuous_fisk
   continuous_foldcauchy
   continuous_foldnorm
   continuous_f
   continuous_gamma
   continuous_genlogistic
   continuous_genpareto
   continuous_genexpon
   continuous_genextreme
   continuous_gengamma
   continuous_genhalflogistic
   continuous_genhyperbolic
   continuous_geninvgauss
   continuous_gennorm
   continuous_gilbrat
   continuous_gompertz
   continuous_gumbel_r
   continuous_gumbel_l
   continuous_halfcauchy
   continuous_halfnorm
   continuous_halflogistic
   continuous_hypsecant
   continuous_gausshyper
   continuous_invgamma
   continuous_invgauss
   continuous_invweibull
   continuous_johnsonsb
   continuous_johnsonsu
   continuous_ksone
   continuous_kstwo
   continuous_kstwobign
   continuous_laplace
   continuous_laplace_asymmetric
   continuous_levy_l
   continuous_levy
   continuous_logistic
   continuous_loglaplace
   continuous_loggamma
   continuous_lognorm
   continuous_loguniform
   continuous_maxwell
   continuous_mielke
   continuous_nakagami
   continuous_ncx2
   continuous_ncf
   continuous_nct
   continuous_norm
   continuous_norminvgauss
   continuous_pareto
   continuous_lomax
   continuous_powerlognorm
   continuous_powernorm
   continuous_powerlaw
   continuous_rdist
   continuous_rayleigh
   continuous_rice
   continuous_recipinvgauss
   continuous_semicircular
   continuous_studentized_range
   continuous_t
   continuous_trapezoid
   continuous_triang
   continuous_truncexpon
   continuous_truncnorm
   continuous_tukeylambda
   continuous_uniform
   continuous_vonmises
   continuous_wald
   continuous_weibull_max
   continuous_weibull_min
   continuous_wrapcauchy

.. _continuous-genlogistic:

Generalized Logistic Distribution
=================================

Has been used in the analysis of extreme values. There is one shape
parameter :math:`c>0`. The support is :math:`x \in \mathcal{R}`.

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x;c\right) & = & \frac{c\exp\left(-x\right)}{\left[1+\exp\left(-x\right)\right]^{c+1}}\\
    F\left(x;c\right) & = & \frac{1}{\left[1+\exp\left(-x\right)\right]^{c}}\\
    G\left(q;c\right) & = & -\log\left(q^{-1/c}-1\right)\end{eqnarray*}

.. math::

     M\left(t\right)=\frac{c}{1-t}\,_{2}F_{1}\left(1+c,\,1-t\,;\,2-t\,;-1\right)

.. math::
   :nowrap:

    \begin{eqnarray*} \mu & = & \gamma+\psi_{0}\left(c\right)\\
    \mu_{2} & = & \frac{\pi^{2}}{6}+\psi_{1}\left(c\right)\\
    \gamma_{1} & = & \frac{\psi_{2}\left(c\right)+2\zeta\left(3\right)}{\mu_{2}^{3/2}}\\
    \gamma_{2} & = & \frac{\left(\frac{\pi^{4}}{15}+\psi_{3}\left(c\right)\right)}{\mu_{2}^{2}}\\
    m_{d} & = & \log c\\
    m_{n} & = & -\log\left(2^{1/c}-1\right)\end{eqnarray*}

Note that the polygamma function is

.. math::
   :nowrap:

    \begin{eqnarray*} \psi_{n}\left(z\right) & = & \frac{d^{n+1}}{dz^{n+1}}\log\Gamma\left(z\right)\\
    & = & \left(-1\right)^{n+1}n!\sum_{k=0}^{\infty}\frac{1}{\left(z+k\right)^{n+1}}\\
    & = & \left(-1\right)^{n+1}n!\zeta\left(n+1,z\right)\end{eqnarray*}

where :math:`\zeta\left(k,x\right)` is a generalization of the Riemann zeta function called the Hurwitz
zeta function. Note that :math:`\zeta\left(n\right)\equiv\zeta\left(n,1\right)`.

Implementation: `scipy.stats.genlogistic`

.. _continuous-semicircular:

Semicircular Distribution
=========================

Defined on :math:`x\in\left[-1,1\right]`

.. math::
   :nowrap:

    \begin{eqnarray*} f\left(x\right) & = & \frac{2}{\pi}\sqrt{1-x^{2}}\\ F\left(x\right) & = & \frac{1}{2}+\frac{1}{\pi}\left[x\sqrt{1-x^{2}}+\arcsin x\right]\\ G\left(q\right) & = & F^{-1}\left(q\right)\end{eqnarray*}

.. math::
   :nowrap:

    \begin{eqnarray*} m_{d}=m_{n}=\mu & = & 0\\ \mu_{2} & = & \frac{1}{4}\\ \gamma_{1} & = & 0\\ \gamma_{2} & = & -1\end{eqnarray*}

.. math::

     h\left[X\right]=0.64472988584940017414.

Implementation: `scipy.stats.semicircular`
.. _scipy-roadmap-detailed:

Detailed SciPy Roadmap
======================

Most of this roadmap is intended to provide a high-level view on what is
most needed per SciPy submodule in terms of new functionality, bug fixes, etc.
Besides important "business as usual" changes, it contains ideas for major new
features - those are marked as such, and are expected to take significant
dedicated effort.  Things not mentioned in this roadmap are
not necessarily unimportant or out of scope, however we (the SciPy developers)
want to provide to our users and contributors a clear picture of where SciPy is
going and where help is needed most.

.. note:: This is the detailed roadmap.  A very high-level overview with only
   the most important ideas is :ref:`scipy-roadmap`.


General
-------
This roadmap will be evolving together with SciPy.  Updates can be submitted as
pull requests.  For large or disruptive changes you may want to discuss
those first on the scipy-dev mailing list.


API changes
```````````
In general, we want to evolve the API to remove known warts as much as possible,
*however as much as possible without breaking backwards compatibility*.


Test coverage
`````````````
Test coverage of code added in the last few years is quite good, and we aim for
a high coverage for all new code that is added.  However, there is still a
significant amount of old code for which coverage is poor.  Bringing that up to
the current standard is probably not realistic, but we should plug the biggest
holes.

Besides coverage there is also the issue of correctness - older code may have a
few tests that provide decent statement coverage, but that doesn't necessarily
say much about whether the code does what it says on the box.  Therefore code
review of some parts of the code (``stats``, ``signal`` and ``ndimage`` in
particular) is necessary.


Documentation
`````````````
The documentation is in good shape. Expanding of current docstrings - adding
examples, references, and better explanations - should continue.  Most modules
also have a tutorial in the reference guide that is a good introduction,
however there are a few missing or incomplete tutorials - this should be fixed.


Benchmarks
``````````
The ``asv``-based benchmark system is in reasonable shape.  It is quite easy to
add new benchmarks, however running the benchmarks is not very intuitive.
Making this easier is a priority.


Moving to the Meson build system
````````````````````````````````
Support for the Meson build system was merged into SciPy main in Dec 2021.
This significantly improves build performance, and will fix multiple issues
(e.g., our issues with Windows compilers, cross-compilation support). The aim
is to make it the default build system for SciPy 1.9.0, and then remove support
for ``numpy.distutils``/``setuptools`` in SciPy 1.10.0. For more details, see
`gh-13615 <https://github.com/scipy/scipy/issues/13615>`_.


Use of Cython
`````````````
Cython's old syntax for using NumPy arrays should be removed and replaced with
Cython memoryviews. When Cython 3.0 is released, the last use of the deprecated
NumPy C API (by Cython, everything in SciPy was fixed) will disappear. Then we
can define ``NPY_NO_DEPRECATED_API`` unconditionally.


Use of Pythran
``````````````
Pythran is still an optional build dependency, and can be disabled with
``SCIPY_USE_PYTHRAN=0``. The aim is to make it a hard dependency - for that to
happen it must be clear that the maintenance burden is low enough (Meson will
help here, because it removes the monkey patching that is now done to enable
Pythran).


Continuous integration
``````````````````````
Continuous integration currently covers 32/64-bit Windows, macOS on x86-64, and
32/64-bit Linux on x86, and Linux on aarch64 - as well as a range of versions
of our dependencies and building release quality wheels. Reliability of CI has
not been good recently (H2 2021), due to the large amount of configurations to
support and some CI jobs needing an overhaul. We aim to reduce build times,
improve caching, move more jobs to GitHub Actions, drop TravisCI and Appveyor
in the `scipy-wheels repo <https://github.com/MacPython/scipy-wheels>`_,
move from ``multibuild`` to ``cibuildwheel`` for building wheels for releases,
and make the set of configurations in CI jobs more orthogonal.


Size of binaries
````````````````
SciPy binaries are quite large (e.g. an unzipped manylinux wheel for 1.7.3 is
39 MB on PyPI and 122 MB after installation), and this can be problematic - for
example for use in AWS Lambda, which has a 250 MB size limit. We aim to keep
binary size as low as possible; when adding new compiled extensions, this needs
checking. Stripping of debug symbols in ``multibuild`` can perhaps be improved
(see `this issue <https://github.com/matthew-brett/multibuild/issues/162>`__).
An effort should be made to slim down where possible, and not add new large
files. In the future, things that are being considered (very tentatively) and
may help are separating out the bundled` ``libopenblas`` and removing support
for ``long double``.


Modules
-------

cluster
```````
``dendrogram`` needs a rewrite, it has a number of hard to fix open issues and
feature requests.


constants
`````````
This module is basically done, low-maintenance and without open issues.


fft
````
This module is in good shape.


integrate
`````````
Needed for ODE solvers:

- Documentation is pretty bad, needs fixing
- A new ODE solver interface  (``solve_ivp``) was added in SciPy 1.0.0.
  In the future we can consider (soft-)deprecating the older API.

The numerical integration functions are in good shape.  Support for integrating
complex-valued functions and integrating multiple intervals (see `gh-3325
<https://github.com/scipy/scipy/issues/3325>`__) could be added.


interpolate
```````````

Ideas for new features:

- Spline fitting routines with better user control.
- Transparent tensor-product splines.
- NURBS support.
- Mesh refinement and coarsening of B-splines and corresponding tensor products.


io
``
wavfile:

- PCM float will be supported, for anything else use ``audiolab`` or other
  specialized libraries.
- Raise errors instead of warnings if data not understood.

Other sub-modules (matlab, netcdf, idl, harwell-boeing, arff, matrix market)
are in good shape.


linalg
``````
``scipy.linalg`` is in good shape.

Needed:

- Reduce duplication of functions with ``numpy.linalg``, make APIs consistent.
- ``get_lapack_funcs`` should always use ``flapack``
- Wrap more LAPACK functions
- One too many funcs for LU decomposition, remove one

Ideas for new features:

- Add type-generic wrappers in the Cython BLAS and LAPACK
- Make many of the linear algebra routines into gufuncs

**BLAS and LAPACK**

The Python and Cython interfaces to BLAS and LAPACK in ``scipy.linalg`` are one
of the most important things that SciPy provides. In general ``scipy.linalg``
is in good shape, however we can make a number of improvements:

1. Library support. Our released wheels now ship with OpenBLAS, which is
   currently the only feasible performant option (ATLAS is too slow, MKL cannot
   be the default due to licensing issues, Accelerate support is dropped
   because Apple doesn't update Accelerate anymore). OpenBLAS isn't very stable
   though, sometimes its releases break things and it has issues with threading
   (currently the only issue for using SciPy with PyPy3).  We need at the very
   least better support for debugging OpenBLAS issues, and better documentation
   on how to build SciPy with it.  An option is to use BLIS for a BLAS
   interface (see `numpy gh-7372 <https://github.com/numpy/numpy/issues/7372>`__).

2. Support for newer LAPACK features.  In SciPy 1.2.0 we increased the minimum
   supported version of LAPACK to 3.4.0.  Now that we dropped Python 2.7, we
   can increase that version further (MKL + Python 2.7 was the blocker for
   >3.4.0 previously) and start adding support for new features in LAPACK.


misc
````
``scipy.misc`` will be removed as a public module.  Most functions in it have
been moved to another submodule or deprecated.  The few that are left:

- ``derivative``, ``central_diff_weight`` : remove, possibly replacing them
  with more extensive functionality for numerical differentiation.
- ``ascent``, ``face``, ``electrocardiogram`` : remove or move to the
  appropriate subpackages (e.g. ``scipy.ndimage``, ``scipy.signal``).


ndimage
```````
Underlying ``ndimage`` is a powerful interpolation engine.  Users come
with an expectation of one of two models: a pixel model with ``(1,
1)`` elements having centers ``(0.5, 0.5)``, or a data point model,
where values are defined at points on a grid.  Over time, we've become
convinced that the data point model is better defined and easier to
implement, but this should be clearly communicated in the documentation.

More importantly, still, SciPy implements one *variant* of this data
point model, where datapoints at any two extremes of an axis share a
spatial location under *periodic wrapping* mode.  E.g., in a 1D array,
you would have ``x[0]`` and ``x[-1]`` co-located.  A very common
use-case, however, is for signals to be periodic, with equal spacing
between the first and last element along an axis (instead of zero
spacing).  Wrapping modes for this use-case were added in
`gh-8537 <https://github.com/scipy/scipy/pull/8537>`__, next the
interpolation routines should be updated to use those modes.
This should address several issues, including gh-1323, gh-1903, gh-2045
and gh-2640.

The morphology interface needs to be standardized:

- binary dilation/erosion/opening/closing take a "structure" argument,
  whereas their grey equivalent take size (has to be a tuple, not a scalar),
  footprint, or structure.
- a scalar should be acceptable for size, equivalent to providing that same
  value for each axis.
- for binary dilation/erosion/opening/closing, the structuring element is
  optional, whereas it's mandatory for grey.  Grey morphology operations
  should get the same default.
- other filters should also take that default value where possible.


odr
```
This module is in reasonable shape, although it could use a bit more
maintenance.  No major plans or wishes here.


optimize
````````
Overall this module is in good shape. Two good global optimizers were added in
1.2.0; large-scale optimizers is still a gap that could be filled.  Other
things that are needed:

- Many ideas for additional functionality (e.g. integer constraints) in
  ``linprog``, see `gh-9269 <https://github.com/scipy/scipy/issues/9269>`__.
- Add functionality to the benchmark suite to compare results more easily
  (e.g. with summary plots).
- deprecate the ``fmin_*`` functions in the documentation, ``minimize`` is
  preferred.
- ``scipy.optimize`` has an extensive set of benchmarks for accuracy and speed of
  the global optimizers. That has allowed adding new optimizers (``shgo`` and
  ``dual_annealing``) with significantly better performance than the existing
  ones.  The ``optimize`` benchmark system itself is slow and hard to use
  however; we need to make it faster and make it easier to compare performance of
  optimizers via plotting performance profiles.


signal
``````
*Convolution and correlation*: (Relevant functions are convolve, correlate,
fftconvolve, convolve2d, correlate2d, and sepfir2d.) Eliminate the overlap with
`ndimage` (and elsewhere).  From ``numpy``, ``scipy.signal`` and ``scipy.ndimage``
(and anywhere else we find them), pick the "best of class" for 1-D, 2-D and n-d
convolution and correlation, put the implementation somewhere, and use that
consistently throughout SciPy.

*B-splines*: (Relevant functions are bspline, cubic, quadratic, gauss_spline,
cspline1d, qspline1d, cspline2d, qspline2d, cspline1d_eval, and spline_filter.)
Move the good stuff to `interpolate` (with appropriate API changes to match how
things are done in `interpolate`), and eliminate any duplication.

*Filter design*: merge `firwin` and `firwin2` so `firwin2` can be removed.

*Continuous-Time Linear Systems*: remove `lsim2`, `impulse2`, `step2`.  The
`lsim`, `impulse` and `step` functions now "just work" for any input system.
Further improve the performance of ``ltisys`` (fewer internal transformations
between different representations). Fill gaps in lti system conversion functions.

*Second Order Sections*: Make SOS filtering equally capable as existing
methods. This includes ltisys objects, an `lfiltic` equivalent, and numerically
stable conversions to and from other filter representations. SOS filters could
be considered as the default filtering method for ltisys objects, for their
numerical stability.

*Wavelets*: what's there now doesn't make much sense.  Continuous wavelets
only at the moment - decide whether to completely rewrite or remove them.
Discrete wavelet transforms are out of scope (PyWavelets does a good job
for those).


sparse
``````
The sparse matrix formats are mostly feature-complete, however the main issue
is that they act like ``numpy.matrix`` (which will be deprecated in NumPy at
some point).

What we want is sparse arrays, that act like ``numpy.ndarray``. In SciPy
``1.8.0`` a new set of classes (``csr_array`` et al.) has been added - these
need testing in the real world, as well as a few extra features like 1-D array
support.
An alternative (more ambitious, and unclear if it will materialize at this
point) plan is being worked on in https://github.com/pydata/sparse.  The
tentative plan for that was/is:

- Start depending on ``pydata/sparse`` once it's feature-complete enough (it
  still needs a CSC/CSR equivalent) and okay performance-wise.
- Add support for ``pydata/sparse`` to ``scipy.sparse.linalg`` (and perhaps to
  ``scipy.sparse.csgraph`` after that).
- Indicate in the documentation that for new code users should prefer
  ``pydata/sparse`` over sparse matrices.
- When NumPy deprecates ``numpy.matrix``, vendor that or maintain it as a
  stand-alone package.

Regarding the different sparse matrix formats: there are a lot of them.  These
should be kept, but improvements/optimizations should go into CSR/CSC, which
are the preferred formats.  LIL may be the exception, it's inherently
inefficient.  It could be dropped if DOK is extended to support all the
operations LIL currently provides.


sparse.csgraph
``````````````
This module is in good shape.


sparse.linalg
`````````````
There are a significant number of open issues for ``_arpack`` and ``lobpcg``.
``_propack`` is new in 1.8.0, TBD how robust it will turn out to be.

``_isolve``:

- callback keyword is inconsistent
- tol keyword is broken, should be relative tol
- Fortran code not re-entrant (but we don't solve, maybe re-use from
  PyKrilov)

``_dsolve``:

- add license-compatible sparse Cholesky or incomplete Cholesky
- add license-compatible sparse QR
- improve interface to SuiteSparse UMFPACK
- add interfaces to SuiteSparse CHOLMOD and SPQR


spatial
```````
QHull wrappers are in good shape, as is ``KDTree``.

A rewrite of ``spatial.distance`` metrics in C++ is in progress - this should
improve performance, make behaviour (e.g., for various non-float64 input
dtypes) more consistent, and fix a few remaining issues with definitions of the
math implement by a few of the metrics.


special
```````
Though there are still a lot of functions that need improvements in precision,
probably the only show-stoppers are hypergeometric functions, parabolic cylinder
functions, and spheroidal wave functions. Three possible ways to handle this:

1. Get good double-precision implementations. This is doable for parabolic
   cylinder functions (in progress). I think it's possible for hypergeometric
   functions, though maybe not in time. For spheroidal wavefunctions this is
   not possible with current theory.

2. Port Boost's arbitrary precision library and use it under the hood to get
   double precision accuracy. This might be necessary as a stopgap measure
   for hypergeometric functions; the idea of using arbitrary precision has
   been suggested before by @nmayorov and in
   `gh-5349 <https://github.com/scipy/scipy/issues/5349>`__.  Likely
   necessary for spheroidal wave functions, this could be reused:
   https://github.com/radelman/scattering.

3. Add clear warnings to the documentation about the limits of the existing
   implementations.


stats
`````

The ``scipy.stats`` subpackage aims to provide fundamental statistical
methods as might be covered in standard statistics texts such as Johnson's
"Miller & Freund's Probability and Statistics for Engineers", Sokal & Rohlf's
"Biometry", or Zar's "Biostatistical Analysis".  It does not seek to duplicate
the advanced functionality of downstream packages (e.g. StatsModels,
LinearModels, PyMC3); instead, it can provide a solid foundation on which
they can build.  (Note that these are rough guidelines, not strict rules.
"Advanced" is an ill-defined and subjective term, and "advanced" methods
may also be included in SciPy, especially if no other widely used and
well-supported package covers the topic.  Also note that *some* duplication
with downstream projects is inevitable and not necessarily a bad thing.)

The following improvements will help SciPy better serve this role.

- Add fundamental and widely used hypothesis tests:

  - Tukey-Kramer test
  - Dunnett's test
  - the various types of analysis of variance (ANOVA):

    - two-way ANOVA (single replicate, uniform number of replicates, variable
      number of replicates)
    - multiway ANOVA (i.e. generalize two-way ANOVA)
    - nested ANOVA
    - analysis of covariance (ANCOVA)

- Add additional tools for meta-analysis; currently we have just `combine_pvalues`.
- Enhance the `fit` method of the continuous probability distributions:

  - Expand the options for fitting to include:

    - maximal product spacings
    - method of L-moments / probability weighted moments

  - Include measures of goodness-of-fit in the results
  - Handle censored data (e.g. merge `gh-13699 <https://github.com/scipy/scipy/pull/13699>`__)

- Implement additional widely used continuous and discrete probability
  distributions, e.g. mixture distributions.

- Improve the core calculations provided by SciPy's probability distributions
  so they can robustly handle wide ranges of parameter values.  Specifically,
  replace many of the PDF and CDF methods from the Fortran library CDFLIB
  used in scipy.special with Boost implementations as in
  `gh-13328 <https://github.com/scipy/scipy/pull/13328>`__.

In addition, we should:

- Consistently handle ``nan_policy`` and ``axis`` arguments in all ``stats``
  functions (where appropriate).
- Continue work on making the function signatures of ``stats`` and
  ``stats.mstats`` more consistent, and add tests to ensure that that
  remains the case.
- Improve statistical tests: return confidence intervals for the test
  statistic, and implement exact p-value calculations - considering the
  possibility of ties - where computationally feasible.
.. _governance:

========================
SciPy Project Governance
========================

The purpose of this document is to formalize the governance process
used by the SciPy project in both ordinary and extraordinary
situations, and to clarify how decisions are made and how the various
elements of our community interact, including the relationship between
open source collaborative development and work that may be funded by
for-profit or non-profit entities.


The Project
===========

The SciPy Project (The Project) is an open source software project.
The goal of The Project is to develop open source software for scientific
computing in Python, and, in particular, the ``scipy`` package. The Software
developed by The Project is released under the BSD (or similar) open source
license, developed openly and hosted on public GitHub repositories under
the ``scipy`` GitHub organization.

The Project is developed by a team of distributed developers, called
Contributors. Contributors are individuals who have contributed code,
documentation, designs, or other work to the Project. Anyone can be a
Contributor. Contributors can be affiliated with any legal entity or
none. Contributors participate in the project by submitting, reviewing,
and discussing GitHub Pull Requests and Issues and participating in open
and public Project discussions on GitHub, mailing lists, and other
channels. The foundation of Project participation is openness and
transparency.

The Project Community consists of all Contributors and Users of the
Project. Contributors work on behalf of and are responsible to the
larger Project Community and we strive to keep the barrier between
Contributors and Users as low as possible.

The Project is not a legal entity, nor does it currently have any formal
relationships with legal entities.


Governance
==========

This section describes the governance and leadership model of The
Project.

The foundations of Project governance are:

-  openness and transparency
-  active contribution
-  institutional neutrality


Traditionally, Project leadership was provided by a subset of Contributors,
called Core Developers, whose active and consistent contributions have been
recognized by their receiving “commit rights” to the Project GitHub
repositories. In general, all Project decisions are made through consensus among
the Core Developers with input from the Community.

While this approach has served us well, as the Project grows, we see a need for
a more formal governance model. The SciPy Core Developers expressed a
preference for a leadership model which includes a BDFL (Benevolent Dictator
for Life). Therefore, moving forward The Project leadership will consist of a
BDFL and Steering Council.

BDFL
----

The Project will have a BDFL (Benevolent Dictator for Life), who is currently
Pauli Virtanen. As Dictator, the BDFL has the authority to make all final
decisions for The Project. As Benevolent, the BDFL, in practice, chooses to
defer that authority to the consensus of the community discussion channels and
the Steering Council (see below). It is expected, and in the past has been the
case, that the BDFL will only rarely assert his/her final authority. Because
rarely used, we refer to BDFL’s final authority as a “special” or “overriding”
vote. When it does occur, the BDFL override typically happens in situations
where there is a deadlock in the Steering Council or if the Steering Council
asks the BDFL to make a decision on a specific matter. To ensure the
benevolence of the BDFL, The Project encourages others to fork the project if
they disagree with the overall direction the BDFL is taking. The BDFL may
delegate his/her authority on a particular decision or set of decisions to
any other Council member at his/her discretion.

The BDFL can appoint his/her successor, but it is expected that the Steering
Council would be consulted on this decision. If the BDFL is unable to appoint a
successor, the Steering Council will make this decision - preferably by
consensus, but if needed, by a majority vote.

Note that the BDFL can step down at any time, and acting in good faith, will
also listen to serious calls to do so. Also note that the BDFL is more a role
for fallback decision making rather than that of a director/CEO.

Steering Council
----------------

The Project will have a Steering Council that consists of Project Contributors
who have produced contributions that are substantial in quality and quantity,
and sustained over at least one year. The overall role of the Council is to
ensure, through working with the BDFL and taking input from the Community, the
long-term well-being of the project, both technically and as a community.

The Council will have a Chair, who is tasked with keeping the organizational
aspects of the functioning of the Council and the Project on track. The
Council will also appoint a Release Manager for the Project, who has final
responsibility for one or more releases.

During the everyday project activities, Council Members participate in all
discussions, code review, and other project activities as peers with all other
Contributors and the Community. In these everyday activities, Council Members
do not have any special power or privilege through their membership on the
Council. However, it is expected that because of the quality and quantity of
their contributions and their expert knowledge of the Project Software and
Services, Council Members will provide useful guidance, both technical and
in terms of project direction, to potentially less experienced contributors.

The Steering Council and its Members play a special role in certain situations.
In particular, the Council may:

-   Make decisions about the overall scope, vision, and direction of the
    project.
-   Make decisions about strategic collaborations with other organizations or
    individuals.
-   Make decisions about specific technical issues, features, bugs, and pull
    requests. They are the primary mechanism of guiding the code review process
    and merging pull requests.
-   Make decisions about the Services that are run by The Project and manage
    those Services for the benefit of the Project and Community.
-   Make decisions when regular community discussion does not produce consensus
    on an issue in a reasonable time frame.
-  Update policy documents, such as this one.

Council membership
~~~~~~~~~~~~~~~~~~

To become eligible for being a Steering Council Member, an individual must be a
Project Contributor who has produced contributions that are substantial in
quality and quantity, and sustained over at least one year. Potential Council
Members are nominated by existing Council members and voted upon by the
existing Council after asking if the potential Member is interested and willing
to serve in that capacity. The Council will be initially formed from the set of
existing Core Developers who, as of January 2017, have been significantly
active over the last two years.

When considering potential Members, the Council will look at candidates with a
comprehensive view of their contributions. This will include, but is not limited
to, code, code review, infrastructure work, mailing list and chat participation,
community help/building, education and outreach, design work, etc. We are
deliberately not setting arbitrary quantitative metrics (like “100 commits in
this repo”) to avoid encouraging behavior that plays to the metrics rather than
the project’s overall well-being. We want to encourage a diverse array of
backgrounds, viewpoints, and talents in our team, which is why we explicitly do
not define code as the sole metric on which council membership will be
evaluated.

If a Council Member becomes inactive in the project for a period of one year,
they will be considered for removal from the Council. Before removal, inactive
Member will be approached to see if they plan on returning to active
participation. If not, they will be removed immediately upon a Council
vote. If they plan on returning to active participation soon, they will be
given a grace period of one year. If they don’t return to active participation
within that time period they will be removed by vote of the Council without
further grace period. All former Council Members can be considered for
membership again at any time in the future, like any other Project Contributor.
Retired Council Members will be listed on the project website, acknowledging
the period during which they were active in the Council.

The Council reserves the right to eject current Members, other than the BDFL,
if they are deemed to be actively harmful to the project’s well-being, and
attempts at communication and conflict resolution have failed.

A list of current Steering Council Members is maintained at the
page `About us <https://scipy.org/about/>`_.

Council Chair
~~~~~~~~~~~~~

The Chair will be appointed by the Steering Council. The Chair can stay on as
long as he/she wants, but may step down at any time and will listen to
serious calls to do so (similar to the BDFL role). The Chair will be
responsible for:

- Starting a review of the technical direction of the project (as captured by
  the :ref:`scipy-roadmap`) bi-yearly, around mid-April and mid-October.
- At the same times of the year, summarizing any relevant
  organizational updates and issues in the preceding period, and asking for
  feedback/suggestions on the mailing list.
- Ensuring the composition of the Steering Council stays current.
- Ensuring matters discussed in private by the Steering Council get
  summarized on the mailing list to keep the Community informed.
- Ensuring other important organizational documents (e.g., Code of Conduct,
  Fiscal Sponsorship Agreement) stay current after they are added.

Release Manager
~~~~~~~~~~~~~~~

The Release Manager has final responsibility for making a release.  This
includes:

- Proposing of and deciding on the timing of a release.
- Determining the content of a release in case there is no consensus on a
  particular change or feature.
- Creating the release and announcing it on the relevant public channels.

For more details on what those responsibilities look like in practice, see
:ref:`making-a-release`.

Conflict of interest
~~~~~~~~~~~~~~~~~~~~

It is expected that the BDFL and Council Members will be employed at a wide
range of companies, universities, and non-profit organizations. Because of this,
it is possible that Members will have a conflict of interest. Such conflicts of
interest include, but are not limited to:

-   Financial interest, such as investments, employment or contracting work,
    outside of The Project that may influence their work on The Project.
-   Access to proprietary information of their employer that could potentially
    leak into their work with the Project.

All members of the Council, BDFL included, shall disclose to the rest of the
Council any conflict of interest they may have. Members with a conflict of
interest in a particular issue may participate in Council discussions on that
issue, but must recuse themselves from voting on the issue. If the BDFL has
recused his/herself for a particular decision, the Council will appoint a
substitute BDFL for that decision.

Private communications of the Council
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Unless specifically required, all Council discussions and activities will be
public and done in collaboration and discussion with the Project Contributors
and Community. The Council will have a private mailing list that will be used
sparingly and only when a specific matter requires privacy. When private
communications and decisions are needed, the Council will do its best to
summarize those to the Community after removing personal/private/sensitive
information that should not be posted to the public internet.

Council decision making
~~~~~~~~~~~~~~~~~~~~~~~

If it becomes necessary for the Steering Council to produce a formal
decision, then they will use a form of the `Apache Foundation voting
process <https://www.apache.org/foundation/voting.html>`_. This is a
formalized version of consensus, in which +1 votes indicate agreement,
-1 votes are vetoes (and must be accompanied with a rationale, as
above), and one can also vote fractionally (e.g. -0.5, +0.5) if one
wishes to express an opinion without registering a full veto. These
numeric votes are also often used informally as a way of getting a
general sense of people's feelings on some issue, and should not
normally be taken as formal votes. A formal vote only occurs if
explicitly declared, and if this does occur, then the vote should be held
open for long enough to give all interested Council Members a chance to
respond -- at least one week.

In practice, we anticipate that for most Steering Council decisions
(e.g., voting in new members) a more informal process will suffice.


Institutional Partners and funding
==================================

The Steering Council is the primary leadership for the project. No
outside institution, individual, or legal entity has the ability to own,
control, usurp, or influence the project other than by participating in
the Project as Contributors and Council Members. However, because
institutions can be an important funding mechanism for the project, it
is important to formally acknowledge institutional participation in the
project. These are Institutional Partners.

An Institutional Contributor is any individual Project Contributor who
contributes to the project as part of their official duties at an
Institutional Partner. Likewise, an Institutional Council Member is any
Project Steering Council Member who contributes to the project as part
of their official duties at an Institutional Partner.

With these definitions, an Institutional Partner is any recognized legal
entity in any country that employs at least 1 Institutional Contributor or
Institutional Council Member. Institutional Partners can be for-profit or
non-profit entities.

Institutions become eligible to become an Institutional Partner by
employing individuals who actively contribute to The Project as part of
their official duties. To state this another way, the only way for a
Partner to influence the project is by actively contributing to the open
development of the project, in equal terms to any other member of the
community of Contributors and Council Members. Merely using Project
Software in institutional context does not allow an entity to become an
Institutional Partner. Financial gifts do not enable an entity to become
an Institutional Partner. Once an institution becomes eligible for
Institutional Partnership, the Steering Council must nominate and
approve the Partnership.

If, at some point, an existing Institutional Partner stops having any
contributing employees, then a one year grace period commences. If, at
the end of this one-year period, they continue not to have any
contributing employees, then their Institutional Partnership will
lapse, and resuming it will require going through the normal process
for new Partnerships.

An Institutional Partner is free to pursue funding for their work on The
Project through any legal means. This could involve a non-profit
organization raising money from private foundations and donors or a
for-profit company building proprietary products and services that
leverage Project Software and Services. Funding acquired by
Institutional Partners to work on The Project is called Institutional
Funding. However, no funding obtained by an Institutional Partner can
override the Steering Council. If a Partner has funding to do SciPy work
and the Council decides to not pursue that work as a project, the
Partner is free to pursue it on their own. However, in this situation,
that part of the Partner’s work will not be under the SciPy umbrella and
cannot use the Project trademarks in any way that suggests a formal
relationship.

Institutional Partner benefits are:

-  acknowledgement on the SciPy website and in talks
-  ability to acknowledge their own funding sources on the SciPy
   website and in talks
-  ability to influence the project through the participation of their
   Council Member
-  invitation of the Council Members to SciPy Developer Meetings

A list of current Institutional Partners is maintained at the page
`About us <https://scipy.org/about/>`_.


Document history
================

https://github.com/scipy/scipy/commits/master/doc/source/dev/governance/governance.rst

Acknowledgements
================

Substantial portions of this document were adapted from the
`Jupyter/IPython project's governance document
<https://github.com/jupyter/governance/blob/master/governance.md>`_ and
`NumPy's governance document
<https://github.com/numpy/numpy/blob/main/doc/source/dev/governance/governance.rst>`_.

License
=======

To the extent possible under law, the authors have waived all
copyright and related or neighboring rights to the SciPy project
governance document, as per the `CC-0 public domain dedication / license
<https://creativecommons.org/publicdomain/zero/1.0/>`_.
.. include:: ../../../HACKING.rst.txt
.. _toolchain-roadmap:

Toolchain Roadmap
=================

The use of the SciPy library requires (or optionally depends upon) several
other libraries in order to operate, the main dependencies being Python
and NumPy. It requires a larger collection of libraries and tools in order
to build the library or to build the documentation.

Of course, the tooling and libraries are themselves not static.
This document aims to provide a guide as to how SciPy's use of
these dynamic dependencies will proceed over time.

SciPy aims to be compatible with a number of releases of its dependent
libraries and tools. Forcing the user base to other components for upgrade
for every release would greatly diminish the value of SciPy. However,
maintaining backwards compatibility with very old tooling/libraries
imposes limitations on which newer functionalities and capabilities
can be incorporated.
SciPy takes a somewhat conservative approach, maintaining compatibility with
several major releases of Python and NumPy on the major platforms.
(That may in and of itself impose further restrictions. See the C Compilers
section for an example.)


- First and foremost, SciPy is a Python project, hence it requires a Python environment.
- BLAS and LAPACK numerical libraries need to be installed.
- Compilers for C, C++, Fortran code are needed, as well as for Cython & Pythran (the latter is opt-out currently)
- The Python environment needs the ``NumPy`` package to be installed.
- Testing requires the ``pytest`` Python package.
- Building the documentation requires the ``matplotlib``, Sphinx packages along with PyData theme,
  as well as a LaTeX installation.

The tooling used to build CPython has some implications for the tooling used
in building SciPy.
It also has implications for the examples used in the
documentation (e.g., docstrings for functions),
as these examples can only use functionality present in all supported configurations.


Building SciPy
--------------

Python Versions
^^^^^^^^^^^^^^^

SciPy is compatible with several versions of Python.  When dropping support for
older Python versions, SciPy takes guidance from NEP 29 [1]_.  Python 2.7
support was dropped starting from SciPy 1.3.

================  =======================================================================
 Date             Pythons supported
================  =======================================================================
 2018              Py2.7, Py3.4+ (SciPy 1.2.x is the last release to support Python 2.7)
 2019              Py3.5+ (but Py2.7-specific code not removed)
 2020              Py3.6+ (removal of Py2.7-specific code permitted)
 2021              Py3.7+
 2022              Py3.8+
================  =======================================================================

NumPy
^^^^^

SciPy depends on NumPy but releases of SciPy are not tied to releases of NumPy.
SciPy attempts to be compatible with at least the 4 previous releases of NumPy.
In particular, SciPy cannot rely on features of just the latest NumPy, but
needs to be written using what is common in all of those 4 releases [2]_.

The table shows the NumPy versions suitable for each major Python version.

=================  ========================    =======================
 SciPy version      Python versions             NumPy versions
=================  ========================    =======================
 1.2                2.7, >=3.4, <=3.7           >=1.8.2, <= 1.16.x
 1.4                >=3.5, <=3.8                >=1.13.3, <= 1.17.3
 1.5                >=3.6, <=3.9                >=1.14.5, <= 1.19.3
 1.6                >=3.7, <=3.9                >=1.16.5, <= 1.20.x
 1.7.0/1            >=3.7, <3.10                >=1.16.5, <1.23.0
 1.7.2-x            >=3.7, <3.11                >=1.16.5, <1.24.0
 1.8                >=3.8, <3.11                >=1.17.3, <1.24.0
=================  ========================    =======================

In specific cases, such as a particular architecture, these requirements
could vary. Please check the release notes [3]_ and the meta-package
``oldest-supported-numpy`` for more info [4]_.


Compilers
^^^^^^^^^

Building SciPy requires compilers for C, C++, Fortran, as well as the
python transpilers Cython and Pythran (the latter is an opt-out dependency
starting from version 1.7.0).

To maintain compatibility with a large number of platforms & setups, especially
where using the official wheels (or other distribution channels like Anaconda
or conda-forge) is not possible, SciPy keeps compatibility with old compilers.

Official Builds
~~~~~~~~~~~~~~~

Currently, SciPy wheels are being built as follows:

================  ========================  ===========================  ==============================
 Platform          Azure Base Image [5]_     Compilers                    Comment
================  ========================  ===========================  ==============================
Linux (nightly)    ``ubuntu-18.04``          GCC 6.5                      See ``azure-pipelines.yml``
Linux (release)    ``ubuntu-18.04``          GCC 7.5                      Built in separate repo [6]_
OSX                ``macOS-10.15``           LLVM 12.0.0                  Built in separate repo [6]_
Windows            ``windows-latest``        Visual Studio 2019 (16.11)   See ``azure-pipelines.yml``
================  ========================  ===========================  ==============================

Note that the OSX wheels additionally vendor gfortran 4.9,
see submodule ``gfortran-install`` in [6]_.


C Compilers
~~~~~~~~~~~

SciPy is compatible with most modern C compilers (in particular ``clang``).
In addition to concerns about compatibility with non-standard platforms,
there was a long-standing restriction that Windows builds of SciPy had to use
the same version of the Microsoft Visual C++ compiler as were used for CPython
itself, for reasons of ABI-compatibility [7]_, [8]_.

With the introduction of the "Universal C Runtime" [9]_ since the release of
Visual Studio 2015, this restriction has been lifted. For more context, see the
explanations by Steve Dower (member of the CPython-on-Windows core developers)
on this topic [10]_.

The use of MS Visual Studio 9.0 (which doesn't have support for C99)
to build Python 2.7 has meant that C code in SciPy has had to conform
to the earlier C90 standard for the language and standard library.
With the dropping of Python 2.7 for SciPy 1.3.x, the C90 restriction is no
longer imposed by compilers.

In terms of C language standards, it's relevant to note that C11 has optional
features [11]_ (e.g. atomics, threading), some of which (VLAs & complex types)
were mandatory in the C99 standard. C17 (occasionally called C18) can be
considered a bug fix for C11, so generally, C11 may be skipped entirely.

SciPy has been restricted in the use of more advanced language features by the
available compiler support, and Microsoft in particular has taken very long to
achieve conformance to C99/C11/C17, however starting from MS Visual Studio 16.8,
C11/C17 is supported [12]_ (though without the C11 optional features).
C99 ``<complex.h>`` would be particularly interesting for SciPy;
MSVC conformance for this is being tracked here [13]_.

Therefore, using C features beyond C90 was only possible insofar there was support on
windows; however, as of as of the end of 2021, a sufficiently recent compiler is used.
This is because GCC & LLVM support all relevant C11 features with the oldest currently
used versions, and C17 is just a bugfix for C11, as mentioned above. In short:

================  =======================================================================
 Date              C Standard
================  =======================================================================
 <= 2018           C90
 2019              C90 for old code, may consider C99 for new
 2020              C99 (no ``<complex.h>``, ``<stdatomic.h>``, ``<threads.h>`` & VLAs)
 2021              C17 (no ``<complex.h>``, ``<stdatomic.h>``, ``<threads.h>`` & VLAs)
 ?                 C23, ``<complex.h>``, ``<stdatomic.h>``, ...
================  =======================================================================


C++ Language Standards
~~~~~~~~~~~~~~~~~~~~~~

C++ language standards for SciPy are generally guidelines
rather than official decisions. This is particularly true of
attempting to predict adoption timelines for newer standards.

================  =======================================================================
 Date              C++ Standard
================  =======================================================================
 <= 2019           C++03
 2020              C++11
 2021              C++14
 ?                 C++17, C++20, C++23
================  =======================================================================

Since dropping support for Python 2.7, C++11 can be used
universally, and since dropping Python 3.6, the Visual Studio version
(that had previously been stuck with 14.0 due to ABI compatibility with
CPython) has been recent enough to support even C++17.

Since the official builds (see above) use a pretty recent version of LLVM,
the bottleneck for C++ support is therefore the oldest supported GCC version,
where SciPy has been constrained mainly by the version in the oldest supported
manylinux versions & images [14]_.

At the end of 2021 (with the final removal of ``manylinux1`` wheels), SciPy
now has a minimum GCC requirement of GCC 6.3, which has full C++14 support
[15]_. This corresponds to the lowest present GCC version in relevant manylinux
versions - somewhat surprisingly, it is not the oldest remaining
``manylinux2010`` that is the most restrictive (due to the ABI-compatible
"RHEL Dev Toolset" backports, it has GCC 8.3), but actually ``manylinux_2_24``
that only comes with GCC 6.3 [16]_.

C++17 _language_ support will require GCC >= 7 (released May 2017). As of the
end of 2021, support for the entirety of the C++17 standard library has not yet
been completed across all compilers; similarly, support for C++20 and C++23
is still under heavy development. [15]_

Fortran Compilers
~~~~~~~~~~~~~~~~~

Generally, any well-maintained compiler is likely suitable and can be
used to build SciPy.

======== ==================
 Tool     Version
======== ==================
gfortran   >= 4.8.0
ifort     A recent version
flang     A recent version
======== ==================


Cython & Pythran
~~~~~~~~~~~~~~~~

SciPy always requires a recent Cython compiler. Since 1.7, Pythran
is a build dependency (currently with the possibility to opt out).


OpenMP support
^^^^^^^^^^^^^^

For various reasons [17]_, SciPy cannot be distributed with built-in OpenMP support.
When using the optional Pythran support, OpenMP-enabled parallel code can be
generated when building from source.

Other Libraries
^^^^^^^^^^^^^^^

Any library conforming to the BLAS/LAPACK interface may be used.
OpenBLAS, ATLAS, MKL, BLIS, and reference Netlib libraries are known to work.

=============== =====================================================
 Library           Minimum version
=============== =====================================================
LAPACK           3.4.1
BLAS             A recent version of OpenBLAS, MKL or ATLAS.
                 The Accelerate BLAS library is no longer supported.
=============== =====================================================


There are some additional optional dependencies.

=============== ======== ==========================================
 Library        Version   URL
=============== ======== ==========================================
mpmath          Recent    http://mpmath.org/
scikit-umfpack  Recent    https://pypi.org/project/scikit-umfpack/
=============== ======== ==========================================


Moreover, Scipy supports interaction with other libraries. The test suite
has additional compatibility tests that are run when these are installed:

=========================  ========  ====================================
 Tool                      Version    URL
=========================  ========  ====================================
pydata/sparse              Recent     https://github.com/pydata/sparse/
=========================  ========  ====================================


Testing and Benchmarking
--------------------------

Testing and benchmarking require recent versions of:

=========================  ========  ====================================
 Tool                      Version    URL
=========================  ========  ====================================
pytest                     Recent     https://docs.pytest.org/en/latest/
asv (airspeed velocity)    Recent     https://asv.readthedocs.io/
=========================  ========  ====================================


Building the Documentation
--------------------------

====================  =================================================
 Tool                 Version
====================  =================================================
Sphinx                Whatever recent versions work. >= 2.0.
PyData Sphinx theme   Whatever recent versions work. >= 0.6.1.
Sphinx-Panels         Whatever recent versions work. >= 0.5.2.
numpydoc              Whatever recent versions work. >= 0.8.0.
matplotlib            Generally suggest >= 2.0.
LaTeX                 A recent distribution, such as ``TeX Live 2016``.
====================  =================================================

[The ``numpydoc`` package is also used, but that is currently
packaged in ``doc/sphinxext``.]


.. note::

    Developer Note: The versions of ``numpy`` and ``matplotlib`` required have
    implications for the examples in Python docstrings.
    Examples must be able to be executed both in the environment used to
    build the documentation,
    as well as with any supported versions of ``numpy/matplotlib`` that
    a user may use with this release of SciPy.


Packaging
---------

A Recent version of:

=============  ========  =============================================
 Tool          Version    URL
=============  ========  =============================================
setuptools     Recent     https://pypi.org/project/setuptools/
wheel          Recent     https://pythonwheels.com
multibuild     Recent     https://github.com/matthew-brett/multibuild
=============  ========  =============================================

:ref:`making-a-release` and :ref:`distributing-a-release` contain information on
making and distributing a SciPy release.

References
----------

.. [1] https://numpy.org/neps/nep-0029-deprecation_policy.html
.. [2] https://numpy.org/doc/stable/release.html
.. [3] https://scipy.github.io/devdocs/release.html
.. [4] https://github.com/scipy/oldest-supported-numpy
.. [5] https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted
.. [6] https://github.com/MacPython/scipy-wheels
.. [7] https://pythondev.readthedocs.io/windows.html#python-and-visual-studio-version-matrix
.. [8] https://en.wikipedia.org/wiki/Microsoft_Visual_C%2B%2B#Internal_version_numbering
.. [9] https://docs.microsoft.com/en-gb/cpp/windows/universal-crt-deployment
.. [10] https://discuss.python.org/t/toolchain-upgrade-on-windows/6377/4
.. [11] https://en.wikipedia.org/wiki/C11_%28C_standard_revision%29#Optional_features
.. [12] https://devblogs.microsoft.com/cppblog/c11-and-c17-standard-support-arriving-in-msvc/
.. [13] https://developercommunity.visualstudio.com/t/Support-for-C99-Complex-numbers/1409049?space=8&q=complex
.. [14] https://github.com/mayeut/pep600_compliance
.. [15] https://en.cppreference.com/w/cpp/compiler_support
.. [16] https://github.com/pypa/manylinux/issues/1012
.. [17] https://github.com/scipy/scipy/issues/10239
.. _scipy-roadmap:

SciPy Roadmap
=============

This roadmap page contains only the most important ideas and needs for SciPy
going forward.  For a more detailed roadmap, including per-subpackage status,
many more ideas, API stability and more, see :ref:`scipy-roadmap-detailed`.


Support for distributed arrays and GPU arrays
---------------------------------------------

NumPy has split its API from its execution engine with
``__array_function__`` and ``__array_ufunc__``.  This will enable parts of SciPy
to accept distributed arrays (e.g. ``dask.array.Array``) and GPU arrays (e.g.
``cupy.ndarray``) that implement the ``ndarray`` interface.  At the moment it is
not yet clear which algorithms will work out of the box, and if there are
significant performance gains when they do.  We want to create a map of which
parts of the SciPy API work, and improve support over time.

In addition to making use of NumPy protocols like ``__array_function__``, we can
make use of these protocols in SciPy as well.  That will make it possible to
(re)implement SciPy functions like, e.g., those in ``scipy.signal`` for Dask
or GPU arrays (see
`NEP 18 - use outside of NumPy <http://www.numpy.org/neps/nep-0018-array-function-protocol.html#use-outside-of-numpy>`__).  NumPy's features in this areas are still evolving,
see e.g. `NEP 37 - A dispatch protocol for NumPy-like modules <https://numpy.org/neps/nep-0037-array-module.html>`__,
and SciPy is an important "client" for those features.


Performance improvements
------------------------

Speed improvements, lower memory usage and the ability to parallelize
algorithms are beneficial to most science domains and use cases.  We have
established an API design pattern for multiprocessing - using the ``workers``
keyword - that can be adopted in many more functions.

Enabling the use of an accelerator like Pythran, possibly via Transonic, and
making it easier for users to use Numba's ``@njit`` in their code that relies
on SciPy functionality would unlock a lot of performance gain.  That needs a
strategy though, all solutions are still maturing (see for example
`this overview <https://fluiddyn.bitbucket.io/transonic-vision.html>`__).

Finally, many individual functions can be optimized for performance.
``scipy.optimize`` and ``scipy.interpolate`` functions are particularly often
requested in this respect.


Statistics enhancements
-----------------------

The `scipy.stats` enhancements listed in the :ref:`scipy-roadmap-detailed` are of
particularly high importance to the project.

- Improve the options for fitting a probability distribution to data.
- Expand the set of hypothesis tests.  In particular, include all the basic
  variations of analysis of variance.
- Add confidence intervals for all statistical tests.


Support for more hardware platforms
-----------------------------------

SciPy now has continuous integration for ARM64 (or ``aarch64``) and POWER8/9
(or ``ppc64le``), and binaries are available via
`Miniforge <https://github.com/conda-forge/miniforge>`__.  Wheels on PyPI for
these platforms are now also possible (with the ``manylinux2014`` standard),
and requests for those are becoming more frequent.

Additionally, having IBM Z (or ``s390x``) in CI is now possible with TravisCI
but not yet done - and ``manylinux2014`` wheels for that platform are also
possible then.  Finally, resolving open AIX build issues would help users.


Implement sparse arrays in addition to sparse matrices
------------------------------------------------------

The sparse matrix formats are mostly feature-complete, however the main issue
is that they act like ``numpy.matrix`` (which will be deprecated in NumPy at
some point).  What we want is sparse *arrays* that act like ``numpy.ndarray``.
This is being worked on in https://github.com/pydata/sparse, which is quite far
along.  The tentative plan is:

- Start depending on ``pydata/sparse`` once it's feature-complete enough (it
  still needs a CSC/CSR equivalent) and okay performance-wise.
- Indicate in the documentation that for new code users should prefer
  ``pydata/sparse`` over sparse matrices.
- When NumPy deprecates ``numpy.matrix``, vendor that or maintain it as a
  stand-alone package.
.. _scipy-development:

Developer Documentation
-----------------------

Bellow you will find general information about contributing.
For an overview of where help or new features are desired or planned, see
the roadmap. And for a more detailed look at how the SciPy project works, see
the organization section.

.. toctree::
   :maxdepth: 1
   :caption: Contributing Information

   conduct/code_of_conduct
   hacking
   contributor/quickerstart_conda
   contributor/contributor_toc

.. toctree::
   :maxdepth: 1
   :caption: Roadmap

   roadmap
   roadmap-detailed
   toolchain

.. toctree::
   :maxdepth: 1
   :caption: SciPy Organization

   core-dev/index
   api-dev/api-dev-toc
   governance

.. This toctree defines previous/next for contributor guide documents
.. toctree::
   :hidden:

   contributor/quickstart_mac
   contributor/quickstart_ubuntu
   contributor/development_workflow
   contributor/pep8
   contributor/rendering_documentation
   contributor/runtests
   contributor/benchmarking
   contributor/cython
   contributor/public_cython_api
   contributor/adding_new
   contributor/continuous_integration
   contributor/meson
   contributor/using_act

.. These files are not intended to be in any toctree. because they have not
   been maintained.They should only be reached via the contributor guide if
   they are specifically sought, not via next/previous links.
..   building/index
..   dev/gitwash/gitwash
..   dev/contributor/recommended_development_setup
..   dev/contributor/compiled_code
:orphan:

.. _CoC_reporting_manual:

SciPy Code of Conduct - How to follow up on a report
----------------------------------------------------

This is the manual followed by SciPy's Code of Conduct Committee. It's used
when we respond to an issue to make sure we're consistent and fair.

Enforcing the Code of Conduct impacts our community today and for the future.
It's an action that we do not take lightly. When reviewing enforcement
measures, the Code of Conduct Committee will keep the following values and
guidelines in mind:

* Act in a personal manner rather than impersonal. The Committee can engage
  the parties to understand the situation, while respecting the privacy and any
  necessary confidentiality of reporters. However, sometimes, it is necessary
  to communicate with one or more individuals directly: the Committee's goal is
  to improve the health of our community rather than only produce a formal
  decision.

* Emphasize empathy for individuals rather than judging behavior, avoiding
  binary labels of "good" and "bad/evil". Overt, clear-cut aggression and
  harassment exists and we will be address that firmly. But many scenarios
  that can prove challenging to resolve are those where normal disagreements
  devolve into unhelpful or harmful behavior from multiple parties.
  Understanding the full context and finding a path that re-engages all is
  hard, but ultimately the most productive for our community.

* We understand that email is a difficult medium and can be isolating.
  Receiving criticism over email, without personal contact, can be
  particularly painful. This makes it especially important to keep an
  atmosphere of open-minded respect of the views of others. It also means
  that we must be transparent in our actions, and that we will do everything
  in our power to make sure that all our members are treated fairly and with
  sympathy.

* Discrimination can be subtle and it can be unconscious. It can show itself
  as unfairness and hostility in otherwise ordinary interactions. We know
  that this does occur, and we will take care to look out for it. We would
  very much like to hear from you if you feel you have been treated unfairly,
  and we will use these procedures to make sure that your complaint is heard
  and addressed.

* Help increase engagement in good discussion practice: try to identify where
  discussion may have broken down and provide actionable information, pointers
  and resources that can lead to positive change on these points.

* Be mindful of the needs of new members: provide them with explicit support
  and consideration, with the aim of increasing participation from
  underrepresented groups in particular.

* Individuals come from different cultural backgrounds and native languages.
  Try to identify any honest misunderstandings caused by a non-native speaker
  and help them understand the issue and what they can change to avoid causing
  offense. Complex discussion in a foreign language can be very intimidating,
  and we want to grow our diversity also across nationalities and cultures.

*Mediation*: voluntary, informal mediation is a tool at our disposal. In
contexts, such as when two or more parties have all escalated to the point of
inappropriate behavior (something sadly common in human conflict), it may be
useful to facilitate a mediation process. This is only an example: the
Committee can consider mediation in any case, mindful that the process is meant
to be strictly voluntary and no party can be pressured to participate. If the
Committee suggests mediation, it should:

* Find a candidate who can serve as a mediator.
* Obtain the agreement of the reporter(s). The reporter(s) have complete
  freedom to decline the mediation idea, or to propose an alternate mediator.
* Obtain the agreement of the reported person(s).
* Settle on the mediator: while parties can propose a different mediator than
  the suggested candidate, only if common agreement is reached on all terms can
  the process move forward.
* Establish a timeline for mediation to complete, ideally within two weeks.

The mediator will engage with all the parties and seek a resolution that is
satisfactory to all. Upon completion, the mediator will provide a report
(vetted by all parties to the process) to the Committee, with recommendations
on further steps. The Committee will then evaluate these results (whether
satisfactory resolution was achieved or not) and decide on any additional
action deemed necessary.


How the committee will respond to reports
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When the committee (or a committee member) receives a report, they will first
determine whether the report is about a clear and severe breach (as defined
below). If so, immediate action needs to be taken in addition to the regular
report-handling process.

Clear and severe breach actions
+++++++++++++++++++++++++++++++

We know that it is painfully common for internet communication to start at or
devolve into obvious and flagrant abuse. We will deal quickly with clear and
severe breaches like personal threats, violent, sexist, or racist language.

When a member of the Code of Conduct committee becomes aware of a clear and
severe breach, they will do the following:

* Immediately disconnect the originator from all SciPy communication channels.
* Reply to the reporter that their report has been received and that the
  originator has been disconnected.
* In every case, the moderator should make a reasonable effort to contact the
  originator, and tell them specifically how their language or actions
  qualify as a "clear and severe breach". The moderator should also say
  that, if the originator believes this is unfair or they want to be
  reconnected to SciPy, they have the right to ask for a review, as below, by
  the Code of Conduct Committee.
  The moderator should copy this explanation to the Code of Conduct Committee.
* The Code of Conduct Committee will formally review and sign off on all cases
  where this mechanism has been applied to make sure it is not being used to
  control ordinary heated disagreement.

Report handling
+++++++++++++++

When a report is sent to the committee, they will immediately reply to the
reporter to confirm receipt. This reply must be sent within 72 hours, and the
group should strive to respond much quicker than that.

If a report doesn't contain enough information, the committee will obtain all
relevant data before acting. The committee is empowered to act on the Steering
Council’s behalf in contacting any individuals involved to get a more complete
account of events.

The committee will then review the incident and determine, to the best of their
ability:

* What happened.
* Whether this event constitutes a Code of Conduct violation.
* Who are the responsible party(ies).
* Whether this is an ongoing situation, and there is a threat to anyone's
  physical safety.

This information will be collected in writing, and whenever possible the
group's deliberations will be recorded and retained (i.e., chat transcripts,
email discussions, recorded conference calls, summaries of voice conversations,
etc.).

It is important to retain an archive of all activities of this committee to
ensure consistency in behavior and provide institutional memory for the
project. To assist in this, the default channel of discussion for this
committee will be a private mailing list accessible to current and future
members of the committee as well as members of the Steering Council upon
justified request. If the Committee finds the need to use off-list
communications (e.g., phone calls for early/rapid response), it should, in all
cases, summarize these back to the list so there's a good record of the process.

The Code of Conduct Committee should aim to have a resolution agreed upon within
two weeks. In the event that a resolution can't be determined in that time, the
committee will respond to the reporter(s) with an update and projected timeline
for the resolution.


.. _CoC_resolutions:

Resolutions
~~~~~~~~~~~

The committee must agree on a resolution by consensus. If the group cannot reach
consensus and deadlocks for over a week, the group will turn the matter over to
the Steering Council for resolution.


Possible responses may include:

* Taking no further action:

  - if we determine no violations have occurred.
  - if the matter has been resolved publicly while the committee was considering responses.

* Coordinating voluntary mediation: if all involved parties agree, the
  Committee may facilitate a mediation process as detailed above.
* Remind publicly, and point out that some behavior/actions/language have been
  judged inappropriate and why in the current context, or can but hurtful to
  some people, requesting the community to self-adjust.
* A private reprimand from the committee to the individual(s) involved. In this
  case, the group chair will deliver that reprimand to the individual(s) over
  email, cc'ing the group.
* A public reprimand. In this case, the committee chair will deliver that
  reprimand in the same venue that the violation occurred, within the limits of
  practicality. E.g., the original mailing list for an email violation, but
  for a chat room discussion where the person/context may be gone, they can be
  reached by other means. The group may choose to publish this message
  elsewhere for documentation purposes.
* A request for a public or private apology, assuming the reporter agrees to
  this idea: they may, at their discretion, refuse further contact with the
  violator. The chair will deliver this request. The committee may, if it
  chooses, attach "strings" to this request: for example, the group may ask a
  violator to apologize, in order to retain one’s membership on a mailing list.
* A "mutually agreed upon hiatus" where the committee asks the individual to
  temporarily refrain from community participation. If the individual chooses
  not to take a temporary break voluntarily, the committee may issue a
  "mandatory cooling off period".
* A permanent or temporary ban from some or all SciPy spaces (mailing lists,
  gitter.im, etc.). The group will maintain records of all such bans so that
  they may be reviewed in the future or otherwise maintained.

Once a resolution is agreed upon, but before it is enacted, the committee will
contact the original reporter and any other affected parties and explain the
proposed resolution. The committee will ask if this resolution is acceptable,
and must note feedback for the record.

Finally, the committee will make a report to the SciPy Steering Council (as
well as the SciPy core team in the event of an ongoing resolution, such as a
ban).

The committee will never publicly discuss the issue; all public statements will
be made by the chair of the Code of Conduct Committee or the SciPy Steering
Council.


Conflicts of interest
~~~~~~~~~~~~~~~~~~~~~

In the event of any conflict of interest, a committee member must immediately
notify the other members, and recuse themselves if necessary.
SciPy Code of Conduct
=====================


Introduction
------------

This code of conduct applies to all spaces managed by the SciPy project,
including all public and private mailing lists, issue trackers, wikis, blogs,
Twitter, and any other communication channel used by our community. The SciPy
project does not organize in-person events, however, events related to our
community should have a code of conduct similar in spirit to this one.

This code of conduct should be honored by everyone who participates in
the SciPy community formally or informally, or claims any affiliation with the
project, in any project-related activities, and, especially, when representing the
project, in any role.

This code is neither exhaustive nor complete. It serves to distill our common
understanding of a collaborative, shared environment and goals. Please try to
follow this code in spirit as much as in letter, to create a friendly and
productive environment that enriches the surrounding community.


Specific guidelines
-------------------

We strive to:

1. Be open. We invite anyone to participate in our community. We prefer to use
   public methods of communication for project-related messages, unless
   discussing something sensitive. This applies to messages for help or
   project-related support, too; not only is a public-support request much more
   likely to result in an answer to a question, it also ensures that any
   inadvertent mistakes in answering are more easily detected and corrected.

2. Be empathetic, welcoming, friendly, and patient. We work together to resolve
   conflict, and assume good intentions. We may all experience some frustration
   from time to time, but we do not allow frustration to turn into a personal
   attack. A community where people feel uncomfortable or threatened is not a
   productive one.

3. Be collaborative. Our work will be used by other people, and in turn we will
   depend on the work of others. When we make something for the benefit of the
   project, we are willing to explain to others how it works, so that they can
   build on the work to make it even better. Any decision we make will affect
   users and colleagues, and we take those consequences seriously when making
   decisions.

4. Be inquisitive. Nobody knows everything! Asking questions early avoids many
   problems later, so we encourage questions, although we may direct them to
   the appropriate forum. We will try hard to be responsive and helpful.

5. Be careful in the words that we choose. We are careful and respectful in
   our communication and we take responsibility for our own speech. Be kind to
   others. Do not insult or put down other participants. We will not accept
   harassment or other exclusionary behavior, such as:

  - Violent threats or language directed against another person.
  - Sexist, racist, or otherwise discriminatory jokes and language.
  - Posting sexually explicit or violent material.
  - Posting (or threatening to post) other people's personally identifying information ("doxing").
  - Sharing private content, such as emails sent privately or non-publicly,
    or unlogged forums, such as IRC channel history, without the sender's consent.
  - Personal insults, especially those using racist or sexist terms.
  - Unwelcome sexual attention.
  - Excessive profanity. Please avoid swearwords; people differ greatly in their sensitivity to swearing.
  - Repeated harassment of others. In general, if someone asks you to stop, then stop.
  - Advocating for, or encouraging, any of the above behavior.


Diversity statement
-------------------

The SciPy project welcomes and encourages participation by everyone. We are
committed to being a community that everyone enjoys being part of. Although
we may not always be able to accommodate each individual's preferences, we try
our best to treat everyone kindly.

No matter how you identify yourself or how others perceive you: we welcome you.
Though no list can hope to be comprehensive, we explicitly honor diversity in:
age, culture, ethnicity, genotype, gender identity or expression, language,
national origin, neurotype, phenotype, political beliefs, profession, race,
religion, sexual orientation, socioeconomic status, subculture and technical
ability, to the extent that these do not conflict with this code of conduct.


Though we welcome people fluent in all languages, SciPy development is
conducted in English.

Standards for behavior in the SciPy community are detailed in the Code of
Conduct above. Participants in our community should uphold these standards
in all their interactions and help others to do so as well (see next section).


Reporting guidelines
--------------------

We know that it is painfully common for internet communication to start at or
devolve into obvious and flagrant abuse. We also recognize that sometimes
people may have a bad day, or be unaware of some of the guidelines in this Code
of Conduct. Please keep this in mind when deciding on how to respond to a
breach of this Code.

For clearly intentional breaches, report those to the Code of Conduct committee
(see below). For possibly unintentional breaches, you may reply to the person
and point out this Code of Conduct (either in public or in private, whatever is
most appropriate). If you would prefer not to do that, please feel free to
report to the Code of Conduct committee directly, or ask the committee for
advice, in confidence.

You can report issues to the SciPy Code of Conduct Committee, at
scipy-conduct@googlegroups.com. Currently, the committee consists of:

- Stefan van der Walt
- Nathaniel J. Smith
- Ralf Gommers

If your report involves any members of the committee, or if they feel they have
a conflict of interest in handling it, then they will recuse themselves from
considering your report. Alternatively, if, for any reason, you feel
uncomfortable making a report to the committee, then you can also contact:

- Chair of the SciPy Steering Committee: Ralf Gommers, or
- Senior `NumFOCUS staff <https://numfocus.org/code-of-conduct#persons-responsible>`__: conduct@numfocus.org


Incident reporting resolution & Code of Conduct enforcement
-----------------------------------------------------------

*This section summarizes the most important points, more details can be found
in* :ref:`CoC_reporting_manual`.

We will investigate and respond to all complaints. The SciPy Code of Conduct
Committee and the SciPy Steering Committee (if involved) will protect the
identity of the reporter, and treat the content of complaints as confidential
(unless the reporter agrees otherwise).

In case of severe and obvious breaches, e.g., personal threat or violent, sexist
or racist language, we will immediately disconnect the originator from SciPy
communication channels; please see the manual for details.

In cases not involving clear severe and obvious breaches of this code of
conduct, the process for acting on any received code of conduct violation
report will be:

1. acknowledgement that the report has been received
2. reasonable discussion/feedback
3. mediation (if feedback didn't help, and only if both reporter and reportee agree to this)
4. enforcement via transparent decision (see :ref:`CoC_resolutions`) by the
   Code of Conduct Committee

The committee will respond to any report as soon as possible, and at most
within 72 hours.


Endnotes
--------

We are thankful to the groups behind the following documents, from which we
drew content and inspiration:

- `The Apache Foundation Code of Conduct <https://www.apache.org/foundation/policies/conduct.html>`_
- `The Contributor Covenant <https://www.contributor-covenant.org/version/1/4/code-of-conduct/>`_
- `Jupyter Code of Conduct <https://github.com/jupyter/governance/tree/master/conduct>`_
- `Open Source Guides - Code of Conduct <https://opensource.guide/code-of-conduct/>`_
.. _configure-git:

=================
Git configuration
=================

.. _git-config-basic:

Overview
========

Your personal git_ configurations are saved in the ``.gitconfig`` file in
your home directory.
Here is an example ``.gitconfig`` file::

  [user]
          name = Your Name
          email = you@yourdomain.example.com

  [alias]
          ci = commit -a
          co = checkout
          st = status -a
          stat = status -a
          br = branch
          wdiff = diff --color-words

  [core]
          editor = vim

  [merge]
          summary = true

You can edit this file directly or you can use the ``git config --global``
command::

  git config --global user.name "Your Name"
  git config --global user.email you@yourdomain.example.com
  git config --global alias.ci "commit -a"
  git config --global alias.co checkout
  git config --global alias.st "status -a"
  git config --global alias.stat "status -a"
  git config --global alias.br branch
  git config --global alias.wdiff "diff --color-words"
  git config --global core.editor vim
  git config --global merge.summary true

To set up on another computer, you can copy your ``~/.gitconfig`` file,
or run the commands above.

In detail
=========

user.name and user.email
------------------------

It is good practice to tell git_ who you are, for labeling any changes
you make to the code.  The simplest way to do this is from the command
line::

  git config --global user.name "Your Name"
  git config --global user.email you@yourdomain.example.com

This will write the settings into your git configuration file,  which
should now contain a user section with your name and email::

  [user]
        name = Your Name
        email = you@yourdomain.example.com

Of course you'll need to replace ``Your Name`` and ``you@yourdomain.example.com``
with your actual name and email address.

Aliases
-------

You might well benefit from some aliases to common commands.

For example, you might well want to be able to shorten ``git checkout``
to ``git co``.  Or you may want to alias ``git diff --color-words``
(which gives a nicely formatted output of the diff) to ``git wdiff``

The following ``git config --global`` commands::

  git config --global alias.ci "commit -a"
  git config --global alias.co checkout
  git config --global alias.st "status -a"
  git config --global alias.stat "status -a"
  git config --global alias.br branch
  git config --global alias.wdiff "diff --color-words"

will create an ``alias`` section in your ``.gitconfig`` file with contents
like this::

  [alias]
          ci = commit -a
          co = checkout
          st = status -a
          stat = status -a
          br = branch
          wdiff = diff --color-words

Editor
------

You may also want to make sure that your editor of choice is used ::

  git config --global core.editor vim

Merging
-------

To enforce summaries when doing merges (``~/.gitconfig`` file again)::

   [merge]
      log = true

Or from the command line::

  git config --global merge.log true


.. include:: git_links.inc
====================================
Getting started with Git development
====================================

This section and the next describe in detail how to set up git for working
with the SciPy source code.  If you have git already set up, skip to
:ref:`development-workflow`.

Basic Git setup
###############

* :ref:`git-intro`.
* Introduce yourself to Git::

      git config --global user.email you@yourdomain.example.com
      git config --global user.name "Your Name Comes Here"

.. _forking:

Making your own copy (fork) of SciPy
####################################

You need to do this only once.  The instructions here are very similar
to the instructions at http://help.github.com/forking/ - please see that
page for more detail.  We're repeating some of it here just to give the
specifics for the SciPy_ project, and to suggest some default names.

Set up and configure a github_ account
======================================

If you don't have a github_ account, go to the github_ page, and make one.

You then need to configure your account to allow write access - see the
``Generating SSH keys`` help on `github help`_.

Create your own forked copy of SciPy_
=========================================

#. Log into your github_ account.
#. Go to the SciPy_ github home at `SciPy github`_.
#. Click on the *fork* button:

   .. image:: forking_button.png

   After a short pause, you should find yourself at the home page for
   your own forked copy of SciPy_.

.. include:: git_links.inc


.. _set-up-fork:

Set up your fork
################

First you follow the instructions for :ref:`forking`.

Overview
========

::

   git clone https://github.com/your-user-name/scipy.git
   cd scipy
   git remote add upstream https://github.com/scipy/scipy.git

In detail
=========

Clone your fork
---------------

#. Clone your fork to the local computer with ``git clone
   https://github.com/your-user-name/scipy.git``
#. Investigate.  Change directory to your new repo: ``cd scipy``. Then
   ``git branch -a`` to show you all branches.  You'll get something
   like::

      * main
      remotes/origin/main

   This tells you that you are currently on the ``main`` branch, and
   that you also have a ``remote`` connection to ``origin/main``.
   What remote repository is ``remote/origin``? Try ``git remote -v`` to
   see the URLs for the remote.  They will point to your github_ fork.

   Now you want to connect to the upstream `SciPy github`_ repository, so
   you can merge in changes from trunk.

.. _linking-to-upstream:

Linking your repository to the upstream repo
--------------------------------------------

::

   cd scipy
   git remote add upstream https://github.com/scipy/scipy.git

``upstream`` here is just the arbitrary name we're using to refer to the
main SciPy_ repository at `SciPy github`_.

Just for your own satisfaction, show yourself that you now have a new
'remote', with ``git remote -v show``, giving you something like::

   upstream	https://github.com/scipy/scipy.git (fetch)
   upstream	https://github.com/scipy/scipy.git (push)
   origin	https://github.com/your-user-name/scipy.git (fetch)
   origin	https://github.com/your-user-name/scipy.git (push)

To keep in sync with changes in SciPy, you want to set up your repository
so it pulls from ``upstream`` by default.  This can be done with::

   git config branch.main.remote upstream
   git config branch.main.merge refs/heads/main

Your config file should now look something like (from
``$ cat .git/config``)::

   [core]
           repositoryformatversion = 0
           filemode = true
           bare = false
           logallrefupdates = true
           ignorecase = true
           precomposeunicode = false
   [remote "origin"]
           url = https://github.com/your-user-name/scipy.git
           fetch = +refs/heads/*:refs/remotes/origin/*
   [remote "upstream"]
           url = https://github.com/scipy/scipy.git
           fetch = +refs/heads/*:refs/remotes/upstream/*
   [branch "main"]
           remote = upstream
           merge = refs/heads/main

.. include:: git_links.inc
.. _dot2-dot3:

======================================
Two and three dots in difference specs
======================================

Imagine a series of commits A, B, C, D...  Imagine that there are two
branches, *topic* and *main*.  You branched *topic* off *main* when
*main* was at commit 'E'.  The graph of the commits looks like this::


        A---B---C topic
        /
   D---E---F---G main

Then::

   git diff main..topic

will output the difference from G to C (i.e. with effects of F and G),
while::

   git diff main...topic

would output just differences in the topic branch (i.e. only A, B, and
C).
.. _useful-git:

========
Git tips
========

.. _rebasing-on-main:

Rebasing on main
----------------

This updates your feature branch with changes from the upstream `SciPy
github`_ repo. If you do not absolutely need to do this, try to avoid doing
it, except perhaps when you are finished. The first step will be to update
the remote repository with new commits from upstream::

   git fetch upstream

Next, you need to update the feature branch::

   # go to the feature branch
   git checkout my-new-feature
   # make a backup in case you mess up
   git branch tmp my-new-feature
   # rebase on upstream main branch
   git rebase upstream/main

If you have made changes to files that have changed also upstream,
this may generate merge conflicts that you need to resolve. See
:ref:`below<recovering-from-mess-up>` for help in this case.

Finally, remove the backup branch upon a successful rebase::

   git branch -D tmp


.. note::

   Rebasing on main is preferred over merging upstream back to your
   branch. Using ``git merge`` and ``git pull`` is discouraged when
   working on feature branches.

.. _recovering-from-mess-up:

Recovering from mess-ups
------------------------

Sometimes, you mess up merges or rebases. Luckily, in Git it is
relatively straightforward to recover from such mistakes.

If you mess up during a rebase::

   git rebase --abort

If you notice you messed up after the rebase::

   # reset branch back to the saved point
   git reset --hard tmp

If you forgot to make a backup branch::

   # look at the reflog of the branch
   git reflog show my-feature-branch

   8630830 my-feature-branch@{0}: commit: BUG: io: close file handles immediately
   278dd2a my-feature-branch@{1}: rebase finished: refs/heads/my-feature-branch onto 11ee694744f2552d
   26aa21a my-feature-branch@{2}: commit: BUG: lib: make seek_gzip_factory not leak gzip obj
   ...

   # reset the branch to where it was before the botched rebase
   git reset --hard my-feature-branch@{2}

If you didn't actually mess up but there are merge conflicts, you need to
resolve those.  This can be one of the trickier things to get right.  For a
good description of how to do this, see `this article on merging conflicts`_.

.. _rewriting-commit-history:

Rewriting commit history
------------------------

.. note::

   Do this only for your own feature branches.

There's an embarrassing typo in a commit you made? Or perhaps the you
made several false starts you would like the posterity not to see.

This can be done via *interactive rebasing*.

Suppose that the commit history looks like this::

    git log --oneline
    eadc391 Fix some remaining bugs
    a815645 Modify it so that it works
    2dec1ac Fix a few bugs + disable
    13d7934 First implementation
    6ad92e5 * masked is now an instance of a new object, MaskedConstant
    29001ed Add pre-nep for a copule of structured_array_extensions.
    ...

and ``6ad92e5`` is the last commit in the ``main`` branch. Suppose we
want to make the following changes:

* Rewrite the commit message for ``13d7934`` to something more sensible.
* Combine the commits ``2dec1ac``, ``a815645``, ``eadc391`` into a single one.

We do as follows::

    # make a backup of the current state
    git branch tmp HEAD
    # interactive rebase
    git rebase -i 6ad92e5

This will open an editor with the following text in it::

    pick 13d7934 First implementation
    pick 2dec1ac Fix a few bugs + disable
    pick a815645 Modify it so that it works
    pick eadc391 Fix some remaining bugs

    # Rebase 6ad92e5..eadc391 onto 6ad92e5
    #
    # Commands:
    #  p, pick = use commit
    #  r, reword = use commit, but edit the commit message
    #  e, edit = use commit, but stop for amending
    #  s, squash = use commit, but meld into previous commit
    #  f, fixup = like "squash", but discard this commit's log message
    #
    # If you remove a line here THAT COMMIT WILL BE LOST.
    # However, if you remove everything, the rebase will be aborted.
    #

To achieve what we want, we will make the following changes to it::

    r 13d7934 First implementation
    pick 2dec1ac Fix a few bugs + disable
    f a815645 Modify it so that it works
    f eadc391 Fix some remaining bugs

This means that (i) we want to edit the commit message for
``13d7934``, and (ii) collapse the last three commits into one. Now we
save and quit the editor.

Git will then immediately bring up an editor for editing the commit
message. After revising it, we get the output::

    [detached HEAD 721fc64] FOO: First implementation
     2 files changed, 199 insertions(+), 66 deletions(-)
    [detached HEAD 0f22701] Fix a few bugs + disable
     1 files changed, 79 insertions(+), 61 deletions(-)
    Successfully rebased and updated refs/heads/my-feature-branch.

and the history looks now like this::

     0f22701 Fix a few bugs + disable
     721fc64 ENH: Sophisticated feature
     6ad92e5 * masked is now an instance of a new object, MaskedConstant

If it went wrong, recovery is again possible as explained :ref:`above
<recovering-from-mess-up>`.

Deleting a branch on github_
----------------------------

::

   git checkout main
   # delete branch locally
   git branch -D my-unwanted-branch
   # delete branch on github
   git push origin :my-unwanted-branch

(Note the colon ``:`` before ``test-branch``.  See also:
https://github.com/guides/remove-a-remote-branch


Several people sharing a single repository
------------------------------------------

If you want to work on some stuff with other people, where you are all
committing into the same repository, or even the same branch, then just
share it via github_.

First fork SciPy into your account, as from :ref:`forking`.

Then, go to your forked repository github page, say
``https://github.com/your-user-name/scipy``

Click on the 'Admin' button, and add anyone else to the repo as a
collaborator:

   .. image:: pull_button.png

Now all those people can do::

    git clone git@github.com:your-user-name/scipy.git

Remember that links starting with ``git@`` use the ssh protocol and are
read-write; links starting with ``git://`` are read-only.

Your collaborators can then commit directly into that repo with the
usual::

     git commit -am 'ENH - much better code'
     git push origin my-feature-branch # pushes directly into your repo

Exploring your repository
-------------------------

To see a graphical representation of the repository branches and
commits::

   gitk --all

To see a linear list of commits for this branch::

   git log

You can also look at the `network graph visualizer`_ for your github_
repo.

Backporting
-----------

Backporting is the process of copying new feature/fixes committed in
`scipy/main`_ back to stable release branches. To do this you make a branch
off the branch you are backporting to, cherry pick the commits you want from
``scipy/main``, and then submit a pull request for the branch containing the
backport.

1. First, you need to make the branch you will work on. This needs to be
   based on the older version of SciPy (not main)::

    # Make a new branch based on scipy/maintenance/1.8.x,
    # backport-3324 is our new name for the branch.
    git checkout -b backport-3324 upstream/maintenance/1.8.x

2. Now you need to apply the changes from main to this branch using
   `git cherry-pick`_::

    # Update remote
    git fetch upstream
    # Check the commit log for commits to cherry pick
    git log upstream/main
    # This pull request included commits aa7a047 to c098283 (inclusive)
    # so you use the .. syntax (for a range of commits), the ^ makes the
    # range inclusive.
    git cherry-pick aa7a047^..c098283
    ...
    # Fix any conflicts, then if needed:
    git cherry-pick --continue

3. You might run into some conflicts cherry picking here. These are
   resolved the same way as merge/rebase conflicts. Except here you can
   use `git blame`_ to see the difference between main and the
   backported branch to make sure nothing gets screwed up.

4. Push the new branch to your Github repository::

    git push -u origin backport-3324

5. Finally make a pull request using Github. Make sure it is against the
   maintenance branch and not main, Github will usually suggest you
   make the pull request against main.

.. _pushing-to-main:

Pushing changes to the main repo
--------------------------------

*This is only relevant if you have commit rights to the main SciPy repo.*

When you have a set of "ready" changes in a feature branch ready for
SciPy's ``main`` or ``maintenance`` branches, you can push
them to ``upstream`` as follows:

1. First, merge or rebase on the target branch.

   a) Only a few, unrelated commits then prefer rebasing::

        git fetch upstream
        git rebase upstream/main

      See :ref:`rebasing-on-main`.

   b) If all of the commits are related, create a merge commit::

        git fetch upstream
        git merge --no-ff upstream/main

2. Check that what you are going to push looks sensible::

        git log -p upstream/main..
        git log --oneline --graph

3. Push to upstream::

        git push upstream my-feature-branch:main

.. note::

    It's usually a good idea to use the ``-n`` flag to ``git push`` to check
    first that you're about to push the changes you want to the place you
    want.

.. _scipy/main: https://github.com/scipy/scipy

.. include:: git_links.inc
.. _git-resources:

=========================
Additional Git_ Resources
=========================

Tutorials and summaries
=======================

* `github help`_ has an excellent series of how-to guides.
* `learn.github`_ has an excellent series of tutorials
* The `pro git book`_ is a good in-depth book on git.
* A `git cheat sheet`_ is a page giving summaries of common commands.
* The `git user manual`_
* The `git tutorial`_
* The `git community book`_
* `git ready`_ - a nice series of tutorials
* `git casts`_ - video snippets giving git how-tos.
* `git magic`_ - extended introduction with intermediate detail
* The `git parable`_ is an easy read explaining the concepts behind git.
* Our own `git foundation`_ expands on the `git parable`_.
* Fernando Perez' git page - `Fernando's git page`_ - many links and tips
* A good but technical page on `git concepts`_
* `git svn crash course`_: git_ for those of us used to subversion_

Advanced git workflow
=====================

There are many ways of working with git_; here are some posts on the
rules of thumb that other projects have come up with:

* Linus Torvalds on `git management`_
* Linus Torvalds on `linux git workflow`_ .  Summary; use the git tools
  to make the history of your edits as clean as possible; merge from
  upstream edits as little as possible in branches where you are doing
  active development.

Manual pages online
===================

You can get these on your own machine with (e.g) ``git help push`` or
(same thing) ``git push --help``, but, for convenience, here are the
online manual pages for some common commands:

* `git add`_
* `git branch`_
* `git checkout`_
* `git clone`_
* `git commit`_
* `git config`_
* `git diff`_
* `git log`_
* `git pull`_
* `git push`_
* `git remote`_
* `git status`_

.. include:: git_links.inc
.. _following-latest:

These are the instructions if you just want to follow the latest
*SciPy* source, but you don't need to do any development for now.
If you do want to contribute a patch (excellent!) or do more extensive
SciPy development, see :ref:`development-workflow`.

The steps are:

* :ref:`git-intro`
* get local copy of the git repository from Github_
* update local copy from time to time

Get the local copy of the code
==============================

From the command line::

   git clone https://github.com/scipy/scipy.git

You now have a copy of the code tree in the new ``scipy`` directory.
If this doesn't work you can try the alternative read-only url::

   git clone https://github.com/scipy/scipy.git

Updating the code
=================

From time to time you may want to pull down the latest code.  Do this with::

   cd scipy
   git fetch
   git merge --ff-only

The tree in ``scipy`` will now have the latest changes from the initial
repository.

.. _Github: https://github.com/scipy
.. _git-intro:

Install git
===========

Developing with git can be done entirely without GitHub. Git is a distributed
version control system. In order to use git on your machine you must `install
it`_.

.. include:: git_links.inc
:orphan:

.. _using-git:
.. _git-development:

=====================
 Git for development
=====================

These pages describe a general git_ and github_ workflow.

This is not a comprehensive git_ reference. It's tailored to working with SciPy
and using the github_ hosting service. You may well find better or quicker ways
of getting stuff done with git_, but these should get you started.

For general resources for learning git_ see :ref:`git-resources`.

Have a look at the github_ install help pages available from `github help`_

.. _install-git:


Contents:

.. toctree::
   :maxdepth: 2

   git_intro
   following_latest
   development_setup
   configure_git
   useful_git
   git_resources
   dot2_dot3

.. include:: git_links.inc
A Design Specification for ``nan_policy``
=========================================

Many functions in `scipy.stats` have a parameter called ``nan_policy``
that determines how the function handles data that contains ``nan``.  In
this section, we provide SciPy developer guidelines for how ``nan_policy``
is intended to be used, to ensure that as this parameter is added to new
functions, we maintain a consistent API.

The basic API
-------------

The parameter ``nan_policy`` accepts three possible strings: ``'omit'``,
``'raise'`` and ``'propagate'``.  The meanings are:

* ``nan_policy='omit'``:
  Ignore occurrences of ``nan`` in the input.  Do not generate a warning
  if the input contains ``nan`` (unless the equivalent input with the
  ``nan`` values removed would generate a warning). For example, for the
  simple case of a function that accepts a single array and returns a
  scalar (and ignoring the possible use of ``axis`` for the moment)::

      func([1.0, 3.0, np.nan, 5.0], nan_policy='omit')

  should behave the same as::

      func([1.0, 3.0, 5.0])

  More generally, for functions that return a scalar,
  ``func(a, nan_policy='omit')`` should behave the same as
  ``func(a[~np.isnan(a)])``.

  For functions that transform a vector to a new vector of the same
  size and for which each entry in the output array depends on
  more than just the corresponding value in the input array [#f1]_ (e.g.
  `scipy.stats.zscore`, `scipy.stats.boxcox` *when* ``lmbda`` *is None*),::

      y = func(a, nan_policy='omit')

  should behave the same as::

      nan_mask = np.isnan(a)
      y = np.empty(a.shape, dtype=np.float64)
      y[~nan_mask] = func(a[~nan_mask])
      y[nan_mask] = np.nan

  (In general, the dtype of ``y`` might depend on ``a`` and on the expected
  behavior of ``func``).  In other words, a `nan` in the input gives a
  corresponding `nan` in the output, but the presence of that `nan` does not
  affect the calculation of the non-`nan` values.

  Unit tests for this property should be used to test functions that
  handle ``nan_policy``.

  For functions that return a scalar and that accept two or more arguments
  but whose values are not related (e.g. `scipy.stats.ansari`,
  `scipy.stats.f_oneway`), the same idea applies to each input array.  So::

      func(a, b, nan_policy='omit')

  should behave the same as::

      func(a[~np.isnan(a)], b[~np.isnan(b)])

  For inputs with *related* or *paired* values (e.g. `scipy.stats.pearsonr`,
  `scipy.stats.ttest_rel`) the recommended behavior is to omit all the values
  for which any of the related values are ``nan``.  For a function with two
  related array inputs, this means::

      y = func(a, b, nan_policy='omit')

  should behave the same as::

      hasnan = np.isnan(a) | np.isnan(b)  # Union of the isnan masks.
      y = func(a[~hasnan], b[~hasnan])

  The docstring for such a function should clearly state this behavior.

* ``nan_policy='raise'``:
  Raise a ``ValueError``.
* ``nan_policy='propagate'``:
  Propagate the ``nan`` value to the output.  Typically, this means just
  execute the function without checking for ``nan``, but see

      https://github.com/scipy/scipy/issues/7818

  for an example where that might lead to unexpected output.


``nan_policy`` combined with an ``axis`` parameter
--------------------------------------------------
There is nothing surprising here--the principle mentioned above still
applies when the function has an ``axis`` parameter.  Suppose, for example,
``func`` reduces a 1-d array to a scalar, and handles n-d arrays as a
collection of 1-d arrays, with the ``axis`` parameter specifying the axis
along which the reduction is to be applied.  If, say::

    func([1, 3, 4])     -> 10.0
    func([2, -3, 8, 2]) ->  4.2
    func([7, 8])        ->  9.5
    func([])            -> -inf

then::

    func([[  1, nan,   3,   4],
          [  2,  -3,   8,   2],
          [nan,   7, nan,   8],
          [nan, nan, nan, nan]], nan_policy='omit', axis=-1)

must give the result::

    np.array([10.0, 4.2, 9.5, -inf])


Edge cases
----------
A function that implements the ``nan_policy`` parameter should gracefully
handle the case where *all* the values in the input array(s) are ``nan``.
The basic principle described above still applies::

    func([nan, nan, nan], nan_policy='omit')

should behave the same as::

    func([])

In practice, when adding ``nan_policy`` to an existing function, it is
not unusual to find that the function doesn't already handle this case
in a well-defined manner, and some thought and design may have to be
applied to ensure that it works.  The correct behavior (whether that be
to return ``nan``, return some other value, raise an exception, or something
else) will be determined on a case-by-case basis.


Why doesn't ``nan_policy`` also apply to ``inf``?
--------------------------------------------------
Although we learn in grade school that "infinity is not a number", the
floating point values ``nan`` and ``inf`` are qualitatively different.
The values ``inf`` and ``-inf`` act much more like regular floating
point values than ``nan``.

* One can compare ``inf`` to other floating point values and it behaves
  as expected, e.g. ``3 < inf`` is True.
* For the most part, arithmetic works "as expected" with ``inf``,
  e.g. ``inf + inf = inf``, ``-2*inf = -inf``, ``1/inf = 0``,
  etc.
* Many existing functions work "as expected" with ``inf``:
  ``np.log(inf) = inf``, ``np.exp(-inf) = 0``,
  ``np.array([1.0, -1.0, np.inf]).min() = -1.0``, etc.

So while ``nan`` almost always means "something went wrong" or "something
is missing", ``inf`` can in many cases be treated as a useful floating
point value.

It is also consistent with the NumPy ``nan`` functions to not ignore
``inf``::

    >>> np.nanmax([1, 2, 3, np.inf, np.nan])
    inf
    >>> np.nansum([1, 2, 3, np.inf, np.nan])
    inf
    >>> np.nanmean([8, -np.inf, 9, 1, np.nan])
    -inf


How *not* to implement ``nan_policy``
-------------------------------------
In the past (and possibly currently), some ``stats`` functions handled
``nan_policy`` by using a masked array to mask the ``nan`` values, and
then computing the result using the functions in the ``mstats`` subpackage.
The problem with this approach is that the masked array code might convert
``inf`` to a masked value, which we don't want to do (see above).  It also
means that, if care is not taken, the return value will be a masked array,
which will likely be a surprise to the user if they passed in regular arrays.


.. rubric:: Footnotes

.. [#f1] If an element of the output depends only on the corresponding
         element of the input (e.g. `numpy.sin`, `scipy.special.gamma`),
         then there is no need for a ``nan_policy`` parameter.
Adding vectorized ufuncs in ``scipy.special``
=============================================

.. highlight:: none

Many of the functions in ``special`` are vectorized versions of scalar
functions. The scalar functions are written by hand and the necessary
loops for vectorization are generated automatically. This section
discusses the steps necessary to add a new vectorized special
function.

The first step in adding a new vectorized function is writing the
corresponding scalar function. This can be done in Cython, C, C++, or
Fortran. If starting from scratch then Cython should be preferred
because the code is easier to maintain for developers only familiar
with Python. If the primary code is in Fortran then it is necessary to
write a C wrapper around the code; for examples of such wrappers see
``specfun_wrappers.c``.

After implementing the scalar function, register the new function by
adding an entry to ``functions.json``. The docstring in
``generate_ufuncs.py`` explains the format. Also add documentation for
the new function by adding an entry to ``add_newdocs.py``; look in the
file for examples.

When writing the parameters section of the documentation for ufuncs,
the type of an argument should be ``array_like``. Discussion of
whether an argument can be e.g. real or complex-valued should be saved
for the description. So for example, if we were to document the
parameters for the Gamma function then it should look like this::

  Parameters
  ----------
  z : array_like
      Real or complex valued argument

When documenting the returns section, the type of the returned value
should be ``scalar or ndarray`` since ufuncs return scalars when given
scalars as arguments. Also keep in mind that providing a ``name`` for
the return value is optional, and indeed is often not helpful for
special functions. So for the Gamma function we might have something
like this::

  Returns
  -------
  scalar or ndarray
      Values of the Gamma function
.. _api-dev-toc:

===========================
SciPy API Development Guide
===========================

.. toctree::
   :maxdepth: 1

   nan_policy
   special_ufuncs
.. _core-dev-guide:

==========================
SciPy Core Developer Guide
==========================

.. include:: decisions.rst.inc

.. include:: newfeatures.rst.inc

.. include:: github.rst.inc

.. include:: licensing.rst.inc

.. include:: versioning.rst.inc

.. include:: deprecations.rst.inc

.. include:: distributing.rst.inc

.. include:: releasing.rst.inc
:orphan:

.. _development-workflow:

====================
Development workflow
====================

*Note: consider watching* `SciPy Development Workflow`_ *before or after
reading to see an example of fixing a bug and submitting a pull request.*

In :ref:`quickstart-mac` or :ref:`quickstart-ubuntu`, you created your own
fork (copy) of the SciPy repository, cloned the repository on your own machine,
and built SciPy from this source code. Before getting started here,
there are two other things you need to do just once before you start modifying
SciPy.

#. In a terminal, introduce yourself to Git::

      git config --global user.email you@yourdomain.com
      git config --global user.name "Your Name"

   This information credits you for your work, but note that it will become
   publicly available if you "push" your work to GitHub. See
   `Setting your commit email address in Git`_ for more information.

#. Navigate to the root directory of your local SciPy repository and enter::

      git remote add upstream https://github.com/scipy/scipy.git

   This associates the name ``upstream`` with the official SciPy repository
   located at `https://github.com/scipy/scipy.git <https://github.com/scipy/scipy.git>`_.
   Note that when you cloned your fork of the SciPy repository, Git already
   associated the name ``origin`` with your fork. The reason you need both of
   these `"remotes"`_ is that you will typically start with the latest version
   of SciPy from the official repository ``upstream``, make changes, "push"
   your changes to your fork of the repository ``origin``, and then submit
   a "pull request" asking SciPy to "pull" your changes from your fork into
   the official repository.

#. Initialize git submodules::

      git submodule update --init

   This fetches and updates any submodules that SciPy needs (such as `Boost`).

Basic workflow
##############

In short:

1. Start a new *feature branch* for each set of edits that you do.
   See :ref:`below <making-a-new-feature-branch>`.

2. Hack away! See :ref:`below <editing-workflow>`.

3. When finished:

   - *Contributors*: push your feature branch to your own Github repo, and
     :ref:`create a pull request <asking-for-merging>`.

   - *Core developers* If you want to push changes without
     further review, see the notes :ref:`below <pushing-to-main>`.

This way of working helps to keep work well organized and the history
as clear as possible.

.. seealso::

   There are many online tutorials to help you `learn git`_. For discussions
   of specific git workflows, see these discussions on `linux git workflow`_,
   and `ipython git workflow`_.

.. _making-a-new-feature-branch:

Making a new feature branch
===========================

First, navigate to the SciPy root directory in your terminal and fetch new
commits from the ``upstream`` repository::

   git fetch upstream

Then, create a new branch based on the main branch of the upstream
repository::

   git checkout -b my-new-feature upstream/main

Equivalently, you might want to keep the main branch of your own repository
up to date and create a new branch based on that::

   git checkout main
   git rebase upstream/main
   git checkout -b my-new-feature

In order, these commands

#. ensure that the ``main`` branch of your local repository is checked out,

#. apply all the latest changes from the ``upstream/main`` (main SciPy
   repository main branch) to your local ``main`` branch, and

#. create and check out a new branch (``-b``) based on your local ``main``
   branch.

In any case, it's important that your feature branch include the latest
changes from the upstream main to help avoid
`merge conflicts <https://help.github.com/en/articles/resolving-a-merge-conflict-using-the-command-line>`_
when it's time to submit a pull request.

It's also a good idea to build this branch and run tests before continuing.
Assuming you've followed :ref:`quickstart-mac` or :ref:`quickstart-ubuntu`
to set up your development environment, you'll need to activate your
development virtual environment, perform an in-place build, and run tests::

   conda activate name-of-your-virtual-environment
   python setup.py build_ext --inplace
   python runtests.py -v

Otherwise, see :ref:`building`, :ref:`runtests` for more information.

.. _editing-workflow:

The editing workflow
====================

Overview
--------

::

   # hack hack
   git status # Optional
   git diff # Optional
   git add modified_file
   git commit
   # push the branch to your own Github repo
   git push origin my-new-feature

In more detail
--------------

#. Make some changes. When you feel that you've made a complete, working set
   of related changes, move on to the next steps.

#. Optional: Check which files have changed with ``git status`` (see `git
   status`_). You'll see a listing like this one::

     # On branch my-new-feature
     # Changed but not updated:
     #   (use "git add <file>..." to update what will be committed)
     #   (use "git checkout -- <file>..." to discard changes in working directory)
     #
     #	modified:   README
     #
     # Untracked files:
     #   (use "git add <file>..." to include in what will be committed)
     #
     #	INSTALL
     no changes added to commit (use "git add" and/or "git commit -a")

#. Optional: Compare the changes with the previous version using with ``git
   diff`` (`git diff`_). This brings up a simple text browser interface that
   highlights the difference between your files and the previous version.

#. Add any relevant modified or new files using  ``git add modified_file``
   (see `git add`_). This puts the files into a staging area, which is a queue
   of files that will be added to your next commit. Only add files that have
   related, complete changes. Leave files with unfinished changes for later
   commits.

#. To commit the staged files into the local copy of your repo, do ``git
   commit``. At this point, a text editor will open up to allow you to write a
   commit message. Read the :ref:`commit message
   section<writing-the-commit-message>` to be sure that you are writing a
   properly formatted and sufficiently detailed commit message. After saving
   your message and closing the editor, your commit will be saved. For trivial
   commits, a short commit message can be passed in through the command line
   using the ``-m`` flag. For example, ``git commit -am "ENH: Some message"``.

   In some cases, you will see this form of the commit command: ``git commit
   -a``. The extra ``-a`` flag automatically commits all modified files and
   removes all deleted files. This can save you some typing of numerous ``git
   add`` commands; however, it can add unwanted changes to a commit if you're
   not careful. For more information, see `why the -a flag?`_ - and the
   helpful use-case description in the `tangled working copy problem`_.

#. Push the changes to your forked repo on github_::

      git push origin my-new-feature

   For more information, see `git push`_.

.. note::

   Assuming you have followed the instructions in these pages, git will create
   a default link to your github_ repo called ``origin``. In git >= 1.7, you
   can ensure that the link to origin is permanently set by using the
   ``--set-upstream`` option::

      git push --set-upstream origin my-new-feature

   From now on, git_ will know that ``my-new-feature`` is related to the
   ``my-new-feature`` branch in your own github_ repo. Subsequent push calls
   are then simplified to the following::

      git push

   You have to use ``--set-upstream`` for each new branch that you create.


It may be the case that while you were working on your edits, new commits have
been added to ``upstream`` that affect your work. In this case, follow the
:ref:`rebasing-on-main` instructions to apply those changes to your branch.

.. _writing-the-commit-message:

Writing the commit message
--------------------------

Commit messages should be clear and follow a few basic rules.  Example::

   ENH: add functionality X to SciPy.<submodule>.

   The first line of the commit message starts with a capitalized acronym
   (options listed below) indicating what type of commit this is. Then a blank
   line, then more text if needed.  Lines shouldn't be longer than 72
   characters.  If the commit is related to a ticket, indicate that with
   "See #3456", "See ticket 3456", "Closes #3456", or similar.

Describing the motivation for a change, the nature of a bug for bug fixes or
some details on what an enhancement does are also good to include in a commit
message. Messages should be understandable without looking at the code
changes. A commit message like ``MAINT: fixed another one`` is an example of
what not to do; the reader has to go look for context elsewhere.

Standard acronyms to start the commit message with are::

   API: an (incompatible) API change
   BENCH: changes to the benchmark suite
   BLD: change related to building SciPy
   BUG: bug fix
   DEP: deprecate something, or remove a deprecated object
   DEV: development tool or utility
   DOC: documentation
   ENH: enhancement
   MAINT: maintenance commit (refactoring, typos, etc.)
   REV: revert an earlier commit
   STY: style fix (whitespace, PEP8)
   TST: addition or modification of tests
   REL: related to releasing SciPy

.. note:: You can add some markers to skip part of the continuous integration.
          See :ref:`continuous-integration`.

.. _asking-for-merging:

Asking for your changes to be merged with the main repo
-------------------------------------------------------

When you feel your work is finished, you can create a pull request (PR). Github
has a nice help page that outlines the process for `filing pull requests`_.

If your changes involve modifications to the API or addition/modification of a
function, you should initiate a code review. This involves sending an email to
the `SciPy mailing list`_ with a link to your PR along with a description of
and a motivation for your changes.

.. _pr-checklist:

Checklist before submitting a PR
--------------------------------

-  Did you check that the code can be distributed under a BSD license? See
   :ref:`license-considerations`.
-  Are there unit tests with good code coverage? See
   `NumPy/SciPy Testing Guidelines`_.
-  Do all unit tests pass locally? See :ref:`runtests`.
-  Do all public function have docstrings including examples? See the
   `numpydoc docstring guide`_.
-  Does the documentation render correctly? See :ref:`rendering-documentation`.
-  Is the code style correct? See :ref:`pep8-scipy`.
-  Are there benchmarks? See :ref:`benchmarking-with-asv`.
-  Is the commit message :ref:`formatted correctly <numpy:writing-the-commit-message>`?
-  Is the docstring of the new functionality tagged with
   ``.. versionadded:: X.Y.Z`` (where ``X.Y.Z`` is the version number of the
   next release? See the ``updating``, ``workers``, and ``constraints``
   documentation of |differential_evolution|_, for example. You can get the
   next version number from the most recent release notes on `the wiki`_ or
   from the ``MAJOR`` and ``MINOR`` version number variables in |setup.py|_.
-  In case of larger additions, is there a tutorial or more extensive
   module-level description? Tutorial files are in ``doc/source/tutorial``.
-  If compiled code is added, is it integrated correctly via ``setup.py``?
   See :ref:`compiled-code` for more information.

.. include:: ../gitwash/git_links.inc

.. _Scipy Development Workflow: https://youtu.be/HgU01gJbzMY

.. _Setting your commit email address in Git: https://help.github.com/en/articles/setting-your-commit-email-address-in-git

.. _"remotes": https://help.github.com/en/categories/managing-remotes

.. _NumPy/SciPy Testing Guidelines: https://docs.scipy.org/doc/numpy/reference/testing.html

.. _numpydoc docstring guide: https://numpydoc.readthedocs.io/en/latest/format.html

.. _the wiki: https://github.com/scipy/scipy/wiki

.. |differential_evolution| replace:: ``differential_evolution``
.. _differential_evolution: https://github.com/scipy/scipy/blob/main/scipy/optimize/_differentialevolution.py

.. |setup.py| replace:: ``setup.py``
.. _setup.py: https://github.com/scipy/scipy/blob/main/setup.py
.. _quickerstart-conda:

==============================================================
Development environment quickerstart guide (Linux and Mac)
==============================================================

With conda installed (through `Miniforge or Mambaforge <https://github.com/conda-forge/miniforge>`_,
`Miniconda <https://docs.conda.io/en/latest/miniconda.html>`_ or
`Anaconda <https://www.anaconda.com/products/individual>`_),
execute the following commands at the terminal from the base directory of
your `SciPy <https://github.com/scipy/scipy>`_ clone::

    # Create an environment with all development dependencies
    conda env create -f environment.yml  # works with `mamba` too
    conda activate scipy-dev

    # Initialize git submodules
    git submodule update --init

    # Build SciPy for development work plus run tests
    python runtests.py

For more detailed instructions, see the other :ref:`dev-env` guides.
:orphan:

.. highlight:: console

.. _benchmarking-with-asv:

Benchmarking SciPy with airspeed velocity
=========================================

*This document introduces benchmarking, including reviewing SciPy
benchmark test results online, writing a benchmark test, and running it
locally. For a video run-through of writing a test and running it
locally, see* \ `Benchmarking SciPy`_\ *.*

As written in the `airspeed velocity (asv) documentation`_:

 Airspeed velocity (asv) is a tool for benchmarking Python packages over their
 lifetime. Runtime, memory consumption, and even custom-computed values
 may be tracked. The results are displayed in an interactive web frontend
 that requires only a basic static webserver to host.

To see what this means, take a look at `airspeed velocity of an unladen
scipy`_. Each plot summarizes the execution time of a particular test
over the commit history of the project; that is, as each commit is
merged, the benchmark test is run, its execution time is measured, and
the elapsed time is plotted. In addition to tracking the performance of
the code, a commit is *intended* to affect, running *all* benchmarks for
each commit is helpful for identifying unintentional regressions:
significant increases in the execution time of one or more benchmark
tests. As SciPy is a web of interconnected code, the repercussions of a
small change may not be immediately obvious to a contributor, so this
benchmark suite makes it easier to detect regressions and identify the
commit that caused them. When you contribute a substantial new feature -
or notice a feature that doesn’t already have a benchmark test - please
consider writing benchmarks.

Writing benchmarks
------------------

*The* \ :ref:`Writing benchmarks <asv:writing-benchmarks>` \ *section of the
airspeed velocity documentation is the definitive guide to writing benchmarks.
Please see also the* \ `SciPy benchmarks readme`_\ *.*

To see how benchmarks are written, take a look at
|optimize-linprog-py|_. Each subclass of
``Benchmark`` defines a benchmark test. For example, the ``KleeMinty``
class defines a benchmark test based on the `Klee-Minty hypercube
problem`_, a diabolical test of the simplex algorithm for linear
programming. The class has four parts:

-  ``setup`` prepares the benchmark to run. The execution time of this
   function is *not* counted in the benchmark results, so this is a good
   place to set up all variables that define the problem. In the ``KleeMinty``
   example, this involves generating arrays ``c``, ``A_ub``, and ``b_ub``
   corresponding with a Klee-Minty hypercube in ``dims`` dimensions and
   storing them as instance variables.
-  ``time_klee_minty`` actually runs the benchmark test. This function
   executes after a ``KleeMinty`` object has been instantiated and
   ``setup`` has run, so it gets the arrays defining the problem from
   ``self``. Note that the prefix ``time`` in the function name
   indicates to ``asv`` that the execution time of this function *is* to
   be counted in the benchmark results.
-  ``params`` is a list of lists defining parameters of the test.
   Benchmarks are run for all possible combinations of these parameters.
   For example, the first time the benchmark is run, the first element
   of ``methods`` (``simplex``) is passed into ``setup`` and
   ``time_klee_minty`` as the first argument, ``meth``, and the first
   element of ``[3, 6, 9]`` (``3``) is passed into ``setup`` and
   ``time_klee_minty`` as the second argument, ``dims``. The next time
   the benchmark is run, ``setup`` and ``time_klee_minty`` are passed
   ``revised simplex`` and ``6`` as arguments, and so this continues
   until all combinations of parameters have been used.
-  ``param_names`` is a list of human-readable names for each element of
   the ``params`` list. These are used for presenting results.

Results of this benchmark over the past few years are available by
clicking on the `KleeMinty.time_klee_minty`_ link at `airspeed velocity
of an unladen scipy`_. Note that each trace of the plot corresponds with
a combination of benchmark parameters and environment settings
(e.g., the Cython version), and that the visibility of the traces can be
toggled using the control panel on the left.

Running benchmarks locally
--------------------------

*Before beginning, ensure that* \ `airspeed velocity`_ \ *is
installed.*

After contributing new benchmarks, you should test them locally before
submitting a pull request.

To run all benchmarks, navigate to the root SciPy directory at the
command line and execute::

   python runtests.py --bench

where ``--bench`` activates the benchmark suite instead of the test
suite. This builds SciPy and runs the benchmarks. (*Note: this could
take a while. Benchmarks often take longer to run than unit tests, and
each benchmark is run multiple times to measure the distribution in
execution times.*)

To run benchmarks from a particular benchmark module, such as
``optimize_linprog.py``, simply append the filename without the
extension::

   python runtests.py --bench optimize_linprog

To run a benchmark defined in a class, such as ``KleeMinty`` from
``optimize_linprog.py``::

   python runtests.py --bench optimize_linprog.KleeMinty

To compare benchmark results between the active branch and another, such
as ``main``::

   python runtests.py --bench-compare main optimize_linprog.KleeMinty

All of the commands above display the results in plain text in the
console, and the results are not saved for comparison with future
commits. For greater control, a graphical view, and to have results
saved for future comparison, you can use use the ``asv`` terminal command
directly.

To use it, navigate to ``scipy/benchmarks`` in the console and then
execute::

   asv run

This command runs the
whole benchmark suite and saves the results for comparison against
future commits.

To run only a single benchmark, such as ``KleeMinty`` from
``optimize_linprog.py``::

   asv run --bench optimize_linprog.KleeMinty

One great feature of ``asv`` is that it can automatically run a
benchmark not just for the current commit, but for every commit in a
range. ``linprog`` ``method='interior-point'`` was merged into SciPy
with commit |7fa17f2369e0e5ad055b23cc1a5ee079f9e8ca32|_, so let’s
run the ``KleeMinty`` benchmark for 10 commits between then and now to
track its performance over time::

   asv run --bench optimize_linprog.KleeMinty --steps 10 7fa17f..

.. note::

   This will take a while, because SciPy has to be rebuilt for each
   commit! For more information about specifying ranges of commits, see
   the `git revisions documentation`_.

To "publish" the results (prepare them to be viewed) and "preview" them
in an interactive console::

   asv publish
   asv preview

ASV will report that it is running a server. Using any browser, you can
review the results by navigating to http://127.0.0.1:8080 (local
machine, port 8080).

For much more information about the ``asv`` commands,
see the airspeed velocity `Commands`_ documentation. (Tip:
check out the ``asv find`` command and the ``--quick``,
``--skip-existing-commits``, and ``--profile`` options for ``asv run``.)

.. _git revisions documentation: https://git-scm.com/docs/gitrevisions#_specifying_ranges
.. _Commands: https://asv.readthedocs.io/en/stable/commands.html#commands
.. _airspeed velocity: https://github.com/airspeed-velocity/asv
.. _Using airspeed velocity: https://asv.readthedocs.io/en/stable/using.html#running-benchmarks
.. _Benchmarking SciPy: https://youtu.be/edLQ8KRpupQ
.. _airspeed velocity (asv) documentation: https://asv.readthedocs.io/en/stable/
.. _airspeed velocity of an unladen scipy: https://pv.github.io/scipy-bench/
.. _SciPy benchmarks readme: https://github.com/scipy/scipy/blob/main/benchmarks/README.rst
.. _Klee-Minty hypercube problem: https://en.wikipedia.org/wiki/Klee%E2%80%93Minty_cube
.. _KleeMinty.time_klee_minty: https://pv.github.io/scipy-bench/#optimize_linprog.KleeMinty.time_klee_minty

.. |optimize-linprog-py| replace:: ``scipy/benchmarks/benchmarks/optimize_linprog.py``
.. _optimize-linprog-py: https://github.com/scipy/scipy/blob/main/benchmarks/benchmarks/optimize_linprog.py

.. |7fa17f2369e0e5ad055b23cc1a5ee079f9e8ca32| replace:: ``7fa17f2369e0e5ad055b23cc1a5ee079f9e8ca32``
.. _7fa17f2369e0e5ad055b23cc1a5ee079f9e8ca32: https://github.com/scipy/scipy/commit/7fa17f2369e0e5ad055b23cc1a5ee079f9e8ca32
:orphan:

.. _runtests:

===========================
Running SciPy Tests Locally
===========================

Basic test writing and execution from within the Python interpreter is
documented in the `NumPy/SciPy Testing Guidelines`_. This page includes
information about running tests from the command line using SciPy’s
``runtests.py``, which permits greater control. *Note: Before beginning,
ensure that* |pytest|_ *is installed.*

To run all tests, navigate to the root SciPy directory at the command
line and execute

::

   python runtests.py -v

where ``-v`` activates the ``--verbose`` option. This builds SciPy (or
updates an existing build) and runs the tests.

To run tests on a particular submodule, such as ``optimize``, use the
``--submodule`` option:

::

   python runtests.py -v -s optimize

To run a particular test module, use the ``--test`` option:

::

   python runtests.py -v -t scipy.<module>.tests.<test_file>

Example for |test-linprog|_ file tests, run:

::

   python runtests.py -v -t scipy.optimize.tests.test_linprog

To run a test class:

::

   python runtests.py -v -t scipy.<module>.tests.<test_file>::<TestClass>

Example for ``TestLinprogRSCommon`` class from ``test_linprog.py``:

::

   python runtests.py -v -t scipy.optimize.tests.test_linprog::TestLinprogRSCommon

To run a particular test:

::

   python runtests.py -v -t scipy.<module>.tests.<test_file>::<test_name>

Example for ``test_unknown_solvers_and_options`` from ``test_linprog.py``:

::

   python runtests.py -v -t scipy.optimize.tests.test_linprog::test_unknown_solvers_and_options

For tests within a class, you need to specify the class name and the test name:

::

   python runtests.py -v -t scipy.<module>.tests.<test_file>::<TestClass>::<test_name>

Example:

::

   python runtests.py -v -t scipy.optimize.tests.test_linprog::TestLinprogRSCommon::test_nontrivial_problem_with_guess


Other useful options include:

-  ``--coverage`` to generate a test coverage report in
   ``scipy/build/coverage/index.html``. *Note:* |pytest-cov|_ *must be
   installed.*
-  ``--doc`` to build the docs in ``scipy/doc/build``. By default,
   docs are built only in the ``html-scipyorg`` format, but you can
   change this by appending the name of the desired format
   (e.g. ``--doc latex``).
-  ``--refguide-check`` to check whether the objects in a Scipy submodule's
   ``__all__`` dict correspond to the objects included in the reference
   guide. It also checks the validity of code samples in docstrings.
-  ``--bench`` to run all benchmarks. See :ref:`benchmarking-with-asv`.
-  ``--pep8`` to perform pep8 check.
-  ``--mypy`` to run *mypy* on the codebase.
-  ``-n`` or ``--no-build`` to prevent SciPy from updating the build
   before testing
-  ``-j`` or ``--parallel`` *n* to engage *n* cores when building SciPy;
   e.g. \ ``python runtests.py -j 4`` engages four cores. As of `#10172`_
   this also runs the tests on four cores if |pytest-xdist|_ is installed.
-  ``-m`` or ``--mode`` ``full`` to run the full test suite, including slow
   tests. For example, ``python runtests.py -m full``.
-  ``--`` to send remaining command line arguments to ``pytest`` instead of
   ``runtest.py``. For instance, while ``-n`` sent to ``pytest.py`` activates
   the ``--no-build`` option, ``-n`` sent to ``pytest`` runs the tests on
   multiple cores; e.g. \ ``python runtests.py -- -n 4`` runs tests using
   four cores. *Note:* |pytest-xdist|_ *must be installed for testing on
   multiple cores.*

Other options not documented here are listed in the ``main`` function of
the source code for |runtests-py|_. For much more information about
``pytest``, see the ``pytest``
`documentation <https://docs.pytest.org/en/latest/usage.html>`_.

Tips:
-----

If you built SciPy from source but are having trouble running tests
after a change to the codebase, try deleting the ``scipy/build``
directory. This forces ``runtest.py`` to completely rebuild SciPy before
performing tests.

There is an additional level of very slow tests (several minutes),
which are disabled even when calling ``python runtests.py -m full``.
They can be enabled by setting the environment variable ``SCIPY_XSLOW=1``
before running the test suite.

.. |runtests-py| replace:: ``runtests.py``
.. _runtests-py: https://github.com/scipy/scipy/blob/main/runtests.py

.. |pytest-cov| replace:: ``pytest-cov``
.. _pytest-cov: https://pypi.org/project/pytest-cov/

.. _#10172: https://github.com/scipy/scipy/pull/10172

.. |pytest-xdist| replace:: ``pytest-xdist``
.. _pytest-xdist: https://pypi.org/project/pytest-xdist/

.. _NumPy/SciPy Testing Guidelines: https://github.com/numpy/numpy/blob/main/doc/TESTS.rst.txt

.. |pytest| replace:: ``pytest``
.. _pytest: https://docs.pytest.org/en/latest/

.. |test-linprog| replace:: ``scipy/optimize/tests/test_linprog.py``
.. _test-linprog: https://github.com/scipy/scipy/blob/main/scipy/optimize/tests/test_linprog.py
:orphan:

.. _rendering-documentation:

===================================
Rendering Documentation with Sphinx
===================================

SciPy docstrings are rendered to HTML using `Sphinx`_ and the
`PyData Sphinx theme`_. Writing
docstrings is covered in the :ref:`numpy:howto-document`; this document
explains how to check that docstrings render properly.

*For a video walkthrough, please see* \ `Rendering SciPy Documentation
with Sphinx`_ \ *.*

.. _rendering-documentation-locally:

Rendering Documentation Locally
-------------------------------

To render the documentation on your own machine:

0. Ensure that you have a working SciPy :ref:`dev-env` active.
   You need to be able to ``import scipy`` regardless of Python's working
   directory; the ``python setup.py develop`` and ``conda develop`` commands
   from the :ref:`quickstart <dev-env>` guides make this possible.
#. Install `Sphinx`_, `PyData Sphinx theme`_, `Sphinx-Panels`_ and `matplotlib`_. For
   example, if you're using the Anaconda distribution of Python, enter in a
   terminal window ``conda install sphinx pydata-sphinx-theme sphinx-panels matplotlib --channel conda-forge``.
   The list of requirements is in ``scipy/doc_requirements.txt``.
#. In a terminal window, browse to the ``scipy/doc`` directory. Note the
   presence of the file ``Makefile``.
#. Execute ``git submodule update --init``.
   Some of the documentation theme files are not distributed
   with the main ``scipy`` repository; this keeps them up to date using
   `git submodules`_.
#. Enter ``make html-scipyorg``. If you have multiple version of Python on
   your path, you can choose which version to use by appending
   ``PYTHON=python3.9`` to this command, where ``python3.9`` is to be
   replaced with the name of the Python you use for SciPy development.
   This uses the `Make build automation tool`_
   to execute the documentation build instructions from the ``Makefile``.
   This can take a while the first time, but subsequent documentation builds
   are typically much faster.
#. View the documentation in ``scipy/doc/build/html-scipyorg``. You can start
   with ``index.html`` and browse, or you can jump straight to the file you’re
   interested in.

.. note::

   Changes to certain documents do not take effect when Sphinx documentation
   is rebuilt. In this case, you can build from scratch by deleting the
   ``scipy/doc/build`` directory, then building again.

.. _rendering-documentation-cloud:

Checking Documentation on the Cloud
-----------------------------------

Once a PR is opened, you can check that documentation renders correctly
on the cloud.

#. Log in to `GitHub`_.
#. Log in `CircleCI`_ using your GitHub account.
#. Back in GitHub, at the bottom of the PR, select “Show all Checks”.
#. Next to “ci/circleci: build_docs artifact”, select “Details”.

.. _GitHub: https://github.com/
.. _CircleCI: https://circleci.com/vcs-authorize/
.. _Sphinx: https://www.sphinx-doc.org/en/master/
.. _PyData Sphinx theme: https://pydata-sphinx-theme.readthedocs.io/en/latest/
.. _Sphinx-Panels: https://sphinx-panels.readthedocs.io/en/latest/
.. _matplotlib: https://www.matplotlib.org/
.. _Rendering SciPy Documentation with Sphinx: https://youtu.be/kGSYU39EhJQ
.. _git submodules: https://git-scm.com/book/en/v2/Git-Tools-Submodules
.. _Make build automation tool: https://en.wikipedia.org/wiki/Make_(software)
:orphan:

.. highlight:: console

.. _recommended-development-setup:

=============================
Recommended development setup
=============================

*This document does not include detailed explanations. For more step-by-step
procedures, see* :ref:`quickstart-mac` *or* :ref:`building`.

Since SciPy contains parts written in C, C++, and Fortran that need to be
compiled before use, make sure you have the necessary compilers and Python
development headers installed.  Having compiled code also means that importing
SciPy from the development sources needs some additional steps, which are
explained below.

First fork a copy of the main SciPy repository in Github onto your own
account and then create your local repository via::

    $ git clone git@github.com:YOURUSERNAME/scipy.git scipy
    $ cd scipy
    $ git submodule update --init
    $ git remote add upstream https://github.com/scipy/scipy.git

Second to code review pull requests it is helpful to have a local copy of the
code changes in the pull request. The preferred method to bring a PR from the
github repository to your local repo in a new branch::

    $ git fetch upstream pull/PULL_REQUEST_ID/head:NEW_BRANCH_NAME

The value of ``PULL_REQUEST_ID`` will be the PR number and the
``NEW_BRANCH_NAME`` will be the name of the branch in your local repository
where the diffs will reside.

Now you have a branch in your local development area to code review in Python.

To build the development version of SciPy and run tests, spawn
interactive shells with the Python import paths properly set up etc.,
do one of::

    $ python runtests.py -v
    $ python runtests.py -v -s optimize
    $ python runtests.py -v -t scipy.special.tests.test_basic::test_xlogy
    $ python runtests.py --ipython
    $ python runtests.py --python somescript.py
    $ python runtests.py --bench

This builds SciPy first, so the first time it may take some time.  If
you specify ``-n``, the tests are run against the version of SciPy (if
any) found on current PYTHONPATH.  *Note: if you run into a build issue,
more detailed build documentation can be found in* :ref:`building`.

Some of the tests in SciPy are very slow and need to be separately
enabled. See :ref:`runtests` for details.
:orphan:

.. _other-languages:

=============
Beyond Python
=============

This is a small collection of thoughts related to the inclusion of code written
in languages other than Python. Currently, the only option for languages other
than Python that we have extra documentation for is :ref:`Cython<adding-cython>`.

*Can I use a programming language other than Python to speed up my code?*

Yes. The languages used in SciPy are Python, Cython, Pythran, C, C++, and
Fortran. All of these have their pros and cons. If Python really doesn't offer
enough performance, one of those languages can be used. Important concerns when
using compiled languages are maintainability and portability. For
maintainability, Pythran and Cython are preferred over C/C++/Fortran. Cython, C
and C++ are more portable than Fortran. A lot of the existing Fortran
code in SciPy is older, battle-tested code that was only wrapped in (but not
specifically written for) Python/SciPy.

Our basic advice is: use Pythran or Cython for accelerating smaller pieces of
code. In cases where Pythran or Cython are no longer enough, prefer C or C++.
If there are specific reasons why Fortran is preferred, please discuss those
reasons first.

*Can I use Numba?*

Not yet, but we're considering it for the future. It is possible to write code
that takes user-defined functions which are generated by Numba, see
:ref:`ndimage-ccallbacks`.

*How do I debug code written in C/C++/Fortran inside SciPy?*

The easiest way to do this is to first write a Python script that
invokes the C code whose execution you want to debug. For instance
``mytest.py``::

    from scipy.special import hyp2f1
    print(hyp2f1(5.0, 1.0, -1.8, 0.95))

Now, you can run::

    gdb --args python runtests.py -g --python mytest.py

If you didn't compile with debug symbols enabled before, remove the
``build`` directory first. While in the debugger::

    (gdb) break cephes_hyp2f1
    (gdb) run

The execution will now stop at the corresponding C function and you
can step through it as usual. Instead of plain ``gdb`` you can, of
course, use your favorite alternative debugger; run it on the
``python`` binary with arguments ``runtests.py -g --python mytest.py``.
:orphan:

.. _reviewing-prs:

=======================
Reviewing Pull Requests
=======================

.. _pull-request-workflow-features:

Using workflow features
-----------------------

When reviewing pull requests, please use workflow tracking features on
Github as appropriate:

1. After you have finished reviewing, and want to ask for the submitter
   to make the changes:

   - Change your review status to "Changes requested".

     This can be done on Github, PR page, ``Files changed`` tab,
     ``Review changes`` (button on top right).

   - Alternatively: add the ``needs-work`` label.

     This can be done on the PR page, ``Labels`` menu on the right.

2. When you re-review the same pull request again, and want to request
   more changes:

   - Do the "Changes requested" thing again, even if the previous status
     was also 'Changes requested'.

   - Alternatively:
     Remove the existing ``needs-work`` label, and then re-add the label
     back again. (Github will add a notice on the page that you did so.)

3. If you're happy about the current status:

   - Mark the pull request as Approved (same way as Changes requested).

   - Alternatively: remove the ``needs-work`` label.

   - Alternatively (for core developers): merge the pull request, if
     you think it is ready to be merged.

This allows automatically tracking which PRs are in need of attention.

The review status is listed at: https://pav.iki.fi/scipy-needs-work/
The page can also be generated using https://github.com/pv/github-needs-work

Some of the information is also visible on Github directly, although
(as of Aug 2019) Github does not show which pull requests have been
updated since the last review.


Code from pull request
----------------------

When you review a pull request created by someone else, it's helpful to have a
copy of their code on your own machine so that you can play with it locally.

One way to do this is to navigate to the SciPy root directory in the terminal
and enter::

   git fetch upstream pull/PULL_REQUEST_ID/head:NEW_BRANCH_NAME

where ``PULL_REQUEST_ID`` is the five digit number corresponding with the
pull request (e.g. ``10286`` for `PR #10286`_) and ``NEW_BRANCH_NAME`` is
whatever name you'd like to use to refer to the author's code (e.g.
``review_10286``).

Now you can check out the branch::

   git checkout NEW_BRANCH_NAME

which converts the code in your local repository to match the author's modified
version of SciPy.

Assuming you set up your development environment according to
:ref:`quickstart-mac` or :ref:`quickstart-ubuntu`, you you can now activate your development environment::

   conda activate scipydev

build the code and test it::

   python setup.py build_ext --inplace
   python runtests.py -v

and if you ``import`` SciPy from Python, you'll be importing the
author's modified version of SciPy.

If you want to collaborate with the author on their PR, you might instead
want to set up a new remote to the author's fork of SciPy::

   git remote add REMOTE_NAME https://github.com/AUTHOR/scipy.git

where ``AUTHOR`` is the author's GitHub user name and ``REMOTE_NAME`` is
whatever name you want to use to refer to this author's repository.

From there, you can view the author's branches::

   git remote show REMOTE_NAME

and create your own branch based on one of them::

   git checkout --track REMOTE_NAME/BRANCH_NAME

where ``BRANCH_NAME`` is the name of the branch you want to start from. This
creates a copy of this branch (with the same name) in your local repository.
If make changes to this branch and push to your GitHub repository
(``origin``), you can then create a pull request to merge your changes with the
author's repository.

.. _PR #10286: https://github.com/scipy/scipy/pull/10286
:orphan:

.. _quickstart-docker:

=================================================
Development environment quickstart guide (Docker)
=================================================

This document describes how to use a Docker container for your SciPy 
development environment.
These instructions should be considered a work in progress.

Docker
------

Docker is a program for running Linux virtual machines within a host
operating system. According to the `Docker website`_:

 A Docker container image is a lightweight, standalone, executable package of
 software that includes everything needed to run an application: code, runtime,
 system tools, system libraries and settings.
 Container images become containers at runtime, and in the case of Docker
 containers - images become containers when they run on Docker Engine.
 Available for both Linux and Windows-based applications, containerized
 software will always run the same, regardless of the host infrastructure.

Docker makes setting up a development environment easy and reliable: we
provide a Docker image with suitable compilers and Scipy's build-time 
dependencies. 
You can then use the Docker engine to execute the image as a container,  
add the latest development version of SciPy, and build SciPy.

There are Docker hosts for several OS's including:
macOS, Linux, and Windows. Please follow the appropriate
installation instructions for your operating system at `docs.docker.com`_.

.. note::

   If you have a version of an operating system that doesn't meet the
   requirements of Docker Desktop, such as Windows 10 Home,
   try `Docker Toolbox`_ .

Cloning SciPy
-------------

Before starting SciPy's Docker container, you should create a copy of the
SciPy source code on your computer. That way, you'll be able to access the
same files both from your native operating system and within the container.

.. note::
   
   Below we will use *terminal window* as a
   collective term that includes the Windows Command Prompt.

#. Browse to the `SciPy repository on GitHub`_ and `create your own fork`_.
   You'll need to create a GitHub account if you don’t
   already have one.

#. Browse to your fork. Your fork will have a URL like
   https://github.com/andyfaff/scipy, except with your GitHub username
   in place of "andyfaff".

#. Click the big, green "Clone or download" button, and copy the ".git"
   URL to the clipboard. The URL will be the same as your fork’s URL,
   except it will end in ".git".

#. Create a folder for the SciPy source code in a convenient place on
   your computer. `Navigate`_ to it in the terminal window.

#. Enter the command ``git clone`` followed by your fork’s .git URL.
   Note that this creates in the terminal’s working directory a
   ``scipy`` folder containing the SciPy source code. This assumes that
   you have a ``git`` command line client that is available on your
   PATH; if not, you can follow these `instructions to install a git client`_.

Starting Docker
---------------

Instructions for getting started with Docker can be found `here`_. After
ensuring that Docker is working correctly, follow the instructions below to
start a Docker container for SciPy development. You'll follow the same
instructions each time you want to start the container, as changes made to a
container do not persist after you close it.

#. In a terminal window, change the directory (using the ``cd`` command)
   to the root folder of the SciPy git repository, which contains the file
   ``setup.py``.

#. Ensure that Docker Desktop (or Docker Toolbox) is running, and start up the
   SciPy Docker container by entering the following command in a terminal
   window::

      docker run -it --rm -v $PWD/:/home/scipy scipy/scipy-dev:<image-tag> 
   
   If you are using Windows cmd, you may run the following command instead::

      docker run -it --rm -v %cd%:/home/scipy scipy/scipy-dev:<image-tag> 

   This command starts (``run``) an interactive (``-it``) Docker container
   named ``scipy-dev`` (based on Ubuntu focal) from the ``scipy``
   `Docker Hub repository`_. When the Docker container starts, the
   ``scipy`` directory from the current directory of the host (``$PWD``) is
   made available in the container as ``/home/scipy``. The changes you make
   from the container to any of the files in that directory are also
   visible in the host, and vice versa.

#. You should now be in the container, with something like::

      (base) root@468e1b9564e4:/home/scipy#

   as a prompt. Notice the ``(base)`` at the beginning, since we are using conda.

#. Activate the ``scipy-dev`` conda environment::

      conda activate scipy-dev

   this environment has all the dependencies you'll need to start using/building SciPy.

#. Initialize git submodules: ``git submodule update --init``.

#. Do an in-place build by entering::

      python setup.py build_ext --inplace

   This will compile the C,
   C++, and Fortran code that comes with SciPy. ``setup.py`` is a
   script in the root directory of SciPy, which is why you have to be
   in the SciPy root directory to call it. ``build_ext`` is a command
   defined in ``setup.py``, and ``--inplace`` is an option we’ll use to
   ensure that the compiling happens in the SciPy directory you already
   have rather than some other folder on your computer. 

#. Test the build by entering::

      python runtests.py -v

   ``runtests.py`` is another script in the SciPy root directory. It runs a
   suite of tests that make sure SciPy is working as it should, and ``-v``
   activates the ``–verbose`` option to show all the test output.

#. If you want to :ref:`build the documentation <rendering-documentation>`
   or import SciPy from any directory other than the SciPy root, you should
   set up SciPy for development::

      conda develop .

   where ``.`` refers to the present directory (in this case ``home/scipy``).

From here, you can start a Python console (e.g., enter ``python``) or
execute Python scripts from the command line (e.g.,
``python scriptname.py``).

You can make changes to files in the ``scipy`` directory in a text editor/IDE
in your host OS, and those changes will be reflected
within the container. Alternatively, you can use the ``vi``
text editor within the container to make changes. No changes made
within the container are retained when the container is exited; only
changes made to files/folders within mounted volumes are kept.
If you would like to contribute changes to the SciPy project, please see
:ref:`development-workflow`.

The Docker image contains all the compilers and dependencies needed for you
to work on SciPy. Similar to the :ref:`quickstart-ubuntu`,the Docker image uses 
the  `Anaconda Distribution of Python`_ to manage the development environment.

.. _here: https://docs.docker.com/get-started/
.. _Docker Hub repository: https://cloud.docker.com/repository/docker/scipy/scipy-dev
.. _Scipy repository on GitHub: https://github.com/scipy/scipy
.. _create your own fork: https://help.github.com/en/articles/fork-a-repo
.. _Navigate: https://blog.teamtreehouse.com/introduction-to-the-mac-os-x-command-line
.. _instructions to install a git client: https://git-scm.com/book/en/v2/Getting-Started-Installing-Git
.. _docs.docker.com: https://docs.docker.com/install/
.. _Docker website: https://www.docker.com/resources/what-container
.. _Docker Toolbox: https://docs.docker.com/toolbox/
.. |PYTHONPATH| replace:: ``PYTHONPATH``
.. _PYTHONPATH: https://docs.python.org/3/using/cmdline.html#environment-variables
.. _Anaconda Distribution of Python: https://www.anaconda.com/distribution/

.. |br| raw:: html

    <br>
.. _meson:

=============================
How to build SciPy with Meson
=============================

.. warning::

   The change over from a `numpy.distutils` to a Meson based build is still a
   work in progress. There may be rough edges, and not all platforms and build
   configurations are supported yet. These instructions shouls work reliably on
   Linux with a conda environment and OpenBLAS as the BLAS/LAPACK library.
   macOS still has one known issue which may occasionally lead to issues
   (however, multiple testers have reported success, it's not deterministic -
   see https://github.com/rgommers/scipy/issues/31). Windows does work with a
   specific setup, but is not officially supported yet (if you want to use it
   on Windows anyway, please look at
   `this CI job <https://github.com/rgommers/scipy/blob/meson/.github/workflows/windows.yml>`_.
   for details)! Other Unix-like OSes may work, but are untested (please open
   an issue if you have tested and something seems broken).

   For the current status, see
   `this tracking issue <https://github.com/rgommers/scipy/issues/22>`_.


Quickstart from scratch
=======================

Clone the repo if you haven't done so yet, and initialize the git submodules::

  git clone git@github.com:scipy/scipy.git
  git submodule update --init

Create a conda development environment, build SciPy with Meson and run the test
suite::

  conda env create -f environment_meson.yml
  conda activate scipy-meson
  python dev.py


Full details and explanation
============================

To build SciPy, we need the SciPy ``main`` branch. Note that further work
on Meson integration is being done in the ``meson`` branch from ``@rgommers``'s
fork. We stay with SciPy ``main`` here::

  git clone git@github.com:scipy/scipy.git
  git submodule update --init

We will use conda here, because it's the easiest way to get a fully
reproducible environment. If you do not have a conda environment yet, the
recommended installer is
`Mambaforge <https://github.com/conda-forge/miniforge#mambaforge>`__
(``mamba`` is basically a much faster ``conda``).

To create a development environment::

  conda env create -f environment_meson.yml  # `mamba` works too for this command
  conda activate scipy-meson

Support for Cython in Meson is very new, and we also need some recent bug
fixes and new features in Meson - hence we need a ``>=0.60.x`` release
(automatically installed via use of ``environment_meson.yml`` above).

Meson uses a configure and a build stage. To configure it for putting the build
artifacts in ``build/`` and a local install under ``installdir/`` and then
build::

  meson setup build --prefix=$PWD/installdir
  ninja -C build

In the command above, ``-C`` is followed by the name of the build directory.
You can have multiple builds at the same time. Meson is fully out-of-place, so
those builds will not interfere with each other. You can for example have a GCC
build, a Clang build and a debug build in different directories.

To then install SciPy into the prefix (``installdir/`` here, but note that
that's just an arbitrary name we picked here)::

  meson install -C build

It will then install to ``installdir/lib/python3.9/site-packages/scipy``, which
is not on your Python path, so to add it do (*note, having to use ``PYTHONPATH``
is temporary, this will be changed once we merge support for building wheels*)::

  export PYTHONPATH=$PWD/installdir/lib/python3.9/site-packages/

Now we should be able to import ``scipy`` and run the tests. Remembering that
we need to move out of the root of the repo to ensure we pick up the package
and not the local ``scipy/`` source directory::

  cd doc
  python -c "from scipy import constants as s; s.test()"

The above runs the tests for a single module, ``constants``. Other ways of
running the tests should also work, for example::

  pytest --pyargs scipy

Current status (24 Dec '21) is that the full test suite passes on Linux, macOS
and Windows with OpenBLAS, without any build warnings on Linux (with GCC 9 at
least) and a moderate amount on the other platforms. There is CI (one job in
SciPy ``main``, and more on ``@rgommers``'s fork) to keep it that way.
The current status is already good enough to work on both build related issues
(e.g. build warnings, debugging some C/C++ extension) and on general SciPy
development. It is already a much smoother/faster experience than
working with the default ``distutils``-based build one gets with
``python setup.py develop`` - especially when working on compiled code.


The ``dev.py`` interface
========================

The above configure-build-install-test docs are useful to understand how the
Meson build works, and for working on build improvements.
If you want the "all-in-one" command for all of the above, run::

  python dev.py

This interface has many options, allowing you to perform all regular
development-related tasks (building, running tests, building docs, running
benchmarks, etc.). Here we document a few of the most commonly used options;
run ``python dev.py --help`` for more details.

Use the following command to build and install SciPy::

  python dev.py --build-only

To run the tests use (``-n`` is short for ``--no-build``)::

  python dev.py -n

To run the tests for a particular submodule(let's say ``optimize``), you can use::

  python dev.py -n -s optimize


To learn more about Meson
=========================

It's worth pointing out that Meson has `very good documentation <https://mesonbuild.com/>`__;
it pays off to read it, and is often the best source of answers for "how to do X". Furthermore, an extensive pdf book on Meson can be obtained for free at https://nibblestew.blogspot.com/2021/12/this-year-receive-gift-of-free-meson.html

To learn more about the design principles Meson uses, the recent talks linked
from `mesonbuild.com/Videos <https://mesonbuild.com/Videos.html>`__ are also a
good resource.

For running the Linux Meson CI job locally, one can use the ``act`` tool, see
:ref:`using-act`.


Frequently asked questions
==========================

**Q: What are the changes in dependencies when switching to Meson?**

There are a couple of new dependencies:

- ``meson``: the Meson build system, installable as a pure Python package from
  PyPI or conda-forge
- ``ninja``: the build tool invoked by Meson to do the actual building (e.g.
  invoking compilers). Installable also from PyPI (on all common platforms) or
  conda-forge.
- ``pkg-config``: the tool used for discovering dependencies (in particular
  BLAS/LAPACK). Available on conda-forge (and Homebrew, Chocolatey, and Linux
  package managers), but not packaged on PyPI.

In case your ``pkg-config`` is not on the ``PATH`` and you don't want to add
it, you can set an environment variable to let Meson find it. For example for
Homebrew:
``export PKG_CONFIG_PATH="/opt/homebrew/opt/openblas/lib/pkgconfig"``.

Note that we are also losing dependencies, namely ``numpy.distutils`` and
``setuptools``. Overall we are (a) switching build systems, and (b) adding
``pkg-config`` for more reliable dependency discovery than the hardcoded paths
that ``numpy.distutils`` used.

**Q: I currently use in-place builds, how is my workflow changing?**

Meson by design does not support in-place builds. This has advantages (e.g.,
one can use multiple parallel builds, caching becomes easier, etc.) - however
it does mean that one current workflow is no longer supported.

The recommended workflow is to use ``python dev.py``. This works exactly the
same way as ``python runtests.py`` worked before. What it does is rebuild if
needed, and then install SciPy to a private directory (default is
``installdir/`` in-tree) before running tests or other development tasks. This
way modifications to pure Python code get picked up.

If you use an IDE with, e.g., a "Run" button for scripts which were pointing to
an in-place build, and you would really like to continue using that same
workflow instead of ``python dev.py``, then you have a few options:

- After modifying pure Python code in the SciPy repo, install it on the command
  line with ``python dev.py --only-build``, or with ``meson install -C build``
  before running your script.
- If your IDE supports it, customize what the "Run" button does before running
  the script, to do the install each time (this is expected to take 2-3 sec.)
  before executing the script. *Note that the Spyder IDE does not yet support
  this; its developers are looking at implementing support before the SciPy
  1.9.0 release).*

**Q: I'm seeing a warning "Broken python installation detected. ..."**

Please ignore these warnings, they are innocuous. They indicate that the
install path is outside of a ``site-packages`` directory (which we prefer as
the default for ``python dev.py``). We are working with the Meson maintainers
to improve the support for this install method or at least make the warnings
less scary.

**Q: How do the current build/install commands change?**

*Old workflows (numpy.distutils based):*

1. ``python runtests.py``
2. ``python setup.py build_ext -i`` + ``export
   PYTHONPATH=/home/username/path/to/scipy/reporoot`` (and then edit pure
   Python code in SciPy and run it with ``python some_script.py``).
3. ``python setup.py develop`` - this is similar to (2), except in-place build
   is made permanently visible in env.
4. ``python setup.py bdist_wheel`` + ``pip install dist/scipy*.whl`` - build
   wheel in current env (i.e. uses installed numpy, etc.) and install it.
5. ``pip install .`` - build wheel in an isolated build env against deps in
   ``pyproject.toml`` and install it. *Note: be careful, this is usually not
   the correct command for development installs - typically you want to use (4)
   or* ``pip install . -v --no-build-isolation``.

*New workflows (Meson based):*

Note that currently (29 Dec 2021) only (1) is implemented. The rest is to be
added/documented in follow-up PRs over the next few weeks to months.

1. ``python dev.py``
2. *no direct equivalent for in-place builds (but see FAQ entry on in-place
   builds)*
3. *same as (2)*
4. ``python -m build --no-isolation`` + ``pip install dist/scipy*.whl`` - see
   `pypa/build <https://pypa-build.readthedocs.io/en/latest/>`_; it's also
   possible Meson will gain the capability to build wheels directly, but
   ``python -m build`` is going to become the standard way of doing this.
5. ``pip install .`` - this will work unchanged after switching the default in
   ``pyproject.toml`` to Meson.

.. _contributor-toc:

=======================
SciPy contributor guide
=======================

This guide is designed to help you quickly find the information you need about SciPy development after you've reviewed the introductory material in :ref:`hacking`. If you're new to this and want to start coding ASAP, you've found the right place.

- :ref:`dev-env` - how to set up and maintain a development environment, including installing compilers and SciPy dependencies, creating a personal fork of the SciPy repository on GitHub, using git to manage a local repository with development branches, performing an in-place build of SciPy, and creating a virtual environment that adds this development version of SciPy to the Python path
- :ref:`editing-scipy` - how to edit SciPy Python code, with tips on finding which module contains SciPy functionality to be edited, adding new modules to SciPy, and complying with PEP8 style standards
- :ref:`unit-tests` - how to write and run unit tests for SciPy with the pytest framework
- :ref:`docs` - how to write reStructuredText documentation that complies with docstring standards, build documentation locally with Sphinx, and view documentation built during continuous integration checks
- :ref:`toc-benchmarking` - how to benchmark code with airspeed velocity
- :ref:`toc-cython` - how to add fast, compiled code to SciPy
- :ref:`continuous-integration` - how does our continuous integration system works and how to debug your PR

.. _dev-env:

Development environment
-----------------------
- :ref:`quickerstart-conda` contains just the commands you need to get started on Mac and Linux
- :ref:`quickstart-pip` presents an overview of setting up the development environment using pip on Linux
- :ref:`quickstart-mac` presents a step-by-step process for setting up a convenient SciPy development environment in macOS
- :ref:`quickstart-ubuntu` presents a step-by-step process for setting up a convenient SciPy development environment in Ubuntu
- :ref:`build-windows` presents a step-by-step process for building SciPy on Windows
- :ref:`quickstart-docker` presents a step-by-step process for building SciPy using Docker; if you have trouble with the instructions above, this may be your best option
- :ref:`quickstart-gitpod` presents a step-by-step process for using Gitpod for SciPy development; this process requires minimal setup and is newcomer friendly
- :ref:`building` may have some helpful hints if you need to deviate from the guides above
- :ref:`recommended-development-setup` includes additional notes about the development setup; all of this information is contained elsewhere, but it is retained as a legacy document
- :ref:`meson` for how to use the Meson build system (experimental, it will replace the ``distutils``-based build in the future)

.. _editing-scipy:

Editing SciPy
-------------
- :ref:`development-workflow` lays out what to do after your development environment is set up
- `SciPy Development Workflow`_ is a five-minute video example of fixing a bug and submitting a pull request
- :ref:`pep8-scipy` gives some tips for ensuring that your code is PEP8 compliant
- :ref:`git-development` is a guide to using ``git``, the distributed version-control system used to manage the changes made to SciPy code from around the world
- :ref:`scipy-api` contains some important notes about how SciPy code is organized and documents the structure of the SciPy API; if you are going to import other SciPy code, read this first
- :ref:`reviewing-prs` explains how to review another author's SciPy code locally
- :doc:`numpy:reference/distutils_guide` - check this out before adding any new files to SciPy
- :ref:`adding-new` has information on how to add new methods, functions and classes
- :ref:`core-dev-guide` has background information including how decisions are made and how a release is prepared; it's geared toward :ref:`Core Developers <governance>`, but contains useful information for all contributors


.. _unit-tests:

Unit tests
----------
- :doc:`numpy:reference/testing` is the definitive guide to writing unit tests of SciPy code
- :ref:`runtests` documents ``runtests.py``, a convenient script for building SciPy and running tests locally

.. _docs:

Documentation
-------------
- :ref:`numpy:howto-document` contains everything you need to know about writing docstrings, which are rendered to produce HTML documentation using `Sphinx`_
- :ref:`rendering-documentation` it's important to check how changes to the documentation render before merging a PR; this document explains how you can do that

.. _toc-benchmarking:

Benchmarks
----------
- :ref:`benchmarking-with-asv` explains how to add benchmarks to SciPy using `airspeed velocity`_


.. _toc-cython:

.. _compiled-code:

Compiled code
-------------
- :ref:`adding-cython` extending and compiling Python code with `Cython`_ can significantly improve its performance; this document helps you get started
- :ref:`other-languages` discusses the use of C, C++, and Fortran code in SciPy
- :ref:`public-cython-api` on guidelines on exposing public Cython APIs

.. _Scipy Development Workflow: https://youtu.be/HgU01gJbzMY

.. _Sphinx: http://www.sphinx-doc.org/en/master/

.. _Airspeed Velocity: https://asv.readthedocs.io/en/stable/

.. _Cython: https://cython.org/

.. |*| replace:: \ :sup:`*` \
.. _using-act:

========================================
`act` for running GitHub Actions locally
========================================

``act`` is a tool offered by Nektos which provides a handy way to run GitHub
Actions locally using Docker. ``act`` provides a quick way to validate your
changes on the CI locally, without committing/pushing your changes to the
workflows to trigger and validate the same. It leads to fast feedback and its
compatibility as a local task runner, to validate all our CI jobs makes it a
handy tool.

``act`` can be set up locally with Homebrew, Chocolatey or even a simple BASH
script. To set it up using the BASH script, just push the following command on
your terminal::

  curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash

Using Homebrew you can set it up via: ``brew install act``.

The next step is to define the custom image that we can use to run our actions
locally. ``act`` provides a micro, medium and larger Docker image for Ubuntu
GitHub runner. ``act`` does not support Windows and macOS images yet.

While running ``act`` for the first time, we can define the image that we would
like to utilize for our local CI runs. The configuration is saved inside the
``~/.actrc`` file.

In a GitHub repository, while running ``act`` for the first time, it will find
the ``./.github/workflows`` and all the workflows present. To checkout the jobs
listed as part of the GitHub Actions CI, push the following command::

  act -l

It will list all the jobs and you can pick up the particular jobs you wish to
run. If you are looking to run a particular job, push in the following
command::

  act -j <JOB_NAME>

To run the job in dry run, push in the following command::

  act -n

To run the job with verbose logging, push in the following command::

  act -v

To reuse the containers in `act` to maintain state, push in the following command::

  act -j <JOB_NAME> --bind --reuse

It is recommended to comment out GitHub specific events like
``github.repository`` or ``github.event.head_commit.message``. If you are using
environment variables, in your action, it is recommended to have a
``my.secrets`` file and supply these environment variables to the ``act`` by
pushing the following command::

  act --secret-file my.secrets

If the environment variables are supplied via `.env` file, use the following
command::

  act --env-file my.env

.. _adding-new:

Adding New Methods, Functions, and Classes
==========================================


While adding code to SciPy is in most cases quite straight forward, there are a few places where that is not the case.
This document contains detailed information on some specific situations where
it may not be clear from the outset what is involved in the task.

.. include:: adding_new/new_stats_distribution.rst.inc
:orphan:

.. _adding-cython:

Adding Cython to SciPy
======================

As written on the `Cython website`_:

 Cython is an optimising static
 compiler for both the Python programming language and the extended
 Cython programming language (based on Pyrex). It makes writing C
 extensions for Python as easy as Python itself.

If your code currently performs a lot of loops in Python, it might
benefit from compilation with Cython. This document is intended to be a
very brief introduction: just enough to see how to use Cython with
SciPy. Once you have your code compiling, you can learn more about how
to optimize it by reviewing the `Cython documentation`_.

There are only two things you need to do in order for SciPy compile your
code with Cython:

#. Include your code in a file with a ``.pyx``
   extension rather than a ``.py`` extension. All files with a ``.pyx``
   extension are automatically converted by Cython to ``.c`` files when
   SciPy is built.

#. Add an extension from this ``.c`` file to the
   configuration of the subpackage in which your code lives. Typically,
   this is very easy: add a single, formulaic line to the subpackage’s
   ``setup.py`` file. Once added as an extension, the ``.c`` code will be
   compiled by your C compiler to machine code when SciPy is built.

Example
-------

|linprog-rs|_ contains the implementation of the
revised simplex method for ``scipy.optimize.linprog``. The revised
simplex method performs many elementary row operations on matrices, and
so it was a natural candidate to be Cythonized.

Note that ``scipy/optimize/_linprog_rs.py`` imports the ``BGLU`` and
``LU`` classes from ``._bglu_dense`` exactly as if they were regular
Python classes. But they’re not. ``BGLU`` and ``LU`` are Cython classes
defined in |bglu-dense|_. There is nothing
about the way they are imported or used that suggests that they are
written in Cython; the only way so far that we can tell they are Cython
classes is that they are defined in a file with a ``.pyx`` extension.

Even in ``/scipy/optimize/_bglu_dense.pyx``, most of the code resembles
Python. The most notable differences are the presence of |cimport|_,
|cdef|_, and `Cython decorators`_. None of these are strictly
necessary. Without them, the pure Python code can still be compiled by
Cython. The Cython language extensions are \*just\* tweaks to improve
performance. This ``.pyx`` file is automatically converted to a ``.c``
file by Cython when SciPy is built.

The only thing left is to add an extension from this ``.c`` file using
|distutils|_. This takes just a single line in |optimize-setup|_:
``config.add_extension('_bglu_dense', sources=['_bglu_dense.c'])``,
``_bglu_dense.c`` is the source and ``_bglu_dense`` is the name of the
extension (for consistency). When SciPy is built, ``_bglu_dense.c`` will
be compiled to machine code, and we will be able to import the ``LU``
and ``BGLU`` classes from the extension ``_bglu_dense``.

Exercise
--------

*See a video run-through of this exercise:* \ `Cythonizing SciPy Code`_ \

#. Update Cython and create a new branch
   (e.g., ``git checkout -b cython_test``) in which to make some
   experimental changes to SciPy

#. Add some simple Python code in a ``.py`` file in the
   ``/scipy/optimize`` directory, say ``/scipy/optimize/mypython.py``.
   For example:

   ::

      def myfun():
          i = 1
          while i < 10000000:
              i += 1
          return i

#. Let’s see how long this pure-Python loop takes so we can compare the
   performance of Cython. For example, in an IPython console in Spyder:

   ::

      from scipy.optimize.mypython import myfun
      %timeit myfun()

   I get something like:

   ::

      715 ms ± 10.7 ms per loop

#. Save your ``.py`` file to a ``.pyx`` file, e.g. \ ``mycython.pyx``.

#. Build SciPy. Note that a ``.c`` file has been added to the
   ``/scipy/optimize`` directory.

#. Somewhere near similar lines, add an extension from your ``.c`` file
   to ``/scipy/optimize/setup.py``. e.g.:

   ::

      config.add_extension('_group_columns', sources=['_group_columns.c'],)  # was already here
      config.add_extension('mycython', sources=['mycython.c'],)  # this was new
      config.add_extension('_bglu_dense', sources=['_bglu_dense.c'])  # was already there

#. Rebuild SciPy. Note that a ``.so`` file has been added to the
   ``/scipy/optimize`` directory.

#. Time it:

   ::

      from scipy.optimize.mycython import myfun
      %timeit myfun()

   I get something like:

   ::

      359 ms ± 6.98 ms per loop

   Cython sped up the pure Python code by a factor of ~2.

#.  That’s not much of an improvement in the scheme of things. To see
    why, it helps to have Cython create an “annotated” version of our
    code to show bottlenecks. In a terminal window, call Cython on your
    ``.pyx`` file with the ``-a`` flag:

    ::

       cython -a scipy/optimize/mycython.pyx

    Note that this creates a new ``.html`` file in the
    ``/scipy/optimize`` directory. Open the ``.html`` file in any
    browser.

#.  The yellow-highlighted lines in the file indicate potential
    interaction between the compiled code and Python, which slows things
    down considerably. The intensity of the highlighting indicates the
    estimated severity of the interaction. In this case, much of the
    interaction can be avoided if we define the variable ``i`` as an
    integer so that Cython doesn’t have to consider the possibility of
    it being a general Python object:

    ::

       def myfun():
           cdef int i = 1  # our first line of Cython code
           while i < 10000000:
               i += 1
           return i

    Recreating the annotated ``.html`` file shows that most of the
    Python interaction has disappeared.

#. Rebuild SciPy, open an fresh IPython console, and ``%timeit``:

::

   from scipy.optimize.mycython import myfun
   %timeit myfun()

I get something like: ``68.6 ns ± 1.95 ns per loop``. The Cython code ran
about 10 million times faster than the original Python code.

In this case, the compiler probably optimized away the loop, simply
returning the final result. This sort of speedup is not typical for real
code, but this exercise certainly illustrates the power of Cython when
the alternative is many low-level operations in Python.

.. _Cython website: https://cython.org/
.. _Cython documentation: http://docs.cython.org/en/latest/

.. |cimport| replace:: ``cimport``
.. _cimport: https://cython.readthedocs.io/en/latest/src/userguide/sharing_declarations.html

.. |cdef| replace:: ``cdef``
.. _cdef: https://github.com/scipy/scipy/blob/main/scipy/optimize/setup.py

.. _Cython decorators: https://cython.readthedocs.io/en/latest/src/userguide/numpy_tutorial.html

.. |linprog-rs| replace:: ``scipy.optimize._linprog_rs.py``
.. _linprog-rs: https://github.com/scipy/scipy/blob/main/scipy/optimize/_linprog_rs.py

.. |bglu-dense| replace:: ``/scipy/optimize/_bglu_dense.pyx``
.. _bglu-dense: https://github.com/scipy/scipy/blob/main/scipy/optimize/_bglu_dense.pyx

.. |distutils| replace:: ``numpy.distutils``
.. _distutils: https://docs.scipy.org/doc/numpy/reference/distutils.html

.. |optimize-setup| replace:: ``scipy/optimize/setup.py``
.. _optimize-setup: https://github.com/scipy/scipy/blob/main/scipy/optimize/setup.py

.. _Cythonizing SciPy Code: https://youtu.be/K9bF7cjUJ7c
:orphan:

.. _quickstart-ubuntu:

=======================================================
Development environment quickstart guide (Ubuntu)
=======================================================

This quickstart guide will cover:

* setting up and maintaining a development environment, including installing compilers and SciPy build dependencies;
* creating a personal fork of the SciPy repository on GitHub;
* using git to manage a local repository with development branches;
* performing an in-place build of SciPy; and
* creating a virtual environment that adds this development version of SciPy to the Python path

in Ubuntu. (Tested on 16.04, 18.04, and 20.04). *Users running Windows can follow these
instructions after setting up* `Windows Subsystem for Linux`_ *or an Amazon EC2
instance with Ubuntu 20.04. However, the instructions for setting up a
development environment with Docker may be more reliable.*

.. note::

   This guide does not present the only way to set up a development environment; there are many valid choices of Python distribution, C/Fortran compiler, and installation options. The steps here can often be adapted for other choices, but we cannot provide documentation tailored for them.

   This guide assumes that you are starting without an existing Python 3 installation. If you already have Python 3, you might want to uninstall it first to avoid ambiguity over which Python version is being used at the command line.

.. _quickstart-ubuntu-build:

Building SciPy
--------------

#. Download, install, and test the latest release of the `Anaconda Distribution of Python`_. In addition to the latest version of Python 3, the Anaconda Distribution includes dozens of the most popular Python packages for scientific computing, the ``conda`` package manager, and tools for managing virtual environments.

   If you're installing using the terminal, be sure to follow the "Next Steps"
   listed after the installer finishes. You might also need to restart your
   terminal window or enter ``source ~/.bashrc`` for all the changes to take
   effect.

#. (Optional) In a terminal window, enter ``conda list``. |br| This shows a list of all the Python packages that came with the Anaconda Distribution of Python. Note the latest released version of SciPy is among them; this is not the development version you are going to build and will be able to modify.

   Ideally, we'd like to have both versions, and we'd like to be able to switch between the two as needed. `Virtual environments <https://medium.freecodecamp.org/why-you-need-python-environments-and-how-to-manage-them-with-conda-85f155f4353c>`_ can do just that. With a few keystrokes in the terminal or even the click of an icon, we can enable or disable our development version. Let's set that up.

   .. note::

      If ``conda`` is not a recognized command, try restarting your terminal. If it is still not recognized, please see "Should I add Anaconda to the macOS or Linux PATH?" in the `Anaconda FAQ`_.

#. Enter ``conda config --env --add channels conda-forge`` to tell Anaconda the source we want for our packages. Then enter ``conda create --name scipydev python=3.8 numpy pybind11 cython pythran pytest gfortran_linux-64 gxx_linux-64 sphinx pydata-sphinx-theme sphinx-panels matplotlib mypy git``. |br| This tells ``conda`` to create a virtual environment named ``scipydev`` (or another name that you prefer) with several packages.

   * ``numpy pybind11 cython pythran`` are four packages that SciPy depends on.

   * ``gfortran_linux-64 gxx_linux-64`` are compilers used to build SciPy's Fortran, C, and C++ source code.

   * ``pytest`` is needed for running the test suite.

   * ``sphinx``, ``pydata-sphinx-theme``, ``sphinx-panels`` and ``matplotlib`` are required to render the SciPy documentation.

   * ``mypy`` is a static type checker for Python. Consider using it.

   * ``git`` is a version control system used to download and manage the SciPy source code.

   Note that we're installing SciPy's build dependencies and some other software, but not SciPy itself.

   .. note::

      You could ``conda create`` an empty virtual environment first, then
      ``conda install`` the packages, but creating the virtual environment
      with all the packages you need is preferable to installing packages
      individually because it makes it easier for ``conda`` to solve
      the package dependencies optimally.

#. You're still in the base environment. Activate your new virtual environment by entering ``conda activate scipydev``. |br| If you're working with an old version of ``conda``, you might need to type ``source activate scipydev`` instead (see `here <https://stackoverflow.com/questions/49600611/python-anaconda-should-i-use-conda-activate-or-source-activate-in-linux)>`__). Note that you'll need to have this virtual environment active whenever you want to work with the development version of SciPy.

#. Browse to the `SciPy repository on GitHub <https://github.com/scipy/scipy>`_ and `create your own fork <https://help.github.com/en/articles/fork-a-repo>`_. You'll need to create a GitHub account if you don't already have one.

#. Browse to your fork. Your fork will have a URL like `https://github.com/mdhaber/scipy <https://github.com/mdhaber/scipy>`_, except with your GitHub username in place of "mdhaber".

#. Click the big, green "Clone or download" button, and copy the ".git" URL to the clipboard. The URL will be the same as your fork's URL, except it will end in ".git".

#. Create a folder for the SciPy source code in a convenient place on your computer. Navigate to it in the terminal.

#. Enter the command ``git clone`` followed by your fork's .git URL. Note that this creates in the terminal's working directory a ``scipy`` folder containing the SciPy source code.

#. In the terminal, navigate into the ``scipy`` root directory (e.g. ``cd scipy``).

#. Initialize git submodules: ``git submodule update --init``.

#. Do an in-place build: enter ``python3 setup.py build_ext --inplace``. |br| This will compile the C, C++, and Fortran code that comes with SciPy. We installed ``python3`` with Anaconda. ``setup.py`` is a script in the root directory of SciPy, which is why you have to be in the SciPy root directory to call it. ``build_ext`` is a command defined in ``setup.py``, and ``--inplace`` is an option we'll use to ensure that the compiling happens in the SciPy directory you already have rather than the default location for Python packages. By building in-place, you avoid having to re-build SciPy before you can test changes to the Python code.

#. Test the build: enter ``python3 runtests.py -v``. ``runtests.py`` is another script in the SciPy root directory. It runs a suite of tests that make sure SciPy is working as it should, and ``-v`` activates the ``--verbose`` option to show all the test output. If the tests are successful, you now have a working development build of SciPy! You could stop here, but you would only be able to use this development build when the Python working directory is the SciPy root directory.

#. Enter ``conda develop .``, where ``.`` refers to the present directory. |br| This will allow us to ``import`` the development version of SciPy in Python regardless of Python's working directory.

#. In a new terminal window, test your setup. If you activate your virtual environment (e.g. ``conda activate scipydev``) and run Python code that imports from SciPy, any changes you make to the SciPy code should be reflected when the code runs. After deactivating the virtual environment (``conda deactivate``), Python imports from the version of SciPy installed by Anaconda. You can also check which version of SciPy you're using by executing in Python::

      import scipy
      print(scipy.__version__)

   If you have successfully imported a development version of SciPy, the word ``dev`` will appear in the output, e.g.::

      1.6.0.dev0+be97f1a


.. _Anaconda SciPy Dev\: Part I (macOS): https://youtu.be/1rPOSNd0ULI

.. _Anaconda SciPy Dev\: Part II (macOS): https://youtu.be/Faz29u5xIZc

.. _Anaconda Distribution of Python: https://www.anaconda.com/distribution/

.. _Rename the file: https://www.maketecheasier.com/rename-files-in-linux/

.. _Anaconda FAQ: https://docs.anaconda.com/anaconda/user-guide/faq/

.. _Homebrew on Linux: https://docs.brew.sh/Homebrew-on-Linux

.. _Windows Subsystem for Linux: https://docs.microsoft.com/en-us/windows/wsl/install-win10

.. |PYTHONPATH| replace:: ``PYTHONPATH``
.. _PYTHONPATH: https://docs.python.org/3/using/cmdline.html#environment-variables

.. |br| raw:: html

    <br>
:orphan:

.. _quickstart-pip:

======================================================================
Development environment quickstart guide using ``pip`` on Ubuntu Linux
======================================================================

This is a high-level overview of what is needed to set up a development
environment. This is only one possible way out of many. This guide assumes
you have a fresh install of Ubuntu Linux 20.04, which only has a ``python3``
executable. We also assume you have already installed ``git``, cloned
the SciPy repository and initialized/updated git submodules.


Installing the system-level dependencies
----------------------------------------

First, you will also need the compilers for C, C++ and Fortran::

    sudo apt install -y gcc g++ gfortran

SciPy also requires BLAS and LAPACK libraries. You can install several variants
(ATLAS, OpenBLAS etc), but here we take the simplest option::

    sudo apt install -y liblapack-dev


Installing the python-level dependencies
----------------------------------------

Start with installing ``pip``::

    sudo apt install -y python3-pip

All further work should proceed in a virtual environment. Popular options include
the standard library ``venv`` module or a separate
``virtualenv`` package. There are muliple third-party tutorials on how to
set up a virtual environment, so we cover only briefly these two options
here.

.. note::

    We repeat: all work should happen in a virtual environment. Never use ``sudo pip``.


Using ``virtualenv``
~~~~~~~~~~~~~~~~~~~~

Install the ``virtualenvwrapper`` package::

    python3 -m pip install virtualenvwrapper --user

Edit the ``.bashrc`` file to add some environment variables which are used
internally by the ``virtualenvwrapper``::

    export WORKON_HOME=$HOME/virtualenvs
    export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3
    . $HOME/.local/bin/virtualenvwrapper.sh

Here we store the virtualenvs in a ``virtualenvs`` folder in the home directory.
(you might need to create the folder manually).

Now open a new terminal window for the changes to the ``.bashrc`` to take effect.

Create a new virtual environment and activate it::

    mkvirtualenv scipy-dev

Your command prompt now lists the name of your new environment, like so
``(scipy-dev)$``. This means that the environment is active. If it is not,
activate it manually with::

    workon scipy-dev

Note ``mkvirtualenv`` and ``workon`` commands come from the ``virtualwrapper``
package.



Using the standard-library ``venv`` package
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Install the ``venv`` package::

    sudo apt install -y python3-venv

Change the directory to your home folder and create a directory ``.venvs`` there.
Create the virtualenvironment::

    python3 -m venv scipy-dev

To activate the environment, use ::

    source $HOME/.venvs/scipy-dev/bin/activate

Your command prompt now lists the name of your new environment, like so
``(scipy-dev)$``.

(For the official docs for the ``venv`` package see
https://docs.python.org/3/tutorial/venv.html).


Building SciPy
--------------

Inside the ``scipy-dev`` environment, install the python-level dependencies::

    python -m pip install numpy pytest cython pythran pybind11

Note that when the virtual environment is active, the system-wide names ``pip3``
and ``python3`` are aliased to ``pip`` and ``python``, respectively.

Now that you have all external dependencies, navigate to the directory where
you cloned the source code into. Download the submodules::

    git submodule update --init

And build SciPy (this takes a while)::

    python setup.py build

Optionally, test it::

    python runtests.py


:orphan:

.. _quickstart-gitpod:

=======================================================
Development environment quickstart guide (Gitpod)
=======================================================

This quick start guide covers:

*  using GitPod for your SciPy development environment
*  creating a personal fork of the SciPy repository on GitHub
*  a quick tour of Gitpod and VSCode
*  working on the SciPy documentation in Gitpod

Gitpod
-------

`Gitpod`_  is an open-source platform for automated and ready-to-code development environments. It enables developers to describe their dev environment as code and start instant and fresh development environments for each new task directly from your browser. This reduces the need to install local development environments and deal with incompatible dependencies.

Gitpod GitHub integration
--------------------------

To be able to use Gitpod, you will need to have the Gitpod app installed on your GitHub account, so if
you do not have an account yet, you will need to create one first.

Head over to the `Gitpod`_ website and click on the **Continue with GitHub** button. You will be redirected to the GitHub authentication page.
You will then be asked to install the `Gitpod GitHub app <https://github.com/marketplace/gitpod-io>`_.

Make sure to select **All repositories** access option to avoid issues with permissions later on. Click on the green **Install** button

.. image:: ../../_static/gitpod/installing-gitpod-io.png
    :alt: Gitpod repository access and installation screenshot

This will install the necessary hooks for the integration.

Forking the SciPy repository
-----------------------------

The best way to work on SciPy as a contributor is by making a fork of the repository first.

#. Browse to the `SciPy repository on GitHub`_ and `create your own fork`_.

#. Browse to your fork. Your fork will have a URL like https://github.com/andyfaff/scipy, except with your GitHub username in place of "andyfaff".

Starting Gitpod
----------------
Once you have authenticated to Gitpod through GitHub, you can install the `Gitpod browser extension <https://www.gitpod.io/docs/browser-extension>`_  which will add a **Gitpod** button next to the **Code** button in the repository:

.. image:: ../../_static/gitpod/scipy-github.png
    :alt: SciPy repository with Gitpod button screenshot

#. If you install the extension - you can click the **Gitpod** button to start a new workspace.
#. Alternatively, if you do not want to install the browser extension you can visit https://gitpod.io/#https://github.com/USERNAME/scipy replacing ``USERNAME`` with your GitHub username.

#. In both cases, this will open a new tab on your web browser and start building your development environment. Please note this can take a few minutes.

#. Once the build is complete, you will be directed to your workspace, including VSCode and all the dependencies you need to work on SciPy. The first time you start your workspace, you will notice that there might be some actions running. This will ensure that you have a development version of SciPy installed and that the docs are being pre-built for you.

#. Once the build is complete, you can test the build by entering::

        python runtests.py -v

``runtests.py`` is another script in the SciPy root directory. It runs a suite of tests that make sure SciPy is working as it should, and ``-v`` activates the ``--verbose`` option to show all the test output.

Quick workspace tour
---------------------
Gitpod uses VSCode as the editor. If you have not used this editor before, you can check the Getting started `VSCode docs`_ to familiarise yourself with it.

Your workspace will look similar to the image below:

.. image:: ../../_static/gitpod/gitpod-workspace.png
    :alt: Gitpod workspace screenshot

.. note::  By default VSCode initialises with a light theme, you can change to a dark theme by with the keyboard shortcut :kbd:`Cmd-K Cmd-T` in Mac or :kbd:`Ctrl-K Ctrl-T` in Linux and Windows.

We have marked some important sections in the editor:

#. Your current Python interpreter - by default, the ``scipy-dev`` is marked as ``base`` on the status bar, but it should be displayed as ``scipy-dev`` on your terminal. You do not need to activate the conda environment as this will always be activated for you.
#. Your current branch is always displayed in the status bar. You can also use this button to change or create branches.
#. GitHub Pull Requests extension - you can use this to work with Pull Requests from your workspace.
#. Marketplace extensions - we have added some essential extensions to the SciPy Gitpod. Still, you can also install other extensions or syntax highlighting themes for your user, and these will be preserved for you.
#. Your workspace directory - by default is ``/workspace/scipy`` **do not change this** as this is the only directory preserved in Gitpod.

We have also pre-installed a few tools and VSCode extensions to help with the development experience:

*  `GitHub CLI <https://cli.github.com/>`_
*  `VSCode rst extension <https://marketplace.visualstudio.com/items?itemName=lextudio.restructuredtext>`_
*  `VSCode Live server extension <https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer>`_
*  `VSCode Gitlens extension <https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens>`_
*  `VSCode autodocstrings extension <https://marketplace.visualstudio.com/items?itemName=njpwerner.autodocstring>`_
*  `VSCode Git Graph extension <https://marketplace.visualstudio.com/items?itemName=mhutchie.git-graph>`_

Development workflow
-----------------------
The  :ref:`development-workflow` section of this documentation contains information regarding the SciPy development workflow. Make sure to check this before working on your contributions.

When using Gitpod, note these main differences with the setup described in :ref:`development-workflow`.

#. You do not need to configure your git username, and email as this should be done for you as you authenticated through GitHub. You can check the git configuration with the command ``git config --list`` in your terminal.
#. As you started your workspace from your own SciPy fork, you will by default have both "upstream" and "origin" added as remotes. You can verify this by typing ``git remote`` on your terminal or by clicking on the **branch name** on the status bar (see image below).

.. image:: ../../_static/gitpod/scipy-gitpod-branches.png
    :alt: Gitpod workspace branches plugin screenshot

Rendering the SciPy documentation
----------------------------------
You can find the detailed documentation on how rendering the documentation with Sphinx works in the :ref:`rendering-documentation` section.

The documentation is pre-built during your workspace initialization. So once this task is completed, you have two main options to render the documentation in Gitpod.

Option 1: Using Liveserve
***************************

#. View the documentation in ``scipy/doc/build/html-scipyorg``. You can start with "index.html" and browse, or you can jump straight to the file you're interested in.
#. To see the rendered version of a page, you can right-click on the ``.html`` file and click on **Open with Live Serve**. Alternatively, you can open the file in the editor and click on the **Go live** button on the status bar.

    .. image:: ../../_static/gitpod/vscode-statusbar.png
        :alt: Gitpod workspace VSCode start live serve screenshot

#. A simple browser will open to the right-hand side of the editor. We recommend closing it and click on the **Open in browser** button in the pop-up.
#. To stop the server click on the **Port: 5500** button on the status bar.

Option 2: Using the rst extension
***********************************

A quick and easy way to see live changes in a ``.rst`` file as you work on it uses the rst extension with docutils.

.. note:: This will generate a simple live preview of the document without the ``html`` theme, and some backlinks might not be added correctly. But it is an easy and lightweight way to get instant feedback on your work.

#. Open any of the source documentation files located in ``doc/source`` in the editor.
#. Open VSCode Command Palette with :kbd:`Cmd-Shift-P` in Mac or :kbd:`Ctrl-Shift-P` in Linux and Windows. Start typing "restructured" and choose either "Open preview" or "Open preview to the Side".

    .. image:: ../../_static/gitpod/vscode-rst.png
        :alt: Gitpod workspace VSCode open rst screenshot

#. As you work on the document, you will see a live rendering of it on the editor.

    .. image:: ../../_static/gitpod/rst-rendering.png
        :alt: Gitpod workspace VSCode rst rendering screenshot

If you want to see the final output with the ``html`` theme you will need to rebuild the docs with ``make html-scipyorg`` and use Live Serve as described in option 1.

FAQ's
-----

#. How long is my Gitpod workspace kept for?
    Your stopped workspace will be kept for 14 days and deleted afterwards if you do not use them.

#. Can I come back to a previous workspace?
    Yes, let's say you stepped away for a while and you want to carry on working on your SciPy contributions. You need to visit https://gitpod.io/workspaces and click on the workspace you want to spin up again. All your changes will be there as you last left them.

#. Can I install additional VSCode extensions?
    Absolutely! Any extensions you installed will be installed in your own workspace and preserved.

#. I registered on Gitpod but I still cannot see a **Gitpod** button in my repositories
    Head to https://gitpod.io/integrations and make sure you are logged in. Hover over GitHub and click on the three buttons that appear on the right. Click on edit permissions and make sure you have ``user:email``, ``read:user``, and ``public_repo`` checked.
    Click on **Update Permissions** and confirm the changes in the GitHub application page.

    .. image:: ../../_static/gitpod/gitpod-edit-permissions-gh.png
        :alt: Gitpod integrations - edit GH permissions screenshot

#. How long does my workspace stay active if I'm not using it?
    If you keep your workspace open in a browser tab but don't interact with it, it will shut down after 30 minutes. If you close the browser tab, it will shut down after 3 minutes.

.. _Gitpod: https://www.gitpod.io/
.. _SciPy repository on GitHub: https://github.com/scipy/scipy
.. _create your own fork: https://help.github.com/en/articles/fork-a-repo
.. _VSCode docs: https://code.visualstudio.com/docs/getstarted/tips-and-tricks


.. |br| raw:: html

    <br>
:orphan:

.. _quickstart-mac:

=======================================================
Development environment quickstart guide (macOS)
=======================================================

This quickstart guide will cover:

* setting up and maintaining a development environment, including installing compilers and SciPy build dependencies;
* creating a personal fork of the SciPy repository on GitHub;
* using git to manage a local repository with development branches;
* performing an in-place build of SciPy; and
* creating a virtual environment that adds this development version of SciPy to the Python path

in macOS (Tested on 11.1).

.. note::

   This guide does not present the only way to set up a development environment; there are many valid choices of Python distribution, C/Fortran compiler, and installation options. The steps here can often be adapted for other choices, but we cannot provide documentation tailored for them.

   This guide assumes that you are starting without an existing Python 3 installation. If you already have Python 3, you might want to uninstall it first to avoid ambiguity over which Python version is being used at the command line.

.. _quickstart-mac-build:

Building SciPy
--------------

#. Install Apple Developer Tools. An easy way to do this is to `open a terminal window <https://blog.teamtreehouse.com/introduction-to-the-mac-os-x-command-line>`_, enter the command ``xcode-select --install``, and follow the prompts. Apple Developer Tools includes `git <https://git-scm.com/>`_, the software we need to download and manage the SciPy source code.

#. Download, install, and test the latest release of the `Anaconda Distribution of Python`_. In addition to the latest version of Python 3, the Anaconda Distribution includes dozens of the most popular Python packages for scientific computing, the ``conda`` package manager, and tools for managing virtual environments.

   If you're installing using the terminal, be sure to follow the "Next Steps"
   listed after the installer finishes. You might also need to restart your
   terminal window or enter ``source ~/.bash_profile`` for all the changes to take
   effect.

#. (Optional) In a terminal window, enter ``conda list``. This shows a list of all the Python packages that came with the Anaconda Distribution of Python. Note the latest released version of SciPy is among them; this is not the development version you are going to build and will be able to modify.

   Ideally, we'd like to have both versions, and we'd like to be able to switch between the two as needed. `Virtual environments <https://medium.freecodecamp.org/why-you-need-python-environments-and-how-to-manage-them-with-conda-85f155f4353c>`_ can do just that. With a few keystrokes in the terminal or even the click of an icon, we can enable or disable our development version. Let's set that up.

   .. note::

      If ``conda`` is not a recognized command, try restarting your terminal. If it is still not recognized, please see "Should I add Anaconda to the macOS or Linux PATH?" in the `Anaconda FAQ`_.

#. Enter ``conda create --name scipydev`` to create an empty virtual environment named ``scipydev`` (or another name that you prefer). This tells ``conda`` to create a new, empty environment for our packages. Activate the environment with ``conda activate scipydev``. Note that you'll need to have this virtual environment active whenever you want to work with the development version of SciPy.

#. Enter ``conda config --env --add channels conda-forge`` to tell Anaconda the source we want for our packages. Then enter ``conda install python=3.8 numpy pybind11 cython pythran pytest compilers sphinx pydata-sphinx-theme sphinx-panels matplotlib mypy`` to install the following packages:

   * ``numpy pybind11 cython pythran`` are four packages that SciPy depends on.

   * ``compilers`` holds compilers used to build SciPy's Fortran, C, and C++ source code.

   * ``pytest`` is needed for running the test suite.

   * ``sphinx``, ``pydata-sphinx-theme``, ``sphinx-panels`` and ``matplotlib`` are required to render the SciPy documentation.

   * ``mypy`` is a static type checker for Python. Consider using it.

   Note that we're installing SciPy's build dependencies and some other software, but not SciPy itself.

#. Browse to the `SciPy repository on GitHub <https://github.com/scipy/scipy>`_ and `create your own fork <https://help.github.com/en/articles/fork-a-repo>`_. You'll need to create a GitHub account if you don't already have one.

#. Browse to your fork. Your fork will have a URL like `https://github.com/mdhaber/scipy <https://github.com/mdhaber/scipy>`_, except with your GitHub username in place of "mdhaber".

#. Click the big, green "Clone or download" button, and copy the ".git" URL to the clipboard. The URL will be the same as your fork's URL, except it will end in ".git".

#. Create a folder for the SciPy source code in a convenient place on your computer. Navigate to it in the terminal.

#. Enter the command ``git clone`` followed by your fork's .git URL. Note that this creates in the terminal's working directory a ``scipy`` folder containing the SciPy source code.

#. In the terminal, navigate into the ``scipy`` root directory (e.g. ``cd scipy``).

#. Initialize git submodules: ``git submodule update --init``.

#. Do an in-place build: enter ``python3 setup.py build_ext --inplace``. |br| This will compile the C, C++, and Fortran code that comes with SciPy. We installed ``python3`` with Anaconda. ``setup.py`` is a script in the root directory of SciPy, which is why you have to be in the SciPy root directory to call it. ``build_ext`` is a command defined in ``setup.py``, and ``--inplace`` is an option we'll use to ensure that the compiling happens in the SciPy directory you already have rather than the default location for Python packages. By building in-place, you avoid having to re-build SciPy before you can test changes to the Python code.

#. Test the build: enter ``python3 runtests.py -v``. 

   * ``runtests.py`` is another script in the SciPy root directory. It runs a suite of tests that make sure SciPy is working as it should, and ``-v`` activates the ``--verbose`` option to show all the test output. If the tests are successful, you now have a working development build of SciPy! You could stop here, but you would only be able to use this development build when the Python working directory is the SciPy root directory.

#. Enter ``conda develop .``, where ``.`` refers to the present directory. |br| This will allow us to ``import`` the development version of SciPy in Python regardless of Python's working directory.

#. In a new terminal window, test your setup. If you activate your virtual environment (e.g. ``conda activate scipydev``) and run Python code that imports from SciPy, any changes you make to the SciPy code should be reflected when the code runs. After deactivating the virtual environment (``conda deactivate``), Python imports from the version of SciPy installed by Anaconda. You can also check which version of SciPy you're using by executing in Python::

      import scipy
      print(scipy.__version__)

   If you have successfully imported a development version of SciPy, the word ``dev`` will appear in the output, e.g.::

      1.6.0.dev0+be97f1a



.. _Anaconda Distribution of Python: https://www.anaconda.com/distribution/

.. _Anaconda FAQ: https://docs.anaconda.com/anaconda/user-guide/faq/


.. |PYTHONPATH| replace:: ``PYTHONPATH``
.. _PYTHONPATH: https://docs.python.org/3/using/cmdline.html#environment-variables

.. |br| raw:: html

    <br>
.. _continuous-integration:

======================
Continuous Integration
======================

Continuous integration is part of our development process and ensure that
every piece of code or documentation which is contributed to SciPy is working
and does not have unforeseen effects.

.. note:: Before submitting or updating your PR, please ensure that you tested
          your changes locally. See :ref:`pr-checklist` and :ref:`runtests`.

Workflows
=========

We run more than 20 different workflows with different versions of the
dependencies, different architectures, etc. A PR must pass all these checks
before it can be merged as to ensure a sustainable state of the project.

Apart from the unit tests, the documentation and examples in the docstrings are
also checked. These are common failing workflows as Sphinx and doctests have
very strict rules. These aspects are very important as documentation and
examples are user facing elements. Ensures that these elements are properly
rendered.

The logs can be long, but you will always find out why your build/test did not
pass a check. Simply click on ``Details`` to access the logs.

Following is a list of all the different workflows in use. They are grouped
by CI resources providers.

GitHub Actions
--------------
* ``Linux Tests``: test suite runs for Linux (``x86_64``)
* ``macOS Tests``: test suite runs for macOS (``x86_64``)

Test suite runs on GitHub Actions and other platforms cover a range of
test/environment conditions: Python and NumPy versions
(lowest-supported to nightly builds), 32-bit vs. 64-bit, different compilers,
and more - for details, see the ``.yml`` configuration files.

Azure
-----
* ``Lint``: PEP8 and code style
* ``Windows Python``: test suite runs for Windows
* ``Linux_Python_37_32bit_full``
* ``wheel_optimized_gcc48``
* ``source_distribution``: install via ``sdist``, then run the test suite
* ``refguide_asv_check``: doctests from examples and benchmarks

CircleCI
--------
* ``build_docs``: build the documentation
* ``build_docs artifact``: live preview of the documentation
* ``build_scipy``
* ``run_benchmarks``: verify how the changes impact performance

Codecov
-------
* ``patch``: the impact on code coverage due to your changes
* ``project``: the coverage of the whole project

Skipping
========

Being an open-source project, we have access to a quota of CI resources.
Ultimately, resources are limited and we should use them with care. This is
why we ask you to verify your changes locally before pushing them.

Depending on the proposed change, you might want to skip part of the checks.
It will be at the discretion of a maintainer to re-run some tests before
integration.

Skipping CI can be achieved by adding a special text in the commit message:

* ``[skip azp]``: will skip Azure
* ``[skip actions]``: will skip GitHub Actions
* ``[skip ci]``: will skip *all* CI

Of course, you can combine these to skip multiple workflows.

This skip information should be placed on a new line. In this example, we
just updated a ``.rst`` file in the documentation and ask to skip Azure and
GitHub Actions' workflows::

    DOC: improve QMCEngine examples.

    [skip azp] [skip actions]
:orphan:

.. _public-cython-api:

Public Cython APIs
==================

As of Apr 2020, the following modules in SciPy expose functionality
via a public ``cdef`` Cython API declarations:

- ``scipy.linalg.cython_blas``
- ``scipy.linalg.cython_lapack``
- ``scipy.optimize.cython_optimize``
- ``scipy.special.cython_special``

This uses `Cython's declaration sharing features
<cython-sharing-declarations>`_, where shared ``cdef`` items are
declared in ``*.pxd`` files that are distributed together with the
corresponding DLL/SO files in binary SciPy installations.

.. _cython-sharing-declarations: https://cython.readthedocs.io/en/latest/src/userguide/sharing_declarations.html


Application Binary Interface
----------------------------

Using these features in SciPy however requires SciPy contributors to
take additional care with regard to maintaining Application Binary
Interface (ABI) stability. This is similar to developing libraries in
C, and different from how backward compatibility works in pure Python.

The main difference to Python originates from the fact that the
declarations in the header ``.pxd`` files are used when code written
by users is *compiled*, but they must also match with what is
available in SciPy when the user code is *imported*.

User code may be compiled with one version of SciPy, and the compiled
binary (which uses the binary interface declared in the ``.pxd``
files) can be used with a different SciPy version installed on the
system. If the interfaces are not compatible, either an
exception is raised or runtime memory corruption and crash ensue.

At import time, Cython checks that signatures of functions in the
installed SciPy SO/DLL file match the one in the ``.pxd`` file used by
the user during compilation, and raises a Python exception if there is
a mismatch.  If the SciPy code is structured correctly (see below),
this check is performed only for functions that are actually imported
in the user code.

We rely on this feature to provide a runtime safety check, which makes
it easier for the users to detect incompatible SciPy versions via
Python exceptions, instead of hard-to-trace runtime crashes.


ABI stability aim
-----------------

SciPy aims to maintain ABI stability in Cython code, in the following
sense:

    Binaries produced by compiling user source with one version of
    SciPy, are compatible with any other SciPy version with which the
    source code can be compiled.

    Trying to use an incompatible version of SciPy at runtime will
    result in a Python exception at user module import time.

    Trying to use an incompatible version of SciPy at compile time
    will result in a Cython error.

This means that users can use any compatible version of SciPy to
compile binaries without having to pay attention to ABI, i.e.,

    ABI compatibility = API compatibility

Cython API backward/forward compatibility will be handled with a
similar deprecation/removal policy as for the Python API, see
:ref:`deprecations`.


Implementing ABI stability in SciPy
-----------------------------------

The following rules in development of Cython APIs in SciPy are
necessary to maintain the ABI stability aim above:

- Adding new ``cdef`` declarations (functions, structs, types, etc.)
  **is allowed**.

- Removing ``cdef`` declarations **is allowed**, but **should follow**
  general deprecation/removal policy.

- ``cdef`` declarations of functions **may be changed**.

  However, changes result in a backward incompatible API change which
  breaks any code using the changed signature, and **should follow**
  general deprecation/removal policy.

- ``cdef`` declarations of anything else (e.g. ``struct``, ``enum``,
  and types) are **final**.  Once a declaration is exposed in the
  public Cython API in a released SciPy version, **it must not be
  changed**.

  If changes are necessary, they need to be carried out by adding
  new declarations with different names, and removing old ones.

- ``cdef`` classes are **not allowed** in the public APIs (TBD:
  backward compatibility of cdef classes needs more research, but must
  not be allowed when we are not sure)

- For each public API module (as in ``scipy.linalg.cython_blas``), use
  a single interface ``.pxd`` declaration file.

  The public interface declaration file **should not** contain
  ``cimport`` statements.  If it does, Cython's signature check will
  check all of the cimported functions, not only the ones that are
  used by user code, so that changing one of them breaks the whole
  API.

- If data structures are necessary, **prefer opaque structs** in the
  public API.  The interface declarations should not contain any
  declarations of struct members.  Allocation, freeing, and attribute
  access of data structures should be done with functions.


.. _deprecating-public-cython-api:

Deprecating public Cython APIs
------------------------------

To deprecate a public Cython API function, for example::

    # scipy/something/foo.pxd
    cdef public int somefunc()

    # scipy/something/foo.pyx
    cdef public int somefunc():
        return 42

you can add use the ``scipy._lib.deprecation.deprecate_cython_api``
function to do the deprecations at the end of the corresponding
``.pyx`` file::

    # scipy/something/foo.pyx
    cdef public int somefunc():
        return 42

    from scipy._lib.deprecation import deprecate_cython_api
    import scipy.something.foo as mod
    deprecate_cython_api(mod, "somefunc", new_name="scipy.something.newfunc",
                         message="Deprecated in Scipy 1.5.0")
    del deprecate_cython_api, mod

After this, Cython modules that ``cimport somefunc``, will emit a
`DeprecationWarning` at import time.

There is no way to deprecate Cython data structures and types.  They
can be however removed after all functions using them in the API are
removed, having gone through the deprecation cycle.

Whole Cython modules can be deprecated similarly as Python modules, by
emitting a `DeprecationWarning` on the top-level.
:orphan:

.. _pep8-scipy:

==============
PEP8 and SciPy
==============

All SciPy Python code should adhere to `PEP8`_ style guidelines. It’s so
important that some continuous integration tests on GitHub will fail due
to certain PEP8 violations. Here are a few tips for ensuring PEP8
compliance before pushing your code:

-  Many integrated development environments (IDEs) have options that
   automatically check for PEP8 compliance. In Spyder, for example,
   `enable Real-time code style analysis`_ in Tools |rarr| Preferences |rarr|
   Editor |rarr| Code Introspection/Analysis and "Automatically remove
   trailing spaces when saving files" in in Tools |rarr| Preferences |rarr|
   Editor |rarr| Advanced Settings. This can help you fix PEP8 issues as you
   write your code.

-  SciPy makes use of special configuration files for linting with the
   |flake8|_ tool.

-  It is typically recommended to leave any existing style issues alone
   unless they are part of the code you're already modifying.
   This practice ensures that the codebase is gradually cleaned up
   without dedicating precious review time to style-only cleanups.
   Before sending a Pull Request, we suggest running the lint tests only
   for the changes you've made in your feature branch. This will mimic
   the continuous integration linting checks setup on GitHub.
   After installing ``flake8``, you can run the following check locally
   in the SciPy root directory to ensure your Pull Request doesn't
   break the Continuous Integration linting tests.

   ::

      python tools/lint_diff.py

   If you want to run the diff based lint tests only for specific files
   or directories, please consider using the ``--files`` option.

   ::

      python tools/lint_diff.py --files scipy/odr/models.py scipy/ndimage

-  If you have existing code with a lot of PEP8 issues, consider using
   |autopep8|_ to automatically fix them before incorporating the code into
   SciPy.

.. _PEP8: https://www.python.org/dev/peps/pep-0008/
.. _enable Real-time code style analysis: https://stackoverflow.com/questions/51463223/how-to-use-pep8-module-using-spyder

.. |flake8| replace:: ``flake8``
.. _flake8: http://flake8.pycqa.org/en/latest/

.. |autopep8| replace:: ``autopep8``
.. _autopep8: https://pypi.org/project/autopep8/0.8/

.. include:: <isonum.txt>
.. automodule:: scipy.linalg.cython_blas
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.misc
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.minimize-slsqp:

minimize(method='SLSQP')
---------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._slsqp_py._minimize_slsqp
   :method: SLSQP
.. automodule:: scipy.linalg.blas
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.linalg.lapack
   :no-members:
   :no-inherited-members:
   :no-special-members:
:orphan:

.. automodule:: scipy.spatial.transform
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.minimize-cg:

minimize(method='CG')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._optimize._minimize_cg
   :method: CG
.. automodule:: scipy.stats.qmc
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.root-dfsane:

root(method='df-sane')
--------------------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._spectral._root_df_sane
   :method: df-sane
.. automodule:: scipy.odr
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.root-diagbroyden:

root(method='diagbroyden')
--------------------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._root._root_diagbroyden_doc
   :method: diagbroyden
.. _optimize.linprog-revised_simplex:

linprog(method='revised simplex')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.linprog
   :impl: scipy.optimize._linprog._linprog_rs_doc
   :method: revised_simplex
.. _optimize.root-linearmixing:

root(method='linearmixing')
------------------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._root._root_linearmixing_doc
   :method: linearmixing
.. _optimize.root-lm:

root(method='lm')
--------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._root._root_leastsq
   :method: lm
.. automodule:: scipy.linalg.cython_lapack
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.root-krylov:

root(method='krylov')
--------------------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._root._root_krylov_doc
   :method: krylov
.. _optimize.linprog-simplex:

linprog(method='simplex')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.linprog
   :impl: scipy.optimize._linprog._linprog_simplex_doc
   :method: simplex
.. automodule:: scipy.linalg.interpolative
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.minimize-tnc:

minimize(method='TNC')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._tnc._minimize_tnc
   :method: TNC
.. _optimize.root_scalar-toms748:

root_scalar(method='toms748')
-----------------------------

.. scipy-optimize:function:: scipy.optimize.root_scalar
   :impl: scipy.optimize._root_scalar._root_scalar_toms748_doc
   :method: toms748

.. _optimize.minimize-trustncg:

minimize(method='trust-ncg')
-------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._trustregion_ncg._minimize_trust_ncg
   :method: trust-ncg
.. _optimize.minimize_scalar-bounded:

minimize_scalar(method='bounded')
------------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize_scalar
   :impl: scipy.optimize._optimize._minimize_scalar_bounded
   :method: bounded
.. automodule:: scipy.sparse
   :no-members:
   :no-inherited-members:
   :no-special-members:
:orphan:

.. automodule:: scipy.signal.windows
   :no-members:
   :no-inherited-members:
   :no-special-members:
============================
Low-level callback functions
============================

.. currentmodule:: scipy

Some functions in SciPy take as arguments callback functions, which
can either be python callables or low-level compiled functions.  Using
compiled callback functions can improve performance somewhat by
avoiding wrapping data in Python objects.

Such low-level functions in SciPy are wrapped in `LowLevelCallable`
objects, which can be constructed from function pointers obtained from
ctypes, cffi, Cython, or contained in Python `PyCapsule` objects.

.. autosummary::
   :toctree: generated/

   LowLevelCallable

.. seealso::

   Functions accepting low-level callables:

   `scipy.integrate.quad`, `scipy.ndimage.generic_filter`, `scipy.ndimage.generic_filter1d`,
   `scipy.ndimage.geometric_transform`

   Usage examples:

   :ref:`ndimage-ccallbacks`, :ref:`quad-callbacks`
:orphan:

.. automodule:: scipy.io.matlab
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.linprog-interior-point:

linprog(method='interior-point')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.linprog
   :impl: scipy.optimize._linprog._linprog_ip_doc
   :method: interior-point
.. automodule:: scipy.stats.contingency
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.minimize_scalar-golden:

minimize_scalar(method='golden')
-----------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize_scalar
   :impl: scipy.optimize._optimize._minimize_scalar_golden
   :method: golden
.. _optimize.minimize-trustexact:

minimize(method='trust-exact')
-------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._trustregion_exact._minimize_trustregion_exact
   :method: trust-exact
.. _optimize.root_scalar-brenth:

root_scalar(method='brenth')
----------------------------

.. scipy-optimize:function:: scipy.optimize.root_scalar
   :impl: scipy.optimize._root_scalar._root_scalar_brenth_doc
   :method: brenth

.. _optimize.minimize_scalar-brent:

minimize_scalar(method='brent')
----------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize_scalar
   :impl: scipy.optimize._optimize._minimize_scalar_brent
   :method: brent
.. _optimize.minimize-lbfgsb:

minimize(method='L-BFGS-B')
------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._lbfgsb_py._minimize_lbfgsb
   :method: L-BFGS-B
.. _optimize.root_scalar-newton:

root_scalar(method='newton')
----------------------------

.. scipy-optimize:function:: scipy.optimize.root_scalar
   :impl: scipy.optimize._root_scalar._root_scalar_newton_doc
   :method: newton

.. _sparse.linalg.svds-arpack:

svds(solver='arpack')
----------------------------------------

.. scipy-optimize:function:: scipy.sparse.linalg.svds
   :impl: scipy.sparse.linalg._eigen._svds_doc._svds_arpack_doc
   :method: arpack
.. automodule:: scipy.sparse.linalg
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.minimize-trustconstr:

minimize(method='trust-constr')
-------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._trustregion_constr._minimize_trustregion_constr
   :method: trust-constr
.. _optimize.root-excitingmixing:

root(method='excitingmixing')
--------------------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._root._root_excitingmixing_doc
   :method: excitingmixing
.. _optimize.minimize-trustkrylov:

minimize(method='trust-krylov')
-------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._trustregion_krylov._minimize_trust_krylov
   :method: trust-krylov
.. automodule:: scipy.linalg
   :no-members:
   :no-inherited-members:
   :no-special-members:

.. toctree::
   :hidden:

   linalg.blas
   linalg.lapack
   linalg.cython_blas
   linalg.cython_lapack
   linalg.interpolative
.. _optimize.root-hybr:

root(method='hybr')
----------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._minpack_py._root_hybr
   :method: hybr
.. automodule:: scipy.cluster.hierarchy
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.spatial.distance
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.minimize-neldermead:

minimize(method='Nelder-Mead')
---------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._optimize._minimize_neldermead
   :method: Nelder-Mead
.. _optimize.minimize-dogleg:

minimize(method='dogleg')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._trustregion_dogleg._minimize_dogleg
   :method: dogleg
.. automodule:: scipy.stats.sampling
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.root_scalar-bisect:

root_scalar(method='bisect')
----------------------------

.. scipy-optimize:function:: scipy.optimize.root_scalar
   :impl: scipy.optimize._root_scalar._root_scalar_bisect_doc
   :method: bisect

.. _optimize.root_scalar-secant:

root_scalar(method='secant')
----------------------------

.. scipy-optimize:function:: scipy.optimize.root_scalar
   :impl: scipy.optimize._root_scalar._root_scalar_secant_doc
   :method: secant

.. _optimize.minimize-newtoncg:

minimize(method='Newton-CG')
-------------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._optimize._minimize_newtoncg
   :method: Newton-CG
.. automodule:: scipy.sparse.csgraph
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.qap-faq:

quadratic_assignment(method='faq')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.quadratic_assignment
   :impl: scipy.optimize._qap._quadratic_assignment_faq
   :method: faq
.. automodule:: scipy.integrate
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.fft
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.stats._result_classes
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.stats.mstats
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.spatial
   :no-members:
   :no-inherited-members:
   :no-special-members:

.. toctree::
   :hidden:

   spatial.distance
.. _optimize.linprog-highs-ipm:

linprog(method='highs-ipm')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.linprog
   :impl: scipy.optimize._linprog._linprog_highs_ipm_doc
   :method: highs-ipm
.. include:: ../../API.rst.txt
.. automodule:: scipy.io
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.constants
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.linprog-highs:

linprog(method='highs')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.linprog
   :impl: scipy.optimize._linprog._linprog_highs_doc
   :method: highs
.. _sparse.linalg.svds-lobpcg:

svds(solver='lobpcg')
----------------------------------------

.. scipy-optimize:function:: scipy.sparse.linalg.svds
   :impl: scipy.sparse.linalg._eigen._svds_doc._svds_lobpcg_doc
   :method: lobpcg
.. automodule:: scipy.optimize
   :no-members:
   :no-inherited-members:
   :no-special-members:

.. toctree::
   :hidden:
   :maxdepth: 1

   optimize.cython_optimize
.. automodule:: scipy.stats
   :no-members:
   :no-inherited-members:
   :no-special-members:

.. toctree::
   :hidden:

   stats._result_classes
   stats.contingency
.. _optimize.root_scalar-ridder:

root_scalar(method='ridder')
----------------------------

.. scipy-optimize:function:: scipy.optimize.root_scalar
   :impl: scipy.optimize._root_scalar._root_scalar_ridder_doc
   :method: ridder

.. _optimize.root-anderson:

root(method='anderson')
--------------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._root._root_anderson_doc
   :method: anderson
.. automodule:: scipy.signal
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.root-broyden2:

root(method='broyden2')
--------------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._root._root_broyden2_doc
   :method: broyden2
.. automodule:: scipy.fftpack
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.special
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _sparse.linalg.svds-propack:

svds(solver='propack')
----------------------------------------

.. scipy-optimize:function:: scipy.sparse.linalg.svds
   :impl: scipy.sparse.linalg._eigen._svds_doc._svds_propack_doc
   :method: propack
:orphan:

.. automodule:: scipy.special.cython_special
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.minimize-bfgs:

minimize(method='BFGS')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._optimize._minimize_bfgs
   :method: BFGS
.. automodule:: scipy.cluster.vq
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.optimize.cython_optimize
.. _optimize.root_scalar-brentq:

root_scalar(method='brentq')
----------------------------

.. scipy-optimize:function:: scipy.optimize.root_scalar
   :impl: scipy.optimize._root_scalar._root_scalar_brentq_doc
   :method: brentq

.. _optimize.minimize-powell:

minimize(method='Powell')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._optimize._minimize_powell
   :method: Powell
.. _optimize.root-broyden1:

root(method='broyden1')
--------------------------------------

.. scipy-optimize:function:: scipy.optimize.root
   :impl: scipy.optimize._root._root_broyden1_doc
   :method: broyden1
.. _optimize.root_scalar-halley:

root_scalar(method='halley')
----------------------------

.. scipy-optimize:function:: scipy.optimize.root_scalar
   :impl: scipy.optimize._root_scalar._root_scalar_halley_doc
   :method: halley

.. _optimize.linprog-highs-ds:

linprog(method='highs-ds')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.linprog
   :impl: scipy.optimize._linprog._linprog_highs_ds_doc
   :method: highs-ds
.. automodule:: scipy.interpolate
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. _optimize.qap-2opt:

quadratic_assignment(method='2opt')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.quadratic_assignment
   :impl: scipy.optimize._qap._quadratic_assignment_2opt
   :method: 2opt
.. _optimize.minimize-cobyla:

minimize(method='COBYLA')
----------------------------------------

.. scipy-optimize:function:: scipy.optimize.minimize
   :impl: scipy.optimize._cobyla_py._minimize_cobyla
   :method: COBYLA
.. automodule:: scipy.ndimage
   :no-members:
   :no-inherited-members:
   :no-special-members:
.. automodule:: scipy.cluster
   :no-members:
   :no-inherited-members:
   :no-special-members:

.. toctree::
   :hidden:

   cluster.vq
   cluster.hierarchy
==============================
Building from source on macOS
==============================

.. note::

   This document has not been maintained and is retained for reference only.
   For building on macOS, please see :ref:`quickstart-mac`.

These instructions describe how to build NumPy and SciPy libraries from
source.

If you just want to use NumPy or SciPy, install pre-built binaries as described
in :ref:`installing-upgrading`.

Python
------

Apple ships its own version of Python with OS X. However, we
*strongly* recommend installing the `official Python distribution
<https://www.python.org/downloads/>`__.

Alternatively, use Python from one of the OS X package managers
(Homebrew, MacPorts, Fink).

Compilers (C/C++/FORTRAN/Cython/Pythran)
----------------------------------------

Though virtually any commercial C/C++ compiler may be used with SciPy, Clang C/C++ compiler,
which is a Xcode command line tool, can be used for OS X.
The only thing missing is the GNU FORTRAN compiler.

We recommend gfortran; this is a free, open source, F95 compiler. We suggest you
use the following binaries:

* gfortran installed via `Homebrew <https://brew.sh/>`__, or,
* http://r.research.att.com/tools/gcc-42-5666.3-darwin11.pkg (for Xcode
  4.2 or higher)

See `this site <http://r.research.att.com/tools/>`__ for the most recent links.

`Cython <https://cython.org/>`__ and `Pythran <https://pythran.readthedocs.io>`__,
two ahead-of-time compilers, are also needed.


BLAS/LAPACK Installation
------------------------

You will also need to install a library providing the BLAS and LAPACK
interfaces. ATLAS, OpenBLAS, and MKL all work. OpenBLAS can be installed
via `Homebrew <https://brew.sh/>`.

As of SciPy version 1.2.0, we do not support compiling against the system
Accelerate library for BLAS and LAPACK. It does not support a sufficiently
recent LAPACK interface.

Version-specific notes
----------------------

This section notes only things specific to one version of OS X or Python.
The build instructions in :ref:`Obtaining and Building NumPy and SciPy
<osx-obtaining-and-building>` apply to all versions.

.. _osx-obtaining-and-building:

Obtaining and Building NumPy and SciPy
--------------------------------------

You may install NumPy and SciPy either by checking out the source
files or downloading a source archive file from
`GitHub <https://github.com/scipy/scipy>`__. If you choose the latter,
simply expand the archive (generally a gzipped tar file), otherwise
check out the following branches from the repository:

::

       $ git clone https://github.com/numpy/numpy.git
       $ git clone https://github.com/scipy/scipy.git

Both NumPy and SciPy are built as follows:

::

       $ python setup.py build
       $ python setup.py install

The above applies to the `official Python distribution
<https://www.python.org/downloads/>`__, which is 32-bit
only for 2.6 while 32/64-bit bundles are available for 2.7 and
3.x. For alternative 64-bit Pythons (either from Apple or home-built)
on Snow Leopard, you may need to extend your build flags to specify
the architecture by setting LDFLAGS and FFLAGS.

Note that with distutils (setup.py) given build flags like LDFLAGS
**do not extend but override the defaults**, so you have to specify
all necessary flags. Only try this if you know what you're doing!

After a successful build, you may try running the built-in unit tests
for SciPy:

::

       $ python
       >>> import numpy as np
       >>> np.test('full')
       >>> import scipy
       >>> scipy.test()

Be sure not to import numpy or scipy while you're in the numpy/scipy
source tree. Change directory first.

If you have any problems installing SciPy on your Mac
based on these instructions, please check the `scipy-users and
scipy-dev mailing list archives
<https://www.scipy.org/mailing-lists>`__
for possible solutions. If you
are still stuck, feel free to join scipy-users for further
assistance. Please have the following information ready:

* Your OS version

* The versions of gcc and gfortran and where you obtained gfortran

  * ``$ gcc --version``

  * ``$ gfortran --version``

* The versions of numpy and scipy that you are trying to install

* The full output of ``$ python setup.py build``
#############################
Building from source on Linux
#############################

====================
Generic instructions
====================

To build NumPy/SciPy from source, get the `source package
<https://github.com/scipy/scipy>`__, unpack it, and:

::

   python setup.py install --user   # installs to your home directory

or

::

   python setup.py build
   python setup.py install --prefix=$HOME/local

Before building, you will also need to install packages that NumPy and
SciPy depend on

* BLAS and LAPACK libraries (optional but strongly recommended for
  NumPy, required for SciPy): typically `ATLAS
  <http://math-atlas.sourceforge.net/>`__ + `OpenBLAS
  <https://github.com/xianyi/OpenBLAS/>`__, or `MKL
  <https://software.intel.com/en-us/intel-mkl>`__.

* C, C++, and Fortran compilers (typically ``gcc``, ``g++``, and ``gfortran``).

* Python header files (typically a package named ``python3-dev`` or ``python3-devel``)

Typically, you will want to install all of the above from packages
supplied by your Linux distribution, as building them yourself is
complicated. If you need to use specific BLAS/LAPACK libraries, you
can do

::

   export BLAS=/path/to/libblas.so
   export LAPACK=/path/to/liblapack.so
   export ATLAS=/path/to/libatlas.so
   python setup.py ............

* The `Cython <https://cython.org/>`__ and `Pythran <https://pythran.readthedocs.io>`__
  ahead-of-time compilers are also necessary, as is ``pybind11``. It is
  recommended to install these packages with ``pip`` or ``conda``, because it
  is possible (even likely) that you need newer versions of these packages than
  the ones that are available in your Linux distribution.


Below, you will find additional installation instructions and advice
for many major Linux distributions.


=====================
Specific instructions
=====================

.. contents::
   :local:


Debian / Ubuntu
===============

To build from source, the following packages are needed::

   sudo apt-get install gcc g++ gfortran python3-dev libopenblas-dev liblapack-dev

To customize which BLAS is used, you can set up a `site.cfg` file. See
the `site.cfg.example` file in the numpy source for the options you
can set.

Note that Debian and Ubuntu package optimized BLAS libraries in an
exchangeable way. You can install libraries, such as ATLAS or OpenBLAS
and change the default one used via the alternatives mechanism:

::

    $ sudo apt-get install libopenblas-base libatlas3-base
    $ update-alternatives --list libblas.so.3
    /usr/lib/atlas-base/atlas/libblas.so.3
    /usr/lib/libblas/libblas.so.3
    /usr/lib/openblas-base/libopenblas.so.0

    $ sudo update-alternatives --set libblas.so.3 /usr/lib/openblas-base/libopenblas.so.0

See /usr/share/doc/libatlas3-base/README.Debian for instructions on
how to build optimized ATLAS packages for your specific CPU. The
packaged OpenBLAS chooses the optimal code at runtime so it does not
need recompiling unless the packaged version does not yet support the
used CPU.

You can also use a library you built yourself by preloading it. This does not
require administrator rights.

::

    LD_PRELOAD=/path/to/libatlas.so.3 ./my-application


Fedora 26
=========

To install scipy build requirements, you can do::

    sudo dnf install gcc-gfortran python3-devel openblas-devel lapack-devel


Intel C compiler and MKL
========================

Intel MKL 11.0 (updated Dec 2012)
---------------------------------

Add the following lines to site.cfg in your top level NumPy directory
to use Intel® MKL for Intel® 64 (or earlier known as em64t)
architecture, considering the default installation path of Intel® MKL,
which is bundled with Intel® Composer XE SP1 version on Linux:

::

   [mkl]
   library_dirs = /opt/intel/composer_xe_2013/mkl/lib/intel64
   include_dirs = /opt/intel/composer_xe_2013/mkl/include
   mkl_libs = mkl_intel_lp64,mkl_intel_thread,mkl_core

If you are building NumPy for 32 bit, please add as the following

::

   [mkl]
   library_dirs = /opt/intel/composer_xe_2013/mkl/lib/ia32
   include_dirs = /opt/intel/composer_xe_2013/mkl/include
   mkl_libs = mkl_intel,mkl_intel_thread,mkl_core

Instead of the layered linking approach for the Intel® MKL as shown
above, you may also use the dynamic interface lib mkl_rt.lib. So, for
both the ia32 and intel64 architecture, make the change as below

::

   mkl_libs = mkl_rt

Modify cc_exe in numpy/numpy/distutils/intelccompiler.py to be
something like:

::

   cc_exe = 'icc -O2 -g -openmp -avx'

Here, we use default optimizations (-O2), OpenMP threading (-openmp),
and Intel® AVX optimizations for Intel® Xeon E5 or E3 Series, which are
based on Intel® SandyBridge Architecture (-avx). Run icc --help for
more information on processor-specific options.

Compile and install NumPy with the Intel compiler (on 64-bit platforms replace "intel" with "intelem"):

::

   python setup.py config --compiler=intel build_clib --compiler=intel build_ext --compiler=intel install

Compile and install SciPy with the Intel compilers (on 64-bit
platforms replace "intel" with "intelem"):

::

   python setup.py config --compiler=intel --fcompiler=intel build_clib --compiler=intel --fcompiler=intel build_ext --compiler=intel --fcompiler=intel install

You'll have to set LD_LIBRARY_PATH to Intel® MKL libraries (exact
values will depend on your architecture, compiler, and library
versions) and OpenMP library for NumPy to work. If you build NumPy
for Intel® 64 platforms:

::

   $export LD_LIBRARY_PATH=/opt/intel/composer_xe_2013/mkl/lib/intel64: /opt/intel/composer_xe_2013/compiler/lib/intel64:$LD_LIBRARY_PATH

If you build NumPy for ia32 bit platforms:

::

   $export LD_LIBRARY_PATH=/opt/intel/composer_xe_2013/mkl/lib/ia32: /opt/intel/composer_xe_2013/compiler/lib/ia32:$LD_LIBRARY_PATH


====================
Fortran ABI mismatch
====================

Some linear algebra libraries are built with G77 ABI and others with
GFortran ABI, and these two ABIs are incompatible. Therefore, if you
build scipy with `gfortran` and link to a linear algebra library, like
MKL, which is built with G77 ABI, then there'll be an exception or a
segfault. SciPy fixes this by using the CBLAS API for the few
functions in the BLAS API that suffers from this issue.

Note that SciPy needs to know at build time, what needs to be done and
the build system will automatically check whether linear algebra
library is MKL and if so, use the CBLAS API instead of the BLAS API.
If autodetection fails or if the user wants to override this
autodetection mechanism, setting the environment variable
`SCIPY_USE_G77_ABI_WRAPPER` to 0 or 1 to disable or enable using CBLAS
API.
.. _build-install-faq:

=================
Build/Install FAQ
=================

*How do I set up a development version of SciPy in parallel to a released
version that I use to do my job/research?*

If you use the ``conda`` package manager, this is covered in the
:ref:`quickstart-mac`.

Another simple way to achieve this is to install the released version in
site-packages, by using a binary installer or pip, for example, and set
up the development version in a virtualenv. First, install
`virtualenv`_ (optionally, use `virtualenvwrapper`_), then create your
virtualenv (named scipy-dev here) with::

    $ virtualenv scipy-dev

Now, whenever you want to switch to the virtual environment, you can use the
command ``source scipy-dev/bin/activate``, and ``deactivate`` to exit from the
virtual environment and back to your previous shell. With scipy-dev
activated, first install Scipy's dependencies::

    $ pip install numpy pytest cython pybind11

After that, you can install a development version of Scipy, for example, via::

    $ python setup.py install

The installation goes to the virtual environment.


*How do I set up an in-place build for development?*

For development, you can set up an in-place build so that changes made to
``.py`` files have effect without rebuild. First, run::

    $ python setup.py build_ext -i

Then you need to point your PYTHONPATH environment variable to this directory.
Some IDEs (`Spyder`_, for example) have utilities to manage PYTHONPATH. On Linux
and OSX, you can run the command::

    $ export PYTHONPATH=$PWD

and on Windows::

    $ set PYTHONPATH=/path/to/scipy

Now, editing a Python source file in SciPy allows you to immediately
test and use your changes (in ``.py`` files), by simply restarting the
interpreter.

If you use the macOS, please find more information in the
:ref:`quickstart-mac`.

.. _virtualenv: https://virtualenv.pypa.io/

.. _virtualenvwrapper: https://bitbucket.org/dhellmann/virtualenvwrapper/

.. _Spyder: https://www.spyder-ide.org/
:orphan:

.. _building:

Building from sources
=====================

.. note::

   If you are only trying to install SciPy, see
   :doc:`../install_upgrade`.

Build instructions for different operating systems and an FAQ:

.. toctree::
   :maxdepth: 2

   linux
   windows
   macosx
   faq


Reference for build options
===========================

Scipy has several tunable build-time options, which can be set.

- ``site.cfg``: build-time library configuration file, see
  ``site.cfg.example`` for details.

- Environment variables ``NPY_LAPACK_ORDER``, ``NPY_BLAS_ORDER``, ``OPENBLAS``,
  ``ATLAS``, etc., also controlling library configuration.
  See `Numpy documentation <numpy-blasdoc>`_ for more details.

- Environment variable ``NPY_USE_BLAS_ILP64=1``: build using 64-bit
  integer size (ILP64) BLAS+LAPACK libraries.

  Note that even when this is set, Scipy requires *also* 32-bit
  integer size (LP64) BLAS+LAPACK libraries to be available and
  configured. This is because only some components in Scipy make use
  of the 64-bit capabilities.

.. _numpy-blasdoc: https://numpy.org/devdocs/user/building.html#accelerated-blas-lapack-libraries
.. _build-windows:

===============================
Building from source on Windows
===============================

.. contents::
   :local:

Overview
--------

Compared to OSX and Linux, building NumPy and SciPy on Windows is more
difficult, largely due to the lack of compatible, open-source libraries like
BLAS/LAPACK_ and open-source compilers that are necessary to build both
libraries and have them perform relatively well. It is not possible to just
call a one-liner on the command prompt as you would on other platforms via
``sudo apt install`` machinery.

This document describes one option to build OpenBLAS and SciPy from source
that was validated for SciPy 1.6.0. However, in light of all the work
currently being done, please **do not expect** these instructions to be
accurate in the long-run and be sure to check up on any of the open source
projects mentioned for the most up-to-date information. For more information
on all of these projects, the Mingwpy_ website is an excellent source of
in-depth information than this document will provide.

.. _Mingwpy: https://mingwpy.github.io/
.. _OpenBLAS: https://github.com/xianyi/OpenBLAS
.. _LAPACK: http://www.netlib.org/lapack/


Building the Released SciPy
---------------------------

This section provides the step-by-step process to build the released SciPy.
If you want to build completely from source, you should estimate at least
three hours to build all libraries and compile SciPy. Feel free to stop and
inspect any step at any time, but for this section, we'll just mention the
steps without providing an in-depth explanation for the reasons behind them.
If you have further questions about what we're doing, more in-depth
documentation is provided in the sections below. Also, please make sure to
read this section before proceeding, as the presence or absence of error
messages in general is not a good indication of whether you've completed a
step correctly. Each step creates particular files, and what ultimately
matters is whether you have built the required files rather than whether
error messages appeared in your terminal.

Building OpenBLAS
=================

First, we need to install the software required to build OpenBLAS_, which is
the BLAS_ library that we're going to use. Because the software to build
OpenBLAS is different than that required to build SciPy and because OpenBLAS
takes a long time to build, we're going to start building OpenBLAS first and
then explain what to do next while the OpenBLAS build is running.
**Alternatively, if you'd rather download a pre-built OpenBLAS, download the
one of the** `pre-built zip files`_ **and skip to the Installing OpenBLAS
section below.**. However it is also likely that your version of Windows and
the compiler you wish to use won't be compatible with what these prebuilt
binaries produced. This is still one of the main pain points of building
for Windows. That's why we will attempt to build our own OpenBLAS.

We start by installing the MSYS2 platform, on which the OpenBLAS build will take
place. First, download the MSYS2 installer from `msysintaller`_ via choosing
32 or 64 bit. Make sure to install the correct architecture for the SciPy
that you want to build (e.g., 32 or 64 bit). If you are not sure which one to use,
proceed with 64bit. Please follow the installation instructions carefully,
especially step 6 and 7 to update all components.

.. note::

    Occasionally,
    during the updates, the terminal might ask you to close the terminal but then
    might refuse to be closed and hang. If this happens, you can kill it via Task
    Manager and continue with the instructions.

Now, the next step is to install some more package bundles that we will need. Open
a MSYS2 **MinGW** (64 or 32 bit) terminal and type the following depending on the
architecture of your choice; run the following for the common 64-bit build

.. code:: shell

    pacman -S --needed base-devel mingw-w64-x86_64-toolchain mingw-w64-x86_64-cmake git

and for 32-bit run instead

.. code:: shell

    pacman -S --needed base-devel mingw-w64-i686-toolchain mingw-w64-i686-cmake git

Again, if you are not sure which one you want, choose 64-bit option in every
step.

It will prompt to whether install everything in these packages and you can
simply accept all via hitting enter key at each step which also takes some time
to complete. Once you install everything, close and
reopen the MSYS2 MinGW terminal.

If you already have a GitHub repository folder where you keep your own repos,
it is better to use that location to keep things nice and tidy since we are
going to clone yet another repository to obtain the source code. It should be
somewhere convenient and with write permissions. If this is your first time then
you can pick "Documents\GitHub" as a viable option. We will assume that you
picked this folder in the rest of this document. You can create a folder in "My
Documents" using Windows Explorer. To make sure that we're ready to build, type
the following in the terminal one-by-one:

.. code:: shell

   make
   gfortran
   gcc
   git

Each of these commands should fail as we have not provided any arguments
to them. However, an explicit failure from the program rather than from
the command prompt implies that the program is accessible on the path,
which is what we wanted to test. In turn, if an error about the command being
not found is returned, then installation of the packages didn't complete
successfully. If any of these are missing, you're not ready to build. Go back
and make sure that MSYS2 is installed correctly and has the required packages
enabled.

Now it's time to clone the OpenBLAS repository somewhere convenient. Run the
following line-by-line separately, modifying the path to your GitHub repo
folder as appropriate.

.. code:: shell

   cd C:\Users\<user name>\Documents\GitHub
   git clone https://github.com/xianyi/OpenBLAS.git
   cd OpenBLAS
   git submodule update --init --recursive
   git fetch --all --tags --prune

Now we are going to switch to a release of our choice. At the time of writing,
the newest OpenBLAS release version is 0.3.7, hence we will use that.

.. code:: shell

   git checkout tags/v0.3.7 -b v0.3.7

You can see all available options via

.. code:: shell

   git tag

Now change the directory one level up via :code:`cd ..` to get out of the
directory and create a file named `build_openblas.sh`. The easiest way is to
type

.. code:: shell

    touch build_openblas.sh

Of course, you can still also use Windows Explorer to create a new txt file at
that location and then rename it. So the resulting structure would be

.. code:: shell

    my repo folder
        ├─── build_openblas.sh
        ├─── OpenBLAS
                ├─── ...

Then open this file in any text editor, like Notepad++, and paste the following
content in this empty file:

.. code:: shell

    # You may adjust to your preferred output directory
    OPENBLAS_ROOT=/c/opt

    # Adjust to match the MSYS2 version you installed
    BUILD_BITS=64

    # Print some gcc info that MSYS2 discovered in the path
    which gcc
    gcc --version

    # Get into the repository that we cloned
    cd OpenBLAS

    # The following two lines clean up in case we make a mistake and need
    # to run the script again
    git clean -fxd
    git reset --hard
    rm -rf $OPENBLAS_ROOT/$BUILD_BITS

    # Set architecture flags
    march="x86-64"
    extra="-fno-asynchronous-unwind-tables"
    vc_arch="X64"
    cflags="-O2 -march=$march -mtune=generic $extra"
    fflags="$cflags -frecursive -ffpe-summary=invalid,zero"

    # Build name for output library from gcc version and OpenBLAS commit.
    GCC_TAG="gcc_$(gcc -dumpversion | tr .- _)"
    OPENBLAS_VERSION=$(git describe --tags)
    # Build OpenBLAS
    # Variable used in creating output libraries
    export LIBNAMESUFFIX=${OPENBLAS_VERSION}-${GCC_TAG}
    make BINARY=$BUILD_BITS DYNAMIC_ARCH=1 USE_THREAD=1 USE_OPENMP=0 \
        NO_WARMUP=1 BUILD_LAPACK_DEPRECATED=1 \
        COMMON_OPT="$cflags" FCOMMON_OPT="$fflags"
    make install PREFIX=$OPENBLAS_ROOT/$BUILD_BITS

This is the automation script that will make sure the right variables are used
in the right place. Linux users are very familiar to such scripts, but for
Windows users it might be a bit awkward. You can think of these as ``.bat``
files. The script should work as-in for MSYS2 64-bit, but you can change the
variables to your situation as needed. After you've created
this file and you are one directory up the OpenBLAS repo of that, start the
OpenBLAS build with:

.. code:: shell

    ./build_openblas.sh

Building OpenBLAS is challenging and time-consuming. The build may fail with an
error after a few hours but may also fail silently and produce an incorrect
binary. Please, if you have any issues, `report them`_ so that we can save the
next person's time.

One of the known issues is the following; if you, by any chance, receive the
following error

.. code:: shell

    <command-line>:0:4: error: expected identifier or '(' before numeric constant

that means you have some header file definition clash and you have to downgrade
certain items. This is not related to SciPy but let's attempt to provide a
solution. See this
`OpenBLASwiki <https://github.com/xianyi/OpenBLAS/wiki/How-to-use-OpenBLAS-in-Microsoft-Visual-Studio#build-openblas-on-windows-os>`__
page to read on which packages to downgrade and how to do it.
Basically, it involves downloading three files. Then in the MSYS terminal
change the directory to the place where you downloaded the files and run the
commands given in the wiki link. Then come back to the script directory where
`./build_openblas.sh` lives and try again. This should be sufficient for you to
build OpenBLAS.

While you're waiting on OpenBLAS to finish building, go ahead and install
`build tools`_ from Microsoft, since these take a while to install and you'll
need them later.

After the :code:`build_openblas.sh` script has completed, there should be an
:code:`libopenblas.....a` as a resulting artifact. If :code:`OPENBLAS_ROOT` was
set to :code:`C:\\opt`, then you might see a line like this in the MSYS2
terminal:

.. code:: shell

   Copying the static library to /c/opt/64/lib

This is very good news: you have successfully built OpenBLAS!


Installing OpenBLAS
===================

Look for the ``lib`` folder in the folder you used as a parameter to
:code:`OPENBLAS_ROOT`. (It's ``/c/opt/64/lib`` if you didn't change anything in
the script.) You will find three ``.a`` files such as (the names can differ):

.. code:: shell

    libopenblas_v0.2.20-2-g5f998efd-gcc_9_2_0.a
    libopenblas_v0.2.20-2-g5f998efd-gcc_9_2_0.dll.a
    libopenblas_v0.2.20-2-g5f998efd-gcc_9_2_0.p-r0.2.20.a

From these three we are interested only in the first one. Just make a copy and
rename it to :code:`openblas.a`.

If you don't have that file, you'll probably need to find
out what happened and then build OpenBLAS again. We know this is **very**
annoying, but unfortunately we have no other alternatives. The first place
to look for is inside the OpenBLAS directory. If the build succeeds but (for
some reason) auto-moving files to :code:`OPENBLAS_ROOT` fails, the artifacts
will stay inside the OpenBLAS repo
folder. But if you have that file, that's great and we'll assume that you've
completed this step correctly. Proceeding on that assumption, let's build
SciPy.

Before continuing, make sure that you don't have other copies of either
:code:`openblas.a` or :code:`libopenblas.a` from previous attempts or via
previous downloads. Multiple copies could result in later build errors that
will be difficult to debug. If this is the first attempt, you don't need to
worry about this step.

Building SciPy
==============

Once you have built OpenBLAS, it's time to build SciPy. Before continuing, make
sure to install the following software for building on the latest Python
version. For building on other Python versions, see the WindowsCompilers_ page.
We are also assuming that your Python is on the system path. That is to say,
when you type `python` in the Windows command prompt the correct Python is
executed.

Install Microsoft Visual Studio 2017 or 2019 Community Edition (use the
`build tools`_ from Microsoft). If you feel that it is too bloated to install
everything in that bundle (which we do feel a bit so) then here are a subset
which are tested during the build of SciPy 1.6.0 and VS 2019. You can switch
to the individual items view at the top and select only the following

.. code:: shell

    C++ Core Features
    Windows Universal C Runtime
    MSVC v142 - VS 2019 C++ x64/x86 build tools (...)
    Windows 10 SDK (10.0.18362.0)
    C++ 2019 Redistributable Update
    C++ Clang-cl for 142 build tools (x64/x86)
    C++ Clang Compiler for Windows (8.0.1)

Just like before, pick a convenient place to
clone SciPy. Next to OpenBLAS is often a convenient option (note: not inside
OpenBLAS folder but next to). Continuing the example from above

.. code:: shell

    my repo folder
        ├─── build_openblas.sh
        ├─── OpenBLAS
        ├─── SciPy
                ├─── ...

Again using the same generic example folder from above

.. code:: shell

   cd C:\Users\<user name>\Documents\GitHub
   git clone https://github.com/scipy/scipy.git
   cd scipy
   git submodule update --init

Now we need to copy the :code:`openblas.a` file that we've built earlier to the
correct location. If your Python is installed somewhere like the following:

.. code:: shell

   C:\Users\<user name>\AppData\Local\Programs\Python\Python38\python.exe

then you'll need to put the :code:`openblas.a` file that we previously copied
and renamed somewhere like the following:

.. code:: shell

   C:\Users\<user name>\AppData\Local\Programs\Python\Python38\Lib

Adjust the location accordingly based on where :code:`python.exe` is located.

At this stage, we are done with the OpenBLAS part and hopefully we will not need
to build OpenBLAS anytime soon. But we tend to build SciPy more often as it is
on a quicker release cycle. Hence it makes sense to use Windows ``cmd`` or
Powershell for the the build as it is a more native tool. This requires placing
the MinGW compilers on the path.  Hence, make sure that the following
folder (or the folder you have installed MSYS to) is on the system path
variable sufficiently close to the top.

.. code:: shell

    C:\MSYS64\MINGW64\BIN

For a sanity check, restart ``cmd`` or Powershell and type:

.. code:: shell

    gfortran

If you see a missing command error with the above, :code:`gfortran` is not
correctly installed or is still not on the path. However, we assume that it is now
on the path and accessible.

Now install the dependencies that we need to build and test SciPy.

.. code:: shell

    python -m pip install wheel setuptools numpy>=1.16.5 Cython>=0.29.18 pybind11>=2.4.3 pythran>=0.9.12 pytest pytest-xdist

.. note::

    These instructions use ``pip`` as the package manager. You can also use ``conda``
    according to the instructions in the :ref:`quickstart-ubuntu` with minimal modifications
    (e.g. you don't need to install ``gfortran`` and ``git`` because you already have them).

The last two are for using SciPy's test suite, which is handy if you want to test
some new change locally.

Please note that this is a simpler procedure than what is used for the official
binaries. **Your binaries will only work with the latest NumPy**.
For building against older NumPy versions, see
`Building Against an Older NumPy Version`_.

Assuming that you are in the top of the SciPy repository directory where
``setup.py`` is and assuming that you have set up everything correctly, you
are ready to build. Run the following commands:

.. code:: shell

    python setup.py build

You may verify that the OpenBLAS library was correctly picked up by looking for
the following in your build log:

.. code:: shell

   FOUND:
      libraries = ['openblas']
      library_dirs = ['C:\...........\lib']
      language = f77
      define_macros = [('HAVE_CBLAS', None)]

Notice that there will be multiple lines similar to these. You only need to
track the OpenBLAS one.

When everything finishes without an error, congratulations! You've built
SciPy!

You can further install the built SciPy via

.. code:: shell

    python setup.py install

Just make sure that you uninstalled the existing installation of other SciPy if
there were any (by the regular ``pip uninstall scipy`` machinery).


.. _BLAS: https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms
.. _OpenBLAS: https://github.com/xianyi/OpenBLAS
.. _`msysintaller`: https://www.msys2.org/
.. _`build tools`: https://www.visualstudio.com/downloads/#build-tools-for-visual-studio-2017
.. _`report them`: https://github.com/scipy/scipy/issues/new
.. _`pre-built zip files`: https://3f23b170c54c2533c070-1c8a9b3114517dc5fe17b7c3f8c63a43.ssl.cf2.rackcdn.com/
.. _WindowsCompilers: https://wiki.python.org/moin/WindowsCompilers

Building Against an Older NumPy Version
---------------------------------------

If you want to build SciPy to work with an older NumPy version, then you will need
to replace the NumPy "distutils" folder with the folder from the latest numpy.
The following Powershell snippet can upgrade NumPy distutils while retaining an older
NumPy ABI_.

.. code:: shell

      $NumpyDir = $((python -c 'import os; import numpy; print(os.path.dirname(numpy.__file__))') | Out-String).Trim()
      rm -r -Force "$NumpyDir\distutils"
      $tmpdir = New-TemporaryFile | %{ rm $_; mkdir $_ }
      git clone -q --depth=1 -b master https://github.com/numpy/numpy.git $tmpdir
      mv $tmpdir\numpy\distutils $NumpyDir

.. _ABI: https://en.wikipedia.org/wiki/Application_binary_interface

Additional Resources
--------------------

As discussed in the overview, this document is not meant to provide extremely detailed explanations on how to build
NumPy and SciPy on Windows. This is largely because currently, there is no single superior way to do so
and because the process for building these libraries on Windows is under development. It is likely that any
information will go out of date relatively soon. If you wish to receive more assistance, please reach out to the NumPy
and SciPy mailing lists, which can be found `here <https://www.scipy.org/mailing-lists>`__.  There are many
developers out there working on this issue right now, and they would certainly be happy to help you out!  Google is also
a good resource, as there are many people out there who use NumPy and SciPy on Windows, so it would not be surprising if
your question or problem has already been addressed.
==========================
SciPy 0.14.1 Release Notes
==========================

SciPy 0.14.1 is a bug-fix release with no new features compared to 0.14.0.


Issues closed
-------------

- `#3630 <https://github.com/scipy/scipy/issues/3630>`__: NetCDF reading results in a segfault
- `#3631 <https://github.com/scipy/scipy/issues/3631>`__: SuperLU object not working as expected for complex matrices
- `#3733 <https://github.com/scipy/scipy/issues/3733>`__: segfault from map_coordinates
- `#3780 <https://github.com/scipy/scipy/issues/3780>`__: Segfault when using CSR/CSC matrix and uint32/uint64
- `#3781 <https://github.com/scipy/scipy/pull/3781>`__: BUG: sparse: fix omitted types in sparsetools typemaps
- `#3802 <https://github.com/scipy/scipy/issues/3802>`__: 0.14.0 API breakage: _gen generators are missing from scipy.stats.distributions API
- `#3805 <https://github.com/scipy/scipy/issues/3805>`__: ndimage test failures with numpy 1.10
- `#3812 <https://github.com/scipy/scipy/issues/3812>`__: == sometimes wrong on csr_matrix
- `#3853 <https://github.com/scipy/scipy/issues/3853>`__: Many scipy.sparse test errors/failures with numpy 1.9.0b2
- `#4084 <https://github.com/scipy/scipy/pull/4084>`__: fix exception declarations for Cython 0.21.1 compatibility
- `#4093 <https://github.com/scipy/scipy/pull/4093>`__: BUG: fitpack: avoid a memory error in splev(x, tck, der=k)
- `#4104 <https://github.com/scipy/scipy/pull/4104>`__: BUG: Workaround SGEMV segfault in Accelerate (maintenance 0.14.x)
- `#4143 <https://github.com/scipy/scipy/pull/4143>`__: BUG: fix ndimage functions for large data
- `#4149 <https://github.com/scipy/scipy/issues/4149>`__: Bug in expm for integer arrays
- `#4154 <https://github.com/scipy/scipy/issues/4154>`__: Backport gh-4041 for 0.14.1 (Ensure that the 'size' argument of PIL's 'resize' method is a tuple)
- `#4163 <https://github.com/scipy/scipy/issues/4163>`__: Backport #4142 (ZeroDivisionError in scipy.sparse.linalg.lsqr)
- `#4164 <https://github.com/scipy/scipy/issues/4164>`__: Backport gh-4153 (remove use of deprecated numpy API in lib/lapack/ f2py wrapper)
- `#4180 <https://github.com/scipy/scipy/pull/4180>`__: backport pil resize support tuple fix
- `#4168 <https://github.com/scipy/scipy/issues/4168>`__: Lots of arpack test failures on windows 32 bits with numpy 1.9.1
- `#4203 <https://github.com/scipy/scipy/issues/4203>`__: Matrix multiplication in 0.14.x is more than 10x slower compared...
- `#4218 <https://github.com/scipy/scipy/pull/4218>`__: attempt to make ndimage interpolation compatible with numpy relaxed...
- `#4225 <https://github.com/scipy/scipy/pull/4225>`__: BUG: off-by-one error in PPoly shape checks
- `#4248 <https://github.com/scipy/scipy/pull/4248>`__: BUG: optimize: fix issue with incorrect use of closure for slsqp.
==========================
SciPy 1.2.2 Release Notes
==========================

.. contents::

SciPy 1.2.2 is a bug-fix release with no new features compared to 1.2.1.
Importantly, the SciPy 1.2.2 wheels are built with OpenBLAS 0.3.7.dev to
alleviate issues with SkylakeX AVX512 kernels.

Authors
=======

* CJ Carey
* Tyler Dawson +
* Ralf Gommers
* Kai Striega
* Andrew Nelson
* Tyler Reddy
* Kevin Sheppard +

A total of 7 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.2.2
-----------------------
* `#9611 <https://github.com/scipy/scipy/issues/9611>`__: Overflow error with new way of p-value calculation in kendall tau correlation for perfectly monotonic vectors
* `#9964 <https://github.com/scipy/scipy/issues/9964>`__: optimize.newton : overwrites x0 argument when it is a numpy array
* `#9784 <https://github.com/scipy/scipy/issues/9784>`__: TST: Minimum NumPy version is not being CI tested
* `#10132 <https://github.com/scipy/scipy/issues/10132>`__: Docs: Description of nnz attribute of sparse.csc_matrix misleading

Pull requests for 1.2.2
-----------------------
* `#10056 <https://github.com/scipy/scipy/pull/10056>`__: BUG: Ensure factorial is not too large in kendaltau
* `#9991 <https://github.com/scipy/scipy/pull/9991>`__: BUG: Avoid inplace modification of input array in newton
* `#9788 <https://github.com/scipy/scipy/pull/9788>`__: TST, BUG: f2py-related issues with NumPy < 1.14.0
* `#9749 <https://github.com/scipy/scipy/pull/9749>`__: BUG: MapWrapper.__exit__ should terminate
* `#10141 <https://github.com/scipy/scipy/pull/10141>`__: Update description for nnz on csc.py 
==========================
SciPy 1.0.1 Release Notes
==========================

.. contents::

SciPy 1.0.1 is a bug-fix release with no new features compared to 1.0.0.
Probably the most important change is a fix for an incompatibility between
SciPy 1.0.0 and ``numpy.f2py`` in the NumPy master branch.

Authors
=======

* Saurabh Agarwal +
* Alessandro Pietro Bardelli
* Philip DeBoer
* Ralf Gommers
* Matt Haberland
* Eric Larson
* Denis Laxalde
* Mihai Capotă +
* Andrew Nelson
* Oleksandr Pavlyk
* Ilhan Polat
* Anant Prakash +
* Pauli Virtanen
* Warren Weckesser
* @xoviat
* Ted Ying +

A total of 16 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 1.0.1
-----------------------

- `#7493 <https://github.com/scipy/scipy/issues/7493>`__: `ndimage.morphology` functions are broken with numpy 1.13.0
- `#8118 <https://github.com/scipy/scipy/issues/8118>`__: minimize_cobyla broken if `disp=True` passed
- `#8142 <https://github.com/scipy/scipy/issues/8142>`__: scipy-v1.0.0 pdist with metric=\`minkowski\` raises \`ValueError:...
- `#8173 <https://github.com/scipy/scipy/issues/8173>`__: `scipy.stats.ortho_group` produces all negative determinants...
- `#8207 <https://github.com/scipy/scipy/issues/8207>`__: gaussian_filter seg faults on float16 numpy arrays
- `#8234 <https://github.com/scipy/scipy/issues/8234>`__: `scipy.optimize.linprog` `interior-point` presolve bug with trivial...
- `#8243 <https://github.com/scipy/scipy/issues/8243>`__: Make csgraph importable again via `from scipy.sparse import*`
- `#8320 <https://github.com/scipy/scipy/issues/8320>`__: scipy.root segfaults with optimizer 'lm'


Pull requests for 1.0.1
-----------------------

- `#8068 <https://github.com/scipy/scipy/pull/8068>`__: BUG: fix numpy deprecation test failures
- `#8082 <https://github.com/scipy/scipy/pull/8082>`__: BUG: fix solve_lyapunov import
- `#8144 <https://github.com/scipy/scipy/pull/8144>`__: MRG: Fix for cobyla
- `#8150 <https://github.com/scipy/scipy/pull/8150>`__: MAINT: resolve UPDATEIFCOPY deprecation errors
- `#8156 <https://github.com/scipy/scipy/pull/8156>`__: BUG: missing check on minkowski w kwarg
- `#8187 <https://github.com/scipy/scipy/pull/8187>`__: BUG: Sign of elements in random orthogonal 2D matrices in "ortho_group_gen"...
- `#8197 <https://github.com/scipy/scipy/pull/8197>`__: CI: uninstall oclint
- `#8215 <https://github.com/scipy/scipy/pull/8215>`__: Fixes Numpy datatype compatibility issues
- `#8237 <https://github.com/scipy/scipy/pull/8237>`__: BUG: optimize: fix bug when variables fixed by bounds are inconsistent...
- `#8248 <https://github.com/scipy/scipy/pull/8248>`__: BUG: declare "gfk" variable before call of terminate() in newton-cg
- `#8280 <https://github.com/scipy/scipy/pull/8280>`__: REV: reintroduce csgraph import in scipy.sparse
- `#8322 <https://github.com/scipy/scipy/pull/8322>`__: MAINT: prevent scipy.optimize.root segfault closes #8320
- `#8334 <https://github.com/scipy/scipy/pull/8334>`__: TST: stats: don't use exact equality check for hdmedian test
- `#8477 <https://github.com/scipy/scipy/pull/8477>`__: BUG: signal/signaltools: fix wrong refcounting in PyArray_OrderFilterND
- `#8530 <https://github.com/scipy/scipy/pull/8530>`__: BUG: linalg: Fixed typo in flapack.pyf.src.
- `#8566 <https://github.com/scipy/scipy/pull/8566>`__: CI: Temporarily pin Cython version to 0.27.3
- `#8573 <https://github.com/scipy/scipy/pull/8573>`__: Backports for 1.0.1
- `#8581 <https://github.com/scipy/scipy/pull/8581>`__: Fix Cython 0.28 build break of qhull.pyx
==========================
SciPy 0.10.0 Release Notes
==========================

.. contents::

SciPy 0.10.0 is the culmination of 8 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a limited number of deprecations
and backwards-incompatible changes in this release, which are documented
below.  All users are encouraged to upgrade to this release, as there
are a large number of bug-fixes and optimizations.  Moreover, our 
development attention will now shift to bug-fix releases on the 0.10.x 
branch, and on adding new features on the development master branch.

Release highlights:

  - Support for Bento as optional build system.
  - Support for generalized eigenvalue problems, and all shift-invert modes
    available in ARPACK.

This release requires Python 2.4-2.7 or 3.1- and NumPy 1.5 or greater.


New features
============

Bento: new optional build system
--------------------------------

Scipy can now be built with `Bento <http://cournape.github.com/Bento/>`_.
Bento has some nice features like parallel builds and partial rebuilds, that
are not possible with the default build system (distutils).  For usage
instructions see BENTO_BUILD.txt in the scipy top-level directory.

Currently Scipy has three build systems, distutils, numscons and bento.
Numscons is deprecated and is planned and will likely be removed in the next
release.


Generalized and shift-invert eigenvalue problems in ``scipy.sparse.linalg``
---------------------------------------------------------------------------

The sparse eigenvalue problem solver functions
``scipy.sparse.eigs/eigh`` now support generalized eigenvalue
problems, and all shift-invert modes available in ARPACK.


Discrete-Time Linear Systems (``scipy.signal``)
-----------------------------------------------

Support for simulating discrete-time linear systems, including
``scipy.signal.dlsim``, ``scipy.signal.dimpulse``, and ``scipy.signal.dstep``,
has been added to SciPy.  Conversion of linear systems from continuous-time to
discrete-time representations is also present via the
``scipy.signal.cont2discrete`` function.


Enhancements to ``scipy.signal``
--------------------------------

A Lomb-Scargle periodogram can now be computed with the new function
``scipy.signal.lombscargle``.

The forward-backward filter function ``scipy.signal.filtfilt`` can now
filter the data in a given axis of an n-dimensional numpy array.
(Previously it only handled a 1-dimensional array.)  Options have been
added to allow more control over how the data is extended before filtering.

FIR filter design with ``scipy.signal.firwin2`` now has options to create
filters of type III (zero at zero and Nyquist frequencies) and IV (zero at zero
frequency).


Additional decomposition options (``scipy.linalg``)
---------------------------------------------------

A sort keyword has been added to the Schur decomposition routine 
(``scipy.linalg.schur``) to allow the sorting of eigenvalues in
the resultant Schur form.

Additional special matrices (``scipy.linalg``)
----------------------------------------------

The functions ``hilbert`` and ``invhilbert`` were added to ``scipy.linalg``.


Enhancements to ``scipy.stats``
-------------------------------

* The *one-sided form* of Fisher's exact test is now also implemented in
  ``stats.fisher_exact``. 
* The function ``stats.chi2_contingency`` for computing the chi-square test of
  independence of factors in a contingency table has been added, along with
  the related utility functions ``stats.contingency.margins`` and
  ``stats.contingency.expected_freq``.


Enhancements to ``scipy.special``
---------------------------------

The functions ``logit(p) = log(p/(1-p))``
and ``expit(x) = 1/(1+exp(-x))`` have been implemented as
``scipy.special.logit`` and ``scipy.special.expit`` respectively.


Basic support for Harwell-Boeing file format for sparse matrices
----------------------------------------------------------------

Both read and write are support through a simple function-based API, as well as
a more complete API to control number format. The functions may be found in
scipy.sparse.io.

The following features are supported:

    * Read and write sparse matrices in the CSC format
    * Only real, symmetric, assembled matrix are supported (RUA format)


Deprecated features
===================

``scipy.maxentropy``
--------------------

The maxentropy module is unmaintained, rarely used and has not been functioning
well for several releases.  Therefore it has been deprecated for this release,
and will be removed for scipy 0.11.  Logistic regression in scikits.learn is a
good alternative for this functionality.  The ``scipy.maxentropy.logsumexp``
function has been moved to ``scipy.misc``.


``scipy.lib.blas``
------------------

There are similar BLAS wrappers in ``scipy.linalg`` and ``scipy.lib``.  These
have now been consolidated as ``scipy.linalg.blas``, and ``scipy.lib.blas`` is
deprecated.


Numscons build system
---------------------

The numscons build system is being replaced by Bento, and will be removed in
one of the next scipy releases.


Backwards-incompatible changes
==============================

The deprecated name `invnorm` was removed from ``scipy.stats.distributions``,
this distribution is available as `invgauss`.

The following deprecated nonlinear solvers from ``scipy.optimize`` have been
removed::

  - ``broyden_modified`` (bad performance)
  - ``broyden1_modified`` (bad performance)
  - ``broyden_generalized`` (equivalent to ``anderson``)
  - ``anderson2`` (equivalent to ``anderson``)
  - ``broyden3`` (obsoleted by new limited-memory broyden methods)
  - ``vackar`` (renamed to ``diagbroyden``)
 

Other changes
=============

``scipy.constants`` has been updated with the CODATA 2010 constants.

``__all__`` dicts have been added to all modules, which has cleaned up the
namespaces (particularly useful for interactive work).

An API section has been added to the documentation, giving recommended import
guidelines and specifying which submodules are public and which aren't.


Authors
=======

This release contains work by the following people (contributed at least
one patch to this release, names in alphabetical order):

* Jeff Armstrong +
* Matthew Brett
* Lars Buitinck +
* David Cournapeau
* FI$H 2000 +
* Michael McNeil Forbes +
* Matty G +
* Christoph Gohlke
* Ralf Gommers
* Yaroslav Halchenko
* Charles Harris
* Thouis (Ray) Jones +
* Chris Jordan-Squire +
* Robert Kern
* Chris Lasher +
* Wes McKinney +
* Travis Oliphant
* Fabian Pedregosa
* Josef Perktold
* Thomas Robitaille +
* Pim Schellart +
* Anthony Scopatz +
* Skipper Seabold +
* Fazlul Shahriar +
* David Simcha +
* Scott Sinclair +
* Andrey Smirnov +
* Collin RM Stocks +
* Martin Teichmann +
* Jake Vanderplas +
* Gaël Varoquaux +
* Pauli Virtanen
* Stefan van der Walt
* Warren Weckesser
* Mark Wiebe +

A total of 35 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.

=========================
SciPy 0.7.2 Release Notes
=========================

.. contents::

SciPy 0.7.2 is a bug-fix release with no new features compared to 0.7.1. The
only change is that all C sources from Cython code have been regenerated with
Cython 0.12.1. This fixes the incompatibility between binaries of SciPy 0.7.1
and NumPy 1.4. 
==========================
SciPy 0.16.0 Release Notes
==========================

.. contents::

SciPy 0.16.0 is the culmination of 7 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.16.x branch, and on adding
new features on the master branch.

This release requires Python 2.6, 2.7 or 3.2-3.4 and NumPy 1.6.2 or greater.

Highlights of this release include:

- A Cython API for BLAS/LAPACK in `scipy.linalg`
- A new benchmark suite.  It's now straightforward to add new benchmarks, and
  they're routinely included with performance enhancement PRs.
- Support for the second order sections (SOS) format in `scipy.signal`.


New features
============

Benchmark suite
---------------

The benchmark suite has switched to using `Airspeed Velocity
<https://asv.readthedocs.io/en/stable/>`__ for benchmarking. You can
run the suite locally via ``python runtests.py --bench``. For more
details, see ``benchmarks/README.rst``.

`scipy.linalg` improvements
---------------------------

A full set of Cython wrappers for BLAS and LAPACK has been added in the
modules `scipy.linalg.cython_blas` and `scipy.linalg.cython_lapack`.
In Cython, these wrappers can now be cimported from their corresponding
modules and used without linking directly against BLAS or LAPACK.

The functions `scipy.linalg.qr_delete`, `scipy.linalg.qr_insert` and
`scipy.linalg.qr_update` for updating QR decompositions were added.

The function `scipy.linalg.solve_circulant` solves a linear system with
a circulant coefficient matrix.

The function `scipy.linalg.invpascal` computes the inverse of a Pascal matrix.

The function `scipy.linalg.solve_toeplitz`, a Levinson-Durbin Toeplitz solver,
was added.

Added wrapper for potentially useful LAPACK function ``*lasd4``.  It computes
the square root of the i-th updated eigenvalue of a positive symmetric rank-one
modification to a positive diagonal matrix. See its LAPACK documentation and
unit tests for it to get more info.

Added two extra wrappers for LAPACK least-square solvers. Namely, they are
``*gelsd`` and ``*gelsy``.

Wrappers for the LAPACK ``*lange`` functions, which calculate various matrix
norms, were added.

Wrappers for ``*gtsv`` and ``*ptsv``, which solve ``A*X = B`` for tri-diagonal
matrix ``A``, were added.

`scipy.signal` improvements
---------------------------

Support for second order sections (SOS) as a format for IIR filters
was added.  The new functions are:

* `scipy.signal.sosfilt`
* `scipy.signal.sosfilt_zi`,
* `scipy.signal.sos2tf`
* `scipy.signal.sos2zpk`
* `scipy.signal.tf2sos`
* `scipy.signal.zpk2sos`.

Additionally, the filter design functions `iirdesign`, `iirfilter`, `butter`,
`cheby1`, `cheby2`, `ellip`, and `bessel` can return the filter in the SOS
format.

The function `scipy.signal.place_poles`, which provides two methods to place
poles for linear systems, was added.

The option to use Gustafsson's method for choosing the initial conditions
of the forward and backward passes was added to `scipy.signal.filtfilt`.

New classes ``TransferFunction``, ``StateSpace`` and ``ZerosPolesGain`` were
added.  These classes are now returned when instantiating `scipy.signal.lti`.
Conversion between those classes can be done explicitly now.

An exponential (Poisson) window was added as ``scipy.signal.exponential``, and a
Tukey window was added as ``scipy.signal.tukey``.

The function for computing digital filter group delay was added as
`scipy.signal.group_delay`.

The functionality for spectral analysis and spectral density estimation has
been significantly improved: `scipy.signal.welch` became ~8x faster and the
functions `scipy.signal.spectrogram`, `scipy.signal.coherence` and
`scipy.signal.csd` (cross-spectral density) were added.

`scipy.signal.lsim` was rewritten - all known issues are fixed, so this
function can now be used instead of ``lsim2``; ``lsim`` is orders of magnitude
faster than ``lsim2`` in most cases.

`scipy.sparse` improvements
---------------------------

The function `scipy.sparse.norm`, which computes sparse matrix norms, was
added.

The function `scipy.sparse.random`, which allows to draw random variates from
an arbitrary distribution, was added.

`scipy.spatial` improvements
----------------------------

`scipy.spatial.cKDTree` has seen a major rewrite, which improved the
performance of the ``query`` method significantly, added support for parallel
queries, pickling, and options that affect the tree layout.  See pull request
4374 for more details.

The function `scipy.spatial.procrustes` for Procrustes analysis (statistical
shape analysis) was added.

`scipy.stats` improvements
--------------------------

The Wishart distribution and its inverse have been added, as
`scipy.stats.wishart` and `scipy.stats.invwishart`.

The Exponentially Modified Normal distribution has been
added as `scipy.stats.exponnorm`.

The Generalized Normal distribution has been added as `scipy.stats.gennorm`.

All distributions now contain a ``random_state`` property and allow specifying a
specific ``numpy.random.RandomState`` random number generator when generating
random variates.

Many statistical tests and other `scipy.stats` functions that have multiple
return values now return ``namedtuples``.  See pull request 4709 for details.

`scipy.optimize` improvements
-----------------------------

A new derivative-free method DF-SANE has been added to the nonlinear equation
system solving function `scipy.optimize.root`.


Deprecated features
===================

``scipy.stats.pdf_fromgamma`` is deprecated.  This function was undocumented,
untested and rarely used.  Statsmodels provides equivalent functionality
with ``statsmodels.distributions.ExpandedNormal``.

``scipy.stats.fastsort`` is deprecated.  This function is unnecessary,
``numpy.argsort`` can be used instead.

``scipy.stats.signaltonoise`` and ``scipy.stats.mstats.signaltonoise`` are
deprecated.  These functions did not belong in ``scipy.stats`` and are rarely
used.  See issue #609 for details.

``scipy.stats.histogram2`` is deprecated. This function is unnecessary,
``numpy.histogram2d`` can be used instead.

Backwards incompatible changes
==============================

The deprecated global optimizer ``scipy.optimize.anneal`` was removed.

The following deprecated modules have been removed: ``scipy.lib.blas``,
``scipy.lib.lapack``, ``scipy.linalg.cblas``, ``scipy.linalg.fblas``,
``scipy.linalg.clapack``, ``scipy.linalg.flapack``.  They had been deprecated
since Scipy 0.12.0, the functionality should be accessed as `scipy.linalg.blas`
and `scipy.linalg.lapack`.

The deprecated function ``scipy.special.all_mat`` has been removed.

The deprecated functions ``fprob``, ``ksprob``, ``zprob``, ``randwcdf``
and ``randwppf`` have been removed from `scipy.stats`.


Other changes
=============

The version numbering for development builds has been updated to comply with PEP 440.

Building with ``python setup.py develop`` is now supported.


Authors
=======

* @axiru +
* @endolith
* Elliott Sales de Andrade +
* Anne Archibald
* Yoshiki Vázquez Baeza +
* Sylvain Bellemare
* Felix Berkenkamp +
* Raoul Bourquin +
* Matthew Brett
* Per Brodtkorb
* Christian Brueffer
* Lars Buitinck
* Evgeni Burovski
* Steven Byrnes
* CJ Carey
* George Castillo +
* Alex Conley +
* Liam Damewood +
* Rupak Das +
* Abraham Escalante +
* Matthias Feurer +
* Eric Firing +
* Clark Fitzgerald
* Chad Fulton
* André Gaul
* Andreea Georgescu +
* Christoph Gohlke
* Andrey Golovizin +
* Ralf Gommers
* J.J. Green +
* Alex Griffing
* Alexander Grigorievskiy +
* Hans Moritz Gunther +
* Jonas Hahnfeld +
* Charles Harris
* Ian Henriksen
* Andreas Hilboll
* Åsmund Hjulstad +
* Jan Schlüter +
* Janko Slavič +
* Daniel Jensen +
* Johannes Ballé +
* Terry Jones +
* Amato Kasahara +
* Eric Larson
* Denis Laxalde
* Antony Lee
* Gregory R. Lee
* Perry Lee +
* Loïc Estève
* Martin Manns +
* Eric Martin +
* Matěj Kocián +
* Andreas Mayer +
* Nikolay Mayorov +
* Robert McGibbon +
* Sturla Molden
* Nicola Montecchio +
* Eric Moore
* Jamie Morton +
* Nikolas Moya +
* Maniteja Nandana +
* Andrew Nelson
* Joel Nothman
* Aldrian Obaja
* Regina Ongowarsito +
* Paul Ortyl +
* Pedro López-Adeva Fernández-Layos +
* Stefan Peterson +
* Irvin Probst +
* Eric Quintero +
* John David Reaver +
* Juha Remes +
* Thomas Robitaille
* Clancy Rowley +
* Tobias Schmidt +
* Skipper Seabold
* Aman Singh +
* Eric Soroos
* Valentine Svensson +
* Julian Taylor
* Aman Thakral +
* Helmut Toplitzer +
* Fukumu Tsutsumi +
* Anastasiia Tsyplia +
* Jacob Vanderplas
* Pauli Virtanen
* Matteo Visconti +
* Warren Weckesser
* Florian Wilhelm +
* Nathan Woods
* Haochen Wu +
* Daan Wynen +

A total of 93 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 0.16.0
------------------------

- `#1063 <https://github.com/scipy/scipy/issues/1063>`__: Implement a whishart distribution (Trac #536)
- `#1885 <https://github.com/scipy/scipy/issues/1885>`__: Rbf: floating point warnings - possible bug (Trac #1360)
- `#2020 <https://github.com/scipy/scipy/issues/2020>`__: Rbf default epsilon too large (Trac #1495)
- `#2325 <https://github.com/scipy/scipy/issues/2325>`__: extending distributions, hypergeom, to degenerate cases (Trac...
- `#3502 <https://github.com/scipy/scipy/issues/3502>`__: [ENH] linalg.hessenberg should use ORGHR for calc_q=True
- `#3603 <https://github.com/scipy/scipy/issues/3603>`__: Passing array as window into signal.resample() fails
- `#3675 <https://github.com/scipy/scipy/issues/3675>`__: Intermittent failures for signal.slepian on Windows
- `#3742 <https://github.com/scipy/scipy/issues/3742>`__: Pchipinterpolator inconvenient as ppoly
- `#3786 <https://github.com/scipy/scipy/issues/3786>`__: add procrustes?
- `#3798 <https://github.com/scipy/scipy/issues/3798>`__: scipy.io.savemat fails for empty dicts
- `#3975 <https://github.com/scipy/scipy/issues/3975>`__: Use RandomState in scipy.stats
- `#4022 <https://github.com/scipy/scipy/issues/4022>`__: savemat incorrectly saves logical arrays
- `#4028 <https://github.com/scipy/scipy/issues/4028>`__: scipy.stats.geom.logpmf(1,1) returns nan. The correct value is...
- `#4030 <https://github.com/scipy/scipy/issues/4030>`__: simplify scipy.stats.betaprime.cdf
- `#4031 <https://github.com/scipy/scipy/issues/4031>`__: improve accuracy of scipy.stats.gompertz distribution for small...
- `#4033 <https://github.com/scipy/scipy/issues/4033>`__: improve accuracy of scipy.stats.lomax distribution for small...
- `#4034 <https://github.com/scipy/scipy/issues/4034>`__: improve accuracy of scipy.stats.rayleigh distribution for large...
- `#4035 <https://github.com/scipy/scipy/issues/4035>`__: improve accuracy of scipy.stats.truncexpon distribution for small...
- `#4081 <https://github.com/scipy/scipy/issues/4081>`__: Error when reading matlab file: buffer is too small for requested...
- `#4100 <https://github.com/scipy/scipy/issues/4100>`__: Why does qr(a, lwork=0) not fail?
- `#4134 <https://github.com/scipy/scipy/issues/4134>`__: scipy.stats: rv_frozen has no expect() method
- `#4204 <https://github.com/scipy/scipy/issues/4204>`__: Please add docstring to scipy.optimize.RootResults
- `#4206 <https://github.com/scipy/scipy/issues/4206>`__: Wrap LAPACK tridiagonal solve routine `gtsv`
- `#4208 <https://github.com/scipy/scipy/issues/4208>`__: Empty sparse matrices written to MAT file cannot be read by MATLAB
- `#4217 <https://github.com/scipy/scipy/issues/4217>`__: use a TravisCI configuration with numpy built with NPY_RELAXED_STRIDES_CHECKING=1
- `#4282 <https://github.com/scipy/scipy/issues/4282>`__: integrate.odeint raises an exception when full_output=1 and the...
- `#4301 <https://github.com/scipy/scipy/issues/4301>`__: scipy and numpy version names do not follow pep 440
- `#4355 <https://github.com/scipy/scipy/issues/4355>`__: PPoly.antiderivative() produces incorrect output
- `#4391 <https://github.com/scipy/scipy/issues/4391>`__: spsolve becomes extremely slow with large b matrix
- `#4393 <https://github.com/scipy/scipy/issues/4393>`__: Documentation glitsch in sparse.linalg.spilu
- `#4408 <https://github.com/scipy/scipy/issues/4408>`__: Vector-valued constraints in minimize() et al
- `#4412 <https://github.com/scipy/scipy/issues/4412>`__: Documentation of scipy.signal.cwt error
- `#4428 <https://github.com/scipy/scipy/issues/4428>`__: dok.__setitem__ problem with negative indices
- `#4434 <https://github.com/scipy/scipy/issues/4434>`__: Incomplete documentation for sparse.linalg.spsolve
- `#4438 <https://github.com/scipy/scipy/issues/4438>`__: linprog() documentation example wrong
- `#4445 <https://github.com/scipy/scipy/issues/4445>`__: Typo in scipy.special.expit doc
- `#4467 <https://github.com/scipy/scipy/issues/4467>`__: Documentation Error in scipy.optimize options for TNC
- `#4492 <https://github.com/scipy/scipy/issues/4492>`__: solve_toeplitz benchmark is bitrotting already
- `#4506 <https://github.com/scipy/scipy/issues/4506>`__: lobpcg/sparse performance regression Jun 2014?
- `#4520 <https://github.com/scipy/scipy/issues/4520>`__: g77_abi_wrappers needed on Linux for MKL as well
- `#4521 <https://github.com/scipy/scipy/issues/4521>`__: Broken check in uses_mkl for newer versions of the library
- `#4523 <https://github.com/scipy/scipy/issues/4523>`__: rbf with gaussian kernel seems to produce more noise than original...
- `#4526 <https://github.com/scipy/scipy/issues/4526>`__: error in site documentation for poisson.pmf() method
- `#4527 <https://github.com/scipy/scipy/issues/4527>`__: KDTree example doesn't work in Python 3
- `#4550 <https://github.com/scipy/scipy/issues/4550>`__: `scipy.stats.mode` - UnboundLocalError on empty sequence
- `#4554 <https://github.com/scipy/scipy/issues/4554>`__: filter out convergence warnings in optimization tests
- `#4565 <https://github.com/scipy/scipy/issues/4565>`__: odeint messages
- `#4569 <https://github.com/scipy/scipy/issues/4569>`__: remez: "ValueError: Failure to converge after 25 iterations....
- `#4582 <https://github.com/scipy/scipy/issues/4582>`__: DOC: optimize: _minimize_scalar_brent does not have a disp option
- `#4585 <https://github.com/scipy/scipy/issues/4585>`__: DOC: Erroneous latex-related characters in tutorial.
- `#4590 <https://github.com/scipy/scipy/issues/4590>`__: sparse.linalg.svds should throw an exception if which not in...
- `#4594 <https://github.com/scipy/scipy/issues/4594>`__: scipy.optimize.linprog IndexError when a callback is providen
- `#4596 <https://github.com/scipy/scipy/issues/4596>`__: scipy.linalg.block_diag misbehavior with empty array inputs (v0.13.3)
- `#4599 <https://github.com/scipy/scipy/issues/4599>`__: scipy.integrate.nquad should call _OptFunc when called with only...
- `#4612 <https://github.com/scipy/scipy/issues/4612>`__: Crash in signal.lfilter on nd input with wrong shaped zi
- `#4613 <https://github.com/scipy/scipy/issues/4613>`__: scipy.io.readsav error on reading sav file
- `#4673 <https://github.com/scipy/scipy/issues/4673>`__: scipy.interpolate.RectBivariateSpline construction locks PyQt...
- `#4681 <https://github.com/scipy/scipy/issues/4681>`__: Broadcasting in signal.lfilter still not quite right.
- `#4705 <https://github.com/scipy/scipy/issues/4705>`__: kmeans k_or_guess parameter error if guess is not square array
- `#4719 <https://github.com/scipy/scipy/issues/4719>`__: Build failure on 14.04.2
- `#4724 <https://github.com/scipy/scipy/issues/4724>`__: GenGamma _munp function fails due to overflow
- `#4726 <https://github.com/scipy/scipy/issues/4726>`__: FAIL: test_cobyla.test_vector_constraints
- `#4734 <https://github.com/scipy/scipy/issues/4734>`__: Failing tests in stats with numpy master.
- `#4736 <https://github.com/scipy/scipy/issues/4736>`__: qr_update bug or incompatibility with numpy 1.10?
- `#4746 <https://github.com/scipy/scipy/issues/4746>`__: linprog returns solution violating equality constraint
- `#4757 <https://github.com/scipy/scipy/issues/4757>`__: optimize.leastsq docstring mismatch
- `#4774 <https://github.com/scipy/scipy/issues/4774>`__: Update contributor list for v0.16
- `#4779 <https://github.com/scipy/scipy/issues/4779>`__: circmean and others do not appear in the documentation
- `#4788 <https://github.com/scipy/scipy/issues/4788>`__: problems with scipy sparse linalg isolve iterative.py when complex
- `#4791 <https://github.com/scipy/scipy/issues/4791>`__: BUG: scipy.spatial: incremental Voronoi doesn't increase size...


Pull requests for 0.16.0
------------------------

- `#3116 <https://github.com/scipy/scipy/pull/3116>`__: sparse: enhancements for DIA format
- `#3157 <https://github.com/scipy/scipy/pull/3157>`__: ENH: linalg: add the function 'solve_circulant' for solving a...
- `#3442 <https://github.com/scipy/scipy/pull/3442>`__: ENH: signal: Add Gustafsson's method as an option for the filtfilt...
- `#3679 <https://github.com/scipy/scipy/pull/3679>`__: WIP: fix sporadic slepian failures
- `#3680 <https://github.com/scipy/scipy/pull/3680>`__: Some cleanups in stats
- `#3717 <https://github.com/scipy/scipy/pull/3717>`__: ENH: Add second-order sections filtering
- `#3741 <https://github.com/scipy/scipy/pull/3741>`__: Dltisys changes
- `#3956 <https://github.com/scipy/scipy/pull/3956>`__: add note to scipy.signal.resample about prime sample numbers
- `#3980 <https://github.com/scipy/scipy/pull/3980>`__: Add check_finite flag to UnivariateSpline
- `#3996 <https://github.com/scipy/scipy/pull/3996>`__: MAINT: stricter linalg argument checking
- `#4001 <https://github.com/scipy/scipy/pull/4001>`__: BUG: numerical precision in dirichlet
- `#4012 <https://github.com/scipy/scipy/pull/4012>`__: ENH: linalg: Add a function to compute the inverse of a Pascal...
- `#4021 <https://github.com/scipy/scipy/pull/4021>`__: ENH: Cython api for lapack and blas
- `#4089 <https://github.com/scipy/scipy/pull/4089>`__: Fixes for various PEP8 issues.
- `#4116 <https://github.com/scipy/scipy/pull/4116>`__: MAINT: fitpack: trim down compiler warnings (unused labels, variables)
- `#4129 <https://github.com/scipy/scipy/pull/4129>`__: ENH: stats: add a random_state property to distributions
- `#4135 <https://github.com/scipy/scipy/pull/4135>`__: ENH: Add Wishart and inverse Wishart distributions
- `#4195 <https://github.com/scipy/scipy/pull/4195>`__: improve the interpolate docs
- `#4200 <https://github.com/scipy/scipy/pull/4200>`__: ENH: Add t-test from descriptive stats function.
- `#4202 <https://github.com/scipy/scipy/pull/4202>`__: Dendrogram threshold color
- `#4205 <https://github.com/scipy/scipy/pull/4205>`__: BLD: fix a number of Bento build warnings.
- `#4211 <https://github.com/scipy/scipy/pull/4211>`__: add an ufunc for the inverse Box-Cox transfrom
- `#4212 <https://github.com/scipy/scipy/pull/4212>`__: MRG:fix for gh-4208
- `#4213 <https://github.com/scipy/scipy/pull/4213>`__: ENH: specific warning if matlab file is empty
- `#4215 <https://github.com/scipy/scipy/pull/4215>`__: Issue #4209: splprep documentation updated to reflect dimensional...
- `#4219 <https://github.com/scipy/scipy/pull/4219>`__: DOC: silence several Sphinx warnings when building the docs
- `#4223 <https://github.com/scipy/scipy/pull/4223>`__: MAINT: remove two redundant lines of code
- `#4226 <https://github.com/scipy/scipy/pull/4226>`__: try forcing the numpy rebuild with relaxed strides
- `#4228 <https://github.com/scipy/scipy/pull/4228>`__: BLD: some updates to Bento config files and docs. Closes gh-3978.
- `#4232 <https://github.com/scipy/scipy/pull/4232>`__: wrong references in the docs
- `#4242 <https://github.com/scipy/scipy/pull/4242>`__: DOC: change example sample spacing
- `#4245 <https://github.com/scipy/scipy/pull/4245>`__: Arff fixes
- `#4246 <https://github.com/scipy/scipy/pull/4246>`__: MAINT: C fixes
- `#4247 <https://github.com/scipy/scipy/pull/4247>`__: MAINT: remove some unused code
- `#4249 <https://github.com/scipy/scipy/pull/4249>`__: Add routines for updating QR decompositions
- `#4250 <https://github.com/scipy/scipy/pull/4250>`__: MAINT: Some pyflakes-driven cleanup in linalg and sparse
- `#4252 <https://github.com/scipy/scipy/pull/4252>`__: MAINT trim away >10 kLOC of generated C code
- `#4253 <https://github.com/scipy/scipy/pull/4253>`__: TST: stop shadowing ellip* tests vs boost data
- `#4254 <https://github.com/scipy/scipy/pull/4254>`__: MAINT: special: use NPY_PI, not M_PI
- `#4255 <https://github.com/scipy/scipy/pull/4255>`__: DOC: INSTALL: use Py3-compatible print syntax, and don't mention...
- `#4256 <https://github.com/scipy/scipy/pull/4256>`__: ENH: spatial: reimplement cdist_cosine using np.dot
- `#4258 <https://github.com/scipy/scipy/pull/4258>`__: BUG: io.arff #4429 #2088
- `#4261 <https://github.com/scipy/scipy/pull/4261>`__: MAINT: signal: PEP8 and related style clean up.
- `#4262 <https://github.com/scipy/scipy/pull/4262>`__: BUG: newton_krylov() was ignoring norm_tol argument, closes #4259
- `#4263 <https://github.com/scipy/scipy/pull/4263>`__: MAINT: clean up test noise and optimize tests for docstrings...
- `#4266 <https://github.com/scipy/scipy/pull/4266>`__: MAINT: io: Give an informative error when attempting to read...
- `#4268 <https://github.com/scipy/scipy/pull/4268>`__: MAINT: fftpack benchmark integer division vs true division
- `#4269 <https://github.com/scipy/scipy/pull/4269>`__: MAINT: avoid shadowing the eigvals function
- `#4272 <https://github.com/scipy/scipy/pull/4272>`__: BUG: sparse: Fix bench_sparse.py
- `#4276 <https://github.com/scipy/scipy/pull/4276>`__: DOC: remove confusing parts of the documentation related to writing...
- `#4281 <https://github.com/scipy/scipy/pull/4281>`__: Sparse matrix multiplication: only convert array if needed (with...
- `#4284 <https://github.com/scipy/scipy/pull/4284>`__: BUG: integrate: odeint crashed when the integration time was...
- `#4286 <https://github.com/scipy/scipy/pull/4286>`__: MRG: fix matlab output type of logical array
- `#4287 <https://github.com/scipy/scipy/pull/4287>`__: DEP: deprecate stats.pdf_fromgamma. Closes gh-699.
- `#4291 <https://github.com/scipy/scipy/pull/4291>`__: DOC: linalg: fix layout in cholesky_banded docstring
- `#4292 <https://github.com/scipy/scipy/pull/4292>`__: BUG: allow empty dict as proxy for empty struct
- `#4293 <https://github.com/scipy/scipy/pull/4293>`__: MAINT: != -> not_equal in hamming distance implementation
- `#4295 <https://github.com/scipy/scipy/pull/4295>`__: Pole placement
- `#4296 <https://github.com/scipy/scipy/pull/4296>`__: MAINT: some cleanups in tests of several modules
- `#4302 <https://github.com/scipy/scipy/pull/4302>`__: ENH: Solve toeplitz linear systems
- `#4306 <https://github.com/scipy/scipy/pull/4306>`__: Add benchmark for conjugate gradient solver.
- `#4307 <https://github.com/scipy/scipy/pull/4307>`__: BLD: PEP 440
- `#4310 <https://github.com/scipy/scipy/pull/4310>`__: BUG: make stats.geom.logpmf(1,1) return 0.0 instead of nan
- `#4311 <https://github.com/scipy/scipy/pull/4311>`__: TST: restore a test that uses slogdet now that we have dropped...
- `#4313 <https://github.com/scipy/scipy/pull/4313>`__: Some minor fixes for stats.wishart addition.
- `#4315 <https://github.com/scipy/scipy/pull/4315>`__: MAINT: drop numpy 1.5 compatibility code in sparse matrix tests
- `#4318 <https://github.com/scipy/scipy/pull/4318>`__: ENH: Add random_state to multivariate distributions
- `#4319 <https://github.com/scipy/scipy/pull/4319>`__: MAINT: fix hamming distance regression for exotic arrays, with...
- `#4320 <https://github.com/scipy/scipy/pull/4320>`__: TST: a few changes like self.assertTrue(x == y, message) -> assert_equal(x,...
- `#4321 <https://github.com/scipy/scipy/pull/4321>`__: TST: more changes like self.assertTrue(x == y, message) -> assert_equal(x,...
- `#4322 <https://github.com/scipy/scipy/pull/4322>`__: TST: in test_signaltools, changes like self.assertTrue(x == y,...
- `#4323 <https://github.com/scipy/scipy/pull/4323>`__: MAINT: clean up benchmarks so they can all be run as single files.
- `#4324 <https://github.com/scipy/scipy/pull/4324>`__: Add more detailed committer guidelines, update MAINTAINERS.txt
- `#4326 <https://github.com/scipy/scipy/pull/4326>`__: TST: use numpy.testing in test_hierarchy.py
- `#4329 <https://github.com/scipy/scipy/pull/4329>`__: MAINT: stats: rename check_random_state test function
- `#4330 <https://github.com/scipy/scipy/pull/4330>`__: Update distance tests
- `#4333 <https://github.com/scipy/scipy/pull/4333>`__: MAINT: import comb, factorial from scipy.special, not scipy.misc
- `#4338 <https://github.com/scipy/scipy/pull/4338>`__: TST: more conversions from nose to numpy.testing
- `#4339 <https://github.com/scipy/scipy/pull/4339>`__: MAINT: remove the deprecated all_mat function from special_matrices.py
- `#4340 <https://github.com/scipy/scipy/pull/4340>`__: add several features to frozen distributions
- `#4344 <https://github.com/scipy/scipy/pull/4344>`__: BUG: Fix/test invalid lwork param in qr
- `#4345 <https://github.com/scipy/scipy/pull/4345>`__: Fix test noise visible with Python 3.x
- `#4347 <https://github.com/scipy/scipy/pull/4347>`__: Remove deprecated blas/lapack imports, rename lib to _lib
- `#4349 <https://github.com/scipy/scipy/pull/4349>`__: DOC: add a nontrivial example to stats.binned_statistic.
- `#4350 <https://github.com/scipy/scipy/pull/4350>`__: MAINT: remove optimize.anneal for 0.16.0 (was deprecated in 0.14.0).
- `#4351 <https://github.com/scipy/scipy/pull/4351>`__: MAINT: fix usage of deprecated Numpy C API in optimize...
- `#4352 <https://github.com/scipy/scipy/pull/4352>`__: MAINT: fix a number of special test failures
- `#4353 <https://github.com/scipy/scipy/pull/4353>`__: implement cdf for betaprime distribution
- `#4357 <https://github.com/scipy/scipy/pull/4357>`__: BUG: piecewise polynomial antiderivative
- `#4358 <https://github.com/scipy/scipy/pull/4358>`__: BUG: integrate: fix handling of banded Jacobians in odeint, plus...
- `#4359 <https://github.com/scipy/scipy/pull/4359>`__: MAINT: remove a code path taken for Python version < 2.5
- `#4360 <https://github.com/scipy/scipy/pull/4360>`__: MAINT: stats.mstats: Remove some unused variables (thanks, pyflakes).
- `#4362 <https://github.com/scipy/scipy/pull/4362>`__: Removed erroneous reference to smoothing parameter #4072
- `#4363 <https://github.com/scipy/scipy/pull/4363>`__: MAINT: interpolate: clean up in fitpack.py
- `#4364 <https://github.com/scipy/scipy/pull/4364>`__: MAINT: lib: don't export "partial" from decorator
- `#4365 <https://github.com/scipy/scipy/pull/4365>`__: svdvals now returns a length-0 sequence of singular values given...
- `#4367 <https://github.com/scipy/scipy/pull/4367>`__: DOC: slightly improve TeX rendering of wishart/invwishart docstring
- `#4373 <https://github.com/scipy/scipy/pull/4373>`__: ENH: wrap gtsv and ptsv for solve_banded and solveh_banded.
- `#4374 <https://github.com/scipy/scipy/pull/4374>`__: ENH: Enhancements to spatial.cKDTree
- `#4376 <https://github.com/scipy/scipy/pull/4376>`__: BF: fix reading off-spec matlab logical sparse
- `#4377 <https://github.com/scipy/scipy/pull/4377>`__: MAINT: integrate: Clean up some Fortran test code.
- `#4378 <https://github.com/scipy/scipy/pull/4378>`__: MAINT: fix usage of deprecated Numpy C API in signal
- `#4380 <https://github.com/scipy/scipy/pull/4380>`__: MAINT: scipy.optimize, removing further anneal references
- `#4381 <https://github.com/scipy/scipy/pull/4381>`__: ENH: Make DCT and DST accept int and complex types like fft
- `#4392 <https://github.com/scipy/scipy/pull/4392>`__: ENH: optimize: add DF-SANE nonlinear derivative-free solver
- `#4394 <https://github.com/scipy/scipy/pull/4394>`__: Make reordering algorithms 64-bit clean
- `#4396 <https://github.com/scipy/scipy/pull/4396>`__: BUG: bundle cblas.h in Accelerate ABI wrappers to enable compilation...
- `#4398 <https://github.com/scipy/scipy/pull/4398>`__: FIX pdist bug where wminkowski's w.dtype != double
- `#4402 <https://github.com/scipy/scipy/pull/4402>`__: BUG: fix stat.hypergeom argcheck
- `#4404 <https://github.com/scipy/scipy/pull/4404>`__: MAINT: Fill in the full symmetric squareform in the C loop
- `#4405 <https://github.com/scipy/scipy/pull/4405>`__: BUG: avoid X += X.T (refs #4401)
- `#4407 <https://github.com/scipy/scipy/pull/4407>`__: improved accuracy of gompertz distribution for small x
- `#4414 <https://github.com/scipy/scipy/pull/4414>`__: DOC:fix error in scipy.signal.cwt documentation.
- `#4415 <https://github.com/scipy/scipy/pull/4415>`__: ENH: Improve accuracy of lomax for small x.
- `#4416 <https://github.com/scipy/scipy/pull/4416>`__: DOC: correct a parameter name in docstring of SuperLU.solve....
- `#4419 <https://github.com/scipy/scipy/pull/4419>`__: Restore scipy.linalg.calc_lwork also in master
- `#4420 <https://github.com/scipy/scipy/pull/4420>`__: fix a performance issue with a sparse solver
- `#4423 <https://github.com/scipy/scipy/pull/4423>`__: ENH: improve rayleigh accuracy for large x.
- `#4424 <https://github.com/scipy/scipy/pull/4424>`__: BUG: optimize.minimize: fix overflow issue with integer x0 input.
- `#4425 <https://github.com/scipy/scipy/pull/4425>`__: ENH: Improve accuracy of truncexpon for small x
- `#4426 <https://github.com/scipy/scipy/pull/4426>`__: ENH: improve rayleigh accuracy for large x.
- `#4427 <https://github.com/scipy/scipy/pull/4427>`__: MAINT: optimize: cleanup of TNC code
- `#4429 <https://github.com/scipy/scipy/pull/4429>`__: BLD: fix build failure with numpy 1.7.x and 1.8.x.
- `#4430 <https://github.com/scipy/scipy/pull/4430>`__: BUG: fix a sparse.dok_matrix set/get copy-paste bug
- `#4433 <https://github.com/scipy/scipy/pull/4433>`__: Update _minimize.py
- `#4435 <https://github.com/scipy/scipy/pull/4435>`__: ENH: release GIL around batch distance computations
- `#4436 <https://github.com/scipy/scipy/pull/4436>`__: Fixed incomplete documentation for spsolve
- `#4439 <https://github.com/scipy/scipy/pull/4439>`__: MAINT: integrate: Some clean up in the tests.
- `#4440 <https://github.com/scipy/scipy/pull/4440>`__: Fast permutation t-test
- `#4442 <https://github.com/scipy/scipy/pull/4442>`__: DOC: optimize: fix wrong result in docstring
- `#4447 <https://github.com/scipy/scipy/pull/4447>`__: DOC: signal: Some additional documentation to go along with the...
- `#4448 <https://github.com/scipy/scipy/pull/4448>`__: DOC: tweak the docstring of lapack.linalg module
- `#4449 <https://github.com/scipy/scipy/pull/4449>`__: fix a typo in the expit docstring
- `#4451 <https://github.com/scipy/scipy/pull/4451>`__: ENH: vectorize distance loops with gcc
- `#4456 <https://github.com/scipy/scipy/pull/4456>`__: MAINT: don't fail large data tests on MemoryError
- `#4461 <https://github.com/scipy/scipy/pull/4461>`__: CI: use travis_retry to deal with network timeouts
- `#4462 <https://github.com/scipy/scipy/pull/4462>`__: DOC: rationalize minimize() et al. documentation
- `#4470 <https://github.com/scipy/scipy/pull/4470>`__: MAINT: sparse: inherit dok_matrix.toarray from spmatrix
- `#4473 <https://github.com/scipy/scipy/pull/4473>`__: BUG: signal: Fix validation of the zi shape in sosfilt.
- `#4475 <https://github.com/scipy/scipy/pull/4475>`__: BLD: setup.py: update min numpy version and support "setup.py...
- `#4481 <https://github.com/scipy/scipy/pull/4481>`__: ENH: add a new linalg special matrix: the Helmert matrix
- `#4485 <https://github.com/scipy/scipy/pull/4485>`__: MRG: some changes to allow reading bad mat files
- `#4490 <https://github.com/scipy/scipy/pull/4490>`__: [ENH] linalg.hessenberg: use orghr - rebase
- `#4491 <https://github.com/scipy/scipy/pull/4491>`__: ENH: linalg: Adding wrapper for potentially useful LAPACK function...
- `#4493 <https://github.com/scipy/scipy/pull/4493>`__: BENCH: the solve_toeplitz benchmark used outdated syntax and...
- `#4494 <https://github.com/scipy/scipy/pull/4494>`__: MAINT: stats: remove duplicated code
- `#4496 <https://github.com/scipy/scipy/pull/4496>`__: References added for watershed_ift algorithm
- `#4499 <https://github.com/scipy/scipy/pull/4499>`__: DOC: reshuffle stats distributions documentation
- `#4501 <https://github.com/scipy/scipy/pull/4501>`__: Replace benchmark suite with airspeed velocity
- `#4502 <https://github.com/scipy/scipy/pull/4502>`__: SLSQP should strictly satisfy bound constraints
- `#4503 <https://github.com/scipy/scipy/pull/4503>`__: DOC: forward port 0.15.x release notes and update author name...
- `#4504 <https://github.com/scipy/scipy/pull/4504>`__: ENH: option to avoid computing possibly unused svd matrix
- `#4505 <https://github.com/scipy/scipy/pull/4505>`__: Rebase of PR 3303 (sparse matrix norms)
- `#4507 <https://github.com/scipy/scipy/pull/4507>`__: MAINT: fix lobpcg performance regression
- `#4509 <https://github.com/scipy/scipy/pull/4509>`__: DOC: sparse: replace dead link
- `#4511 <https://github.com/scipy/scipy/pull/4511>`__: Fixed differential evolution bug
- `#4512 <https://github.com/scipy/scipy/pull/4512>`__: Change to fully PEP440 compliant dev version numbers (always...
- `#4525 <https://github.com/scipy/scipy/pull/4525>`__: made tiny style corrections (pep8)
- `#4533 <https://github.com/scipy/scipy/pull/4533>`__: Add exponentially modified gaussian distribution (scipy.stats.expongauss)
- `#4534 <https://github.com/scipy/scipy/pull/4534>`__: MAINT: benchmarks: make benchmark suite importable on all scipy...
- `#4535 <https://github.com/scipy/scipy/pull/4535>`__: BUG: Changed zip() to list(zip()) so that it could work in Python...
- `#4536 <https://github.com/scipy/scipy/pull/4536>`__: Follow up to pr 4348 (exponential window)
- `#4540 <https://github.com/scipy/scipy/pull/4540>`__: ENH: spatial: Add procrustes analysis
- `#4541 <https://github.com/scipy/scipy/pull/4541>`__: Bench fixes
- `#4542 <https://github.com/scipy/scipy/pull/4542>`__: TST: NumpyVersion dev -> dev0
- `#4543 <https://github.com/scipy/scipy/pull/4543>`__: BUG: Overflow in savgol_coeffs
- `#4544 <https://github.com/scipy/scipy/pull/4544>`__: pep8 fixes for stats
- `#4546 <https://github.com/scipy/scipy/pull/4546>`__: MAINT: use reduction axis arguments in one-norm estimation
- `#4549 <https://github.com/scipy/scipy/pull/4549>`__: ENH : Added group_delay to scipy.signal
- `#4553 <https://github.com/scipy/scipy/pull/4553>`__: ENH: Significantly faster moment function
- `#4556 <https://github.com/scipy/scipy/pull/4556>`__: DOC: document the changes of the sparse.linalg.svds (optional...
- `#4559 <https://github.com/scipy/scipy/pull/4559>`__: DOC: stats: describe loc and scale parameters in the docstring...
- `#4563 <https://github.com/scipy/scipy/pull/4563>`__: ENH: rewrite of stats.ppcc_plot
- `#4564 <https://github.com/scipy/scipy/pull/4564>`__: Be more (or less) forgiving when user passes +-inf instead of...
- `#4566 <https://github.com/scipy/scipy/pull/4566>`__: DEP: remove a bunch of deprecated function from scipy.stats,...
- `#4570 <https://github.com/scipy/scipy/pull/4570>`__: MNT: Suppress LineSearchWarning's in scipy.optimize tests
- `#4572 <https://github.com/scipy/scipy/pull/4572>`__: ENH: Extract inverse hessian information from L-BFGS-B
- `#4576 <https://github.com/scipy/scipy/pull/4576>`__: ENH: Split signal.lti into subclasses, part of #2912
- `#4578 <https://github.com/scipy/scipy/pull/4578>`__: MNT: Reconcile docstrings and function signatures
- `#4581 <https://github.com/scipy/scipy/pull/4581>`__: Fix build with Intel MKL on Linux
- `#4583 <https://github.com/scipy/scipy/pull/4583>`__: DOC: optimize: remove references to unused disp kwarg
- `#4584 <https://github.com/scipy/scipy/pull/4584>`__: ENH: scipy.signal - Tukey window
- `#4587 <https://github.com/scipy/scipy/pull/4587>`__: Hermite asymptotic
- `#4593 <https://github.com/scipy/scipy/pull/4593>`__: DOC - add example to RegularGridInterpolator
- `#4595 <https://github.com/scipy/scipy/pull/4595>`__: DOC: Fix erroneous latex characters in tutorial/optimize.
- `#4600 <https://github.com/scipy/scipy/pull/4600>`__: Add return codes to optimize.tnc docs
- `#4603 <https://github.com/scipy/scipy/pull/4603>`__: ENH: Wrap LAPACK ``*lange`` functions for matrix norms
- `#4604 <https://github.com/scipy/scipy/pull/4604>`__: scipy.stats: generalized normal distribution
- `#4609 <https://github.com/scipy/scipy/pull/4609>`__: MAINT: interpolate: fix a few inconsistencies between docstrings...
- `#4610 <https://github.com/scipy/scipy/pull/4610>`__: MAINT: make runtest.py --bench-compare use asv continuous and...
- `#4611 <https://github.com/scipy/scipy/pull/4611>`__: DOC: stats: explain rice scaling; add a note to the tutorial...
- `#4614 <https://github.com/scipy/scipy/pull/4614>`__: BUG: lfilter, the size of zi was not checked correctly for nd...
- `#4617 <https://github.com/scipy/scipy/pull/4617>`__: MAINT: integrate: Clean the C code behind odeint.
- `#4618 <https://github.com/scipy/scipy/pull/4618>`__: FIX: Raise error when window length != data length
- `#4619 <https://github.com/scipy/scipy/pull/4619>`__: Issue #4550: `scipy.stats.mode` - UnboundLocalError on empty...
- `#4620 <https://github.com/scipy/scipy/pull/4620>`__: Fixed a problem (#4590) with svds accepting wrong eigenvalue...
- `#4621 <https://github.com/scipy/scipy/pull/4621>`__: Speed up special.ai_zeros/bi_zeros by 10x
- `#4623 <https://github.com/scipy/scipy/pull/4623>`__: MAINT: some tweaks to spatial.procrustes (private file, html...
- `#4628 <https://github.com/scipy/scipy/pull/4628>`__: Speed up signal.lfilter and add a convolution path for FIR filters
- `#4629 <https://github.com/scipy/scipy/pull/4629>`__: Bug: integrate.nquad; resolve issue #4599
- `#4631 <https://github.com/scipy/scipy/pull/4631>`__: MAINT: integrate: Remove unused variables in a Fortran test function.
- `#4633 <https://github.com/scipy/scipy/pull/4633>`__: MAINT: Fix convergence message for remez
- `#4635 <https://github.com/scipy/scipy/pull/4635>`__: PEP8: indentation (so that pep8 bot does not complain)
- `#4637 <https://github.com/scipy/scipy/pull/4637>`__: MAINT: generalize a sign function to do the right thing for complex...
- `#4639 <https://github.com/scipy/scipy/pull/4639>`__: Amended typo in apple_sgemv_fix.c
- `#4642 <https://github.com/scipy/scipy/pull/4642>`__: MAINT: use lapack for scipy.linalg.norm
- `#4643 <https://github.com/scipy/scipy/pull/4643>`__: RBF default epsilon too large 2020
- `#4646 <https://github.com/scipy/scipy/pull/4646>`__: Added atleast_1d around poly in invres and invresz
- `#4647 <https://github.com/scipy/scipy/pull/4647>`__: fix doc pdf build
- `#4648 <https://github.com/scipy/scipy/pull/4648>`__: BUG: Fixes #4408: Vector-valued constraints in minimize() et...
- `#4649 <https://github.com/scipy/scipy/pull/4649>`__: Vonmisesfix
- `#4650 <https://github.com/scipy/scipy/pull/4650>`__: Signal example clean up in Tukey and place_poles
- `#4652 <https://github.com/scipy/scipy/pull/4652>`__: DOC: Fix the error in convolve for same mode
- `#4653 <https://github.com/scipy/scipy/pull/4653>`__: improve erf performance
- `#4655 <https://github.com/scipy/scipy/pull/4655>`__: DEP: deprecate scipy.stats.histogram2 in favour of np.histogram2d
- `#4656 <https://github.com/scipy/scipy/pull/4656>`__: DEP: deprecate scipy.stats.signaltonoise
- `#4660 <https://github.com/scipy/scipy/pull/4660>`__: Avoid extra copy for sparse compressed [:, seq] and [seq, :]...
- `#4661 <https://github.com/scipy/scipy/pull/4661>`__: Clean, rebase of #4478, adding ?gelsy and ?gelsd wrappers
- `#4662 <https://github.com/scipy/scipy/pull/4662>`__: MAINT: Correct odeint messages
- `#4664 <https://github.com/scipy/scipy/pull/4664>`__: Update _monotone.py
- `#4672 <https://github.com/scipy/scipy/pull/4672>`__: fix behavior of scipy.linalg.block_diag for empty input
- `#4675 <https://github.com/scipy/scipy/pull/4675>`__: Fix lsim
- `#4676 <https://github.com/scipy/scipy/pull/4676>`__: Added missing colon to :math: directive in docstring.
- `#4679 <https://github.com/scipy/scipy/pull/4679>`__: ENH: sparse randn
- `#4682 <https://github.com/scipy/scipy/pull/4682>`__: ENH: scipy.signal - Addition of CSD, coherence; Enhancement of...
- `#4684 <https://github.com/scipy/scipy/pull/4684>`__: BUG: various errors in weight calculations in orthogonal.py
- `#4685 <https://github.com/scipy/scipy/pull/4685>`__: BUG: Fixes #4594: optimize.linprog IndexError when a callback...
- `#4686 <https://github.com/scipy/scipy/pull/4686>`__: MAINT: cluster: Clean up duplicated exception raising code.
- `#4688 <https://github.com/scipy/scipy/pull/4688>`__: Improve is_distance_dm exception message
- `#4692 <https://github.com/scipy/scipy/pull/4692>`__: MAINT: stats: Simplify the calculation in tukeylambda._ppf
- `#4693 <https://github.com/scipy/scipy/pull/4693>`__: ENH: added functionality to handle scalars in `stats._chk_asarray`
- `#4694 <https://github.com/scipy/scipy/pull/4694>`__: Vectorization of Anderson-Darling computations.
- `#4696 <https://github.com/scipy/scipy/pull/4696>`__: Fix singleton expansion in lfilter.
- `#4698 <https://github.com/scipy/scipy/pull/4698>`__: MAINT: quiet warnings from cephes.
- `#4701 <https://github.com/scipy/scipy/pull/4701>`__: add Bpoly.antiderivatives / integrals
- `#4703 <https://github.com/scipy/scipy/pull/4703>`__: Add citation of published paper
- `#4706 <https://github.com/scipy/scipy/pull/4706>`__: MAINT: special: avoid out-of-bounds access in specfun
- `#4707 <https://github.com/scipy/scipy/pull/4707>`__: MAINT: fix issues with np.matrix as input to functions related...
- `#4709 <https://github.com/scipy/scipy/pull/4709>`__: ENH: `scipy.stats` now returns namedtuples.
- `#4710 <https://github.com/scipy/scipy/pull/4710>`__: scipy.io.idl: make reader more robust to missing variables in...
- `#4711 <https://github.com/scipy/scipy/pull/4711>`__: Fix crash for unknown chunks at the end of file
- `#4712 <https://github.com/scipy/scipy/pull/4712>`__: Reduce onenormest memory usage
- `#4713 <https://github.com/scipy/scipy/pull/4713>`__: MAINT: interpolate: no need to pass dtype around if it can be...
- `#4714 <https://github.com/scipy/scipy/pull/4714>`__: BENCH: Add benchmarks for stats module
- `#4715 <https://github.com/scipy/scipy/pull/4715>`__: MAINT: polish signal.place_poles and signal/test_ltisys.py
- `#4716 <https://github.com/scipy/scipy/pull/4716>`__: DEP: deprecate mstats.signaltonoise ...
- `#4717 <https://github.com/scipy/scipy/pull/4717>`__: MAINT: basinhopping: fix error in tests, silence /0 warning,...
- `#4718 <https://github.com/scipy/scipy/pull/4718>`__: ENH: stats: can specify f-shapes to fix in fitting by name
- `#4721 <https://github.com/scipy/scipy/pull/4721>`__: Document that imresize converts the input to a PIL image
- `#4722 <https://github.com/scipy/scipy/pull/4722>`__: MAINT: PyArray_BASE is not an lvalue unless the deprecated API...
- `#4725 <https://github.com/scipy/scipy/pull/4725>`__: Fix gengamma _nump failure
- `#4728 <https://github.com/scipy/scipy/pull/4728>`__: DOC: add poch to the list of scipy special function descriptions
- `#4735 <https://github.com/scipy/scipy/pull/4735>`__: MAINT: stats: avoid (a spurious) division-by-zero in skew
- `#4738 <https://github.com/scipy/scipy/pull/4738>`__: TST: silence runtime warnings for some corner cases in `stats`...
- `#4739 <https://github.com/scipy/scipy/pull/4739>`__: BLD: try to build numpy instead of using the one on TravisCI
- `#4740 <https://github.com/scipy/scipy/pull/4740>`__: DOC: Update some docstrings with 'versionadded'.
- `#4742 <https://github.com/scipy/scipy/pull/4742>`__: BLD: make sure that relaxed strides checking is in effect on...
- `#4750 <https://github.com/scipy/scipy/pull/4750>`__: DOC: special: TeX typesetting of rel_entr, kl_div and pseudo_huber
- `#4751 <https://github.com/scipy/scipy/pull/4751>`__: BENCH: add sparse null slice benchmark
- `#4753 <https://github.com/scipy/scipy/pull/4753>`__: BUG: Fixed compilation with recent Cython versions.
- `#4756 <https://github.com/scipy/scipy/pull/4756>`__: BUG: Fixes #4733: optimize.brute finish option is not compatible...
- `#4758 <https://github.com/scipy/scipy/pull/4758>`__: DOC: optimize.leastsq default maxfev clarification
- `#4759 <https://github.com/scipy/scipy/pull/4759>`__: improved stats mle fit
- `#4760 <https://github.com/scipy/scipy/pull/4760>`__: MAINT: count bfgs updates more carefully
- `#4762 <https://github.com/scipy/scipy/pull/4762>`__: BUGS: Fixes #4746 and #4594: linprog returns solution violating...
- `#4763 <https://github.com/scipy/scipy/pull/4763>`__: fix small linprog bugs
- `#4766 <https://github.com/scipy/scipy/pull/4766>`__: BENCH: add signal.lsim benchmark
- `#4768 <https://github.com/scipy/scipy/pull/4768>`__: fix python syntax errors in docstring examples
- `#4769 <https://github.com/scipy/scipy/pull/4769>`__: Fixes #4726: test_cobyla.test_vector_constraints
- `#4770 <https://github.com/scipy/scipy/pull/4770>`__: Mark FITPACK functions as thread safe.
- `#4771 <https://github.com/scipy/scipy/pull/4771>`__: edited scipy/stats/stats.py to fix doctest for fisher_exact
- `#4773 <https://github.com/scipy/scipy/pull/4773>`__: DOC: update 0.16.0 release notes.
- `#4775 <https://github.com/scipy/scipy/pull/4775>`__: DOC: linalg: add funm_psd as a docstring example
- `#4778 <https://github.com/scipy/scipy/pull/4778>`__: Use a dictionary for function name synonyms
- `#4780 <https://github.com/scipy/scipy/pull/4780>`__: Include apparently-forgotten functions in docs
- `#4783 <https://github.com/scipy/scipy/pull/4783>`__: Added many missing special functions to docs
- `#4784 <https://github.com/scipy/scipy/pull/4784>`__: add an axis attribute to PPoly and friends
- `#4785 <https://github.com/scipy/scipy/pull/4785>`__: Brief note about origin of Lena image
- `#4786 <https://github.com/scipy/scipy/pull/4786>`__: DOC: reformat the Methods section of the KDE docstring
- `#4787 <https://github.com/scipy/scipy/pull/4787>`__: Add rice cdf and ppf.
- `#4792 <https://github.com/scipy/scipy/pull/4792>`__: CI: add a kludge for detecting test failures which try to disguise...
- `#4795 <https://github.com/scipy/scipy/pull/4795>`__: Make refguide_check smarter about false positives
- `#4797 <https://github.com/scipy/scipy/pull/4797>`__: BUG/TST: numpoints not updated for incremental Voronoi
- `#4799 <https://github.com/scipy/scipy/pull/4799>`__: BUG: spatial: Fix a couple edge cases for the Mahalanobis metric...
- `#4801 <https://github.com/scipy/scipy/pull/4801>`__: BUG: Fix TypeError in scipy.optimize._trust-region.py when disp=True.
- `#4803 <https://github.com/scipy/scipy/pull/4803>`__: Issues with relaxed strides in QR updating routines
- `#4806 <https://github.com/scipy/scipy/pull/4806>`__: MAINT: use an informed initial guess for cauchy fit
- `#4810 <https://github.com/scipy/scipy/pull/4810>`__: PEP8ify codata.py
- `#4812 <https://github.com/scipy/scipy/pull/4812>`__: BUG: Relaxed strides cleanup in decomp_update.pyx.in
- `#4820 <https://github.com/scipy/scipy/pull/4820>`__: BLD: update Bento build for sgemv fix and install cython blas/lapack...
- `#4823 <https://github.com/scipy/scipy/pull/4823>`__: ENH: scipy.signal - Addition of spectrogram function
- `#4827 <https://github.com/scipy/scipy/pull/4827>`__: DOC: add csd and coherence to __init__.py
- `#4833 <https://github.com/scipy/scipy/pull/4833>`__: BLD: fix issue in linalg ``*lange`` wrappers for g77 builds.
- `#4841 <https://github.com/scipy/scipy/pull/4841>`__: TST: fix test failures in scipy.special with mingw32 due to test...
- `#4842 <https://github.com/scipy/scipy/pull/4842>`__: DOC: update site.cfg.example. Mostly taken over from Numpy
- `#4845 <https://github.com/scipy/scipy/pull/4845>`__: BUG: signal: Make spectrogram's return values order match the...
- `#4849 <https://github.com/scipy/scipy/pull/4849>`__: DOC:Fix error in ode docstring example
- `#4856 <https://github.com/scipy/scipy/pull/4856>`__: BUG: fix typo causing memleak
==========================
SciPy 1.6.2 Release Notes
==========================

.. contents::

SciPy 1.6.2 is a bug-fix release with no new features
compared to 1.6.1. This is also the first SciPy release
to place upper bounds on some dependencies to improve
the long-term repeatability of source builds.

Authors
=======

* Pradipta Ghosh +
* Tyler Reddy
* Ralf Gommers
* Martin K. Scherer +
* Robert Uhl
* Warren Weckesser

A total of 6 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.6.2
-----------------------

* `#13512 <https://github.com/scipy/scipy/issues/13512>`__: \`stats.gaussian_kde.evaluate\` broken on S390X
* `#13584 <https://github.com/scipy/scipy/issues/13584>`__: rotation._compute_euler_from_matrix() creates an array with negative...
* `#13585 <https://github.com/scipy/scipy/issues/13585>`__: Behavior change in coo_matrix when dtype=None
* `#13686 <https://github.com/scipy/scipy/issues/13686>`__: delta0 argument of scipy.odr.ODR() ignored

Pull requests for 1.6.2
-----------------------

* `#12862 <https://github.com/scipy/scipy/pull/12862>`__: REL: put upper bounds on versions of dependencies
* `#13575 <https://github.com/scipy/scipy/pull/13575>`__: BUG: fix \`gaussian_kernel_estimate\` on S390X
* `#13586 <https://github.com/scipy/scipy/pull/13586>`__: BUG: sparse: Create a utility function \`getdata\`
* `#13598 <https://github.com/scipy/scipy/pull/13598>`__: MAINT, BUG: enforce contiguous layout for output array in Rotation.as_euler
* `#13687 <https://github.com/scipy/scipy/pull/13687>`__: BUG: fix scipy.odr to consider given delta0 argument
==========================
SciPy 1.3.1 Release Notes
==========================

.. contents::

SciPy 1.3.1 is a bug-fix release with no new features
compared to 1.3.0.

Authors
=======

* Matt Haberland
* Geordie McBain
* Yu Feng
* Evgeni Burovski
* Sturla Molden
* Tapasweni Pathak
* Eric Larson
* Peter Bell
* Carlos Ramos Carreño +
* Ralf Gommers
* David Hagen
* Antony Lee
* Ayappan P
* Tyler Reddy
* Pauli Virtanen

A total of 15 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.3.1
-----------------------

* `#5040 <https://github.com/scipy/scipy/issues/5040>`__: BUG: Empty data handling of (c)KDTrees
* `#9901 <https://github.com/scipy/scipy/issues/9901>`__: lsoda fails to detect stiff problem when called from solve_ivp
* `#10206 <https://github.com/scipy/scipy/issues/10206>`__: sparse matrices indexing with scipy 1.3
* `#10232 <https://github.com/scipy/scipy/issues/10232>`__: Exception in loadarff with quoted nominal attributes in scipy...
* `#10292 <https://github.com/scipy/scipy/issues/10292>`__: DOC/REL: Some sections of the release notes are not nested correctly. 
* `#10303 <https://github.com/scipy/scipy/issues/10303>`__: BUG: optimize: `linprog` failing TestLinprogSimplexBland::test_unbounded_below_no_presolve_corrected 
* `#10376 <https://github.com/scipy/scipy/issues/10376>`__: TST: Travis CI fails (with pytest 5.0 ?)
* `#10384 <https://github.com/scipy/scipy/issues/10384>`__: CircleCI doc build failing on new warnings
* `#10398 <https://github.com/scipy/scipy/issues/10398>`__: Scipy 1.3.0 build broken in AIX
* `#10501 <https://github.com/scipy/scipy/issues/10501>`__: BUG: scipy.spatial.HalfspaceIntersection works incorrectly
* `#10514 <https://github.com/scipy/scipy/issues/10514>`__: BUG: cKDTree GIL handling is incorrect
* `#10535 <https://github.com/scipy/scipy/issues/10535>`__: TST: master branch CI failures 
* `#10572 <https://github.com/scipy/scipy/issues/10572>`__: BUG: ckdtree query_ball_point errors on discontiguous input
* `#10597 <https://github.com/scipy/scipy/issues/10597>`__: BUG: No warning on PchipInterpolator changing from bernstein base to local power base

Pull requests for 1.3.1
-----------------------

* `#10071 <https://github.com/scipy/scipy/pull/10071>`__: DOC: reconstruct SuperLU permutation matrices avoiding SparseEfficiencyWarning
* `#10196 <https://github.com/scipy/scipy/pull/10196>`__: Fewer checks on xdata for curve_fit.
* `#10207 <https://github.com/scipy/scipy/pull/10207>`__: BUG: Compressed matrix indexing should return a scalar
* `#10233 <https://github.com/scipy/scipy/pull/10233>`__: Fix for ARFF reader regression (#10232)
* `#10306 <https://github.com/scipy/scipy/pull/10306>`__: BUG: optimize: Fix for 10303
* `#10309 <https://github.com/scipy/scipy/pull/10309>`__: BUG: Pass jac=None directly to lsoda
* `#10377 <https://github.com/scipy/scipy/pull/10377>`__: TST, MAINT: adjustments for pytest 5.0
* `#10379 <https://github.com/scipy/scipy/pull/10379>`__: BUG: sparse: set writeability to be forward-compatible with numpy>=1.17
* `#10426 <https://github.com/scipy/scipy/pull/10426>`__: MAINT: Fix doc build bugs
* `#10431 <https://github.com/scipy/scipy/pull/10431>`__: Update numpy version for AIX
* `#10457 <https://github.com/scipy/scipy/pull/10457>`__: BUG: Allow ckdtree to accept empty data input
* `#10503 <https://github.com/scipy/scipy/pull/10503>`__: BUG: spatial/qhull: get HalfspaceIntersection.dual_points from the correct array
* `#10516 <https://github.com/scipy/scipy/pull/10516>`__: BUG: Use nogil contexts in cKDTree
* `#10520 <https://github.com/scipy/scipy/pull/10520>`__: DOC: Proper .rst formatting for deprecated features and Backwards incompatible changes
* `#10540 <https://github.com/scipy/scipy/pull/10540>`__: MAINT: Fix Travis and Circle 
* `#10573 <https://github.com/scipy/scipy/pull/10573>`__: BUG: Fix query_ball_point with discontiguous input
* `#10600 <https://github.com/scipy/scipy/pull/10600>`__: BUG: interpolate: fix broken conversions between PPoly/BPoly objects
==========================
SciPy 1.0.0 Release Notes
==========================

.. contents::

We are extremely pleased to announce the release of SciPy 1.0, 16 years after
version 0.1 saw the light of day.  It has been a long, productive journey to
get here, and we anticipate many more exciting new features and releases in the
future.


Why 1.0 now?
------------

A version number should reflect the maturity of a project - and SciPy was a
mature and stable library that is heavily used in production settings for a
long time already.  From that perspective, the 1.0 version number is long
overdue.

Some key project goals, both technical (e.g. Windows wheels and continuous
integration) and organisational (a governance structure, code of conduct and a
roadmap), have been achieved recently.

Many of us are a bit perfectionist, and therefore are reluctant to call
something "1.0" because it may imply that it's "finished" or "we are 100% happy
with it".  This is normal for many open source projects, however that doesn't
make it right.  We acknowledge to ourselves that it's not perfect, and there
are some dusty corners left (that will probably always be the case).  Despite
that, SciPy is extremely useful to its users, on average has high quality code
and documentation, and gives the stability and backwards compatibility
guarantees that a 1.0 label imply.


Some history and perspectives
-----------------------------

- 2001: the first SciPy release
- 2005: transition to NumPy
- 2007: creation of scikits
- 2008: scipy.spatial module and first Cython code added
- 2010: moving to a 6-monthly release cycle
- 2011: SciPy development moves to GitHub
- 2011: Python 3 support
- 2012: adding a sparse graph module and unified optimization interface
- 2012: removal of scipy.maxentropy
- 2013: continuous integration with TravisCI
- 2015: adding Cython interface for BLAS/LAPACK and a benchmark suite
- 2017: adding a unified C API with scipy.LowLevelCallable; removal of scipy.weave
- 2017: SciPy 1.0 release


**Pauli Virtanen** is SciPy's Benevolent Dictator For Life (BDFL).  He says:

*Truthfully speaking, we could have released a SciPy 1.0 a long time ago, so I'm
happy we do it now at long last. The project has a long history, and during the
years it has matured also as a software project.  I believe it has well proved
its merit to warrant a version number starting with unity.*

*Since its conception 15+ years ago, SciPy has largely been written by and for
scientists, to provide a box of basic tools that they need. Over time, the set
of people active in its development has undergone some rotation, and we have
evolved towards a somewhat more systematic approach to development. Regardless,
this underlying drive has stayed the same, and I think it will also continue
propelling the project forward in future. This is all good, since not long
after 1.0 comes 1.1.*

**Travis Oliphant** is one of SciPy's creators.  He says:

*I'm honored to write a note of congratulations to the SciPy developers and the
entire SciPy community for the release of SciPy 1.0.   This release represents
a dream of many that has been patiently pursued by a stalwart group of pioneers
for nearly 2 decades.   Efforts have been broad and consistent over that time
from many hundreds of people.   From initial discussions to efforts coding and
packaging to documentation efforts to extensive conference and community
building, the SciPy effort has been a global phenomenon that it has been a
privilege to participate in.*

*The idea of SciPy was already in multiple people’s minds in 1997 when I first
joined the Python community as a young graduate student who had just fallen in
love with the expressibility and extensibility of Python.   The internet was
just starting to bringing together like-minded mathematicians and scientists in
nascent electronically-connected communities.   In 1998, there was a concerted
discussion on the matrix-SIG, python mailing list with people like Paul
Barrett, Joe Harrington, Perry Greenfield, Paul Dubois, Konrad Hinsen, David
Ascher, and others.   This discussion encouraged me in 1998 and 1999 to
procrastinate my PhD and spend a lot of time writing extension modules to
Python that mostly wrapped battle-tested Fortran and C-code making it available
to the Python user.   This work attracted the help of others like Robert Kern,
Pearu Peterson and Eric Jones who joined their efforts with mine in 2000 so
that by 2001, the first SciPy release was ready.   This was long before Github
simplified collaboration and input from others and the "patch" command and
email was how you helped a project improve.*

*Since that time, hundreds of people have spent an enormous amount of time
improving the SciPy library and the community surrounding this library has
dramatically grown. I stopped being able to participate actively in developing
the SciPy library around 2010.  Fortunately, at that time, Pauli Virtanen and
Ralf Gommers picked up the pace of development supported by dozens of other key
contributors such as David Cournapeau, Evgeni Burovski, Josef Perktold, and
Warren Weckesser.   While I have only been able to admire the development of
SciPy from a distance for the past 7 years, I have never lost my love of the
project and the concept of community-driven development.    I remain driven
even now by a desire to help sustain the development of not only the SciPy
library but many other affiliated and related open-source projects.  I am
extremely pleased that SciPy is in the hands of a world-wide community of
talented developers who will ensure that SciPy remains an example of how
grass-roots, community-driven development can succeed.*

**Fernando Perez** offers a wider community perspective:

*The existence of a nascent Scipy library, and the incredible --if tiny by
today's standards-- community surrounding it is what drew me into the
scientific Python world while still a physics graduate student in 2001.  Today,
I am awed when I see these tools power everything from high school education to
the research that led to the 2017 Nobel Prize in physics.*

*Don't be fooled by the 1.0 number: this project is a mature cornerstone of the
modern scientific computing ecosystem.  I am grateful for the many who have
made it possible, and hope to be able to contribute again to it in the future.
My sincere congratulations to the whole team!*


Highlights of this release
--------------------------

Some of the highlights of this release are:

- Major build improvements.  Windows wheels are available on PyPI for the
  first time, and continuous integration has been set up on Windows and OS X
  in addition to Linux.
- A set of new ODE solvers and a unified interface to them
  (`scipy.integrate.solve_ivp`).
- Two new trust region optimizers and a new linear programming method, with
  improved performance compared to what `scipy.optimize` offered previously.
- Many new BLAS and LAPACK functions were wrapped.  The BLAS wrappers are now
  complete.


Upgrading and compatibility
---------------------------

There have been a number of deprecations and API changes in this release, which
are documented below.  Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so, run your
code with ``python -Wd`` and check for ``DeprecationWarning`` s).

This release requires Python 2.7 or >=3.4 and NumPy 1.8.2 or greater.

This is also the last release to support LAPACK 3.1.x - 3.3.x.  Moving the
lowest supported LAPACK version to >3.2.x was long blocked by Apple Accelerate
providing the LAPACK 3.2.1 API.  We have decided that it's time to either drop
Accelerate or, if there is enough interest, provide shims for functions added
in more recent LAPACK versions so it can still be used.


New features
============

`scipy.cluster` improvements
----------------------------

`scipy.cluster.hierarchy.optimal_leaf_ordering`, a function to reorder a
linkage matrix to minimize distances between adjacent leaves, was added.


`scipy.fftpack` improvements
----------------------------

N-dimensional versions of the discrete sine and cosine transforms and their
inverses were added as ``dctn``, ``idctn``, ``dstn`` and ``idstn``.


`scipy.integrate` improvements
------------------------------

A set of new ODE solvers have been added to `scipy.integrate`.  The convenience
function `scipy.integrate.solve_ivp` allows uniform access to all solvers.
The individual solvers (``RK23``, ``RK45``, ``Radau``, ``BDF`` and ``LSODA``)
can also be used directly.


`scipy.linalg` improvements
----------------------------

The BLAS wrappers in `scipy.linalg.blas` have been completed.  Added functions
are ``*gbmv``, ``*hbmv``, ``*hpmv``, ``*hpr``, ``*hpr2``, ``*spmv``, ``*spr``,
``*tbmv``, ``*tbsv``, ``*tpmv``, ``*tpsv``, ``*trsm``, ``*trsv``, ``*sbmv``,
``*spr2``,

Wrappers for the LAPACK functions ``*gels``, ``*stev``, ``*sytrd``, ``*hetrd``,
``*sytf2``, ``*hetrf``, ``*sytrf``, ``*sycon``, ``*hecon``, ``*gglse``,
``*stebz``, ``*stemr``, ``*sterf``, and ``*stein`` have been added.

The function `scipy.linalg.subspace_angles` has been added to compute the
subspace angles between two matrices.

The function `scipy.linalg.clarkson_woodruff_transform` has been added.
It finds low-rank matrix approximation via the Clarkson-Woodruff Transform.

The functions `scipy.linalg.eigh_tridiagonal` and
`scipy.linalg.eigvalsh_tridiagonal`, which find the eigenvalues and
eigenvectors of tridiagonal hermitian/symmetric matrices, were added.


`scipy.ndimage` improvements
----------------------------

Support for homogeneous coordinate transforms has been added to
`scipy.ndimage.affine_transform`.

The ``ndimage`` C code underwent a significant refactoring, and is now
a lot easier to understand and maintain.


`scipy.optimize` improvements
-----------------------------

The methods ``trust-region-exact`` and ``trust-krylov`` have been added to the
function `scipy.optimize.minimize`. These new trust-region methods solve the
subproblem with higher accuracy at the cost of more Hessian factorizations
(compared to dogleg) or more matrix vector products (compared to ncg) but
usually require less nonlinear iterations and are able to deal with indefinite
Hessians. They seem very competitive against the other Newton methods
implemented in scipy.

`scipy.optimize.linprog` gained an interior point method.  Its performance is
superior (both in accuracy and speed) to the older simplex method.


`scipy.signal` improvements
---------------------------

An argument ``fs`` (sampling frequency) was added to the following functions:
``firwin``, ``firwin2``, ``firls``, and ``remez``.  This makes these functions
consistent with many other functions in `scipy.signal` in which the sampling
frequency can be specified.

`scipy.signal.freqz` has been sped up significantly for FIR filters.


`scipy.sparse` improvements
---------------------------

Iterating over and slicing of CSC and CSR matrices is now faster by up to ~35%.

The ``tocsr`` method of COO matrices is now several times faster.

The ``diagonal`` method of sparse matrices now takes a parameter, indicating
which diagonal to return.


`scipy.sparse.linalg` improvements
----------------------------------

A new iterative solver for large-scale nonsymmetric sparse linear systems,
`scipy.sparse.linalg.gcrotmk`, was added.  It implements ``GCROT(m,k)``, a
flexible variant of ``GCROT``.

`scipy.sparse.linalg.lsmr` now accepts an initial guess, yielding potentially
faster convergence.

SuperLU was updated to version 5.2.1.


`scipy.spatial` improvements
----------------------------

Many distance metrics in `scipy.spatial.distance` gained support for weights.

The signatures of `scipy.spatial.distance.pdist` and
`scipy.spatial.distance.cdist` were changed to ``*args, **kwargs`` in order to
support a wider range of metrics (e.g. string-based metrics that need extra
keywords).  Also, an optional ``out`` parameter was added to ``pdist`` and
``cdist`` allowing the user to specify where the resulting distance matrix is
to be stored


`scipy.stats` improvements
--------------------------

The methods ``cdf`` and ``logcdf`` were added to
`scipy.stats.multivariate_normal`, providing the cumulative distribution
function of the multivariate normal distribution.

New statistical distance functions were added, namely
`scipy.stats.wasserstein_distance` for the first Wasserstein distance and
`scipy.stats.energy_distance` for the energy distance.


Deprecated features
===================

The following functions in `scipy.misc` are deprecated: ``bytescale``,
``fromimage``, ``imfilter``, ``imread``, ``imresize``, ``imrotate``,
``imsave``, ``imshow`` and ``toimage``.  Most of those functions have unexpected
behavior (like rescaling and type casting image data without the user asking
for that).  Other functions simply have better alternatives.

``scipy.interpolate.interpolate_wrapper`` and all functions in that submodule
are deprecated.  This was a never finished set of wrapper functions which is
not relevant anymore.

The ``fillvalue`` of `scipy.signal.convolve2d` will be cast directly to the
dtypes of the input arrays in the future and checked that it is a scalar or
an array with a single element.

``scipy.spatial.distance.matching`` is deprecated.  It is an alias of
`scipy.spatial.distance.hamming`, which should be used instead.

Implementation of `scipy.spatial.distance.wminkowski` was based on a wrong
interpretation of the metric definition. In scipy 1.0 it has been just
deprecated in the documentation to keep retro-compatibility but is recommended
to use the new version of `scipy.spatial.distance.minkowski` that implements
the correct behaviour.

Positional arguments of `scipy.spatial.distance.pdist` and
`scipy.spatial.distance.cdist` should be replaced with their keyword version.


Backwards incompatible changes
==============================

The following deprecated functions have been removed from `scipy.stats`:
``betai``, ``chisqprob``, ``f_value``, ``histogram``, ``histogram2``,
``pdf_fromgamma``, ``signaltonoise``, ``square_of_sums``, ``ss`` and
``threshold``.

The following deprecated functions have been removed from `scipy.stats.mstats`:
``betai``, ``f_value_wilks_lambda``, ``signaltonoise`` and ``threshold``.

The deprecated ``a`` and ``reta`` keywords have been removed from
`scipy.stats.shapiro`.

The deprecated functions ``sparse.csgraph.cs_graph_components`` and
``sparse.linalg.symeig`` have been removed from `scipy.sparse`.

The following deprecated keywords have been removed in `scipy.sparse.linalg`:
``drop_tol`` from ``splu``, and ``xtype`` from ``bicg``, ``bicgstab``, ``cg``,
``cgs``, ``gmres``, ``qmr`` and ``minres``.

The deprecated functions ``expm2`` and ``expm3`` have been removed from
`scipy.linalg`.  The deprecated keyword ``q`` was removed from
`scipy.linalg.expm`.  And the deprecated submodule ``linalg.calc_lwork`` was
removed.

The deprecated functions ``C2K``, ``K2C``, ``F2C``, ``C2F``, ``F2K`` and
``K2F`` have been removed from `scipy.constants`.

The deprecated ``ppform`` class was removed from `scipy.interpolate`.

The deprecated keyword ``iprint`` was removed from `scipy.optimize.fmin_cobyla`.

The default value for the ``zero_phase`` keyword of `scipy.signal.decimate`
has been changed to True.

The ``kmeans`` and ``kmeans2`` functions in `scipy.cluster.vq` changed the
method used for random initialization, so using a fixed random seed will
not necessarily produce the same results as in previous versions.

`scipy.special.gammaln` does not accept complex arguments anymore.

The deprecated functions ``sph_jn``, ``sph_yn``, ``sph_jnyn``, ``sph_in``,
``sph_kn``, and ``sph_inkn`` have been removed. Users should instead use
the functions ``spherical_jn``, ``spherical_yn``, ``spherical_in``, and
``spherical_kn``. Be aware that the new functions have different
signatures.

The cross-class properties of `scipy.signal.lti` systems have been removed.
The following properties/setters have been removed:

Name - (accessing/setting has been removed) - (setting has been removed)

* StateSpace - (``num``, ``den``, ``gain``) - (``zeros``, ``poles``)
* TransferFunction (``A``, ``B``, ``C``, ``D``, ``gain``) - (``zeros``, ``poles``)
* ZerosPolesGain (``A``, ``B``, ``C``, ``D``, ``num``, ``den``) - ()

``signal.freqz(b, a)`` with ``b`` or ``a`` >1-D raises a ``ValueError``.  This
was a corner case for which it was unclear that the behavior was well-defined.

The method ``var`` of `scipy.stats.dirichlet` now returns a scalar rather than
an ndarray when the length of alpha is 1.


Other changes
=============

SciPy now has a formal governance structure.  It consists of a BDFL (Pauli
Virtanen) and a Steering Committee.  See `the governance document
<https://github.com/scipy/scipy/blob/main/doc/source/dev/governance/governance.rst>`_
for details.

It is now possible to build SciPy on Windows with MSVC + gfortran!  Continuous
integration has been set up for this build configuration on Appveyor, building
against OpenBLAS.

Continuous integration for OS X has been set up on TravisCI.

The SciPy test suite has been migrated from ``nose`` to ``pytest``.

``scipy/_distributor_init.py`` was added to allow redistributors of SciPy to
add custom code that needs to run when importing SciPy (e.g. checks for
hardware, DLL search paths, etc.).

Support for PEP 518 (specifying build system requirements) was added - see
``pyproject.toml`` in the root of the SciPy repository.

In order to have consistent function names, the function
``scipy.linalg.solve_lyapunov`` is renamed to
`scipy.linalg.solve_continuous_lyapunov`.  The old name is kept for
backwards-compatibility.


Authors
=======

* @arcady +
* @xoviat +
* Anton Akhmerov
* Dominic Antonacci +
* Alessandro Pietro Bardelli
* Ved Basu +
* Michael James Bedford +
* Ray Bell +
* Juan M. Bello-Rivas +
* Sebastian Berg
* Felix Berkenkamp
* Jyotirmoy Bhattacharya +
* Matthew Brett
* Jonathan Bright
* Bruno Jiménez +
* Evgeni Burovski
* Patrick Callier
* Mark Campanelli +
* CJ Carey
* Robert Cimrman
* Adam Cox +
* Michael Danilov +
* David Haberthür +
* Andras Deak +
* Philip DeBoer
* Anne-Sylvie Deutsch
* Cathy Douglass +
* Dominic Else +
* Guo Fei +
* Roman Feldbauer +
* Yu Feng
* Jaime Fernandez del Rio
* Orestis Floros +
* David Freese +
* Adam Geitgey +
* James Gerity +
* Dezmond Goff +
* Christoph Gohlke
* Ralf Gommers
* Dirk Gorissen +
* Matt Haberland +
* David Hagen +
* Charles Harris
* Lam Yuen Hei +
* Jean Helie +
* Gaute Hope +
* Guillaume Horel +
* Franziska Horn +
* Yevhenii Hyzyla +
* Vladislav Iakovlev +
* Marvin Kastner +
* Mher Kazandjian
* Thomas Keck
* Adam Kurkiewicz +
* Ronan Lamy +
* J.L. Lanfranchi +
* Eric Larson
* Denis Laxalde
* Gregory R. Lee
* Felix Lenders +
* Evan Limanto
* Julian Lukwata +
* François Magimel
* Syrtis Major +
* Charles Masson +
* Nikolay Mayorov
* Tobias Megies
* Markus Meister +
* Roman Mirochnik +
* Jordi Montes +
* Nathan Musoke +
* Andrew Nelson
* M.J. Nichol
* Juan Nunez-Iglesias
* Arno Onken +
* Nick Papior +
* Dima Pasechnik +
* Ashwin Pathak +
* Oleksandr Pavlyk +
* Stefan Peterson
* Ilhan Polat
* Andrey Portnoy +
* Ravi Kumar Prasad +
* Aman Pratik
* Eric Quintero
* Vedant Rathore +
* Tyler Reddy
* Joscha Reimer
* Philipp Rentzsch +
* Antonio Horta Ribeiro
* Ned Richards +
* Kevin Rose +
* Benoit Rostykus +
* Matt Ruffalo +
* Eli Sadoff +
* Pim Schellart
* Nico Schlömer +
* Klaus Sembritzki +
* Nikolay Shebanov +
* Jonathan Tammo Siebert
* Scott Sievert
* Max Silbiger +
* Mandeep Singh +
* Michael Stewart +
* Jonathan Sutton +
* Deep Tavker +
* Martin Thoma
* James Tocknell +
* Aleksandar Trifunovic +
* Paul van Mulbregt +
* Jacob Vanderplas
* Aditya Vijaykumar
* Pauli Virtanen
* James Webber
* Warren Weckesser
* Eric Wieser +
* Josh Wilson
* Zhiqing Xiao +
* Evgeny Zhurko
* Nikolay Zinov +
* Zé Vinícius +

A total of 121 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 1.0.0
-----------------------

- `#2300 <https://github.com/scipy/scipy/issues/2300>`__: scipy.misc.toimage (and therefore imresize) converts to uint32...
- `#2347 <https://github.com/scipy/scipy/issues/2347>`__: Several ``misc.im*`` functions incorrectly handle 3 or 4-channeled...
- `#2442 <https://github.com/scipy/scipy/issues/2442>`__: scipy.misc.pilutil -> scipy.ndimage?
- `#2829 <https://github.com/scipy/scipy/issues/2829>`__: Mingw Gfortran on Windows?
- `#3154 <https://github.com/scipy/scipy/issues/3154>`__: scipy.misc.imsave creates wrong bitmap header
- `#3505 <https://github.com/scipy/scipy/issues/3505>`__: scipy.linalg.lstsq() residual's help text is a lil strange
- `#3808 <https://github.com/scipy/scipy/issues/3808>`__: Is Brent's method for minimizing the value of a function implemented...
- `#4121 <https://github.com/scipy/scipy/issues/4121>`__: Add cdf() method to stats.multivariate_normal
- `#4458 <https://github.com/scipy/scipy/issues/4458>`__: scipy.misc.imresize changes image range
- `#4575 <https://github.com/scipy/scipy/issues/4575>`__: Docs for L-BFGS-B mention non-existent parameter
- `#4893 <https://github.com/scipy/scipy/issues/4893>`__: misc.imsave does not work with file type defined
- `#5231 <https://github.com/scipy/scipy/issues/5231>`__: Discrepancies in scipy.optimize.minimize(method='L-BFGS-B')
- `#5238 <https://github.com/scipy/scipy/issues/5238>`__: Optimal leaf ordering in scipy.cluster.hierarchy.dendrogram
- `#5305 <https://github.com/scipy/scipy/issues/5305>`__: Wrong image scaling in scipy/misc/pilutil.py with misc.imsave?
- `#5823 <https://github.com/scipy/scipy/issues/5823>`__: test failure in ``filter_design``
- `#6061 <https://github.com/scipy/scipy/issues/6061>`__: scipy.stats.spearmanr return values outside range -1 to 1
- `#6242 <https://github.com/scipy/scipy/issues/6242>`__: Inconsistency / duplication for imread and imshow, imsave
- `#6265 <https://github.com/scipy/scipy/issues/6265>`__: BUG: signal.iirfilter of bandpass type is unstable when high...
- `#6370 <https://github.com/scipy/scipy/issues/6370>`__: ``scipy.optimize.linear_sum_assignment`` hangs on undefined matrix
- `#6417 <https://github.com/scipy/scipy/issues/6417>`__: scipy.misc.imresize converts images to uint8
- `#6618 <https://github.com/scipy/scipy/issues/6618>`__: splrep and splprep inconsistent
- `#6854 <https://github.com/scipy/scipy/issues/6854>`__: Support PEP 519 in I/O functions
- `#6921 <https://github.com/scipy/scipy/issues/6921>`__: [Feature request] Random unitary matrix
- `#6930 <https://github.com/scipy/scipy/issues/6930>`__: ``uniform_filter1d`` appears to truncate rather than round when output...
- `#6949 <https://github.com/scipy/scipy/issues/6949>`__: interp2d function crashes python
- `#6959 <https://github.com/scipy/scipy/issues/6959>`__: scipy.interpolate.LSQUnivariateSpline - check for increasing...
- `#7005 <https://github.com/scipy/scipy/issues/7005>`__: linear_sum_assignment in scipy.optimize never return if one of...
- `#7010 <https://github.com/scipy/scipy/issues/7010>`__: ``scipy.statsbinned_statistic_2d``: incorrect binnumbers returned
- `#7049 <https://github.com/scipy/scipy/issues/7049>`__: ``expm_multiply`` is excessively slow when called for intervals
- `#7050 <https://github.com/scipy/scipy/issues/7050>`__: Documenting ``_argcheck`` for ``rv_discrete``
- `#7077 <https://github.com/scipy/scipy/issues/7077>`__: ``coo_matrix.tocsr()`` still slow
- `#7093 <https://github.com/scipy/scipy/issues/7093>`__: Wheels licensing
- `#7122 <https://github.com/scipy/scipy/issues/7122>`__: Sketching-based Matrix Computations
- `#7133 <https://github.com/scipy/scipy/issues/7133>`__: Discontinuity of a scipy special function
- `#7141 <https://github.com/scipy/scipy/issues/7141>`__: Improve documentation for Elliptic Integrals
- `#7181 <https://github.com/scipy/scipy/issues/7181>`__: A change in `numpy.poly1d` is causing the scipy tests to fail.
- `#7220 <https://github.com/scipy/scipy/issues/7220>`__: String Formatting Issue in ``LinearOperator.__init__``
- `#7239 <https://github.com/scipy/scipy/issues/7239>`__: Source tarball distribution
- `#7247 <https://github.com/scipy/scipy/issues/7247>`__: genlaguerre poly1d-object doesn't respect 'monic' option at evaluation
- `#7248 <https://github.com/scipy/scipy/issues/7248>`__: BUG: regression in Legendre polynomials on master
- `#7316 <https://github.com/scipy/scipy/issues/7316>`__: dgels is missing
- `#7381 <https://github.com/scipy/scipy/issues/7381>`__: Krogh interpolation fails to produce derivatives for complex...
- `#7416 <https://github.com/scipy/scipy/issues/7416>`__: scipy.stats.kappa4(h,k) raise a ValueError for positive integer...
- `#7421 <https://github.com/scipy/scipy/issues/7421>`__: scipy.stats.arcsine().pdf and scipy.stats.beta(0.5, 0.5).pdf...
- `#7429 <https://github.com/scipy/scipy/issues/7429>`__: ``test_matrix_norms()`` in scipy/linalg/tests/test_basic.py calls...
- `#7444 <https://github.com/scipy/scipy/issues/7444>`__: Doc: stats.dirichlet.var output description is wrong
- `#7475 <https://github.com/scipy/scipy/issues/7475>`__: Parameter amax in ``scalar_search_wolfe2`` is not used
- `#7510 <https://github.com/scipy/scipy/issues/7510>`__: Operations between numpy.array and scipy.sparse matrix return...
- `#7550 <https://github.com/scipy/scipy/issues/7550>`__: DOC: signal tutorial: Typo in explanation of convolution
- `#7551 <https://github.com/scipy/scipy/issues/7551>`__: stdint.h included in SuperLU header files, but does not exist...
- `#7553 <https://github.com/scipy/scipy/issues/7553>`__: Build for master broken on OS X
- `#7557 <https://github.com/scipy/scipy/issues/7557>`__: Error in scipy.signal.periodogram example
- `#7590 <https://github.com/scipy/scipy/issues/7590>`__: OSX test fail - ``test_ltisys.TestPlacePoles.test_real``
- `#7658 <https://github.com/scipy/scipy/issues/7658>`__: optimize.BenchGlobal broken
- `#7669 <https://github.com/scipy/scipy/issues/7669>`__: nan result from multivariate_normal.cdf
- `#7733 <https://github.com/scipy/scipy/issues/7733>`__: Inconsistent usage of indices, indptr in ``Delaunay.vertex_neighbor_vertices``
- `#7747 <https://github.com/scipy/scipy/issues/7747>`__: Numpy changes in np.random.dirichlet cause test failures
- `#7772 <https://github.com/scipy/scipy/issues/7772>`__: Fix numpy lstsq rcond= parameter
- `#7776 <https://github.com/scipy/scipy/issues/7776>`__: tests require \`nose\`
- `#7798 <https://github.com/scipy/scipy/issues/7798>`__: contributor names for 1.0 release notes
- `#7828 <https://github.com/scipy/scipy/issues/7828>`__: 32-bit Linux test errors on TestCephes
- `#7893 <https://github.com/scipy/scipy/issues/7893>`__: scipy.spatial.distance.wminkowski behaviour change in 1.0.0b1
- `#7898 <https://github.com/scipy/scipy/issues/7898>`__: DOC: Window functions
- `#7959 <https://github.com/scipy/scipy/issues/7959>`__: BUG maybe: fmin_bfgs possibly broken in 1.0
- `#7969 <https://github.com/scipy/scipy/issues/7969>`__: scipy 1.0.0rc1 windows wheels depend on missing msvcp140.dll


Pull requests for 1.0.0
-----------------------

- `#4978 <https://github.com/scipy/scipy/pull/4978>`__: WIP: add pre_center and normalize options to lombscargle
- `#5796 <https://github.com/scipy/scipy/pull/5796>`__: TST: Remove all permanent filter changes from tests
- `#5910 <https://github.com/scipy/scipy/pull/5910>`__: ENH: sparse.linalg: add GCROT(m,k)
- `#6326 <https://github.com/scipy/scipy/pull/6326>`__: ENH: New ODE solvers
- `#6480 <https://github.com/scipy/scipy/pull/6480>`__: ENH: Make `signal.decimate` default to ``zero_phase=True``
- `#6705 <https://github.com/scipy/scipy/pull/6705>`__: ENH: add initial guess to sparse.linalg.lsqr
- `#6706 <https://github.com/scipy/scipy/pull/6706>`__: ENH: add initial guess to sparse.linalg.lsmr
- `#6769 <https://github.com/scipy/scipy/pull/6769>`__: BUG: optimize: add sufficient descent condition check to CG line...
- `#6855 <https://github.com/scipy/scipy/pull/6855>`__: Handle objects supporting PEP 519 in I/O functions
- `#6945 <https://github.com/scipy/scipy/pull/6945>`__: MAINT: ckdtree codebase clean up
- `#6953 <https://github.com/scipy/scipy/pull/6953>`__: DOC: add a SciPy Project Governance document
- `#6998 <https://github.com/scipy/scipy/pull/6998>`__: fix documentation of spearman rank corrcoef
- `#7017 <https://github.com/scipy/scipy/pull/7017>`__: ENH: add methods logcdf and cdf to ``scipy.stats.multivariate_normal``
- `#7027 <https://github.com/scipy/scipy/pull/7027>`__: Add random unitary matrices
- `#7030 <https://github.com/scipy/scipy/pull/7030>`__: ENH: Add strictly-increasing checks for x to 1D splines
- `#7031 <https://github.com/scipy/scipy/pull/7031>`__: BUG: Fix ``linear_sum_assignment`` hanging on an undefined matrix
- `#7041 <https://github.com/scipy/scipy/pull/7041>`__: DOC: Clairfy that windows are DFT-even by default
- `#7048 <https://github.com/scipy/scipy/pull/7048>`__: DOC: modified docs for ``find_peak_cwt``. Fixes #6922
- `#7056 <https://github.com/scipy/scipy/pull/7056>`__: Fix insufficient precision when calculating spearman/kendall...
- `#7057 <https://github.com/scipy/scipy/pull/7057>`__: MAINT: change dtype comparison in ``optimize.linear_sum_assignment``.
- `#7059 <https://github.com/scipy/scipy/pull/7059>`__: TST: make ``Xdist_deprecated_args`` cover all metrics
- `#7061 <https://github.com/scipy/scipy/pull/7061>`__: Fix msvc 9 and 10 compile errors
- `#7070 <https://github.com/scipy/scipy/pull/7070>`__: ENH: sparse: optimizing CSR/CSC slicing fast paths
- `#7078 <https://github.com/scipy/scipy/pull/7078>`__: ENH: sparse: defer ``sum_duplicates`` to csr/csc
- `#7079 <https://github.com/scipy/scipy/pull/7079>`__: ENH: sparse: allow subclasses to override specific math operations
- `#7081 <https://github.com/scipy/scipy/pull/7081>`__: ENH: sparse: speed up CSR/CSC toarray()
- `#7082 <https://github.com/scipy/scipy/pull/7082>`__: MAINT: Add missing ``PyType_Ready(&SuperLUGlobalType)`` for Py3
- `#7083 <https://github.com/scipy/scipy/pull/7083>`__: Corrected typo in the doc of scipy.linalg.lstsq()
- `#7086 <https://github.com/scipy/scipy/pull/7086>`__: Fix bug #7049 causing excessive slowness in ``expm_multiply``
- `#7088 <https://github.com/scipy/scipy/pull/7088>`__: Documented ``_argcheck`` for ``rv_discrete``
- `#7094 <https://github.com/scipy/scipy/pull/7094>`__: MAINT: Fix mistake in PR #7082
- `#7098 <https://github.com/scipy/scipy/pull/7098>`__: BF: return NULL from failed Py3 module check
- `#7105 <https://github.com/scipy/scipy/pull/7105>`__: MAINT: Customize ?TRSYL call in lyapunov solver
- `#7111 <https://github.com/scipy/scipy/pull/7111>`__: Fix error message typo in UnivariateSpline
- `#7113 <https://github.com/scipy/scipy/pull/7113>`__: FIX: Add add float to return type in documentation
- `#7119 <https://github.com/scipy/scipy/pull/7119>`__: ENH: sparse.linalg: remove ``_count_nonzero`` hack
- `#7123 <https://github.com/scipy/scipy/pull/7123>`__: ENH: added "interior-point" method for ``scipy.optimize.linprog``
- `#7137 <https://github.com/scipy/scipy/pull/7137>`__: DOC: clarify stats.linregress docstring, closes gh-7074
- `#7138 <https://github.com/scipy/scipy/pull/7138>`__: DOC: special: Add an example to the airy docstring.
- `#7139 <https://github.com/scipy/scipy/pull/7139>`__: DOC: stats: Update stats tutorial
- `#7142 <https://github.com/scipy/scipy/pull/7142>`__: BUG: special: prevent segfault in ``pbwa``
- `#7143 <https://github.com/scipy/scipy/pull/7143>`__: DOC: special: warn about alternate elliptic integral parameterizations
- `#7146 <https://github.com/scipy/scipy/pull/7146>`__: fix docstring of NearestNDInterpolator
- `#7148 <https://github.com/scipy/scipy/pull/7148>`__: DOC: special: Add Parameters, Returns and Examples to gamma docstring
- `#7152 <https://github.com/scipy/scipy/pull/7152>`__: MAINT: spatial: Remove two unused variables in ckdtree/src/distance.h
- `#7153 <https://github.com/scipy/scipy/pull/7153>`__: MAINT: special: remove deprecated variant of ``gammaln``
- `#7154 <https://github.com/scipy/scipy/pull/7154>`__: MAINT: Fix some code that generates C compiler warnings
- `#7155 <https://github.com/scipy/scipy/pull/7155>`__: DOC: linalg: Add examples for ``solve_banded`` and ``solve_triangular``
- `#7156 <https://github.com/scipy/scipy/pull/7156>`__: DOC: fix docstring of NearestNDInterpolator
- `#7159 <https://github.com/scipy/scipy/pull/7159>`__: BUG: special: fix sign of derivative when ``x < 0`` in ``pbwa``
- `#7161 <https://github.com/scipy/scipy/pull/7161>`__: MAINT: interpolate: make Rbf.A array a property
- `#7163 <https://github.com/scipy/scipy/pull/7163>`__: MAINT: special: return nan for inaccurate regions of ``pbwa``
- `#7165 <https://github.com/scipy/scipy/pull/7165>`__: ENH: optimize: changes to make BFGS implementation more efficient.
- `#7166 <https://github.com/scipy/scipy/pull/7166>`__: BUG: Prevent infinite loop in ``optimize._lsq.trf_linear.py``
- `#7173 <https://github.com/scipy/scipy/pull/7173>`__: BUG: sparse: return a numpy matrix from ``_add_dense``
- `#7179 <https://github.com/scipy/scipy/pull/7179>`__: DOC: Fix an error in sparse argmax docstring
- `#7180 <https://github.com/scipy/scipy/pull/7180>`__: MAINT: interpolate: A bit of clean up in ``interpolate/src/_interpolate.cpp``
- `#7182 <https://github.com/scipy/scipy/pull/7182>`__: Allow homogeneous coordinate transforms in ``affine_transform``
- `#7184 <https://github.com/scipy/scipy/pull/7184>`__: MAINT: Remove hack modifying a readonly attr
- `#7185 <https://github.com/scipy/scipy/pull/7185>`__: ENH: Add evaluation of periodic splines #6730
- `#7186 <https://github.com/scipy/scipy/pull/7186>`__: MAINT: PPoly: improve error messages for wrong shape/axis
- `#7187 <https://github.com/scipy/scipy/pull/7187>`__: DEP: interpolate: deprecate interpolate_wrapper
- `#7198 <https://github.com/scipy/scipy/pull/7198>`__: DOC: linalg: Add examples for ``solveh_banded`` and ``solve_toeplitz``.
- `#7200 <https://github.com/scipy/scipy/pull/7200>`__: DOC: stats: Added tutorial documentation for the generalized...
- `#7208 <https://github.com/scipy/scipy/pull/7208>`__: DOC: Added docstrings to ``issparse/isspmatrix(_...)`` methods and...
- `#7213 <https://github.com/scipy/scipy/pull/7213>`__: DOC: Added examples to circmean, circvar, circstd
- `#7215 <https://github.com/scipy/scipy/pull/7215>`__: DOC: Adding examples to scipy.sparse.linalg.... docstrings
- `#7223 <https://github.com/scipy/scipy/pull/7223>`__: DOC: special: Add examples for expit and logit.
- `#7224 <https://github.com/scipy/scipy/pull/7224>`__: BUG: interpolate: fix integer overflow in fitpack.bispev
- `#7225 <https://github.com/scipy/scipy/pull/7225>`__: DOC: update 1.0 release notes for several recent PRs.
- `#7226 <https://github.com/scipy/scipy/pull/7226>`__: MAINT: update docs and code for mailing list move to python.org
- `#7233 <https://github.com/scipy/scipy/pull/7233>`__: Fix issue #7232: Do not mask exceptions in objective func evaluation
- `#7234 <https://github.com/scipy/scipy/pull/7234>`__: MAINT: cluster: cleaning up VQ/k-means code
- `#7236 <https://github.com/scipy/scipy/pull/7236>`__: DOC: Fixed typo
- `#7238 <https://github.com/scipy/scipy/pull/7238>`__: BUG: fix syntaxerror due to unicode character in ``trustregion_exact``.
- `#7243 <https://github.com/scipy/scipy/pull/7243>`__: DOC: Update docstring in misc/pilutil.py
- `#7246 <https://github.com/scipy/scipy/pull/7246>`__: DEP: misc: deprecate imported names
- `#7249 <https://github.com/scipy/scipy/pull/7249>`__: DOC: Add plotted example to scipy.cluster.vq.kmeans
- `#7252 <https://github.com/scipy/scipy/pull/7252>`__: Fix 5231: docs of `factr`, `ftol` in sync w/ code
- `#7254 <https://github.com/scipy/scipy/pull/7254>`__: ENH: SphericalVoronoi Input Handling
- `#7256 <https://github.com/scipy/scipy/pull/7256>`__: fix for issue #7255 - Circular statistics functions give wrong...
- `#7263 <https://github.com/scipy/scipy/pull/7263>`__: CI: use python's faulthandler to ease tracing segfaults
- `#7288 <https://github.com/scipy/scipy/pull/7288>`__: ENH: linalg: add ``subspace_angles`` function.
- `#7290 <https://github.com/scipy/scipy/pull/7290>`__: BUG: stats: Fix spurious warnings in genextreme.
- `#7292 <https://github.com/scipy/scipy/pull/7292>`__: ENH: optimize: added trust region method trust-trlib
- `#7296 <https://github.com/scipy/scipy/pull/7296>`__: DOC: stats: Add an example to the ``ttest_ind_from_stats`` docstring.
- `#7297 <https://github.com/scipy/scipy/pull/7297>`__: DOC: signal: Add examples for ``chirp()`` and ``sweep_poly()``.
- `#7299 <https://github.com/scipy/scipy/pull/7299>`__: DOC: Made difference between brent and fminbound clearer
- `#7305 <https://github.com/scipy/scipy/pull/7305>`__: Simplify if-statements and constructor calls in ``integrate._ode``
- `#7309 <https://github.com/scipy/scipy/pull/7309>`__: Comply with PEP 518.
- `#7313 <https://github.com/scipy/scipy/pull/7313>`__: REL: add ``python_requires`` to setup.py, fix Python version check.
- `#7315 <https://github.com/scipy/scipy/pull/7315>`__: BUG: Fixed bug with Laguerre and Legendre polynomials
- `#7320 <https://github.com/scipy/scipy/pull/7320>`__: DOC: clarify meaning of flags in ode.integrate
- `#7333 <https://github.com/scipy/scipy/pull/7333>`__: DOC: Add examples to ``scipy.ndimage.gaussian_filter1d``
- `#7337 <https://github.com/scipy/scipy/pull/7337>`__: ENH: add n-dimensional DCT and IDCT to fftpack
- `#7353 <https://github.com/scipy/scipy/pull/7353>`__: Add ``_gels`` functions
- `#7357 <https://github.com/scipy/scipy/pull/7357>`__: DOC: linalg: Add examples to the svdvals docstring.
- `#7359 <https://github.com/scipy/scipy/pull/7359>`__: Bump Sphinx version to 1.5.5
- `#7361 <https://github.com/scipy/scipy/pull/7361>`__: DOC: linalg: Add some 'See Also' links among special matrices...
- `#7362 <https://github.com/scipy/scipy/pull/7362>`__: TST: Fix some Fedora 25 test failures.
- `#7363 <https://github.com/scipy/scipy/pull/7363>`__: DOC: linalg: tweak the docstring example of svd
- `#7365 <https://github.com/scipy/scipy/pull/7365>`__: MAINT: fix ``refguide_check.py`` for Sphinx >= 1.5
- `#7367 <https://github.com/scipy/scipy/pull/7367>`__: BUG: odrpack: fix invalid stride checks in ``d_lpkbls.f``
- `#7368 <https://github.com/scipy/scipy/pull/7368>`__: DOC: constants: Add examples to the 'find' docstring.
- `#7376 <https://github.com/scipy/scipy/pull/7376>`__: MAINT: bundle Mathjax with built docs
- `#7377 <https://github.com/scipy/scipy/pull/7377>`__: MAINT: optimize: Better name for trust-region-exact method.
- `#7378 <https://github.com/scipy/scipy/pull/7378>`__: Improve wording in tutorial
- `#7383 <https://github.com/scipy/scipy/pull/7383>`__: fix KroghInterpolator.derivatives failure with complex input
- `#7389 <https://github.com/scipy/scipy/pull/7389>`__: FIX: Copy mutable window in ``resample_poly``
- `#7390 <https://github.com/scipy/scipy/pull/7390>`__: DOC: optimize: A few tweaks of the examples in the ``curve_fit``
- `#7391 <https://github.com/scipy/scipy/pull/7391>`__: DOC: Add examples to scipy.stats
- `#7394 <https://github.com/scipy/scipy/pull/7394>`__: "Weight" is actually mass. Add slugs and slinches/blobs to mass
- `#7398 <https://github.com/scipy/scipy/pull/7398>`__: DOC: Correct minor typo in optimize.{brenth,brentq}
- `#7401 <https://github.com/scipy/scipy/pull/7401>`__: DOC: zeta only accepts real input
- `#7413 <https://github.com/scipy/scipy/pull/7413>`__: BUG: fix error messages in ``_minimize_trustregion_exact``
- `#7414 <https://github.com/scipy/scipy/pull/7414>`__: DOC: fix ``ndimage.distance_transform_bf`` docstring [ci skip]
- `#7415 <https://github.com/scipy/scipy/pull/7415>`__: DOC: fix skew docstring [ci skip]
- `#7423 <https://github.com/scipy/scipy/pull/7423>`__: Expand binnumbers with correct dimensions
- `#7431 <https://github.com/scipy/scipy/pull/7431>`__: BUG: Extend scipy.stats.arcsine.pdf to endpoints 0 and 1 #7427
- `#7432 <https://github.com/scipy/scipy/pull/7432>`__: DOC: Add examples to scipy.cluster.hierarchy
- `#7448 <https://github.com/scipy/scipy/pull/7448>`__: ENH: stats: Implement the survival function for pareto.
- `#7454 <https://github.com/scipy/scipy/pull/7454>`__: FIX Replaced ``np.assert_allclose`` with imported ``assert_allclose``
- `#7460 <https://github.com/scipy/scipy/pull/7460>`__: TST: fix integrate.ivp test that fails on 32-bit Python.
- `#7461 <https://github.com/scipy/scipy/pull/7461>`__: Doc: Added tutorial documentation for stats distributions ksone
- `#7463 <https://github.com/scipy/scipy/pull/7463>`__: DOC: Fix typos and remove trailing whitespace
- `#7465 <https://github.com/scipy/scipy/pull/7465>`__: Fix some ndimage.interpolation endianness bugs
- `#7468 <https://github.com/scipy/scipy/pull/7468>`__: del redundance in interpolate.py
- `#7470 <https://github.com/scipy/scipy/pull/7470>`__: Initialize "info" in ``minpack_lmdif``
- `#7478 <https://github.com/scipy/scipy/pull/7478>`__: Added more testing of smirnov/smirnovi functions
- `#7479 <https://github.com/scipy/scipy/pull/7479>`__: MAINT: update for new FutureWarning's in numpy 1.13.0
- `#7480 <https://github.com/scipy/scipy/pull/7480>`__: DOC: correctly describe output shape of dirichlet.mean() and...
- `#7482 <https://github.com/scipy/scipy/pull/7482>`__: signal.lti: Remove deprecated cross-system properties
- `#7484 <https://github.com/scipy/scipy/pull/7484>`__: MAINT: Clean-up uses of np.asarray in ndimage
- `#7485 <https://github.com/scipy/scipy/pull/7485>`__: ENH: support any order >=0 in ``ndimage.gaussian_filter``
- `#7486 <https://github.com/scipy/scipy/pull/7486>`__: ENH: Support k!=0 for sparse.diagonal()
- `#7498 <https://github.com/scipy/scipy/pull/7498>`__: BUG: sparse: pass assumeSortedIndices option to scikit.umfpack
- `#7501 <https://github.com/scipy/scipy/pull/7501>`__: ENH: add optimal leaf ordering for linkage matrices
- `#7506 <https://github.com/scipy/scipy/pull/7506>`__: MAINT: remove overflow in Metropolis fixes #7495
- `#7507 <https://github.com/scipy/scipy/pull/7507>`__: TST: speed up full test suite by less eval points in mpmath tests.
- `#7509 <https://github.com/scipy/scipy/pull/7509>`__: BUG: fix issue when using ``python setup.py somecommand --force``.
- `#7511 <https://github.com/scipy/scipy/pull/7511>`__: fix some alerts found with lgtm
- `#7514 <https://github.com/scipy/scipy/pull/7514>`__: Add explanation what the integer returned mean.
- `#7516 <https://github.com/scipy/scipy/pull/7516>`__: BUG: Fix roundoff errors in ``ndimage.uniform_filter1d``.
- `#7517 <https://github.com/scipy/scipy/pull/7517>`__: TST: fix signal.convolve test that was effectively being skipped.
- `#7523 <https://github.com/scipy/scipy/pull/7523>`__: ENH: linalg: allow lstsq to work with 0-shaped arrays
- `#7525 <https://github.com/scipy/scipy/pull/7525>`__: TST: Warning cleanup
- `#7526 <https://github.com/scipy/scipy/pull/7526>`__: DOC: params in ndimage.interpolation functions not optional
- `#7527 <https://github.com/scipy/scipy/pull/7527>`__: MAINT: Encapsulate error message handling in ``NI_LineBuffer``.
- `#7528 <https://github.com/scipy/scipy/pull/7528>`__: MAINT: Remove ndimage aliases for ``NPY_MAXDIMS``.
- `#7529 <https://github.com/scipy/scipy/pull/7529>`__: MAINT: Remove ``NI_(UN)LIKELY`` macros in favor of numpy ones.
- `#7537 <https://github.com/scipy/scipy/pull/7537>`__: MAINT: Use accessor function for numpy array internals
- `#7541 <https://github.com/scipy/scipy/pull/7541>`__: MAINT: Remove some uses of Numarray types in ndimage.
- `#7543 <https://github.com/scipy/scipy/pull/7543>`__: MAINT: Replace all NumarrayTypes uses in ``ni_fourier.c``
- `#7544 <https://github.com/scipy/scipy/pull/7544>`__: MAINT: Replace all uses of NumarrayTypes in ``ni_interpolation.c``
- `#7545 <https://github.com/scipy/scipy/pull/7545>`__: MAINT: Replace all uses of NumarrayTypes in ``ni_measure.c``
- `#7546 <https://github.com/scipy/scipy/pull/7546>`__: MAINT: Replace all uses of NumarrayTypes in ``ni_morphology.c``
- `#7548 <https://github.com/scipy/scipy/pull/7548>`__: DOC: make a note in benchmarks README on how to run without rebuilding.
- `#7549 <https://github.com/scipy/scipy/pull/7549>`__: MAINT: Get rid of NumarrayTypes.
- `#7552 <https://github.com/scipy/scipy/pull/7552>`__: TST: Fix new warnings -> error bugs found on OSX
- `#7554 <https://github.com/scipy/scipy/pull/7554>`__: Update superlu to 5.2.1 + fix stdint.h issue on MSVC
- `#7556 <https://github.com/scipy/scipy/pull/7556>`__: MAINT: Fix some types from #7549 + miscellaneous warnings.
- `#7558 <https://github.com/scipy/scipy/pull/7558>`__: MAINT: Use correct #define ``NO_IMPORT_ARRAY``, not ``NO_ARRAY_IMPORT``...
- `#7562 <https://github.com/scipy/scipy/pull/7562>`__: BUG: Copy ``import_nose`` from numpy.
- `#7563 <https://github.com/scipy/scipy/pull/7563>`__: ENH: Add the first Wasserstein and the Cramér-von Mises statistical...
- `#7568 <https://github.com/scipy/scipy/pull/7568>`__: Test janitoring
- `#7571 <https://github.com/scipy/scipy/pull/7571>`__: Test janitoring pt. 2
- `#7572 <https://github.com/scipy/scipy/pull/7572>`__: Pytestifying
- `#7574 <https://github.com/scipy/scipy/pull/7574>`__: TST: Remove ignore warnings filters from stats
- `#7577 <https://github.com/scipy/scipy/pull/7577>`__: MAINT: Remove unused code in ``ndimage/ni_measure.c`` and .h
- `#7578 <https://github.com/scipy/scipy/pull/7578>`__: TST: Remove ignore warnings filters from sparse, clean up warning...
- `#7581 <https://github.com/scipy/scipy/pull/7581>`__: BUG: properly deallocate memory from ``PyArray_IntpConverter``.
- `#7582 <https://github.com/scipy/scipy/pull/7582>`__: DOC: signal tutorial: Typo in explanation of convolution
- `#7583 <https://github.com/scipy/scipy/pull/7583>`__: Remove remaining ignore warnings filters
- `#7586 <https://github.com/scipy/scipy/pull/7586>`__: DOC: add note to HACKING.rst on where to find build docs.
- `#7587 <https://github.com/scipy/scipy/pull/7587>`__: DOC: Add examples to scipy.optimize
- `#7594 <https://github.com/scipy/scipy/pull/7594>`__: TST: Add tests for ndimage converter functions.
- `#7596 <https://github.com/scipy/scipy/pull/7596>`__: Added a sanity check to ``signal.savgol_filter``
- `#7599 <https://github.com/scipy/scipy/pull/7599>`__: _upfirdn_apply stopping condition bugfix
- `#7601 <https://github.com/scipy/scipy/pull/7601>`__: MAINT: special: remove ``sph_jn`` et al.
- `#7602 <https://github.com/scipy/scipy/pull/7602>`__: TST: fix test failures in trimmed statistics tests with numpy...
- `#7605 <https://github.com/scipy/scipy/pull/7605>`__: Be clear about required dimension order
- `#7606 <https://github.com/scipy/scipy/pull/7606>`__: MAINT: Remove unused function ``NI_NormalizeType``.
- `#7607 <https://github.com/scipy/scipy/pull/7607>`__: TST: add osx to travis matrix
- `#7608 <https://github.com/scipy/scipy/pull/7608>`__: DOC: improve HACKING guide - mention reviewing PRs as contribution.
- `#7609 <https://github.com/scipy/scipy/pull/7609>`__: MAINT: Remove unnecessary warning filter by avoiding unnecessary...
- `#7610 <https://github.com/scipy/scipy/pull/7610>`__: #7557 : fix example code in periodogram
- `#7611 <https://github.com/scipy/scipy/pull/7611>`__: #7220 : fix TypeError while raising ValueError for invalid shape
- `#7612 <https://github.com/scipy/scipy/pull/7612>`__: Convert yield tests to pytest parametrized tests
- `#7613 <https://github.com/scipy/scipy/pull/7613>`__: Add distributor init file
- `#7614 <https://github.com/scipy/scipy/pull/7614>`__: fixup header
- `#7615 <https://github.com/scipy/scipy/pull/7615>`__: BUG: sparse: Fix assignment w/ non-canonical sparse argument
- `#7617 <https://github.com/scipy/scipy/pull/7617>`__: DOC: Clarify digital filter functions
- `#7619 <https://github.com/scipy/scipy/pull/7619>`__: ENH: scipy.sparse.spmatrix.astype: casting and copy parameter...
- `#7621 <https://github.com/scipy/scipy/pull/7621>`__: Expose VODE/ZVODE/LSODE IDID return code to user
- `#7622 <https://github.com/scipy/scipy/pull/7622>`__: MAINT: special: remove out-of-date comment for ``ellpk``
- `#7625 <https://github.com/scipy/scipy/pull/7625>`__: TST: Add a test for "ignore" warning filters
- `#7628 <https://github.com/scipy/scipy/pull/7628>`__: MAINT: refactoring and cleaning distance.py/.c/.h
- `#7629 <https://github.com/scipy/scipy/pull/7629>`__: DEP: deprecate args usage in xdist
- `#7630 <https://github.com/scipy/scipy/pull/7630>`__: ENH: weighted metrics
- `#7634 <https://github.com/scipy/scipy/pull/7634>`__: Follow-up to #6855
- `#7635 <https://github.com/scipy/scipy/pull/7635>`__: interpolate.splprep: Test some error cases, give slightly better...
- `#7642 <https://github.com/scipy/scipy/pull/7642>`__: Add an example to ``interpolate.lagrange``
- `#7643 <https://github.com/scipy/scipy/pull/7643>`__: ENH: Added wrappers for LAPACK <s,d>stev
- `#7649 <https://github.com/scipy/scipy/pull/7649>`__: Fix #7636, add PEP 519 test coverage to remaining I/O functions
- `#7650 <https://github.com/scipy/scipy/pull/7650>`__: DOC: signal: Add 'Examples' to the docstring for sosfiltfilt.
- `#7651 <https://github.com/scipy/scipy/pull/7651>`__: Fix up ccache usage on Travis + try enabling on OSX
- `#7653 <https://github.com/scipy/scipy/pull/7653>`__: DOC: transition of examples from 2 to 3. Closes #7366
- `#7659 <https://github.com/scipy/scipy/pull/7659>`__: BENCH: fix optimize.BenchGlobal. Closes gh-7658.
- `#7662 <https://github.com/scipy/scipy/pull/7662>`__: CI: speed up continuous integration builds
- `#7664 <https://github.com/scipy/scipy/pull/7664>`__: Update odr documentation
- `#7665 <https://github.com/scipy/scipy/pull/7665>`__: BUG: wolfe2 line/scalar search now uses amax parameter
- `#7671 <https://github.com/scipy/scipy/pull/7671>`__: MAINT: ``_lib/ccallback.h``: PyCapsule_GetName returns const ``char*``
- `#7672 <https://github.com/scipy/scipy/pull/7672>`__: TST: interpolate: test integrating periodic b-splines against...
- `#7674 <https://github.com/scipy/scipy/pull/7674>`__: Tests tuning
- `#7675 <https://github.com/scipy/scipy/pull/7675>`__: CI: move refguide-check to faster build
- `#7676 <https://github.com/scipy/scipy/pull/7676>`__: DOC: bump scipy-sphinx-theme to fix copybutton.js
- `#7678 <https://github.com/scipy/scipy/pull/7678>`__: Note the zero-padding of the results of ``splrep`` and ``splprep``
- `#7681 <https://github.com/scipy/scipy/pull/7681>`__: MAINT: ``_lib``: add user-overridable available memory determination
- `#7684 <https://github.com/scipy/scipy/pull/7684>`__: TST: linalg: explicitly close opened npz files
- `#7686 <https://github.com/scipy/scipy/pull/7686>`__: MAINT: remove unnecessary shebang lines and executable bits
- `#7687 <https://github.com/scipy/scipy/pull/7687>`__: BUG: stats: don't emit invalid warnings if moments are infinite
- `#7690 <https://github.com/scipy/scipy/pull/7690>`__: ENH: allow int-like parameters in several routines
- `#7691 <https://github.com/scipy/scipy/pull/7691>`__: DOC: Drop non-working source links from docs
- `#7694 <https://github.com/scipy/scipy/pull/7694>`__: fix ``ma.rray`` to ``ma.array`` in func ``median_cihs``
- `#7698 <https://github.com/scipy/scipy/pull/7698>`__: BUG: stats: fix nan result from ``multivariate_normal.cdf`` (#7669)
- `#7703 <https://github.com/scipy/scipy/pull/7703>`__: DOC: special: Update the docstrings for noncentral F functions.
- `#7709 <https://github.com/scipy/scipy/pull/7709>`__: BLD: integrate: avoid symbol clash between lsoda and vode
- `#7711 <https://github.com/scipy/scipy/pull/7711>`__: TST: ``_lib``: make ``test_parallel_threads`` to not fail falsely
- `#7712 <https://github.com/scipy/scipy/pull/7712>`__: TST: stats: bump test tolerance in ``TestMultivariateNormal.test_broadcasting``
- `#7715 <https://github.com/scipy/scipy/pull/7715>`__: MAINT: fix deprecated use of numpy.issubdtype
- `#7716 <https://github.com/scipy/scipy/pull/7716>`__: TST: integrate: drop timing tests
- `#7717 <https://github.com/scipy/scipy/pull/7717>`__: MAINT: mstats.winsorize inclusion bug fix
- `#7719 <https://github.com/scipy/scipy/pull/7719>`__: DOC: stats: Add a note about the special cases of the rdist distribution.
- `#7720 <https://github.com/scipy/scipy/pull/7720>`__: DOC: Add example and math to stats.pearsonr
- `#7723 <https://github.com/scipy/scipy/pull/7723>`__: DOC: Added Mann-Whitney U statistic reference
- `#7727 <https://github.com/scipy/scipy/pull/7727>`__: BUG: special/cdflib: deal with nan and nonfinite inputs
- `#7728 <https://github.com/scipy/scipy/pull/7728>`__: BLD: spatial: fix ckdtree depends header list
- `#7732 <https://github.com/scipy/scipy/pull/7732>`__: BLD: update Bento build for optimal_leaf_ordering addition
- `#7734 <https://github.com/scipy/scipy/pull/7734>`__: DOC: signal: Copy-edit and add examples to the Kaiser-related...
- `#7736 <https://github.com/scipy/scipy/pull/7736>`__: BUG: Fixes #7735: Prevent integer overflow in concatenated index...
- `#7737 <https://github.com/scipy/scipy/pull/7737>`__: DOC: rename indices/indptr for ``spatial.Delaunay vertex_neighbor_vertices``
- `#7738 <https://github.com/scipy/scipy/pull/7738>`__: ENH: Speed up freqz computation
- `#7739 <https://github.com/scipy/scipy/pull/7739>`__: TST: ignore ncfdtridfn failure in win32 and warn on FPU mode changes
- `#7740 <https://github.com/scipy/scipy/pull/7740>`__: Fix overflow in Anderson-Darling k-sample test
- `#7742 <https://github.com/scipy/scipy/pull/7742>`__: TST: special: limit expm1 mpmath comparison range
- `#7748 <https://github.com/scipy/scipy/pull/7748>`__: TST: stats: don't pass invalid alpha to np.random.dirichlet
- `#7749 <https://github.com/scipy/scipy/pull/7749>`__: BUG/DOC: optimize: method is 'interior-point', not 'interior...
- `#7751 <https://github.com/scipy/scipy/pull/7751>`__: BUG: optimize: ``show_options('linprog', method='interior-point')``...
- `#7753 <https://github.com/scipy/scipy/pull/7753>`__: ENH: io: easier syntax for FortranFile read/write of mixed records
- `#7754 <https://github.com/scipy/scipy/pull/7754>`__: BLD: add ``_lib._fpumode`` extension to Bento build.
- `#7756 <https://github.com/scipy/scipy/pull/7756>`__: DOC: Show probability density functions as math
- `#7757 <https://github.com/scipy/scipy/pull/7757>`__: MAINT: remove outdated OS X build scripts. Fixes pytest failure.
- `#7758 <https://github.com/scipy/scipy/pull/7758>`__: MAINT: stats: pep8, wrap lines
- `#7760 <https://github.com/scipy/scipy/pull/7760>`__: DOC: special: add instructions on how to add special functions
- `#7761 <https://github.com/scipy/scipy/pull/7761>`__: DOC: allow specifying Python version for Sphinx makefile
- `#7765 <https://github.com/scipy/scipy/pull/7765>`__: TST: fix test coverage of ``mstats_extras.py``
- `#7767 <https://github.com/scipy/scipy/pull/7767>`__: DOC: update 1.0 release notes.
- `#7768 <https://github.com/scipy/scipy/pull/7768>`__: DOC: update notes on how to release. Also change paver file to...
- `#7769 <https://github.com/scipy/scipy/pull/7769>`__: Add the ``_sf`` and ``_logsf`` function for planck dist
- `#7770 <https://github.com/scipy/scipy/pull/7770>`__: DOC: Replace rotten links in the docstring of minres
- `#7771 <https://github.com/scipy/scipy/pull/7771>`__: MAINT: f2py build output cleanup
- `#7773 <https://github.com/scipy/scipy/pull/7773>`__: DOC: optimize: Some copy-editing of linprog docs.
- `#7774 <https://github.com/scipy/scipy/pull/7774>`__: MAINT: set rcond explicitly for np.linalg.lstsq calls
- `#7777 <https://github.com/scipy/scipy/pull/7777>`__: remove leftover ``nose`` imports
- `#7780 <https://github.com/scipy/scipy/pull/7780>`__: ENH: Wrap LAPACK's dsytrd
- `#7781 <https://github.com/scipy/scipy/pull/7781>`__: DOC: Link rfft
- `#7782 <https://github.com/scipy/scipy/pull/7782>`__: MAINT: run pyx autogeneration in cythonize & remove autogen files
- `#7783 <https://github.com/scipy/scipy/pull/7783>`__: FIX: Disallow Wn==1 in digital filters
- `#7790 <https://github.com/scipy/scipy/pull/7790>`__: Fix test errors introduced by gh-5910
- `#7792 <https://github.com/scipy/scipy/pull/7792>`__: MAINT: fix syntax in pyproject.toml
- `#7809 <https://github.com/scipy/scipy/pull/7809>`__: ENH: sketches - Clarkson Woodruff Transform
- `#7810 <https://github.com/scipy/scipy/pull/7810>`__: ENH: Add ``eig(vals)_tridiagonal``
- `#7811 <https://github.com/scipy/scipy/pull/7811>`__: BUG: stats: Fix warnings in ``binned_statistics_dd``
- `#7814 <https://github.com/scipy/scipy/pull/7814>`__: ENH: signal: Replace 'nyq' and 'Hz' arguments with 'fs'.
- `#7820 <https://github.com/scipy/scipy/pull/7820>`__: DOC: update 1.0 release notes and mailmap
- `#7823 <https://github.com/scipy/scipy/pull/7823>`__: BUG: memory leak in messagestream / qhull.pyx
- `#7830 <https://github.com/scipy/scipy/pull/7830>`__: DOC: linalg: Add an example to the lstsq docstring.
- `#7835 <https://github.com/scipy/scipy/pull/7835>`__: ENH: Automatic FIR order for ``decimate``
- `#7838 <https://github.com/scipy/scipy/pull/7838>`__: MAINT: stats: Deprecate ``frechet_l`` and ``frechet_r``.
- `#7841 <https://github.com/scipy/scipy/pull/7841>`__: slsqp PEP8 formatting fixes, typos, etc.
- `#7843 <https://github.com/scipy/scipy/pull/7843>`__: ENH: Wrap all BLAS routines
- `#7844 <https://github.com/scipy/scipy/pull/7844>`__: DOC: update LICENSE.txt with licenses of bundled libs as needed.
- `#7851 <https://github.com/scipy/scipy/pull/7851>`__: ENH: Add wrappers for ?GGLSE, ?(HE/SY)CON, ?SYTF2, ?(HE/SY)TRF
- `#7856 <https://github.com/scipy/scipy/pull/7856>`__: ENH: added out argument to Xdist
- `#7858 <https://github.com/scipy/scipy/pull/7858>`__: BUG: special/cdflib: fix fatal loss of precision issues in cumfnc
- `#7859 <https://github.com/scipy/scipy/pull/7859>`__: FIX: Squash ``place_poles`` warning corner case
- `#7861 <https://github.com/scipy/scipy/pull/7861>`__: dummy statement for undefined ``WITH_THREAD``
- `#7863 <https://github.com/scipy/scipy/pull/7863>`__: MAINT: add license texts to binary distributions
- `#7866 <https://github.com/scipy/scipy/pull/7866>`__: DOC, MAINT: fix links in the doc
- `#7867 <https://github.com/scipy/scipy/pull/7867>`__: DOC: fix up descriptions of pdf's in distribution docstrings.
- `#7869 <https://github.com/scipy/scipy/pull/7869>`__: DEP: deprecate misc.pilutil functions
- `#7870 <https://github.com/scipy/scipy/pull/7870>`__: DEP: remove deprecated functions
- `#7872 <https://github.com/scipy/scipy/pull/7872>`__: TST: silence RuntimeWarning for stats.truncnorm test marked as...
- `#7874 <https://github.com/scipy/scipy/pull/7874>`__: TST: fix an optimize.linprog test that fails intermittently.
- `#7875 <https://github.com/scipy/scipy/pull/7875>`__: TST: filter two integration warnings in stats tests.
- `#7876 <https://github.com/scipy/scipy/pull/7876>`__: GEN: Add comments to the tests for clarification
- `#7891 <https://github.com/scipy/scipy/pull/7891>`__: ENH: backport #7879 to 1.0.x
- `#7902 <https://github.com/scipy/scipy/pull/7902>`__: MAINT: signal: Make freqz handling of multidim. arrays match...
- `#7905 <https://github.com/scipy/scipy/pull/7905>`__: REV: restore wminkowski
- `#7908 <https://github.com/scipy/scipy/pull/7908>`__: FIX: Avoid bad ``__del__`` (close) behavior
- `#7918 <https://github.com/scipy/scipy/pull/7918>`__: TST: mark two optimize.linprog tests as xfail. See gh-7877.
- `#7929 <https://github.com/scipy/scipy/pull/7929>`__: MAINT: changed defaults to lower in sytf2, sytrf and hetrf
- `#7939 <https://github.com/scipy/scipy/pull/7939>`__: Fix umfpack solver construction for win-amd64
- `#7948 <https://github.com/scipy/scipy/pull/7948>`__: DOC: add note on checking for deprecations before upgrade to...
- `#7952 <https://github.com/scipy/scipy/pull/7952>`__: DOC: update SciPy Roadmap for 1.0 release and recent discussions.
- `#7960 <https://github.com/scipy/scipy/pull/7960>`__: BUG: optimize: revert changes to bfgs in gh-7165
- `#7962 <https://github.com/scipy/scipy/pull/7962>`__: TST: special: mark a failing hyp2f1 test as xfail
- `#7973 <https://github.com/scipy/scipy/pull/7973>`__: BUG: fixed keyword in 'info' in ``_get_mem_available`` utility
- `#8001 <https://github.com/scipy/scipy/pull/8001>`__: TST: fix test failures from Matplotlib 2.1 update
- `#8010 <https://github.com/scipy/scipy/pull/8010>`__: BUG: signal: fix crash in lfilter
- `#8019 <https://github.com/scipy/scipy/pull/8019>`__: MAINT: fix test failures with NumPy master

==========================
SciPy 1.4.0 Release Notes
==========================

.. contents::

SciPy 1.4.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been a number of deprecations and API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning`` s).
Our development attention will now shift to bug-fix releases on the
1.4.x branch, and on adding new features on the master branch.

This release requires Python 3.5+ and NumPy >=1.13.3 (for Python 3.5, 3.6),
>=1.14.5 (for Python 3.7), >= 1.17.3 (for Python 3.8)

For running on PyPy, PyPy3 6.0+ and NumPy 1.15.0 are required.

Highlights of this release
--------------------------

- a new submodule, `scipy.fft`, now supersedes `scipy.fftpack`; this
  means support for ``long double`` transforms, faster multi-dimensional
  transforms, improved algorithm time complexity, release of the global
  intepreter lock, and control over threading behavior
- support for ``pydata/sparse`` arrays in `scipy.sparse.linalg`
- substantial improvement to the documentation and functionality of
  several `scipy.special` functions, and some new additions
- the generalized inverse Gaussian distribution has been added to
  `scipy.stats`
- an implementation of the Edmonds-Karp algorithm in
  `scipy.sparse.csgraph.maximum_flow`
- `scipy.spatial.SphericalVoronoi` now supports n-dimensional input, 
   has linear memory complexity, improved performance, and
   supports single-hemisphere generators


New features
============

Infrastructure
--------------
Documentation can now be built with ``runtests.py --doc``

A ``Dockerfile`` is now available in the ``scipy/scipy-dev`` repository to
facilitate getting started with SciPy development.

`scipy.constants` improvements
------------------------------
`scipy.constants` has been updated with the CODATA 2018 constants.


`scipy.fft` added
-----------------
`scipy.fft` is a new submodule that supersedes the `scipy.fftpack` submodule. 
For the most part, this is a drop-in replacement for ``numpy.fft`` and 
`scipy.fftpack` alike. With some important differences, `scipy.fft`:
- uses NumPy's conventions for real transforms (``rfft``). This means the 
return value is a complex array, half the size of the full ``fft`` output.
This is different from the output of ``fftpack`` which returned a real array 
representing complex components packed together.
- the inverse real to real transforms (``idct`` and ``idst``) are normalized 
for ``norm=None`` in thesame way as ``ifft``. This means the identity 
``idct(dct(x)) == x`` is now ``True`` for all norm modes.
- does not include the convolutions or pseudo-differential operators
from ``fftpack``.

This submodule is based on the ``pypocketfft`` library, developed by the 
author of ``pocketfft`` which was recently adopted by NumPy as well.
``pypocketfft`` offers a number of advantages over fortran ``FFTPACK``:
- support for long double (``np.longfloat``) precision transforms.
- faster multi-dimensional transforms using vectorisation
- Bluestein’s algorithm removes the worst-case ``O(n^2)`` complexity of
``FFTPACK``
- the global interpreter lock (``GIL``) is released during transforms
- optional multithreading of multi-dimensional transforms via the ``workers``
argument

Note that `scipy.fftpack` has not been deprecated and will continue to be 
maintained but is now considered legacy. New code is recommended to use 
`scipy.fft` instead, where possible.

`scipy.fftpack` improvements
------------------------------
`scipy.fftpack` now uses pypocketfft to perform its FFTs, offering the same
speed and accuracy benefits listed for scipy.fft above but without the
improved API.

`scipy.integrate` improvements
------------------------------

The function `scipy.integrate.solve_ivp` now has an ``args`` argument.
This allows the user-defined functions passed to the function to have
additional parameters without having to create wrapper functions or
lambda expressions for them.

`scipy.integrate.solve_ivp` can now return a ``y_events`` attribute 
representing the solution of the ODE at event times

New ``OdeSolver`` is implemented --- ``DOP853``. This is a high-order explicit
Runge-Kutta method originally implemented in Fortran. Now we provide a pure 
Python implementation usable through ``solve_ivp`` with all its features.

`scipy.integrate.quad` provides better user feedback when break points are 
specified with a weighted integrand.

`scipy.integrate.quad_vec` is now available for general purpose integration
of vector-valued functions


`scipy.interpolate` improvements
--------------------------------
`scipy.interpolate.pade` now handles complex input data gracefully

`scipy.interpolate.Rbf` can now interpolate multi-dimensional functions

`scipy.io` improvements
-----------------------

`scipy.io.wavfile.read` can now read data from a `WAV` file that has a
malformed header, similar to other modern `WAV` file parsers

`scipy.io.FortranFile` now has an expanded set of available ``Exception``
classes for handling poorly-formatted files


`scipy.linalg` improvements
---------------------------
The function ``scipy.linalg.subspace_angles(A, B)`` now gives correct
results for complex-valued matrices. Before this, the function only returned
correct values for real-valued matrices.

New boolean keyword argument ``check_finite`` for `scipy.linalg.norm`; whether 
to check that the input matrix contains only finite numbers. Disabling may 
give a performance gain, but may result in problems (crashes, non-termination)
if the inputs do contain infinities or NaNs.

`scipy.linalg.solve_triangular` has improved performance for a C-ordered
triangular matrix

``LAPACK`` wrappers have been added for ``?geequ``, ``?geequb``, ``?syequb``,
and ``?heequb``

Some performance improvements may be observed due to an internal optimization
in operations involving LAPACK routines via ``_compute_lwork``. This is
particularly true for operations on small arrays.

Block ``QR`` wrappers are now available in `scipy.linalg.lapack`


`scipy.ndimage` improvements
----------------------------


`scipy.optimize` improvements
-----------------------------
It is now possible to use linear and non-linear constraints with 
`scipy.optimize.differential_evolution`.

`scipy.optimize.linear_sum_assignment` has been re-written in C++ to improve 
performance, and now allows input costs to be infinite.

A ``ScalarFunction.fun_and_grad`` method was added for convenient simultaneous
retrieval of a function and gradient evaluation

`scipy.optimize.minimize` ``BFGS`` method has improved performance by avoiding
duplicate evaluations in some cases

Better user feedback is provided when an objective function returns an array
instead of a scalar.


`scipy.signal` improvements
---------------------------

Added a new function to calculate convolution using the overlap-add method,
named `scipy.signal.oaconvolve`. Like `scipy.signal.fftconvolve`, this
function supports specifying dimensions along which to do the convolution.

`scipy.signal.cwt` now supports complex wavelets.

The implementation of ``choose_conv_method`` has been updated to reflect the 
new FFT implementation. In addition, the performance has been significantly 
improved (with rather drastic improvements in edge cases).

The function ``upfirdn`` now has a ``mode`` keyword argument that can be used
to select the signal extension mode used at the signal boundaries. These modes
are also available for use in ``resample_poly`` via a newly added ``padtype``
argument.

`scipy.signal.sosfilt` now benefits from Cython code for improved performance

`scipy.signal.resample` should be more efficient by leveraging ``rfft`` when
possible

`scipy.sparse` improvements
---------------------------
It is now possible to use the LOBPCG method in `scipy.sparse.linalg.svds`.

`scipy.sparse.linalg.LinearOperator` now supports the operation ``rmatmat`` 
for adjoint matrix-matrix multiplication, in addition to ``rmatvec``.

Multiple stability updates enable float32 support in the LOBPCG eigenvalue 
solver for symmetric and Hermitian eigenvalues problems in 
``scipy.sparse.linalg.lobpcg``.

A solver for the maximum flow problem has been added as
`scipy.sparse.csgraph.maximum_flow`.

`scipy.sparse.csgraph.maximum_bipartite_matching` now allows non-square inputs,
no longer requires a perfect matching to exist, and has improved performance.

`scipy.sparse.lil_matrix` conversions now perform better in some scenarios

Basic support is available for ``pydata/sparse`` arrays in
`scipy.sparse.linalg`

`scipy.sparse.linalg.spsolve_triangular` now supports the ``unit_diagonal``
argument to improve call signature similarity with its dense counterpart,
`scipy.linalg.solve_triangular`

``assertAlmostEqual`` may now be used with sparse matrices, which have added
support for ``__round__``

`scipy.spatial` improvements
----------------------------
The bundled Qhull library was upgraded to version 2019.1, fixing several
issues. Scipy-specific patches are no longer applied to it.

`scipy.spatial.SphericalVoronoi` now has linear memory complexity, improved
performance, and supports single-hemisphere generators. Support has also been
added for handling generators that lie on a great circle arc (geodesic input)
and for generators in n-dimensions.

`scipy.spatial.transform.Rotation` now includes functions for calculation of a
mean rotation, generation of the 3D rotation groups, and reduction of rotations
with rotational symmetries.

`scipy.spatial.transform.Slerp` is now callable with a scalar argument

`scipy.spatial.voronoi_plot_2d` now supports furthest site Voronoi diagrams

`scipy.spatial.Delaunay` and `scipy.spatial.Voronoi` now have attributes
for tracking whether they are furthest site diagrams

`scipy.special` improvements
----------------------------
The Voigt profile has been added as `scipy.special.voigt_profile`.

A real dispatch has been added for the Wright Omega function
(`scipy.special.wrightomega`).

The analytic continuation of the Riemann zeta function has been added. (The 
Riemann zeta function is the one-argument variant of `scipy.special.zeta`.)

The complete elliptic integral of the first kind (`scipy.special.ellipk`) is 
now available in `scipy.special.cython_special`.

The accuracy of `scipy.special.hyp1f1` for real arguments has been improved.

The documentation of many functions has been improved.

`scipy.stats` improvements
--------------------------
`scipy.stats.multiscale_graphcorr` added as an independence test that
operates on high dimensional and nonlinear data sets. It has higher statistical
power than other `scipy.stats` tests while being the only one that operates on
multivariate data.

The generalized inverse Gaussian distribution (`scipy.stats.geninvgauss`) has 
been added.

It is now possible to efficiently reuse `scipy.stats.binned_statistic_dd` 
with new values by providing the result of a previous call to the function.

`scipy.stats.hmean` now handles input with zeros more gracefully.

The beta-binomial distribution is now available in `scipy.stats.betabinom`.

`scipy.stats.zscore`, `scipy.stats.circmean`, `scipy.stats.circstd`, and
`scipy.stats.circvar` now support the ``nan_policy`` argument for enhanced
handling of ``NaN`` values

`scipy.stats.entropy` now accepts an ``axis`` argument

`scipy.stats.gaussian_kde.resample` now accepts a ``seed`` argument to empower
reproducibility

`scipy.stats.kendalltau` performance has improved, especially for large inputs,
due to improved cache usage

`scipy.stats.truncnorm` distribution has been rewritten to support much wider
tails


Deprecated features
===================

`scipy` deprecations
--------------------
Support for NumPy functions exposed via the root SciPy namespace is deprecated
and will be removed in 2.0.0. For example, if you use ``scipy.rand`` or
``scipy.diag``, you should change your code to directly use
``numpy.random.default_rng`` or ``numpy.diag``, respectively.
They remain available in the currently continuing Scipy 1.x release series.

The exception to this rule is using ``scipy.fft`` as a function --
:mod:`scipy.fft` is now meant to be used only as a module, so the ability to
call ``scipy.fft(...)`` will be removed in SciPy 1.5.0.

In `scipy.spatial.Rotation` methods ``from_dcm``, ``as_dcm`` were renamed to 
``from_matrix``, ``as_matrix`` respectively. The old names will be removed in 
SciPy 1.6.0.

Method ``Rotation.match_vectors`` was deprecated in favor of 
``Rotation.align_vectors``, which provides a more logical and 
general API to the same functionality. The old method 
will be removed in SciPy 1.6.0.

Backwards incompatible changes
==============================

`scipy.special` changes
---------------------------
The deprecated functions ``hyp2f0``, ``hyp1f2``, and ``hyp3f0`` have been
removed.

The deprecated function ``bessel_diff_formula`` has been removed.

The function ``i0`` is no longer registered with ``numpy.dual``, so that 
``numpy.dual.i0`` will unconditionally refer to the NumPy version regardless 
of whether `scipy.special` is imported.

The function ``expn`` has been changed to return ``nan`` outside of its 
domain of definition (``x, n < 0``) instead of ``inf``.

`scipy.sparse` changes
---------------------------
Sparse matrix reshape now raises an error if shape is not two-dimensional, 
rather than guessing what was meant. The behavior is now the same as before 
SciPy 1.1.0.

``CSR`` and ``CSC`` sparse matrix classes should now return empty matrices
of the same type when indexed out of bounds. Previously, for some versions
of SciPy, this would raise an ``IndexError``. The change is largely motivated
by greater consistency with ``ndarray`` and ``numpy.matrix`` semantics.

`scipy.signal` changes
----------------------
`scipy.signal.resample` behavior for length-1 signal inputs has been
fixed to output a constant (DC) value rather than an impulse, consistent with
the assumption of signal periodicity in the FFT method.

`scipy.signal.cwt` now performs complex conjugation and time-reversal of
wavelet data, which is a backwards-incompatible bugfix for
time-asymmetric wavelets.

`scipy.stats` changes
---------------------
`scipy.stats.loguniform` added with better documentation as (an alias for
``scipy.stats.reciprocal``). ``loguniform`` generates random variables
that are equally likely in the log space; e.g., ``1``, ``10`` and ``100``
are all equally likely if ``loguniform(10 ** 0, 10 ** 2).rvs()`` is used.


Other changes
=============
The ``LSODA`` method of `scipy.integrate.solve_ivp` now correctly detects stiff
problems.

`scipy.spatial.cKDTree` now accepts and correctly handles empty input data

`scipy.stats.binned_statistic_dd` now calculates the standard deviation 
statistic in a numerically stable way.

`scipy.stats.binned_statistic_dd` now throws an error if the input data 
contains either ``np.nan`` or ``np.inf``. Similarly, in `scipy.stats` now all 
continuous distributions' ``.fit()`` methods throw an error if the input data
contain any instance of either ``np.nan`` or ``np.inf``.


Authors
=======

* @endolith
* @wenhui-prudencemed +
* Abhinav +
* Anne Archibald
* ashwinpathak20nov1996 +
* Danilo Augusto +
* Nelson Auner +
* aypiggott +
* Christoph Baumgarten
* Peter Bell
* Sebastian Berg
* Arman Bilge +
* Benedikt Boecking +
* Christoph Boeddeker +
* Daniel Bunting
* Evgeni Burovski
* Angeline Burrell +
* Angeline G. Burrell +
* CJ Carey
* Carlos Ramos Carreño +
* Mak Sze Chun +
* Malayaja Chutani +
* Christian Clauss +
* Jonathan Conroy +
* Stephen P Cook +
* Dylan Cutler +
* Anirudh Dagar +
* Aidan Dang +
* dankleeman +
* Brandon David +
* Tyler Dawson +
* Dieter Werthmüller
* Joe Driscoll +
* Jakub Dyczek +
* Dávid Bodnár
* Fletcher Easton +
* Stefan Endres
* etienne +
* Johann Faouzi
* Yu Feng
* Isuru Fernando +
* Matthew H Flamm
* Martin Gauch +
* Gabriel Gerlero +
* Ralf Gommers
* Chris Gorgolewski +
* Domen Gorjup +
* Edouard Goudenhoofdt +
* Jan Gwinner +
* Maja Gwozdz +
* Matt Haberland
* hadshirt +
* Pierre Haessig +
* David Hagen
* Charles Harris
* Gina Helfrich +
* Alex Henrie +
* Francisco J. Hernandez Heras +
* Andreas Hilboll
* Lindsey Hiltner
* Thomas Hisch
* Min ho Kim +
* Gert-Ludwig Ingold
* jakobjakobson13 +
* Todd Jennings
* He Jia
* Muhammad Firmansyah Kasim +
* Andrew Knyazev +
* Holger Kohr +
* Mateusz Konieczny +
* Krzysztof Pióro +
* Philipp Lang +
* Peter Mahler Larsen +
* Eric Larson
* Antony Lee
* Gregory R. Lee
* Chelsea Liu +
* Jesse Livezey
* Peter Lysakovski +
* Jason Manley +
* Michael Marien +
* Nikolay Mayorov
* G. D. McBain +
* Sam McCormack +
* Melissa Weber Mendonça +
* Kevin Michel +
* mikeWShef +
* Sturla Molden
* Eric Moore
* Peyton Murray +
* Andrew Nelson
* Clement Ng +
* Juan Nunez-Iglesias
* Renee Otten +
* Kellie Ottoboni +
* Ayappan P
* Sambit Panda +
* Tapasweni Pathak +
* Oleksandr Pavlyk
* Fabian Pedregosa
* Petar Mlinarić
* Matti Picus
* Marcel Plch +
* Christoph Pohl +
* Ilhan Polat
* Siddhesh Poyarekar +
* Ioannis Prapas +
* James Alan Preiss +
* Yisheng Qiu +
* Eric Quintero
* Bharat Raghunathan +
* Tyler Reddy
* Joscha Reimer
* Antonio Horta Ribeiro
* Lucas Roberts
* rtshort +
* Josua Sassen
* Kevin Sheppard
* Scott Sievert
* Leo Singer
* Kai Striega
* Søren Fuglede Jørgensen
* tborisow +
* Étienne Tremblay +
* tuxcell +
* Miguel de Val-Borro
* Andrew Valentine +
* Hugo van Kemenade
* Paul van Mulbregt
* Sebastiano Vigna
* Pauli Virtanen
* Dany Vohl +
* Ben Walsh +
* Huize Wang +
* Warren Weckesser
* Anreas Weh +
* Joseph Weston +
* Adrian Wijaya +
* Timothy Willard +
* Josh Wilson
* Kentaro Yamamoto +
* Dave Zbarsky +

A total of 142 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 1.4.0
-----------------------

* `#1255 <https://github.com/scipy/scipy/issues/1255>`__: maxiter broken for Scipy.sparse.linalg gmres, in addition to...
* `#1301 <https://github.com/scipy/scipy/issues/1301>`__: consolidate multipack.h from interpolate and integrate packages...
* `#1739 <https://github.com/scipy/scipy/issues/1739>`__: Single precision FFT insufficiently accurate. (Trac #1212)
* `#1795 <https://github.com/scipy/scipy/issues/1795>`__: stats test_distributions.py: replace old fuzz tests (Trac #1269)
* `#2233 <https://github.com/scipy/scipy/issues/2233>`__: fftpack segfault with big arrays (Trac #1714)
* `#2434 <https://github.com/scipy/scipy/issues/2434>`__: rmatmat and the sophistication of linear operator objects
* `#2477 <https://github.com/scipy/scipy/issues/2477>`__: stats.truncnorm.rvs() does not give symmetric results for negative...
* `#2629 <https://github.com/scipy/scipy/issues/2629>`__: FFTpack is unacceptably slow on non power of 2
* `#2883 <https://github.com/scipy/scipy/issues/2883>`__: UnboundLocalError in scipy.interpolate.splrep
* `#2956 <https://github.com/scipy/scipy/issues/2956>`__: Feature Request: axis argument for stats.entropy function
* `#3528 <https://github.com/scipy/scipy/issues/3528>`__: Segfault on test_djbfft (possibly MKL-related?)
* `#3793 <https://github.com/scipy/scipy/issues/3793>`__: cwt should also return complex array
* `#4464 <https://github.com/scipy/scipy/issues/4464>`__: TST: residue/residuez/invres/invresz don't have any tests
* `#4561 <https://github.com/scipy/scipy/issues/4561>`__: BUG: tf filter trailing and leading zeros in residuez
* `#4669 <https://github.com/scipy/scipy/issues/4669>`__: Rewrite sosfilt to make a single loop over the input?
* `#5040 <https://github.com/scipy/scipy/issues/5040>`__: BUG: Empty data handling of (c)KDTrees
* `#5112 <https://github.com/scipy/scipy/issues/5112>`__: boxcox transform edge cases could use more care
* `#5441 <https://github.com/scipy/scipy/issues/5441>`__: scipy.stats.ncx2 fails for nc=0
* `#5502 <https://github.com/scipy/scipy/issues/5502>`__: args keyword not handled in optimize.curve_fit
* `#6484 <https://github.com/scipy/scipy/issues/6484>`__: Qhull segmentation fault
* `#6900 <https://github.com/scipy/scipy/issues/6900>`__: linear_sum_assignment with infinite weights
* `#6966 <https://github.com/scipy/scipy/issues/6966>`__: Hypergeometric Functions documentation is lacking
* `#6999 <https://github.com/scipy/scipy/issues/6999>`__: possible false positive corruption check in compressed loadmat()
* `#7018 <https://github.com/scipy/scipy/issues/7018>`__: ydata that needs broadcasting renders curve_fit unable to compute...
* `#7140 <https://github.com/scipy/scipy/issues/7140>`__: trouble with documentation for windows
* `#7327 <https://github.com/scipy/scipy/issues/7327>`__: interpolate.ndgriddata.griddata causes Python to crash rather...
* `#7396 <https://github.com/scipy/scipy/issues/7396>`__: MatrixLinearOperator implements _adjoint(), but not _transpose()
* `#7400 <https://github.com/scipy/scipy/issues/7400>`__: BUG(?): special: factorial and factorial2 return a 0-dimensional...
* `#7434 <https://github.com/scipy/scipy/issues/7434>`__: Testing of scipy.stats continuous distributions misses 25 distributions
* `#7491 <https://github.com/scipy/scipy/issues/7491>`__: Several scipy.stats distributions (fisk, burr, burr12, f) return...
* `#7759 <https://github.com/scipy/scipy/issues/7759>`__: Overflow in stats.kruskal for large samples
* `#7906 <https://github.com/scipy/scipy/issues/7906>`__: Wrong result from scipy.interpolate.UnivariateSpline.integral...
* `#8165 <https://github.com/scipy/scipy/issues/8165>`__: ENH: match functionality of R for hmean
* `#8417 <https://github.com/scipy/scipy/issues/8417>`__: optimimze.minimize(method='L-BFGS-B', options={'disp': True})...
* `#8535 <https://github.com/scipy/scipy/issues/8535>`__: Strictly increasing requirement in UnivariateSpline
* `#8815 <https://github.com/scipy/scipy/issues/8815>`__: [BUG] GMRES: number of iteration is only increased if callback...
* `#9207 <https://github.com/scipy/scipy/issues/9207>`__: scipy.linalg.solve_triangular speed after scipy.linalg.lu_factor
* `#9275 <https://github.com/scipy/scipy/issues/9275>`__: new feature: adding LOBPCG solver in svds in addition to ARPACK
* `#9403 <https://github.com/scipy/scipy/issues/9403>`__: range of truncnorm.logpdf could be extended
* `#9429 <https://github.com/scipy/scipy/issues/9429>`__: gaussian_kde not working with numpy matrix
* `#9515 <https://github.com/scipy/scipy/issues/9515>`__: ndimage implementation relies on undefined behavior
* `#9643 <https://github.com/scipy/scipy/issues/9643>`__: arpack returns singular values in ascending order
* `#9669 <https://github.com/scipy/scipy/issues/9669>`__: DOC: matthew-brett/build-openblas has been retired
* `#9852 <https://github.com/scipy/scipy/issues/9852>`__: scipy.spatial.ConvexHull exit with code 134, free(): invalid...
* `#9902 <https://github.com/scipy/scipy/issues/9902>`__: scipy.stats.truncnorm second moment may be wrong
* `#9943 <https://github.com/scipy/scipy/issues/9943>`__: Custom sampling methods in shgo do not work
* `#9947 <https://github.com/scipy/scipy/issues/9947>`__: DOC: Incorrect documentation for \`nan_policy='propagate\` in...
* `#9994 <https://github.com/scipy/scipy/issues/9994>`__: BUG: sparse: reshape method allows a shape containing an arbitrary...
* `#10036 <https://github.com/scipy/scipy/issues/10036>`__: Official Nelder mead tutorial uses xtol instead of xatol, which...
* `#10078 <https://github.com/scipy/scipy/issues/10078>`__: possible to get a better error message when objective function...
* `#10092 <https://github.com/scipy/scipy/issues/10092>`__: overflow in truncnorm.rvs
* `#10121 <https://github.com/scipy/scipy/issues/10121>`__: A little spelling mistake
* `#10126 <https://github.com/scipy/scipy/issues/10126>`__: inaccurate std implementation in binned_statistic
* `#10161 <https://github.com/scipy/scipy/issues/10161>`__: Error in documentation scipy.special.modstruve
* `#10195 <https://github.com/scipy/scipy/issues/10195>`__: Derivative of spline with 'const' extrapolation is also extrapolted...
* `#10206 <https://github.com/scipy/scipy/issues/10206>`__: sparse matrices indexing with scipy 1.3
* `#10236 <https://github.com/scipy/scipy/issues/10236>`__: Non-descriptive error on type mismatch for functions of scipy.optimize...
* `#10258 <https://github.com/scipy/scipy/issues/10258>`__: LOBPCG convergence failure if guess provided
* `#10262 <https://github.com/scipy/scipy/issues/10262>`__: distance matrix lacks dtype checks / warnings
* `#10271 <https://github.com/scipy/scipy/issues/10271>`__: BUG: optimize failure on wheels
* `#10277 <https://github.com/scipy/scipy/issues/10277>`__: scipy.special.zeta(0) = NAN
* `#10292 <https://github.com/scipy/scipy/issues/10292>`__: DOC/REL: Some sections of the release notes are not nested correctly.
* `#10300 <https://github.com/scipy/scipy/issues/10300>`__: scipy.stats.rv_continuous.fit throws empty RuntimeError when...
* `#10319 <https://github.com/scipy/scipy/issues/10319>`__: events in scipy.integrate.solve_ivp: How do I setup an events...
* `#10323 <https://github.com/scipy/scipy/issues/10323>`__: Adding more low-level LAPACK wrappers
* `#10360 <https://github.com/scipy/scipy/issues/10360>`__: firwin2 inadvertently modifies input and may result in undefined...
* `#10388 <https://github.com/scipy/scipy/issues/10388>`__: BLD: TestHerd::test_hetrd core dumps with Python-dbg
* `#10395 <https://github.com/scipy/scipy/issues/10395>`__: Remove warning about output shape of zoom
* `#10403 <https://github.com/scipy/scipy/issues/10403>`__: DOC: scipy.signal.resample ignores t parameter
* `#10421 <https://github.com/scipy/scipy/issues/10421>`__: Yeo-Johnson power transformation fails with integer input data
* `#10422 <https://github.com/scipy/scipy/issues/10422>`__: BUG: scipy.fft does not support multiprocessing
* `#10427 <https://github.com/scipy/scipy/issues/10427>`__: ENH: convolve numbers should be updated
* `#10444 <https://github.com/scipy/scipy/issues/10444>`__: BUG: scipy.spatial.transform.Rotation.match_vectors returns improper...
* `#10488 <https://github.com/scipy/scipy/issues/10488>`__: ENH: DCTs/DSTs for scipy.fft
* `#10501 <https://github.com/scipy/scipy/issues/10501>`__: BUG: scipy.spatial.HalfspaceIntersection works incorrectly
* `#10514 <https://github.com/scipy/scipy/issues/10514>`__: BUG: cKDTree GIL handling is incorrect
* `#10535 <https://github.com/scipy/scipy/issues/10535>`__: TST: master branch CI failures
* `#10588 <https://github.com/scipy/scipy/issues/10588>`__: scipy.fft and numpy.fft inconsistency when axes=None and shape...
* `#10628 <https://github.com/scipy/scipy/issues/10628>`__: Scipy python>3.6 Windows wheels don't ship msvcp\*.dll
* `#10733 <https://github.com/scipy/scipy/issues/10733>`__: DOC/BUG: min_only result does not match documentation
* `#10774 <https://github.com/scipy/scipy/issues/10774>`__: min_only=true djisktra infinite loop with duplicate indices
* `#10775 <https://github.com/scipy/scipy/issues/10775>`__: UnboundLocalError in Radau when given a NaN
* `#10835 <https://github.com/scipy/scipy/issues/10835>`__: io.wavfile.read unnecessarily raises an error for a bad wav header
* `#10838 <https://github.com/scipy/scipy/issues/10838>`__: Error in documentation for scipy.linalg.lu_factor
* `#10875 <https://github.com/scipy/scipy/issues/10875>`__: DOC: Graphical guides (using TikZ)
* `#10880 <https://github.com/scipy/scipy/issues/10880>`__: setting verbose > 2 in minimize with trust-constr method leads...
* `#10887 <https://github.com/scipy/scipy/issues/10887>`__: scipy.signal.signaltools._fftconv_faster has incorrect estimates
* `#10948 <https://github.com/scipy/scipy/issues/10948>`__: gammainc(0,x) = nan but should be 1, gammaincc(0,x) = nan but...
* `#10952 <https://github.com/scipy/scipy/issues/10952>`__: TestQRdelete_F.test_delete_last_p_col test failure
* `#10968 <https://github.com/scipy/scipy/issues/10968>`__: API: Change normalized=False to normalize=True in Rotation
* `#10987 <https://github.com/scipy/scipy/issues/10987>`__: Memory leak in shgo triangulation
* `#10991 <https://github.com/scipy/scipy/issues/10991>`__: Error running openBlas probably missing a step
* `#11033 <https://github.com/scipy/scipy/issues/11033>`__: deadlock on osx for python 3.8
* `#11041 <https://github.com/scipy/scipy/issues/11041>`__: Test failure in wheel builds for TestTf2zpk.test_simple
* `#11089 <https://github.com/scipy/scipy/issues/11089>`__: Regression in scipy.stats where distribution will not accept loc and scale parameters
* `#11100 <https://github.com/scipy/scipy/issues/11100>`__: BUG: multiscale_graphcorr random state seeding and parallel use
* `#11121 <https://github.com/scipy/scipy/issues/11121>`__: Calls to `scipy.interpolate.splprep` increase RAM usage.
* `#11125 <https://github.com/scipy/scipy/issues/11125>`__: BUG: segfault when slicing a CSR or CSC sparse matrix with slice start index > stop index
* `#11198 <https://github.com/scipy/scipy/issues/11198>`__: BUG: sparse eigs (arpack) shift-invert drops the smallest eigenvalue for some k

Pull requests for 1.4.0
-----------------------

* `#4591 <https://github.com/scipy/scipy/pull/4591>`__: BUG, TST: Several issues with scipy.signal.residue
* `#6629 <https://github.com/scipy/scipy/pull/6629>`__: ENH: sparse: canonicalize on initialization
* `#7076 <https://github.com/scipy/scipy/pull/7076>`__: ENH: add complex wavelet support to scipy.signal.cwt.
* `#8681 <https://github.com/scipy/scipy/pull/8681>`__: ENH add generalized inverse Gaussian distribution to scipy.stats
* `#9064 <https://github.com/scipy/scipy/pull/9064>`__: BUG/ENH: Added default _transpose into LinearOperator. Fixes...
* `#9215 <https://github.com/scipy/scipy/pull/9215>`__: ENH: Rbf interpolation of large multi-dimensional data
* `#9311 <https://github.com/scipy/scipy/pull/9311>`__: ENH: Added voigt in scipy.special.
* `#9642 <https://github.com/scipy/scipy/pull/9642>`__: ENH: integrate: quad() for vector-valued functions
* `#9679 <https://github.com/scipy/scipy/pull/9679>`__: DOC: expand docstring of exponweib distribution
* `#9684 <https://github.com/scipy/scipy/pull/9684>`__: TST: add ppc64le ci testing
* `#9800 <https://github.com/scipy/scipy/pull/9800>`__: WIP : ENH: Refactored _hungarian.py for speed and added a minimize/maximize…
* `#9847 <https://github.com/scipy/scipy/pull/9847>`__: DOC: Change integrate tutorial to use solve_ivp instead of odeint
* `#9876 <https://github.com/scipy/scipy/pull/9876>`__: ENH: Use rfft when possible in resampling
* `#9998 <https://github.com/scipy/scipy/pull/9998>`__: BUG: Do not remove 1s when calling sparse: reshape method #9994
* `#10002 <https://github.com/scipy/scipy/pull/10002>`__: ENH: adds constraints for differential evolution
* `#10098 <https://github.com/scipy/scipy/pull/10098>`__: ENH: integrate: add args argument to solve_ivp.
* `#10099 <https://github.com/scipy/scipy/pull/10099>`__: DOC: Add missing docs for linprog unknown_options
* `#10104 <https://github.com/scipy/scipy/pull/10104>`__: BUG: Rewrite of stats.truncnorm distribution.
* `#10105 <https://github.com/scipy/scipy/pull/10105>`__: MAINT improve efficiency of rvs_ratio_uniforms in scipy.stats
* `#10107 <https://github.com/scipy/scipy/pull/10107>`__: TST: dual_annealing set seed
* `#10108 <https://github.com/scipy/scipy/pull/10108>`__: ENH: stats: improve kendall_tau cache usage
* `#10110 <https://github.com/scipy/scipy/pull/10110>`__: MAINT: _lib: Fix a build warning.
* `#10114 <https://github.com/scipy/scipy/pull/10114>`__: FIX: only print bounds when supported by minimizer (shgo)
* `#10115 <https://github.com/scipy/scipy/pull/10115>`__: TST: Add a test with an almost singular design matrix for lsq_linear
* `#10118 <https://github.com/scipy/scipy/pull/10118>`__: MAINT: fix rdist methods in scipy.stats
* `#10119 <https://github.com/scipy/scipy/pull/10119>`__: MAINT: improve rvs of randint in scipy.stats
* `#10127 <https://github.com/scipy/scipy/pull/10127>`__: Fix typo in record array field name (spatial-ckdtree-sparse_distance…
* `#10130 <https://github.com/scipy/scipy/pull/10130>`__: MAINT: ndimage: Fix some compiler warnings.
* `#10131 <https://github.com/scipy/scipy/pull/10131>`__: DOC: Note the solve_ivp args enhancement in the 1.4.0 release...
* `#10133 <https://github.com/scipy/scipy/pull/10133>`__: MAINT: add rvs for semicircular in scipy.stats
* `#10138 <https://github.com/scipy/scipy/pull/10138>`__: BUG: special: Invalid arguments to ellip_harm can crash Python.
* `#10139 <https://github.com/scipy/scipy/pull/10139>`__: MAINT: spatial: Fix some compiler warnings in the file distance_wrap.c.
* `#10140 <https://github.com/scipy/scipy/pull/10140>`__: ENH: add handling of NaN in RuntimeWarning except clause
* `#10142 <https://github.com/scipy/scipy/pull/10142>`__: DOC: return value of scipy.special.comb
* `#10143 <https://github.com/scipy/scipy/pull/10143>`__: MAINT: Loosen linprog tol
* `#10152 <https://github.com/scipy/scipy/pull/10152>`__: BUG: Fix custom sampling input for shgo, add unittest
* `#10154 <https://github.com/scipy/scipy/pull/10154>`__: MAINT: add moments and improve doc of mielke in scipy.stats
* `#10158 <https://github.com/scipy/scipy/pull/10158>`__: Issue #6999: read zlib checksum before checking bytes read.
* `#10166 <https://github.com/scipy/scipy/pull/10166>`__: BUG: Correctly handle broadcasted ydata in curve_fit pcov computation.
* `#10167 <https://github.com/scipy/scipy/pull/10167>`__: DOC: special: Add missing factor of \`i\` to \`modstruve\` docstring
* `#10168 <https://github.com/scipy/scipy/pull/10168>`__: MAINT: stats: Fix an incorrect comment.
* `#10169 <https://github.com/scipy/scipy/pull/10169>`__: ENH: optimize: Clarify error when objective function returns...
* `#10172 <https://github.com/scipy/scipy/pull/10172>`__: DEV: Run tests in parallel when --parallel flag is passed to...
* `#10173 <https://github.com/scipy/scipy/pull/10173>`__: ENH: Implement DOP853 ODE integrator
* `#10176 <https://github.com/scipy/scipy/pull/10176>`__: Fixed typo
* `#10182 <https://github.com/scipy/scipy/pull/10182>`__: TST: fix test issue for stats.pearsonr
* `#10184 <https://github.com/scipy/scipy/pull/10184>`__: MAINT: stats: Simplify zmap and zscore (we can use keepdims now).
* `#10191 <https://github.com/scipy/scipy/pull/10191>`__: DOC: fix a formatting issue in the scipy.spatial module docstring.
* `#10193 <https://github.com/scipy/scipy/pull/10193>`__: DOC: Updated docstring for optimize.nnls
* `#10198 <https://github.com/scipy/scipy/pull/10198>`__: DOC, ENH: special: Make \`hyp2f1\` references more specific
* `#10202 <https://github.com/scipy/scipy/pull/10202>`__: DOC: Format DST and DCT definitions as latex equations
* `#10207 <https://github.com/scipy/scipy/pull/10207>`__: BUG: Compressed matrix indexing should return a scalar
* `#10210 <https://github.com/scipy/scipy/pull/10210>`__: DOC: Update docs for connection='weak' in connected_components
* `#10225 <https://github.com/scipy/scipy/pull/10225>`__: DOC: Clarify new interfaces for legacy functions in 'optimize'
* `#10231 <https://github.com/scipy/scipy/pull/10231>`__: DOC, MAINT: gpg2 updates to release docs / pavement
* `#10235 <https://github.com/scipy/scipy/pull/10235>`__: LICENSE: split license file in standard BSD 3-clause and bundled.
* `#10238 <https://github.com/scipy/scipy/pull/10238>`__: ENH: Add new scipy.fft module using pocketfft
* `#10243 <https://github.com/scipy/scipy/pull/10243>`__: BUG: fix ARFF reader regression with quoted values.
* `#10248 <https://github.com/scipy/scipy/pull/10248>`__: DOC: update README file
* `#10255 <https://github.com/scipy/scipy/pull/10255>`__: CI: bump OpenBLAS to match wheels
* `#10264 <https://github.com/scipy/scipy/pull/10264>`__: TST: add tests for stats.tvar with unflattened arrays
* `#10280 <https://github.com/scipy/scipy/pull/10280>`__: MAINT: stats: Use a constant value for sqrt(2/PI).
* `#10286 <https://github.com/scipy/scipy/pull/10286>`__: Development Documentation Overhaul
* `#10290 <https://github.com/scipy/scipy/pull/10290>`__: MAINT: Deprecate NumPy functions in SciPy root
* `#10291 <https://github.com/scipy/scipy/pull/10291>`__: FIX: Avoid importing xdist when checking for availability
* `#10295 <https://github.com/scipy/scipy/pull/10295>`__: Disable deprecated Numpy API in __odrpack.c
* `#10296 <https://github.com/scipy/scipy/pull/10296>`__: ENH: C++ extension for linear assignment problem
* `#10298 <https://github.com/scipy/scipy/pull/10298>`__: ENH: Made pade function work with complex inputs
* `#10301 <https://github.com/scipy/scipy/pull/10301>`__: DOC: Fix critical value significance levels in stats.anderson_ksamp
* `#10307 <https://github.com/scipy/scipy/pull/10307>`__: Minkowski Distance Type Fix (issue #10262)
* `#10309 <https://github.com/scipy/scipy/pull/10309>`__: BUG: Pass jac=None directly to lsoda
* `#10310 <https://github.com/scipy/scipy/pull/10310>`__: BUG: interpolate: UnivariateSpline.derivative.ext is 'zeros'...
* `#10312 <https://github.com/scipy/scipy/pull/10312>`__: FIX: Fixing a typo in a comment
* `#10314 <https://github.com/scipy/scipy/pull/10314>`__: scipy.spatial enhancement request
* `#10315 <https://github.com/scipy/scipy/pull/10315>`__: DOC: Update integration tutorial to solve_ivp
* `#10318 <https://github.com/scipy/scipy/pull/10318>`__: DOC: update the example for PPoly.solve
* `#10333 <https://github.com/scipy/scipy/pull/10333>`__: TST: add tests for stats.tvar with unflattened arrays
* `#10334 <https://github.com/scipy/scipy/pull/10334>`__: MAINT: special: Remove deprecated \`hyp2f0\`, \`hyp1f2\`, and...
* `#10336 <https://github.com/scipy/scipy/pull/10336>`__: BUG: linalg/interpolative: fix interp_decomp modifying input
* `#10341 <https://github.com/scipy/scipy/pull/10341>`__: BUG: sparse.linalg/gmres: deprecate effect of callback on semantics...
* `#10344 <https://github.com/scipy/scipy/pull/10344>`__: DOC: improve wording of mathematical formulation
* `#10345 <https://github.com/scipy/scipy/pull/10345>`__: ENH: Tiled QR wrappers for scipy.linalg.lapack
* `#10350 <https://github.com/scipy/scipy/pull/10350>`__: MAINT: linalg: Use the new fft subpackage in linalg.dft test...
* `#10351 <https://github.com/scipy/scipy/pull/10351>`__: BUG: Fix unstable standard deviation calculation in histogram
* `#10353 <https://github.com/scipy/scipy/pull/10353>`__: Bug: interpolate.NearestNDInterpolator (issue #10352)
* `#10357 <https://github.com/scipy/scipy/pull/10357>`__: DOC: linalg: Refer to scipy.fft.fft (not fftpack) in the dft...
* `#10359 <https://github.com/scipy/scipy/pull/10359>`__: DOC: Update roadmap now scipy.fft has been merged
* `#10361 <https://github.com/scipy/scipy/pull/10361>`__: ENH: Prefer scipy.fft to scipy.fftpack in scipy.signal
* `#10371 <https://github.com/scipy/scipy/pull/10371>`__: DOC: Tweaks to fft documentation
* `#10372 <https://github.com/scipy/scipy/pull/10372>`__: DOC: Fix typos
* `#10377 <https://github.com/scipy/scipy/pull/10377>`__: TST, MAINT: adjustments for pytest 5.0
* `#10378 <https://github.com/scipy/scipy/pull/10378>`__: ENH: _lib: allow new np.random.Generator in check_random_state
* `#10379 <https://github.com/scipy/scipy/pull/10379>`__: BUG: sparse: set writeability to be forward-compatible with numpy>=1.17
* `#10381 <https://github.com/scipy/scipy/pull/10381>`__: BUG: Fixes gh-7491, pdf at x=0 of fisk/burr/burr12/f distributions.
* `#10387 <https://github.com/scipy/scipy/pull/10387>`__: ENH: optimize/bfgs: don't evaluate twice at initial point for...
* `#10392 <https://github.com/scipy/scipy/pull/10392>`__: [DOC] Add an example for _binned_statistic_dd
* `#10396 <https://github.com/scipy/scipy/pull/10396>`__: Remove warning about output shape of zoom
* `#10397 <https://github.com/scipy/scipy/pull/10397>`__: ENH: Add check_finite to sp.linalg.norm
* `#10399 <https://github.com/scipy/scipy/pull/10399>`__: ENH: Add __round__ method to sparse matrix
* `#10407 <https://github.com/scipy/scipy/pull/10407>`__: MAINT: drop pybind11 from install_requires, it's only build-time...
* `#10408 <https://github.com/scipy/scipy/pull/10408>`__: TST: use pytest.raises, not numpy assert_raises
* `#10409 <https://github.com/scipy/scipy/pull/10409>`__: CI: uninstall nose on Travis
* `#10410 <https://github.com/scipy/scipy/pull/10410>`__: [ENH] ncx2 dispatch to chi2 when nc=0
* `#10411 <https://github.com/scipy/scipy/pull/10411>`__: TST: optimize: test should use assert_allclose for fp comparisons
* `#10414 <https://github.com/scipy/scipy/pull/10414>`__: DOC: add pybind11 to the other part of quickstart guides
* `#10417 <https://github.com/scipy/scipy/pull/10417>`__: DOC: special: don't mark non-ufuncs with a \`[+]\`
* `#10423 <https://github.com/scipy/scipy/pull/10423>`__: FIX: Use pybind11::isinstace to check array dtypes
* `#10424 <https://github.com/scipy/scipy/pull/10424>`__: DOC: add doctest example for binary data for ttest_ind_from_stats
* `#10425 <https://github.com/scipy/scipy/pull/10425>`__: ENH: Add missing Hermitian transforms to scipy.fft
* `#10426 <https://github.com/scipy/scipy/pull/10426>`__: MAINT: Fix doc build bugs
* `#10431 <https://github.com/scipy/scipy/pull/10431>`__: Update numpy version for AIX
* `#10433 <https://github.com/scipy/scipy/pull/10433>`__: MAINT: Minor fixes for the stats
* `#10434 <https://github.com/scipy/scipy/pull/10434>`__: BUG: special: make \`ndtri\` return NaN outside domain of definition
* `#10435 <https://github.com/scipy/scipy/pull/10435>`__: BUG: Allow integer input data in scipy.stats.yeojohnson
* `#10438 <https://github.com/scipy/scipy/pull/10438>`__: [DOC] Add example for kurtosis
* `#10440 <https://github.com/scipy/scipy/pull/10440>`__: ENH: special: make \`ellipk\` a ufunc
* `#10443 <https://github.com/scipy/scipy/pull/10443>`__: MAINT: ndimage: malloc fail check
* `#10447 <https://github.com/scipy/scipy/pull/10447>`__: BLD: Divert output from test compiles into a temporary directory
* `#10451 <https://github.com/scipy/scipy/pull/10451>`__: MAINT: signal: malloc fail check
* `#10455 <https://github.com/scipy/scipy/pull/10455>`__: BUG: special: fix values of \`hyperu\` for negative \`x\`
* `#10456 <https://github.com/scipy/scipy/pull/10456>`__: DOC: Added comment clarifying the call for dcsrch.f in lbfgsb.f
* `#10457 <https://github.com/scipy/scipy/pull/10457>`__: BUG: Allow ckdtree to accept empty data input
* `#10459 <https://github.com/scipy/scipy/pull/10459>`__: BUG:TST: Compute lwork safely
* `#10460 <https://github.com/scipy/scipy/pull/10460>`__: [DOC] Add example to entropy
* `#10461 <https://github.com/scipy/scipy/pull/10461>`__: DOC: Quickstart Guide updates
* `#10462 <https://github.com/scipy/scipy/pull/10462>`__: TST: special: only show max atol/rtol for test points that failed
* `#10465 <https://github.com/scipy/scipy/pull/10465>`__: BUG: Correctly align fft inputs
* `#10467 <https://github.com/scipy/scipy/pull/10467>`__: ENH: lower-memory duplicate generator checking in spatial.SphericalVoronoi
* `#10470 <https://github.com/scipy/scipy/pull/10470>`__: ENH: Normalise the inverse DCT/DST in scipy.fft
* `#10472 <https://github.com/scipy/scipy/pull/10472>`__: BENCH: adjust timeout for slow setup_cache
* `#10475 <https://github.com/scipy/scipy/pull/10475>`__: CI: include python debug for Travis-ci
* `#10476 <https://github.com/scipy/scipy/pull/10476>`__: TST: special: use \`__tracebackhide__\` to get better error messages
* `#10477 <https://github.com/scipy/scipy/pull/10477>`__: ENH: faster region building in spatial.SphericalVoronoi
* `#10479 <https://github.com/scipy/scipy/pull/10479>`__: BUG: stats: Fix a few issues with the distributions' fit method.
* `#10480 <https://github.com/scipy/scipy/pull/10480>`__: Add RuntimeError in _distn_infrastructure.py in fit() method
* `#10481 <https://github.com/scipy/scipy/pull/10481>`__: BENCH, MAINT: wheel_cache_size has been renamed build_cache_size
* `#10494 <https://github.com/scipy/scipy/pull/10494>`__: ENH: faster circumcenter calculation in spatial.SphericalVoronoi
* `#10500 <https://github.com/scipy/scipy/pull/10500>`__: Splrep _curfit_cache global variable bugfix
* `#10503 <https://github.com/scipy/scipy/pull/10503>`__: BUG: spatial/qhull: get HalfspaceIntersection.dual_points from...
* `#10506 <https://github.com/scipy/scipy/pull/10506>`__: DOC: interp2d, note nearest neighbor extrapolation
* `#10507 <https://github.com/scipy/scipy/pull/10507>`__: MAINT: Remove fortran fftpack library in favour of pypocketfft
* `#10508 <https://github.com/scipy/scipy/pull/10508>`__: TST: fix a bug in the circular import test.
* `#10509 <https://github.com/scipy/scipy/pull/10509>`__: MAINT: Set up _build_utils as subpackage
* `#10516 <https://github.com/scipy/scipy/pull/10516>`__: BUG: Use nogil contexts in cKDTree
* `#10517 <https://github.com/scipy/scipy/pull/10517>`__: ENH: fftconvolve should not FFT broadcastable axes
* `#10518 <https://github.com/scipy/scipy/pull/10518>`__: ENH: Speedup fftconvolve
* `#10520 <https://github.com/scipy/scipy/pull/10520>`__: DOC: Proper .rst formatting for deprecated features and Backwards...
* `#10523 <https://github.com/scipy/scipy/pull/10523>`__: DOC: Improve scipy.signal.resample documentation
* `#10524 <https://github.com/scipy/scipy/pull/10524>`__: ENH: Add MGC to scipy.stats
* `#10525 <https://github.com/scipy/scipy/pull/10525>`__: [ENH] ncx2.ppf dispatch to chi2 when nc=0
* `#10526 <https://github.com/scipy/scipy/pull/10526>`__: DOC: clarify laplacian normalization
* `#10528 <https://github.com/scipy/scipy/pull/10528>`__: API: Rename scipy.fft DCT/DST shape argument to s
* `#10531 <https://github.com/scipy/scipy/pull/10531>`__: BUG: fixed improper rotations in spatial.transform.rotation.match_vectors
* `#10533 <https://github.com/scipy/scipy/pull/10533>`__: [DOC] Add example for winsorize function
* `#10539 <https://github.com/scipy/scipy/pull/10539>`__: MAINT: special: don't register \`i0\` with \`numpy.dual\`
* `#10540 <https://github.com/scipy/scipy/pull/10540>`__: MAINT: Fix Travis and Circle
* `#10542 <https://github.com/scipy/scipy/pull/10542>`__: MAINT: interpolate: use cython_lapack
* `#10547 <https://github.com/scipy/scipy/pull/10547>`__: Feature request. Add furthest site Voronoi diagrams to scipy.spatial.plotutils.
* `#10549 <https://github.com/scipy/scipy/pull/10549>`__: [BUG] Fix bug in trimr when inclusive=False
* `#10552 <https://github.com/scipy/scipy/pull/10552>`__: add scipy.signal.upfirdn signal extension modes
* `#10555 <https://github.com/scipy/scipy/pull/10555>`__: MAINT: special: move \`c_misc\` into Cephes
* `#10556 <https://github.com/scipy/scipy/pull/10556>`__: [DOC] Add example for trima
* `#10562 <https://github.com/scipy/scipy/pull/10562>`__: [DOC] Fix triple string fo trimmed so that __doc__ can show...
* `#10563 <https://github.com/scipy/scipy/pull/10563>`__: improve least_squares error msg for mismatched shape
* `#10564 <https://github.com/scipy/scipy/pull/10564>`__: ENH: linalg: memoize get_lapack/blas_funcs to speed it up
* `#10566 <https://github.com/scipy/scipy/pull/10566>`__: ENH: add implementation of solver for the maximum flow problem
* `#10567 <https://github.com/scipy/scipy/pull/10567>`__: BUG: spatial: use c++11 construct for getting start of vector...
* `#10568 <https://github.com/scipy/scipy/pull/10568>`__: DOC: special: small tweaks to the \`zetac\` docstring
* `#10571 <https://github.com/scipy/scipy/pull/10571>`__: [ENH] Gaussian_kde can accept matrix dataset
* `#10574 <https://github.com/scipy/scipy/pull/10574>`__: ENH: linalg: speed up _compute_lwork by avoiding numpy constructs
* `#10582 <https://github.com/scipy/scipy/pull/10582>`__: Fix typos with typos in bundled libraries reverted
* `#10583 <https://github.com/scipy/scipy/pull/10583>`__: ENH: special: add the analytic continuation of Riemann zeta
* `#10584 <https://github.com/scipy/scipy/pull/10584>`__: MAINT: special: clean up \`special.__all__\`
* `#10586 <https://github.com/scipy/scipy/pull/10586>`__: BUG: multidimensional scipy.fft functions should accept 's' rather...
* `#10587 <https://github.com/scipy/scipy/pull/10587>`__: BUG: integrate/lsoda: never abort run, set error istate instead
* `#10594 <https://github.com/scipy/scipy/pull/10594>`__: API: Replicate numpy's fftn behaviour when s is given but not...
* `#10599 <https://github.com/scipy/scipy/pull/10599>`__: DOC: dev: update documentation vs. github pull request workflow...
* `#10603 <https://github.com/scipy/scipy/pull/10603>`__: MAINT: installer scripts removed
* `#10604 <https://github.com/scipy/scipy/pull/10604>`__: MAINT: Change c\*np.ones(...) to np.full(..., c, ...) in many...
* `#10608 <https://github.com/scipy/scipy/pull/10608>`__: Univariate splines should require x to be strictly increasing...
* `#10613 <https://github.com/scipy/scipy/pull/10613>`__: ENH: Add seed option for gaussian_kde.resample
* `#10614 <https://github.com/scipy/scipy/pull/10614>`__: ENH: Add parallel computation to scipy.fft
* `#10615 <https://github.com/scipy/scipy/pull/10615>`__: MAINT: interpolate: remove unused header file
* `#10616 <https://github.com/scipy/scipy/pull/10616>`__: MAINT: Clean up 32-bit platform xfail markers
* `#10618 <https://github.com/scipy/scipy/pull/10618>`__: BENCH: Added 'trust-constr' to minimize benchmarks
* `#10621 <https://github.com/scipy/scipy/pull/10621>`__: [MRG] multiple stability updates in lobpcg
* `#10622 <https://github.com/scipy/scipy/pull/10622>`__: MAINT: forward port 1.3.1 release notes
* `#10624 <https://github.com/scipy/scipy/pull/10624>`__: DOC: stats: Fix spelling of 'support'.
* `#10627 <https://github.com/scipy/scipy/pull/10627>`__: DOC: stats: Add references for the alpha distribution.
* `#10629 <https://github.com/scipy/scipy/pull/10629>`__: MAINT: special: avoid overflow longer in \`zeta\` for negative...
* `#10630 <https://github.com/scipy/scipy/pull/10630>`__: TST: GH10271, relax test assertion, fixes #10271
* `#10631 <https://github.com/scipy/scipy/pull/10631>`__: DOC: nelder-mean uses xatol fixes #10036
* `#10633 <https://github.com/scipy/scipy/pull/10633>`__: BUG: interpolate: integral(a, b) should be zero when both limits...
* `#10635 <https://github.com/scipy/scipy/pull/10635>`__: DOC: special: complete hypergeometric functions documentation
* `#10636 <https://github.com/scipy/scipy/pull/10636>`__: BUG: special: use series for \`hyp1f1\` when it converges rapidly
* `#10641 <https://github.com/scipy/scipy/pull/10641>`__: ENH: allow matching of general bipartite graphs
* `#10643 <https://github.com/scipy/scipy/pull/10643>`__: ENH: scipy.sparse.linalg.spsolve triangular unit diagonal
* `#10650 <https://github.com/scipy/scipy/pull/10650>`__: ENH: Cythonize sosfilt
* `#10654 <https://github.com/scipy/scipy/pull/10654>`__: DOC: Vertical alignment of table entries
* `#10655 <https://github.com/scipy/scipy/pull/10655>`__: ENH: Dockerfile for scipy development
* `#10660 <https://github.com/scipy/scipy/pull/10660>`__: TST: clean up tests for rvs in scipy.stats
* `#10664 <https://github.com/scipy/scipy/pull/10664>`__: Throw error on non-finite input for binned_statistic_dd()
* `#10665 <https://github.com/scipy/scipy/pull/10665>`__: DOC: special: improve the docstrings for \`gamma\` and \`gammasgn\`
* `#10669 <https://github.com/scipy/scipy/pull/10669>`__: TST: Update scipy.fft real transform tests
* `#10670 <https://github.com/scipy/scipy/pull/10670>`__: DOC: Clarify docs and error messages for scipy.signal.butter
* `#10672 <https://github.com/scipy/scipy/pull/10672>`__: ENH: return solution attribute when using events in solve_ivp
* `#10675 <https://github.com/scipy/scipy/pull/10675>`__: MAINT: special: add an explicit NaN check for \`iv\` arguments
* `#10679 <https://github.com/scipy/scipy/pull/10679>`__: DOC: special: Add documentation for \`beta\` function
* `#10681 <https://github.com/scipy/scipy/pull/10681>`__: TST: sparse.linalg: fix arnoldi test seed
* `#10682 <https://github.com/scipy/scipy/pull/10682>`__: DOC: special: Add documentation for \`betainc\` function
* `#10684 <https://github.com/scipy/scipy/pull/10684>`__: TST: special: require Mpmath 1.1.0 for \`test_hyperu_around_0\`
* `#10686 <https://github.com/scipy/scipy/pull/10686>`__: FIX: sphinx isattributedescriptor is not available in sphinx...
* `#10687 <https://github.com/scipy/scipy/pull/10687>`__: DOC: added Docker quickstart guide by @andyfaff
* `#10689 <https://github.com/scipy/scipy/pull/10689>`__: DOC: special: clarify format of parameters/returns sections for...
* `#10690 <https://github.com/scipy/scipy/pull/10690>`__: DOC: special: improve docstrings of incomplete gamma functions
* `#10692 <https://github.com/scipy/scipy/pull/10692>`__: ENH: higher-dimensional input in \`spatial.SphericalVoronoi\`
* `#10694 <https://github.com/scipy/scipy/pull/10694>`__: ENH: ScalarFunction.fun_and_grad
* `#10698 <https://github.com/scipy/scipy/pull/10698>`__: DOC: special: Add documentation for \`betaincinv\`
* `#10699 <https://github.com/scipy/scipy/pull/10699>`__: MAINT: remove time print lbfgsb fixes #8417
* `#10701 <https://github.com/scipy/scipy/pull/10701>`__: TST, MAINT: bump OpenBLAS to 0.3.7 stable
* `#10702 <https://github.com/scipy/scipy/pull/10702>`__: DOC: clarify iterations consume multiple function calls
* `#10703 <https://github.com/scipy/scipy/pull/10703>`__: DOC: iprint doc lbfgsb closes #5482
* `#10708 <https://github.com/scipy/scipy/pull/10708>`__: TST: test suggested in gh1758
* `#10710 <https://github.com/scipy/scipy/pull/10710>`__: ENH: Added nan_policy to circ functions in \`stats\`
* `#10712 <https://github.com/scipy/scipy/pull/10712>`__: ENH: add axis parameter to stats.entropy
* `#10714 <https://github.com/scipy/scipy/pull/10714>`__: DOC: Formatting fix rv_continuous.expect docs
* `#10715 <https://github.com/scipy/scipy/pull/10715>`__: DOC: BLD: update doc Makefile for python version; add scipy version...
* `#10717 <https://github.com/scipy/scipy/pull/10717>`__: MAINT: modernize doc/Makefile
* `#10719 <https://github.com/scipy/scipy/pull/10719>`__: Enable setting minres initial vector
* `#10720 <https://github.com/scipy/scipy/pull/10720>`__: DOC: silence random warning in doc build for \`stats.binned_statistic_dd\`
* `#10724 <https://github.com/scipy/scipy/pull/10724>`__: DEV: Add doc option to runtests.py
* `#10728 <https://github.com/scipy/scipy/pull/10728>`__: MAINT: get rid of gramA, gramB text files that lobpcg tests leave...
* `#10732 <https://github.com/scipy/scipy/pull/10732>`__: DOC: add min_only to docstring for Dijkstra's algorithm
* `#10734 <https://github.com/scipy/scipy/pull/10734>`__: DOC: spell out difference between source and target in shortest...
* `#10735 <https://github.com/scipy/scipy/pull/10735>`__: Fix for Python 4
* `#10739 <https://github.com/scipy/scipy/pull/10739>`__: BUG: optimize/slsqp: deal with singular BFGS update
* `#10741 <https://github.com/scipy/scipy/pull/10741>`__: ENH: LAPACK wrappers for ?geequ, ?geequb, ?syequb, ?heequb
* `#10742 <https://github.com/scipy/scipy/pull/10742>`__: DOC: special: add to the docstring of \`gammaln\`
* `#10743 <https://github.com/scipy/scipy/pull/10743>`__: ENH: special: add a real dispatch for \`wrightomega\`
* `#10746 <https://github.com/scipy/scipy/pull/10746>`__: MAINT: Fix typos in comments, docs and test name
* `#10747 <https://github.com/scipy/scipy/pull/10747>`__: Remove spurious quotes
* `#10750 <https://github.com/scipy/scipy/pull/10750>`__: MAINT: make cython code more precise
* `#10751 <https://github.com/scipy/scipy/pull/10751>`__: MAINT: Check that scipy.linalg.lapack functions are documented
* `#10752 <https://github.com/scipy/scipy/pull/10752>`__: MAINT: special: use \`sf_error\` in Cephes
* `#10755 <https://github.com/scipy/scipy/pull/10755>`__: DOC: cluster: Add 'See Also' and 'Examples' for kmeans2.
* `#10763 <https://github.com/scipy/scipy/pull/10763>`__: MAINT: list of minimize methods
* `#10768 <https://github.com/scipy/scipy/pull/10768>`__: BUG: Fix corner case for sos2zpk
* `#10773 <https://github.com/scipy/scipy/pull/10773>`__: Fix error type for complex input to scipy.fftpack.rfft and irfft
* `#10776 <https://github.com/scipy/scipy/pull/10776>`__: ENH: handle geodesic input in \`spatial.SphericalVoronoi\`
* `#10777 <https://github.com/scipy/scipy/pull/10777>`__: MAINT: minimizer-->custom should handle the kinds of bounds/constrain…...
* `#10781 <https://github.com/scipy/scipy/pull/10781>`__: ENH: solve_triangular C order improvement
* `#10787 <https://github.com/scipy/scipy/pull/10787>`__: Fix behavior of \`exp1\` on branch cut and add docstring
* `#10789 <https://github.com/scipy/scipy/pull/10789>`__: DOC: special: add parameters/returns doc sections for erfc/erfcx/erfi
* `#10790 <https://github.com/scipy/scipy/pull/10790>`__: Travis CI: sudo is deprecated and Xenial is default distro
* `#10792 <https://github.com/scipy/scipy/pull/10792>`__: DOC: special: add full docstring for \`expi\`
* `#10799 <https://github.com/scipy/scipy/pull/10799>`__: DOC: special: add a complete docstring for \`expn\`
* `#10800 <https://github.com/scipy/scipy/pull/10800>`__: Docs edits (GSoD)
* `#10802 <https://github.com/scipy/scipy/pull/10802>`__: BUG: fix UnboundLocalError in Radau (scipy#10775)
* `#10804 <https://github.com/scipy/scipy/pull/10804>`__: ENH: Speed up next_fast_len with LRU cache
* `#10805 <https://github.com/scipy/scipy/pull/10805>`__: DOC: Fix unbalanced quotes in signal.place_poles
* `#10809 <https://github.com/scipy/scipy/pull/10809>`__: ENH: Speed up next_fast_len
* `#10810 <https://github.com/scipy/scipy/pull/10810>`__: ENH: Raise catchable exceptions for bad Fortran files
* `#10811 <https://github.com/scipy/scipy/pull/10811>`__: MAINT: optimize: Remove extra variable from _remove_redundancy_dense
* `#10813 <https://github.com/scipy/scipy/pull/10813>`__: MAINT: special: Remove unused variables from _kolmogi and _smirnovi
* `#10815 <https://github.com/scipy/scipy/pull/10815>`__: DOC, API: scipy.stats.reciprocal is "log-uniform"
* `#10816 <https://github.com/scipy/scipy/pull/10816>`__: MAINT: special: remove deprecated \`bessel_diff_formula\`
* `#10817 <https://github.com/scipy/scipy/pull/10817>`__: DOC: special: complete the docstring for \`fresnel\`
* `#10820 <https://github.com/scipy/scipy/pull/10820>`__: Fixed compiler_helper.py to allow compilation with ICC on Linux
* `#10823 <https://github.com/scipy/scipy/pull/10823>`__: DOC: updated reference guide text for consistency in writing...
* `#10825 <https://github.com/scipy/scipy/pull/10825>`__: MAINT: special: change some features of the Voigt function
* `#10828 <https://github.com/scipy/scipy/pull/10828>`__: MAINT: integrate: Remove unused variable from init_callback
* `#10830 <https://github.com/scipy/scipy/pull/10830>`__: Adding LOBPCG solver in svds in addition to ARPACK
* `#10837 <https://github.com/scipy/scipy/pull/10837>`__: WIP: ENH: reduction function for \`spatial.tranform.Rotation\`...
* `#10843 <https://github.com/scipy/scipy/pull/10843>`__: ENH: Adding optional parameter to stats.zscores to allow for...
* `#10845 <https://github.com/scipy/scipy/pull/10845>`__: Rebase kruskal fix
* `#10847 <https://github.com/scipy/scipy/pull/10847>`__: remove redundant __getitem__ from scipy.sparse.lil
* `#10848 <https://github.com/scipy/scipy/pull/10848>`__: Better handling of empty (not missing) docstrings
* `#10849 <https://github.com/scipy/scipy/pull/10849>`__: ENH: implement rmatmat for LinearOperator
* `#10850 <https://github.com/scipy/scipy/pull/10850>`__: MAINT : Refactoring lil List of Lists
* `#10851 <https://github.com/scipy/scipy/pull/10851>`__: DOC: add a generative art example to the scipy.spatial tutorial.
* `#10852 <https://github.com/scipy/scipy/pull/10852>`__: DOC: linalg: fixed gh-10838 unused imports in example deleted
* `#10854 <https://github.com/scipy/scipy/pull/10854>`__: DOC: special: add a full docstring for \`pdtr\`
* `#10861 <https://github.com/scipy/scipy/pull/10861>`__: ENH: option to reuse binnumbers in stats.binned_statistic_dd
* `#10863 <https://github.com/scipy/scipy/pull/10863>`__: DOC: partial standardization and validation of scipy.stats reference...
* `#10865 <https://github.com/scipy/scipy/pull/10865>`__: BUG: special: fix incomplete gamma functions for infinite \`a\`
* `#10866 <https://github.com/scipy/scipy/pull/10866>`__: ENH: calculation of mean in spatial.transform.Rotation
* `#10867 <https://github.com/scipy/scipy/pull/10867>`__: MAINT: Also store latex directory
* `#10869 <https://github.com/scipy/scipy/pull/10869>`__: ENH: Implement overlap-add convolution
* `#10870 <https://github.com/scipy/scipy/pull/10870>`__: ENH: Do not raise EOF error if wavfile data read
* `#10876 <https://github.com/scipy/scipy/pull/10876>`__: ENH: Add beta-binomial distribution to scipy.stats
* `#10878 <https://github.com/scipy/scipy/pull/10878>`__: MAINT: Update R project URL
* `#10883 <https://github.com/scipy/scipy/pull/10883>`__: MAINT: (ndimage) More robust check for output being a numpy dtype
* `#10884 <https://github.com/scipy/scipy/pull/10884>`__: DOC: Added instructions on adding a new distribution to scipy.stats.
* `#10885 <https://github.com/scipy/scipy/pull/10885>`__: [BUG] fix lobpcg with maxiter=None results in Exception
* `#10899 <https://github.com/scipy/scipy/pull/10899>`__: ENH: Match R functionality for hmean
* `#10900 <https://github.com/scipy/scipy/pull/10900>`__: MAINT: stats: Use keepdims to simplify a few lines in power_divergence.
* `#10901 <https://github.com/scipy/scipy/pull/10901>`__: ENH: sparse/linalg: support pydata/sparse matrices
* `#10907 <https://github.com/scipy/scipy/pull/10907>`__: Check whether \`maxiter\` is integer
* `#10912 <https://github.com/scipy/scipy/pull/10912>`__: ENH: warn user that quad() ignores \`points=...\` when \`weight=...\`...
* `#10918 <https://github.com/scipy/scipy/pull/10918>`__: CI: fix Travis CI py3.8 build
* `#10920 <https://github.com/scipy/scipy/pull/10920>`__: MAINT: Update constants to codata 2018 values (second try)
* `#10921 <https://github.com/scipy/scipy/pull/10921>`__: ENH: scipy.sparse.lil: tocsr accelerated
* `#10924 <https://github.com/scipy/scipy/pull/10924>`__: BUG: Forbid passing 'args' as kwarg in scipy.optimize.curve_fit
* `#10928 <https://github.com/scipy/scipy/pull/10928>`__: DOC: Add examples to io.wavfile docstrings
* `#10934 <https://github.com/scipy/scipy/pull/10934>`__: typo fix
* `#10935 <https://github.com/scipy/scipy/pull/10935>`__: BUG: Avoid undefined behaviour on float to unsigned conversion
* `#10936 <https://github.com/scipy/scipy/pull/10936>`__: DOC: Added missing example to stats.mstats.variation
* `#10939 <https://github.com/scipy/scipy/pull/10939>`__: ENH: scipy.sparse.lil: tocsr accelerated depending on density
* `#10946 <https://github.com/scipy/scipy/pull/10946>`__: BUG: setting verbose > 2 in minimize with trust-constr method...
* `#10947 <https://github.com/scipy/scipy/pull/10947>`__: DOC: special: small improvements to the \`poch\` docstring
* `#10949 <https://github.com/scipy/scipy/pull/10949>`__: BUG: fix return type of erlang_gen._argcheck
* `#10951 <https://github.com/scipy/scipy/pull/10951>`__: DOC: fixed Ricker wavelet formula
* `#10954 <https://github.com/scipy/scipy/pull/10954>`__: BUG: special: fix \`factorial\` return type for 0-d inputs
* `#10955 <https://github.com/scipy/scipy/pull/10955>`__: MAINT: Relax the assert_unitary atol value
* `#10956 <https://github.com/scipy/scipy/pull/10956>`__: WIP: make pdtr(int, double) be pdtr(double, double)
* `#10957 <https://github.com/scipy/scipy/pull/10957>`__: BUG: Ensure full binary compatibility of long double test data
* `#10964 <https://github.com/scipy/scipy/pull/10964>`__: ENH: Make Slerp callable with a scalar argument
* `#10972 <https://github.com/scipy/scipy/pull/10972>`__: BUG: Handle complex gains in zpk2sos
* `#10975 <https://github.com/scipy/scipy/pull/10975>`__: TST: skip test_kendalltau ppc64le
* `#10978 <https://github.com/scipy/scipy/pull/10978>`__: BUG: boxcox data dimension and constancy check #5112
* `#10979 <https://github.com/scipy/scipy/pull/10979>`__: API: Rename dcm to (rotation) matrix in Rotation class
* `#10981 <https://github.com/scipy/scipy/pull/10981>`__: MAINT: add support for a==0 and x>0 edge case to igam and igamc
* `#10986 <https://github.com/scipy/scipy/pull/10986>`__: MAINT: Remove direct imports from numpy in signaltools.py
* `#10988 <https://github.com/scipy/scipy/pull/10988>`__: BUG: signal: fixed issue #10360
* `#10989 <https://github.com/scipy/scipy/pull/10989>`__: FIX binned_statistic_dd Mac wheel test fails
* `#10990 <https://github.com/scipy/scipy/pull/10990>`__: BUG: Fix memory leak in shgo triangulation
* `#10992 <https://github.com/scipy/scipy/pull/10992>`__: TST: Relax tolerance in upfirdn test_modes
* `#10993 <https://github.com/scipy/scipy/pull/10993>`__: TST: bump tolerance in optimize tests
* `#10997 <https://github.com/scipy/scipy/pull/10997>`__: MAINT: Rework residue and residuez
* `#11001 <https://github.com/scipy/scipy/pull/11001>`__: DOC: Updated Windows build tutorial
* `#11004 <https://github.com/scipy/scipy/pull/11004>`__: BUG: integrate/quad_vec: fix several bugs in quad_vec
* `#11005 <https://github.com/scipy/scipy/pull/11005>`__: TST: add Python 3.8 Win CI
* `#11006 <https://github.com/scipy/scipy/pull/11006>`__: DOC: special: add a reference for \`kl_div\`
* `#11012 <https://github.com/scipy/scipy/pull/11012>`__: MAINT: Rework invres and invresz
* `#11015 <https://github.com/scipy/scipy/pull/11015>`__: DOC: special: add references for \`rel_entr\`
* `#11017 <https://github.com/scipy/scipy/pull/11017>`__: DOC: numpydoc validation of morestats.py
* `#11018 <https://github.com/scipy/scipy/pull/11018>`__: MAINT: Filter unrelated warning
* `#11031 <https://github.com/scipy/scipy/pull/11031>`__: MAINT: update choose_conv_method for pocketfft implementation
* `#11034 <https://github.com/scipy/scipy/pull/11034>`__: MAINT: TST: Skip tests with multiprocessing that use "spawn"...
* `#11036 <https://github.com/scipy/scipy/pull/11036>`__: DOC: update doc/README with some more useful content.
* `#11037 <https://github.com/scipy/scipy/pull/11037>`__: DOC: special: add a complete docstring for \`rgamma\`
* `#11038 <https://github.com/scipy/scipy/pull/11038>`__: DOC: special: add a reference for the polygamma function
* `#11042 <https://github.com/scipy/scipy/pull/11042>`__: TST: fix tf2zpk test failure due to incorrect complex sorting.
* `#11044 <https://github.com/scipy/scipy/pull/11044>`__: MAINT: choose_conv_method can choose fftconvolution for longcomplex
* `#11046 <https://github.com/scipy/scipy/pull/11046>`__: TST: Reduce tolerance for ppc64le with reference lapack
* `#11048 <https://github.com/scipy/scipy/pull/11048>`__: DOC: special: add reference for orthogonal polynomial functions
* `#11049 <https://github.com/scipy/scipy/pull/11049>`__: MAINT: proper random number initialization and readability fix
* `#11051 <https://github.com/scipy/scipy/pull/11051>`__: MAINT: pep8 cleanup
* `#11054 <https://github.com/scipy/scipy/pull/11054>`__: TST: bump test precision for dual_annealing SLSQP test
* `#11055 <https://github.com/scipy/scipy/pull/11055>`__: DOC: special: add a reference for \`zeta\`
* `#11056 <https://github.com/scipy/scipy/pull/11056>`__: API: Deprecated normalized keyword in Rotation
* `#11065 <https://github.com/scipy/scipy/pull/11065>`__: DOC: Ubuntu Development Environment Quickstart should not modify...
* `#11066 <https://github.com/scipy/scipy/pull/11066>`__: BUG: skip deprecation for numpy top-level types
* `#11067 <https://github.com/scipy/scipy/pull/11067>`__: DOC: updated documentation for consistency in writing style
* `#11070 <https://github.com/scipy/scipy/pull/11070>`__: DOC: Amendment to Ubuntu Development Environment Quickstart should...
* `#11073 <https://github.com/scipy/scipy/pull/11073>`__: DOC: fix 1.4.0 release notes
* `#11081 <https://github.com/scipy/scipy/pull/11081>`__: API: Replace Rotation.match_vectors with align_vectors
* `#11083 <https://github.com/scipy/scipy/pull/11083>`__: DOC: more 1.4.0 release note fixes
* `#11092 <https://github.com/scipy/scipy/pull/11092>`__: BUG: stats: fix freezing of some distributions
* `#11096 <https://github.com/scipy/scipy/pull/11096>`__: BUG: scipy.sparse.csgraph: fixed issue #10774
* `#11124 <https://github.com/scipy/scipy/pull/11124>`__: fix Cython warnings related to _stats.pyx
* `#11126 <https://github.com/scipy/scipy/pull/11126>`__: BUG: interpolate/fitpack: fix memory leak in splprep
* `#11127 <https://github.com/scipy/scipy/pull/11127>`__: Avoid potential segfault in CSR and CSC matrix indexing
* `#11152 <https://github.com/scipy/scipy/pull/11152>`__: BUG: Fix random state bug multiscale_graphcorr
* `#11166 <https://github.com/scipy/scipy/pull/11166>`__: BUG: empty sparse slice shapes
* `#11167 <https://github.com/scipy/scipy/pull/11167>`__: BUG: redundant fft in signal.resample
* `#11181 <https://github.com/scipy/scipy/pull/11181>`__: TST: Fix tolerance of tests for aarch64
* `#11182 <https://github.com/scipy/scipy/pull/11182>`__: TST: Bump up tolerance for test_maxiter_worsening
* `#11199 <https://github.com/scipy/scipy/pull/11199>`__: BUG: sparse.linalg: mistake in unsymm. real shift-invert ARPACK eigenvalue selection
==========================
SciPy 1.7.1 Release Notes
==========================

.. contents::

SciPy 1.7.1 is a bug-fix release with no new features
compared to 1.7.0.

Authors
=======

* Peter Bell
* Evgeni Burovski
* Justin Charlong +
* Ralf Gommers
* Matti Picus
* Tyler Reddy
* Pamphile Roy
* Sebastian Wallkötter
* Arthur Volant

A total of 9 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.7.1
-----------------------

* `#14074 <https://github.com/scipy/scipy/issues/14074>`__: Segmentation fault when building cKDTree with Scipy 1.6.3.
* `#14271 <https://github.com/scipy/scipy/issues/14271>`__: scipy.io.loadmat failure in 1.7.0
* `#14273 <https://github.com/scipy/scipy/issues/14273>`__: \`scipy.signal.{medfilt,medfilt2d}\` hit "Windows fatal exception:...
* `#14282 <https://github.com/scipy/scipy/issues/14282>`__: DOC, CI: stats skewtest refguide failure
* `#14363 <https://github.com/scipy/scipy/issues/14363>`__: Huge stack allocation in _sobol.pyx may cause stack overvflow
* `#14382 <https://github.com/scipy/scipy/issues/14382>`__: Memory leak in \`scipy.spatial.distance\` for \`cdist\`
* `#14396 <https://github.com/scipy/scipy/issues/14396>`__: BUG: Sphinx 4.1 breaks the banner's logo
* `#14444 <https://github.com/scipy/scipy/issues/14444>`__: DOC/FEAT Rotation.from_rotvec documents a degrees argument which...

Pull requests for 1.7.1
-----------------------

* `#14178 <https://github.com/scipy/scipy/pull/14178>`__: DEV: Update Boschloo Exact test
* `#14264 <https://github.com/scipy/scipy/pull/14264>`__: REL: prepare for SciPy 1.7.1
* `#14283 <https://github.com/scipy/scipy/pull/14283>`__: BUG: fix refguide-check namedtuple handling
* `#14303 <https://github.com/scipy/scipy/pull/14303>`__: FIX: Check for None before calling str methods
* `#14327 <https://github.com/scipy/scipy/pull/14327>`__: BUG: medfilt can access beyond the end of an array
* `#14355 <https://github.com/scipy/scipy/pull/14355>`__: BUG: KDTree balanced_tree is unbalanced for degenerate data
* `#14368 <https://github.com/scipy/scipy/pull/14368>`__: BUG: avoid large cython global variable in function
* `#14384 <https://github.com/scipy/scipy/pull/14384>`__: BUG: Reference count leak in distance_pybind
* `#14397 <https://github.com/scipy/scipy/pull/14397>`__: DOC/CI: do not allow sphinx 4.1.
* `#14417 <https://github.com/scipy/scipy/pull/14417>`__: DOC/CI: pin sphinx to !=4.1.0
* `#14460 <https://github.com/scipy/scipy/pull/14460>`__: DOC: add required scipy version to kwarg
* `#14466 <https://github.com/scipy/scipy/pull/14466>`__: MAINT: 1.7.1 backports (round 1)
* `#14508 <https://github.com/scipy/scipy/pull/14508>`__: MAINT: bump scipy-mathjax
* `#14509 <https://github.com/scipy/scipy/pull/14509>`__: MAINT: 1.7.1 backports (round 2)

==========================
SciPy 1.2.0 Release Notes
==========================

.. contents::

SciPy 1.2.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been a number of deprecations and API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning`` s).
Our development attention will now shift to bug-fix releases on the
1.2.x branch, and on adding new features on the master branch.

This release requires Python 2.7 or 3.4+ and NumPy 1.8.2 or greater.

.. note:: This will be the last SciPy release to support Python 2.7.
          Consequently, the 1.2.x series will be a long term support (LTS)
          release; we will backport bug-fixes until 1 Jan 2020.

For running on PyPy, PyPy3 6.0+ and NumPy 1.15.0 are required.

Highlights of this release
===========================

- 1-D root finding improvements with a new solver, ``toms748``, and a new
  unified interface, ``root_scalar``
- new ``dual_annealing`` optimization method that combines stochastic and
  local deterministic searching
- a new optimization algorithm, ``shgo`` (simplicial homology
  global optimization), for derivative-free optimization problems
- a new category of quaternion-based transformations are available in
  `scipy.spatial.transform`

New features
============

`scipy.ndimage` improvements
--------------------------------

Proper spline coefficient calculations have been added for the ``mirror``,
``wrap``, and ``reflect`` modes of `scipy.ndimage.rotate`.

`scipy.fftpack` improvements
--------------------------------

DCT-IV, DST-IV, DCT-I, and DST-I orthonormalization are now supported in
`scipy.fftpack`.

`scipy.interpolate` improvements
--------------------------------

`scipy.interpolate.pade` now accepts a new argument for the order of the
numerator.

`scipy.cluster` improvements
----------------------------

`scipy.cluster.vq.kmeans2` gained a new initialization method, kmeans++.

`scipy.special` improvements
----------------------------

The function ``softmax`` was added to `scipy.special`.

`scipy.optimize` improvements
-----------------------------

The one-dimensional nonlinear solvers have been given a unified interface
`scipy.optimize.root_scalar`, similar to the `scipy.optimize.root` interface
for multi-dimensional solvers. ``scipy.optimize.root_scalar(f, bracket=[a ,b],
method="brenth")`` is equivalent to ``scipy.optimize.brenth(f, a ,b)``.  If no
``method`` is specified, an appropriate one will be selected based upon the
bracket and the number of derivatives available.

The so-called Algorithm 748 of Alefeld, Potra and Shi for root-finding within
an enclosing interval has been added as `scipy.optimize.toms748`. This provides
guaranteed convergence to a root with convergence rate per function evaluation
of approximately 1.65 (for sufficiently well-behaved functions).

``differential_evolution`` now has the ``updating`` and ``workers`` keywords.
The first chooses between continuous updating of the best solution vector (the
default), or once per generation. Continuous updating can lead to faster
convergence. The ``workers`` keyword accepts an ``int`` or map-like callable,
and parallelises the solver (having the side effect of updating once per
generation). Supplying an ``int`` evaluates the trial solutions in N parallel
parts. Supplying a map-like callable allows other parallelisation approaches
(such as ``mpi4py``, or ``joblib``) to be used.

``dual_annealing`` (and ``shgo`` below) is a powerful new general-purpose
global optizimation (GO) algorithm. ``dual_annealing`` uses two annealing
processes to accelerate the convergence towards the global minimum of an
objective mathematical function. The first annealing process controls the
stochastic Markov chain searching and the second annealing process controls the
deterministic minimization. So, dual annealing is a hybrid method that takes
advantage of stochastic and local deterministic searching in an efficient way.

``shgo`` (simplicial homology global optimization) is a similar algorithm
appropriate for solving black box and derivative-free optimization (DFO)
problems. The algorithm generally converges to the global solution in finite
time. The convergence holds for non-linear inequality and
equality constraints. In addition to returning a global minimum, the
algorithm also returns any other global and local minima found after every
iteration. This makes it useful for exploring the solutions in a domain.

`scipy.optimize.newton` can now accept a scalar or an array.

``MINPACK`` usage is now thread-safe, such that ``MINPACK`` + callbacks may
be used on multiple threads.

`scipy.signal` improvements
---------------------------

Digital filter design functions now include a parameter to specify the sampling
rate. Previously, digital filters could only be specified using normalized
frequency, but different functions used different scales (e.g. 0 to 1 for
``butter`` vs 0 to π for ``freqz``), leading to errors and confusion.  With
the ``fs`` parameter, ordinary frequencies can now be entered directly into
functions, with the normalization handled internally.

``find_peaks`` and related functions no longer raise an exception if the
properties of a peak have unexpected values (e.g. a prominence of 0). A
``PeakPropertyWarning`` is given instead.

The new keyword argument ``plateau_size`` was added to ``find_peaks``.
``plateau_size`` may be used to select peaks based on the length of the
flat top of a peak.

``welch()`` and ``csd()`` methods in `scipy.signal` now support calculation
of a median average PSD, using ``average='mean'`` keyword.

`scipy.sparse` improvements
---------------------------

The `scipy.sparse.bsr_matrix.tocsr` method is now implemented directly instead
of converting via COO format, and the `scipy.sparse.bsr_matrix.tocsc` method
is now also routed via CSR conversion instead of COO. The efficiency of both
conversions is now improved.

The issue where SuperLU or UMFPACK solvers crashed on matrices with
non-canonical format in `scipy.sparse.linalg` was fixed. The solver wrapper
canonicalizes the matrix if necessary before calling the SuperLU or UMFPACK
solver.

The ``largest`` option of `scipy.sparse.linalg.lobpcg()` was fixed to have
a correct (and expected) behavior. The order of the eigenvalues was made
consistent with the ARPACK solver (``eigs()``), i.e. ascending for the
smallest eigenvalues, and descending for the largest eigenvalues.

The `scipy.sparse.random` function is now faster and also supports integer and
complex values by passing the appropriate value to the ``dtype`` argument.

`scipy.spatial` improvements
----------------------------

The function `scipy.spatial.distance.jaccard` was modified to return 0 instead
of ``np.nan`` when two all-zero vectors are compared.

Support for the Jensen Shannon distance, the square-root of the divergence, has
been added under `scipy.spatial.distance.jensenshannon`.

An optional keyword was added to the function
`scipy.spatial.cKDTree.query_ball_point()` to sort or not sort the returned
indices. Not sorting the indices can speed up calls.

A new category of quaternion-based transformations are available in
`scipy.spatial.transform`, including spherical linear interpolation of
rotations (``Slerp``), conversions to and from quaternions, Euler angles,
and general rotation and inversion capabilities
(`spatial.transform.Rotation`), and uniform random sampling of 3D
rotations (`spatial.transform.Rotation.random`).

`scipy.stats` improvements
--------------------------

The Yeo-Johnson power transformation is now supported (``yeojohnson``,
``yeojohnson_llf``, ``yeojohnson_normmax``, ``yeojohnson_normplot``). Unlike
the Box-Cox transformation, the Yeo-Johnson transformation can accept negative
values.

Added a general method to sample random variates based on the density only, in
the new function ``rvs_ratio_uniforms``.

The Yule-Simon distribution (``yulesimon``) was added -- this is a new
discrete probability distribution.

``stats`` and ``mstats`` now have access to a new regression method,
``siegelslopes``, a robust linear regression algorithm

`scipy.stats.gaussian_kde` now has the ability to deal with weighted samples,
and should have a modest improvement in performance

Levy Stable Parameter Estimation, PDF, and CDF calculations are now supported
for `scipy.stats.levy_stable`.

The Brunner-Munzel test is now available as ``brunnermunzel`` in ``stats``
and ``mstats``.

`scipy.linalg` improvements
---------------------------

`scipy.linalg.lapack` now exposes the LAPACK routines using the Rectangular
Full Packed storage (RFP) for upper triangular, lower triangular, symmetric,
or Hermitian matrices; the upper trapezoidal fat matrix RZ decomposition
routines are now available as well.

Deprecated features
===================
The functions ``hyp2f0``, ``hyp1f2`` and ``hyp3f0`` in ``scipy.special`` have
been deprecated.


Backwards-incompatible changes
==============================

LAPACK version 3.4.0 or later is now required. Building with
Apple Accelerate is no longer supported.

The function ``scipy.linalg.subspace_angles(A, B)`` now gives correct
results for all angles. Before this, the function only returned
correct values for those angles which were greater than π/4.

Support for the Bento build system has been removed. Bento had not been
maintained for several years, and did not have good Python 3 or wheel support,
hence it was time to remove it.

The required signature of `scipy.optimize.lingprog` ``method=simplex``
callback function has changed. Before iteration begins, the simplex solver
first converts the problem into a standard form that does not, in general,
have the same variables or constraints
as the problem defined by the user. Previously, the simplex solver would pass a
user-specified callback function several separate arguments, such as the
current solution vector ``xk``, corresponding to this standard-form problem.
Unfortunately, the relationship between the standard-form problem and the
user-defined problem was not documented, limiting the utility of the
information passed to the callback function.

In addition to numerous bug-fix changes, the simplex solver now passes a
user-specified callback function a single ``OptimizeResult`` object containing
information that corresponds directly to the user-defined problem. In future
releases, this ``OptimizeResult`` object may be expanded to include additional
information, such as variables corresponding to the standard-form problem and
information concerning the relationship between the standard-form and
user-defined problems.

The implementation of `scipy.sparse.random` has changed, and this affects the
numerical values returned for both ``sparse.random`` and ``sparse.rand`` for
some matrix shapes and a given seed.

`scipy.optimize.newton` will no longer use Halley's method in cases where it
negatively impacts convergence.


Authors
=======

* @endolith
* @luzpaz
* Hameer Abbasi +
* akahard2dj +
* Anton Akhmerov
* Joseph Albert
* alexthomas93 +
* ashish +
* atpage +
* Blair Azzopardi +
* Yoshiki Vázquez Baeza
* Bence Bagi +
* Christoph Baumgarten
* Lucas Bellomo +
* BH4 +
* Aditya Bharti
* Max Bolingbroke
* François Boulogne
* Ward Bradt +
* Matthew Brett
* Evgeni Burovski
* Rafał Byczek +
* Alfredo Canziani +
* CJ Carey
* Lucía Cheung +
* Poom Chiarawongse +
* Jeanne Choo +
* Robert Cimrman
* Graham Clenaghan +
* cynthia-rempel +
* Johannes Damp +
* Jaime Fernandez del Rio
* Dowon +
* emmi474 +
* Stefan Endres +
* Thomas Etherington +
* Piotr Figiel
* Alex Fikl +
* fo40225 +
* Joseph Fox-Rabinovitz
* Lars G
* Abhinav Gautam +
* Stiaan Gerber +
* C.A.M. Gerlach +
* Ralf Gommers
* Todd Goodall
* Lars Grueter +
* Sylvain Gubian +
* Matt Haberland
* David Hagen
* Will Handley +
* Charles Harris
* Ian Henriksen
* Thomas Hisch +
* Theodore Hu
* Michael Hudson-Doyle +
* Nicolas Hug +
* jakirkham +
* Jakob Jakobson +
* James +
* Jan Schlüter
* jeanpauphilet +
* josephmernst +
* Kai +
* Kai-Striega +
* kalash04 +
* Toshiki Kataoka +
* Konrad0 +
* Tom Krauss +
* Johannes Kulick
* Lars Grüter +
* Eric Larson
* Denis Laxalde
* Will Lee +
* Katrin Leinweber +
* Yin Li +
* P. L. Lim +
* Jesse Livezey +
* Duncan Macleod +
* MatthewFlamm +
* Nikolay Mayorov
* Mike McClurg +
* Christian Meyer +
* Mark Mikofski
* Naoto Mizuno +
* mohmmadd +
* Nathan Musoke
* Anju Geetha Nair +
* Andrew Nelson
* Ayappan P +
* Nick Papior
* Haesun Park +
* Ronny Pfannschmidt +
* pijyoi +
* Ilhan Polat
* Anthony Polloreno +
* Ted Pudlik
* puenka
* Eric Quintero
* Pradeep Reddy Raamana +
* Vyas Ramasubramani +
* Ramon Viñas +
* Tyler Reddy
* Joscha Reimer
* Antonio H Ribeiro
* richardjgowers +
* Rob +
* robbystk +
* Lucas Roberts +
* rohan +
* Joaquin Derrac Rus +
* Josua Sassen +
* Bruce Sharpe +
* Max Shinn +
* Scott Sievert
* Sourav Singh
* Strahinja Lukić +
* Kai Striega +
* Shinya SUZUKI +
* Mike Toews +
* Piotr Uchwat
* Miguel de Val-Borro +
* Nicky van Foreest
* Paul van Mulbregt
* Gael Varoquaux
* Pauli Virtanen
* Stefan van der Walt
* Warren Weckesser
* Joshua Wharton +
* Bernhard M. Wiedemann +
* Eric Wieser
* Josh Wilson
* Tony Xiang +
* Roman Yurchak +
* Roy Zywina +

A total of 137 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.2.0
-----------------------

* `#9520 <https://github.com/scipy/scipy/issues/9520>`__: signal.correlate with method='fft' doesn't benefit from long...
* `#9547 <https://github.com/scipy/scipy/issues/9547>`__: signature of dual_annealing doesn't match other optimizers
* `#9540 <https://github.com/scipy/scipy/issues/9540>`__: SciPy v1.2.0rc1 cannot be imported on Python 2.7.15
* `#1240 <https://github.com/scipy/scipy/issues/1240>`__: Allowing multithreaded use of minpack through scipy.optimize...
* `#1432 <https://github.com/scipy/scipy/issues/1432>`__: scipy.stats.mode extremely slow (Trac #905)
* `#3372 <https://github.com/scipy/scipy/issues/3372>`__: Please add Sphinx search field to online scipy html docs
* `#3678 <https://github.com/scipy/scipy/issues/3678>`__: _clough_tocher_2d_single direction between centroids
* `#4174 <https://github.com/scipy/scipy/issues/4174>`__: lobpcg "largest" option invalid?
* `#5493 <https://github.com/scipy/scipy/issues/5493>`__: anderson_ksamp p-values>1
* `#5743 <https://github.com/scipy/scipy/issues/5743>`__: slsqp fails to detect infeasible problem
* `#6139 <https://github.com/scipy/scipy/issues/6139>`__: scipy.optimize.linprog failed to find a feasible starting point...
* `#6358 <https://github.com/scipy/scipy/issues/6358>`__: stats: docstring for `vonmises_line` points to `vonmises_line`...
* `#6498 <https://github.com/scipy/scipy/issues/6498>`__: runtests.py is missing in pypi distfile
* `#7426 <https://github.com/scipy/scipy/issues/7426>`__: scipy.stats.ksone(n).pdf(x) returns nan for positive values of...
* `#7455 <https://github.com/scipy/scipy/issues/7455>`__: scipy.stats.ksone.pdf(2,x) return incorrect values for x near...
* `#7456 <https://github.com/scipy/scipy/issues/7456>`__: scipy.special.smirnov and scipy.special.smirnovi have accuracy...
* `#7492 <https://github.com/scipy/scipy/issues/7492>`__: scipy.special.kolmogorov(x)/kolmogi(p) inefficient, inaccurate...
* `#7914 <https://github.com/scipy/scipy/issues/7914>`__: TravisCI not failing when it should for -OO run
* `#8064 <https://github.com/scipy/scipy/issues/8064>`__: linalg.solve test crashes on Windows
* `#8212 <https://github.com/scipy/scipy/issues/8212>`__: LAPACK Rectangular Full Packed routines
* `#8256 <https://github.com/scipy/scipy/issues/8256>`__: differential_evolution bug converges to wrong results in complex...
* `#8443 <https://github.com/scipy/scipy/issues/8443>`__: Deprecate `hyp2f0`, `hyp1f2`, and `hyp3f0`?
* `#8452 <https://github.com/scipy/scipy/issues/8452>`__: DOC: ARPACK tutorial has two conflicting equations
* `#8680 <https://github.com/scipy/scipy/issues/8680>`__: scipy fails compilation when building from source
* `#8686 <https://github.com/scipy/scipy/issues/8686>`__: Division by zero in _trustregion.py when x0 is exactly equal...
* `#8700 <https://github.com/scipy/scipy/issues/8700>`__: _MINPACK_LOCK not held when calling into minpack from least_squares
* `#8786 <https://github.com/scipy/scipy/issues/8786>`__: erroneous moment values for t-distribution
* `#8791 <https://github.com/scipy/scipy/issues/8791>`__: Checking COLA condition in istft should be optional (or omitted)
* `#8843 <https://github.com/scipy/scipy/issues/8843>`__: imresize cannot be deprecated just yet
* `#8844 <https://github.com/scipy/scipy/issues/8844>`__: Inverse Wishart Log PDF Incorrect for Non-diagonal Scale Matrix?
* `#8878 <https://github.com/scipy/scipy/issues/8878>`__: vonmises and vonmises_line in stats: vonmises wrong and superfluous?
* `#8895 <https://github.com/scipy/scipy/issues/8895>`__: v1.1.0 `ndi.rotate` documentation – reused parameters not filled...
* `#8900 <https://github.com/scipy/scipy/issues/8900>`__: Missing complex conjugation in scipy.sparse.linalg.LinearOperator
* `#8904 <https://github.com/scipy/scipy/issues/8904>`__: BUG: if zero derivative at root, then Newton fails with RuntimeWarning
* `#8911 <https://github.com/scipy/scipy/issues/8911>`__: make_interp_spline bc_type incorrect input interpretation
* `#8942 <https://github.com/scipy/scipy/issues/8942>`__: MAINT: Refactor `_linprog.py` and `_linprog_ip.py` to remove...
* `#8947 <https://github.com/scipy/scipy/issues/8947>`__: np.int64 in scipy.fftpack.next_fast_len
* `#9020 <https://github.com/scipy/scipy/issues/9020>`__: BUG: linalg.subspace_angles gives wrong results
* `#9033 <https://github.com/scipy/scipy/issues/9033>`__: scipy.stats.normaltest sometimes gives incorrect returns b/c...
* `#9036 <https://github.com/scipy/scipy/issues/9036>`__: Bizarre times for `scipy.sparse.rand` function with 'low' density...
* `#9044 <https://github.com/scipy/scipy/issues/9044>`__: optimize.minimize(method=`trust-constr`) result dict does not...
* `#9071 <https://github.com/scipy/scipy/issues/9071>`__: doc/linalg: add cho_solve_banded to see also of cholesky_banded
* `#9082 <https://github.com/scipy/scipy/issues/9082>`__: eigenvalue sorting in scipy.sparse.linalg.eigsh
* `#9086 <https://github.com/scipy/scipy/issues/9086>`__: signaltools.py:491: FutureWarning: Using a non-tuple sequence...
* `#9091 <https://github.com/scipy/scipy/issues/9091>`__: test_spline_filter failure on 32-bit
* `#9122 <https://github.com/scipy/scipy/issues/9122>`__: Typo on scipy minimization tutorial
* `#9135 <https://github.com/scipy/scipy/issues/9135>`__: doc error at https://docs.scipy.org/doc/scipy/reference/tutorial/stats/discrete_poisson.html
* `#9167 <https://github.com/scipy/scipy/issues/9167>`__: DOC: BUG: typo in ndimage LowLevelCallable tutorial example
* `#9169 <https://github.com/scipy/scipy/issues/9169>`__: truncnorm does not work if b < a in scipy.stats
* `#9250 <https://github.com/scipy/scipy/issues/9250>`__: scipy.special.tests.test_mpmath::TestSystematic::test_pcfw fails...
* `#9259 <https://github.com/scipy/scipy/issues/9259>`__: rv.expect() == rv.mean() is false for rv.mean() == nan (and inf)
* `#9286 <https://github.com/scipy/scipy/issues/9286>`__: DOC: Rosenbrock expression in optimize.minimize tutorial
* `#9316 <https://github.com/scipy/scipy/issues/9316>`__: SLSQP fails in nested optimization
* `#9337 <https://github.com/scipy/scipy/issues/9337>`__: scipy.signal.find_peaks key typo in documentation
* `#9345 <https://github.com/scipy/scipy/issues/9345>`__: Example from documentation of scipy.sparse.linalg.eigs raises...
* `#9383 <https://github.com/scipy/scipy/issues/9383>`__: Default value for "mode" in "ndimage.shift"
* `#9419 <https://github.com/scipy/scipy/issues/9419>`__: dual_annealing off by one in the number of iterations
* `#9442 <https://github.com/scipy/scipy/issues/9442>`__: Error in Defintion of Rosenbrock Function
* `#9453 <https://github.com/scipy/scipy/issues/9453>`__: TST: test_eigs_consistency() doesn't have consistent results


Pull requests for 1.2.0
-----------------------

* `#9526 <https://github.com/scipy/scipy/pull/9526>`__: TST: relax precision requirements in signal.correlate tests
* `#9507 <https://github.com/scipy/scipy/pull/9507>`__: CI: MAINT: Skip a ckdtree test on pypy
* `#9512 <https://github.com/scipy/scipy/pull/9512>`__: TST: test_random_sampling 32-bit handling
* `#9494 <https://github.com/scipy/scipy/pull/9494>`__: TST: test_kolmogorov xfail 32-bit
* `#9486 <https://github.com/scipy/scipy/pull/9486>`__: BUG: fix sparse random int handling
* `#9550 <https://github.com/scipy/scipy/pull/9550>`__: BUG: scipy/_lib/_numpy_compat: get_randint
* `#9549 <https://github.com/scipy/scipy/pull/9549>`__: MAINT: make dual_annealing signature match other optimizers
* `#9541 <https://github.com/scipy/scipy/pull/9541>`__: BUG: fix SyntaxError due to non-ascii character on Python 2.7
* `#7352 <https://github.com/scipy/scipy/pull/7352>`__: ENH: add Brunner Munzel test to scipy.stats.
* `#7373 <https://github.com/scipy/scipy/pull/7373>`__: BUG: Jaccard distance for all-zero arrays would return np.nan
* `#7374 <https://github.com/scipy/scipy/pull/7374>`__: ENH: Add PDF, CDF and parameter estimation for Stable Distributions
* `#8098 <https://github.com/scipy/scipy/pull/8098>`__: ENH: Add shgo for global optimization of NLPs.
* `#8203 <https://github.com/scipy/scipy/pull/8203>`__: ENH: adding simulated dual annealing to optimize
* `#8259 <https://github.com/scipy/scipy/pull/8259>`__: Option to follow original Storn and Price algorithm and its parallelisation
* `#8293 <https://github.com/scipy/scipy/pull/8293>`__: ENH add ratio-of-uniforms method for rv generation to scipy.stats
* `#8294 <https://github.com/scipy/scipy/pull/8294>`__: BUG: Fix slowness in stats.mode
* `#8295 <https://github.com/scipy/scipy/pull/8295>`__: ENH: add Jensen Shannon distance to `scipy.spatial.distance`
* `#8357 <https://github.com/scipy/scipy/pull/8357>`__: ENH: vectorize scalar zero-search-functions
* `#8397 <https://github.com/scipy/scipy/pull/8397>`__: Add `fs=` parameter to filter design functions
* `#8537 <https://github.com/scipy/scipy/pull/8537>`__: ENH: Implement mode parameter for spline filtering.
* `#8558 <https://github.com/scipy/scipy/pull/8558>`__: ENH: small speedup for stats.gaussian_kde
* `#8560 <https://github.com/scipy/scipy/pull/8560>`__: BUG: fix p-value calc of anderson_ksamp in scipy.stats
* `#8614 <https://github.com/scipy/scipy/pull/8614>`__: ENH: correct p-values for stats.kendalltau and stats.mstats.kendalltau
* `#8670 <https://github.com/scipy/scipy/pull/8670>`__: ENH: Require Lapack 3.4.0
* `#8683 <https://github.com/scipy/scipy/pull/8683>`__: Correcting kmeans documentation
* `#8725 <https://github.com/scipy/scipy/pull/8725>`__: MAINT: Cleanup scipy.optimize.leastsq
* `#8726 <https://github.com/scipy/scipy/pull/8726>`__: BUG: Fix _get_output in scipy.ndimage to support string
* `#8733 <https://github.com/scipy/scipy/pull/8733>`__: MAINT: stats: A bit of clean up.
* `#8737 <https://github.com/scipy/scipy/pull/8737>`__: BUG: Improve numerical precision/convergence failures of smirnov/kolmogorov
* `#8738 <https://github.com/scipy/scipy/pull/8738>`__: MAINT: stats: A bit of clean up in test_distributions.py.
* `#8740 <https://github.com/scipy/scipy/pull/8740>`__: BF/ENH: make minpack thread safe
* `#8742 <https://github.com/scipy/scipy/pull/8742>`__: BUG: Fix division by zero in trust-region optimization methods
* `#8746 <https://github.com/scipy/scipy/pull/8746>`__: MAINT: signal: Fix a docstring of a private function, and fix...
* `#8750 <https://github.com/scipy/scipy/pull/8750>`__: DOC clarified description of norminvgauss in scipy.stats
* `#8753 <https://github.com/scipy/scipy/pull/8753>`__: DOC: signal: Fix a plot title in the chirp docstring.
* `#8755 <https://github.com/scipy/scipy/pull/8755>`__: DOC: MAINT: Fix link to the wheel documentation in developer...
* `#8760 <https://github.com/scipy/scipy/pull/8760>`__: BUG: stats: boltzmann wasn't setting the upper bound.
* `#8763 <https://github.com/scipy/scipy/pull/8763>`__: [DOC] Improved scipy.cluster.hierarchy documentation
* `#8765 <https://github.com/scipy/scipy/pull/8765>`__: DOC: added example for scipy.stat.mstats.tmin
* `#8788 <https://github.com/scipy/scipy/pull/8788>`__: DOC: fix definition of optional `disp` parameter
* `#8802 <https://github.com/scipy/scipy/pull/8802>`__: MAINT: Suppress dd_real unused function compiler warnings.
* `#8803 <https://github.com/scipy/scipy/pull/8803>`__: ENH: Add full_output support to optimize.newton()
* `#8804 <https://github.com/scipy/scipy/pull/8804>`__: MAINT: stats cleanup
* `#8808 <https://github.com/scipy/scipy/pull/8808>`__: DOC: add note about isinstance for frozen rvs
* `#8812 <https://github.com/scipy/scipy/pull/8812>`__: Updated numpydoc submodule
* `#8813 <https://github.com/scipy/scipy/pull/8813>`__: MAINT: stats: Fix multinomial docstrings, and do some clean up.
* `#8816 <https://github.com/scipy/scipy/pull/8816>`__: BUG: fixed _stats of t-distribution in scipy.stats
* `#8817 <https://github.com/scipy/scipy/pull/8817>`__: BUG: ndimage: Fix validation of the origin argument in correlate...
* `#8822 <https://github.com/scipy/scipy/pull/8822>`__: BUG: integrate: Fix crash with repeated t values in odeint.
* `#8832 <https://github.com/scipy/scipy/pull/8832>`__: Hyperlink DOIs against preferred resolver
* `#8837 <https://github.com/scipy/scipy/pull/8837>`__: BUG: sparse: Ensure correct dtype for sparse comparison operations.
* `#8839 <https://github.com/scipy/scipy/pull/8839>`__: DOC: stats: A few tweaks to the linregress docstring.
* `#8846 <https://github.com/scipy/scipy/pull/8846>`__: BUG: stats: Fix logpdf method of invwishart.
* `#8849 <https://github.com/scipy/scipy/pull/8849>`__: DOC: signal: Fixed mistake in the firwin docstring.
* `#8854 <https://github.com/scipy/scipy/pull/8854>`__: DOC: fix type descriptors in ltisys documentation
* `#8865 <https://github.com/scipy/scipy/pull/8865>`__: Fix tiny typo in docs for chi2 pdf
* `#8870 <https://github.com/scipy/scipy/pull/8870>`__: Fixes related to invertibility of STFT
* `#8872 <https://github.com/scipy/scipy/pull/8872>`__: ENH: special: Add the softmax function
* `#8874 <https://github.com/scipy/scipy/pull/8874>`__: DOC correct gamma function in docstrings in scipy.stats
* `#8876 <https://github.com/scipy/scipy/pull/8876>`__: ENH: Added TOMS Algorithm 748 as 1-d root finder; 17 test function...
* `#8882 <https://github.com/scipy/scipy/pull/8882>`__: ENH: Only use Halley's adjustment to Newton if close enough.
* `#8883 <https://github.com/scipy/scipy/pull/8883>`__: FIX: optimize: make jac and hess truly optional for 'trust-constr'
* `#8885 <https://github.com/scipy/scipy/pull/8885>`__: TST: Do not error on warnings raised about non-tuple indexing.
* `#8887 <https://github.com/scipy/scipy/pull/8887>`__: MAINT: filter out np.matrix PendingDeprecationWarning's in numpy...
* `#8889 <https://github.com/scipy/scipy/pull/8889>`__: DOC: optimize: separate legacy interfaces from new ones
* `#8890 <https://github.com/scipy/scipy/pull/8890>`__: ENH: Add optimize.root_scalar() as a universal dispatcher for...
* `#8899 <https://github.com/scipy/scipy/pull/8899>`__: DCT-IV, DST-IV and DCT-I, DST-I orthonormalization support in...
* `#8901 <https://github.com/scipy/scipy/pull/8901>`__: MAINT: Reorganize flapack.pyf.src file
* `#8907 <https://github.com/scipy/scipy/pull/8907>`__: BUG: ENH: Check if guess for newton is already zero before checking...
* `#8908 <https://github.com/scipy/scipy/pull/8908>`__: ENH: Make sorting optional for cKDTree.query_ball_point()
* `#8910 <https://github.com/scipy/scipy/pull/8910>`__: DOC: sparse.csgraph simple examples.
* `#8914 <https://github.com/scipy/scipy/pull/8914>`__: DOC: interpolate: fix equivalences of string aliases
* `#8918 <https://github.com/scipy/scipy/pull/8918>`__: add float_control(precise, on) to _fpumode.c
* `#8919 <https://github.com/scipy/scipy/pull/8919>`__: MAINT: interpolate: improve error messages for common `bc_type`...
* `#8920 <https://github.com/scipy/scipy/pull/8920>`__: DOC: update Contributing to SciPy to say "prefer no PEP8 only...
* `#8924 <https://github.com/scipy/scipy/pull/8924>`__: MAINT: special: deprecate `hyp2f0`, `hyp1f2`, and `hyp3f0`
* `#8927 <https://github.com/scipy/scipy/pull/8927>`__: MAINT: special: remove `errprint`
* `#8932 <https://github.com/scipy/scipy/pull/8932>`__: Fix broadcasting scale arg of entropy
* `#8936 <https://github.com/scipy/scipy/pull/8936>`__: Fix (some) non-tuple index warnings
* `#8937 <https://github.com/scipy/scipy/pull/8937>`__: ENH: implement sparse matrix BSR to CSR conversion directly.
* `#8938 <https://github.com/scipy/scipy/pull/8938>`__: DOC: add @_ni_docstrings.docfiller in ndimage.rotate
* `#8940 <https://github.com/scipy/scipy/pull/8940>`__: Update _discrete_distns.py
* `#8943 <https://github.com/scipy/scipy/pull/8943>`__: DOC: Finish dangling sentence in `convolve` docstring
* `#8944 <https://github.com/scipy/scipy/pull/8944>`__: MAINT: Address tuple indexing and warnings
* `#8945 <https://github.com/scipy/scipy/pull/8945>`__: ENH: spatial.transform.Rotation [GSOC2018]
* `#8950 <https://github.com/scipy/scipy/pull/8950>`__: csgraph Dijkstra function description rewording
* `#8953 <https://github.com/scipy/scipy/pull/8953>`__: DOC, MAINT: HTTP -> HTTPS, and other linkrot fixes
* `#8955 <https://github.com/scipy/scipy/pull/8955>`__: BUG: np.int64 in scipy.fftpack.next_fast_len
* `#8958 <https://github.com/scipy/scipy/pull/8958>`__: MAINT: Add more descriptive error message for phase one simplex.
* `#8962 <https://github.com/scipy/scipy/pull/8962>`__: BUG: sparse.linalg: add missing conjugate to _ScaledLinearOperator.adjoint
* `#8963 <https://github.com/scipy/scipy/pull/8963>`__: BUG: sparse.linalg: downgrade LinearOperator TypeError to warning
* `#8965 <https://github.com/scipy/scipy/pull/8965>`__: ENH: Wrapped RFP format and RZ decomposition routines
* `#8969 <https://github.com/scipy/scipy/pull/8969>`__: MAINT: doc and code fixes for optimize.newton
* `#8970 <https://github.com/scipy/scipy/pull/8970>`__: Added 'average' keyword for welch/csd to enable median averaging
* `#8971 <https://github.com/scipy/scipy/pull/8971>`__: Better imresize deprecation warning
* `#8972 <https://github.com/scipy/scipy/pull/8972>`__: MAINT: Switch np.where(c) for np.nonzero(c)
* `#8975 <https://github.com/scipy/scipy/pull/8975>`__: MAINT: Fix warning-based failures
* `#8979 <https://github.com/scipy/scipy/pull/8979>`__: DOC: fix description of count_sort keyword of dendrogram
* `#8982 <https://github.com/scipy/scipy/pull/8982>`__: MAINT: optimize: Fixed minor mistakes in test_linprog.py (#8978)
* `#8984 <https://github.com/scipy/scipy/pull/8984>`__: BUG: sparse.linalg: ensure expm casts integer inputs to float
* `#8986 <https://github.com/scipy/scipy/pull/8986>`__: BUG: optimize/slsqp: do not exit with convergence on steps where...
* `#8989 <https://github.com/scipy/scipy/pull/8989>`__: MAINT: use collections.abc in basinhopping
* `#8990 <https://github.com/scipy/scipy/pull/8990>`__: ENH extend p-values of anderson_ksamp in scipy.stats
* `#8991 <https://github.com/scipy/scipy/pull/8991>`__: ENH: Weighted kde
* `#8993 <https://github.com/scipy/scipy/pull/8993>`__: ENH: spatial.transform.Rotation.random [GSOC 2018]
* `#8994 <https://github.com/scipy/scipy/pull/8994>`__: ENH: spatial.transform.Slerp [GSOC 2018]
* `#8995 <https://github.com/scipy/scipy/pull/8995>`__: TST: time.time in test
* `#9007 <https://github.com/scipy/scipy/pull/9007>`__: Fix typo in fftpack.rst
* `#9013 <https://github.com/scipy/scipy/pull/9013>`__: Added correct plotting code for two sided output from spectrogram
* `#9014 <https://github.com/scipy/scipy/pull/9014>`__: BUG: differential_evolution with inf objective functions
* `#9017 <https://github.com/scipy/scipy/pull/9017>`__: BUG: fixed #8446 corner case for asformat(array|dense)
* `#9018 <https://github.com/scipy/scipy/pull/9018>`__: MAINT: _lib/ccallback: remove unused code
* `#9021 <https://github.com/scipy/scipy/pull/9021>`__: BUG: Issue with subspace_angles
* `#9022 <https://github.com/scipy/scipy/pull/9022>`__: DOC: Added "See Also" section to lombscargle docstring
* `#9034 <https://github.com/scipy/scipy/pull/9034>`__: BUG: Fix tolerance printing behavior, remove meaningless tol...
* `#9035 <https://github.com/scipy/scipy/pull/9035>`__: TST: improve signal.bsplines test coverage
* `#9037 <https://github.com/scipy/scipy/pull/9037>`__: ENH: add a new init method for k-means
* `#9039 <https://github.com/scipy/scipy/pull/9039>`__: DOC: Add examples to fftpack.irfft docstrings
* `#9048 <https://github.com/scipy/scipy/pull/9048>`__: ENH: scipy.sparse.random
* `#9050 <https://github.com/scipy/scipy/pull/9050>`__: BUG: scipy.io.hb_write: fails for matrices not in csc format
* `#9051 <https://github.com/scipy/scipy/pull/9051>`__: MAINT: Fix slow sparse.rand for k < mn/3 (#9036).
* `#9054 <https://github.com/scipy/scipy/pull/9054>`__: MAINT: spatial: Explicitly initialize LAPACK output parameters.
* `#9055 <https://github.com/scipy/scipy/pull/9055>`__: DOC: Add examples to scipy.special docstrings
* `#9056 <https://github.com/scipy/scipy/pull/9056>`__: ENH: Use one thread in OpenBLAS
* `#9059 <https://github.com/scipy/scipy/pull/9059>`__: DOC: Update README with link to Code of Conduct
* `#9060 <https://github.com/scipy/scipy/pull/9060>`__: BLD: remove support for the Bento build system.
* `#9062 <https://github.com/scipy/scipy/pull/9062>`__: DOC add sections to overview in scipy.stats
* `#9066 <https://github.com/scipy/scipy/pull/9066>`__: BUG: Correct "remez" error message
* `#9069 <https://github.com/scipy/scipy/pull/9069>`__: DOC: update linalg section of roadmap for LAPACK versions.
* `#9079 <https://github.com/scipy/scipy/pull/9079>`__: MAINT: add spatial.transform to refguide check; complete some...
* `#9081 <https://github.com/scipy/scipy/pull/9081>`__: MAINT: Add warnings if pivot value is close to tolerance in linprog(method='simplex')
* `#9084 <https://github.com/scipy/scipy/pull/9084>`__: BUG fix incorrect p-values of kurtosistest in scipy.stats
* `#9095 <https://github.com/scipy/scipy/pull/9095>`__: DOC: add sections to mstats overview in scipy.stats
* `#9096 <https://github.com/scipy/scipy/pull/9096>`__: BUG: Add test for Stackoverflow example from issue 8174.
* `#9101 <https://github.com/scipy/scipy/pull/9101>`__: ENH: add Siegel slopes (robust regression) to scipy.stats
* `#9105 <https://github.com/scipy/scipy/pull/9105>`__: allow resample_poly() to output float32 for float32 inputs.
* `#9112 <https://github.com/scipy/scipy/pull/9112>`__: MAINT: optimize: make trust-constr accept constraint dict (#9043)
* `#9118 <https://github.com/scipy/scipy/pull/9118>`__: Add doc entry to cholesky_banded
* `#9120 <https://github.com/scipy/scipy/pull/9120>`__: eigsh documentation parameters
* `#9125 <https://github.com/scipy/scipy/pull/9125>`__: interpolative: correctly reconstruct full rank matrices
* `#9126 <https://github.com/scipy/scipy/pull/9126>`__: MAINT: Use warnings for unexpected peak properties
* `#9129 <https://github.com/scipy/scipy/pull/9129>`__: BUG: Do not catch and silence KeyboardInterrupt
* `#9131 <https://github.com/scipy/scipy/pull/9131>`__: DOC: Correct the typo in scipy.optimize tutorial page
* `#9133 <https://github.com/scipy/scipy/pull/9133>`__: FIX: Avoid use of bare except
* `#9134 <https://github.com/scipy/scipy/pull/9134>`__: DOC: Update of 'return_eigenvectors' description
* `#9137 <https://github.com/scipy/scipy/pull/9137>`__: DOC: typo fixes for discrete Poisson tutorial
* `#9139 <https://github.com/scipy/scipy/pull/9139>`__: FIX: Doctest failure in optimize tutorial
* `#9143 <https://github.com/scipy/scipy/pull/9143>`__: DOC: missing sigma in Pearson r formula
* `#9145 <https://github.com/scipy/scipy/pull/9145>`__: MAINT: Refactor linear programming solvers
* `#9149 <https://github.com/scipy/scipy/pull/9149>`__: FIX: Make scipy.odr.ODR ifixx equal to its data.fix if given
* `#9156 <https://github.com/scipy/scipy/pull/9156>`__: DOC: special: Mention the sigmoid function in the expit docstring.
* `#9160 <https://github.com/scipy/scipy/pull/9160>`__: Fixed a latex delimiter error in levy()
* `#9170 <https://github.com/scipy/scipy/pull/9170>`__: DOC: correction / update of docstrings of distributions in scipy.stats
* `#9171 <https://github.com/scipy/scipy/pull/9171>`__: better description of the hierarchical clustering parameter
* `#9174 <https://github.com/scipy/scipy/pull/9174>`__: domain check for a < b in stats.truncnorm
* `#9175 <https://github.com/scipy/scipy/pull/9175>`__: DOC: Minor grammar fix
* `#9176 <https://github.com/scipy/scipy/pull/9176>`__: BUG: CloughTocher2DInterpolator: fix miscalculation at neighborless...
* `#9177 <https://github.com/scipy/scipy/pull/9177>`__: BUILD: Document the "clean" target in the doc/Makefile.
* `#9178 <https://github.com/scipy/scipy/pull/9178>`__: MAINT: make refguide-check more robust for printed numpy arrays
* `#9186 <https://github.com/scipy/scipy/pull/9186>`__: MAINT: Remove np.ediff1d occurence
* `#9188 <https://github.com/scipy/scipy/pull/9188>`__: DOC: correct typo in extending ndimage with C
* `#9190 <https://github.com/scipy/scipy/pull/9190>`__: ENH: Support specifying axes for fftconvolve
* `#9192 <https://github.com/scipy/scipy/pull/9192>`__: MAINT: optimize: fixed @pv style suggestions from #9112
* `#9200 <https://github.com/scipy/scipy/pull/9200>`__: Fix make_interp_spline(..., k=0 or 1, axis<0)
* `#9201 <https://github.com/scipy/scipy/pull/9201>`__: BUG: sparse.linalg/gmres: use machine eps in breakdown check
* `#9204 <https://github.com/scipy/scipy/pull/9204>`__: MAINT: fix up stats.spearmanr and match mstats.spearmanr with...
* `#9206 <https://github.com/scipy/scipy/pull/9206>`__: MAINT: include benchmarks and dev files in sdist.
* `#9208 <https://github.com/scipy/scipy/pull/9208>`__: TST: signal: bump bsplines test tolerance for complex data
* `#9210 <https://github.com/scipy/scipy/pull/9210>`__: TST: mark tests as slow, fix missing random seed
* `#9211 <https://github.com/scipy/scipy/pull/9211>`__: ENH: add capability to specify orders in pade func
* `#9217 <https://github.com/scipy/scipy/pull/9217>`__: MAINT: Include ``success`` and ``nit`` in OptimizeResult returned...
* `#9222 <https://github.com/scipy/scipy/pull/9222>`__: ENH: interpolate: Use scipy.spatial.distance to speed-up Rbf
* `#9229 <https://github.com/scipy/scipy/pull/9229>`__: MNT: Fix Fourier filter double case
* `#9233 <https://github.com/scipy/scipy/pull/9233>`__: BUG: spatial/distance: fix pdist/cdist performance regression...
* `#9234 <https://github.com/scipy/scipy/pull/9234>`__: FIX: Proper suppression
* `#9235 <https://github.com/scipy/scipy/pull/9235>`__: BENCH: rationalize slow benchmarks + miscellaneous fixes
* `#9238 <https://github.com/scipy/scipy/pull/9238>`__: BENCH: limit number of parameter combinations in spatial.*KDTree...
* `#9239 <https://github.com/scipy/scipy/pull/9239>`__: DOC: stats: Fix LaTeX markup of a couple distribution PDFs.
* `#9241 <https://github.com/scipy/scipy/pull/9241>`__: ENH: Evaluate plateau size during peak finding
* `#9242 <https://github.com/scipy/scipy/pull/9242>`__: ENH: stats: Implement _ppf and _logpdf for crystalball, and do...
* `#9246 <https://github.com/scipy/scipy/pull/9246>`__: DOC: Properly render versionadded directive in HTML documentation
* `#9255 <https://github.com/scipy/scipy/pull/9255>`__: DOC: mention RootResults in optimization reference guide
* `#9260 <https://github.com/scipy/scipy/pull/9260>`__: TST: relax some tolerances so tests pass with x87 math
* `#9264 <https://github.com/scipy/scipy/pull/9264>`__: TST Use assert_raises "match" parameter instead of the "message"...
* `#9267 <https://github.com/scipy/scipy/pull/9267>`__: DOC: clarify expect() return val when moment is inf/nan
* `#9272 <https://github.com/scipy/scipy/pull/9272>`__: DOC: Add description of default bounds to linprog
* `#9277 <https://github.com/scipy/scipy/pull/9277>`__: MAINT: sparse/linalg: make test deterministic
* `#9278 <https://github.com/scipy/scipy/pull/9278>`__: MAINT: interpolate: pep8 cleanup in test_polyint
* `#9279 <https://github.com/scipy/scipy/pull/9279>`__: Fixed docstring for resample
* `#9280 <https://github.com/scipy/scipy/pull/9280>`__: removed first check for float in get_sum_dtype
* `#9281 <https://github.com/scipy/scipy/pull/9281>`__: BUG: only accept 1d input for bartlett / levene in scipy.stats
* `#9282 <https://github.com/scipy/scipy/pull/9282>`__: MAINT: dense_output and t_eval are mutually exclusive inputs
* `#9283 <https://github.com/scipy/scipy/pull/9283>`__: MAINT: add docs and do some cleanups in interpolate.Rbf
* `#9288 <https://github.com/scipy/scipy/pull/9288>`__: Run distance_transform_edt tests on all types
* `#9294 <https://github.com/scipy/scipy/pull/9294>`__: DOC: fix the formula typo
* `#9298 <https://github.com/scipy/scipy/pull/9298>`__: MAINT: optimize/trust-constr: restore .niter attribute for backward-compat
* `#9299 <https://github.com/scipy/scipy/pull/9299>`__: DOC: clarification of default rvs method in scipy.stats
* `#9301 <https://github.com/scipy/scipy/pull/9301>`__: MAINT: removed unused import sys
* `#9302 <https://github.com/scipy/scipy/pull/9302>`__: MAINT: removed unused imports
* `#9303 <https://github.com/scipy/scipy/pull/9303>`__: DOC: signal: Refer to fs instead of nyq in the firwin docstring.
* `#9305 <https://github.com/scipy/scipy/pull/9305>`__: ENH: Added Yeo-Johnson power transformation
* `#9306 <https://github.com/scipy/scipy/pull/9306>`__: ENH - add dual annealing
* `#9309 <https://github.com/scipy/scipy/pull/9309>`__: ENH add the yulesimon distribution to scipy.stats
* `#9317 <https://github.com/scipy/scipy/pull/9317>`__: Nested SLSQP bug fix.
* `#9320 <https://github.com/scipy/scipy/pull/9320>`__: MAINT: stats: avoid underflow in stats.geom.ppf
* `#9326 <https://github.com/scipy/scipy/pull/9326>`__: Add example for Rosenbrock function
* `#9332 <https://github.com/scipy/scipy/pull/9332>`__: Sort file lists
* `#9340 <https://github.com/scipy/scipy/pull/9340>`__: Fix typo in find_peaks documentation
* `#9343 <https://github.com/scipy/scipy/pull/9343>`__: MAINT Use np.full when possible
* `#9344 <https://github.com/scipy/scipy/pull/9344>`__: DOC: added examples to docstring of dirichlet class
* `#9346 <https://github.com/scipy/scipy/pull/9346>`__: DOC: Fix import of scipy.sparse.linalg in example (#9345)
* `#9350 <https://github.com/scipy/scipy/pull/9350>`__: Fix interpolate read only
* `#9351 <https://github.com/scipy/scipy/pull/9351>`__: MAINT: special.erf: use the x->-x symmetry
* `#9356 <https://github.com/scipy/scipy/pull/9356>`__: Fix documentation typo
* `#9358 <https://github.com/scipy/scipy/pull/9358>`__: DOC: improve doc for ksone and kstwobign in scipy.stats
* `#9362 <https://github.com/scipy/scipy/pull/9362>`__: DOC: Change datatypes of A matrices in linprog
* `#9364 <https://github.com/scipy/scipy/pull/9364>`__: MAINT: Adds implicit none to fftpack fortran sources
* `#9369 <https://github.com/scipy/scipy/pull/9369>`__: DOC: minor tweak to CoC (updated NumFOCUS contact address).
* `#9373 <https://github.com/scipy/scipy/pull/9373>`__: Fix exception if python is called with -OO option
* `#9374 <https://github.com/scipy/scipy/pull/9374>`__: FIX: AIX compilation issue with NAN and INFINITY
* `#9376 <https://github.com/scipy/scipy/pull/9376>`__: COBLYA -> COBYLA in docs
* `#9377 <https://github.com/scipy/scipy/pull/9377>`__: DOC: Add examples integrate: fixed_quad and quadrature
* `#9379 <https://github.com/scipy/scipy/pull/9379>`__: MAINT: TST: Make tests NumPy 1.8 compatible
* `#9385 <https://github.com/scipy/scipy/pull/9385>`__: CI: On Travis matrix "OPTIMIZE=-OO" flag ignored
* `#9387 <https://github.com/scipy/scipy/pull/9387>`__: Fix defaut value for 'mode' in 'ndimage.shift' in the doc
* `#9392 <https://github.com/scipy/scipy/pull/9392>`__: BUG: rank has to be integer in rank_filter: fixed issue 9388
* `#9399 <https://github.com/scipy/scipy/pull/9399>`__: DOC: Misc. typos
* `#9400 <https://github.com/scipy/scipy/pull/9400>`__: TST: stats: Fix the expected r-value of a linregress test.
* `#9405 <https://github.com/scipy/scipy/pull/9405>`__: BUG: np.hstack does not accept generator expressions
* `#9408 <https://github.com/scipy/scipy/pull/9408>`__: ENH: linalg: Shorter ill-conditioned warning message
* `#9418 <https://github.com/scipy/scipy/pull/9418>`__: DOC: Fix ndimage docstrings and reduce doc build warnings
* `#9421 <https://github.com/scipy/scipy/pull/9421>`__: DOC: Add missing docstring examples in scipy.spatial
* `#9422 <https://github.com/scipy/scipy/pull/9422>`__: DOC: Add an example to integrate.newton_cotes
* `#9427 <https://github.com/scipy/scipy/pull/9427>`__: BUG: Fixed defect with maxiter #9419 in dual annealing
* `#9431 <https://github.com/scipy/scipy/pull/9431>`__: BENCH: Add dual annealing to scipy benchmark (see #9415)
* `#9435 <https://github.com/scipy/scipy/pull/9435>`__: DOC: Add docstring examples for stats.binom_test
* `#9443 <https://github.com/scipy/scipy/pull/9443>`__: DOC: Fix the order of indices in optimize tutorial
* `#9444 <https://github.com/scipy/scipy/pull/9444>`__: MAINT: interpolate: use operator.index for checking/coercing...
* `#9445 <https://github.com/scipy/scipy/pull/9445>`__: DOC: Added missing example to stats.mstats.kruskal
* `#9446 <https://github.com/scipy/scipy/pull/9446>`__: DOC: Add note about version changed for jaccard distance
* `#9447 <https://github.com/scipy/scipy/pull/9447>`__: BLD: version-script handling in setup.py
* `#9448 <https://github.com/scipy/scipy/pull/9448>`__: TST: skip a problematic linalg test
* `#9449 <https://github.com/scipy/scipy/pull/9449>`__: TST: fix missing seed in lobpcg test.
* `#9456 <https://github.com/scipy/scipy/pull/9456>`__: TST: test_eigs_consistency() now sorts output
==========================
SciPy 1.5.2 Release Notes
==========================

.. contents::

SciPy 1.5.2 is a bug-fix release with no new features
compared to 1.5.1.

Authors
=======

* Peter Bell
* Tobias Biester +
* Evgeni Burovski
* Thomas A Caswell
* Ralf Gommers
* Sturla Molden
* Andrew Nelson
* ofirr +
* Sambit Panda
* Ilhan Polat
* Tyler Reddy
* Atsushi Sakai
* Pauli Virtanen

A total of 13 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 1.5.2
-----------------------

* `#3847 <https://github.com/scipy/scipy/issues/3847>`__: Crash of interpolate.splprep(task=-1)
* `#7395 <https://github.com/scipy/scipy/issues/7395>`__: splprep segfaults if fixed knots are specified
* `#10761 <https://github.com/scipy/scipy/issues/10761>`__: scipy.signal.convolve2d produces incorrect values for large arrays
* `#11971 <https://github.com/scipy/scipy/issues/11971>`__: DOC: search in devdocs returns wrong link
* `#12155 <https://github.com/scipy/scipy/issues/12155>`__: BUG: Fix permutation of distance matrices in scipy.stats.multiscale_graphcorr
* `#12203 <https://github.com/scipy/scipy/issues/12203>`__: Unable to install on PyPy 7.3.1 (Python 3.6.9)
* `#12316 <https://github.com/scipy/scipy/issues/12316>`__: negative scipy.spatial.distance.correlation
* `#12422 <https://github.com/scipy/scipy/issues/12422>`__: BUG: slsqp: ValueError: failed to initialize intent(inout) array...
* `#12428 <https://github.com/scipy/scipy/issues/12428>`__: stats.truncnorm.rvs() never returns a scalar in 1.5
* `#12441 <https://github.com/scipy/scipy/issues/12441>`__: eigvalsh inconsistent eigvals= subset_by_index=
* `#12445 <https://github.com/scipy/scipy/issues/12445>`__: DOC: scipy.linalg.eigh
* `#12449 <https://github.com/scipy/scipy/issues/12449>`__: Warnings are not filtered in csr_matrix.sum()
* `#12469 <https://github.com/scipy/scipy/issues/12469>`__: SciPy 1.9 exception in LSQSphereBivariateSpline
* `#12487 <https://github.com/scipy/scipy/issues/12487>`__: BUG: optimize: incorrect result from approx_fprime
* `#12493 <https://github.com/scipy/scipy/issues/12493>`__: CI: GitHub Actions for maintenance branches
* `#12533 <https://github.com/scipy/scipy/issues/12533>`__: eigh gives incorrect results
* `#12579 <https://github.com/scipy/scipy/issues/12579>`__: BLD, MAINT: distutils issues in wheels repo

Pull requests for 1.5.2
-----------------------

* `#12156 <https://github.com/scipy/scipy/pull/12156>`__: BUG: Fix permutation of distance matrices in scipy.stats.multiscale_graphcorr
* `#12238 <https://github.com/scipy/scipy/pull/12238>`__: BUG: Use 64-bit indexing in convolve2d to avoid overflow
* `#12256 <https://github.com/scipy/scipy/pull/12256>`__: BLD: Build lsap as a single extension instead of extension +...
* `#12320 <https://github.com/scipy/scipy/pull/12320>`__: BUG: spatial: avoid returning negative correlation distance
* `#12383 <https://github.com/scipy/scipy/pull/12383>`__: ENH: Make cKDTree.tree more efficient
* `#12392 <https://github.com/scipy/scipy/pull/12392>`__: DOC: update scipy-sphinx-theme
* `#12430 <https://github.com/scipy/scipy/pull/12430>`__: BUG: truncnorm and geninvgauss never return scalars from rvs
* `#12437 <https://github.com/scipy/scipy/pull/12437>`__: BUG: optimize: cast bounds to floats in new_bounds_to_old/old_bounds_to_new
* `#12442 <https://github.com/scipy/scipy/pull/12442>`__: MAINT:linalg: Fix for input args of eigvalsh
* `#12461 <https://github.com/scipy/scipy/pull/12461>`__: MAINT: sparse: write matrix/asmatrix wrappers without warning...
* `#12478 <https://github.com/scipy/scipy/pull/12478>`__: BUG: fix array_like input defects and add tests for all functions...
* `#12488 <https://github.com/scipy/scipy/pull/12488>`__: BUG: fix approx_derivative step size. Closes #12487
* `#12500 <https://github.com/scipy/scipy/pull/12500>`__: CI: actions branch trigger fix
* `#12501 <https://github.com/scipy/scipy/pull/12501>`__: CI: actions branch trigger fix
* `#12504 <https://github.com/scipy/scipy/pull/12504>`__: BUG: cKDTreeNode use after free
* `#12529 <https://github.com/scipy/scipy/pull/12529>`__: MAINT: allow graceful docs re-upload
* `#12538 <https://github.com/scipy/scipy/pull/12538>`__: BUG:linalg: eigh type parameter handling corrected
* `#12560 <https://github.com/scipy/scipy/pull/12560>`__: MAINT: truncnorm.rvs compatibility for \`Generator\`
* `#12562 <https://github.com/scipy/scipy/pull/12562>`__: redo gh-12188: fix segfaults in splprep with fixed knots
* `#12586 <https://github.com/scipy/scipy/pull/12586>`__: BLD: Add -std=c99 to sigtools to compile with C99
* `#12590 <https://github.com/scipy/scipy/pull/12590>`__: CI: Add GCC 4.8 entry to travis build matrix
* `#12591 <https://github.com/scipy/scipy/pull/12591>`__: BLD: fix cython error on master-branch cython
==========================
SciPy 1.2.1 Release Notes
==========================

.. contents::

SciPy 1.2.1 is a bug-fix release with no new features compared to 1.2.0.
Most importantly, it solves the issue that 1.2.0 cannot be installed
from source on Python 2.7 because of non-ascii character issues.

It is also notable that SciPy 1.2.1 wheels were built with OpenBLAS
0.3.5.dev, which may alleviate some linear algebra issues observed
in SciPy 1.2.0.

Authors
=======

* Eric Larson
* Mark Mikofski
* Evgeni Burovski
* Ralf Gommers
* Eric Moore
* Tyler Reddy

Issues closed for 1.2.1
-----------------------

* `#9606 <https://github.com/scipy/scipy/issues/9606>`__: SyntaxError: Non-ASCII character '\xe2' in file scipy/stats/_continuous_distns.py on line 3346, but no encoding declared
* `#9608 <https://github.com/scipy/scipy/issues/9608>`__: Version 1.2.0 introduces `too many indices for array` error in...
* `#9709 <https://github.com/scipy/scipy/issues/9709>`__: scipy.stats.gaussian_kde normalizes the weights keyword argument...
* `#9733 <https://github.com/scipy/scipy/issues/9733>`__: scipy.linalg.qr_update gives NaN result
* `#9724 <https://github.com/scipy/scipy/issues/9724>`__: CI: Is scipy.scipy Windows Python36-32bit-full working?

Pull requests for 1.2.1
-----------------------

* `#9612 <https://github.com/scipy/scipy/pull/9612>`__: BUG: don't use array newton unless size is greater than 1
* `#9615 <https://github.com/scipy/scipy/pull/9615>`__: ENH: Add test for encoding
* `#9720 <https://github.com/scipy/scipy/pull/9720>`__: BUG: stats: weighted KDE does not modify the weights array
* `#9739 <https://github.com/scipy/scipy/pull/9739>`__: BUG: qr_updates fails if u is exactly in span Q
* `#9725 <https://github.com/scipy/scipy/pull/9725>`__: TST: pin mingw for Azure Win CI
* `#9736 <https://github.com/scipy/scipy/pull/9736>`__: TST: adjust to vmImage dispatch in Azure
* `#9681 <https://github.com/scipy/scipy/pull/9681>`__: BUG: Fix failing stats tests (partial backport)
* `#9662 <https://github.com/scipy/scipy/pull/9662>`__: TST: interpolate: avoid pytest deprecations
==========================
SciPy 1.9.0 Release Notes
==========================

.. note:: Scipy 1.9.0 is not released yet!

.. contents::

SciPy 1.9.0 is the culmination of X months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been a number of deprecations and API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning`` s).
Our development attention will now shift to bug-fix releases on the
1.9.x branch, and on adding new features on the main branch.

This release requires Python 3.8+ and NumPy 1.17.3 or greater.

For running on PyPy, PyPy3 6.0+ is required.


**************************
Highlights of this release
**************************


************
New features
************

`scipy.cluster` improvements
============================


`scipy.interpolate` improvements
================================


`scipy.linalg` improvements
===========================


`scipy.ndimage` improvements
============================


`scipy.optimize` improvements
=============================


`scipy.signal` improvements
===========================


`scipy.sparse` improvements
===========================



`scipy.spatial` improvements
============================


`scipy.special` improvements
============================


`scipy.stats` improvements
==========================

Hypothesis Tests
----------------


Sample statistics
-----------------


Statistical Distributions
-------------------------


Other
-----




*******************
Deprecated features
*******************

`scipy.linalg` deprecations
===========================


`scipy.spatial` deprecations
============================



******************************
Backwards incompatible changes
******************************

*************
Other changes
*************



*******
Authors
*******



***********************
Issues closed for 1.9.0
***********************


***********************
Pull requests for 1.9.0
***********************

==========================
SciPy 0.18.1 Release Notes
==========================

SciPy 0.18.1 is a bug-fix release with no new features compared to 0.18.0.

Authors
=======

* @kleskjr
* Evgeni Burovski
* CJ Carey
* Luca Citi +
* Yu Feng
* Ralf Gommers
* Johannes Schmitz +
* Josh Wilson
* Nathan Woods

A total of 9 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 0.18.1
------------------------

- `#6357 <https://github.com/scipy/scipy/issues/6357>`__: scipy 0.17.1 piecewise cubic hermite interpolation does not return...
- `#6420 <https://github.com/scipy/scipy/issues/6420>`__: circmean() changed behaviour from 0.17 to 0.18
- `#6421 <https://github.com/scipy/scipy/issues/6421>`__: scipy.linalg.solve_banded overwrites input 'b' when the inversion...
- `#6425 <https://github.com/scipy/scipy/issues/6425>`__: cKDTree INF bug
- `#6435 <https://github.com/scipy/scipy/issues/6435>`__: scipy.stats.ks_2samp returns different values on different computers
- `#6458 <https://github.com/scipy/scipy/issues/6458>`__: Error in scipy.integrate.dblquad when using variable integration...


Pull requests for 0.18.1
------------------------

- `#6405 <https://github.com/scipy/scipy/pull/6405>`__: BUG: sparse: fix elementwise divide for CSR/CSC
- `#6431 <https://github.com/scipy/scipy/pull/6431>`__: BUG: result for insufficient neighbours from cKDTree is wrong.
- `#6432 <https://github.com/scipy/scipy/pull/6432>`__: BUG Issue #6421: scipy.linalg.solve_banded overwrites input 'b'...
- `#6455 <https://github.com/scipy/scipy/pull/6455>`__: DOC: add links to release notes
- `#6462 <https://github.com/scipy/scipy/pull/6462>`__: BUG: interpolate: fix .roots method of PchipInterpolator
- `#6492 <https://github.com/scipy/scipy/pull/6492>`__: BUG: Fix regression in dblquad: #6458
- `#6543 <https://github.com/scipy/scipy/pull/6543>`__: fix the regression in circmean
- `#6545 <https://github.com/scipy/scipy/pull/6545>`__: Revert gh-5938, restore ks_2samp
- `#6557 <https://github.com/scipy/scipy/pull/6557>`__: Backports for 0.18.1

==========================
SciPy 0.13.1 Release Notes
==========================

SciPy 0.13.1 is a bug-fix release with no new features compared to 0.13.0.
The only changes are several fixes in ``ndimage``, one of which was a serious
regression in ``ndimage.label`` (Github issue 3025), which gave
incorrect results in 0.13.0.

Issues fixed
------------

- 3025: ``ndimage.label`` returns incorrect results in scipy 0.13.0
- 1992: ``ndimage.label`` return type changed from int32 to uint32
- 1992: ``ndimage.find_objects`` doesn't work with int32 input in some cases
==========================
SciPy 0.17.0 Release Notes
==========================

.. contents::

SciPy 0.17.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.17.x branch, and on adding
new features on the master branch.

This release requires Python 2.6, 2.7 or 3.2-3.5 and NumPy 1.6.2 or greater.

Release highlights:

    - New functions for linear and nonlinear least squares optimization with
      constraints: `scipy.optimize.lsq_linear` and
      `scipy.optimize.least_squares`
    - Support for fitting with bounds in `scipy.optimize.curve_fit`.
    - Significant improvements to `scipy.stats`, providing many functions with
      better handing of inputs which have NaNs or are empty, improved
      documentation, and consistent behavior between `scipy.stats` and
      `scipy.stats.mstats`.
    - Significant performance improvements and new functionality in
      `scipy.spatial.cKDTree`.


New features
============

`scipy.cluster` improvements
----------------------------

A new function `scipy.cluster.hierarchy.cut_tree`, which determines a cut tree
from a linkage matrix, was added.

`scipy.io` improvements
-----------------------

`scipy.io.mmwrite` gained support for symmetric sparse matrices.

``scipy.io.netcdf`` gained support for masking and scaling data based on data
attributes.

`scipy.optimize` improvements
-----------------------------

Linear assignment problem solver
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

`scipy.optimize.linear_sum_assignment` is a new function for solving the
linear sum assignment problem.  It uses the Hungarian algorithm (Kuhn-Munkres).

Least squares optimization
~~~~~~~~~~~~~~~~~~~~~~~~~~

A new function for *nonlinear* least squares optimization with constraints was
added: `scipy.optimize.least_squares`.  It provides several methods:
Levenberg-Marquardt for unconstrained problems, and two trust-region methods
for constrained ones.  Furthermore it provides different loss functions.
New trust-region methods also handle sparse Jacobians.

A new function for *linear* least squares optimization with constraints was
added: `scipy.optimize.lsq_linear`.  It provides a trust-region method as well
as an implementation of the Bounded-Variable Least-Squares (BVLS) algorithm.

`scipy.optimize.curve_fit` now supports fitting with bounds.

`scipy.signal` improvements
---------------------------

A ``mode`` keyword was added to `scipy.signal.spectrogram`, to let it return
other spectrograms than power spectral density.

`scipy.stats` improvements
--------------------------

Many functions in `scipy.stats` have gained a ``nan_policy`` keyword, which
allows specifying how to treat input with NaNs in them: propagate the NaNs,
raise an error, or omit the NaNs.

Many functions in `scipy.stats` have been improved to correctly handle input
arrays that are empty or contain infs/nans.

A number of functions with the same name in `scipy.stats` and
`scipy.stats.mstats` were changed to have matching signature and behavior.
See `gh-5474 <https://github.com/scipy/scipy/issues/5474>`__ for details.

`scipy.stats.binom_test` and `scipy.stats.mannwhitneyu` gained a keyword
``alternative``, which allows specifying the hypothesis to test for.
Eventually all hypothesis testing functions will get this keyword.

For methods of many continuous distributions, complex input is now accepted.

Matrix normal distribution has been implemented as `scipy.stats.matrix_normal`.

`scipy.sparse` improvements
---------------------------

The `axis` keyword was added to sparse norms, `scipy.sparse.linalg.norm`.

`scipy.spatial` improvements
----------------------------

`scipy.spatial.cKDTree` was partly rewritten for improved performance and
several new features were added to it:

- the ``query_ball_point`` method became significantly faster
- ``query`` and ``query_ball_point`` gained an ``n_jobs`` keyword for parallel
  execution
- build and query methods now release the GIL
- full pickling support
- support for periodic spaces
- the ``sparse_distance_matrix`` method can now return and sparse matrix type

`scipy.interpolate` improvements
--------------------------------

Out-of-bounds behavior of `scipy.interpolate.interp1d` has been improved.
Use a two-element tuple for the ``fill_value`` argument to specify separate
fill values for input below and above the interpolation range.
Linear and nearest interpolation kinds of `scipy.interpolate.interp1d` support
extrapolation via the ``fill_value="extrapolate"`` keyword.

``fill_value`` can also be set to an array-like (or a two-element tuple of
array-likes for separate below and above values) so long as it broadcasts
properly to the non-interpolated dimensions of an array. This was implicitly
supported by previous versions of scipy, but support has now been formalized
and gets compatibility-checked before use. For example, a set of ``y`` values
to interpolate with shape ``(2, 3, 5)`` interpolated along the last axis (2)
could accept a ``fill_value`` array with shape ``()`` (singleton), ``(1,)``,
``(2, 1)``, ``(1, 3)``, ``(3,)``, or ``(2, 3)``; or it can be a 2-element tuple
to specify separate below and above bounds, where each of the two tuple
elements obeys proper broadcasting rules.

`scipy.linalg` improvements
---------------------------

The default algorithm for `scipy.linalg.leastsq` has been changed to use
LAPACK's function ``*gelsd``. Users wanting to get the previous behavior
can use a new keyword ``lapack_driver="gelss"`` (allowed values are
"gelss", "gelsd" and "gelsy").

``scipy.sparse`` matrices and linear operators now support the matmul (``@``)
operator when available (Python 3.5+). See
[PEP 465](https://legacy.python.org/dev/peps/pep-0465/)

A new function `scipy.linalg.ordqz`, for QZ decomposition with reordering, has
been added.


Deprecated features
===================

``scipy.stats.histogram`` is deprecated in favor of ``np.histogram``, which is
faster and provides the same functionality.

``scipy.stats.threshold`` and ``scipy.mstats.threshold`` are deprecated
in favor of ``np.clip``. See issue #617 for details.

``scipy.stats.ss`` is deprecated. This is a support function, not meant to
be exposed to the user. Also, the name is unclear. See issue #663 for details.

``scipy.stats.square_of_sums`` is deprecated. This too is a support function
not meant to be exposed to the user. See issues #665 and #663 for details.

``scipy.stats.f_value``, ``scipy.stats.f_value_multivariate``,
``scipy.stats.f_value_wilks_lambda``, and ``scipy.mstats.f_value_wilks_lambda``
are deprecated. These are related to ANOVA, for which ``scipy.stats`` provides
quite limited functionality and these functions are not very useful standalone.
See issues #660 and #650 for details.

``scipy.stats.chisqprob`` is deprecated. This is an alias. ``stats.chi2.sf``
should be used instead.

``scipy.stats.betai`` is deprecated. This is an alias for ``special.betainc``
which should be used instead.


Backwards incompatible changes
==============================

The functions ``stats.trim1`` and ``stats.trimboth`` now make sure the
elements trimmed are the lowest and/or highest, depending on the case.
Slicing without at least partial sorting was previously done, but didn't
make sense for unsorted input.

When ``variable_names`` is set to an empty list, ``scipy.io.loadmat`` now
correctly returns no values instead of all the contents of the MAT file.

Element-wise multiplication of sparse matrices now returns a sparse result
in all cases. Previously, multiplying a sparse matrix with a dense matrix or
array would return a dense matrix.

The function ``misc.lena`` has been removed due to license incompatibility.

The constructor for ``sparse.coo_matrix`` no longer accepts ``(None, (m,n))``
to construct an all-zero matrix of shape ``(m,n)``. This functionality was
deprecated since at least 2007 and was already broken in the previous SciPy
release. Use ``coo_matrix((m,n))`` instead.

The Cython wrappers in ``linalg.cython_lapack`` for the LAPACK routines
``*gegs``, ``*gegv``, ``*gelsx``, ``*geqpf``, ``*ggsvd``, ``*ggsvp``,
``*lahrd``, ``*latzm``, ``*tzrqf`` have been removed since these routines
are not present in the new LAPACK 3.6.0 release. With the exception of
the routines ``*ggsvd`` and ``*ggsvp``, these were all deprecated in favor
of routines that are currently present in our Cython LAPACK wrappers.

Because the LAPACK ``*gegv`` routines were removed in LAPACK 3.6.0. The
corresponding Python wrappers in ``scipy.linalg.lapack`` are now
deprecated and will be removed in a future release. The source files for
these routines have been temporarily included as a part of ``scipy.linalg``
so that SciPy can be built against LAPACK versions that do not provide
these deprecated routines.


Other changes
=============

Html and pdf documentation of development versions of Scipy is now
automatically rebuilt after every merged pull request.

`scipy.constants` is updated to the CODATA 2014 recommended values.

Usage of `scipy.fftpack` functions within Scipy has been changed in such a
way that `PyFFTW <https://hgomersall.github.io/pyFFTW/>`__ can easily replace
`scipy.fftpack` functions (with improved performance).  See
`gh-5295 <https://github.com/scipy/scipy/pull/5295>`__ for details.

The ``imread`` functions in `scipy.misc` and `scipy.ndimage` were unified, for
which a ``mode`` argument was added to `scipy.misc.imread`.  Also, bugs for
1-bit and indexed RGB image formats were fixed.

``runtests.py``, the development script to build and test Scipy, now allows
building in parallel with ``--parallel``.

Authors
=======

* @cel4 +
* @chemelnucfin +
* @endolith
* @mamrehn +
* @tosh1ki +
* Joshua L. Adelman +
* Anne Archibald
* Hervé Audren +
* Vincent Barrielle +
* Bruno Beltran +
* Sumit Binnani +
* Joseph Jon Booker
* Olga Botvinnik +
* Michael Boyle +
* Matthew Brett
* Zaz Brown +
* Lars Buitinck
* Pete Bunch +
* Evgeni Burovski
* CJ Carey
* Ien Cheng +
* Cody +
* Jaime Fernandez del Rio
* Ales Erjavec +
* Abraham Escalante
* Yves-Rémi Van Eycke +
* Yu Feng +
* Eric Firing
* Francis T. O'Donovan +
* André Gaul
* Christoph Gohlke
* Ralf Gommers
* Alex Griffing
* Alexander Grigorievskiy
* Charles Harris
* Jörn Hees +
* Ian Henriksen
* Derek Homeier +
* David Menéndez Hurtado
* Gert-Ludwig Ingold
* Aakash Jain +
* Rohit Jamuar +
* Jan Schlüter
* Johannes Ballé
* Luke Zoltan Kelley +
* Jason King +
* Andreas Kopecky +
* Eric Larson
* Denis Laxalde
* Antony Lee
* Gregory R. Lee
* Josh Levy-Kramer +
* Sam Lewis +
* François Magimel +
* Martín Gaitán +
* Sam Mason +
* Andreas Mayer
* Nikolay Mayorov
* Damon McDougall +
* Robert McGibbon
* Sturla Molden
* Will Monroe +
* Eric Moore
* Maniteja Nandana
* Vikram Natarajan +
* Andrew Nelson
* Marti Nito +
* Behzad Nouri +
* Daisuke Oyama +
* Giorgio Patrini +
* Fabian Paul +
* Christoph Paulik +
* Mad Physicist +
* Irvin Probst
* Sebastian Pucilowski +
* Ted Pudlik +
* Eric Quintero
* Yoav Ram +
* Joscha Reimer +
* Juha Remes
* Frederik Rietdijk +
* Rémy Léone +
* Christian Sachs +
* Skipper Seabold
* Sebastian Skoupý +
* Alex Seewald +
* Andreas Sorge +
* Bernardo Sulzbach +
* Julian Taylor
* Louis Tiao +
* Utkarsh Upadhyay +
* Jacob Vanderplas
* Gael Varoquaux +
* Pauli Virtanen
* Fredrik Wallner +
* Stefan van der Walt
* James Webber +
* Warren Weckesser
* Raphael Wettinger +
* Josh Wilson +
* Nat Wilson +
* Peter Yin +

A total of 101 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 0.17.0
------------------------

- `#1923 <https://github.com/scipy/scipy/issues/1923>`__: problem with numpy 0's in stats.poisson.rvs (Trac #1398)
- `#2138 <https://github.com/scipy/scipy/issues/2138>`__: scipy.misc.imread segfaults on 1 bit png (Trac #1613)
- `#2237 <https://github.com/scipy/scipy/issues/2237>`__: distributions do not accept complex arguments (Trac #1718)
- `#2282 <https://github.com/scipy/scipy/issues/2282>`__: scipy.special.hyp1f1(0.5, 1.5, -1000) fails (Trac #1763)
- `#2618 <https://github.com/scipy/scipy/issues/2618>`__: poisson.pmf returns NaN if mu is 0
- `#2957 <https://github.com/scipy/scipy/issues/2957>`__: hyp1f1 precision issue
- `#2997 <https://github.com/scipy/scipy/issues/2997>`__: FAIL: test_qhull.TestUtilities.test_more_barycentric_transforms
- `#3129 <https://github.com/scipy/scipy/issues/3129>`__: No way to set ranges for fitting parameters in Optimize functions
- `#3191 <https://github.com/scipy/scipy/issues/3191>`__: interp1d should contain a fill_value_below and a fill_value_above...
- `#3453 <https://github.com/scipy/scipy/issues/3453>`__: PchipInterpolator sets slopes at edges differently than Matlab's...
- `#4106 <https://github.com/scipy/scipy/issues/4106>`__: ndimage._ni_support._normalize_sequence() fails with numpy.int64
- `#4118 <https://github.com/scipy/scipy/issues/4118>`__: `scipy.integrate.ode.set_solout` called after `scipy.integrate.ode.set_initial_value` fails silently
- `#4233 <https://github.com/scipy/scipy/issues/4233>`__: 1D scipy.interpolate.griddata using method=nearest produces nans...
- `#4375 <https://github.com/scipy/scipy/issues/4375>`__: All tests fail due to bad file permissions
- `#4580 <https://github.com/scipy/scipy/issues/4580>`__: scipy.ndimage.filters.convolve documenation is incorrect
- `#4627 <https://github.com/scipy/scipy/issues/4627>`__: logsumexp with sign indicator - enable calculation with negative...
- `#4702 <https://github.com/scipy/scipy/issues/4702>`__: logsumexp with zero scaling factor
- `#4834 <https://github.com/scipy/scipy/issues/4834>`__: gammainc should return 1.0 instead of NaN for infinite x
- `#4838 <https://github.com/scipy/scipy/issues/4838>`__: enh: exprel special function
- `#4862 <https://github.com/scipy/scipy/issues/4862>`__: the scipy.special.boxcox function is inaccurate for denormal...
- `#4887 <https://github.com/scipy/scipy/issues/4887>`__: Spherical harmonic incongruences
- `#4895 <https://github.com/scipy/scipy/issues/4895>`__: some scipy ufuncs have inconsistent output dtypes?
- `#4923 <https://github.com/scipy/scipy/issues/4923>`__: logm does not aggressively convert complex outputs to float
- `#4932 <https://github.com/scipy/scipy/issues/4932>`__: BUG: stats: The `fit` method of the distributions silently ignores...
- `#4956 <https://github.com/scipy/scipy/issues/4956>`__: Documentation error in `scipy.special.bi_zeros`
- `#4957 <https://github.com/scipy/scipy/issues/4957>`__: Docstring for `pbvv_seq` is wrong
- `#4967 <https://github.com/scipy/scipy/issues/4967>`__: block_diag should look at dtypes of all arguments, not only the...
- `#5037 <https://github.com/scipy/scipy/issues/5037>`__: scipy.optimize.minimize error messages are printed to stdout...
- `#5039 <https://github.com/scipy/scipy/issues/5039>`__: Cubic interpolation: On entry to DGESDD parameter number 12 had...
- `#5163 <https://github.com/scipy/scipy/issues/5163>`__: Base case example of Hierarchical Clustering (offer)
- `#5181 <https://github.com/scipy/scipy/issues/5181>`__: BUG: stats.genextreme.entropy should use the explicit formula
- `#5184 <https://github.com/scipy/scipy/issues/5184>`__: Some? wheels don't express a numpy dependency
- `#5197 <https://github.com/scipy/scipy/issues/5197>`__: mstats: test_kurtosis fails (ULP max is 2)
- `#5260 <https://github.com/scipy/scipy/issues/5260>`__: Typo causing an error in splrep
- `#5263 <https://github.com/scipy/scipy/issues/5263>`__: Default epsilon in rbf.py fails for colinear points
- `#5276 <https://github.com/scipy/scipy/issues/5276>`__: Reading empty (no data) arff file fails
- `#5280 <https://github.com/scipy/scipy/issues/5280>`__: 1d scipy.signal.convolve much slower than numpy.convolve
- `#5326 <https://github.com/scipy/scipy/issues/5326>`__: Implementation error in scipy.interpolate.PchipInterpolator
- `#5370 <https://github.com/scipy/scipy/issues/5370>`__: Test issue with test_quadpack and libm.so as a linker script
- `#5426 <https://github.com/scipy/scipy/issues/5426>`__: ERROR: test_stats.test_chisquare_masked_arrays
- `#5427 <https://github.com/scipy/scipy/issues/5427>`__: Automate installing correct numpy versions in numpy-vendor image
- `#5430 <https://github.com/scipy/scipy/issues/5430>`__: Python3 : Numpy scalar types "not iterable"; specific instance...
- `#5450 <https://github.com/scipy/scipy/issues/5450>`__: BUG: spatial.ConvexHull triggers a seg. fault when given nans.
- `#5478 <https://github.com/scipy/scipy/issues/5478>`__: clarify the relation between matrix normal distribution and `multivariate_normal`
- `#5539 <https://github.com/scipy/scipy/issues/5539>`__: lstsq related test failures on windows binaries from numpy-vendor
- `#5560 <https://github.com/scipy/scipy/issues/5560>`__: doc: scipy.stats.burr pdf issue
- `#5571 <https://github.com/scipy/scipy/issues/5571>`__: lstsq test failure after lapack_driver change
- `#5577 <https://github.com/scipy/scipy/issues/5577>`__: ordqz segfault on Python 3.4 in Wine
- `#5578 <https://github.com/scipy/scipy/issues/5578>`__: scipy.linalg test failures on python 3 in Wine
- `#5607 <https://github.com/scipy/scipy/issues/5607>`__: Overloaded ‘isnan(double&)’ is ambiguous when compiling with...
- `#5629 <https://github.com/scipy/scipy/issues/5629>`__: Test for lstsq randomly failed
- `#5630 <https://github.com/scipy/scipy/issues/5630>`__: memory leak with scipy 0.16 spatial cKDEtree
- `#5689 <https://github.com/scipy/scipy/issues/5689>`__: isnan errors compiling scipy/special/Faddeeva.cc with clang++
- `#5694 <https://github.com/scipy/scipy/issues/5694>`__: fftpack test failure in test_import
- `#5719 <https://github.com/scipy/scipy/issues/5719>`__: curve_fit(method!="lm") ignores initial guess


Pull requests for 0.17.0
------------------------

- `#3022 <https://github.com/scipy/scipy/pull/3022>`__: hyp1f1: better handling of large negative arguments
- `#3107 <https://github.com/scipy/scipy/pull/3107>`__: ENH: Add ordered QZ decomposition
- `#4390 <https://github.com/scipy/scipy/pull/4390>`__: ENH: Allow axis and keepdims arguments to be passed to scipy.linalg.norm.
- `#4671 <https://github.com/scipy/scipy/pull/4671>`__: ENH: add axis to sparse norms
- `#4796 <https://github.com/scipy/scipy/pull/4796>`__: ENH: Add cut tree function to scipy.cluster.hierarchy
- `#4809 <https://github.com/scipy/scipy/pull/4809>`__: MAINT: cauchy moments are undefined
- `#4821 <https://github.com/scipy/scipy/pull/4821>`__: ENH: stats: make distribution instances picklable
- `#4839 <https://github.com/scipy/scipy/pull/4839>`__: ENH: Add scipy.special.exprel relative error exponential ufunc
- `#4859 <https://github.com/scipy/scipy/pull/4859>`__: Logsumexp fixes - allows sign flags and b==0
- `#4865 <https://github.com/scipy/scipy/pull/4865>`__: BUG: scipy.io.mmio.write: error with big indices and low precision
- `#4869 <https://github.com/scipy/scipy/pull/4869>`__: add as_inexact option to _lib._util._asarray_validated
- `#4884 <https://github.com/scipy/scipy/pull/4884>`__: ENH: Finite difference approximation of Jacobian matrix
- `#4890 <https://github.com/scipy/scipy/pull/4890>`__: ENH: Port cKDTree query methods to C++, allow pickling on Python...
- `#4892 <https://github.com/scipy/scipy/pull/4892>`__: how much doctesting is too much?
- `#4896 <https://github.com/scipy/scipy/pull/4896>`__: MAINT: work around a possible numpy ufunc loop selection bug
- `#4898 <https://github.com/scipy/scipy/pull/4898>`__: MAINT: A bit of pyflakes-driven cleanup.
- `#4899 <https://github.com/scipy/scipy/pull/4899>`__: ENH: add 'alternative' keyword to hypothesis tests in stats
- `#4903 <https://github.com/scipy/scipy/pull/4903>`__: BENCH: Benchmarks for interpolate module
- `#4905 <https://github.com/scipy/scipy/pull/4905>`__: MAINT: prepend underscore to mask_to_limits; delete masked_var.
- `#4906 <https://github.com/scipy/scipy/pull/4906>`__: MAINT: Benchmarks for optimize.leastsq
- `#4910 <https://github.com/scipy/scipy/pull/4910>`__: WIP: Trimmed statistics functions have inconsistent API.
- `#4912 <https://github.com/scipy/scipy/pull/4912>`__: MAINT: fix typo in stats tutorial. Closes gh-4911.
- `#4914 <https://github.com/scipy/scipy/pull/4914>`__: DEP: deprecate `scipy.stats.ss` and `scipy.stats.square_of_sums`.
- `#4924 <https://github.com/scipy/scipy/pull/4924>`__: MAINT: if the imaginary part of logm of a real matrix is small,...
- `#4930 <https://github.com/scipy/scipy/pull/4930>`__: BENCH: Benchmarks for signal module
- `#4941 <https://github.com/scipy/scipy/pull/4941>`__: ENH: update `find_repeats`.
- `#4942 <https://github.com/scipy/scipy/pull/4942>`__: MAINT: use np.float64_t instead of np.float_t in cKDTree
- `#4944 <https://github.com/scipy/scipy/pull/4944>`__: BUG: integer overflow in correlate_nd
- `#4951 <https://github.com/scipy/scipy/pull/4951>`__: do not ignore invalid kwargs in distributions fit method
- `#4958 <https://github.com/scipy/scipy/pull/4958>`__: Add some detail to docstrings for special functions
- `#4961 <https://github.com/scipy/scipy/pull/4961>`__: ENH: stats.describe: add bias kw and empty array handling
- `#4963 <https://github.com/scipy/scipy/pull/4963>`__: ENH: scipy.sparse.coo.coo_matrix.__init__: less memory needed
- `#4968 <https://github.com/scipy/scipy/pull/4968>`__: DEP: deprecate ``stats.f_value*`` and ``mstats.f_value*`` functions.
- `#4969 <https://github.com/scipy/scipy/pull/4969>`__: ENH: review `stats.relfreq` and `stats.cumfreq`; fixes to `stats.histogram`
- `#4971 <https://github.com/scipy/scipy/pull/4971>`__: Extend github source links to line ranges
- `#4972 <https://github.com/scipy/scipy/pull/4972>`__: MAINT: impove the error message in validate_runtests_log
- `#4976 <https://github.com/scipy/scipy/pull/4976>`__: DEP: deprecate `scipy.stats.threshold`
- `#4977 <https://github.com/scipy/scipy/pull/4977>`__: MAINT: more careful dtype treatment in block diagonal matrix...
- `#4979 <https://github.com/scipy/scipy/pull/4979>`__: ENH: distributions, complex arguments
- `#4984 <https://github.com/scipy/scipy/pull/4984>`__: clarify dirichlet distribution error handling
- `#4992 <https://github.com/scipy/scipy/pull/4992>`__: ENH: `stats.fligner` and `stats.bartlett` empty input handling.
- `#4996 <https://github.com/scipy/scipy/pull/4996>`__: DOC: fix stats.spearmanr docs
- `#4997 <https://github.com/scipy/scipy/pull/4997>`__: Fix up boxcox for underflow / loss of precision
- `#4998 <https://github.com/scipy/scipy/pull/4998>`__: DOC: improved documentation for `stats.ppcc_max`
- `#5000 <https://github.com/scipy/scipy/pull/5000>`__: ENH: added empty input handling `scipy.moment`; doc enhancements
- `#5003 <https://github.com/scipy/scipy/pull/5003>`__: ENH: improves rankdata algorithm
- `#5005 <https://github.com/scipy/scipy/pull/5005>`__: scipy.stats: numerical stability improvement
- `#5007 <https://github.com/scipy/scipy/pull/5007>`__: ENH: nan handling in functions that use `stats._chk_asarray`
- `#5009 <https://github.com/scipy/scipy/pull/5009>`__: remove coveralls.io
- `#5010 <https://github.com/scipy/scipy/pull/5010>`__: Hypergeometric distribution log survival function
- `#5014 <https://github.com/scipy/scipy/pull/5014>`__: Patch to compute the volume and area of convex hulls
- `#5015 <https://github.com/scipy/scipy/pull/5015>`__: DOC: Fix mistaken variable name in sawtooth
- `#5016 <https://github.com/scipy/scipy/pull/5016>`__: DOC: resample example
- `#5017 <https://github.com/scipy/scipy/pull/5017>`__: DEP: deprecate `stats.betai` and `stats.chisqprob`
- `#5018 <https://github.com/scipy/scipy/pull/5018>`__: ENH: Add test on random inpu to volume computations
- `#5026 <https://github.com/scipy/scipy/pull/5026>`__: BUG: Fix return dtype of lil_matrix.getnnz(axis=0)
- `#5030 <https://github.com/scipy/scipy/pull/5030>`__: DOC: resample slow for prime output too
- `#5033 <https://github.com/scipy/scipy/pull/5033>`__: MAINT: integrate, special: remove unused R1MACH and Makefile
- `#5034 <https://github.com/scipy/scipy/pull/5034>`__: MAINT: signal: lift max_len_seq validation out of Cython
- `#5035 <https://github.com/scipy/scipy/pull/5035>`__: DOC/MAINT: refguide / doctest drudgery
- `#5041 <https://github.com/scipy/scipy/pull/5041>`__: BUG: fixing some small memory leaks detected by cppcheck
- `#5044 <https://github.com/scipy/scipy/pull/5044>`__: [GSoC] ENH: New least-squares algorithms
- `#5050 <https://github.com/scipy/scipy/pull/5050>`__: MAINT: C fixes, trimmed a lot of dead code from Cephes
- `#5057 <https://github.com/scipy/scipy/pull/5057>`__: ENH: sparse: avoid densifying on sparse/dense elementwise mult
- `#5058 <https://github.com/scipy/scipy/pull/5058>`__: TST: stats: add a sample distribution to the test loop
- `#5061 <https://github.com/scipy/scipy/pull/5061>`__: ENH: spatial: faster 2D Voronoi and Convex Hull plotting
- `#5065 <https://github.com/scipy/scipy/pull/5065>`__: TST: improve test coverage for `stats.mvsdist` and `stats.bayes_mvs`
- `#5066 <https://github.com/scipy/scipy/pull/5066>`__: MAINT: fitpack: remove a noop
- `#5067 <https://github.com/scipy/scipy/pull/5067>`__: ENH: empty and nan input handling for `stats.kstat` and `stats.kstatvar`
- `#5071 <https://github.com/scipy/scipy/pull/5071>`__: DOC: optimize: Correct paper reference, add doi
- `#5072 <https://github.com/scipy/scipy/pull/5072>`__: MAINT: scipy.sparse cleanup
- `#5073 <https://github.com/scipy/scipy/pull/5073>`__: DOC: special: Add an example showing the relation of diric to...
- `#5075 <https://github.com/scipy/scipy/pull/5075>`__: DOC: clarified parameterization of stats.lognorm
- `#5076 <https://github.com/scipy/scipy/pull/5076>`__: use int, float, bool instead of np.int, np.float, np.bool
- `#5078 <https://github.com/scipy/scipy/pull/5078>`__: DOC: Rename fftpack docs to README
- `#5081 <https://github.com/scipy/scipy/pull/5081>`__: BUG: Correct handling of scalar 'b' in lsmr and lsqr
- `#5082 <https://github.com/scipy/scipy/pull/5082>`__: loadmat variable_names: don't confuse [] and None.
- `#5083 <https://github.com/scipy/scipy/pull/5083>`__: Fix integrate.fixed_quad docstring to indicate None return value
- `#5086 <https://github.com/scipy/scipy/pull/5086>`__: Use solve() instead of inv() for gaussian_kde
- `#5090 <https://github.com/scipy/scipy/pull/5090>`__: MAINT: stats: add explicit _sf, _isf to gengamma distribution
- `#5094 <https://github.com/scipy/scipy/pull/5094>`__: ENH: scipy.interpolate.NearestNDInterpolator: cKDTree configurable
- `#5098 <https://github.com/scipy/scipy/pull/5098>`__: DOC: special: fix typesetting in ``*_roots quadrature`` functions
- `#5099 <https://github.com/scipy/scipy/pull/5099>`__: DOC: make the docstring of stats.moment raw
- `#5104 <https://github.com/scipy/scipy/pull/5104>`__: DOC/ENH fixes and micro-optimizations for scipy.linalg
- `#5105 <https://github.com/scipy/scipy/pull/5105>`__: enh: made l-bfgs-b parameter for the maximum number of line search...
- `#5106 <https://github.com/scipy/scipy/pull/5106>`__: TST: add NIST test cases to `stats.f_oneway`
- `#5110 <https://github.com/scipy/scipy/pull/5110>`__: [GSoC]: Bounded linear least squares
- `#5111 <https://github.com/scipy/scipy/pull/5111>`__: MAINT: special: Cephes cleanup
- `#5118 <https://github.com/scipy/scipy/pull/5118>`__: BUG: FIR path failed if len(x) < len(b) in lfilter.
- `#5124 <https://github.com/scipy/scipy/pull/5124>`__: ENH: move the filliben approximation to a publicly visible function
- `#5126 <https://github.com/scipy/scipy/pull/5126>`__: StatisticsCleanup: `stats.kruskal` review
- `#5130 <https://github.com/scipy/scipy/pull/5130>`__: DOC: update PyPi trove classifiers. Beta -> Stable. Add license.
- `#5131 <https://github.com/scipy/scipy/pull/5131>`__: DOC: differential_evolution, improve docstring for mutation and...
- `#5132 <https://github.com/scipy/scipy/pull/5132>`__: MAINT: differential_evolution improve init_population_lhs comments...
- `#5133 <https://github.com/scipy/scipy/pull/5133>`__: MRG: rebased mmio refactoring
- `#5135 <https://github.com/scipy/scipy/pull/5135>`__: MAINT: `stats.mstats` consistency with `stats.stats`
- `#5139 <https://github.com/scipy/scipy/pull/5139>`__: TST: linalg: add a smoke test for gh-5039
- `#5140 <https://github.com/scipy/scipy/pull/5140>`__: EHN: Update constants.codata to CODATA 2014
- `#5145 <https://github.com/scipy/scipy/pull/5145>`__: added ValueError to docstring as possible error raised
- `#5146 <https://github.com/scipy/scipy/pull/5146>`__: MAINT: Improve implementation details and doc in `stats.shapiro`
- `#5147 <https://github.com/scipy/scipy/pull/5147>`__: [GSoC] ENH: Upgrades to curve_fit
- `#5150 <https://github.com/scipy/scipy/pull/5150>`__: Fix misleading wavelets/cwt example
- `#5152 <https://github.com/scipy/scipy/pull/5152>`__: BUG: cluster.hierarchy.dendrogram: missing font size doesn't...
- `#5153 <https://github.com/scipy/scipy/pull/5153>`__: add keywords to control the summation in discrete distributions...
- `#5156 <https://github.com/scipy/scipy/pull/5156>`__: DOC: added comments on algorithms used in Legendre function
- `#5158 <https://github.com/scipy/scipy/pull/5158>`__: ENH: optimize: add the Hungarian algorithm
- `#5162 <https://github.com/scipy/scipy/pull/5162>`__: FIX: Remove lena
- `#5164 <https://github.com/scipy/scipy/pull/5164>`__: MAINT: fix cluster.hierarchy.dendrogram issues and docs
- `#5166 <https://github.com/scipy/scipy/pull/5166>`__: MAINT: changed `stats.pointbiserialr` to delegate to `stats.pearsonr`
- `#5167 <https://github.com/scipy/scipy/pull/5167>`__: ENH: add nan_policy to `stats.kendalltau`.
- `#5168 <https://github.com/scipy/scipy/pull/5168>`__: TST: added nist test case (Norris) to `stats.linregress`.
- `#5169 <https://github.com/scipy/scipy/pull/5169>`__: update lpmv docstring
- `#5171 <https://github.com/scipy/scipy/pull/5171>`__: Clarify metric parameter in linkage docstring
- `#5172 <https://github.com/scipy/scipy/pull/5172>`__: ENH: add mode keyword to signal.spectrogram
- `#5177 <https://github.com/scipy/scipy/pull/5177>`__: DOC: graphical example for KDTree.query_ball_point
- `#5179 <https://github.com/scipy/scipy/pull/5179>`__: MAINT: stats: tweak the formula for ncx2.pdf
- `#5188 <https://github.com/scipy/scipy/pull/5188>`__: MAINT: linalg: A bit of clean up.
- `#5189 <https://github.com/scipy/scipy/pull/5189>`__: BUG: stats: Use the explicit formula in stats.genextreme.entropy
- `#5193 <https://github.com/scipy/scipy/pull/5193>`__: BUG: fix uninitialized use in lartg
- `#5194 <https://github.com/scipy/scipy/pull/5194>`__: BUG: properly return error to fortran from ode_jacobian_function
- `#5198 <https://github.com/scipy/scipy/pull/5198>`__: TST: Fix TestCtypesQuad failure on Python 3.5 for Windows
- `#5201 <https://github.com/scipy/scipy/pull/5201>`__: allow extrapolation in interp1d
- `#5209 <https://github.com/scipy/scipy/pull/5209>`__: MAINT: Change complex parameter to boolean in Y_()
- `#5213 <https://github.com/scipy/scipy/pull/5213>`__: BUG: sparse: fix logical comparison dtype conflicts
- `#5216 <https://github.com/scipy/scipy/pull/5216>`__: BUG: sparse: fixing unbound local error
- `#5218 <https://github.com/scipy/scipy/pull/5218>`__: DOC and BUG: Bessel function docstring improvements, fix array_like,...
- `#5222 <https://github.com/scipy/scipy/pull/5222>`__: MAINT: sparse: fix COO ctor
- `#5224 <https://github.com/scipy/scipy/pull/5224>`__: DOC: optimize: type of OptimizeResult.hess_inv varies
- `#5228 <https://github.com/scipy/scipy/pull/5228>`__: ENH: Add maskandscale support to netcdf; based on pupynere and...
- `#5229 <https://github.com/scipy/scipy/pull/5229>`__: DOC: sparse.linalg.svds doc typo fixed
- `#5234 <https://github.com/scipy/scipy/pull/5234>`__: MAINT: sparse: simplify COO ctor
- `#5235 <https://github.com/scipy/scipy/pull/5235>`__: MAINT: sparse: warn on todia() with many diagonals
- `#5236 <https://github.com/scipy/scipy/pull/5236>`__: MAINT: ndimage: simplify thread handling/recursion + constness
- `#5239 <https://github.com/scipy/scipy/pull/5239>`__: BUG: integrate: Fixed issue 4118
- `#5241 <https://github.com/scipy/scipy/pull/5241>`__: qr_insert fixes, closes #5149
- `#5246 <https://github.com/scipy/scipy/pull/5246>`__: Doctest tutorial files
- `#5247 <https://github.com/scipy/scipy/pull/5247>`__: DOC: optimize: typo/import fix in linear_sum_assignment
- `#5248 <https://github.com/scipy/scipy/pull/5248>`__: remove inspect.getargspec and test python 3.5 on Travis CI
- `#5250 <https://github.com/scipy/scipy/pull/5250>`__: BUG: Fix sparse multiply by single-element zero
- `#5261 <https://github.com/scipy/scipy/pull/5261>`__: Fix bug causing a TypeError in splrep when a runtime warning...
- `#5262 <https://github.com/scipy/scipy/pull/5262>`__: Follow up to 4489 (Addition LAPACK routines in linalg.lstsq)
- `#5264 <https://github.com/scipy/scipy/pull/5264>`__: ignore zero-length edges for default epsilon
- `#5269 <https://github.com/scipy/scipy/pull/5269>`__: DOC: Typos and spell-checking
- `#5272 <https://github.com/scipy/scipy/pull/5272>`__: MAINT: signal: Convert array syntax to memoryviews
- `#5273 <https://github.com/scipy/scipy/pull/5273>`__: DOC: raw strings for docstrings with math
- `#5274 <https://github.com/scipy/scipy/pull/5274>`__: MAINT: sparse: update cython code for MST
- `#5278 <https://github.com/scipy/scipy/pull/5278>`__: BUG: io: Stop guessing the data delimiter in ARFF files.
- `#5289 <https://github.com/scipy/scipy/pull/5289>`__: BUG: misc: Fix the Pillow work-around for 1-bit images.
- `#5291 <https://github.com/scipy/scipy/pull/5291>`__: ENH: call np.correlate for 1d in scipy.signal.correlate
- `#5294 <https://github.com/scipy/scipy/pull/5294>`__: DOC: special: Remove a potentially misleading example from the...
- `#5295 <https://github.com/scipy/scipy/pull/5295>`__: Simplify replacement of fftpack by pyfftw
- `#5296 <https://github.com/scipy/scipy/pull/5296>`__: ENH: Add matrix normal distribution to stats
- `#5297 <https://github.com/scipy/scipy/pull/5297>`__: Fixed leaf_rotation and leaf_font_size in Python 3
- `#5303 <https://github.com/scipy/scipy/pull/5303>`__: MAINT: stats: rewrite find_repeats
- `#5307 <https://github.com/scipy/scipy/pull/5307>`__: MAINT: stats: remove unused Fortran routine
- `#5313 <https://github.com/scipy/scipy/pull/5313>`__: BUG: sparse: fix diags for nonsquare matrices
- `#5315 <https://github.com/scipy/scipy/pull/5315>`__: MAINT: special: Cephes cleanup
- `#5316 <https://github.com/scipy/scipy/pull/5316>`__: fix input check for sparse.linalg.svds
- `#5319 <https://github.com/scipy/scipy/pull/5319>`__: MAINT: Cython code maintenance
- `#5328 <https://github.com/scipy/scipy/pull/5328>`__: BUG: Fix place_poles return values
- `#5329 <https://github.com/scipy/scipy/pull/5329>`__: avoid a spurious divide-by-zero in Student t stats
- `#5334 <https://github.com/scipy/scipy/pull/5334>`__: MAINT: integrate: miscellaneous cleanup
- `#5340 <https://github.com/scipy/scipy/pull/5340>`__: MAINT: Printing Error Msg to STDERR and Removing iterate.dat
- `#5347 <https://github.com/scipy/scipy/pull/5347>`__: ENH: add Py3.5-style matmul operator (e.g. A @ B) to sparse linear...
- `#5350 <https://github.com/scipy/scipy/pull/5350>`__: FIX error, when reading 32-bit float wav files
- `#5351 <https://github.com/scipy/scipy/pull/5351>`__: refactor the PCHIP interpolant's algorithm
- `#5354 <https://github.com/scipy/scipy/pull/5354>`__: MAINT: construct csr and csc matrices from integer lists
- `#5359 <https://github.com/scipy/scipy/pull/5359>`__: add a fast path to interp1d
- `#5364 <https://github.com/scipy/scipy/pull/5364>`__: Add two fill_values to interp1d.
- `#5365 <https://github.com/scipy/scipy/pull/5365>`__: ABCD docstrings
- `#5366 <https://github.com/scipy/scipy/pull/5366>`__: Fixed typo in the documentation for scipy.signal.cwt() per #5290.
- `#5367 <https://github.com/scipy/scipy/pull/5367>`__: DOC updated scipy.spatial.Delaunay example
- `#5368 <https://github.com/scipy/scipy/pull/5368>`__: ENH: Do not create a throwaway class at every function call
- `#5372 <https://github.com/scipy/scipy/pull/5372>`__: DOC: spectral: fix reference formatting
- `#5375 <https://github.com/scipy/scipy/pull/5375>`__: PEP8 amendments to ffpack_basic.py
- `#5377 <https://github.com/scipy/scipy/pull/5377>`__: BUG: integrate: builtin name no longer shadowed
- `#5381 <https://github.com/scipy/scipy/pull/5381>`__: PEP8ified fftpack_pseudo_diffs.py
- `#5385 <https://github.com/scipy/scipy/pull/5385>`__: BLD: fix Bento build for changes to optimize and spatial
- `#5386 <https://github.com/scipy/scipy/pull/5386>`__: STY: PEP8 amendments to interpolate.py
- `#5387 <https://github.com/scipy/scipy/pull/5387>`__: DEP: deprecate stats.histogram
- `#5388 <https://github.com/scipy/scipy/pull/5388>`__: REL: add "make upload" command to doc/Makefile.
- `#5389 <https://github.com/scipy/scipy/pull/5389>`__: DOC: updated origin param of scipy.ndimage.filters.convolve
- `#5395 <https://github.com/scipy/scipy/pull/5395>`__: BUG: special: fix a number of edge cases related to `x = np.inf`.
- `#5398 <https://github.com/scipy/scipy/pull/5398>`__: MAINT: stats: avoid spurious warnings in lognorm.pdf(0, s)
- `#5407 <https://github.com/scipy/scipy/pull/5407>`__: ENH: stats: Handle mu=0 in stats.poisson
- `#5409 <https://github.com/scipy/scipy/pull/5409>`__: Fix the behavior of discrete distributions at the right-hand...
- `#5412 <https://github.com/scipy/scipy/pull/5412>`__: TST: stats: skip a test to avoid a spurious log(0) warning
- `#5413 <https://github.com/scipy/scipy/pull/5413>`__: BUG: linalg: work around LAPACK single-precision lwork computation...
- `#5414 <https://github.com/scipy/scipy/pull/5414>`__: MAINT: stats: move creation of namedtuples outside of function...
- `#5415 <https://github.com/scipy/scipy/pull/5415>`__: DOC: fix up sections in ToC in the pdf reference guide
- `#5416 <https://github.com/scipy/scipy/pull/5416>`__: TST: fix issue with a ctypes test for integrate on Fedora.
- `#5418 <https://github.com/scipy/scipy/pull/5418>`__: DOC: fix bugs in signal.TransferFunction docstring. Closes gh-5287.
- `#5419 <https://github.com/scipy/scipy/pull/5419>`__: MAINT: sparse: fix usage of NotImplementedError
- `#5420 <https://github.com/scipy/scipy/pull/5420>`__: Raise proper error if maxiter < 1
- `#5422 <https://github.com/scipy/scipy/pull/5422>`__: DOC: changed documentation of brent to be consistent with bracket
- `#5444 <https://github.com/scipy/scipy/pull/5444>`__: BUG: gaussian_filter, BPoly.from_derivatives fail on numpy int...
- `#5445 <https://github.com/scipy/scipy/pull/5445>`__: MAINT: stats: fix incorrect deprecation warnings and test noise
- `#5446 <https://github.com/scipy/scipy/pull/5446>`__: DOC: add note about PyFFTW in fftpack tutorial.
- `#5459 <https://github.com/scipy/scipy/pull/5459>`__: DOC: integrate: Some improvements to the differential equation...
- `#5465 <https://github.com/scipy/scipy/pull/5465>`__: BUG: Relax mstats kurtosis test tolerance by a few ulp
- `#5471 <https://github.com/scipy/scipy/pull/5471>`__: ConvexHull should raise ValueError for NaNs.
- `#5473 <https://github.com/scipy/scipy/pull/5473>`__: MAINT: update decorators.py module to version 4.0.5
- `#5476 <https://github.com/scipy/scipy/pull/5476>`__: BUG: imsave searches for wrong channel axis if image has 3 or...
- `#5477 <https://github.com/scipy/scipy/pull/5477>`__: BLD: add numpy to setup/install_requires for OS X wheels
- `#5479 <https://github.com/scipy/scipy/pull/5479>`__: ENH: return Jacobian/Hessian from BasinHopping
- `#5484 <https://github.com/scipy/scipy/pull/5484>`__: BUG: fix ttest zero division handling
- `#5486 <https://github.com/scipy/scipy/pull/5486>`__: Fix crash on kmeans2
- `#5491 <https://github.com/scipy/scipy/pull/5491>`__: MAINT: Expose parallel build option to runtests.py
- `#5494 <https://github.com/scipy/scipy/pull/5494>`__: Sort OptimizeResult.__repr__ by key
- `#5496 <https://github.com/scipy/scipy/pull/5496>`__: DOC: update the author name mapping
- `#5497 <https://github.com/scipy/scipy/pull/5497>`__: Enhancement to binned_statistic: option to unraveled returned...
- `#5498 <https://github.com/scipy/scipy/pull/5498>`__: BUG: sparse: fix a bug in sparsetools input dtype resolution
- `#5500 <https://github.com/scipy/scipy/pull/5500>`__: DOC: detect unprintable characters in docstrings
- `#5505 <https://github.com/scipy/scipy/pull/5505>`__: BUG: misc: Ensure fromimage converts mode 'P' to 'RGB' or 'RGBA'.
- `#5514 <https://github.com/scipy/scipy/pull/5514>`__: DOC: further update the release notes
- `#5515 <https://github.com/scipy/scipy/pull/5515>`__: ENH: optionally disable fixed-point acceleration
- `#5517 <https://github.com/scipy/scipy/pull/5517>`__: DOC: Improvements and additions to the matrix_normal doc
- `#5518 <https://github.com/scipy/scipy/pull/5518>`__: Remove wrappers for LAPACK deprecated routines
- `#5521 <https://github.com/scipy/scipy/pull/5521>`__: TST: skip a linalg.orth memory test on 32-bit platforms.
- `#5523 <https://github.com/scipy/scipy/pull/5523>`__: DOC: change a few floats to integers in docstring examples
- `#5524 <https://github.com/scipy/scipy/pull/5524>`__: DOC: more updates to 0.17.0 release notes.
- `#5525 <https://github.com/scipy/scipy/pull/5525>`__: Fix to minor typo in documentation for scipy.integrate.ode
- `#5527 <https://github.com/scipy/scipy/pull/5527>`__: TST: bump arccosh tolerance to allow for inaccurate numpy or...
- `#5535 <https://github.com/scipy/scipy/pull/5535>`__: DOC: signal: minor clarification to docstring of TransferFunction.
- `#5538 <https://github.com/scipy/scipy/pull/5538>`__: DOC: signal: fix find_peaks_cwt documentation
- `#5545 <https://github.com/scipy/scipy/pull/5545>`__: MAINT: Fix typo in linalg/basic.py
- `#5547 <https://github.com/scipy/scipy/pull/5547>`__: TST: mark TestEig.test_singular as knownfail in master.
- `#5550 <https://github.com/scipy/scipy/pull/5550>`__: MAINT: work around lstsq driver selection issue
- `#5556 <https://github.com/scipy/scipy/pull/5556>`__: BUG: Fixed broken dogbox trust-region radius update
- `#5561 <https://github.com/scipy/scipy/pull/5561>`__: BUG: eliminate warnings, exception (on Win) in test_maskandscale;...
- `#5567 <https://github.com/scipy/scipy/pull/5567>`__: TST: a few cleanups in the test suite; run_module_suite and clearer...
- `#5568 <https://github.com/scipy/scipy/pull/5568>`__: MAINT: simplify poisson's _argcheck
- `#5569 <https://github.com/scipy/scipy/pull/5569>`__: TST: bump GMean test tolerance to make it pass on Wine
- `#5572 <https://github.com/scipy/scipy/pull/5572>`__: TST: lstsq: bump test tolerance for TravisCI
- `#5573 <https://github.com/scipy/scipy/pull/5573>`__: TST: remove use of np.fromfile from cluster.vq tests
- `#5576 <https://github.com/scipy/scipy/pull/5576>`__: Lapack deprecations
- `#5579 <https://github.com/scipy/scipy/pull/5579>`__: TST: skip tests of linalg.norm axis keyword on numpy <= 1.7.x
- `#5582 <https://github.com/scipy/scipy/pull/5582>`__: Clarify language of survival function documentation
- `#5583 <https://github.com/scipy/scipy/pull/5583>`__: MAINT: stats/tests: A bit of clean up.
- `#5588 <https://github.com/scipy/scipy/pull/5588>`__: DOC: stats: Add a note that stats.burr is the Type III Burr distribution.
- `#5595 <https://github.com/scipy/scipy/pull/5595>`__: TST: fix test_lamch failures on Python 3
- `#5600 <https://github.com/scipy/scipy/pull/5600>`__: MAINT: Ignore spatial/ckdtree.cxx and .h
- `#5602 <https://github.com/scipy/scipy/pull/5602>`__: Explicitly numbered replacement fields for maintainability
- `#5605 <https://github.com/scipy/scipy/pull/5605>`__: MAINT: collection of small fixes to test suite
- `#5614 <https://github.com/scipy/scipy/pull/5614>`__: Minor doc change.
- `#5624 <https://github.com/scipy/scipy/pull/5624>`__: FIX: Fix interpolate
- `#5625 <https://github.com/scipy/scipy/pull/5625>`__: BUG: msvc9 binaries crash when indexing std::vector of size 0
- `#5635 <https://github.com/scipy/scipy/pull/5635>`__: BUG: misspelled __dealloc__ in cKDTree.
- `#5642 <https://github.com/scipy/scipy/pull/5642>`__: STY: minor fixup of formatting of 0.17.0 release notes.
- `#5643 <https://github.com/scipy/scipy/pull/5643>`__: BLD: fix a build issue in special/Faddeeva.cc with isnan.
- `#5661 <https://github.com/scipy/scipy/pull/5661>`__: TST: linalg tests used stdlib random instead of numpy.random.
- `#5682 <https://github.com/scipy/scipy/pull/5682>`__: backports for 0.17.0
- `#5696 <https://github.com/scipy/scipy/pull/5696>`__: Minor improvements to least_squares' docstring.
- `#5697 <https://github.com/scipy/scipy/pull/5697>`__: BLD: fix for isnan/isinf issues in special/Faddeeva.cc
- `#5720 <https://github.com/scipy/scipy/pull/5720>`__: TST: fix for file opening error in fftpack test_import.py
- `#5722 <https://github.com/scipy/scipy/pull/5722>`__: BUG: Make curve_fit respect an initial guess with bounds
- `#5726 <https://github.com/scipy/scipy/pull/5726>`__: Backports for v0.17.0rc2
- `#5727 <https://github.com/scipy/scipy/pull/5727>`__: API: Changes to least_squares API
==========================
SciPy 1.5.3 Release Notes
==========================

.. contents::

SciPy 1.5.3 is a bug-fix release with no new features
compared to 1.5.2. In particular, Linux ARM64 wheels are now
available and a compatibility issue with XCode 12 has
been fixed.

Authors
=======

* Peter Bell
* CJ Carey
* Thomas Duvernay +
* Gregory Lee
* Eric Moore
* odidev
* Dima Pasechnik
* Tyler Reddy
* Simon Segerblom Rex +
* Daniel B. Smith
* Will Tirone +
* Warren Weckesser

A total of 12 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.5.3
-----------------------

* `#9611 <https://github.com/scipy/scipy/issues/9611>`__: Overflow error with new way of p-value calculation in kendall...
* `#10069 <https://github.com/scipy/scipy/issues/10069>`__: scipy.ndimage.watershed_ift regression in 1.0.0
* `#11260 <https://github.com/scipy/scipy/issues/11260>`__: BUG: DOP853 with complex data computes complex error norm, causing...
* `#11479 <https://github.com/scipy/scipy/issues/11479>`__: RuntimeError: dictionary changed size during iteration on loading...
* `#11972 <https://github.com/scipy/scipy/issues/11972>`__: BUG (solved): Error estimation in DOP853 ODE solver fails for...
* `#12543 <https://github.com/scipy/scipy/issues/12543>`__: BUG: Picture rotated 180 degrees and rotated -180 degrees should...
* `#12613 <https://github.com/scipy/scipy/issues/12613>`__: Travis X.4 and X.7 failures in master
* `#12654 <https://github.com/scipy/scipy/issues/12654>`__: scipy.stats.combine_pvalues produces wrong results with method='mudholkar_george'
* `#12819 <https://github.com/scipy/scipy/issues/12819>`__: BUG: Scipy Sparse slice indexing assignment Bug with zeros
* `#12834 <https://github.com/scipy/scipy/issues/12834>`__: BUG: ValueError upon calling Scipy Interpolator objects
* `#12836 <https://github.com/scipy/scipy/issues/12836>`__: ndimage.median can return incorrect values for integer inputs
* `#12860 <https://github.com/scipy/scipy/issues/12860>`__: Build failure with Xcode 12

Pull requests for 1.5.3
-----------------------

* `#12611 <https://github.com/scipy/scipy/pull/12611>`__: MAINT: prepare for SciPy 1.5.3
* `#12614 <https://github.com/scipy/scipy/pull/12614>`__: MAINT: prevent reverse broadcasting
* `#12617 <https://github.com/scipy/scipy/pull/12617>`__: MAINT: optimize: Handle nonscalar size 1 arrays in fmin_slsqp...
* `#12623 <https://github.com/scipy/scipy/pull/12623>`__: MAINT: stats: Loosen some test tolerances.
* `#12638 <https://github.com/scipy/scipy/pull/12638>`__: CI, MAINT: pin pytest for Azure win
* `#12668 <https://github.com/scipy/scipy/pull/12668>`__: BUG: Ensure factorial is not too large in mstats.kendalltau
* `#12705 <https://github.com/scipy/scipy/pull/12705>`__: MAINT: \`openblas_support\` added sha256 hash
* `#12706 <https://github.com/scipy/scipy/pull/12706>`__: BUG: fix incorrect 1d case of the fourier_ellipsoid filter
* `#12721 <https://github.com/scipy/scipy/pull/12721>`__: BUG: use special.sindg in ndimage.rotate
* `#12724 <https://github.com/scipy/scipy/pull/12724>`__: BUG: per #12654 adjusted mudholkar_george method to combine p...
* `#12726 <https://github.com/scipy/scipy/pull/12726>`__: BUG: Fix DOP853 error norm for complex problems
* `#12730 <https://github.com/scipy/scipy/pull/12730>`__: CI: pin xdist for Azure windows
* `#12786 <https://github.com/scipy/scipy/pull/12786>`__: BUG: stats: Fix formula in the \`stats\` method of the ARGUS...
* `#12795 <https://github.com/scipy/scipy/pull/12795>`__: CI: Pin setuptools on windows CI
* `#12830 <https://github.com/scipy/scipy/pull/12830>`__: [BUG] sparse: Avoid using size attribute in LIL __setitem__
* `#12833 <https://github.com/scipy/scipy/pull/12833>`__: BUG: change list of globals items to list of a copy
* `#12842 <https://github.com/scipy/scipy/pull/12842>`__: BUG: Use uint16 for cost in NI_WatershedElement
* `#12845 <https://github.com/scipy/scipy/pull/12845>`__: BUG: avoid boolean or integer addition error in ndimage.measurements.median
* `#12864 <https://github.com/scipy/scipy/pull/12864>`__: BLD: replace the #include of libqull_r.h with with this of qhull_ra.h...
* `#12867 <https://github.com/scipy/scipy/pull/12867>`__: BUG: Fixes a ValueError yielded upon calling Scipy Interpolator...
* `#12902 <https://github.com/scipy/scipy/pull/12902>`__: CI: Remove 'env' from pytest.ini
* `#12913 <https://github.com/scipy/scipy/pull/12913>`__: MAINT: Ignore pytest's PytestConfigWarning

=========================
SciPy 0.8.0 Release Notes
=========================

.. contents::

SciPy 0.8.0 is the culmination of 17 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.8.x branch, and on adding
new features on the development trunk.  This release requires Python
2.4 - 2.6 and NumPy 1.4.1 or greater.

Please note that SciPy is still considered to have "Beta" status, as
we work toward a SciPy 1.0.0 release.  The 1.0.0 release will mark a
major milestone in the development of SciPy, after which changing the
package structure or API will be much more difficult.  Whilst these
pre-1.0 releases are considered to have "Beta" status, we are
committed to making them as bug-free as possible.

However, until the 1.0 release, we are aggressively reviewing and
refining the functionality, organization, and interface. This is being
done in an effort to make the package as coherent, intuitive, and
useful as possible.  To achieve this, we need help from the community
of users.  Specifically, we need feedback regarding all aspects of the
project - everything - from which algorithms we implement, to details
about our function's call signatures.

Python 3
========

Python 3 compatibility is planned and is currently technically
feasible, since Numpy has been ported. However, since the Python 3
compatible Numpy 1.5 has not been released yet, support for Python 3
in Scipy is not yet included in Scipy 0.8.  SciPy 0.9, planned for fall
2010, will very likely include experimental support for Python 3.

Major documentation improvements
================================

SciPy documentation is greatly improved.

Deprecated features
===================

Swapping inputs for correlation functions (scipy.signal)
--------------------------------------------------------

Concern correlate, correlate2d, convolve and convolve2d. If the second input is
larger than the first input, the inputs are swapped before calling the
underlying computation routine. This behavior is deprecated, and will be
removed in scipy 0.9.0.

Obsolete code deprecated (scipy.misc)
-------------------------------------

The modules `helpmod`, `ppimport` and `pexec` from `scipy.misc` are deprecated.
They will be removed from SciPy in version 0.9.

Additional deprecations
-----------------------

* linalg: The function `solveh_banded` currently returns a tuple containing
  the Cholesky factorization and the solution to the linear system.  In
  SciPy 0.9, the return value will be just the solution.
* The function `constants.codata.find` will generate a DeprecationWarning.
  In Scipy version 0.8.0, the keyword argument 'disp' was added to the
  function, with the default value 'True'.  In 0.9.0, the default will be
  'False'.
* The `qshape` keyword argument of `signal.chirp` is deprecated.  Use
  the argument `vertex_zero` instead.
* Passing the coefficients of a polynomial as the argument `f0` to
  `signal.chirp` is deprecated.  Use the function `signal.sweep_poly`
  instead.
* The `io.recaster` module has been deprecated and will be removed in 0.9.0.

New features
============

DCT support (scipy.fftpack)
---------------------------

New realtransforms have been added, namely dct and idct for Discrete Cosine
Transform; type I, II and III are available.

Single precision support for fft functions (scipy.fftpack)
----------------------------------------------------------

fft functions can now handle single precision inputs as well: fft(x) will
return a single precision array if x is single precision.

At the moment, for FFT sizes that are not composites of 2, 3, and 5, the
transform is computed internally in double precision to avoid rounding error in
FFTPACK.

Correlation functions now implement the usual definition (scipy.signal)
-----------------------------------------------------------------------

The outputs should now correspond to their matlab and R counterparts, and do
what most people expect if the old_behavior=False argument is passed:

* correlate, convolve and their 2d counterparts do not swap their inputs
  depending on their relative shape anymore;
* correlation functions now conjugate their second argument while computing
  the slided sum-products, which correspond to the usual definition of
  correlation.

Additions and modification to LTI functions (scipy.signal)
----------------------------------------------------------

* The functions `impulse2` and `step2` were added to `scipy.signal`.
  They use the function `scipy.signal.lsim2` to compute the impulse and
  step response of a system, respectively.
* The function `scipy.signal.lsim2` was changed to pass any additional
  keyword arguments to the ODE solver.

Improved waveform generators (scipy.signal)
-------------------------------------------

Several improvements to the `chirp` function in `scipy.signal` were made:

* The waveform generated when `method="logarithmic"` was corrected; it
  now generates a waveform that is also known as an "exponential" or
  "geometric" chirp. (See https://en.wikipedia.org/wiki/Chirp.)
* A new `chirp` method, "hyperbolic", was added.
* Instead of the keyword `qshape`, `chirp` now uses the keyword
  `vertex_zero`, a boolean.
* `chirp` no longer handles an arbitrary polynomial.  This functionality
  has been moved to a new function, `sweep_poly`.

A new function, `sweep_poly`, was added.

New functions and other changes in scipy.linalg
-----------------------------------------------

The functions `cho_solve_banded`, `circulant`, `companion`, `hadamard` and
`leslie` were added to `scipy.linalg`.

The function `block_diag` was enhanced to accept scalar and 1D arguments,
along with the usual 2D arguments.

New function and changes in scipy.optimize
------------------------------------------

The `curve_fit` function has been added; it takes a function and uses
non-linear least squares to fit that to the provided data.

The `leastsq` and `fsolve` functions now return an array of size one instead of
a scalar when solving for a single parameter.

New sparse least squares solver
-------------------------------

The `lsqr` function was added to `scipy.sparse`.  `This routine
<https://web.stanford.edu/group/SOL/software/lsqr/>`_ finds a
least-squares solution to a large, sparse, linear system of equations.

ARPACK-based sparse SVD
-----------------------

A naive implementation of SVD for sparse matrices is available in
scipy.sparse.linalg._eigen.arpack. It is based on using an symmetric solver on
<A, A>, and as such may not be very precise.

Alternative behavior available for `scipy.constants.find`
---------------------------------------------------------

The keyword argument `disp` was added to the function `scipy.constants.find`,
with the default value `True`.  When `disp` is `True`, the behavior is the
same as in Scipy version 0.7.  When `False`, the function returns the list of
keys instead of printing them.  (In SciPy version 0.9, the default will be
reversed.)

Incomplete sparse LU decompositions
-----------------------------------

Scipy now wraps SuperLU version 4.0, which supports incomplete sparse LU
decompositions. These can be accessed via `scipy.sparse.linalg.spilu`.
Upgrade to SuperLU 4.0 also fixes some known bugs.

Faster matlab file reader and default behavior change
------------------------------------------------------

We've rewritten the matlab file reader in Cython and it should now read
matlab files at around the same speed that Matlab does.

The reader reads matlab named and anonymous functions, but it can't
write them.

Until scipy 0.8.0 we have returned arrays of matlab structs as numpy
object arrays, where the objects have attributes named for the struct
fields.  As of 0.8.0, we return matlab structs as numpy structured
arrays.  You can get the older behavior by using the optional
``struct_as_record=False`` keyword argument to `scipy.io.loadmat` and
friends.

There is an inconsistency in the matlab file writer, in that it writes
numpy 1D arrays as column vectors in matlab 5 files, and row vectors in
matlab 4 files.  We will change this in the next version, so both write
row vectors.  There is a `FutureWarning` when calling the writer to warn
of this change; for now we suggest using the ``oned_as='row'`` keyword
argument to `scipy.io.savemat` and friends.

Faster evaluation of orthogonal polynomials
-------------------------------------------

Values of orthogonal polynomials can be evaluated with new vectorized functions
in `scipy.special`: `eval_legendre`, `eval_chebyt`, `eval_chebyu`,
`eval_chebyc`, `eval_chebys`, `eval_jacobi`, `eval_laguerre`,
`eval_genlaguerre`, `eval_hermite`, `eval_hermitenorm`,
`eval_gegenbauer`, `eval_sh_legendre`, `eval_sh_chebyt`,
`eval_sh_chebyu`, `eval_sh_jacobi`. This is faster than constructing the
full coefficient representation of the polynomials, which was previously the
only available way.

Note that the previous orthogonal polynomial routines will now also invoke this
feature, when possible.

Lambert W function
------------------

`scipy.special.lambertw` can now be used for evaluating the Lambert W
function.

Improved hypergeometric 2F1 function
------------------------------------

Implementation of `scipy.special.hyp2f1` for real parameters was revised.
The new version should produce accurate values for all real parameters.

More flexible interface for Radial basis function interpolation
---------------------------------------------------------------

The `scipy.interpolate.Rbf` class now accepts a callable as input for the
"function" argument, in addition to the built-in radial basis functions which
can be selected with a string argument.

Removed features
================

scipy.stsci: the package was removed

The module `scipy.misc.limits` was removed.

scipy.io
--------

The IO code in both NumPy and SciPy is being extensively
reworked. NumPy will be where basic code for reading and writing NumPy
arrays is located, while SciPy will house file readers and writers for
various data formats (data, audio, video, images, matlab, etc.).

Several functions in `scipy.io` are removed in the 0.8.0 release including:
`npfile`, `save`, `load`, `create_module`, `create_shelf`,
`objload`, `objsave`, `fopen`, `read_array`, `write_array`,
`fread`, `fwrite`, `bswap`, `packbits`, `unpackbits`, and
`convert_objectarray`.  Some of these functions have been replaced by NumPy's
raw reading and writing capabilities, memory-mapping capabilities, or array
methods.  Others have been moved from SciPy to NumPy, since basic array reading
and writing capability is now handled by NumPy.
==========================
SciPy 0.14.0 Release Notes
==========================

.. contents::

SciPy 0.14.0 is the culmination of 8 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.14.x branch, and on adding
new features on the master branch.

This release requires Python 2.6, 2.7 or 3.2-3.4 and NumPy 1.5.1 or greater.


New features
============

``scipy.interpolate`` improvements
----------------------------------

A new wrapper function `scipy.interpolate.interpn` for interpolation on regular
grids has been added. `interpn` supports linear and nearest-neighbor
interpolation in arbitrary dimensions and spline interpolation in two
dimensions.

Faster implementations of piecewise polynomials in power and Bernstein
polynomial bases have been added as `scipy.interpolate.PPoly` and
`scipy.interpolate.BPoly`. New users should use these in favor of
`scipy.interpolate.PiecewisePolynomial`.

`scipy.interpolate.interp1d` now accepts non-monotonic inputs and sorts them.
If performance is critical, sorting can be turned off by using the new
``assume_sorted`` keyword.

Functionality for evaluation of bivariate spline derivatives in
``scipy.interpolate`` has been added.

The new class `scipy.interpolate.Akima1DInterpolator` implements the piecewise
cubic polynomial interpolation scheme devised by H. Akima.

Functionality for fast interpolation on regular, unevenly spaced grids
in arbitrary dimensions has been added as
`scipy.interpolate.RegularGridInterpolator` .


``scipy.linalg`` improvements
-----------------------------

The new function `scipy.linalg.dft` computes the matrix of the
discrete Fourier transform.

A condition number estimation function for matrix exponential,
`scipy.linalg.expm_cond`, has been added.


``scipy.optimize`` improvements
-------------------------------

A set of benchmarks for optimize, which can be run with ``optimize.bench()``,
has been added.

`scipy.optimize.curve_fit` now has more controllable error estimation via the
``absolute_sigma`` keyword.

Support for passing custom minimization methods to ``optimize.minimize()``
and ``optimize.minimize_scalar()`` has been added, currently useful especially
for combining ``optimize.basinhopping()`` with custom local optimizer routines.


``scipy.stats`` improvements
----------------------------

A new class `scipy.stats.multivariate_normal` with functionality for 
multivariate normal random variables has been added.

A lot of work on the ``scipy.stats`` distribution framework has been done.
Moment calculations (skew and kurtosis mainly) are fixed and verified, all
examples are now runnable, and many small accuracy and performance improvements
for individual distributions were merged.

The new function `scipy.stats.anderson_ksamp` computes the k-sample
Anderson-Darling test for the null hypothesis that k samples come from
the same parent population.


``scipy.signal`` improvements
-----------------------------

``scipy.signal.iirfilter`` and related functions to design Butterworth,
Chebyshev, elliptical and Bessel IIR filters now all use pole-zero ("zpk")
format internally instead of using transformations to numerator/denominator
format.  The accuracy of the produced filters, especially high-order ones, is
improved significantly as a result.

The Savitzky-Golay filter was added with the new functions
`scipy.signal.savgol_filter` and `scipy.signal.savgol_coeffs`.

The new function `scipy.signal.vectorstrength` computes the vector strength,
a measure of phase synchrony, of a set of events.


``scipy.special`` improvements
------------------------------

The functions `scipy.special.boxcox` and `scipy.special.boxcox1p`, which
compute the Box-Cox transformation, have been added.


``scipy.sparse`` improvements
-----------------------------

- Significant performance improvement in CSR, CSC, and DOK indexing speed. 
- When using Numpy >= 1.9 (to be released in MM 2014), sparse matrices function
  correctly when given to arguments of ``np.dot``, ``np.multiply`` and other
  ufuncs.  With earlier Numpy and Scipy versions, the results of such
  operations are undefined and usually unexpected. 
- Sparse matrices are no longer limited to ``2^31`` nonzero elements.  They
  automatically switch to using 64-bit index data type for matrices containing
  more elements.  User code written assuming the sparse matrices use int32 as
  the index data type will continue to work, except for such large matrices.
  Code dealing with larger matrices needs to accept either int32 or int64
  indices. 


Deprecated features
===================

``anneal``
----------

The global minimization function `scipy.optimize.anneal` is deprecated.
All users should use the `scipy.optimize.basinhopping` function instead.

``scipy.stats``
---------------

``randwcdf`` and ``randwppf`` functions are deprecated. All users should use
distribution-specific ``rvs`` methods instead.

Probability calculation aliases ``zprob``, ``fprob`` and ``ksprob`` are
deprecated. Use instead the ``sf`` methods of the corresponding distributions
or the ``special`` functions directly.

``scipy.interpolate``
---------------------

``PiecewisePolynomial`` class is deprecated.


Backwards incompatible changes
==============================

scipy.special.lpmn
------------------

``lpmn`` no longer accepts complex-valued arguments. A new function
``clpmn`` with uniform complex analytic behavior has been added, and
it should be used instead.

scipy.sparse.linalg
-------------------

Eigenvectors in the case of generalized eigenvalue problem are normalized to
unit vectors in 2-norm, rather than following the LAPACK normalization
convention.

The deprecated UMFPACK wrapper in ``scipy.sparse.linalg`` has been removed due
to license and install issues.  If available, ``scikits.umfpack`` is still used
transparently in the ``spsolve`` and ``factorized`` functions.  Otherwise,
SuperLU is used instead in these functions.

scipy.stats
-----------

The deprecated functions ``glm``, ``oneway`` and ``cmedian`` have been removed
from ``scipy.stats``.

``stats.scoreatpercentile`` now returns an array instead of a list of
percentiles.

scipy.interpolate
-----------------

The API for computing derivatives of a monotone piecewise interpolation has
changed: if `p` is a ``PchipInterpolator`` object, `p.derivative(der)`
returns a callable object representing the derivative of `p`. For in-place
derivatives use the second argument of the `__call__` method: 
`p(0.1, der=2)` evaluates the second derivative of `p` at `x=0.1`.

The method `p.derivatives` has been removed.


Other changes
=============


Authors
=======

* Marc Abramowitz +
* Anders Bech Borchersen +
* Vincent Arel-Bundock +
* Petr Baudis +
* Max Bolingbroke
* François Boulogne
* Matthew Brett
* Lars Buitinck
* Evgeni Burovski
* CJ Carey +
* Thomas A Caswell +
* Pawel Chojnacki +
* Phillip Cloud +
* Stefano Costa +
* David Cournapeau
* David Menendez Hurtado +
* Matthieu Dartiailh +
* Christoph Deil +
* Jörg Dietrich +
* endolith
* Francisco de la Peña +
* Ben FrantzDale +
* Jim Garrison +
* André Gaul
* Christoph Gohlke
* Ralf Gommers
* Robert David Grant
* Alex Griffing
* Blake Griffith
* Yaroslav Halchenko
* Andreas Hilboll
* Kat Huang
* Gert-Ludwig Ingold
* James T. Webber +
* Dorota Jarecka +
* Todd Jennings +
* Thouis (Ray) Jones
* Juan Luis Cano Rodríguez
* ktritz +
* Jacques Kvam +
* Eric Larson +
* Justin Lavoie +
* Denis Laxalde
* Jussi Leinonen +
* lemonlaug +
* Tim Leslie
* Alain Leufroy +
* George Lewis +
* Max Linke +
* Brandon Liu +
* Benny Malengier +
* Matthias Kümmerer +
* Cimarron Mittelsteadt +
* Eric Moore
* Andrew Nelson +
* Niklas Hambüchen +
* Joel Nothman +
* Clemens Novak
* Emanuele Olivetti +
* Stefan Otte +
* peb +
* Josef Perktold
* pjwerneck
* poolio
* Jérôme Roy +
* Carl Sandrock +
* Andrew Sczesnak +
* Shauna +
* Fabrice Silva
* Daniel B. Smith
* Patrick Snape +
* Thomas Spura +
* Jacob Stevenson
* Julian Taylor
* Tomas Tomecek
* Richard Tsai
* Jacob Vanderplas
* Joris Vankerschaver +
* Pauli Virtanen
* Warren Weckesser

A total of 80 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed
-------------

- `#1325 <https://github.com/scipy/scipy/issues/1325>`__: add custom axis keyword to dendrogram function in scipy.cluster.hierarchy...
- `#1437 <https://github.com/scipy/scipy/issues/1437>`__: Wrong pochhammer symbol for negative integers (Trac #910)
- `#1555 <https://github.com/scipy/scipy/issues/1555>`__: scipy.io.netcdf leaks file descriptors (Trac #1028)
- `#1569 <https://github.com/scipy/scipy/issues/1569>`__: sparse matrix failed with element-wise multiplication using numpy.multiply()...
- `#1833 <https://github.com/scipy/scipy/issues/1833>`__: Sparse matrices are limited to 2^32 non-zero elements (Trac #1307)
- `#1834 <https://github.com/scipy/scipy/issues/1834>`__: scipy.linalg.eig does not normalize eigenvector if B is given...
- `#1866 <https://github.com/scipy/scipy/issues/1866>`__: stats for invgamma (Trac #1340)
- `#1886 <https://github.com/scipy/scipy/issues/1886>`__: stats.zipf floating point warnings (Trac #1361)
- `#1887 <https://github.com/scipy/scipy/issues/1887>`__: Stats continuous distributions - floating point warnings (Trac...
- `#1897 <https://github.com/scipy/scipy/issues/1897>`__: scoreatpercentile() does not handle empty list inputs (Trac #1372)
- `#1918 <https://github.com/scipy/scipy/issues/1918>`__: splint returns incorrect results (Trac #1393)
- `#1949 <https://github.com/scipy/scipy/issues/1949>`__: kurtosistest fails in mstats with type error (Trac #1424)
- `#2092 <https://github.com/scipy/scipy/issues/2092>`__: scipy.test leaves darwin27compiled_catalog, cpp and so files...
- `#2106 <https://github.com/scipy/scipy/issues/2106>`__: stats ENH: shape parameters in distribution docstrings (Trac...
- `#2123 <https://github.com/scipy/scipy/issues/2123>`__: Bad behavior of sparse matrices in a binary ufunc (Trac #1598)
- `#2152 <https://github.com/scipy/scipy/issues/2152>`__: Fix mmio/fromfile on gzip on Python 3 (Trac #1627)
- `#2164 <https://github.com/scipy/scipy/issues/2164>`__: stats.rice.pdf(x, 0) returns nan (Trac #1639)
- `#2169 <https://github.com/scipy/scipy/issues/2169>`__: scipy.optimize.fmin_bfgs not handling functions with boundaries...
- `#2177 <https://github.com/scipy/scipy/issues/2177>`__: scipy.cluster.hierarchy.ClusterNode.pre_order returns IndexError...
- `#2179 <https://github.com/scipy/scipy/issues/2179>`__: coo.todense() segfaults (Trac #1654)
- `#2185 <https://github.com/scipy/scipy/issues/2185>`__: Precision of scipy.ndimage.gaussian_filter*() limited (Trac #1660)
- `#2186 <https://github.com/scipy/scipy/issues/2186>`__: scipy.stats.mstats.kurtosistest crashes on 1d input (Trac #1661)
- `#2238 <https://github.com/scipy/scipy/issues/2238>`__: Negative p-value on hypergeom.cdf (Trac #1719)
- `#2283 <https://github.com/scipy/scipy/issues/2283>`__: ascending order in interpolation routines (Trac #1764)
- `#2288 <https://github.com/scipy/scipy/issues/2288>`__: mstats.kurtosistest is incorrectly converting to float, and fails...
- `#2396 <https://github.com/scipy/scipy/issues/2396>`__: lpmn wrong results for ``|z| > 1`` (Trac #1877)
- `#2398 <https://github.com/scipy/scipy/issues/2398>`__: ss2tf returns num as 2D array instead of 1D (Trac #1879)
- `#2406 <https://github.com/scipy/scipy/issues/2406>`__: linkage does not take Unicode strings as method names (Trac #1887)
- `#2443 <https://github.com/scipy/scipy/issues/2443>`__: IIR filter design should not transform to tf representation internally
- `#2572 <https://github.com/scipy/scipy/issues/2572>`__: class method solve of splu return object corrupted or falsely...
- `#2667 <https://github.com/scipy/scipy/issues/2667>`__: stats endless loop ?
- `#2671 <https://github.com/scipy/scipy/issues/2671>`__: .stats.hypergeom documentation error in the note about pmf
- `#2691 <https://github.com/scipy/scipy/issues/2691>`__: BUG scipy.linalg.lapack: potrf/ptroi interpret their 'lower'...
- `#2721 <https://github.com/scipy/scipy/issues/2721>`__: Allow use of ellipsis in scipy.sparse slicing
- `#2741 <https://github.com/scipy/scipy/issues/2741>`__: stats: deprecate and remove alias for special functions
- `#2742 <https://github.com/scipy/scipy/issues/2742>`__: stats add rvs to rice distribution
- `#2765 <https://github.com/scipy/scipy/issues/2765>`__: bugs stats entropy
- `#2832 <https://github.com/scipy/scipy/issues/2832>`__: argrelextrema returns tuple of 2 empty arrays when no peaks found...
- `#2861 <https://github.com/scipy/scipy/issues/2861>`__: scipy.stats.scoreatpercentile broken for vector `per`
- `#2891 <https://github.com/scipy/scipy/issues/2891>`__: COBYLA successful termination when constraints violated
- `#2919 <https://github.com/scipy/scipy/issues/2919>`__: test failure with the current master
- `#2922 <https://github.com/scipy/scipy/issues/2922>`__: ndimage.percentile_filter ignores origin argument for multidimensional...
- `#2938 <https://github.com/scipy/scipy/issues/2938>`__: Sparse/dense matrix inplace operations fail due to __numpy_ufunc__
- `#2944 <https://github.com/scipy/scipy/issues/2944>`__: MacPorts builds yield 40Mb worth of build warnings
- `#2945 <https://github.com/scipy/scipy/issues/2945>`__: FAIL: test_random_complex (test_basic.TestDet)
- `#2947 <https://github.com/scipy/scipy/issues/2947>`__: FAIL: Test some trivial edge cases for savgol_filter()
- `#2953 <https://github.com/scipy/scipy/issues/2953>`__: Scipy Delaunay triangulation is not oriented
- `#2971 <https://github.com/scipy/scipy/issues/2971>`__: scipy.stats.mstats.winsorize documentation error
- `#2980 <https://github.com/scipy/scipy/issues/2980>`__: Problems running what seems a perfectly valid example
- `#2996 <https://github.com/scipy/scipy/issues/2996>`__: entropy for rv_discrete is incorrect?!
- `#2998 <https://github.com/scipy/scipy/issues/2998>`__: Fix numpy version comparisons
- `#3002 <https://github.com/scipy/scipy/issues/3002>`__: python setup.py install fails
- `#3014 <https://github.com/scipy/scipy/issues/3014>`__: Bug in stats.fisher_exact
- `#3030 <https://github.com/scipy/scipy/issues/3030>`__: relative entropy using scipy.stats.distribution.entropy when...
- `#3037 <https://github.com/scipy/scipy/issues/3037>`__: scipy.optimize.curve_fit leads to unexpected behavior when input...
- `#3047 <https://github.com/scipy/scipy/issues/3047>`__: mstats.ttest_rel axis=None, requires masked array
- `#3059 <https://github.com/scipy/scipy/issues/3059>`__: BUG: Slices of sparse matrices return incorrect dtype
- `#3063 <https://github.com/scipy/scipy/issues/3063>`__: range keyword in binned_statistics incorrect
- `#3067 <https://github.com/scipy/scipy/issues/3067>`__: cumtrapz not working as expected
- `#3069 <https://github.com/scipy/scipy/issues/3069>`__: sinc
- `#3086 <https://github.com/scipy/scipy/issues/3086>`__: standard error calculation inconsistent between 'stats' and 'mstats'
- `#3094 <https://github.com/scipy/scipy/issues/3094>`__: Add a `perm` function into `scipy.misc` and an enhancement of...
- `#3111 <https://github.com/scipy/scipy/issues/3111>`__: scipy.sparse.[hv]stack don't respect anymore the dtype parameter
- `#3172 <https://github.com/scipy/scipy/issues/3172>`__: optimize.curve_fit uses different nomenclature from optimize.leastsq
- `#3196 <https://github.com/scipy/scipy/issues/3196>`__: scipy.stats.mstats.gmean does not actually take dtype
- `#3212 <https://github.com/scipy/scipy/issues/3212>`__: Dot product of csr_matrix causes segmentation fault
- `#3227 <https://github.com/scipy/scipy/issues/3227>`__: ZeroDivisionError in broyden1 when initial guess is the right...
- `#3238 <https://github.com/scipy/scipy/issues/3238>`__: lbfgsb output not suppressed by disp=0
- `#3249 <https://github.com/scipy/scipy/issues/3249>`__: Sparse matrix min/max/etc don't support axis=-1
- `#3251 <https://github.com/scipy/scipy/issues/3251>`__: cdist performance issue with 'sqeuclidean' metric
- `#3279 <https://github.com/scipy/scipy/issues/3279>`__: logm fails for singular matrix
- `#3285 <https://github.com/scipy/scipy/issues/3285>`__: signal.chirp(method='hyp') disallows hyperbolic upsweep
- `#3299 <https://github.com/scipy/scipy/issues/3299>`__: MEMORY LEAK: fmin_tnc
- `#3330 <https://github.com/scipy/scipy/issues/3330>`__: test failures with the current master
- `#3345 <https://github.com/scipy/scipy/issues/3345>`__: scipy and/or numpy change is causing tests to fail in another...
- `#3363 <https://github.com/scipy/scipy/issues/3363>`__: splu does not work for non-vector inputs
- `#3385 <https://github.com/scipy/scipy/issues/3385>`__: expit does not handle large arguments well
- `#3395 <https://github.com/scipy/scipy/issues/3395>`__: specfun.f doesn't compile with MinGW
- `#3399 <https://github.com/scipy/scipy/issues/3399>`__: Error message bug in scipy.cluster.hierarchy.linkage
- `#3404 <https://github.com/scipy/scipy/issues/3404>`__: interpolate._ppoly doesn't build with MinGW
- `#3412 <https://github.com/scipy/scipy/issues/3412>`__: Test failures in signal
- `#3466 <https://github.com/scipy/scipy/issues/3466>`__: ```scipy.sparse.csgraph.shortest_path``` does not work on ```scipy.sparse.csr_matrix``` or ```lil_matrix```


Pull requests
-------------

- `#442 <https://github.com/scipy/scipy/pull/442>`__: ENH: sparse: enable 64-bit index arrays & nnz > 2**31
- `#2766 <https://github.com/scipy/scipy/pull/2766>`__: DOC: remove doc/seps/technology-preview.rst
- `#2772 <https://github.com/scipy/scipy/pull/2772>`__: TST: stats: Added a regression test for stats.wilcoxon. Closes...
- `#2778 <https://github.com/scipy/scipy/pull/2778>`__: Clean up stats._support, close statistics review issues
- `#2792 <https://github.com/scipy/scipy/pull/2792>`__: BUG io: fix file descriptor closing for netcdf variables
- `#2847 <https://github.com/scipy/scipy/pull/2847>`__: Rice distribution: extend to b=0, add an explicit rvs method.
- `#2878 <https://github.com/scipy/scipy/pull/2878>`__: [stats] fix formulas for higher moments of dweibull distribution
- `#2904 <https://github.com/scipy/scipy/pull/2904>`__: ENH: moments for the zipf distribution
- `#2907 <https://github.com/scipy/scipy/pull/2907>`__: ENH: add coverage info with coveralls.io for Travis runs.
- `#2932 <https://github.com/scipy/scipy/pull/2932>`__: BUG+TST: setdiag implementation for dia_matrix (Close #2931)...
- `#2942 <https://github.com/scipy/scipy/pull/2942>`__: Misc fixes pointed out by Eclipse PyDev static code analysis
- `#2946 <https://github.com/scipy/scipy/pull/2946>`__: ENH: allow non-monotonic input in interp1d
- `#2986 <https://github.com/scipy/scipy/pull/2986>`__: BUG: runtests: chdir away from root when running tests
- `#2987 <https://github.com/scipy/scipy/pull/2987>`__: DOC: linalg: don't recommend np.linalg.norm
- `#2992 <https://github.com/scipy/scipy/pull/2992>`__: ENH: Add "limit" parameter to dijkstra calculation
- `#2995 <https://github.com/scipy/scipy/pull/2995>`__: ENH: Use int shape
- `#3006 <https://github.com/scipy/scipy/pull/3006>`__: DOC: stats: add a log base note to the docstring
- `#3007 <https://github.com/scipy/scipy/pull/3007>`__: DEP: stats: Deprecate randwppf and randwcdf
- `#3008 <https://github.com/scipy/scipy/pull/3008>`__: Fix mstats.kurtosistest, and test coverage for skewtest/normaltest
- `#3009 <https://github.com/scipy/scipy/pull/3009>`__: Minor reST typo
- `#3010 <https://github.com/scipy/scipy/pull/3010>`__: Add `scipy.optimize.Result` to API docs
- `#3012 <https://github.com/scipy/scipy/pull/3012>`__: Corrects documentation error
- `#3052 <https://github.com/scipy/scipy/pull/3052>`__: PEP-8 conformance improvements
- `#3064 <https://github.com/scipy/scipy/pull/3064>`__: Binned statistic
- `#3068 <https://github.com/scipy/scipy/pull/3068>`__: Fix Issue #3067 fix cumptrapz that was raising an exception when...
- `#3073 <https://github.com/scipy/scipy/pull/3073>`__: Arff reader with nominal value of 1 character
- `#3074 <https://github.com/scipy/scipy/pull/3074>`__: Some maintenance work
- `#3080 <https://github.com/scipy/scipy/pull/3080>`__: Review and clean up all Box-Cox functions
- `#3083 <https://github.com/scipy/scipy/pull/3083>`__: Bug: should return 0 if no regions found
- `#3085 <https://github.com/scipy/scipy/pull/3085>`__: BUG: Use zpk in IIR filter design to improve accuracy
- `#3101 <https://github.com/scipy/scipy/pull/3101>`__: refactor stats tests a bit
- `#3112 <https://github.com/scipy/scipy/pull/3112>`__: ENH: implement Akima interpolation in 1D
- `#3123 <https://github.com/scipy/scipy/pull/3123>`__: MAINT: an easier way to make ranges from slices
- `#3124 <https://github.com/scipy/scipy/pull/3124>`__: File object support for imread and imsave
- `#3126 <https://github.com/scipy/scipy/pull/3126>`__: pep8ify stats/distributions.py
- `#3134 <https://github.com/scipy/scipy/pull/3134>`__: MAINT: split distributions.py into three files
- `#3138 <https://github.com/scipy/scipy/pull/3138>`__: clean up tests for discrete distributions
- `#3155 <https://github.com/scipy/scipy/pull/3155>`__: special: handle the edge case lambda=0 in pdtr, pdtrc and pdtrik
- `#3156 <https://github.com/scipy/scipy/pull/3156>`__: Rename optimize.Result to OptimizeResult
- `#3166 <https://github.com/scipy/scipy/pull/3166>`__: BUG: make curve_fit() work with array_like input. Closes gh-3037.
- `#3170 <https://github.com/scipy/scipy/pull/3170>`__: Fix numpy version checks
- `#3175 <https://github.com/scipy/scipy/pull/3175>`__: use numpy sinc
- `#3177 <https://github.com/scipy/scipy/pull/3177>`__: Update numpy version warning, remove oldnumeric import
- `#3178 <https://github.com/scipy/scipy/pull/3178>`__: DEP: remove deprecated umfpack wrapper. Closes gh-3002.
- `#3179 <https://github.com/scipy/scipy/pull/3179>`__: DOC: add BPoly to the docs
- `#3180 <https://github.com/scipy/scipy/pull/3180>`__: Suppress warnings when running stats.test()
- `#3181 <https://github.com/scipy/scipy/pull/3181>`__: altered sem func in mstats to match stats
- `#3182 <https://github.com/scipy/scipy/pull/3182>`__: Make weave tests behave
- `#3183 <https://github.com/scipy/scipy/pull/3183>`__: ENH: Add k-sample Anderson-Darling test to stats module
- `#3186 <https://github.com/scipy/scipy/pull/3186>`__: Fix stats.scoreatpercentile
- `#3187 <https://github.com/scipy/scipy/pull/3187>`__: DOC: make curve_fit nomenclature same as leastsq
- `#3201 <https://github.com/scipy/scipy/pull/3201>`__: Added axis keyword to dendrogram function
- `#3207 <https://github.com/scipy/scipy/pull/3207>`__: Make docstring examples in stats.distributions docstrings runnable
- `#3218 <https://github.com/scipy/scipy/pull/3218>`__: BUG: integrate: Fix banded jacobian handling in the "vode" and...
- `#3222 <https://github.com/scipy/scipy/pull/3222>`__: BUG: limit input ranges in special.nctdtr
- `#3223 <https://github.com/scipy/scipy/pull/3223>`__: Fix test errors with numpy master
- `#3224 <https://github.com/scipy/scipy/pull/3224>`__: Fix int32 overflows in sparsetools
- `#3228 <https://github.com/scipy/scipy/pull/3228>`__: DOC: tf2ss zpk2ss note controller canonical form
- `#3234 <https://github.com/scipy/scipy/pull/3234>`__: Add See Also links and Example graphs to filter design ``*ord`` functions
- `#3235 <https://github.com/scipy/scipy/pull/3235>`__: Updated the buttord function to be consistent with the other...
- `#3239 <https://github.com/scipy/scipy/pull/3239>`__: correct doc for pchip interpolation
- `#3240 <https://github.com/scipy/scipy/pull/3240>`__: DOC: fix ReST errors in the BPoly docstring
- `#3241 <https://github.com/scipy/scipy/pull/3241>`__: RF: check write attr of fileobject without writing
- `#3243 <https://github.com/scipy/scipy/pull/3243>`__: a bit of maintanence work in stats
- `#3245 <https://github.com/scipy/scipy/pull/3245>`__: BUG/ENH: stats: make frozen distributions hold separate instances
- `#3247 <https://github.com/scipy/scipy/pull/3247>`__: ENH function to return nnz per row/column in some sparse matrices
- `#3248 <https://github.com/scipy/scipy/pull/3248>`__: ENH much more efficient sparse min/max with axis
- `#3252 <https://github.com/scipy/scipy/pull/3252>`__: Fast sqeuclidean
- `#3253 <https://github.com/scipy/scipy/pull/3253>`__: FIX support axis=-1 and -2 for sparse reduce methods
- `#3254 <https://github.com/scipy/scipy/pull/3254>`__: TST tests for non-canonical input to sparse matrix operations
- `#3272 <https://github.com/scipy/scipy/pull/3272>`__: BUG: sparse: fix bugs in dia_matrix.setdiag
- `#3278 <https://github.com/scipy/scipy/pull/3278>`__: Also generate a tar.xz when running paver sdist
- `#3286 <https://github.com/scipy/scipy/pull/3286>`__: DOC: update 0.14.0 release notes.
- `#3289 <https://github.com/scipy/scipy/pull/3289>`__: TST: remove insecure mktemp use in tests
- `#3292 <https://github.com/scipy/scipy/pull/3292>`__: MAINT: fix a backwards incompatible change to stats.distributions.__all__
- `#3293 <https://github.com/scipy/scipy/pull/3293>`__: ENH: signal: Allow upsweeps of frequency in the 'hyperbolic'...
- `#3302 <https://github.com/scipy/scipy/pull/3302>`__: ENH: add dtype arg to stats.mstats.gmean and stats.mstats.hmean
- `#3307 <https://github.com/scipy/scipy/pull/3307>`__: DOC: add note about different ba forms in tf2zpk
- `#3309 <https://github.com/scipy/scipy/pull/3309>`__: doc enhancements to scipy.stats.mstats.winsorize
- `#3310 <https://github.com/scipy/scipy/pull/3310>`__: DOC: clarify matrix vs array in mmio docstrings
- `#3314 <https://github.com/scipy/scipy/pull/3314>`__: BUG: fix scipy.io.mmread() of gzipped files under Python3
- `#3323 <https://github.com/scipy/scipy/pull/3323>`__: ENH: Efficient interpolation on regular grids in arbitrary dimensions
- `#3332 <https://github.com/scipy/scipy/pull/3332>`__: DOC: clean up scipy.special docs
- `#3335 <https://github.com/scipy/scipy/pull/3335>`__: ENH: improve nanmedian performance
- `#3347 <https://github.com/scipy/scipy/pull/3347>`__: BUG: fix use of np.max in stats.fisher_exact
- `#3356 <https://github.com/scipy/scipy/pull/3356>`__: ENH: sparse: speed up LIL indexing + assignment via Cython
- `#3357 <https://github.com/scipy/scipy/pull/3357>`__: Fix "imresize does not work with size = int"
- `#3358 <https://github.com/scipy/scipy/pull/3358>`__: MAINT: rename AkimaInterpolator to Akima1DInterpolator
- `#3366 <https://github.com/scipy/scipy/pull/3366>`__: WHT: sparse: reindent ``dsolve/*.c *.h``
- `#3367 <https://github.com/scipy/scipy/pull/3367>`__: BUG: sparse/dsolve: fix dense matrix fortran order bugs in superlu...
- `#3369 <https://github.com/scipy/scipy/pull/3369>`__: ENH minimize, minimize_scalar: Add support for user-provided...
- `#3371 <https://github.com/scipy/scipy/pull/3371>`__: scipy.stats.sigmaclip doesn't appear in the html docs.
- `#3373 <https://github.com/scipy/scipy/pull/3373>`__: BUG: sparse/dsolve: detect invalid LAPACK parameters in superlu...
- `#3375 <https://github.com/scipy/scipy/pull/3375>`__: ENH: sparse/dsolve: make the L and U factors of splu and spilu...
- `#3377 <https://github.com/scipy/scipy/pull/3377>`__: MAINT: make travis build one target against Numpy 1.5
- `#3378 <https://github.com/scipy/scipy/pull/3378>`__: MAINT: fftpack: Remove the use of ``'import *'`` in a couple test...
- `#3381 <https://github.com/scipy/scipy/pull/3381>`__: MAINT: replace np.isinf(x) & (x>0) -> np.isposinf(x) to avoid...
- `#3383 <https://github.com/scipy/scipy/pull/3383>`__: MAINT: skip float96 tests on platforms without float96
- `#3384 <https://github.com/scipy/scipy/pull/3384>`__: MAINT: add pyflakes to Travis-CI
- `#3386 <https://github.com/scipy/scipy/pull/3386>`__: BUG: stable evaluation of expit
- `#3388 <https://github.com/scipy/scipy/pull/3388>`__: BUG: SuperLU: fix missing declaration of dlamch
- `#3389 <https://github.com/scipy/scipy/pull/3389>`__: BUG: sparse: downcast 64-bit indices safely to intp when required
- `#3390 <https://github.com/scipy/scipy/pull/3390>`__: BUG: nonlinear solvers are not confused by lucky guess
- `#3391 <https://github.com/scipy/scipy/pull/3391>`__: TST: fix sparse test errors due to axis=-1,-2 usage in np.matrix.sum().
- `#3392 <https://github.com/scipy/scipy/pull/3392>`__: BUG: sparse/lil: fix up Cython bugs in fused type lookup
- `#3393 <https://github.com/scipy/scipy/pull/3393>`__: BUG: sparse/compressed: work around bug in np.unique in earlier...
- `#3394 <https://github.com/scipy/scipy/pull/3394>`__: BUG: allow ClusterNode.pre_order() for non-root nodes
- `#3400 <https://github.com/scipy/scipy/pull/3400>`__: BUG: cluster.linkage ValueError typo bug
- `#3402 <https://github.com/scipy/scipy/pull/3402>`__: BUG: special: In specfun.f, replace the use of CMPLX with DCMPLX,...
- `#3408 <https://github.com/scipy/scipy/pull/3408>`__: MAINT: sparse: Numpy 1.5 compatibility fixes
- `#3410 <https://github.com/scipy/scipy/pull/3410>`__: MAINT: interpolate: fix blas defs in _ppoly
- `#3411 <https://github.com/scipy/scipy/pull/3411>`__: MAINT: Numpy 1.5 fixes in interpolate
- `#3413 <https://github.com/scipy/scipy/pull/3413>`__: Fix more test issues with older numpy versions
- `#3414 <https://github.com/scipy/scipy/pull/3414>`__: TST: signal: loosen some error tolerances in the filter tests....
- `#3415 <https://github.com/scipy/scipy/pull/3415>`__: MAINT: tools: automated close issue + pr listings for release...
- `#3440 <https://github.com/scipy/scipy/pull/3440>`__: MAINT: wrap sparsetools manually instead via SWIG
- `#3460 <https://github.com/scipy/scipy/pull/3460>`__: TST: open image file in binary mode
- `#3467 <https://github.com/scipy/scipy/pull/3467>`__: BUG: fix validation in csgraph.shortest_path
==========================
SciPy 0.19.0 Release Notes
==========================

.. contents::

SciPy 0.19.0 is the culmination of 7 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.19.x branch, and on adding
new features on the master branch.

This release requires Python 2.7 or 3.4-3.6 and NumPy 1.8.2 or greater.

Highlights of this release include:

- A unified foreign function interface layer, `scipy.LowLevelCallable`.
- Cython API for scalar, typed versions of the universal functions from
  the `scipy.special` module, via `cimport scipy.special.cython_special`.


New features
============

Foreign function interface improvements
---------------------------------------

`scipy.LowLevelCallable` provides a new unified interface for wrapping
low-level compiled callback functions in the Python space. It supports
Cython imported "api" functions, ctypes function pointers, CFFI function
pointers, ``PyCapsules``, Numba jitted functions and more.
See `gh-6509 <https://github.com/scipy/scipy/pull/6509>`_ for details.


`scipy.linalg` improvements
---------------------------

The function `scipy.linalg.solve` obtained two more keywords ``assume_a`` and
``transposed``. The underlying LAPACK routines are replaced with "expert"
versions and now can also be used to solve symmetric, hermitian and positive
definite coefficient matrices. Moreover, ill-conditioned matrices now cause
a warning to be emitted with the estimated condition number information. Old
``sym_pos`` keyword is kept for backwards compatibility reasons however it
is identical to using ``assume_a='pos'``. Moreover, the ``debug`` keyword,
which had no function but only printing the ``overwrite_<a, b>`` values, is
deprecated.

The function `scipy.linalg.matrix_balance` was added to perform the so-called
matrix balancing using the LAPACK xGEBAL routine family. This can be used to
approximately equate the row and column norms through diagonal similarity
transformations.

The functions `scipy.linalg.solve_continuous_are` and
`scipy.linalg.solve_discrete_are` have numerically more stable algorithms.
These functions can also solve generalized algebraic matrix Riccati equations.
Moreover, both gained a ``balanced`` keyword to turn balancing on and off.

`scipy.spatial` improvements
----------------------------

`scipy.spatial.SphericalVoronoi.sort_vertices_of_regions` has been re-written in
Cython to improve performance.

`scipy.spatial.SphericalVoronoi` can handle > 200 k points (at least 10 million)
and has improved performance.

The function `scipy.spatial.distance.directed_hausdorff` was
added to calculate the directed Hausdorff distance.

``count_neighbors`` method of `scipy.spatial.cKDTree` gained an ability to
perform weighted pair counting via the new keywords ``weights`` and
``cumulative``. See `gh-5647 <https://github.com/scipy/scipy/pull/5647>`_ for
details.

`scipy.spatial.distance.pdist` and `scipy.spatial.distance.cdist` now support
non-double custom metrics.

`scipy.ndimage` improvements
----------------------------

The callback function C API supports PyCapsules in Python 2.7

Multidimensional filters now allow having different extrapolation modes for
different axes.

`scipy.optimize` improvements
-----------------------------

The `scipy.optimize.basinhopping` global minimizer obtained a new keyword,
`seed`, which can be used to seed the random number generator and obtain
repeatable minimizations.

The keyword `sigma` in `scipy.optimize.curve_fit` was overloaded to also accept
the covariance matrix of errors in the data.

`scipy.signal` improvements
---------------------------

The function `scipy.signal.correlate` and `scipy.signal.convolve` have a new
optional parameter `method`. The default value of `auto` estimates the fastest
of two computation methods, the direct approach and the Fourier transform
approach.

A new function has been added to choose the convolution/correlation method,
`scipy.signal.choose_conv_method` which may be appropriate if convolutions or
correlations are performed on many arrays of the same size.

New functions have been added to calculate complex short time fourier
transforms of an input signal, and to invert the transform to recover the
original signal: `scipy.signal.stft` and `scipy.signal.istft`. This
implementation also fixes the previously incorrect output of
`scipy.signal.spectrogram` when complex output data were requested.

The function `scipy.signal.sosfreqz` was added to compute the frequency
response from second-order sections.

The function `scipy.signal.unit_impulse` was added to conveniently
generate an impulse function.

The function `scipy.signal.iirnotch` was added to design second-order
IIR notch filters that can be used to remove a frequency component from
a signal. The dual function  `scipy.signal.iirpeak` was added to
compute the coefficients of a second-order IIR peak (resonant) filter.

The function `scipy.signal.minimum_phase` was added to convert linear-phase
FIR filters to minimum phase.

The functions `scipy.signal.upfirdn` and `scipy.signal.resample_poly` are now
substantially faster when operating on some n-dimensional arrays when n > 1.
The largest reduction in computation time is realized in cases where the size
of the array is small (<1k samples or so) along the axis to be filtered.

`scipy.fftpack` improvements
----------------------------

Fast Fourier transform routines now accept `np.float16` inputs and upcast
them to `np.float32`. Previously, they would raise an error.

`scipy.cluster` improvements
----------------------------

Methods ``"centroid"`` and ``"median"`` of `scipy.cluster.hierarchy.linkage`
have been significantly sped up. Long-standing issues with using ``linkage`` on
large input data (over 16 GB) have been resolved.

`scipy.sparse` improvements
---------------------------

The functions `scipy.sparse.save_npz` and `scipy.sparse.load_npz` were added,
providing simple serialization for some sparse formats.

The `prune` method of classes `bsr_matrix`, `csc_matrix`, and `csr_matrix`
was updated to reallocate backing arrays under certain conditions, reducing
memory usage.

The methods `argmin` and `argmax` were added to classes `coo_matrix`,
`csc_matrix`, `csr_matrix`, and `bsr_matrix`.

New function `scipy.sparse.csgraph.structural_rank` computes the structural
rank of a graph with a given sparsity pattern.

New function `scipy.sparse.linalg.spsolve_triangular` solves a sparse linear
system with a triangular left hand side matrix.


`scipy.special` improvements
----------------------------

Scalar, typed versions of universal functions from `scipy.special` are available
in the Cython space via ``cimport`` from the new module
`scipy.special.cython_special`. These scalar functions can be expected to be
significantly faster then the universal functions for scalar arguments. See
the `scipy.special` tutorial for details.

Better control over special-function errors is offered by the
functions `scipy.special.geterr` and `scipy.special.seterr` and the
context manager `scipy.special.errstate`.

The names of orthogonal polynomial root functions have been changed to
be consistent with other functions relating to orthogonal
polynomials. For example, ``scipy.special.j_roots`` has been renamed
`scipy.special.roots_jacobi` for consistency with the related
functions `scipy.special.jacobi` and `scipy.special.eval_jacobi`. To
preserve back-compatibility the old names have been left as aliases.

Wright Omega function is implemented as `scipy.special.wrightomega`.


`scipy.stats` improvements
--------------------------

The function `scipy.stats.weightedtau` was added.  It provides a weighted
version of Kendall's tau.

New class `scipy.stats.multinomial` implements the multinomial distribution.

New class `scipy.stats.rv_histogram` constructs a continuous univariate
distribution with a piecewise linear CDF from a binned data sample.

New class `scipy.stats.argus` implements the Argus distribution.


`scipy.interpolate` improvements
--------------------------------

New class `scipy.interpolate.BSpline` represents splines. ``BSpline`` objects
contain knots and coefficients and can evaluate the spline. The format is
consistent with FITPACK, so that one can do, for example::

    >>> t, c, k = splrep(x, y, s=0)
    >>> spl = BSpline(t, c, k)
    >>> np.allclose(spl(x), y)

``spl*`` functions, `scipy.interpolate.splev`, `scipy.interpolate.splint`,
`scipy.interpolate.splder` and `scipy.interpolate.splantider`, accept both
``BSpline`` objects and ``(t, c, k)`` tuples for backwards compatibility.

For multidimensional splines, ``c.ndim > 1``, ``BSpline`` objects are consistent
with piecewise polynomials, `scipy.interpolate.PPoly`. This means that
``BSpline`` objects are not immediately consistent with
`scipy.interpolate.splprep`, and one *cannot* do
``>>> BSpline(*splprep([x, y])[0])``. Consult the `scipy.interpolate` test suite
for examples of the precise equivalence.

In new code, prefer using ``scipy.interpolate.BSpline`` objects instead of
manipulating ``(t, c, k)`` tuples directly.

New function `scipy.interpolate.make_interp_spline` constructs an interpolating
spline given data points and boundary conditions.

New function `scipy.interpolate.make_lsq_spline` constructs a least-squares
spline approximation given data points.

`scipy.integrate` improvements
------------------------------

Now `scipy.integrate.fixed_quad` supports vector-valued functions.


Deprecated features
===================

`scipy.interpolate.splmake`, `scipy.interpolate.spleval` and
`scipy.interpolate.spline` are deprecated. The format used by `splmake/spleval`
was inconsistent with `splrep/splev` which was confusing to users.

`scipy.special.errprint` is deprecated. Improved functionality is
available in `scipy.special.seterr`.

calling `scipy.spatial.distance.pdist` or `scipy.spatial.distance.cdist` with
arguments not needed by the chosen metric is deprecated. Also, metrics
`"old_cosine"` and `"old_cos"` are deprecated.


Backwards incompatible changes
==============================

The deprecated ``scipy.weave`` submodule was removed.

`scipy.spatial.distance.squareform` now returns arrays of the same dtype as
the input, instead of always float64.

`scipy.special.errprint` now returns a boolean.

The function `scipy.signal.find_peaks_cwt` now returns an array instead of
a list.

`scipy.stats.kendalltau` now computes the correct p-value in case the
input contains ties. The p-value is also identical to that computed by
`scipy.stats.mstats.kendalltau` and by R. If the input does not
contain ties there is no change w.r.t. the previous implementation.

The function `scipy.linalg.block_diag` will not ignore zero-sized matrices anymore.
Instead it will insert rows or columns of zeros of the appropriate size.
See gh-4908 for more details.


Other changes
=============

SciPy wheels will now report their dependency on ``numpy`` on all platforms.
This change was made because Numpy wheels are available, and because the pip
upgrade behavior is finally changing for the better (use
``--upgrade-strategy=only-if-needed`` for ``pip >= 8.2``; that behavior will
become the default in the next major version of ``pip``).

Numerical values returned by `scipy.interpolate.interp1d` with ``kind="cubic"``
and ``"quadratic"`` may change relative to previous scipy versions. If your
code depended on specific numeric values (i.e., on implementation
details of the interpolators), you may want to double-check your results.


Authors
=======

* @endolith
* Max Argus +
* Hervé Audren
* Alessandro Pietro Bardelli +
* Michael Benfield +
* Felix Berkenkamp
* Matthew Brett
* Per Brodtkorb
* Evgeni Burovski
* Pierre de Buyl
* CJ Carey
* Brandon Carter +
* Tim Cera
* Klesk Chonkin
* Christian Häggström +
* Luca Citi
* Peadar Coyle +
* Daniel da Silva +
* Greg Dooper +
* John Draper +
* drlvk +
* David Ellis +
* Yu Feng
* Baptiste Fontaine +
* Jed Frey +
* Siddhartha Gandhi +
* Wim Glenn +
* Akash Goel +
* Christoph Gohlke
* Ralf Gommers
* Alexander Goncearenco +
* Richard Gowers +
* Alex Griffing
* Radoslaw Guzinski +
* Charles Harris
* Callum Jacob Hays +
* Ian Henriksen
* Randy Heydon +
* Lindsey Hiltner +
* Gerrit Holl +
* Hiroki IKEDA +
* jfinkels +
* Mher Kazandjian +
* Thomas Keck +
* keuj6 +
* Kornel Kielczewski +
* Sergey B Kirpichev +
* Vasily Kokorev +
* Eric Larson
* Denis Laxalde
* Gregory R. Lee
* Josh Lefler +
* Julien Lhermitte +
* Evan Limanto +
* Jin-Guo Liu +
* Nikolay Mayorov
* Geordie McBain +
* Josue Melka +
* Matthieu Melot
* michaelvmartin15 +
* Surhud More +
* Brett M. Morris +
* Chris Mutel +
* Paul Nation
* Andrew Nelson
* David Nicholson +
* Aaron Nielsen +
* Joel Nothman
* nrnrk +
* Juan Nunez-Iglesias
* Mikhail Pak +
* Gavin Parnaby +
* Thomas Pingel +
* Ilhan Polat +
* Aman Pratik +
* Sebastian Pucilowski
* Ted Pudlik
* puenka +
* Eric Quintero
* Tyler Reddy
* Joscha Reimer
* Antonio Horta Ribeiro +
* Edward Richards +
* Roman Ring +
* Rafael Rossi +
* Colm Ryan +
* Sami Salonen +
* Alvaro Sanchez-Gonzalez +
* Johannes Schmitz
* Kari Schoonbee
* Yurii Shevchuk +
* Jonathan Siebert +
* Jonathan Tammo Siebert +
* Scott Sievert +
* Sourav Singh
* Byron Smith +
* Srikiran +
* Samuel St-Jean +
* Yoni Teitelbaum +
* Bhavika Tekwani
* Martin Thoma
* timbalam +
* Svend Vanderveken +
* Sebastiano Vigna +
* Aditya Vijaykumar +
* Santi Villalba +
* Ze Vinicius
* Pauli Virtanen
* Matteo Visconti
* Yusuke Watanabe +
* Warren Weckesser
* Phillip Weinberg +
* Nils Werner
* Jakub Wilk
* Josh Wilson
* wirew0rm +
* David Wolever +
* Nathan Woods
* ybeltukov +
* G Young
* Evgeny Zhurko +

A total of 121 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 0.19.0
------------------------

- `#1767 <https://github.com/scipy/scipy/issues/1767>`__: Function definitions in __fitpack.h should be moved. (Trac #1240)
- `#1774 <https://github.com/scipy/scipy/issues/1774>`__: _kmeans chokes on large thresholds (Trac #1247)
- `#2089 <https://github.com/scipy/scipy/issues/2089>`__: Integer overflows cause segfault in linkage function with large...
- `#2190 <https://github.com/scipy/scipy/issues/2190>`__: Are odd-length window functions supposed to be always symmetrical?...
- `#2251 <https://github.com/scipy/scipy/issues/2251>`__: solve_discrete_are in scipy.linalg does (sometimes) not solve...
- `#2580 <https://github.com/scipy/scipy/issues/2580>`__: scipy.interpolate.UnivariateSpline (or a new superclass of it)...
- `#2592 <https://github.com/scipy/scipy/issues/2592>`__: scipy.stats.anderson assumes gumbel_l
- `#3054 <https://github.com/scipy/scipy/issues/3054>`__: scipy.linalg.eig does not handle infinite eigenvalues
- `#3160 <https://github.com/scipy/scipy/issues/3160>`__: multinomial pmf / logpmf
- `#3904 <https://github.com/scipy/scipy/issues/3904>`__: scipy.special.ellipj dn wrong values at quarter period
- `#4044 <https://github.com/scipy/scipy/issues/4044>`__: Inconsistent code book initialization in kmeans
- `#4234 <https://github.com/scipy/scipy/issues/4234>`__: scipy.signal.flattop documentation doesn't list a source for...
- `#4831 <https://github.com/scipy/scipy/issues/4831>`__: Bugs in C code in __quadpack.h
- `#4908 <https://github.com/scipy/scipy/issues/4908>`__: bug: unnessesary validity check for block dimension in scipy.sparse.block_diag
- `#4917 <https://github.com/scipy/scipy/issues/4917>`__: BUG: indexing error for sparse matrix with ix\_
- `#4938 <https://github.com/scipy/scipy/issues/4938>`__: Docs on extending ndimage need to be updated.
- `#5056 <https://github.com/scipy/scipy/issues/5056>`__: sparse matrix element-wise multiplying dense matrix returns dense...
- `#5337 <https://github.com/scipy/scipy/issues/5337>`__: Formula in documentation for correlate is wrong
- `#5537 <https://github.com/scipy/scipy/issues/5537>`__: use OrderedDict in io.netcdf
- `#5750 <https://github.com/scipy/scipy/issues/5750>`__: [doc] missing data index value in KDTree, cKDTree
- `#5755 <https://github.com/scipy/scipy/issues/5755>`__: p-value computation in scipy.stats.kendalltau() in broken in...
- `#5757 <https://github.com/scipy/scipy/issues/5757>`__: BUG: Incorrect complex output of signal.spectrogram
- `#5964 <https://github.com/scipy/scipy/issues/5964>`__: ENH: expose scalar versions of scipy.special functions to cython
- `#6107 <https://github.com/scipy/scipy/issues/6107>`__: scipy.cluster.hierarchy.single segmentation fault with 2**16...
- `#6278 <https://github.com/scipy/scipy/issues/6278>`__: optimize.basinhopping should take a RandomState object
- `#6296 <https://github.com/scipy/scipy/issues/6296>`__: InterpolatedUnivariateSpline: check_finite fails when w is unspecified
- `#6306 <https://github.com/scipy/scipy/issues/6306>`__: Anderson-Darling bad results
- `#6314 <https://github.com/scipy/scipy/issues/6314>`__: scipy.stats.kendaltau() p value not in agreement with R, SPSS...
- `#6340 <https://github.com/scipy/scipy/issues/6340>`__: Curve_fit bounds and maxfev
- `#6377 <https://github.com/scipy/scipy/issues/6377>`__: expm_multiply, complex matrices not working using start,stop,etc...
- `#6382 <https://github.com/scipy/scipy/issues/6382>`__: optimize.differential_evolution stopping criterion has unintuitive...
- `#6391 <https://github.com/scipy/scipy/issues/6391>`__: Global Benchmarking times out at 600s.
- `#6397 <https://github.com/scipy/scipy/issues/6397>`__: mmwrite errors with large (but still 64-bit) integers
- `#6413 <https://github.com/scipy/scipy/issues/6413>`__: scipy.stats.dirichlet computes multivariate gaussian differential...
- `#6428 <https://github.com/scipy/scipy/issues/6428>`__: scipy.stats.mstats.mode modifies input
- `#6440 <https://github.com/scipy/scipy/issues/6440>`__: Figure out ABI break policy for scipy.special Cython API
- `#6441 <https://github.com/scipy/scipy/issues/6441>`__: Using Qhull for halfspace intersection : segfault
- `#6442 <https://github.com/scipy/scipy/issues/6442>`__: scipy.spatial : In incremental mode volume is not recomputed
- `#6451 <https://github.com/scipy/scipy/issues/6451>`__: Documentation for scipy.cluster.hierarchy.to_tree is confusing...
- `#6490 <https://github.com/scipy/scipy/issues/6490>`__: interp1d (kind=zero) returns wrong value for rightmost interpolation...
- `#6521 <https://github.com/scipy/scipy/issues/6521>`__: scipy.stats.entropy does *not* calculate the KL divergence
- `#6530 <https://github.com/scipy/scipy/issues/6530>`__: scipy.stats.spearmanr unexpected NaN handling
- `#6541 <https://github.com/scipy/scipy/issues/6541>`__: Test runner does not run scipy._lib/tests?
- `#6552 <https://github.com/scipy/scipy/issues/6552>`__: BUG: misc.bytescale returns unexpected results when using cmin/cmax...
- `#6556 <https://github.com/scipy/scipy/issues/6556>`__: RectSphereBivariateSpline(u, v, r) fails if min(v) >= pi
- `#6559 <https://github.com/scipy/scipy/issues/6559>`__: Differential_evolution maxiter causing memory overflow
- `#6565 <https://github.com/scipy/scipy/issues/6565>`__: Coverage of spectral functions could be improved
- `#6628 <https://github.com/scipy/scipy/issues/6628>`__: Incorrect parameter name in binomial documentation
- `#6634 <https://github.com/scipy/scipy/issues/6634>`__: Expose LAPACK's xGESVX family for linalg.solve ill-conditioned...
- `#6657 <https://github.com/scipy/scipy/issues/6657>`__: Confusing documentation for `scipy.special.sph_harm`
- `#6676 <https://github.com/scipy/scipy/issues/6676>`__: optimize: Incorrect size of Jacobian returned by \`minimize(...,...
- `#6681 <https://github.com/scipy/scipy/issues/6681>`__: add a new context manager to wrap `scipy.special.seterr`
- `#6700 <https://github.com/scipy/scipy/issues/6700>`__: BUG: scipy.io.wavfile.read stays in infinite loop, warns on wav...
- `#6721 <https://github.com/scipy/scipy/issues/6721>`__: scipy.special.chebyt(N) throw a 'TypeError' when N > 64
- `#6727 <https://github.com/scipy/scipy/issues/6727>`__: Documentation for scipy.stats.norm.fit is incorrect
- `#6764 <https://github.com/scipy/scipy/issues/6764>`__: Documentation for scipy.spatial.Delaunay is partially incorrect
- `#6811 <https://github.com/scipy/scipy/issues/6811>`__: scipy.spatial.SphericalVoronoi fails for large number of points
- `#6841 <https://github.com/scipy/scipy/issues/6841>`__: spearmanr fails when nan_policy='omit' is set
- `#6869 <https://github.com/scipy/scipy/issues/6869>`__: Currently in gaussian_kde, the logpdf function is calculated...
- `#6875 <https://github.com/scipy/scipy/issues/6875>`__: SLSQP inconsistent handling of invalid bounds
- `#6876 <https://github.com/scipy/scipy/issues/6876>`__: Python stopped working (Segfault?) with minimum/maximum filter...
- `#6889 <https://github.com/scipy/scipy/issues/6889>`__: dblquad gives different results under scipy 0.17.1 and 0.18.1
- `#6898 <https://github.com/scipy/scipy/issues/6898>`__: BUG: dblquad ignores error tolerances
- `#6901 <https://github.com/scipy/scipy/issues/6901>`__: Solving sparse linear systems in CSR format with complex values
- `#6903 <https://github.com/scipy/scipy/issues/6903>`__: issue in spatial.distance.pdist docstring
- `#6917 <https://github.com/scipy/scipy/issues/6917>`__: Problem in passing drop_rule to scipy.sparse.linalg.spilu
- `#6926 <https://github.com/scipy/scipy/issues/6926>`__: signature mismatches for LowLevelCallable
- `#6961 <https://github.com/scipy/scipy/issues/6961>`__: Scipy contains shebang pointing to /usr/bin/python and /bin/bash...
- `#6972 <https://github.com/scipy/scipy/issues/6972>`__: BUG: special: `generate_ufuncs.py` is broken
- `#6984 <https://github.com/scipy/scipy/issues/6984>`__: Assert raises test failure for test_ill_condition_warning
- `#6990 <https://github.com/scipy/scipy/issues/6990>`__: BUG: sparse: Bad documentation of the `k` argument in `sparse.linalg.eigs`
- `#6991 <https://github.com/scipy/scipy/issues/6991>`__: Division by zero in linregress()
- `#7011 <https://github.com/scipy/scipy/issues/7011>`__: possible speed improvment in rv_continuous.fit()
- `#7015 <https://github.com/scipy/scipy/issues/7015>`__: Test failure with Python 3.5 and numpy master
- `#7055 <https://github.com/scipy/scipy/issues/7055>`__: SciPy 0.19.0rc1 test errors and failures on Windows
- `#7096 <https://github.com/scipy/scipy/issues/7096>`__: macOS test failues for test_solve_continuous_are
- `#7100 <https://github.com/scipy/scipy/issues/7100>`__: test_distance.test_Xdist_deprecated_args test error in 0.19.0rc2


Pull requests for 0.19.0
------------------------

- `#2908 <https://github.com/scipy/scipy/pull/2908>`__: Scipy 1.0 Roadmap
- `#3174 <https://github.com/scipy/scipy/pull/3174>`__: add b-splines
- `#4606 <https://github.com/scipy/scipy/pull/4606>`__: ENH: Add a unit impulse waveform function
- `#5608 <https://github.com/scipy/scipy/pull/5608>`__: Adds keyword argument to choose faster convolution method
- `#5647 <https://github.com/scipy/scipy/pull/5647>`__: ENH: Faster count_neighour in cKDTree / + weighted input data
- `#6021 <https://github.com/scipy/scipy/pull/6021>`__: Netcdf append
- `#6058 <https://github.com/scipy/scipy/pull/6058>`__: ENH: scipy.signal - Add stft and istft
- `#6059 <https://github.com/scipy/scipy/pull/6059>`__: ENH: More accurate signal.freqresp for zpk systems
- `#6195 <https://github.com/scipy/scipy/pull/6195>`__: ENH: Cython interface for special
- `#6234 <https://github.com/scipy/scipy/pull/6234>`__: DOC: Fixed a typo in ward() help
- `#6261 <https://github.com/scipy/scipy/pull/6261>`__: ENH: add docstring and clean up code for signal.normalize
- `#6270 <https://github.com/scipy/scipy/pull/6270>`__: MAINT: special: add tests for cdflib
- `#6271 <https://github.com/scipy/scipy/pull/6271>`__: Fix for scipy.cluster.hierarchy.is_isomorphic
- `#6273 <https://github.com/scipy/scipy/pull/6273>`__: optimize: rewrite while loops as for loops
- `#6279 <https://github.com/scipy/scipy/pull/6279>`__: MAINT: Bessel tweaks
- `#6291 <https://github.com/scipy/scipy/pull/6291>`__: Fixes gh-6219: remove runtime warning from genextreme distribution
- `#6294 <https://github.com/scipy/scipy/pull/6294>`__: STY: Some PEP8 and cleaning up imports in stats/_continuous_distns.py
- `#6297 <https://github.com/scipy/scipy/pull/6297>`__: Clarify docs in misc/__init__.py
- `#6300 <https://github.com/scipy/scipy/pull/6300>`__: ENH: sparse: Loosen input validation for `diags` with empty inputs
- `#6301 <https://github.com/scipy/scipy/pull/6301>`__: BUG: standardizes check_finite behavior re optional weights,...
- `#6303 <https://github.com/scipy/scipy/pull/6303>`__: Fixing example in _lazyselect docstring.
- `#6307 <https://github.com/scipy/scipy/pull/6307>`__: MAINT: more improvements to gammainc/gammaincc
- `#6308 <https://github.com/scipy/scipy/pull/6308>`__: Clarified documentation of hypergeometric distribution.
- `#6309 <https://github.com/scipy/scipy/pull/6309>`__: BUG: stats: Improve calculation of the Anderson-Darling statistic.
- `#6315 <https://github.com/scipy/scipy/pull/6315>`__: ENH: Descending order of x in PPoly
- `#6317 <https://github.com/scipy/scipy/pull/6317>`__: ENH: stats: Add support for nan_policy to stats.median_test
- `#6321 <https://github.com/scipy/scipy/pull/6321>`__: TST: fix a typo in test name
- `#6328 <https://github.com/scipy/scipy/pull/6328>`__: ENH: sosfreqz
- `#6335 <https://github.com/scipy/scipy/pull/6335>`__: Define LinregressResult outside of linregress
- `#6337 <https://github.com/scipy/scipy/pull/6337>`__: In anderson test, added support for right skewed gumbel distribution.
- `#6341 <https://github.com/scipy/scipy/pull/6341>`__: Accept several spellings for the curve_fit max number of function...
- `#6342 <https://github.com/scipy/scipy/pull/6342>`__: DOC: cluster: clarify hierarchy.linkage usage
- `#6352 <https://github.com/scipy/scipy/pull/6352>`__: DOC: removed brentq from its own 'see also'
- `#6362 <https://github.com/scipy/scipy/pull/6362>`__: ENH: stats: Use explicit formulas for sf, logsf, etc in weibull...
- `#6369 <https://github.com/scipy/scipy/pull/6369>`__: MAINT: special: add a comment to hyp0f1_complex
- `#6375 <https://github.com/scipy/scipy/pull/6375>`__: Added the multinomial distribution.
- `#6387 <https://github.com/scipy/scipy/pull/6387>`__: MAINT: special: improve accuracy of ellipj's `dn` at quarter...
- `#6388 <https://github.com/scipy/scipy/pull/6388>`__: BenchmarkGlobal - getting it to work in Python3
- `#6394 <https://github.com/scipy/scipy/pull/6394>`__: ENH: scipy.sparse: add save and load functions for sparse matrices
- `#6400 <https://github.com/scipy/scipy/pull/6400>`__: MAINT: moves global benchmark run from setup_cache to track_all
- `#6403 <https://github.com/scipy/scipy/pull/6403>`__: ENH: seed kwd for basinhopping. Closes #6278
- `#6404 <https://github.com/scipy/scipy/pull/6404>`__: ENH: signal: added irrnotch and iirpeak functions.
- `#6406 <https://github.com/scipy/scipy/pull/6406>`__: ENH: special: extend `sici`/`shichi` to complex arguments
- `#6407 <https://github.com/scipy/scipy/pull/6407>`__: ENH: Window functions should not accept non-integer or negative...
- `#6408 <https://github.com/scipy/scipy/pull/6408>`__: MAINT: _differentialevolution now uses _lib._util.check_random_state
- `#6427 <https://github.com/scipy/scipy/pull/6427>`__: MAINT: Fix gmpy build & test that mpmath uses gmpy
- `#6439 <https://github.com/scipy/scipy/pull/6439>`__: MAINT: ndimage: update callback function c api
- `#6443 <https://github.com/scipy/scipy/pull/6443>`__: BUG: Fix volume computation in incremental mode
- `#6447 <https://github.com/scipy/scipy/pull/6447>`__: Fixes issue #6413 - Minor documentation fix in the entropy function...
- `#6448 <https://github.com/scipy/scipy/pull/6448>`__: ENH: Add halfspace mode to Qhull
- `#6449 <https://github.com/scipy/scipy/pull/6449>`__: ENH: rtol and atol for differential_evolution termination fixes...
- `#6453 <https://github.com/scipy/scipy/pull/6453>`__: DOC: Add some See Also links between similar functions
- `#6454 <https://github.com/scipy/scipy/pull/6454>`__: DOC: linalg: clarify callable signature in `ordqz`
- `#6457 <https://github.com/scipy/scipy/pull/6457>`__: ENH: spatial: enable non-double dtypes in squareform
- `#6459 <https://github.com/scipy/scipy/pull/6459>`__: BUG: Complex matrices not handled correctly by expm_multiply...
- `#6465 <https://github.com/scipy/scipy/pull/6465>`__: TST DOC Window docs, tests, etc.
- `#6469 <https://github.com/scipy/scipy/pull/6469>`__: ENH: linalg: better handling of infinite eigenvalues in `eig`/`eigvals`
- `#6475 <https://github.com/scipy/scipy/pull/6475>`__: DOC: calling interp1d/interp2d with NaNs is undefined
- `#6477 <https://github.com/scipy/scipy/pull/6477>`__: Document magic numbers in optimize.py
- `#6481 <https://github.com/scipy/scipy/pull/6481>`__: TST: Supress some warnings from test_windows
- `#6485 <https://github.com/scipy/scipy/pull/6485>`__: DOC: spatial: correct typo in procrustes
- `#6487 <https://github.com/scipy/scipy/pull/6487>`__: Fix Bray-Curtis formula in pdist docstring
- `#6493 <https://github.com/scipy/scipy/pull/6493>`__: ENH: Add covariance functionality to scipy.optimize.curve_fit
- `#6494 <https://github.com/scipy/scipy/pull/6494>`__: ENH: stats: Use log1p() to improve some calculations.
- `#6495 <https://github.com/scipy/scipy/pull/6495>`__: BUG: Use MST algorithm instead of SLINK for single linkage clustering
- `#6497 <https://github.com/scipy/scipy/pull/6497>`__: MRG: Add minimum_phase filter function
- `#6505 <https://github.com/scipy/scipy/pull/6505>`__: reset scipy.signal.resample window shape to 1-D
- `#6507 <https://github.com/scipy/scipy/pull/6507>`__: BUG: linkage: Raise exception if y contains non-finite elements
- `#6509 <https://github.com/scipy/scipy/pull/6509>`__: ENH: _lib: add common machinery for low-level callback functions
- `#6520 <https://github.com/scipy/scipy/pull/6520>`__: scipy.sparse.base.__mul__ non-numpy/scipy objects with 'shape'...
- `#6522 <https://github.com/scipy/scipy/pull/6522>`__: Replace kl_div by rel_entr in entropy
- `#6524 <https://github.com/scipy/scipy/pull/6524>`__: DOC: add next_fast_len to list of functions
- `#6527 <https://github.com/scipy/scipy/pull/6527>`__: DOC: Release notes to reflect the new covariance feature in optimize.curve_fit
- `#6532 <https://github.com/scipy/scipy/pull/6532>`__: ENH: Simplify _cos_win, document it, add symmetric/periodic arg
- `#6535 <https://github.com/scipy/scipy/pull/6535>`__: MAINT: sparse.csgraph: updating old cython loops
- `#6540 <https://github.com/scipy/scipy/pull/6540>`__: DOC: add to documentation of orthogonal polynomials
- `#6544 <https://github.com/scipy/scipy/pull/6544>`__: TST: Ensure tests for scipy._lib are run by scipy.test()
- `#6546 <https://github.com/scipy/scipy/pull/6546>`__: updated docstring of stats.linregress
- `#6553 <https://github.com/scipy/scipy/pull/6553>`__: commited changes that I originally submitted for scipy.signal.cspline…
- `#6561 <https://github.com/scipy/scipy/pull/6561>`__: BUG: modify signal.find_peaks_cwt() to return array and accept...
- `#6562 <https://github.com/scipy/scipy/pull/6562>`__: DOC: Negative binomial distribution clarification
- `#6563 <https://github.com/scipy/scipy/pull/6563>`__: MAINT: be more liberal in requiring numpy
- `#6567 <https://github.com/scipy/scipy/pull/6567>`__: MAINT: use xrange for iteration in differential_evolution fixes...
- `#6572 <https://github.com/scipy/scipy/pull/6572>`__: BUG: "sp.linalg.solve_discrete_are" fails for random data
- `#6578 <https://github.com/scipy/scipy/pull/6578>`__: BUG: misc: allow both cmin/cmax and low/high params in bytescale
- `#6581 <https://github.com/scipy/scipy/pull/6581>`__: Fix some unfortunate typos
- `#6582 <https://github.com/scipy/scipy/pull/6582>`__: MAINT: linalg: make handling of infinite eigenvalues in `ordqz`...
- `#6585 <https://github.com/scipy/scipy/pull/6585>`__: DOC: interpolate: correct seealso links to ndimage
- `#6588 <https://github.com/scipy/scipy/pull/6588>`__: Update docstring of scipy.spatial.distance_matrix
- `#6592 <https://github.com/scipy/scipy/pull/6592>`__: DOC: Replace 'first' by 'smallest' in mode
- `#6593 <https://github.com/scipy/scipy/pull/6593>`__: MAINT: remove scipy.weave submodule
- `#6594 <https://github.com/scipy/scipy/pull/6594>`__: DOC: distance.squareform: fix html docs, add note about dtype...
- `#6598 <https://github.com/scipy/scipy/pull/6598>`__: [DOC] Fix incorrect error message in medfilt2d
- `#6599 <https://github.com/scipy/scipy/pull/6599>`__: MAINT: linalg: turn a `solve_discrete_are` test back on
- `#6600 <https://github.com/scipy/scipy/pull/6600>`__: DOC: Add SOS goals to roadmap
- `#6601 <https://github.com/scipy/scipy/pull/6601>`__: DEP: Raise minimum numpy version to 1.8.2
- `#6605 <https://github.com/scipy/scipy/pull/6605>`__: MAINT: 'new' module is deprecated, don't use it
- `#6607 <https://github.com/scipy/scipy/pull/6607>`__: DOC: add note on change in wheel dependency on numpy and pip...
- `#6609 <https://github.com/scipy/scipy/pull/6609>`__: Fixes #6602 - Typo in docs
- `#6616 <https://github.com/scipy/scipy/pull/6616>`__: ENH: generalization of continuous and discrete Riccati solvers...
- `#6621 <https://github.com/scipy/scipy/pull/6621>`__: DOC: improve cluster.hierarchy docstrings.
- `#6623 <https://github.com/scipy/scipy/pull/6623>`__: CS matrix prune method should copy data from large unpruned arrays
- `#6625 <https://github.com/scipy/scipy/pull/6625>`__: DOC: special: complete documentation of `eval_*` functions
- `#6626 <https://github.com/scipy/scipy/pull/6626>`__: TST: special: silence some deprecation warnings
- `#6631 <https://github.com/scipy/scipy/pull/6631>`__: fix parameter name doc for discrete distributions
- `#6632 <https://github.com/scipy/scipy/pull/6632>`__: MAINT: stats: change some instances of `special` to `sc`
- `#6633 <https://github.com/scipy/scipy/pull/6633>`__: MAINT: refguide: py2k long integers are equal to py3k integers
- `#6638 <https://github.com/scipy/scipy/pull/6638>`__: MAINT: change type declaration in cluster.linkage, prevent overflow
- `#6640 <https://github.com/scipy/scipy/pull/6640>`__: BUG: fix issue with duplicate values used in cluster.vq.kmeans
- `#6641 <https://github.com/scipy/scipy/pull/6641>`__: BUG: fix corner case in cluster.vq.kmeans for large thresholds
- `#6643 <https://github.com/scipy/scipy/pull/6643>`__: MAINT: clean up truncation modes of dendrogram
- `#6645 <https://github.com/scipy/scipy/pull/6645>`__: MAINT: special: rename `*_roots` functions
- `#6646 <https://github.com/scipy/scipy/pull/6646>`__: MAINT: clean up mpmath imports
- `#6647 <https://github.com/scipy/scipy/pull/6647>`__: DOC: add sqrt to Mahalanobis description for pdist
- `#6648 <https://github.com/scipy/scipy/pull/6648>`__: DOC: special: add a section on `cython_special` to the tutorial
- `#6649 <https://github.com/scipy/scipy/pull/6649>`__: ENH: Added scipy.spatial.distance.directed_hausdorff
- `#6650 <https://github.com/scipy/scipy/pull/6650>`__: DOC: add Sphinx roles for DOI and arXiv links
- `#6651 <https://github.com/scipy/scipy/pull/6651>`__: BUG: mstats: make sure mode(..., None) does not modify its input
- `#6652 <https://github.com/scipy/scipy/pull/6652>`__: DOC: special: add section to tutorial on functions not in special
- `#6653 <https://github.com/scipy/scipy/pull/6653>`__: ENH: special: add the Wright Omega function
- `#6656 <https://github.com/scipy/scipy/pull/6656>`__: ENH: don't coerce input to double with custom metric in cdist...
- `#6658 <https://github.com/scipy/scipy/pull/6658>`__: Faster/shorter code for computation of discordances
- `#6659 <https://github.com/scipy/scipy/pull/6659>`__: DOC: special: make __init__ summaries and html summaries match
- `#6661 <https://github.com/scipy/scipy/pull/6661>`__: general.rst: Fix a typo
- `#6664 <https://github.com/scipy/scipy/pull/6664>`__: TST: Spectral functions' window correction factor
- `#6665 <https://github.com/scipy/scipy/pull/6665>`__: [DOC] Conditions on v in RectSphereBivariateSpline
- `#6668 <https://github.com/scipy/scipy/pull/6668>`__: DOC: Mention negative masses for center of mass
- `#6675 <https://github.com/scipy/scipy/pull/6675>`__: MAINT: special: remove outdated README
- `#6677 <https://github.com/scipy/scipy/pull/6677>`__: BUG: Fixes computation of p-values.
- `#6679 <https://github.com/scipy/scipy/pull/6679>`__: BUG: optimize: return correct Jacobian for method 'SLSQP' in...
- `#6680 <https://github.com/scipy/scipy/pull/6680>`__: ENH: Add structural rank to sparse.csgraph
- `#6686 <https://github.com/scipy/scipy/pull/6686>`__: TST: Added Airspeed Velocity benchmarks for SphericalVoronoi
- `#6687 <https://github.com/scipy/scipy/pull/6687>`__: DOC: add section "deciding on new features" to developer guide.
- `#6691 <https://github.com/scipy/scipy/pull/6691>`__: ENH: Clearer error when fmin_slsqp obj doesn't return scalar
- `#6702 <https://github.com/scipy/scipy/pull/6702>`__: TST: Added airspeed velocity benchmarks for scipy.spatial.distance.cdist
- `#6707 <https://github.com/scipy/scipy/pull/6707>`__: TST: interpolate: test fitpack wrappers, not _impl
- `#6709 <https://github.com/scipy/scipy/pull/6709>`__: TST: fix a number of test failures on 32-bit systems
- `#6711 <https://github.com/scipy/scipy/pull/6711>`__: MAINT: move function definitions from __fitpack.h to _fitpackmodule.c
- `#6712 <https://github.com/scipy/scipy/pull/6712>`__: MAINT: clean up wishlist in stats.morestats, and copyright statement.
- `#6715 <https://github.com/scipy/scipy/pull/6715>`__: DOC: update the release notes with BSpline et al.
- `#6716 <https://github.com/scipy/scipy/pull/6716>`__: MAINT: scipy.io.wavfile: No infinite loop when trying to read...
- `#6717 <https://github.com/scipy/scipy/pull/6717>`__: some style cleanup
- `#6723 <https://github.com/scipy/scipy/pull/6723>`__: BUG: special: cast to float before in-place multiplication in...
- `#6726 <https://github.com/scipy/scipy/pull/6726>`__: address performance regressions in interp1d
- `#6728 <https://github.com/scipy/scipy/pull/6728>`__: DOC: made code examples in `integrate` tutorial copy-pasteable
- `#6731 <https://github.com/scipy/scipy/pull/6731>`__: DOC: scipy.optimize: Added an example for wrapping complex-valued...
- `#6732 <https://github.com/scipy/scipy/pull/6732>`__: MAINT: cython_special: remove `errprint`
- `#6733 <https://github.com/scipy/scipy/pull/6733>`__: MAINT: special: fix some pyflakes warnings
- `#6734 <https://github.com/scipy/scipy/pull/6734>`__: DOC: sparse.linalg: fixed matrix description in `bicgstab` doc
- `#6737 <https://github.com/scipy/scipy/pull/6737>`__: BLD: update `cythonize.py` to detect changes in pxi files
- `#6740 <https://github.com/scipy/scipy/pull/6740>`__: DOC: special: some small fixes to docstrings
- `#6741 <https://github.com/scipy/scipy/pull/6741>`__: MAINT: remove dead code in interpolate.py
- `#6742 <https://github.com/scipy/scipy/pull/6742>`__: BUG: fix ``linalg.block_diag`` to support zero-sized matrices.
- `#6744 <https://github.com/scipy/scipy/pull/6744>`__: ENH: interpolate: make PPoly.from_spline accept BSpline objects
- `#6746 <https://github.com/scipy/scipy/pull/6746>`__: DOC: special: clarify use of Condon-Shortley phase in `sph_harm`/`lpmv`
- `#6750 <https://github.com/scipy/scipy/pull/6750>`__: ENH: sparse: avoid densification on broadcasted elem-wise mult
- `#6751 <https://github.com/scipy/scipy/pull/6751>`__: sinm doc explained cosm
- `#6753 <https://github.com/scipy/scipy/pull/6753>`__: ENH: special: allow for more fine-tuned error handling
- `#6759 <https://github.com/scipy/scipy/pull/6759>`__: Move logsumexp and pade from scipy.misc to scipy.special and...
- `#6761 <https://github.com/scipy/scipy/pull/6761>`__: ENH: argmax and argmin methods for sparse matrices
- `#6762 <https://github.com/scipy/scipy/pull/6762>`__: DOC: Improve docstrings of sparse matrices
- `#6763 <https://github.com/scipy/scipy/pull/6763>`__: ENH: Weighted tau
- `#6768 <https://github.com/scipy/scipy/pull/6768>`__: ENH: cythonized spherical Voronoi region polygon vertex sorting
- `#6770 <https://github.com/scipy/scipy/pull/6770>`__: Correction of Delaunay class' documentation
- `#6775 <https://github.com/scipy/scipy/pull/6775>`__: ENH: Integrating LAPACK "expert" routines with conditioning warnings...
- `#6776 <https://github.com/scipy/scipy/pull/6776>`__: MAINT: Removing the trivial f2py warnings
- `#6777 <https://github.com/scipy/scipy/pull/6777>`__: DOC: Update rv_continuous.fit doc.
- `#6778 <https://github.com/scipy/scipy/pull/6778>`__: MAINT: cluster.hierarchy: Improved wording of error msgs
- `#6786 <https://github.com/scipy/scipy/pull/6786>`__: BLD: increase minimum Cython version to 0.23.4
- `#6787 <https://github.com/scipy/scipy/pull/6787>`__: DOC: expand on ``linalg.block_diag`` changes in 0.19.0 release...
- `#6789 <https://github.com/scipy/scipy/pull/6789>`__: ENH: Add further documentation for norm.fit
- `#6790 <https://github.com/scipy/scipy/pull/6790>`__: MAINT: Fix a potential problem in nn_chain linkage algorithm
- `#6791 <https://github.com/scipy/scipy/pull/6791>`__: DOC: Add examples to scipy.ndimage.fourier
- `#6792 <https://github.com/scipy/scipy/pull/6792>`__: DOC: fix some numpydoc / Sphinx issues.
- `#6793 <https://github.com/scipy/scipy/pull/6793>`__: MAINT: fix circular import after moving functions out of misc
- `#6796 <https://github.com/scipy/scipy/pull/6796>`__: TST: test importing each submodule. Regression test for gh-6793.
- `#6799 <https://github.com/scipy/scipy/pull/6799>`__: ENH: stats: Argus distribution
- `#6801 <https://github.com/scipy/scipy/pull/6801>`__: ENH: stats: Histogram distribution
- `#6803 <https://github.com/scipy/scipy/pull/6803>`__: TST: make sure tests for ``_build_utils`` are run.
- `#6804 <https://github.com/scipy/scipy/pull/6804>`__: MAINT: more fixes in `loggamma`
- `#6806 <https://github.com/scipy/scipy/pull/6806>`__: ENH: Faster linkage for 'centroid' and 'median' methods
- `#6810 <https://github.com/scipy/scipy/pull/6810>`__: ENH: speed up upfirdn and resample_poly for n-dimensional arrays
- `#6812 <https://github.com/scipy/scipy/pull/6812>`__: TST: Added ConvexHull asv benchmark code
- `#6814 <https://github.com/scipy/scipy/pull/6814>`__: ENH: Different extrapolation modes for different dimensions in...
- `#6826 <https://github.com/scipy/scipy/pull/6826>`__: Signal spectral window default fix
- `#6828 <https://github.com/scipy/scipy/pull/6828>`__: BUG: SphericalVoronoi Space Complexity (Fixes #6811)
- `#6830 <https://github.com/scipy/scipy/pull/6830>`__: RealData docstring correction
- `#6834 <https://github.com/scipy/scipy/pull/6834>`__: DOC: Added reference for skewtest function. See #6829
- `#6836 <https://github.com/scipy/scipy/pull/6836>`__: DOC: Added mode='mirror' in the docstring for the functions accepting...
- `#6838 <https://github.com/scipy/scipy/pull/6838>`__: MAINT: sparse: start removing old BSR methods
- `#6844 <https://github.com/scipy/scipy/pull/6844>`__: handle incompatible dimensions when input is not an ndarray in...
- `#6847 <https://github.com/scipy/scipy/pull/6847>`__: Added maxiter to golden search.
- `#6850 <https://github.com/scipy/scipy/pull/6850>`__: BUG: added check for optional param scipy.stats.spearmanr
- `#6858 <https://github.com/scipy/scipy/pull/6858>`__: MAINT: Removing redundant tests
- `#6861 <https://github.com/scipy/scipy/pull/6861>`__: DEP: Fix escape sequences deprecated in Python 3.6.
- `#6862 <https://github.com/scipy/scipy/pull/6862>`__: DOC: dx should be float, not int
- `#6863 <https://github.com/scipy/scipy/pull/6863>`__: updated documentation curve_fit
- `#6866 <https://github.com/scipy/scipy/pull/6866>`__: DOC : added some documentation to j1 referring to spherical_jn
- `#6867 <https://github.com/scipy/scipy/pull/6867>`__: DOC: cdist move long examples list into Notes section
- `#6868 <https://github.com/scipy/scipy/pull/6868>`__: BUG: Make stats.mode return a ModeResult namedtuple on empty...
- `#6871 <https://github.com/scipy/scipy/pull/6871>`__: Corrected documentation.
- `#6874 <https://github.com/scipy/scipy/pull/6874>`__: ENH: gaussian_kde.logpdf based on logsumexp
- `#6877 <https://github.com/scipy/scipy/pull/6877>`__: BUG: ndimage: guard against footprints of all zeros
- `#6881 <https://github.com/scipy/scipy/pull/6881>`__: python 3.6
- `#6885 <https://github.com/scipy/scipy/pull/6885>`__: Vectorized integrate.fixed_quad
- `#6886 <https://github.com/scipy/scipy/pull/6886>`__: fixed typo
- `#6891 <https://github.com/scipy/scipy/pull/6891>`__: TST: fix failures for linalg.dare/care due to tightened test...
- `#6892 <https://github.com/scipy/scipy/pull/6892>`__: DOC: fix a bunch of Sphinx errors.
- `#6894 <https://github.com/scipy/scipy/pull/6894>`__: TST: Added asv benchmarks for scipy.spatial.Voronoi
- `#6908 <https://github.com/scipy/scipy/pull/6908>`__: BUG: Fix return dtype for complex input in spsolve
- `#6909 <https://github.com/scipy/scipy/pull/6909>`__: ENH: fftpack: use float32 routines for float16 inputs.
- `#6911 <https://github.com/scipy/scipy/pull/6911>`__: added min/max support to binned_statistic
- `#6913 <https://github.com/scipy/scipy/pull/6913>`__: Fix 6875: SLSQP raise ValueError for all invalid bounds.
- `#6914 <https://github.com/scipy/scipy/pull/6914>`__: DOCS: GH6903 updating docs of Spatial.distance.pdist
- `#6916 <https://github.com/scipy/scipy/pull/6916>`__: MAINT: fix some issues for 32-bit Python
- `#6924 <https://github.com/scipy/scipy/pull/6924>`__: BLD: update Bento build for scipy.LowLevelCallable
- `#6932 <https://github.com/scipy/scipy/pull/6932>`__: ENH: Use OrderedDict in io.netcdf. Closes gh-5537
- `#6933 <https://github.com/scipy/scipy/pull/6933>`__: BUG: fix LowLevelCallable issue on 32-bit Python.
- `#6936 <https://github.com/scipy/scipy/pull/6936>`__: BUG: sparse: handle size-1 2D indexes correctly
- `#6938 <https://github.com/scipy/scipy/pull/6938>`__: TST: fix test failures in special on 32-bit Python.
- `#6939 <https://github.com/scipy/scipy/pull/6939>`__: Added attributes list to cKDTree docstring
- `#6940 <https://github.com/scipy/scipy/pull/6940>`__: improve efficiency of dok_matrix.tocoo
- `#6942 <https://github.com/scipy/scipy/pull/6942>`__: DOC: add link to liac-arff package in the io.arff docstring.
- `#6943 <https://github.com/scipy/scipy/pull/6943>`__: MAINT: Docstring fixes and an additional test for linalg.solve
- `#6944 <https://github.com/scipy/scipy/pull/6944>`__: DOC: Add example of odeint with a banded Jacobian to the integrate...
- `#6946 <https://github.com/scipy/scipy/pull/6946>`__: ENH: hypergeom.logpmf in terms of betaln
- `#6947 <https://github.com/scipy/scipy/pull/6947>`__: TST: speedup distance tests
- `#6948 <https://github.com/scipy/scipy/pull/6948>`__: DEP: Deprecate the keyword "debug" from linalg.solve
- `#6950 <https://github.com/scipy/scipy/pull/6950>`__: BUG: Correctly treat large integers in MMIO (fixes #6397)
- `#6952 <https://github.com/scipy/scipy/pull/6952>`__: ENH: Minor user-friendliness cleanup in LowLevelCallable
- `#6956 <https://github.com/scipy/scipy/pull/6956>`__: DOC: improve description of 'output' keyword for convolve
- `#6957 <https://github.com/scipy/scipy/pull/6957>`__: ENH more informative error in sparse.bmat
- `#6962 <https://github.com/scipy/scipy/pull/6962>`__: Shebang fixes
- `#6964 <https://github.com/scipy/scipy/pull/6964>`__: DOC: note argmin/argmax addition
- `#6965 <https://github.com/scipy/scipy/pull/6965>`__: BUG: Fix issues passing error tolerances in dblquad and tplquad.
- `#6971 <https://github.com/scipy/scipy/pull/6971>`__: fix the docstring of signaltools.correlate
- `#6973 <https://github.com/scipy/scipy/pull/6973>`__: Silence expected numpy warnings in scipy.ndimage.interpolation.zoom()
- `#6975 <https://github.com/scipy/scipy/pull/6975>`__: BUG: special: fix regex in `generate_ufuncs.py`
- `#6976 <https://github.com/scipy/scipy/pull/6976>`__: Update docstring for griddata
- `#6978 <https://github.com/scipy/scipy/pull/6978>`__: Avoid division by zero in zoom factor calculation
- `#6979 <https://github.com/scipy/scipy/pull/6979>`__: BUG: ARE solvers did not check the generalized case carefully
- `#6985 <https://github.com/scipy/scipy/pull/6985>`__: ENH: sparse: add scipy.sparse.linalg.spsolve_triangular
- `#6994 <https://github.com/scipy/scipy/pull/6994>`__: MAINT: spatial: updates to plotting utils
- `#6995 <https://github.com/scipy/scipy/pull/6995>`__: DOC: Bad documentation of k in sparse.linalg.eigs See #6990
- `#6997 <https://github.com/scipy/scipy/pull/6997>`__: TST: Changed the test with a less singular example
- `#7000 <https://github.com/scipy/scipy/pull/7000>`__: DOC: clarify interp1d 'zero' argument
- `#7007 <https://github.com/scipy/scipy/pull/7007>`__: BUG: Fix division by zero in linregress() for 2 data points
- `#7009 <https://github.com/scipy/scipy/pull/7009>`__: BUG: Fix problem in passing drop_rule to scipy.sparse.linalg.spilu
- `#7012 <https://github.com/scipy/scipy/pull/7012>`__: speed improvment in _distn_infrastructure.py
- `#7014 <https://github.com/scipy/scipy/pull/7014>`__: Fix Typo: add a single quotation mark to fix a slight typo
- `#7021 <https://github.com/scipy/scipy/pull/7021>`__: MAINT: stats: use machine constants from np.finfo, not machar
- `#7026 <https://github.com/scipy/scipy/pull/7026>`__: MAINT: update .mailmap
- `#7032 <https://github.com/scipy/scipy/pull/7032>`__: Fix layout of rv_histogram docs
- `#7035 <https://github.com/scipy/scipy/pull/7035>`__: DOC: update 0.19.0 release notes
- `#7036 <https://github.com/scipy/scipy/pull/7036>`__: ENH: Add more boundary options to signal.stft
- `#7040 <https://github.com/scipy/scipy/pull/7040>`__: TST: stats: skip too slow tests
- `#7042 <https://github.com/scipy/scipy/pull/7042>`__: MAINT: sparse: speed up setdiag tests
- `#7043 <https://github.com/scipy/scipy/pull/7043>`__: MAINT: refactory and code cleaning Xdist
- `#7053 <https://github.com/scipy/scipy/pull/7053>`__: Fix msvc 9 and 10 compile errors
- `#7060 <https://github.com/scipy/scipy/pull/7060>`__: DOC: updated release notes with #7043 and #6656
- `#7062 <https://github.com/scipy/scipy/pull/7062>`__: MAINT: Change defaut STFT boundary kwarg to "zeros"
- `#7064 <https://github.com/scipy/scipy/pull/7064>`__: Fix ValueError: path is on mount 'X:', start on mount 'D:' on...
- `#7067 <https://github.com/scipy/scipy/pull/7067>`__: TST: Fix PermissionError: [Errno 13] Permission denied on Windows
- `#7068 <https://github.com/scipy/scipy/pull/7068>`__: TST: Fix UnboundLocalError: local variable 'data' referenced...
- `#7069 <https://github.com/scipy/scipy/pull/7069>`__: Fix OverflowError: Python int too large to convert to C long...
- `#7071 <https://github.com/scipy/scipy/pull/7071>`__: TST: silence RuntimeWarning for nan test of stats.spearmanr
- `#7072 <https://github.com/scipy/scipy/pull/7072>`__: Fix OverflowError: Python int too large to convert to C long...
- `#7084 <https://github.com/scipy/scipy/pull/7084>`__: TST: linalg: bump tolerance in test_falker
- `#7095 <https://github.com/scipy/scipy/pull/7095>`__: TST: linalg: bump more tolerances in test_falker
- `#7101 <https://github.com/scipy/scipy/pull/7101>`__: TST: Relax solve_continuous_are test case 2 and 12
- `#7106 <https://github.com/scipy/scipy/pull/7106>`__: BUG: stop cdist "correlation" modifying input
- `#7116 <https://github.com/scipy/scipy/pull/7116>`__: Backports to 0.19.0rc2

=========================
SciPy 1.1.0 Release Notes
=========================

.. contents::


SciPy 1.1.0 is the culmination of 7 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been a number of deprecations and API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning``
s). Our development attention will now shift to bug-fix releases on the
1.1.x branch, and on adding new features on the master branch.

This release requires Python 2.7 or 3.4+ and NumPy 1.8.2 or greater.

This release has improved but not necessarily 100% compatible with
the `PyPy <https://pypy.org/>`__ Python implementation. For running on
PyPy, PyPy 6.0+ and Numpy 1.15.0+ are required.

New features
============

`scipy.integrate` improvements
------------------------------

The argument ``tfirst`` has been added to the function
`scipy.integrate.odeint`. This allows ``odeint`` to use the same user
functions as `scipy.integrate.solve_ivp` and `scipy.integrate.ode` without
the need for wrapping them in a function that swaps the first two
arguments.

Error messages from ``quad()`` are now clearer.

`scipy.linalg` improvements
---------------------------

The function `scipy.linalg.ldl` has been added for factorization of
indefinite symmetric/hermitian matrices into triangular and block
diagonal matrices.

Python wrappers for LAPACK ``sygst``, ``hegst`` added in
`scipy.linalg.lapack`.

Added `scipy.linalg.null_space`, `scipy.linalg.cdf2rdf`,
`scipy.linalg.rsf2csf`.

`scipy.misc` improvements
-------------------------

An electrocardiogram has been added as an example dataset for a
one-dimensional signal. It can be accessed through
`scipy.misc.electrocardiogram`.

`scipy.ndimage` improvements
----------------------------

The routines `scipy.ndimage.binary_opening`, and
`scipy.ndimage.binary_closing` now support masks and different border
values.

`scipy.optimize` improvements
-----------------------------

The method ``trust-constr`` has been added to
`scipy.optimize.minimize`. The method switches between two
implementations depending on the problem definition. For equality-constrained
problems it is an implementation of a trust-region
sequential quadratic programming solver and, when inequality constraints
are imposed, it switches to a trust-region interior point method. Both
methods are appropriate for large scale problems. Quasi-Newton options
BFGS and SR1 were implemented and can be used to approximate
second-order derivatives for this new method. Also, finite-differences can be
used to approximate either first-order or second-order derivatives.

Random-to-Best/1/bin and Random-to-Best/1/exp mutation strategies were
added to `scipy.optimize.differential_evolution` as ``randtobest1bin``
and ``randtobest1exp``, respectively. Note: These names were already in
use but implemented a different mutation strategy. See `Backwards-incompatible
changes <#backwards-incompatible-changes>`__ below. The
``init`` keyword for the `scipy.optimize.differential_evolution`
function can now accept an array. This array allows the user to specify
the entire population.

Added an ``adaptive`` option to Nelder-Mead to use step parameters adapted
to the dimensionality of the problem.

Minor improvements in `scipy.optimize.basinhopping`.

`scipy.signal` improvements
---------------------------

Three new functions for peak finding in one-dimensional arrays were
added. `scipy.signal.find_peaks` searches for peaks (local maxima) based
on simple value comparison of neighboring samples and returns those
peaks whose properties match optionally specified conditions for their
height, prominence, width, threshold and distance to each other.
`scipy.signal.peak_prominences` and `scipy.signal.peak_widths` can directly
calculate the prominences or widths of known peaks.

Added ZPK versions of frequency transformations:
`scipy.signal.bilinear_zpk`, `scipy.signal.lp2bp_zpk`,
`scipy.signal.lp2bs_zpk`, `scipy.signal.lp2hp_zpk`,
`scipy.signal.lp2lp_zpk`.

Added `scipy.signal.windows.dpss`,
`scipy.signal.windows.general_cosine` and
`scipy.signal.windows.general_hamming`.

`scipy.sparse` improvements
---------------------------

Previously, the ``reshape`` method only worked on
`scipy.sparse.lil_matrix`, and in-place reshaping did not work on any
matrices. Both operations are now implemented for all matrices. Handling
of shapes has been made consistent with ``numpy.matrix`` throughout the
`scipy.sparse` module (shape can be a tuple or splatted, negative
number acts as placeholder, padding and unpadding dimensions of size 1
to ensure length-2 shape).

`scipy.special` improvements
----------------------------

Added Owen’s T function as `scipy.special.owens_t`.

Accuracy improvements in ``chndtr``, ``digamma``, ``gammaincinv``,
``lambertw``, ``zetac``.

`scipy.stats` improvements
--------------------------

The Moyal distribution has been added as `scipy.stats.moyal`.

Added the normal inverse Gaussian distribution as
`scipy.stats.norminvgauss`.

Deprecated features
===================

The iterative linear equation solvers in `scipy.sparse.linalg` had a
sub-optimal way of how absolute tolerance is considered. The default
behavior will be changed in a future Scipy release to a more standard
and less surprising one. To silence deprecation warnings, set the
``atol=`` parameter explicitly.

`scipy.signal.windows.slepian` is deprecated, replaced by
`scipy.signal.windows.dpss`.

The window functions in `scipy.signal` are now available in
`scipy.signal.windows`. They will remain also available in the old
location in the `scipy.signal` namespace in future Scipy versions.
However, importing them from `scipy.signal.windows` is preferred, and
new window functions will be added only there.

Indexing sparse matrices with floating-point numbers instead of integers
is deprecated.

The function `scipy.stats.itemfreq` is deprecated.

Backwards incompatible changes
==============================

Previously, `scipy.linalg.orth` used a singular value cutoff value
appropriate for double precision numbers also for single-precision
input. The cutoff value is now tunable, and the default has been changed
to depend on the input data precision.

In previous versions of Scipy, the ``randtobest1bin`` and
``randtobest1exp`` mutation strategies in
`scipy.optimize.differential_evolution` were actually implemented using
the Current-to-Best/1/bin and Current-to-Best/1/exp strategies,
respectively. These strategies were renamed to ``currenttobest1bin`` and
``currenttobest1exp`` and the implementations of ``randtobest1bin`` and
``randtobest1exp`` strategies were corrected.

Functions in the ndimage module now always return their output array.
Before, most functions only returned the output array if it had been
allocated by the function, and would return ``None`` if it had been
provided by the user.

Distance metrics in `scipy.spatial.distance` now require non-negative
weights.

`scipy.special.loggamma` now returns real-valued result when the input
is real-valued.

Other changes
=============

When building on Linux with GNU compilers, the ``.so`` Python extension
files now hide all symbols except those required by Python, which can
avoid problems when embedding the Python interpreter.



Authors
=======

* Saurabh Agarwal +
* Diogo Aguiam +
* Joseph Albert +
* Gerrit Ansmann +
* Jean-François B +
* Vahan Babayan +
* Alessandro Pietro Bardelli
* Christoph Baumgarten +
* Felix Berkenkamp
* Lilian Besson +
* Aditya Bharti +
* Matthew Brett
* Evgeni Burovski
* CJ Carey
* Martin Ø. Christensen +
* Robert Cimrman
* Vicky Close +
* Peter Cock +
* Philip DeBoer
* Jaime Fernandez del Rio
* Dieter Werthmüller +
* Tom Donoghue +
* Matt Dzugan +
* Lars G +
* Jacques Gaudin +
* Andriy Gelman +
* Sean Gillies +
* Dezmond Goff
* Christoph Gohlke
* Ralf Gommers
* Uri Goren +
* Deepak Kumar Gouda +
* Douglas Lessa Graciosa +
* Matt Haberland
* David Hagen
* Charles Harris
* Jordan Heemskerk +
* Danny Hermes +
* Stephan Hoyer +
* Theodore Hu +
* Jean-François B. +
* Mads Jensen +
* Jon Haitz Legarreta Gorroño +
* Ben Jude +
* Noel Kippers +
* Julius Bier Kirkegaard +
* Maria Knorps +
* Mikkel Kristensen +
* Eric Larson
* Kasper Primdal Lauritzen +
* Denis Laxalde
* KangWon Lee +
* Jan Lehky +
* Jackie Leng +
* P.L. Lim +
* Nikolay Mayorov
* Mihai Capotă +
* Max Mikhaylov +
* Mark Mikofski +
* Jarrod Millman
* Raden Muhammad +
* Paul Nation
* Andrew Nelson
* Nico Schlömer
* Joel Nothman
* Kyle Oman +
* Egor Panfilov +
* Nick Papior
* Anubhav Patel +
* Oleksandr Pavlyk
* Ilhan Polat
* Robert Pollak +
* Anant Prakash +
* Aman Pratik
* Sean Quinn +
* Giftlin Rajaiah +
* Tyler Reddy
* Joscha Reimer
* Antonio H Ribeiro +
* Antonio Horta Ribeiro
* Benjamin Rose +
* Fabian Rost
* Divakar Roy +
* Scott Sievert
* Leo Singer
* Sourav Singh
* Martino Sorbaro +
* Eric Stansifer +
* Martin Thoma
* Phil Tooley +
* Piotr Uchwat +
* Paul van Mulbregt
* Pauli Virtanen
* Stefan van der Walt
* Warren Weckesser
* Florian Weimer +
* Eric Wieser
* Josh Wilson
* Ted Ying +
* Evgeny Zhurko
* Zé Vinícius
* @Astrofysicus +
* @awakenting +
* @endolith
* @FormerPhysicist +
* @gaulinmp +
* @hugovk
* @ksemb +
* @kshitij12345 +
* @luzpaz +
* @NKrvavica +
* @rafalalgo +
* @samyak0210 +
* @soluwalana +
* @sudheerachary +
* @Tokixix +
* @tttthomasssss +
* @vkk800 +
* @xoviat
* @ziejcow +

A total of 122 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 1.1.0
-----------------------

* `#979 <https://github.com/scipy/scipy/issues/979>`__: Allow Hermitian matrices in lobpcg (Trac #452)
* `#2694 <https://github.com/scipy/scipy/issues/2694>`__: Solution of iterative solvers can be less accurate than tolerance...
* `#3164 <https://github.com/scipy/scipy/issues/3164>`__: RectBivariateSpline usage inconsistent with other interpolation...
* `#4161 <https://github.com/scipy/scipy/issues/4161>`__: Missing ITMAX optional argument in scipy.optimize.nnls
* `#4354 <https://github.com/scipy/scipy/issues/4354>`__: signal.slepian should use definition of digital window
* `#4866 <https://github.com/scipy/scipy/issues/4866>`__: Shouldn't scipy.linalg.sqrtm raise an error if matrix is singular?
* `#4953 <https://github.com/scipy/scipy/issues/4953>`__: The dirichlet distribution unnecessarily requires strictly positive...
* `#5336 <https://github.com/scipy/scipy/issues/5336>`__: sqrtm on a diagonal matrix can warn "Matrix is singular and may...
* `#5922 <https://github.com/scipy/scipy/issues/5922>`__: Suboptimal convergence of Halley's method?
* `#6036 <https://github.com/scipy/scipy/issues/6036>`__: Incorrect edge case in scipy.stats.triang.pdf
* `#6202 <https://github.com/scipy/scipy/issues/6202>`__: Enhancement: Add LDLt factorization to scipy
* `#6589 <https://github.com/scipy/scipy/issues/6589>`__: sparse.random with custom rvs callable does pass on arg to subclass
* `#6654 <https://github.com/scipy/scipy/issues/6654>`__: Spearman's rank correlation coefficient slow with nan values...
* `#6794 <https://github.com/scipy/scipy/issues/6794>`__: Remove NumarrayType struct with numarray type names from ndimage
* `#7136 <https://github.com/scipy/scipy/issues/7136>`__: The dirichlet distribution unnecessarily rejects probabilities...
* `#7169 <https://github.com/scipy/scipy/issues/7169>`__: Will it be possible to add LDL' factorization for Hermitian indefinite...
* `#7291 <https://github.com/scipy/scipy/issues/7291>`__: fsolve docs should say it doesn't handle over- or under-determined...
* `#7453 <https://github.com/scipy/scipy/issues/7453>`__: binary_opening/binary_closing missing arguments
* `#7500 <https://github.com/scipy/scipy/issues/7500>`__: linalg.solve test failure on OS X with Accelerate
* `#7555 <https://github.com/scipy/scipy/issues/7555>`__: Integratig a function with singularities using the quad routine
* `#7624 <https://github.com/scipy/scipy/issues/7624>`__: allow setting both absolute and relative tolerance of sparse...
* `#7724 <https://github.com/scipy/scipy/issues/7724>`__: odeint documentation refers to t0 instead of t
* `#7746 <https://github.com/scipy/scipy/issues/7746>`__: False CDF values for skew normal distribution
* `#7750 <https://github.com/scipy/scipy/issues/7750>`__: mstats.winsorize documentation needs clarification
* `#7787 <https://github.com/scipy/scipy/issues/7787>`__: Documentation error in spherical Bessel, Neumann, modified spherical...
* `#7836 <https://github.com/scipy/scipy/issues/7836>`__: Scipy mmwrite incorrectly writes the zeros for skew-symmetric,...
* `#7839 <https://github.com/scipy/scipy/issues/7839>`__: sqrtm is unable to compute square root of zero matrix
* `#7847 <https://github.com/scipy/scipy/issues/7847>`__: solve is very slow since #6775
* `#7888 <https://github.com/scipy/scipy/issues/7888>`__: Scipy 1.0.0b1 prints spurious DVODE/ZVODE/lsoda messages
* `#7909 <https://github.com/scipy/scipy/issues/7909>`__: bessel kv function in 0 is nan
* `#7915 <https://github.com/scipy/scipy/issues/7915>`__: LinearOperator's __init__ runs two times when instantiating the...
* `#7958 <https://github.com/scipy/scipy/issues/7958>`__: integrate.quad could use better error messages when given bad...
* `#7968 <https://github.com/scipy/scipy/issues/7968>`__: integrate.quad handles decreasing limits (b<a) inconsistently
* `#7970 <https://github.com/scipy/scipy/issues/7970>`__: ENH: matching return dtype for loggamma/gammaln
* `#7991 <https://github.com/scipy/scipy/issues/7991>`__: `lfilter` segfaults for integer inputs
* `#8076 <https://github.com/scipy/scipy/issues/8076>`__: "make dist" for the docs doesn't complete cleanly
* `#8080 <https://github.com/scipy/scipy/issues/8080>`__: Use JSON in `special/_generate_pyx.py`?
* `#8127 <https://github.com/scipy/scipy/issues/8127>`__: scipy.special.psi(x) very slow for some values of x
* `#8145 <https://github.com/scipy/scipy/issues/8145>`__: BUG: ndimage geometric_transform and zoom using deprecated NumPy...
* `#8158 <https://github.com/scipy/scipy/issues/8158>`__: BUG: romb print output requires correction
* `#8181 <https://github.com/scipy/scipy/issues/8181>`__: loadmat() raises TypeError instead of FileNotFound when reading...
* `#8228 <https://github.com/scipy/scipy/issues/8228>`__: bug for log1p on csr_matrix
* `#8235 <https://github.com/scipy/scipy/issues/8235>`__: scipy.stats multinomial pmf return nan
* `#8271 <https://github.com/scipy/scipy/issues/8271>`__: scipy.io.mmwrite raises type error for uint16
* `#8288 <https://github.com/scipy/scipy/issues/8288>`__: Should tests be written for scipy.sparse.linalg.isolve.minres...
* `#8298 <https://github.com/scipy/scipy/issues/8298>`__: Broken links on scipy API web page
* `#8329 <https://github.com/scipy/scipy/issues/8329>`__: `_gels` fails for fat A matrix
* `#8346 <https://github.com/scipy/scipy/issues/8346>`__: Avoidable overflow in scipy.special.binom(n, k)
* `#8371 <https://github.com/scipy/scipy/issues/8371>`__: BUG: special: zetac(x) returns 0 for x < -30.8148
* `#8382 <https://github.com/scipy/scipy/issues/8382>`__: collections.OrderedDict in test_mio.py
* `#8492 <https://github.com/scipy/scipy/issues/8492>`__: Missing documentation for `brute_force` parameter in scipy.ndimage.morphology
* `#8532 <https://github.com/scipy/scipy/issues/8532>`__: leastsq needlessly appends extra dimension for scalar problems
* `#8544 <https://github.com/scipy/scipy/issues/8544>`__: [feature request] Convert complex diagonal form to real block...
* `#8561 <https://github.com/scipy/scipy/issues/8561>`__: [Bug?] Example of Bland's Rule for optimize.linprog (simplex)...
* `#8562 <https://github.com/scipy/scipy/issues/8562>`__: CI: Appveyor builds fail because it can't import ConvexHull from...
* `#8576 <https://github.com/scipy/scipy/issues/8576>`__: BUG: optimize: `show_options(solver='minimize', method='Newton-CG')`...
* `#8603 <https://github.com/scipy/scipy/issues/8603>`__: test_roots_gegenbauer/chebyt/chebyc failures on manylinux
* `#8604 <https://github.com/scipy/scipy/issues/8604>`__: Test failures in scipy.sparse test_inplace_dense
* `#8616 <https://github.com/scipy/scipy/issues/8616>`__: special: ellpj.c code can be cleaned up a bit
* `#8625 <https://github.com/scipy/scipy/issues/8625>`__: scipy 1.0.1 no longer allows overwriting variables in netcdf...
* `#8629 <https://github.com/scipy/scipy/issues/8629>`__: gcrotmk.test_atol failure with MKL
* `#8632 <https://github.com/scipy/scipy/issues/8632>`__: Sigma clipping on data with the same value
* `#8646 <https://github.com/scipy/scipy/issues/8646>`__: scipy.special.sinpi test failures in test_zero_sign on old MSVC
* `#8663 <https://github.com/scipy/scipy/issues/8663>`__: linprog with method=interior-point produced incorrect answer...
* `#8694 <https://github.com/scipy/scipy/issues/8694>`__: linalg:TestSolve.test_all_type_size_routine_combinations fails...
* `#8703 <https://github.com/scipy/scipy/issues/8703>`__: Q: Does runtests.py --refguide-check need env (or other) variables...


Pull requests for 1.1.0
-----------------------

* `#6590 <https://github.com/scipy/scipy/pull/6590>`__: BUG: sparse: fix custom rvs callable argument in sparse.random
* `#7004 <https://github.com/scipy/scipy/pull/7004>`__: ENH: scipy.linalg.eigsh cannot get all eigenvalues
* `#7120 <https://github.com/scipy/scipy/pull/7120>`__: ENH: implemented Owen's T function
* `#7483 <https://github.com/scipy/scipy/pull/7483>`__: ENH: Addition/multiplication operators for StateSpace systems
* `#7566 <https://github.com/scipy/scipy/pull/7566>`__: Informative exception when passing a sparse matrix
* `#7592 <https://github.com/scipy/scipy/pull/7592>`__: Adaptive Nelder-Mead
* `#7729 <https://github.com/scipy/scipy/pull/7729>`__: WIP: ENH: optimize: large-scale constrained optimization algorithms...
* `#7802 <https://github.com/scipy/scipy/pull/7802>`__: MRG: Add dpss window function
* `#7803 <https://github.com/scipy/scipy/pull/7803>`__: DOC: Add examples to spatial.distance
* `#7821 <https://github.com/scipy/scipy/pull/7821>`__: Add Returns section to the docstring
* `#7833 <https://github.com/scipy/scipy/pull/7833>`__: ENH: Performance improvements in scipy.linalg.special_matrices
* `#7864 <https://github.com/scipy/scipy/pull/7864>`__: MAINT: sparse: Simplify sputils.isintlike
* `#7865 <https://github.com/scipy/scipy/pull/7865>`__: ENH: Improved speed of copy into L, U matrices
* `#7871 <https://github.com/scipy/scipy/pull/7871>`__: ENH: sparse: Add 64-bit integer to sparsetools
* `#7879 <https://github.com/scipy/scipy/pull/7879>`__: ENH: re-enabled old sv lapack routine as defaults
* `#7889 <https://github.com/scipy/scipy/pull/7889>`__: DOC: Show probability density functions as math
* `#7900 <https://github.com/scipy/scipy/pull/7900>`__: API: Soft deprecate signal.* windows
* `#7910 <https://github.com/scipy/scipy/pull/7910>`__: ENH: allow `sqrtm` to compute the root of some singular matrices
* `#7911 <https://github.com/scipy/scipy/pull/7911>`__: MAINT: Avoid unnecessary array copies in xdist
* `#7913 <https://github.com/scipy/scipy/pull/7913>`__: DOC: Clarifies the meaning of `initial` of scipy.integrate.cumtrapz()
* `#7916 <https://github.com/scipy/scipy/pull/7916>`__: BUG: sparse.linalg: fix wrong use of __new__ in LinearOperator
* `#7921 <https://github.com/scipy/scipy/pull/7921>`__: BENCH: split spatial benchmark imports
* `#7927 <https://github.com/scipy/scipy/pull/7927>`__: ENH: added sygst/hegst routines to lapack
* `#7934 <https://github.com/scipy/scipy/pull/7934>`__: MAINT: add `io/_test_fortranmodule` to `.gitignore`
* `#7936 <https://github.com/scipy/scipy/pull/7936>`__: DOC: Fixed typo in scipy.special.roots_jacobi documentation
* `#7937 <https://github.com/scipy/scipy/pull/7937>`__: MAINT: special: Mark a test that fails on i686 as a known failure.
* `#7941 <https://github.com/scipy/scipy/pull/7941>`__: ENH: LDLt decomposition for indefinite symmetric/hermitian matrices
* `#7945 <https://github.com/scipy/scipy/pull/7945>`__: ENH: Implement reshape method on sparse matrices
* `#7947 <https://github.com/scipy/scipy/pull/7947>`__: DOC: update docs on releasing and installing/upgrading
* `#7954 <https://github.com/scipy/scipy/pull/7954>`__: Basin-hopping changes
* `#7964 <https://github.com/scipy/scipy/pull/7964>`__: BUG: test_falker not robust against numerical fuss in eigenvalues
* `#7967 <https://github.com/scipy/scipy/pull/7967>`__: QUADPACK Errors - human friendly errors to replace 'Invalid Input'
* `#7975 <https://github.com/scipy/scipy/pull/7975>`__: Make sure integrate.quad doesn't double-count singular points
* `#7978 <https://github.com/scipy/scipy/pull/7978>`__: TST: ensure negative weights are not allowed in distance metrics
* `#7980 <https://github.com/scipy/scipy/pull/7980>`__: MAINT: Truncate the warning msg about ill-conditioning
* `#7981 <https://github.com/scipy/scipy/pull/7981>`__: BUG: special: fix hyp2f1 behavior in certain circumstances
* `#7983 <https://github.com/scipy/scipy/pull/7983>`__: ENH: special: Add a real dispatch to `loggamma`
* `#7989 <https://github.com/scipy/scipy/pull/7989>`__: BUG: special: make `kv` return `inf` at a zero real argument
* `#7990 <https://github.com/scipy/scipy/pull/7990>`__: TST: special: test ufuncs in special at `nan` inputs
* `#7994 <https://github.com/scipy/scipy/pull/7994>`__: DOC: special: fix typo in spherical Bessel function documentation
* `#7995 <https://github.com/scipy/scipy/pull/7995>`__: ENH: linalg: add null_space for computing null spaces via svd
* `#7999 <https://github.com/scipy/scipy/pull/7999>`__: BUG: optimize: Protect _minpack calls with a lock.
* `#8003 <https://github.com/scipy/scipy/pull/8003>`__: MAINT: consolidate c99 compatibility
* `#8004 <https://github.com/scipy/scipy/pull/8004>`__: TST: special: get all `cython_special` tests running again
* `#8006 <https://github.com/scipy/scipy/pull/8006>`__: MAINT: Consolidate an additional _c99compat.h
* `#8011 <https://github.com/scipy/scipy/pull/8011>`__: Add new example of integrate.quad
* `#8015 <https://github.com/scipy/scipy/pull/8015>`__: DOC: special: remove `jn` from the refguide (again)
* `#8018 <https://github.com/scipy/scipy/pull/8018>`__: BUG - Issue with uint datatypes for array in get_index_dtype
* `#8021 <https://github.com/scipy/scipy/pull/8021>`__: DOC: spatial: Simplify Delaunay plotting
* `#8024 <https://github.com/scipy/scipy/pull/8024>`__: Documentation fix
* `#8027 <https://github.com/scipy/scipy/pull/8027>`__: BUG: io.matlab: fix saving unicode matrix names on py2
* `#8028 <https://github.com/scipy/scipy/pull/8028>`__: BUG: special: some fixes for `lambertw`
* `#8030 <https://github.com/scipy/scipy/pull/8030>`__: MAINT: Bump Cython version
* `#8034 <https://github.com/scipy/scipy/pull/8034>`__: BUG: sparse.linalg: fix corner-case bug in expm
* `#8035 <https://github.com/scipy/scipy/pull/8035>`__: MAINT: special: remove complex division hack
* `#8038 <https://github.com/scipy/scipy/pull/8038>`__: ENH: Cythonize pyx files if pxd dependencies change
* `#8042 <https://github.com/scipy/scipy/pull/8042>`__: TST: stats: reduce required precision in test_fligner
* `#8043 <https://github.com/scipy/scipy/pull/8043>`__: TST: Use diff. values for decimal keyword for single and doubles
* `#8044 <https://github.com/scipy/scipy/pull/8044>`__: TST: accuracy of tests made different for singles and doubles
* `#8049 <https://github.com/scipy/scipy/pull/8049>`__: Unhelpful error message when calling scipy.sparse.save_npz on...
* `#8052 <https://github.com/scipy/scipy/pull/8052>`__: TST: spatial: add a regression test for gh-8051
* `#8059 <https://github.com/scipy/scipy/pull/8059>`__: BUG: special: fix ufunc results for `nan` arguments
* `#8066 <https://github.com/scipy/scipy/pull/8066>`__: MAINT: special: reimplement inverses of incomplete gamma functions
* `#8072 <https://github.com/scipy/scipy/pull/8072>`__: Example for scipy.fftpack.ifft, https://github.com/scipy/scipy/issues/7168
* `#8073 <https://github.com/scipy/scipy/pull/8073>`__: Example for ifftn, https://github.com/scipy/scipy/issues/7168
* `#8078 <https://github.com/scipy/scipy/pull/8078>`__: Link to CoC in contributing.rst doc
* `#8085 <https://github.com/scipy/scipy/pull/8085>`__: BLD: Fix npy_isnan of integer variables in cephes
* `#8088 <https://github.com/scipy/scipy/pull/8088>`__: DOC: note version for which new attributes have been added to...
* `#8090 <https://github.com/scipy/scipy/pull/8090>`__: BUG: special: add nan check to `_legacy_cast_check` functions
* `#8091 <https://github.com/scipy/scipy/pull/8091>`__: Doxy Typos + trivial comment typos (2nd attempt)
* `#8096 <https://github.com/scipy/scipy/pull/8096>`__: TST: special: simplify `Arg`
* `#8101 <https://github.com/scipy/scipy/pull/8101>`__: MAINT: special: run `_generate_pyx.py` when `add_newdocs.py`...
* `#8104 <https://github.com/scipy/scipy/pull/8104>`__: Input checking for scipy.sparse.linalg.inverse()
* `#8105 <https://github.com/scipy/scipy/pull/8105>`__: DOC: special: Update the 'euler' docstring.
* `#8109 <https://github.com/scipy/scipy/pull/8109>`__: MAINT: fixing code comments and hyp2f1 docstring: see issues...
* `#8112 <https://github.com/scipy/scipy/pull/8112>`__: More trivial typos
* `#8113 <https://github.com/scipy/scipy/pull/8113>`__: MAINT: special: generate test data npz files in setup.py and...
* `#8116 <https://github.com/scipy/scipy/pull/8116>`__: DOC: add build instructions
* `#8120 <https://github.com/scipy/scipy/pull/8120>`__: DOC: Clean up README
* `#8121 <https://github.com/scipy/scipy/pull/8121>`__: DOC: Add missing colons in docstrings
* `#8123 <https://github.com/scipy/scipy/pull/8123>`__: BLD: update Bento build config files for recent C99 changes.
* `#8124 <https://github.com/scipy/scipy/pull/8124>`__: Change to avoid use of `fmod` in scipy.signal.chebwin
* `#8126 <https://github.com/scipy/scipy/pull/8126>`__: Added examples for mode arg in geometric_transform
* `#8128 <https://github.com/scipy/scipy/pull/8128>`__: relax relative tolerance parameter in TestMinumumPhase.test_hilbert
* `#8129 <https://github.com/scipy/scipy/pull/8129>`__: ENH: special: use rational approximation for \`digamma\` on \`[1,...
* `#8137 <https://github.com/scipy/scipy/pull/8137>`__: DOC Correct matrix width
* `#8141 <https://github.com/scipy/scipy/pull/8141>`__: MAINT: optimize: remove unused `__main__` code in L-BSGS-B
* `#8147 <https://github.com/scipy/scipy/pull/8147>`__: BLD: update Bento build for removal of .npz scipy.special test...
* `#8148 <https://github.com/scipy/scipy/pull/8148>`__: Alias hanning as an explanatory function of hann
* `#8149 <https://github.com/scipy/scipy/pull/8149>`__: MAINT: special: small fixes for `digamma`
* `#8159 <https://github.com/scipy/scipy/pull/8159>`__: Update version classifiers
* `#8164 <https://github.com/scipy/scipy/pull/8164>`__: BUG: riccati solvers don't catch ill-conditioned problems sufficiently...
* `#8168 <https://github.com/scipy/scipy/pull/8168>`__: DOC: release note for sparse resize methods
* `#8170 <https://github.com/scipy/scipy/pull/8170>`__: BUG: correctly pad netCDF files with null bytes
* `#8171 <https://github.com/scipy/scipy/pull/8171>`__: ENH added normal inverse gaussian distribution to scipy.stats
* `#8175 <https://github.com/scipy/scipy/pull/8175>`__: DOC: Add example to scipy.ndimage.zoom
* `#8177 <https://github.com/scipy/scipy/pull/8177>`__: MAINT: diffev small speedup in ensure constraint
* `#8178 <https://github.com/scipy/scipy/pull/8178>`__: FIX: linalg._qz String formatter syntax error
* `#8179 <https://github.com/scipy/scipy/pull/8179>`__: TST: Added pdist to asv spatial benchmark suite
* `#8180 <https://github.com/scipy/scipy/pull/8180>`__: TST: ensure constraint test improved
* `#8183 <https://github.com/scipy/scipy/pull/8183>`__: 0d conj correlate
* `#8186 <https://github.com/scipy/scipy/pull/8186>`__: BUG: special: fix derivative of `spherical_jn(1, 0)`
* `#8194 <https://github.com/scipy/scipy/pull/8194>`__: Fix warning message
* `#8196 <https://github.com/scipy/scipy/pull/8196>`__: BUG: correctly handle inputs with nan's and ties in spearmanr
* `#8198 <https://github.com/scipy/scipy/pull/8198>`__: MAINT: stats.triang edge case fixes #6036
* `#8200 <https://github.com/scipy/scipy/pull/8200>`__: DOC: Completed "Examples" sections of all linalg funcs
* `#8201 <https://github.com/scipy/scipy/pull/8201>`__: MAINT: stats.trapz edge cases
* `#8204 <https://github.com/scipy/scipy/pull/8204>`__: ENH: sparse.linalg/lobpcg: change .T to .T.conj() to support...
* `#8206 <https://github.com/scipy/scipy/pull/8206>`__: MAINT: missed triang edge case.
* `#8214 <https://github.com/scipy/scipy/pull/8214>`__: BUG: Fix memory corruption in linalg._decomp_update C extension
* `#8222 <https://github.com/scipy/scipy/pull/8222>`__: DOC: recommend scipy.integrate.solve_ivp
* `#8223 <https://github.com/scipy/scipy/pull/8223>`__: ENH: added Moyal distribution to scipy.stats
* `#8232 <https://github.com/scipy/scipy/pull/8232>`__: BUG: sparse: Use deduped data for numpy ufuncs
* `#8236 <https://github.com/scipy/scipy/pull/8236>`__: Fix #8235
* `#8253 <https://github.com/scipy/scipy/pull/8253>`__: BUG: optimize: fix bug related with function call calculation...
* `#8264 <https://github.com/scipy/scipy/pull/8264>`__: ENH: Extend peak finding capabilities in scipy.signal
* `#8273 <https://github.com/scipy/scipy/pull/8273>`__: BUG fixed printing of convergence message in minimize_scalar...
* `#8276 <https://github.com/scipy/scipy/pull/8276>`__: DOC: Add notes to explain constrains on overwrite_<>
* `#8279 <https://github.com/scipy/scipy/pull/8279>`__: CI: fixing doctests
* `#8282 <https://github.com/scipy/scipy/pull/8282>`__: MAINT: weightedtau, change search for nan
* `#8287 <https://github.com/scipy/scipy/pull/8287>`__: Improving documentation of solve_ivp and the underlying solvers
* `#8291 <https://github.com/scipy/scipy/pull/8291>`__: DOC: fix non-ascii characters in docstrings which broke the doc...
* `#8292 <https://github.com/scipy/scipy/pull/8292>`__: CI: use numpy 1.13 for refguide check build
* `#8296 <https://github.com/scipy/scipy/pull/8296>`__: Fixed bug reported in issue #8181
* `#8297 <https://github.com/scipy/scipy/pull/8297>`__: DOC: Examples for linalg/decomp eigvals function
* `#8300 <https://github.com/scipy/scipy/pull/8300>`__: MAINT: Housekeeping for minimizing the linalg compiler warnings
* `#8301 <https://github.com/scipy/scipy/pull/8301>`__: DOC: make public API documentation cross-link to refguide.
* `#8302 <https://github.com/scipy/scipy/pull/8302>`__: make sure _onenorm_matrix_power_nnm actually returns a float
* `#8313 <https://github.com/scipy/scipy/pull/8313>`__: Change copyright to outdated 2008-2016 to 2008-year
* `#8315 <https://github.com/scipy/scipy/pull/8315>`__: TST: Add tests for \`scipy.sparse.linalg.isolve.minres\`
* `#8318 <https://github.com/scipy/scipy/pull/8318>`__: ENH: odeint: Add the argument 'tfirst' to odeint.
* `#8328 <https://github.com/scipy/scipy/pull/8328>`__: ENH: optimize: ``trust-constr`` optimization algorithms [GSoC...
* `#8330 <https://github.com/scipy/scipy/pull/8330>`__: ENH: add a maxiter argument to NNLS
* `#8331 <https://github.com/scipy/scipy/pull/8331>`__: DOC: tweak the Moyal distribution docstring
* `#8333 <https://github.com/scipy/scipy/pull/8333>`__: FIX: Rewrapped ?gels and ?gels_lwork routines
* `#8336 <https://github.com/scipy/scipy/pull/8336>`__: MAINT: integrate: handle b < a in quad
* `#8337 <https://github.com/scipy/scipy/pull/8337>`__: BUG: special: Ensure zetac(1) returns inf.
* `#8347 <https://github.com/scipy/scipy/pull/8347>`__: BUG: Fix overflow in special.binom. Issue #8346
* `#8356 <https://github.com/scipy/scipy/pull/8356>`__: DOC: Corrected Documentation Issue #7750 winsorize function
* `#8358 <https://github.com/scipy/scipy/pull/8358>`__: ENH: stats: Use explicit MLE formulas in lognorm.fit and expon.fit
* `#8374 <https://github.com/scipy/scipy/pull/8374>`__: BUG: gh7854, maxiter for l-bfgs-b closes #7854
* `#8379 <https://github.com/scipy/scipy/pull/8379>`__: CI: enable gcov coverage on travis
* `#8383 <https://github.com/scipy/scipy/pull/8383>`__: Removed collections.OrderedDict import ignore.
* `#8384 <https://github.com/scipy/scipy/pull/8384>`__: TravisCI: tool pep8 is now pycodestyle
* `#8387 <https://github.com/scipy/scipy/pull/8387>`__: MAINT: special: remove unused specfun code for Struve functions
* `#8393 <https://github.com/scipy/scipy/pull/8393>`__: DOC: Replace old type names in ndimage tutorial.
* `#8400 <https://github.com/scipy/scipy/pull/8400>`__: Fix tolerance specification in sparse.linalg iterative solvers
* `#8402 <https://github.com/scipy/scipy/pull/8402>`__: MAINT: Some small cleanups in ndimage.
* `#8403 <https://github.com/scipy/scipy/pull/8403>`__: FIX: Make scipy.optimize.zeros run under PyPy
* `#8407 <https://github.com/scipy/scipy/pull/8407>`__: BUG: sparse.linalg: fix termination bugs for cg, cgs
* `#8409 <https://github.com/scipy/scipy/pull/8409>`__: MAINT: special: add a `.pxd` file for Cephes functions
* `#8412 <https://github.com/scipy/scipy/pull/8412>`__: MAINT: special: remove `cephes/protos.h`
* `#8421 <https://github.com/scipy/scipy/pull/8421>`__: Setting "unknown" message in OptimizeResult when calling MINPACK.
* `#8423 <https://github.com/scipy/scipy/pull/8423>`__: FIX: Handle unsigned integers in mmio
* `#8426 <https://github.com/scipy/scipy/pull/8426>`__: DOC: correct FAQ entry on Apache license compatibility. Closes...
* `#8433 <https://github.com/scipy/scipy/pull/8433>`__: MAINT: add `.pytest_cache` to the `.gitignore`
* `#8436 <https://github.com/scipy/scipy/pull/8436>`__: MAINT: scipy.sparse: less copies at transpose method
* `#8437 <https://github.com/scipy/scipy/pull/8437>`__: BUG: correct behavior for skew-symmetric matrices in io.mmwrite
* `#8440 <https://github.com/scipy/scipy/pull/8440>`__: DOC:Add examples to integrate.quadpack docstrings
* `#8441 <https://github.com/scipy/scipy/pull/8441>`__: BUG: sparse.linalg/gmres: deal with exact breakdown in gmres
* `#8442 <https://github.com/scipy/scipy/pull/8442>`__: MAINT: special: clean up Cephes header files
* `#8448 <https://github.com/scipy/scipy/pull/8448>`__: TST: Generalize doctest stopwords .axis( .plot(
* `#8457 <https://github.com/scipy/scipy/pull/8457>`__: MAINT: special: use JSON for function signatures in `_generate_pyx.py`
* `#8461 <https://github.com/scipy/scipy/pull/8461>`__: MAINT: Simplify return value of ndimage functions.
* `#8464 <https://github.com/scipy/scipy/pull/8464>`__: MAINT: Trivial typos
* `#8474 <https://github.com/scipy/scipy/pull/8474>`__: BUG: spatial: make qhull.pyx more pypy-friendly
* `#8476 <https://github.com/scipy/scipy/pull/8476>`__: TST: _lib: disable refcounting tests on PyPy
* `#8479 <https://github.com/scipy/scipy/pull/8479>`__: BUG: io/matlab: fix issues in matlab i/o on pypy
* `#8481 <https://github.com/scipy/scipy/pull/8481>`__: DOC: Example for signal.cmplx_sort
* `#8482 <https://github.com/scipy/scipy/pull/8482>`__: TST: integrate: use integers instead of PyCapsules to store pointers
* `#8483 <https://github.com/scipy/scipy/pull/8483>`__: ENH: io/netcdf: make mmap=False the default on PyPy
* `#8484 <https://github.com/scipy/scipy/pull/8484>`__: BUG: io/matlab: work around issue in to_writeable on PyPy
* `#8488 <https://github.com/scipy/scipy/pull/8488>`__: MAINT: special: add const/static specifiers where possible
* `#8489 <https://github.com/scipy/scipy/pull/8489>`__: BUG: ENH: use common halley's method instead of parabolic variant
* `#8491 <https://github.com/scipy/scipy/pull/8491>`__: DOC: fix typos
* `#8496 <https://github.com/scipy/scipy/pull/8496>`__: ENH: special: make Chebyshev nodes symmetric
* `#8501 <https://github.com/scipy/scipy/pull/8501>`__: BUG: stats: Split the integral used to compute skewnorm.cdf.
* `#8502 <https://github.com/scipy/scipy/pull/8502>`__: WIP: Port CircleCI to v2
* `#8507 <https://github.com/scipy/scipy/pull/8507>`__: DOC: Add missing description to `brute_force` parameter.
* `#8509 <https://github.com/scipy/scipy/pull/8509>`__: BENCH: forgot to add nelder-mead to list of methods
* `#8512 <https://github.com/scipy/scipy/pull/8512>`__: MAINT: Move spline interpolation code to spline.c
* `#8513 <https://github.com/scipy/scipy/pull/8513>`__: TST: special: mark a slow test as xslow
* `#8514 <https://github.com/scipy/scipy/pull/8514>`__: CircleCI: Share data between jobs
* `#8515 <https://github.com/scipy/scipy/pull/8515>`__: ENH: special: improve accuracy of `zetac` for negative arguments
* `#8520 <https://github.com/scipy/scipy/pull/8520>`__: TST: Decrease the array sizes for two linalg tests
* `#8522 <https://github.com/scipy/scipy/pull/8522>`__: TST: special: restrict range of `test_besselk`/`test_besselk_int`
* `#8527 <https://github.com/scipy/scipy/pull/8527>`__: Documentation - example added for voronoi_plot_2d
* `#8528 <https://github.com/scipy/scipy/pull/8528>`__: DOC: Better, shared docstrings in ndimage
* `#8533 <https://github.com/scipy/scipy/pull/8533>`__: BUG: Fix PEP8 errors introduced in #8528.
* `#8534 <https://github.com/scipy/scipy/pull/8534>`__: ENH: Expose additional window functions
* `#8538 <https://github.com/scipy/scipy/pull/8538>`__: MAINT: Fix a couple mistakes in .pyf files.
* `#8540 <https://github.com/scipy/scipy/pull/8540>`__: ENH: interpolate: allow string aliases in make_interp_spline...
* `#8541 <https://github.com/scipy/scipy/pull/8541>`__: ENH: Cythonize peak_prominences
* `#8542 <https://github.com/scipy/scipy/pull/8542>`__: Remove numerical arguments from convolve2d / correlate2d
* `#8546 <https://github.com/scipy/scipy/pull/8546>`__: ENH: New arguments, documentation, and tests for ndimage.binary_opening
* `#8547 <https://github.com/scipy/scipy/pull/8547>`__: Giving both size and input now raises UserWarning (#7334)
* `#8549 <https://github.com/scipy/scipy/pull/8549>`__: DOC: stats: invweibull is also known as Frechet or type II extreme...
* `#8550 <https://github.com/scipy/scipy/pull/8550>`__: add cdf2rdf function
* `#8551 <https://github.com/scipy/scipy/pull/8551>`__: ENH: Port of most of the dd_real part of the qd high-precision...
* `#8553 <https://github.com/scipy/scipy/pull/8553>`__: Note in docs to address issue #3164.
* `#8554 <https://github.com/scipy/scipy/pull/8554>`__: ENH: stats: Use explicit MLE formulas in uniform.fit()
* `#8555 <https://github.com/scipy/scipy/pull/8555>`__: MAINT: adjust benchmark config
* `#8557 <https://github.com/scipy/scipy/pull/8557>`__: [DOC]: fix Nakagami density docstring
* `#8559 <https://github.com/scipy/scipy/pull/8559>`__: DOC: Fix docstring of diric(x, n)
* `#8563 <https://github.com/scipy/scipy/pull/8563>`__: [DOC]: fix gamma density docstring
* `#8564 <https://github.com/scipy/scipy/pull/8564>`__: BLD: change default Python version for doc build from 2.7 to...
* `#8568 <https://github.com/scipy/scipy/pull/8568>`__: BUG: Fixes Bland's Rule for pivot row/leaving variable, closes...
* `#8572 <https://github.com/scipy/scipy/pull/8572>`__: ENH: Add previous/next to interp1d
* `#8578 <https://github.com/scipy/scipy/pull/8578>`__: Example for linalg.eig()
* `#8580 <https://github.com/scipy/scipy/pull/8580>`__: DOC: update link to asv docs
* `#8584 <https://github.com/scipy/scipy/pull/8584>`__: filter_design: switch to explicit arguments, keeping None as...
* `#8586 <https://github.com/scipy/scipy/pull/8586>`__: DOC: stats: Add parentheses that were missing in the exponnorm...
* `#8587 <https://github.com/scipy/scipy/pull/8587>`__: TST: add benchmark for newton, secant, halley
* `#8588 <https://github.com/scipy/scipy/pull/8588>`__: DOC: special: Remove heaviside from "functions not in special"...
* `#8591 <https://github.com/scipy/scipy/pull/8591>`__: DOC: cdf2rdf Added version info and "See also"
* `#8594 <https://github.com/scipy/scipy/pull/8594>`__: ENH: Cythonize peak_widths
* `#8595 <https://github.com/scipy/scipy/pull/8595>`__: MAINT/ENH/BUG/TST: cdf2rdf: Address review comments made after...
* `#8597 <https://github.com/scipy/scipy/pull/8597>`__: DOC: add versionadded 1.1.0 for new keywords in ndimage.morphology
* `#8605 <https://github.com/scipy/scipy/pull/8605>`__: MAINT: special: improve implementations of `sinpi` and `cospi`
* `#8607 <https://github.com/scipy/scipy/pull/8607>`__: MAINT: add 2D benchmarks for convolve
* `#8608 <https://github.com/scipy/scipy/pull/8608>`__: FIX: Fix int check
* `#8613 <https://github.com/scipy/scipy/pull/8613>`__: fix typo in doc of signal.peak_widths
* `#8615 <https://github.com/scipy/scipy/pull/8615>`__: TST: fix failing linalg.qz float32 test by decreasing precision.
* `#8617 <https://github.com/scipy/scipy/pull/8617>`__: MAINT: clean up code in ellpj.c
* `#8618 <https://github.com/scipy/scipy/pull/8618>`__: add fsolve docs it doesn't handle over- or under-determined problems
* `#8620 <https://github.com/scipy/scipy/pull/8620>`__: DOC: add note on dtype attribute of aslinearoperator() argument
* `#8627 <https://github.com/scipy/scipy/pull/8627>`__: ENH: Add example 1D signal (ECG) to scipy.misc
* `#8630 <https://github.com/scipy/scipy/pull/8630>`__: ENH: Remove unnecessary copying in stats.percentileofscore
* `#8631 <https://github.com/scipy/scipy/pull/8631>`__: BLD: fix pdf doc build. closes gh-8076
* `#8633 <https://github.com/scipy/scipy/pull/8633>`__: BUG: fix regression in `io.netcdf_file` with append mode.
* `#8635 <https://github.com/scipy/scipy/pull/8635>`__: MAINT: remove spurious warning from (z)vode and lsoda. Closes...
* `#8636 <https://github.com/scipy/scipy/pull/8636>`__: BUG: sparse.linalg/gcrotmk: avoid rounding error in termination...
* `#8637 <https://github.com/scipy/scipy/pull/8637>`__: For pdf build
* `#8639 <https://github.com/scipy/scipy/pull/8639>`__: CI: build pdf documentation on circleci
* `#8640 <https://github.com/scipy/scipy/pull/8640>`__: TST: fix special test that was importing `np.testing.utils` (deprecated)
* `#8641 <https://github.com/scipy/scipy/pull/8641>`__: BUG: optimize: fixed sparse redundancy removal bug
* `#8645 <https://github.com/scipy/scipy/pull/8645>`__: BUG: modified sigmaclip to avoid clipping of constant input in...
* `#8647 <https://github.com/scipy/scipy/pull/8647>`__: TST: sparse: skip test_inplace_dense for numpy<1.13
* `#8657 <https://github.com/scipy/scipy/pull/8657>`__: Latex reduce left margins
* `#8659 <https://github.com/scipy/scipy/pull/8659>`__: TST: special: skip sign-of-zero test on 32-bit win32 with old...
* `#8661 <https://github.com/scipy/scipy/pull/8661>`__: Fix dblquad and tplquad not accepting float boundaries
* `#8666 <https://github.com/scipy/scipy/pull/8666>`__: DOC: fixes #8532
* `#8667 <https://github.com/scipy/scipy/pull/8667>`__: BUG: optimize: fixed issue #8663
* `#8668 <https://github.com/scipy/scipy/pull/8668>`__: Fix example in docstring of netcdf_file
* `#8671 <https://github.com/scipy/scipy/pull/8671>`__: DOC: Replace deprecated matplotlib kwarg
* `#8673 <https://github.com/scipy/scipy/pull/8673>`__: BUG: special: Use a stricter tolerance for the chndtr calculation.
* `#8674 <https://github.com/scipy/scipy/pull/8674>`__: ENH: In the Dirichlet distribution allow x_i to be 0 if alpha_i...
* `#8676 <https://github.com/scipy/scipy/pull/8676>`__: BUG: optimize: partial fix to linprog fails to detect infeasibility...
* `#8685 <https://github.com/scipy/scipy/pull/8685>`__: DOC: Add interp1d-next/previous example to tutorial
* `#8687 <https://github.com/scipy/scipy/pull/8687>`__: TST: netcdf: explicit mmap=True in test
* `#8688 <https://github.com/scipy/scipy/pull/8688>`__: BUG: signal, stats: use Python sum() instead of np.sum for summing...
* `#8689 <https://github.com/scipy/scipy/pull/8689>`__: TST: bump tolerances in tests
* `#8690 <https://github.com/scipy/scipy/pull/8690>`__: DEP: deprecate stats.itemfreq
* `#8691 <https://github.com/scipy/scipy/pull/8691>`__: BLD: special: fix build vs. dd_real.h package
* `#8695 <https://github.com/scipy/scipy/pull/8695>`__: DOC: Improve examples in signal.find_peaks with ECG signal
* `#8697 <https://github.com/scipy/scipy/pull/8697>`__: BUG: Fix `setup.py build install egg_info`, which did not previously...
* `#8704 <https://github.com/scipy/scipy/pull/8704>`__: TST: linalg: drop large size from solve() test
* `#8705 <https://github.com/scipy/scipy/pull/8705>`__: DOC: Describe signal.find_peaks and related functions behavior...
* `#8706 <https://github.com/scipy/scipy/pull/8706>`__: DOC: Specify encoding of rst file, remove an ambiguity in an...
* `#8710 <https://github.com/scipy/scipy/pull/8710>`__: MAINT: fix an import cycle sparse -> special -> integrate ->...
* `#8711 <https://github.com/scipy/scipy/pull/8711>`__: ENH: remove an avoidable overflow in scipy.stats.norminvgauss.pdf()
* `#8716 <https://github.com/scipy/scipy/pull/8716>`__: BUG: interpolate: allow list inputs for make_interp_spline(...,...
* `#8720 <https://github.com/scipy/scipy/pull/8720>`__: np.testing import that is compatible with numpy 1.15
* `#8724 <https://github.com/scipy/scipy/pull/8724>`__: CI: don't use pyproject.toml in the CI builds
==========================
SciPy 1.6.3 Release Notes
==========================

.. contents::

SciPy 1.6.3 is a bug-fix release with no new features
compared to 1.6.2.

Authors
=======

* Peter Bell
* Ralf Gommers
* Matt Haberland
* Peter Mahler Larsen
* Tirth Patel
* Tyler Reddy
* Pamphile ROY +
* Xingyu Liu +

A total of 8 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.6.3
-----------------------

* `#13772 <https://github.com/scipy/scipy/issues/13772>`__: Divide by zero in distance.yule
* `#13796 <https://github.com/scipy/scipy/issues/13796>`__: CI: prerelease_deps failures
* `#13890 <https://github.com/scipy/scipy/issues/13890>`__: TST: spatial rotation failure in (1.6.3) wheels repo (ARM64)


Pull requests for 1.6.3
-----------------------

* `#13755 <https://github.com/scipy/scipy/pull/13755>`__: CI: fix the matplotlib warning emitted during builing docs
* `#13773 <https://github.com/scipy/scipy/pull/13773>`__: BUG: Divide by zero in yule dissimilarity of constant vectors
* `#13799 <https://github.com/scipy/scipy/pull/13799>`__: CI/MAINT: deprecated np.typeDict
* `#13819 <https://github.com/scipy/scipy/pull/13819>`__: substitute np.math.factorial with math.factorial
* `#13895 <https://github.com/scipy/scipy/pull/13895>`__: TST: add random seeds in Rotation module
==========================
SciPy 0.15.0 Release Notes
==========================

.. contents::

SciPy 0.15.0 is the culmination of 6 months of hard work. It contains
several new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.16.x branch, and on adding
new features on the master branch.

This release requires Python 2.6, 2.7 or 3.2-3.4 and NumPy 1.5.1 or greater.


New features
============

Linear Programming Interface
----------------------------

The new function `scipy.optimize.linprog` provides a generic
linear programming similar to the way `scipy.optimize.minimize`
provides a generic interface to nonlinear programming optimizers.
Currently the only method supported is *simplex* which provides
a two-phase, dense-matrix-based simplex algorithm. Callbacks
functions are supported, allowing the user to monitor the progress
of the algorithm.

Differential evolution, a global optimizer
------------------------------------------

A new `scipy.optimize.differential_evolution` function has been added to the
``optimize`` module.  Differential Evolution is an algorithm used for finding
the global minimum of multivariate functions. It is stochastic in nature (does
not use gradient methods), and can search large areas of candidate space, but
often requires larger numbers of function evaluations than conventional
gradient based techniques.

``scipy.signal`` improvements
-----------------------------

The function `scipy.signal.max_len_seq` was added, which computes a Maximum
Length Sequence (MLS) signal.

``scipy.integrate`` improvements
--------------------------------

It is now possible to use `scipy.integrate` routines to integrate
multivariate ctypes functions, thus avoiding callbacks to Python and
providing better performance.

``scipy.linalg`` improvements
-----------------------------

The function `scipy.linalg.orthogonal_procrustes` for solving the procrustes
linear algebra problem was added.

BLAS level 2 functions ``her``, ``syr``, ``her2`` and ``syr2`` are now wrapped
in ``scipy.linalg``.

``scipy.sparse`` improvements
-----------------------------

`scipy.sparse.linalg.svds` can now take a ``LinearOperator`` as its main input.

``scipy.special`` improvements
------------------------------

Values of ellipsoidal harmonic (i.e. Lame) functions and associated
normalization constants can be now computed using ``ellip_harm``,
``ellip_harm_2``, and ``ellip_normal``.

New convenience functions ``entr``, ``rel_entr`` ``kl_div``,
``huber``, and ``pseudo_huber`` were added.

``scipy.sparse.csgraph`` improvements
-------------------------------------

Routines ``reverse_cuthill_mckee`` and ``maximum_bipartite_matching``
for computing reorderings of sparse graphs were added.

``scipy.stats`` improvements
----------------------------

Added a Dirichlet multivariate distribution, `scipy.stats.dirichlet`.

The new function `scipy.stats.median_test` computes Mood's median test.

The new function `scipy.stats.combine_pvalues` implements Fisher's
and Stouffer's methods for combining p-values.

`scipy.stats.describe` returns a namedtuple rather than a tuple, allowing
users to access results by index or by name.


Deprecated features
===================

The `scipy.weave` module is deprecated.  It was the only module never ported
to Python 3.x, and is not recommended to be used for new code - use Cython
instead.  In order to support existing code, ``scipy.weave`` has been packaged
separately: https://github.com/scipy/weave.  It is a pure Python package, and
can easily be installed with ``pip install weave``.

``scipy.special.bessel_diff_formula`` is deprecated.  It is a private function,
and therefore will be removed from the public API in a following release.

``scipy.stats.nanmean``, ``nanmedian`` and ``nanstd`` functions are deprecated
in favor of their numpy equivalents.


Backwards incompatible changes
==============================

scipy.ndimage
-------------

The functions `scipy.ndimage.minimum_positions`,
`scipy.ndimage.maximum_positions`` and `scipy.ndimage.extrema` return
positions as ints instead of floats.

scipy.integrate
---------------

The format of banded Jacobians in `scipy.integrate.ode` solvers is
changed. Note that the previous documentation of this feature was
erroneous.

Authors
=======

* Abject +
* Ankit Agrawal +
* Sylvain Bellemare +
* Matthew Brett
* Christian Brodbeck
* Christian Brueffer
* Lars Buitinck
* Evgeni Burovski
* Pierre de Buyl +
* Greg Caporaso +
* CJ Carey
* Jacob Carey +
* Thomas A Caswell
* Helder Cesar +
* Björn Dahlgren +
* Kevin Davies +
* Yotam Doron +
* Marcos Duarte +
* endolith
* Jesse Engel +
* Rob Falck +
* Corey Farwell +
* Jaime Fernandez del Rio +
* Clark Fitzgerald +
* Tom Flannaghan +
* Chad Fulton +
* Jochen Garcke +
* François Garillot +
* André Gaul
* Christoph Gohlke
* Ralf Gommers
* Alex Griffing
* Blake Griffith
* Olivier Grisel
* Charles Harris
* Trent Hauck +
* Ian Henriksen +
* Jinhyok Heo +
* Matt Hickford +
* Andreas Hilboll
* Danilo Horta +
* David Menéndez Hurtado +
* Gert-Ludwig Ingold
* Thouis (Ray) Jones
* Chris Kerr +
* Carl Kleffner +
* Andreas Kloeckner
* Thomas Kluyver +
* Adrian Kretz +
* Johannes Kulick +
* Eric Larson
* Brianna Laugher +
* Denis Laxalde
* Antony Lee +
* Gregory R. Lee +
* Brandon Liu
* Alex Loew +
* Loïc Estève +
* Jaakko Luttinen +
* Benny Malengier
* Tobias Megies +
* Sturla Molden
* Eric Moore
* Brett R. Murphy +
* Paul Nation +
* Andrew Nelson
* Brian Newsom +
* Joel Nothman
* Sergio Oller +
* Janani Padmanabhan +
* Tiago M.D. Pereira +
* Nicolas Del Piano +
* Manuel Reinhardt +
* Thomas Robitaille
* Mike Romberg +
* Alex Rothberg +
* Sebastian Pölsterl +
* Maximilian Singh +
* Brigitta Sipocz +
* Alex Stewart +
* Julian Taylor
* Collin Tokheim +
* James Tomlinson +
* Benjamin Trendelkamp-Schroer +
* Richard Tsai
* Alexey Umnov +
* Jacob Vanderplas
* Joris Vankerschaver
* Bastian Venthur +
* Pauli Virtanen
* Stefan van der Walt
* Yuxiang Wang +
* James T. Webber
* Warren Weckesser
* Axl West +
* Nathan Woods
* Benda Xu +
* Víctor Zabalza +
* Tiziano Zito +

A total of 99 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed
-------------

- `#1431 <https://github.com/scipy/scipy/issues/1431>`__: ellipk(x) extending its domain for x<0 (Trac #904)
- `#1727 <https://github.com/scipy/scipy/issues/1727>`__: consistency of std interface (Trac #1200)
- `#1851 <https://github.com/scipy/scipy/issues/1851>`__: Shape parameter negated in genextreme (relative to R, MATLAB,...
- `#1889 <https://github.com/scipy/scipy/issues/1889>`__: interp2d is weird (Trac #1364)
- `#2188 <https://github.com/scipy/scipy/issues/2188>`__: splev gives wrong values or crashes outside of support when der...
- `#2343 <https://github.com/scipy/scipy/issues/2343>`__: scipy.insterpolate's splrep function fails with certain combinations...
- `#2669 <https://github.com/scipy/scipy/issues/2669>`__: .signal.ltisys.ss2tf should only apply to MISO systems in current...
- `#2911 <https://github.com/scipy/scipy/issues/2911>`__: interpolate.splder() failure on Fedora
- `#3171 <https://github.com/scipy/scipy/issues/3171>`__: future of weave in scipy
- `#3176 <https://github.com/scipy/scipy/issues/3176>`__: Suggestion to improve error message in scipy.integrate.odeint
- `#3198 <https://github.com/scipy/scipy/issues/3198>`__: pdf() and logpdf() methods for scipy.stats.gaussian_kde
- `#3318 <https://github.com/scipy/scipy/issues/3318>`__: Travis CI is breaking on test("full")
- `#3329 <https://github.com/scipy/scipy/issues/3329>`__: scipy.stats.scoreatpercentile backward-incompatible change not...
- `#3362 <https://github.com/scipy/scipy/issues/3362>`__: Reference cycle in scipy.sparse.linalg.eigs with shift-invert...
- `#3364 <https://github.com/scipy/scipy/issues/3364>`__: BUG: linalg.hessenberg broken (wrong results)
- `#3376 <https://github.com/scipy/scipy/issues/3376>`__: stats f_oneway needs floats
- `#3379 <https://github.com/scipy/scipy/issues/3379>`__: Installation of scipy 0.13.3 via zc.buildout fails
- `#3403 <https://github.com/scipy/scipy/issues/3403>`__: hierarchy.linkage raises an ugly exception for a compressed 2x2...
- `#3422 <https://github.com/scipy/scipy/issues/3422>`__: optimize.curve_fit() handles NaN by returning all parameters...
- `#3457 <https://github.com/scipy/scipy/issues/3457>`__: linalg.fractional_matrix_power has no docstring
- `#3469 <https://github.com/scipy/scipy/issues/3469>`__: DOC: `ndimage.find_object` ignores zero-values
- `#3491 <https://github.com/scipy/scipy/issues/3491>`__: optimize.leastsq() documentation should mention it does not work...
- `#3499 <https://github.com/scipy/scipy/issues/3499>`__: cluster.vq.whiten return nan for all zeros column in observations
- `#3503 <https://github.com/scipy/scipy/issues/3503>`__: minimize attempts to do vector addition when numpy arrays are...
- `#3508 <https://github.com/scipy/scipy/issues/3508>`__: exponweib.logpdf fails for valid parameters
- `#3509 <https://github.com/scipy/scipy/issues/3509>`__: libatlas3-base-dev does not exist
- `#3550 <https://github.com/scipy/scipy/issues/3550>`__: BUG: anomalous values computed by special.ellipkinc
- `#3555 <https://github.com/scipy/scipy/issues/3555>`__: `scipy.ndimage` positions are float instead of int
- `#3557 <https://github.com/scipy/scipy/issues/3557>`__: UnivariateSpline.__call__ should pass all relevant args through...
- `#3569 <https://github.com/scipy/scipy/issues/3569>`__: No license statement for test data imported from boost?
- `#3576 <https://github.com/scipy/scipy/issues/3576>`__: mstats test failure (too sensitive?)
- `#3579 <https://github.com/scipy/scipy/issues/3579>`__: Errors on scipy 0.14.x branch using MKL, Ubuntu 14.04 x86_64
- `#3580 <https://github.com/scipy/scipy/issues/3580>`__: Operator overloading with sparse matrices
- `#3587 <https://github.com/scipy/scipy/issues/3587>`__: Wrong alphabetical order in continuous statistical distribution...
- `#3596 <https://github.com/scipy/scipy/issues/3596>`__: scipy.signal.fftconvolve no longer threadsafe
- `#3623 <https://github.com/scipy/scipy/issues/3623>`__: BUG: signal.convolve takes longer than it needs to
- `#3655 <https://github.com/scipy/scipy/issues/3655>`__: Integer returned from integer data in scipy.signal.periodogram...
- `#3662 <https://github.com/scipy/scipy/issues/3662>`__: Travis failure on Numpy 1.5.1 (not reproducible?)
- `#3668 <https://github.com/scipy/scipy/issues/3668>`__: dendogram(orientation='foo')
- `#3669 <https://github.com/scipy/scipy/issues/3669>`__: KroghInterpolator doesn't pass through points
- `#3672 <https://github.com/scipy/scipy/issues/3672>`__: Inserting a knot in a spline
- `#3682 <https://github.com/scipy/scipy/issues/3682>`__: misleading documentation of scipy.optimize.curve_fit
- `#3699 <https://github.com/scipy/scipy/issues/3699>`__: BUG?: minor problem with scipy.signal.lfilter w/initial conditions
- `#3700 <https://github.com/scipy/scipy/issues/3700>`__: Inconsistent exceptions raised by scipy.io.loadmat
- `#3703 <https://github.com/scipy/scipy/issues/3703>`__: TypeError for RegularGridInterpolator with big-endian data
- `#3714 <https://github.com/scipy/scipy/issues/3714>`__: Misleading error message in eigsh: k must be between 1 and rank(A)-1
- `#3720 <https://github.com/scipy/scipy/issues/3720>`__: coo_matrix.setdiag() fails
- `#3740 <https://github.com/scipy/scipy/issues/3740>`__: Scipy.Spatial.KdTree (Query) Return Type?
- `#3761 <https://github.com/scipy/scipy/issues/3761>`__: Invalid result from scipy.special.btdtri
- `#3784 <https://github.com/scipy/scipy/issues/3784>`__: DOC - Special Functions - Drum example fix for higher modes
- `#3785 <https://github.com/scipy/scipy/issues/3785>`__: minimize() should have friendlier args=
- `#3787 <https://github.com/scipy/scipy/issues/3787>`__: BUG: signal: Division by zero in lombscargle
- `#3800 <https://github.com/scipy/scipy/issues/3800>`__: BUG: scipy.sparse.csgraph.shortest_path overwrites input matrix
- `#3817 <https://github.com/scipy/scipy/issues/3817>`__: Warning in calculating moments from Binomial distribution for...
- `#3821 <https://github.com/scipy/scipy/issues/3821>`__: review scipy usage of `np.ma.is_masked`
- `#3829 <https://github.com/scipy/scipy/issues/3829>`__: Linear algebra function documentation doesn't mention default...
- `#3830 <https://github.com/scipy/scipy/issues/3830>`__: A bug in Docstring of scipy.linalg.eig
- `#3844 <https://github.com/scipy/scipy/issues/3844>`__: Issue with shape parameter returned by genextreme
- `#3858 <https://github.com/scipy/scipy/issues/3858>`__: "ImportError: No module named Cython.Compiler.Main" on install
- `#3876 <https://github.com/scipy/scipy/issues/3876>`__: savgol_filter not in release notes and has no versionadded
- `#3884 <https://github.com/scipy/scipy/issues/3884>`__: scipy.stats.kendalltau empty array error
- `#3895 <https://github.com/scipy/scipy/issues/3895>`__: ValueError: illegal value in 12-th argument of internal gesdd...
- `#3898 <https://github.com/scipy/scipy/issues/3898>`__: skimage test broken by minmax filter change
- `#3901 <https://github.com/scipy/scipy/issues/3901>`__: scipy sparse errors with numpy master
- `#3905 <https://github.com/scipy/scipy/issues/3905>`__: DOC: optimize: linprog docstring has two "Returns" sections
- `#3915 <https://github.com/scipy/scipy/issues/3915>`__: DOC: sphinx warnings because of `**kwds` in the stats distributions...
- `#3935 <https://github.com/scipy/scipy/issues/3935>`__: Split stats.distributions files in tutorial
- `#3969 <https://github.com/scipy/scipy/issues/3969>`__: gh-3607 breaks backward compatibility in ode solver banded jacobians
- `#4025 <https://github.com/scipy/scipy/issues/4025>`__: DOC: signal: The return value of find_peaks_cwt is not documented.
- `#4029 <https://github.com/scipy/scipy/issues/4029>`__: scipy.stats.nbinom.logpmf(0,1,1) returns nan. Correct value is...
- `#4032 <https://github.com/scipy/scipy/issues/4032>`__: ERROR: test_imresize (test_pilutil.TestPILUtil)
- `#4038 <https://github.com/scipy/scipy/issues/4038>`__: errors do not propagate through scipy.integrate.odeint properly
- `#4171 <https://github.com/scipy/scipy/issues/4171>`__: orthogonal_procrustes always returns scale.
- `#4176 <https://github.com/scipy/scipy/issues/4176>`__: Solving the Discrete Lyapunov Equation does not work with matrix...


Pull requests
-------------

- `#3109 <https://github.com/scipy/scipy/pull/3109>`__: ENH Added Fisher's method and Stouffer's Z-score method
- `#3225 <https://github.com/scipy/scipy/pull/3225>`__: Add the limiting distributions to generalized Pareto distribution...
- `#3262 <https://github.com/scipy/scipy/pull/3262>`__: Implement back end of faster multivariate integration
- `#3266 <https://github.com/scipy/scipy/pull/3266>`__: ENH: signal: add type=False as parameter for periodogram and...
- `#3273 <https://github.com/scipy/scipy/pull/3273>`__: Add PEP8 check to Travis-CI
- `#3342 <https://github.com/scipy/scipy/pull/3342>`__: ENH: linprog function for linear programming
- `#3348 <https://github.com/scipy/scipy/pull/3348>`__: BUG: add proper error handling when using interp2d on regular...
- `#3351 <https://github.com/scipy/scipy/pull/3351>`__: ENH: Add MLS method
- `#3382 <https://github.com/scipy/scipy/pull/3382>`__: ENH: scipy.special information theory functions
- `#3396 <https://github.com/scipy/scipy/pull/3396>`__: ENH: improve stats.nanmedian more by assuming nans are rare
- `#3398 <https://github.com/scipy/scipy/pull/3398>`__: Added two wrappers to the gaussian_kde class.
- `#3405 <https://github.com/scipy/scipy/pull/3405>`__: BUG: cluster.linkage array conversion to double dtype
- `#3407 <https://github.com/scipy/scipy/pull/3407>`__: MAINT: use assert_warns instead of a more complicated mechanism
- `#3409 <https://github.com/scipy/scipy/pull/3409>`__: ENH: change to use array view in signal/_peak_finding.py
- `#3416 <https://github.com/scipy/scipy/pull/3416>`__: Issue 3376 : stats f_oneway needs floats
- `#3419 <https://github.com/scipy/scipy/pull/3419>`__: BUG: tools: Fix list of FMA instructions in detect_cpu_extensions_wine.py
- `#3420 <https://github.com/scipy/scipy/pull/3420>`__: DOC: stats: Add 'entropy' to the stats package-level documentation.
- `#3429 <https://github.com/scipy/scipy/pull/3429>`__: BUG: close intermediate file descriptor right after it is used...
- `#3430 <https://github.com/scipy/scipy/pull/3430>`__: MAINT: Fix some cython variable declarations to avoid warnings...
- `#3433 <https://github.com/scipy/scipy/pull/3433>`__: Correcting the normalization of chebwin window function
- `#3435 <https://github.com/scipy/scipy/pull/3435>`__: Add more precise link to R's quantile documentation
- `#3446 <https://github.com/scipy/scipy/pull/3446>`__: ENH: scipy.optimize - adding differential_evolution
- `#3450 <https://github.com/scipy/scipy/pull/3450>`__: MAINT: remove unused function scipy.stats.mstats_basic._kolmog1
- `#3458 <https://github.com/scipy/scipy/pull/3458>`__: Reworked version of PR-3084 (mstats-stats comparison)
- `#3462 <https://github.com/scipy/scipy/pull/3462>`__: MAINT : Returning a warning for low attenuation values of chebwin...
- `#3463 <https://github.com/scipy/scipy/pull/3463>`__: DOC: linalg: Add examples to functions in matfuncs.py
- `#3477 <https://github.com/scipy/scipy/pull/3477>`__: ENH: sparse: release GIL in sparsetools routines
- `#3480 <https://github.com/scipy/scipy/pull/3480>`__: DOC: Add more details to deconvolve docstring
- `#3484 <https://github.com/scipy/scipy/pull/3484>`__: BLD: fix Qhull build issue with MinGW-w64. Closes gh-3237.
- `#3498 <https://github.com/scipy/scipy/pull/3498>`__: MAINT: io: remove old warnings from idl.py
- `#3504 <https://github.com/scipy/scipy/pull/3504>`__: BUG: cluster.vq.whiten returns nan or inf when std==0
- `#3510 <https://github.com/scipy/scipy/pull/3510>`__: MAINT: stats: Reimplement the pdf and logpdf methods of exponweib.
- `#3512 <https://github.com/scipy/scipy/pull/3512>`__: Fix PEP8 errors showing up on TravisCI after pep8 1.5 release
- `#3514 <https://github.com/scipy/scipy/pull/3514>`__: DOC: libatlas3-base-dev seems to have never been a thing
- `#3516 <https://github.com/scipy/scipy/pull/3516>`__: DOC improve scipy.sparse docstrings
- `#3517 <https://github.com/scipy/scipy/pull/3517>`__: ENH: speed-up ndimage.filters.min(max)imum_filter1d
- `#3518 <https://github.com/scipy/scipy/pull/3518>`__: Issues in scipy.misc.logsumexp
- `#3526 <https://github.com/scipy/scipy/pull/3526>`__: DOC: graphical example for cwt, and use a more interesting signal
- `#3527 <https://github.com/scipy/scipy/pull/3527>`__: ENH: Implement min(max)imum_filter1d using the MINLIST algorithm
- `#3537 <https://github.com/scipy/scipy/pull/3537>`__: STY: reduce number of C compiler warnings
- `#3540 <https://github.com/scipy/scipy/pull/3540>`__: DOC: linalg: add docstring to fractional_matrix_power
- `#3542 <https://github.com/scipy/scipy/pull/3542>`__: kde.py Doc Typo
- `#3545 <https://github.com/scipy/scipy/pull/3545>`__: BUG: stats: stats.levy.cdf with small arguments loses precision.
- `#3547 <https://github.com/scipy/scipy/pull/3547>`__: BUG: special: erfcinv with small arguments loses precision.
- `#3553 <https://github.com/scipy/scipy/pull/3553>`__: DOC: Convolve examples
- `#3561 <https://github.com/scipy/scipy/pull/3561>`__: FIX: in ndimage.measurements return positions as int instead...
- `#3564 <https://github.com/scipy/scipy/pull/3564>`__: Fix test failures with numpy master. Closes gh-3554
- `#3565 <https://github.com/scipy/scipy/pull/3565>`__: ENH: make interp2d accept unsorted arrays for interpolation.
- `#3566 <https://github.com/scipy/scipy/pull/3566>`__: BLD: add numpy requirement to metadata if it can't be imported.
- `#3567 <https://github.com/scipy/scipy/pull/3567>`__: DOC: move matfuncs docstrings to user-visible functions
- `#3574 <https://github.com/scipy/scipy/pull/3574>`__: Fixes multiple bugs in mstats.theilslopes
- `#3577 <https://github.com/scipy/scipy/pull/3577>`__: TST: decrease sensitivity of an mstats test
- `#3585 <https://github.com/scipy/scipy/pull/3585>`__: Cleanup of code in scipy.constants
- `#3589 <https://github.com/scipy/scipy/pull/3589>`__: BUG: sparse: allow operator overloading
- `#3594 <https://github.com/scipy/scipy/pull/3594>`__: BUG: lobpcg returned wrong values for small matrices (n < 10)
- `#3598 <https://github.com/scipy/scipy/pull/3598>`__: MAINT: fix coverage and coveralls
- `#3599 <https://github.com/scipy/scipy/pull/3599>`__: MAINT: symeig -- now that's a name I've not heard in a long time
- `#3602 <https://github.com/scipy/scipy/pull/3602>`__: MAINT: clean up the new optimize.linprog and add a few more tests
- `#3607 <https://github.com/scipy/scipy/pull/3607>`__: BUG: integrate: Fix some bugs and documentation errors in the...
- `#3609 <https://github.com/scipy/scipy/pull/3609>`__: MAINT integrate/odepack: kill dead Fortran code
- `#3616 <https://github.com/scipy/scipy/pull/3616>`__: FIX: Invalid values
- `#3617 <https://github.com/scipy/scipy/pull/3617>`__: Sort netcdf variables in a Python-3 compatible way
- `#3622 <https://github.com/scipy/scipy/pull/3622>`__: DOC: Added 0.15.0 release notes entry for linprog function.
- `#3625 <https://github.com/scipy/scipy/pull/3625>`__: Fix documentation for cKDTree.sparse_distance_matrix
- `#3626 <https://github.com/scipy/scipy/pull/3626>`__: MAINT: linalg.orth memory efficiency
- `#3627 <https://github.com/scipy/scipy/pull/3627>`__: MAINT: stats: A bit of clean up
- `#3628 <https://github.com/scipy/scipy/pull/3628>`__: MAINT: signal: remove a useless function from wavelets.py
- `#3632 <https://github.com/scipy/scipy/pull/3632>`__: ENH: stats: Add Mood's median test.
- `#3636 <https://github.com/scipy/scipy/pull/3636>`__: MAINT: cluster: some clean up
- `#3638 <https://github.com/scipy/scipy/pull/3638>`__: DOC: docstring of optimize.basinhopping confuses singular and...
- `#3639 <https://github.com/scipy/scipy/pull/3639>`__: BUG: change ddof default to 1 in mstats.sem, consistent with...
- `#3640 <https://github.com/scipy/scipy/pull/3640>`__: Weave: deprecate the module and disable slow tests on TravisCI
- `#3641 <https://github.com/scipy/scipy/pull/3641>`__: ENH: Added support for date attributes to io.arff.arffread
- `#3644 <https://github.com/scipy/scipy/pull/3644>`__: MAINT: stats: remove superfluous alias in mstats_basic.py
- `#3646 <https://github.com/scipy/scipy/pull/3646>`__: ENH: adding `sum_duplicates` method to COO sparse matrix
- `#3647 <https://github.com/scipy/scipy/pull/3647>`__: Fix for #3596: Make fftconvolve threadsafe
- `#3650 <https://github.com/scipy/scipy/pull/3650>`__: BUG: sparse: smarter random index selection
- `#3652 <https://github.com/scipy/scipy/pull/3652>`__: fix wrong option name in power_divergence dosctring example
- `#3654 <https://github.com/scipy/scipy/pull/3654>`__: Changing EPD to Canopy
- `#3657 <https://github.com/scipy/scipy/pull/3657>`__: BUG: signal.welch: ensure floating point dtype regardless of...
- `#3660 <https://github.com/scipy/scipy/pull/3660>`__: TST: mark a test as known fail
- `#3661 <https://github.com/scipy/scipy/pull/3661>`__: BLD: ignore pep8 E302 (expected 2 blank lines, found 1)
- `#3663 <https://github.com/scipy/scipy/pull/3663>`__: BUG: fix leaking errstate, and ignore invalid= errors in a test
- `#3664 <https://github.com/scipy/scipy/pull/3664>`__: BUG: correlate was extremely slow when in2.size > in1.size
- `#3667 <https://github.com/scipy/scipy/pull/3667>`__: ENH: Adds default params to pdfs of multivariate_norm
- `#3670 <https://github.com/scipy/scipy/pull/3670>`__: ENH: Small speedup of FFT size check
- `#3671 <https://github.com/scipy/scipy/pull/3671>`__: DOC: adding differential_evolution function to 0.15 release notes
- `#3673 <https://github.com/scipy/scipy/pull/3673>`__: BUG: interpolate/fitpack: arguments to fortran routines may not...
- `#3674 <https://github.com/scipy/scipy/pull/3674>`__: Add support for appending to existing netcdf files
- `#3681 <https://github.com/scipy/scipy/pull/3681>`__: Speed up test('full'), solve Travis CI timeout issues
- `#3683 <https://github.com/scipy/scipy/pull/3683>`__: ENH: cluster: rewrite and optimize `vq` in Cython
- `#3684 <https://github.com/scipy/scipy/pull/3684>`__: Update special docs
- `#3688 <https://github.com/scipy/scipy/pull/3688>`__: Spacing in special docstrings
- `#3692 <https://github.com/scipy/scipy/pull/3692>`__: ENH: scipy.special: Improving sph_harm function
- `#3693 <https://github.com/scipy/scipy/pull/3693>`__: Update refguide entries for signal and fftpack
- `#3695 <https://github.com/scipy/scipy/pull/3695>`__: Update continuous.rst
- `#3696 <https://github.com/scipy/scipy/pull/3696>`__: ENH: check for valid 'orientation' kwarg in dendrogram()
- `#3701 <https://github.com/scipy/scipy/pull/3701>`__: make 'a' and 'b' coefficients atleast_1d array in filtfilt
- `#3702 <https://github.com/scipy/scipy/pull/3702>`__: BUG: cluster: _vq unable to handle large features
- `#3704 <https://github.com/scipy/scipy/pull/3704>`__: BUG: special: ellip(k,e)inc nan and double expected value
- `#3707 <https://github.com/scipy/scipy/pull/3707>`__: BUG: handle fill_value dtype checks correctly in RegularGridInterpolator
- `#3708 <https://github.com/scipy/scipy/pull/3708>`__: Reraise exception on failure to read mat file.
- `#3709 <https://github.com/scipy/scipy/pull/3709>`__: BUG: cast 'x' to correct dtype in KroghInterpolator._evaluate
- `#3712 <https://github.com/scipy/scipy/pull/3712>`__: ENH: cluster: reimplement the update-step of K-means in Cython
- `#3713 <https://github.com/scipy/scipy/pull/3713>`__: FIX: Check type of lfiltic
- `#3718 <https://github.com/scipy/scipy/pull/3718>`__: Changed INSTALL file extension to rst
- `#3719 <https://github.com/scipy/scipy/pull/3719>`__: address svds returning nans for zero input matrix
- `#3722 <https://github.com/scipy/scipy/pull/3722>`__: MAINT: spatial: static, unused code, sqrt(sqeuclidean)
- `#3725 <https://github.com/scipy/scipy/pull/3725>`__: ENH: use numpys nanmedian if available
- `#3727 <https://github.com/scipy/scipy/pull/3727>`__: TST: add a new fixed_point test and change some test function...
- `#3731 <https://github.com/scipy/scipy/pull/3731>`__: BUG: fix romb in scipy.integrate.quadrature
- `#3734 <https://github.com/scipy/scipy/pull/3734>`__: DOC: simplify examples with semilogx
- `#3735 <https://github.com/scipy/scipy/pull/3735>`__: DOC: Add minimal docstrings to lti.impulse/step
- `#3736 <https://github.com/scipy/scipy/pull/3736>`__: BUG: cast pchip arguments to floats
- `#3744 <https://github.com/scipy/scipy/pull/3744>`__: stub out inherited methods of Akima1DInterpolator
- `#3746 <https://github.com/scipy/scipy/pull/3746>`__: DOC: Fix formatting for Raises section
- `#3748 <https://github.com/scipy/scipy/pull/3748>`__: ENH: Added discrete Lyapunov transformation solve
- `#3750 <https://github.com/scipy/scipy/pull/3750>`__: Enable automated testing with Python 3.4
- `#3751 <https://github.com/scipy/scipy/pull/3751>`__: Reverse Cuthill-McKee and Maximum Bipartite Matching reorderings...
- `#3759 <https://github.com/scipy/scipy/pull/3759>`__: MAINT: avoid indexing with a float array
- `#3762 <https://github.com/scipy/scipy/pull/3762>`__: TST: filter out RuntimeWarning in vq tests
- `#3766 <https://github.com/scipy/scipy/pull/3766>`__: TST: cluster: some cleanups in test_hierarchy.py
- `#3767 <https://github.com/scipy/scipy/pull/3767>`__: ENH/BUG: support negative m in elliptic integrals
- `#3769 <https://github.com/scipy/scipy/pull/3769>`__: ENH: avoid repeated matrix inverse
- `#3770 <https://github.com/scipy/scipy/pull/3770>`__: BUG: signal: In lfilter_zi, b was not rescaled correctly when...
- `#3772 <https://github.com/scipy/scipy/pull/3772>`__: STY avoid unnecessary transposes in csr_matrix.getcol/row
- `#3773 <https://github.com/scipy/scipy/pull/3773>`__: ENH: Add ext parameter to UnivariateSpline call
- `#3774 <https://github.com/scipy/scipy/pull/3774>`__: BUG: in integrate/quadpack.h, put all declarations before statements.
- `#3779 <https://github.com/scipy/scipy/pull/3779>`__: Incbet fix
- `#3788 <https://github.com/scipy/scipy/pull/3788>`__: BUG: Fix lombscargle ZeroDivisionError
- `#3791 <https://github.com/scipy/scipy/pull/3791>`__: Some maintenance for doc builds
- `#3795 <https://github.com/scipy/scipy/pull/3795>`__: scipy.special.legendre docstring
- `#3796 <https://github.com/scipy/scipy/pull/3796>`__: TYPO: sheroidal -> spheroidal
- `#3801 <https://github.com/scipy/scipy/pull/3801>`__: BUG: shortest_path overwrite
- `#3803 <https://github.com/scipy/scipy/pull/3803>`__: TST: lombscargle regression test related to atan vs atan2
- `#3809 <https://github.com/scipy/scipy/pull/3809>`__: ENH: orthogonal procrustes solver
- `#3811 <https://github.com/scipy/scipy/pull/3811>`__: ENH: scipy.special, Implemented Ellipsoidal harmonic function:...
- `#3819 <https://github.com/scipy/scipy/pull/3819>`__: BUG: make a fully connected csgraph from an ndarray with no zeros
- `#3820 <https://github.com/scipy/scipy/pull/3820>`__: MAINT: avoid spurious warnings in binom(n, p=0).mean() etc
- `#3825 <https://github.com/scipy/scipy/pull/3825>`__: Don't claim scipy.cluster does distance matrix calculations.
- `#3827 <https://github.com/scipy/scipy/pull/3827>`__: get and set diagonal of coo_matrix, and related csgraph laplacian...
- `#3832 <https://github.com/scipy/scipy/pull/3832>`__: DOC: Minor additions to integrate/nquad docstring.
- `#3845 <https://github.com/scipy/scipy/pull/3845>`__: Bug fix for #3842: Bug in scipy.optimize.line_search
- `#3848 <https://github.com/scipy/scipy/pull/3848>`__: BUG: edge case where the covariance matrix is exactly zero
- `#3850 <https://github.com/scipy/scipy/pull/3850>`__: DOC: typo
- `#3851 <https://github.com/scipy/scipy/pull/3851>`__: DOC: document default argument values for some arpack functions
- `#3860 <https://github.com/scipy/scipy/pull/3860>`__: DOC: sparse: add the function 'find' to the module-level docstring
- `#3861 <https://github.com/scipy/scipy/pull/3861>`__: BUG: Removed unnecessary storage of args as instance variables...
- `#3862 <https://github.com/scipy/scipy/pull/3862>`__: BUG: signal: fix handling of multi-output systems in ss2tf.
- `#3865 <https://github.com/scipy/scipy/pull/3865>`__: Feature request: ability to read heterogeneous types in FortranFile
- `#3866 <https://github.com/scipy/scipy/pull/3866>`__: MAINT: update pip wheelhouse for installs
- `#3871 <https://github.com/scipy/scipy/pull/3871>`__: MAINT: linalg: get rid of calc_lwork.f
- `#3872 <https://github.com/scipy/scipy/pull/3872>`__: MAINT: use scipy.linalg instead of np.dual
- `#3873 <https://github.com/scipy/scipy/pull/3873>`__: BLD: show a more informative message if Cython wasn't installed.
- `#3874 <https://github.com/scipy/scipy/pull/3874>`__: TST: cluster: cleanup the hierarchy test data
- `#3877 <https://github.com/scipy/scipy/pull/3877>`__: DOC: Savitzky-Golay filter version added
- `#3878 <https://github.com/scipy/scipy/pull/3878>`__: DOC: move versionadded to notes
- `#3879 <https://github.com/scipy/scipy/pull/3879>`__: small tweaks to the docs
- `#3881 <https://github.com/scipy/scipy/pull/3881>`__: FIX incorrect sorting during fancy assignment
- `#3885 <https://github.com/scipy/scipy/pull/3885>`__: kendalltau function now returns a nan tuple if empty arrays used...
- `#3886 <https://github.com/scipy/scipy/pull/3886>`__: BUG: fixing linprog's kwarg order to match docs
- `#3888 <https://github.com/scipy/scipy/pull/3888>`__: BUG: optimize: In _linprog_simplex, handle the case where the...
- `#3891 <https://github.com/scipy/scipy/pull/3891>`__: BUG: stats: Fix ValueError message in chi2_contingency.
- `#3892 <https://github.com/scipy/scipy/pull/3892>`__: DOC: sparse.linalg: Fix lobpcg docstring.
- `#3894 <https://github.com/scipy/scipy/pull/3894>`__: DOC: stats: Assorted docstring edits.
- `#3896 <https://github.com/scipy/scipy/pull/3896>`__: Fix 2 mistakes in MatrixMarket format parsing
- `#3897 <https://github.com/scipy/scipy/pull/3897>`__: BUG: associated Legendre function of second kind for 1<x<1.0001
- `#3899 <https://github.com/scipy/scipy/pull/3899>`__: BUG: fix undefined behavior in alngam
- `#3906 <https://github.com/scipy/scipy/pull/3906>`__: MAINT/DOC: Whitespace tweaks in several docstrings.
- `#3907 <https://github.com/scipy/scipy/pull/3907>`__: TST: relax bounds of interpolate test to accomodate rounding...
- `#3909 <https://github.com/scipy/scipy/pull/3909>`__: MAINT: Create a common version of `count_nonzero` for compatibility...
- `#3910 <https://github.com/scipy/scipy/pull/3910>`__: Fix a couple of test errors in master
- `#3911 <https://github.com/scipy/scipy/pull/3911>`__: Use MathJax for the html docs
- `#3914 <https://github.com/scipy/scipy/pull/3914>`__: Rework the _roots functions and document them.
- `#3916 <https://github.com/scipy/scipy/pull/3916>`__: Remove all linpack_lite code and replace with LAPACK routines
- `#3917 <https://github.com/scipy/scipy/pull/3917>`__: splines, constant extrapolation
- `#3918 <https://github.com/scipy/scipy/pull/3918>`__: DOC: tweak the rv_discrete docstring example
- `#3919 <https://github.com/scipy/scipy/pull/3919>`__: Quadrature speed-up: scipy.special.orthogonal.p_roots with cache
- `#3920 <https://github.com/scipy/scipy/pull/3920>`__: DOC: Clarify docstring for `sigma` parameter for `curve_fit`
- `#3922 <https://github.com/scipy/scipy/pull/3922>`__: Fixed Docstring issues in linprog (Fixes #3905).
- `#3924 <https://github.com/scipy/scipy/pull/3924>`__: Coerce args into tuple if necessary.
- `#3926 <https://github.com/scipy/scipy/pull/3926>`__: DOC: Surround stats class methods in docstrings with backticks.
- `#3927 <https://github.com/scipy/scipy/pull/3927>`__: Changed doc for romb's dx parameter to int.
- `#3928 <https://github.com/scipy/scipy/pull/3928>`__: check FITPACK conditions in LSQUnivariateSpline
- `#3929 <https://github.com/scipy/scipy/pull/3929>`__: Added a warning about leastsq using with NaNs.
- `#3930 <https://github.com/scipy/scipy/pull/3930>`__: ENH: optimize: curve_fit now warns if pcov is undetermined
- `#3932 <https://github.com/scipy/scipy/pull/3932>`__: Clarified the k > n case.
- `#3933 <https://github.com/scipy/scipy/pull/3933>`__: DOC: remove `import scipy as sp` abbreviation here and there
- `#3936 <https://github.com/scipy/scipy/pull/3936>`__: Add license and copyright holders to test data imported from...
- `#3938 <https://github.com/scipy/scipy/pull/3938>`__: DOC: Corrected documentation for return types.
- `#3939 <https://github.com/scipy/scipy/pull/3939>`__: DOC: fitpack: add a note about Sch-W conditions to splrep docstring
- `#3940 <https://github.com/scipy/scipy/pull/3940>`__: TST: integrate: Remove an invalid test of odeint.
- `#3942 <https://github.com/scipy/scipy/pull/3942>`__: FIX: Corrected error message of eigsh.
- `#3943 <https://github.com/scipy/scipy/pull/3943>`__: ENH: release GIL for filter and interpolation of ndimage
- `#3944 <https://github.com/scipy/scipy/pull/3944>`__: FIX: Raise value error if window data-type is unsupported
- `#3946 <https://github.com/scipy/scipy/pull/3946>`__: Fixed signal.get_window with unicode window name
- `#3947 <https://github.com/scipy/scipy/pull/3947>`__: MAINT: some docstring fixes and style cleanups in stats.mstats
- `#3949 <https://github.com/scipy/scipy/pull/3949>`__: DOC: fix a couple of issues in stats docstrings.
- `#3950 <https://github.com/scipy/scipy/pull/3950>`__: TST: sparse: remove known failure that doesn't fail
- `#3951 <https://github.com/scipy/scipy/pull/3951>`__: TST: switch from Rackspace wheelhouse to numpy/cython source...
- `#3952 <https://github.com/scipy/scipy/pull/3952>`__: DOC: stats: Small formatting correction to the 'chi' distribution...
- `#3953 <https://github.com/scipy/scipy/pull/3953>`__: DOC: stats: Several corrections and small additions to docstrings.
- `#3955 <https://github.com/scipy/scipy/pull/3955>`__: signal.__init__.py: remove duplicated `get_window` entry
- `#3959 <https://github.com/scipy/scipy/pull/3959>`__: TST: sparse: more "known failures" for DOK that don't fail
- `#3960 <https://github.com/scipy/scipy/pull/3960>`__: BUG: io.netcdf: do not close mmap if there are references left...
- `#3965 <https://github.com/scipy/scipy/pull/3965>`__: DOC: Fix a few more sphinx warnings that occur when building...
- `#3966 <https://github.com/scipy/scipy/pull/3966>`__: DOC: add guidelines for using test generators in HACKING
- `#3968 <https://github.com/scipy/scipy/pull/3968>`__: BUG: sparse.linalg: make Inv objects in arpack garbage-collectable...
- `#3971 <https://github.com/scipy/scipy/pull/3971>`__: Remove all linpack_lite code and replace with LAPACK routines
- `#3972 <https://github.com/scipy/scipy/pull/3972>`__: fix typo in error message
- `#3973 <https://github.com/scipy/scipy/pull/3973>`__: MAINT: better error message for multivariate normal.
- `#3981 <https://github.com/scipy/scipy/pull/3981>`__: turn the cryptically named scipy.special information theory functions...
- `#3984 <https://github.com/scipy/scipy/pull/3984>`__: Wrap her, syr, her2, syr2 blas routines
- `#3990 <https://github.com/scipy/scipy/pull/3990>`__: improve UnivariateSpline docs
- `#3991 <https://github.com/scipy/scipy/pull/3991>`__: ENH: stats: return namedtuple for describe output
- `#3993 <https://github.com/scipy/scipy/pull/3993>`__: DOC: stats: percentileofscore references np.percentile
- `#3997 <https://github.com/scipy/scipy/pull/3997>`__: BUG: linalg: pascal(35) was incorrect: last element overflowed...
- `#3998 <https://github.com/scipy/scipy/pull/3998>`__: MAINT: use isMaskedArray instead of is_masked to check type
- `#3999 <https://github.com/scipy/scipy/pull/3999>`__: TST: test against all of boost data files.
- `#4000 <https://github.com/scipy/scipy/pull/4000>`__: BUG: stats: Fix edge-case handling in a few distributions.
- `#4003 <https://github.com/scipy/scipy/pull/4003>`__: ENH: using python's warnings instead of prints in fitpack.
- `#4004 <https://github.com/scipy/scipy/pull/4004>`__: MAINT: optimize: remove a couple unused variables in zeros.c
- `#4006 <https://github.com/scipy/scipy/pull/4006>`__: BUG: Fix C90 compiler warnings in `NI_MinOrMaxFilter1D`
- `#4007 <https://github.com/scipy/scipy/pull/4007>`__: MAINT/DOC: Fix spelling of 'decomposition' in several files.
- `#4008 <https://github.com/scipy/scipy/pull/4008>`__: DOC: stats: Split the descriptions of the distributions in the...
- `#4015 <https://github.com/scipy/scipy/pull/4015>`__: TST: logsumexp regression test
- `#4016 <https://github.com/scipy/scipy/pull/4016>`__: MAINT: remove some inf-related warnings from logsumexp
- `#4020 <https://github.com/scipy/scipy/pull/4020>`__: DOC: stats: fix whitespace in docstrings of several distributions
- `#4023 <https://github.com/scipy/scipy/pull/4023>`__: Exactly one space required before assignments
- `#4024 <https://github.com/scipy/scipy/pull/4024>`__: In dendrogram(): Correct an argument name and a grammar issue...
- `#4041 <https://github.com/scipy/scipy/pull/4041>`__: BUG: misc: Ensure that the 'size' argument of PIL's 'resize'...
- `#4049 <https://github.com/scipy/scipy/pull/4049>`__: BUG: Return of _logpmf
- `#4051 <https://github.com/scipy/scipy/pull/4051>`__: BUG: expm of integer matrices
- `#4052 <https://github.com/scipy/scipy/pull/4052>`__: ENH: integrate: odeint: Handle exceptions in the callback functions.
- `#4053 <https://github.com/scipy/scipy/pull/4053>`__: BUG: stats: Refactor argument validation to avoid a unicode issue.
- `#4057 <https://github.com/scipy/scipy/pull/4057>`__: Added newline to scipy.sparse.linalg.svds documentation for correct...
- `#4058 <https://github.com/scipy/scipy/pull/4058>`__: MAINT: stats: Add note about change to scoreatpercentile in release...
- `#4059 <https://github.com/scipy/scipy/pull/4059>`__: ENH: interpolate: Allow splev to accept an n-dimensional array.
- `#4064 <https://github.com/scipy/scipy/pull/4064>`__: Documented the return value for scipy.signal.find_peaks_cwt
- `#4074 <https://github.com/scipy/scipy/pull/4074>`__: ENH: Support LinearOperator as input to svds
- `#4084 <https://github.com/scipy/scipy/pull/4084>`__: BUG: Match exception declarations in scipy/io/matlab/streams.pyx...
- `#4091 <https://github.com/scipy/scipy/pull/4091>`__: DOC: special: more clear instructions on how to evaluate polynomials
- `#4105 <https://github.com/scipy/scipy/pull/4105>`__: BUG: Workaround for SGEMV segfault in Accelerate
- `#4107 <https://github.com/scipy/scipy/pull/4107>`__: DOC: get rid of 'import \*' in examples
- `#4113 <https://github.com/scipy/scipy/pull/4113>`__: DOC: fix typos in distance.yule
- `#4114 <https://github.com/scipy/scipy/pull/4114>`__: MAINT C fixes
- `#4117 <https://github.com/scipy/scipy/pull/4117>`__: deprecate nanmean, nanmedian and nanstd in favor of their numpy...
- `#4126 <https://github.com/scipy/scipy/pull/4126>`__: scipy.io.idl: support description records and fix bug with null...
- `#4131 <https://github.com/scipy/scipy/pull/4131>`__: ENH: release GIL in more ndimage functions
- `#4132 <https://github.com/scipy/scipy/pull/4132>`__: MAINT: stats: fix a typo [skip ci]
- `#4145 <https://github.com/scipy/scipy/pull/4145>`__: DOC: Fix documentation error for nc chi-squared dist
- `#4150 <https://github.com/scipy/scipy/pull/4150>`__: Fix _nd_image.geometric_transform endianness bug
- `#4153 <https://github.com/scipy/scipy/pull/4153>`__: MAINT: remove use of deprecated numpy API in lib/lapack/ f2py...
- `#4156 <https://github.com/scipy/scipy/pull/4156>`__: MAINT: optimize: remove dead code
- `#4159 <https://github.com/scipy/scipy/pull/4159>`__: MAINT: optimize: clean up Zeros code
- `#4165 <https://github.com/scipy/scipy/pull/4165>`__: DOC: add missing special functions to __doc__
- `#4172 <https://github.com/scipy/scipy/pull/4172>`__: DOC: remove misleading procrustes docstring line
- `#4175 <https://github.com/scipy/scipy/pull/4175>`__: DOC: sparse: clarify CSC and CSR constructor usage
- `#4177 <https://github.com/scipy/scipy/pull/4177>`__: MAINT: enable np.matrix inputs to solve_discrete_lyapunov
- `#4179 <https://github.com/scipy/scipy/pull/4179>`__: TST: fix an intermittently failing test case for special.legendre
- `#4181 <https://github.com/scipy/scipy/pull/4181>`__: MAINT: remove unnecessary null checks before free
- `#4182 <https://github.com/scipy/scipy/pull/4182>`__: Ellipsoidal harmonics
- `#4183 <https://github.com/scipy/scipy/pull/4183>`__: Skip Cython build in Travis-CI
- `#4184 <https://github.com/scipy/scipy/pull/4184>`__: Pr 4074
- `#4187 <https://github.com/scipy/scipy/pull/4187>`__: Pr/3923
- `#4190 <https://github.com/scipy/scipy/pull/4190>`__: BUG: special: fix up ellip_harm build
- `#4193 <https://github.com/scipy/scipy/pull/4193>`__: BLD: fix msvc compiler errors
- `#4194 <https://github.com/scipy/scipy/pull/4194>`__: BUG: fix buffer dtype mismatch on win-amd64
- `#4199 <https://github.com/scipy/scipy/pull/4199>`__: ENH: Changed scipy.stats.describe output from datalen to nobs
- `#4201 <https://github.com/scipy/scipy/pull/4201>`__: DOC: add blas2 and nan* deprecations to the release notes
- `#4243 <https://github.com/scipy/scipy/pull/4243>`__: TST: bump test tolerances

==========================
SciPy 0.13.0 Release Notes
==========================

.. contents::

SciPy 0.13.0 is the culmination of 7 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.13.x branch, and on adding
new features on the master branch.

This release requires Python 2.6, 2.7 or 3.1-3.3 and NumPy 1.5.1 or greater.
Highlights of this release are:

  - support for fancy indexing and boolean comparisons with sparse matrices
  - interpolative decompositions and matrix functions in the linalg module
  - two new trust-region solvers for unconstrained minimization


New features
============

``scipy.integrate`` improvements
--------------------------------

N-dimensional numerical integration
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A new function `scipy.integrate.nquad`, which provides N-dimensional
integration functionality with a more flexible interface than ``dblquad`` and
``tplquad``, has been added.

``dopri*`` improvements
^^^^^^^^^^^^^^^^^^^^^^^

The intermediate results from the ``dopri`` family of ODE solvers can now be
accessed by a *solout* callback function.


``scipy.linalg`` improvements
-----------------------------

Interpolative decompositions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Scipy now includes a new module `scipy.linalg.interpolative`
containing routines for computing interpolative matrix decompositions
(ID). This feature is based on the ID software package by
P.G. Martinsson, V. Rokhlin, Y. Shkolnisky, and M. Tygert, previously
adapted for Python in the PymatrixId package by K.L. Ho.

Polar decomposition
^^^^^^^^^^^^^^^^^^^

A new function `scipy.linalg.polar`, to compute the polar decomposition
of a matrix, was added.

BLAS level 3 functions
^^^^^^^^^^^^^^^^^^^^^^

The BLAS functions ``symm``, ``syrk``, ``syr2k``, ``hemm``, ``herk`` and
``her2k`` are now wrapped in `scipy.linalg`.

Matrix functions
^^^^^^^^^^^^^^^^

Several matrix function algorithms have been implemented or updated following
detailed descriptions in recent papers of Nick Higham and his co-authors.
These include the matrix square root (``sqrtm``), the matrix logarithm
(``logm``), the matrix exponential (``expm``) and its Frechet derivative
(``expm_frechet``), and fractional matrix powers (``fractional_matrix_power``).


``scipy.optimize`` improvements
-------------------------------

Trust-region unconstrained minimization algorithms
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The ``minimize`` function gained two trust-region solvers for unconstrained
minimization: ``dogleg`` and ``trust-ncg``.


``scipy.sparse`` improvements
-----------------------------

Boolean comparisons and sparse matrices
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

All sparse matrix types now support boolean data, and boolean operations.  Two
sparse matrices `A` and `B` can be compared in all the expected ways `A < B`,
`A >= B`, `A != B`, producing similar results as dense Numpy arrays.
Comparisons with dense matrices and scalars are also supported.

CSR and CSC fancy indexing
^^^^^^^^^^^^^^^^^^^^^^^^^^

Compressed sparse row and column sparse matrix types now support fancy indexing
with boolean matrices, slices, and lists. So where A is a (CSC or CSR) sparse
matrix, you can do things like::

    >>> A[A > 0.5] = 1  # since Boolean sparse matrices work
    >>> A[:2, :3] = 2
    >>> A[[1,2], 2] = 3


``scipy.sparse.linalg`` improvements
------------------------------------

The new function ``onenormest`` provides a lower bound of the 1-norm of a
linear operator and has been implemented according to Higham and Tisseur
(2000).  This function is not only useful for sparse matrices, but can also be
used to estimate the norm of products or powers of dense matrices without
explicitly building the intermediate matrix.

The multiplicative action of the matrix exponential of a linear operator
(``expm_multiply``) has been implemented following the description in Al-Mohy
and Higham (2011).

Abstract linear operators (`scipy.sparse.linalg.LinearOperator`) can now be
multiplied, added to each other, and exponentiated, producing new linear
operators. This enables easier construction of composite linear operations.


``scipy.spatial`` improvements
------------------------------

The vertices of a `ConvexHull` can now be accessed via the `vertices` attribute,
which gives proper orientation in 2-D.


``scipy.signal`` improvements
-----------------------------

The cosine window function ``scipy.signal.cosine`` was added.


``scipy.special`` improvements
------------------------------

New functions `scipy.special.xlogy` and `scipy.special.xlog1py` were added.
These functions can simplify and speed up code that has to calculate
``x * log(y)`` and give 0 when ``x == 0``.


``scipy.io`` improvements
-------------------------

Unformatted Fortran file reader
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The new class `scipy.io.FortranFile` facilitates reading unformatted
sequential files written by Fortran code.

``scipy.io.wavfile`` enhancements
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

`scipy.io.wavfile.write` now accepts a file buffer. Previously it only
accepted a filename.

`scipy.io.wavfile.read` and `scipy.io.wavfile.write` can now handle floating
point WAV files.


``scipy.interpolate`` improvements
----------------------------------

B-spline derivatives and antiderivatives
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

`scipy.interpolate.splder` and `scipy.interpolate.splantider` functions
for computing B-splines that represent derivatives and antiderivatives
of B-splines were added.  These functions are also available in the
class-based FITPACK interface as ``UnivariateSpline.derivative`` and
``UnivariateSpline.antiderivative``.


``scipy.stats`` improvements
----------------------------

Distributions now allow using keyword parameters in addition to
positional parameters in all methods.

The function `scipy.stats.power_divergence` has been added for the
Cressie-Read power divergence statistic and goodness of fit test.
Included in this family of statistics is the "G-test"
(https://en.wikipedia.org/wiki/G-test).

`scipy.stats.mood` now accepts multidimensional input.

An option was added to `scipy.stats.wilcoxon` for continuity correction.

`scipy.stats.chisquare` now has an `axis` argument.

`scipy.stats.mstats.chisquare` now has `axis` and `ddof` arguments.


Deprecated features
===================

``expm2`` and ``expm3``
-----------------------

The matrix exponential functions `scipy.linalg.expm2` and `scipy.linalg.expm3`
are deprecated. All users should use the numerically more robust
`scipy.linalg.expm` function instead.

``scipy.stats`` functions
-------------------------

`scipy.stats.oneway` is deprecated; `scipy.stats.f_oneway` should be used
instead.

`scipy.stats.glm` is deprecated.  `scipy.stats.ttest_ind` is an equivalent
function; more full-featured general (and generalized) linear model
implementations can be found in statsmodels.

`scipy.stats.cmedian` is deprecated; ``numpy.median`` should be used instead.


Backwards incompatible changes
==============================

LIL matrix assignment
---------------------
Assigning values to LIL matrices with two index arrays now works similarly as
assigning into ndarrays::

    >>> x = lil_matrix((3, 3))
    >>> x[[0,1,2],[0,1,2]]=[0,1,2]
    >>> x.todense()
    matrix([[ 0.,  0.,  0.],
            [ 0.,  1.,  0.],
            [ 0.,  0.,  2.]])

rather than giving the result::

    >>> x.todense()
    matrix([[ 0.,  1.,  2.],
            [ 0.,  1.,  2.],
            [ 0.,  1.,  2.]])

Users relying on the previous behavior will need to revisit their code.
The previous behavior is obtained by ``x[numpy.ix_([0,1,2],[0,1,2])] = ...``.


Deprecated ``radon`` function removed
-------------------------------------

The ``misc.radon`` function, which was deprecated in scipy 0.11.0, has been
removed.  Users can find a more full-featured ``radon`` function in
scikit-image.


Removed deprecated keywords ``xa`` and ``xb`` from ``stats.distributions``
--------------------------------------------------------------------------

The keywords ``xa`` and ``xb``, which were deprecated since 0.11.0, have
been removed from the distributions in ``scipy.stats``.

Changes to MATLAB file readers / writers
----------------------------------------

The major change is that 1D arrays in numpy now become row vectors (shape 1, N)
when saved to a MATLAB 5 format file.  Previously 1D arrays saved as column
vectors (N, 1).  This is to harmonize the behavior of writing MATLAB 4 and 5
formats, and adapt to the defaults of numpy and MATLAB - for example
``np.atleast_2d`` returns 1D arrays as row vectors.

Trying to save arrays of greater than 2 dimensions in MATLAB 4 format now raises
an error instead of silently reshaping the array as 2D.

``scipy.io.loadmat('afile')`` used to look for `afile` on the Python system path
(``sys.path``); now ``loadmat`` only looks in the current directory for a
relative path filename.


Other changes
=============

Security fix: ``scipy.weave`` previously used temporary directories in an
insecure manner under certain circumstances.

Cython is now required to build *unreleased* versions of scipy.
The C files generated from Cython sources are not included in the git repo
anymore.  They are however still shipped in source releases.

The code base received a fairly large PEP8 cleanup.  A ``tox pep8``
command has been added; new code should pass this test command.

Scipy cannot be compiled with gfortran 4.1 anymore (at least on RH5), likely
due to that compiler version not supporting entry constructs well.


Authors
=======

This release contains work by the following people (contributed at least
one patch to this release, names in alphabetical order):

* Jorge Cañardo Alastuey +
* Tom Aldcroft +
* Max Bolingbroke +
* Joseph Jon Booker +
* François Boulogne
* Matthew Brett
* Christian Brodbeck +
* Per Brodtkorb +
* Christian Brueffer +
* Lars Buitinck
* Evgeni Burovski +
* Tim Cera
* Lawrence Chan +
* David Cournapeau
* Dražen Lučanin +
* Alexander J. Dunlap +
* endolith
* André Gaul +
* Christoph Gohlke
* Ralf Gommers
* Alex Griffing +
* Blake Griffith +
* Charles Harris
* Bob Helmbold +
* Andreas Hilboll
* Kat Huang +
* Oleksandr (Sasha) Huziy +
* Gert-Ludwig Ingold +
* Thouis (Ray) Jones
* Juan Luis Cano Rodríguez +
* Robert Kern
* Andreas Kloeckner +
* Sytse Knypstra +
* Gustav Larsson +
* Denis Laxalde
* Christopher Lee
* Tim Leslie
* Wendy Liu +
* Clemens Novak +
* Takuya Oshima +
* Josef Perktold
* Illia Polosukhin +
* Przemek Porebski +
* Steve Richardson +
* Branden Rolston +
* Skipper Seabold
* Fazlul Shahriar
* Leo Singer +
* Rohit Sivaprasad +
* Daniel B. Smith +
* Julian Taylor
* Louis Thibault +
* Tomas Tomecek +
* John Travers
* Richard Tsai +
* Jacob Vanderplas
* Patrick Varilly
* Pauli Virtanen
* Stefan van der Walt
* Warren Weckesser
* Pedro Werneck +
* Nils Werner +
* Michael Wimmer +
* Nathan Woods +
* Tony S. Yu +

A total of 65 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.

==========================
SciPy 1.4.1 Release Notes
==========================

.. contents::

SciPy 1.4.1 is a bug-fix release with no new features
compared to 1.4.0. Importantly, it aims to fix a problem
where an older version of pybind11 may cause a segmentation
fault when imported alongside incompatible libraries.

Authors
=======

* Ralf Gommers
* Tyler Reddy

Issues closed for 1.4.1
-----------------------

* `#11237 <https://github.com/scipy/scipy/issues/11237>`__: Seg fault when importing torch

Pull requests for 1.4.1
-----------------------

* `#11238 <https://github.com/scipy/scipy/pull/11238>`__: BLD: update minimum pybind11 version to 2.4.0.
==========================
SciPy 0.12.1 Release Notes
==========================

SciPy 0.12.1 is a bug-fix release with no new features compared to 0.12.0.
The single issue fixed by this release is a security issue in ``scipy.weave``,
which was previously using temporary directories in an insecure manner under 
certain circumstances.
==========================
SciPy 1.6.1 Release Notes
==========================

.. contents::

SciPy 1.6.1 is a bug-fix release with no new features
compared to 1.6.0.

Please note that for SciPy wheels to correctly install with Pip on
macOS 11, Pip >= 20.3.3 is needed.


Authors
=======

* Peter Bell
* Evgeni Burovski
* CJ Carey
* Ralf Gommers
* Peter Mahler Larsen
* Cheng H. Lee +
* Cong Ma
* Nicholas McKibben
* Nikola Forró
* Tyler Reddy
* Warren Weckesser

A total of 11 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.6.1
-----------------------

* `#13072 <https://github.com/scipy/scipy/issues/13072>`__: BLD: Quadpack undefined references
* `#13241 <https://github.com/scipy/scipy/issues/13241>`__: Not enough values to unpack when passing tuple to \`blocksize\`...
* `#13329 <https://github.com/scipy/scipy/issues/13329>`__: Large sparse matrices of big integers lose information
* `#13342 <https://github.com/scipy/scipy/issues/13342>`__: fftn crashes if shape arguments are supplied as ndarrays
* `#13356 <https://github.com/scipy/scipy/issues/13356>`__: LSQBivariateSpline segmentation fault when quitting the Python...
* `#13358 <https://github.com/scipy/scipy/issues/13358>`__: scipy.spatial.transform.Rotation object can not be deepcopied...
* `#13408 <https://github.com/scipy/scipy/issues/13408>`__: Type of \`has_sorted_indices\` property
* `#13412 <https://github.com/scipy/scipy/issues/13412>`__: Sorting spherical Voronoi vertices leads to crash in area calculation
* `#13421 <https://github.com/scipy/scipy/issues/13421>`__: linear_sum_assignment - support for matrices with more than 2^31...
* `#13428 <https://github.com/scipy/scipy/issues/13428>`__: \`stats.exponnorm.cdf\` returns \`nan\` for small values of \`K\`...
* `#13465 <https://github.com/scipy/scipy/issues/13465>`__: KDTree.count_neighbors : 0xC0000005 error for tuple of different...
* `#13468 <https://github.com/scipy/scipy/issues/13468>`__: directed_hausdorff issue with shuffle
* `#13472 <https://github.com/scipy/scipy/issues/13472>`__: Failures on FutureWarnings with numpy 1.20.0 for lfilter, sosfilt...
* `#13565 <https://github.com/scipy/scipy/issues/13565>`__: BUG: 32-bit wheels repo test failure in optimize

Pull requests for 1.6.1
-----------------------

* `#13318 <https://github.com/scipy/scipy/pull/13318>`__: REL: prepare for SciPy 1.6.1
* `#13344 <https://github.com/scipy/scipy/pull/13344>`__: BUG: fftpack doesn't work with ndarray shape argument
* `#13345 <https://github.com/scipy/scipy/pull/13345>`__: MAINT: Replace scipy.take with numpy.take in FFT function docstrings.
* `#13354 <https://github.com/scipy/scipy/pull/13354>`__: BUG: optimize: rename private functions to include leading underscore
* `#13387 <https://github.com/scipy/scipy/pull/13387>`__: BUG: Support big-endian platforms and big-endian WAVs
* `#13394 <https://github.com/scipy/scipy/pull/13394>`__: BUG: Fix Python crash by allocating larger array in LSQBivariateSpline
* `#13400 <https://github.com/scipy/scipy/pull/13400>`__: BUG: sparse: Better validation for BSR ctor
* `#13403 <https://github.com/scipy/scipy/pull/13403>`__: BUG: sparse: Propagate dtype through CSR/CSC constructors
* `#13414 <https://github.com/scipy/scipy/pull/13414>`__: BUG: maintain dtype of SphericalVoronoi regions
* `#13422 <https://github.com/scipy/scipy/pull/13422>`__: FIX: optimize: use npy_intp to store array dims for lsap
* `#13425 <https://github.com/scipy/scipy/pull/13425>`__: BUG: spatial: make Rotation picklable
* `#13426 <https://github.com/scipy/scipy/pull/13426>`__: BUG: \`has_sorted_indices\` and \`has_canonical_format\` should...
* `#13430 <https://github.com/scipy/scipy/pull/13430>`__: BUG: stats: Fix exponnorm.cdf and exponnorm.sf for small K
* `#13470 <https://github.com/scipy/scipy/pull/13470>`__: MAINT: silence warning generated by \`spatial.directed_hausdorff\`
* `#13473 <https://github.com/scipy/scipy/pull/13473>`__: TST: fix failures due to new FutureWarnings in NumPy 1.21.dev0
* `#13479 <https://github.com/scipy/scipy/pull/13479>`__: MAINT: update directed_hausdorff Cython code
* `#13485 <https://github.com/scipy/scipy/pull/13485>`__: BUG: KDTree weighted count_neighbors doesn't work between two...
* `#13503 <https://github.com/scipy/scipy/pull/13503>`__: TST: fix \`test_fortranfile_read_mixed_record\` on big-endian...
* `#13518 <https://github.com/scipy/scipy/pull/13518>`__: DOC: document that pip >= 20.3.3 is needed for macOS 11
* `#13520 <https://github.com/scipy/scipy/pull/13520>`__: BLD: update reqs based on oldest-supported-numpy in pyproject.toml
* `#13567 <https://github.com/scipy/scipy/pull/13567>`__: TST, BUG: adjust tol on test_equivalence
==========================
SciPy 0.10.1 Release Notes
==========================

.. contents::

SciPy 0.10.1 is a bug-fix release with no new features compared to 0.10.0.  

Main changes
------------

The most important changes are:

1. The single precision routines of ``eigs`` and ``eigsh`` in
   ``scipy.sparse.linalg`` have been disabled (they internally use double
   precision now).
2. A compatibility issue related to changes in NumPy macros has been fixed, in
   order to make scipy 0.10.1 compile with the upcoming numpy 1.7.0 release.


Other issues fixed
------------------

- #835: stats: nan propagation in stats.distributions
- #1202: io: netcdf segfault
- #1531: optimize: make curve_fit work with method as callable.
- #1560: linalg: fixed mistake in eig_banded documentation.
- #1565: ndimage: bug in ndimage.variance
- #1457: ndimage: standard_deviation does not work with sequence of indexes
- #1562: cluster: segfault in linkage function
- #1568: stats: One-sided fisher_exact() returns `p` < 1 for 0 successful attempts
- #1575: stats: zscore and zmap handle the axis keyword incorrectly

==========================
SciPy 0.19.1 Release Notes
==========================

SciPy 0.19.1 is a bug-fix release with no new features compared to 0.19.0.
The most important change is a fix for a severe memory leak in
``integrate.quad``.


Authors
=======

* Evgeni Burovski
* Patrick Callier +
* Yu Feng
* Ralf Gommers
* Ilhan Polat
* Eric Quintero
* Scott Sievert
* Pauli Virtanen
* Warren Weckesser

A total of 9 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 0.19.1
------------------------

- `#7214 <https://github.com/scipy/scipy/issues/7214>`__: Memory use in integrate.quad in scipy-0.19.0
- `#7258 <https://github.com/scipy/scipy/issues/7258>`__: ``linalg.matrix_balance`` gives wrong transformation matrix
- `#7262 <https://github.com/scipy/scipy/issues/7262>`__: Segfault in daily testing
- `#7273 <https://github.com/scipy/scipy/issues/7273>`__: ``scipy.interpolate._bspl.evaluate_spline`` gets wrong type
- `#7335 <https://github.com/scipy/scipy/issues/7335>`__: scipy.signal.dlti(A,B,C,D).freqresp() fails


Pull requests for 0.19.1
------------------------

- `#7211 <https://github.com/scipy/scipy/pull/7211>`__: BUG: convolve may yield inconsistent dtypes with method changed
- `#7216 <https://github.com/scipy/scipy/pull/7216>`__: BUG: integrate: fix refcounting bug in quad()
- `#7229 <https://github.com/scipy/scipy/pull/7229>`__: MAINT: special: Rewrite a test of wrightomega
- `#7261 <https://github.com/scipy/scipy/pull/7261>`__: FIX: Corrected the transformation matrix permutation
- `#7265 <https://github.com/scipy/scipy/pull/7265>`__: BUG: Fix broken axis handling in spectral functions
- `#7266 <https://github.com/scipy/scipy/pull/7266>`__: FIX 7262: ckdtree crashes in query_knn.
- `#7279 <https://github.com/scipy/scipy/pull/7279>`__: Upcast half- and single-precision floats to doubles in BSpline...
- `#7336 <https://github.com/scipy/scipy/pull/7336>`__: BUG: Fix signal.dfreqresp for StateSpace systems
- `#7419 <https://github.com/scipy/scipy/pull/7419>`__: Fix several issues in ``sparse.load_npz``, ``save_npz``
- `#7420 <https://github.com/scipy/scipy/pull/7420>`__: BUG: stats: allow integers as kappa4 shape parameters

==========================
SciPy 1.3.2 Release Notes
==========================

.. contents::

SciPy 1.3.2 is a bug-fix and maintenance release that adds
support for Python 3.8.

Authors
=======

* CJ Carey
* Dany Vohl
* Martin Gauch +
* Ralf Gommers
* Matt Haberland
* Eric Larson
* Nikolay Mayorov
* Sam McCormack +
* Andrew Nelson
* Tyler Reddy
* Pauli Virtanen
* Huize Wang +
* Warren Weckesser
* Joseph Weston +

A total of 14 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.3.2
-----------------------

* `#4915 <https://github.com/scipy/scipy/issues/4915>`__: Bug in unique_roots in scipy.signal.signaltools.py for roots...
* `#5161 <https://github.com/scipy/scipy/issues/5161>`__: Optimizers reporting success when the minimum is NaN
* `#5546 <https://github.com/scipy/scipy/issues/5546>`__: ValueError raised if scipy.sparse.linalg.expm recieves array...
* `#10124 <https://github.com/scipy/scipy/issues/10124>`__: linprog(method='revised simplex') doctest bug
* `#10609 <https://github.com/scipy/scipy/issues/10609>`__: Graph shortest path with Floyd-Warshall removes explicit zeros.
* `#10658 <https://github.com/scipy/scipy/issues/10658>`__: BUG: stats: Formula for the variance of the noncentral F distribution...
* `#10695 <https://github.com/scipy/scipy/issues/10695>`__: BUG: Assignation issues in csr_matrix with fancy indexing
* `#10846 <https://github.com/scipy/scipy/issues/10846>`__: root_scalar fails when passed a function wrapped with functools.lru_cache
* `#10902 <https://github.com/scipy/scipy/issues/10902>`__: CI: travis osx build failure
* `#10967 <https://github.com/scipy/scipy/issues/10967>`__: macOS build failure in SuperLU on maintenance/1.3.x
* `#10976 <https://github.com/scipy/scipy/issues/10976>`__: Typo in sp.stats.wilcoxon docstring


Pull requests for 1.3.2
-----------------------

* `#10498 <https://github.com/scipy/scipy/pull/10498>`__: TST: optimize: fixed \`linprog\` \`"disp": True\` bug
* `#10536 <https://github.com/scipy/scipy/pull/10536>`__: CI: add 3.8-dev to travis
* `#10671 <https://github.com/scipy/scipy/pull/10671>`__: BUG: stats: Fix the formula for the variance of the noncentral...
* `#10693 <https://github.com/scipy/scipy/pull/10693>`__: BUG: ScalarFunction stores original array
* `#10700 <https://github.com/scipy/scipy/pull/10700>`__: BUG: sparse: Loosen checks on sparse fancy assignment
* `#10709 <https://github.com/scipy/scipy/pull/10709>`__: BUG: Fix floyd_warshall to support zero-weight edges
* `#10756 <https://github.com/scipy/scipy/pull/10756>`__: BUG: optimize: ensure solvers exit with success=False for nan...
* `#10833 <https://github.com/scipy/scipy/pull/10833>`__: BUG: Fix subspace_angles for complex values
* `#10882 <https://github.com/scipy/scipy/pull/10882>`__: BUG: sparse/arpack: fix incorrect code for complex hermitian...
* `#10891 <https://github.com/scipy/scipy/pull/10891>`__: BUG: make C-implemented root finders work with functools.lru_cache
* `#10906 <https://github.com/scipy/scipy/pull/10906>`__: BUG: sparse/linalg: fix expm for np.matrix inputs
* `#10917 <https://github.com/scipy/scipy/pull/10917>`__: CI: fix travis osx CI
* `#10930 <https://github.com/scipy/scipy/pull/10930>`__: MAINT: Updates for 3.8
* `#10938 <https://github.com/scipy/scipy/pull/10938>`__: MAINT: Add Python 3.8 to pyproject.toml
* `#10943 <https://github.com/scipy/scipy/pull/10943>`__: BLD: update Cython version to 0.29.13
* `#10961 <https://github.com/scipy/scipy/pull/10961>`__: BUG: Fix signal.unique_roots
* `#10971 <https://github.com/scipy/scipy/pull/10971>`__: MAINT: use 3.8 stable in CI
* `#10977 <https://github.com/scipy/scipy/pull/10977>`__: DOC: Fix typo in sp.stats.wilcoxon docsting
* `#11025 <https://github.com/scipy/scipy/pull/11025>`__: Update _peak_finding.py
=========================
SciPy 0.7.1 Release Notes
=========================

.. contents::

SciPy 0.7.1 is a bug-fix release with no new features compared to 0.7.0.

scipy.io
========

Bugs fixed:

- Several fixes in Matlab file IO

scipy.odr
=========

Bugs fixed:

- Work around a failure with Python 2.6

scipy.signal
============

Memory leak in lfilter have been fixed, as well as support for array object

Bugs fixed:

- #880, #925: lfilter fixes
- #871: bicgstab fails on Win32


scipy.sparse
============

Bugs fixed:

- #883: scipy.io.mmread with scipy.sparse.lil_matrix broken
- lil_matrix and csc_matrix reject now unexpected sequences,
  cf. http://thread.gmane.org/gmane.comp.python.scientific.user/19996 (dead link)

scipy.special
=============

Several bugs of varying severity were fixed in the special functions:

- #503, #640: iv: problems at large arguments fixed by new implementation
- #623: jv: fix errors at large arguments
- #679: struve: fix wrong output for v < 0
- #803: pbdv produces invalid output
- #804: lqmn: fix crashes on some input
- #823: betainc: fix documentation
- #834: exp1 strange behavior near negative integer values
- #852: jn_zeros: more accurate results for large s, also in jnp/yn/ynp_zeros
- #853: jv, yv, iv: invalid results for non-integer v < 0, complex x
- #854: jv, yv, iv, kv: return nan more consistently when out-of-domain
- #927: ellipj: fix segfault on Windows
- #946: ellpj: fix segfault on Mac OS X/python 2.6 combination.
- ive, jve, yve, kv, kve: with real-valued input, return nan for out-of-domain
  instead of returning only the real part of the result.

Also, when ``scipy.special.errprint(1)`` has been enabled, warning
messages are now issued as Python warnings instead of printing them to
stderr.


scipy.stats
===========

- linregress, mannwhitneyu, describe: errors fixed
- kstwobign, norm, expon, exponweib, exponpow, frechet, genexpon, rdist,
  truncexpon, planck: improvements to numerical accuracy in distributions

Windows binaries for python 2.6
===============================

python 2.6 binaries for windows are now included. The binary for python 2.5
requires numpy 1.2.0 or above, and the one for python 2.6 requires numpy
1.3.0 or above.

Universal build for scipy
=========================

Mac OS X binary installer is now a proper universal build, and does not depend
on gfortran anymore (libgfortran is statically linked). The python 2.5 version
of scipy requires numpy 1.2.0 or above, the python 2.6 version requires numpy
1.3.0 or above.
=========================
SciPy 1.8.0 Release Notes
=========================

.. note:: Scipy 1.8.0 is not released yet!

.. contents::

SciPy 1.8.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been a number of deprecations and API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning`` s).
Our development attention will now shift to bug-fix releases on the
1.8.x branch, and on adding new features on the master branch.

This release requires Python 3.8+ and NumPy 1.17.3 or greater.

For running on PyPy, PyPy3 6.0+ is required.


**************************
Highlights of this release
**************************

- A sparse array API has been added for early testing and feedback; users
  may expect backwards compatibility changes in future releases
- The sparse SVD library PROPACK is now vendored with SciPy, and an interface
  is exposed via `scipy.sparse.svds` with ``solver='PROPACK'``.
- A new `scipy.stats.sampling` submodule that leverages the ``UNU.RAN`` C
  library to sample from arbitrary univariate non-uniform continuous and
  discrete distributions
- All namespaces that were private but happened to miss underscores in
  their names have been deprecated.


************
New features
************

`scipy.fft` improvements
========================

Added an ``orthogonalize=None`` parameter to the real transforms in `scipy.fft`
which controls whether the modified definition of DCT/DST is used without
changing the overall scaling.

`scipy.fft` backend registration is now smoother, operating with a single
registration call and no longer requiring a context manager.

`scipy.integrate` improvements
==============================

`scipy.integrate.quad_vec` introduces a new optional keyword-only argument,
``args``. ``args`` takes in a tuple of extra arguments if any (default is
``args=()``), which is then internally used to pass into the callable function
(needing these extra arguments) which we wish to integrate.

`scipy.interpolate` improvements
================================

`scipy.interpolate.BSpline` has a new method, ``design_matrix``, which
constructs a design matrix of b-splines in the sparse CSR format.

A new method ``from_cubic`` in ``BSpline`` class allows to convert a
``CubicSpline`` object to ``BSpline`` object.

`scipy.linalg` improvements
===========================

`scipy.linalg` gained three new public array structure investigation functions.
`scipy.linalg.bandwidth` returns information about the bandedness of an array
and can be used to test for triangular structure discovery, while
`scipy.linalg.issymmetric` and `scipy.linalg.ishermitian` test the array for
exact and approximate symmetric/Hermitian structure.

`scipy.optimize` improvements
=============================

`scipy.optimize.check_grad` introduces two new optional keyword only arguments,
``direction`` and ``seed``. ``direction`` can take values, ``'all'`` (default),
in which case all the one hot direction vectors will be used for verifying
the input analytical gradient function and ``'random'``, in which case a
random direction vector will be used for the same purpose. ``seed``
(default is ``None``) can be used for reproducing the return value of
``check_grad`` function. It will be used only when ``direction='random'``.

The `scipy.optimize.minimize` ``TNC`` method has been rewritten to use Cython
bindings. This also fixes an issue with the callback altering the state of the
optimization.

Added optional parameters ``target_accept_rate`` and ``stepwise_factor`` for
adapative step size adjustment in ``basinhopping``.

The ``epsilon`` argument to ``approx_fprime`` is now optional so that it may
have a default value consistent with most other functions in `scipy.optimize`.

`scipy.signal` improvements
===========================

Add ``analog`` argument, default ``False``, to ``zpk2sos``, and add new pairing
option ``'minimal'`` to construct analog and minimal discrete SOS arrays.
``tf2sos`` uses zpk2sos; add ``analog`` argument here as well, and pass it on
to ``zpk2sos``.

``savgol_coeffs`` and ``savgol_filter`` now work for even window lengths.

Added the Chirp Z-transform and Zoom FFT available as `scipy.signal.CZT` and
`scipy.signal.ZoomFFT`.

`scipy.sparse` improvements
===========================

An array API has been added for early testing and feedback. This work is
ongoing, and users may expect backwards compatibility changes in
future releases. Please refer to the `scipy.sparse`
docstring for more information.

``maximum_flow`` introduces optional keyword only argument, ``method``
which accepts either, ``'edmonds-karp'`` (Edmonds Karp algorithm) or
``'dinic'`` (Dinic's algorithm). Moreover, ``'dinic'`` is used as default
value for ``method`` which means that Dinic's algorithm is used for computing
maximum flow unless specified. See, the comparison between the supported
algorithms in
`this comment <https://github.com/scipy/scipy/pull/14358#issue-684212523>`_.

Parameters ``atol``, ``btol`` now default to 1e-6 in
`scipy.sparse.linalg.lsmr` to match with default values in
`scipy.sparse.linalg.lsqr`.

Add the Transpose-Free Quasi-Minimal Residual algorithm (TFQMR) for general
nonsingular non-Hermitian linear systems in `scipy.sparse.linalg.tfqmr`.

The sparse SVD library PROPACK is now vendored with SciPy, and an interface is
exposed via `scipy.sparse.svds` with ``solver='PROPACK'``. For some problems,
this may be faster and/or more accurate than the default, ARPACK.

``sparse.linalg`` iterative solvers now have a nonzero initial guess option,
which may be specified as ``x0 = 'Mb'``.

The ``trace`` method has been added for sparse matrices.

`scipy.spatial` improvements
============================

`scipy.spatial.transform.Rotation` now supports item assignment and has a new
``concatenate`` method.

Add `scipy.spatial.distance.kulczynski1` in favour of
`scipy.spatial.distance.kulsinski` which will be deprecated in the next
release.

`scipy.spatial.distance.minkowski` now also supports ``0<p<1``.

`scipy.special` improvements
============================

The new function `scipy.special.log_expit` computes the logarithm of the
logistic sigmoid function. The function is formulated to provide accurate
results for large positive and negative inputs, so it avoids the problems
that would occur in the naive implementation ``log(expit(x))``.

A suite of five new functions for elliptic integrals:
``scipy.special.ellipr{c,d,f,g,j}``. These are the
`Carlson symmetric elliptic integrals <https://dlmf.nist.gov/19.16>`_, which
have computational advantages over the classical Legendre integrals. Previous
versions included some elliptic integrals from the Cephes library
(``scipy.special.ellip{k,km1,kinc,e,einc}``) but was missing the integral of
third kind (Legendre's Pi), which can be evaluated using the new Carlson
functions. The new Carlson elliptic integral functions can be evaluated in the
complex plane, whereas the Cephes library's functions are only defined for
real inputs.

Several defects in `scipy.special.hyp2f1` have been corrected. Approximately
correct values are now returned for ``z`` near ``exp(+-i*pi/3)``, fixing
`#8054 <https://github.com/scipy/scipy/issues/8054>`_. Evaluation for such ``z``
is now calculated through a series derived by
`López and Temme (2013) <https://arxiv.org/abs/1306.2046>`_ that converges in
these regions. In addition, degenerate cases with one or more of ``a``, ``b``,
and/or ``c`` a non-positive integer are now handled in a manner consistent with
`mpmath's hyp2f1 implementation <https://mpmath.org/doc/current/functions/hypergeometric.html>`_,
which fixes `#7340 <https://github.com/scipy/scipy/issues/7340>`_. These fixes
were made as part of an effort to rewrite the Fortran 77 implementation of
hyp2f1 in Cython piece by piece. This rewriting is now roughly 50% complete.

`scipy.stats` improvements
==========================

`scipy.stats.qmc.LatinHypercube` introduces two new optional keyword-only
arguments, ``optimization`` and ``strength``. ``optimization`` is either
``None`` or ``random-cd``. In the latter, random permutations are performed to
improve the centered discrepancy. ``strength`` is either 1 or 2. 1 corresponds
to the classical LHS while 2 has better sub-projection properties. This
construction is referred to as an orthogonal array based LHS of strength 2.
In both cases, the output is still a LHS.

`scipy.stats.qmc.Halton` is faster as the underlying Van der Corput sequence
was ported to Cython.

The ``alternative`` parameter was added to the ``kendalltau`` and ``somersd``
functions to allow one-sided hypothesis testing. Similarly, the masked
versions of ``skewtest``, ``kurtosistest``, ``ttest_1samp``, ``ttest_ind``,
and ``ttest_rel`` now also have an ``alternative`` parameter.

Add `scipy.stats.gzscore` to calculate the geometrical z score.

Random variate generators to sample from arbitrary univariate non-uniform
continuous and discrete distributions have been added to the new
`scipy.stats.sampling` submodule. Implementations of a C library
`UNU.RAN <http://statmath.wu.ac.at/software/unuran/>`_ are used for
performance. The generators added are:

- TransformedDensityRejection
- DiscreteAliasUrn
- NumericalInversePolynomial
- DiscreteGuideTable
- SimpleRatioUniforms

The ``binned_statistic`` set of functions now have improved performance for
the ``std``, ``min``, ``max``, and ``median`` statistic calculations.

``somersd`` and ``_tau_b`` now have faster Pythran-based implementations.

Some general efficiency improvements to handling of ``nan`` values in
several ``stats`` functions.

Added the Tukey-Kramer test as `scipy.stats.tukey_hsd`.

Improved performance of `scipy.stats.argus` ``rvs`` method.

Added the parameter ``keepdims`` to `scipy.stats.variation` and prevent the
undesirable return of a masked array from the function in some cases.

``permutation_test`` performs an exact or randomized permutation test of a
given statistic on provided data.

*******************
Deprecated features
*******************

Clear split between public and private API
==========================================

SciPy has always documented what its public API consisted of in
:ref:`its API reference docs <scipy-api>`,
however there never was a clear split between public and
private namespaces in the code base. In this release, all namespaces that were
private but happened to miss underscores in their names have been deprecated.
These include (as examples, there are many more):

- ``scipy.signal.spline``
- ``scipy.ndimage.filters``
- ``scipy.ndimage.fourier``
- ``scipy.ndimage.measurements``
- ``scipy.ndimage.morphology``
- ``scipy.ndimage.interpolation``
- ``scipy.sparse.linalg.solve``
- ``scipy.sparse.linalg.eigen``
- ``scipy.sparse.linalg.isolve``

All functions and other objects in these namespaces that were meant to be
public are accessible from their respective public namespace (e.g.
`scipy.signal`). The design principle is that any public object must be
accessible from a single namespace only; there are a few exceptions, mostly for
historical reasons (e.g., ``stats`` and ``stats.distributions`` overlap).
For other libraries aiming to provide a SciPy-compatible API, it is now
unambiguous what namespace structure to follow.  See
`gh-14360 <https://github.com/scipy/scipy/issues/14360>`_ for more details.

Other deprecations
==================

``NumericalInverseHermite`` has been deprecated from `scipy.stats` and moved
to the `scipy.stats.sampling` submodule. It now uses the C implementation of
the UNU.RAN library so the result of methods like ``ppf`` may vary slightly.
Parameter ``tol`` has been deprecated and renamed to ``u_resolution``. The
parameter ``max_intervals`` has also been deprecated and will be removed in a
future release of SciPy.


******************************
Backwards incompatible changes
******************************

- SciPy has raised the minimum compiler versions to GCC 6.3 on linux and
  VS2019 on windows. In particular, this means that SciPy may now use C99 and
  C++14 features. For more details see
  `here <https://docs.scipy.org/doc/scipy/reference/dev/toolchain.html>`_.
- The result for empty bins for `scipy.stats.binned_statistic` with the builtin
  ``'std'`` metric is now ``nan``, for consistency with ``np.std``.
- The function `scipy.spatial.distance.wminkowski` has been removed. To achieve
  the same results as before, please use the ``minkowski`` distance function
  with the (optional) ``w=`` keyword-argument for the given weight.

*************
Other changes
*************

Some Fortran 77 code was modernized to be compatible with NAG's nagfor Fortran
compiler (see, e.g., `PR 13229 <https://github.com/scipy/scipy/pull/13229>`_).

``threadpoolctl`` may now be used by our test suite to substantially improve
the efficiency of parallel test suite runs.

*******
Authors
*******

* @endolith
* adamadanandy +
* akeemlh +
* Anton Akhmerov
* Marvin Albert +
* alegresor +
* Andrew Annex +
* Pantelis Antonoudiou +
* Ross Barnowski +
* Christoph Baumgarten
* Stephen Becker +
* Nickolai Belakovski
* Peter Bell
* berberto +
* Georgii Bocharov +
* Evgeni Burovski
* Matthias Bussonnier
* CJ Carey
* Justin Charlong +
* Dennis Collaris +
* David Cottrell +
* cruyffturn +
* da-woods +
* Anirudh Dagar
* Tiger Du +
* Thomas Duvernay
* Dani El-Ayyass +
* Castedo Ellerman +
* Donnie Erb +
* Andreas Esders-Kopecky +
* Livio F +
* Isuru Fernando
* Evelyn Fitzgerald +
* Sara Fridovich-Keil +
* Mark E Fuller +
* Ralf Gommers
* Kevin Richard Green +
* guiweber +
* Nitish Gupta +
* h-vetinari
* Matt Haberland
* J. Hariharan +
* Charles Harris
* Trever Hines
* Ian Hunt-Isaak +
* ich +
* Itrimel +
* Jan-Hendrik Müller +
* Jebby993 +
* Evan W Jones +
* Nathaniel Jones +
* Jeffrey Kelling +
* Malik Idrees Hasan Khan +
* Sergey B Kirpichev
* Kadatatlu Kishore +
* Andrew Knyazev
* Ravin Kumar +
* Peter Mahler Larsen
* Eric Larson
* Antony Lee
* Gregory R. Lee
* Tim Leslie
* lezcano +
* Xingyu Liu
* Christian Lorentzen
* Lorenzo +
* Smit Lunagariya +
* Lv101Magikarp +
* Yair M +
* Cong Ma
* Lorenzo Maffioli +
* majiang +
* Brian McFee +
* Nicholas McKibben
* John Speed Meyers +
* millivolt9 +
* Jarrod Millman
* Harsh Mishra +
* Boaz Mohar +
* naelsondouglas +
* Andrew Nelson
* Nico Schlömer
* Thomas Nowotny +
* nullptr +
* Teddy Ort +
* Nick Papior
* ParticularMiner +
* Dima Pasechnik
* Tirth Patel
* Matti Picus
* Ilhan Polat
* Adrian Price-Whelan +
* Quentin Barthélemy +
* Sundar R +
* Judah Rand +
* Tyler Reddy
* Renal-Of-Loon +
* Frederic Renner +
* Pamphile Roy
* Bharath Saiguhan +
* Atsushi Sakai
* Eric Schanet +
* Sebastian Wallkötter
* serge-sans-paille
* Reshama Shaikh +
* Namami Shanker
* Walter Simson +
* Gagandeep Singh +
* Leo C. Stein +
* Albert Steppi
* Kai Striega
* Diana Sukhoverkhova
* Søren Fuglede Jørgensen
* Mike Taves
* Ben Thompson +
* Bas van Beek
* Jacob Vanderplas
* Dhruv Vats +
* H. Vetinari +
* Thomas Viehmann +
* Pauli Virtanen
* Vlad +
* Arthur Volant
* Samuel Wallan
* Stefan van der Walt
* Warren Weckesser
* Josh Wilson
* Haoyin Xu +
* Rory Yorke
* Egor Zemlyanoy
* Gang Zhao +
* 赵丰 (Zhao Feng) +

A total of 132 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


***********************
Issues closed for 1.8.0
***********************

* `#592 <https://github.com/scipy/scipy/issues/592>`__: Statistics Review: variation (Trac #65)
* `#857 <https://github.com/scipy/scipy/issues/857>`__: A Wrapper for PROPACK (Trac #330)
* `#2009 <https://github.com/scipy/scipy/issues/2009>`__: "Kulsinski" dissimilarity seems wrong (Trac #1484)
* `#2063 <https://github.com/scipy/scipy/issues/2063>`__: callback functions for COBYLA and TNC (Trac #1538)
* `#2358 <https://github.com/scipy/scipy/issues/2358>`__: ndimage.center_of_mass doesnt return all for all labelled objects...
* `#5668 <https://github.com/scipy/scipy/issues/5668>`__: Need zpk2sos for analog filters
* `#7340 <https://github.com/scipy/scipy/issues/7340>`__: SciPy Hypergeometric function hyp2f1 producing infinities
* `#8774 <https://github.com/scipy/scipy/issues/8774>`__: In \`optimize.basinhopping\`, the target acceptance rate should...
* `#10497 <https://github.com/scipy/scipy/issues/10497>`__: scipy.sparse.csc_matrix.toarray docstring is wrong
* `#10888 <https://github.com/scipy/scipy/issues/10888>`__: Check finite difference gradient approximation in a random direction
* `#10974 <https://github.com/scipy/scipy/issues/10974>`__: Non explicit error message in lobpcg
* `#11452 <https://github.com/scipy/scipy/issues/11452>`__: Normalisation requirement for \`Wn\` unclear in \`scipy.signal.butter\`
* `#11700 <https://github.com/scipy/scipy/issues/11700>`__: solve_ivp errors out instead of simply quitting after the solve...
* `#12006 <https://github.com/scipy/scipy/issues/12006>`__: newton: Shouldn't it take a Jacobian for multivariate problems...
* `#12100 <https://github.com/scipy/scipy/issues/12100>`__: solve_ivp: custom t_eval list and the terminating event
* `#12192 <https://github.com/scipy/scipy/issues/12192>`__: \`scipy.stats.rv_continuous.moment\` does not accept array input
* `#12502 <https://github.com/scipy/scipy/issues/12502>`__: Divide by zero in Jacobian numerical differentiation when equality...
* `#12981 <https://github.com/scipy/scipy/issues/12981>`__: SLSQP constrained minimization error in 1.5.2
* `#12999 <https://github.com/scipy/scipy/issues/12999>`__: Bug in scipy.stats.ks_2samp for two-sided auto and exact modes...
* `#13402 <https://github.com/scipy/scipy/issues/13402>`__: ENH: Faster Max Flow algorithm in scipy.sparse.csgraph
* `#13580 <https://github.com/scipy/scipy/issues/13580>`__: truncnorm gives incorrect means and variances
* `#13642 <https://github.com/scipy/scipy/issues/13642>`__: stats.truncnorm variance works incorrectly when input is an array.
* `#13659 <https://github.com/scipy/scipy/issues/13659>`__: Orthogonal Array for Latin hypercube in \`scipy.stats.qmc\`
* `#13737 <https://github.com/scipy/scipy/issues/13737>`__: brentq can overflow / underflow
* `#13745 <https://github.com/scipy/scipy/issues/13745>`__: different default atol, btol for lsqr, lsmr
* `#13898 <https://github.com/scipy/scipy/issues/13898>`__: Savitzky-Golay filter for even number data
* `#13902 <https://github.com/scipy/scipy/issues/13902>`__: Different solvers of \`svds\` return quite different results
* `#13922 <https://github.com/scipy/scipy/issues/13922>`__: Need Exception / Error for Incorrect and/or misleading analog...
* `#14122 <https://github.com/scipy/scipy/issues/14122>`__: Item assignement for spatial.transform.Rotation objects
* `#14140 <https://github.com/scipy/scipy/issues/14140>`__: Likely unnecessary invalid value warning from PchipInterpolator
* `#14152 <https://github.com/scipy/scipy/issues/14152>`__: zpk2sos not working correctly when butterworth band-pass filter...
* `#14165 <https://github.com/scipy/scipy/issues/14165>`__: scipy.optimize.minimize method='Nelder-Mead': 'maxfev' is not...
* `#14168 <https://github.com/scipy/scipy/issues/14168>`__: Missing "inverse" word in the multidimensional Discrete Cosine/Sine...
* `#14189 <https://github.com/scipy/scipy/issues/14189>`__: Incorrect shape handling in \`scipy.stat.multivariate_t.rvs\`...
* `#14190 <https://github.com/scipy/scipy/issues/14190>`__: Links in documentation of Dirichlet distribution are a mess
* `#14193 <https://github.com/scipy/scipy/issues/14193>`__: Implementation of scrambled Van der Corput sequence differs from...
* `#14217 <https://github.com/scipy/scipy/issues/14217>`__: Error in documentation for \`scipy.stats.gaussian_kde.factor\`
* `#14235 <https://github.com/scipy/scipy/issues/14235>`__: Should this be $y$ only, instead of $m_y$?
* `#14236 <https://github.com/scipy/scipy/issues/14236>`__: BUG: discrete isf is wrong at boundary if loc != 0
* `#14277 <https://github.com/scipy/scipy/issues/14277>`__: Broken reference in docstring of scipy.stats.power_divergence
* `#14324 <https://github.com/scipy/scipy/issues/14324>`__: BUG: scipy.stats.theilslopes intercept calculation can produce...
* `#14332 <https://github.com/scipy/scipy/issues/14332>`__: Strange output of \`binned_statistic_dd\` with \`statistic=sum\`
* `#14340 <https://github.com/scipy/scipy/issues/14340>`__: Initialize Rotation using list or array of Rotations
* `#14346 <https://github.com/scipy/scipy/issues/14346>`__: scipy.stats.rv_continuous.fit returns wrapper instead of fit...
* `#14360 <https://github.com/scipy/scipy/issues/14360>`__: Making clearer what namespaces are public by use of underscores
* `#14385 <https://github.com/scipy/scipy/issues/14385>`__: csgraph.maximum_flow can cause Python crash for large but very...
* `#14409 <https://github.com/scipy/scipy/issues/14409>`__: Lagrange polynomials and numpy Polynomials
* `#14412 <https://github.com/scipy/scipy/issues/14412>`__: Extra function arguments to \`scipy.integrate.quad_vec\`
* `#14416 <https://github.com/scipy/scipy/issues/14416>`__: Is the r-value outputted by scipy.stats.linregress always the...
* `#14425 <https://github.com/scipy/scipy/issues/14425>`__: Running tests in parallel is not any faster than without pytest-xdist...
* `#14445 <https://github.com/scipy/scipy/issues/14445>`__: BUG: out of bounds indexing issue in \`prini.f\`
* `#14482 <https://github.com/scipy/scipy/issues/14482>`__: Azure CI jobs do not set exit status for build stage correctly
* `#14491 <https://github.com/scipy/scipy/issues/14491>`__: MAINT: Replace np.rollaxis with np.moveaxis
* `#14501 <https://github.com/scipy/scipy/issues/14501>`__: runtests.py overrides \`$PYTHONPATH\`
* `#14514 <https://github.com/scipy/scipy/issues/14514>`__: linprog kwargs not recognised
* `#14529 <https://github.com/scipy/scipy/issues/14529>`__: CI: Azure pipelines don't appear to be running
* `#14535 <https://github.com/scipy/scipy/issues/14535>`__: hess option does not work in minimize function
* `#14551 <https://github.com/scipy/scipy/issues/14551>`__: Cannot create Compressed sparse column matrix of shape N x N-2
* `#14568 <https://github.com/scipy/scipy/issues/14568>`__: \`stats.norminvgauss\` incorrect implementation?
* `#14585 <https://github.com/scipy/scipy/issues/14585>`__: DOC: toolchain updates and max Python
* `#14607 <https://github.com/scipy/scipy/issues/14607>`__: scipy.sparse.linalg.inv cannot take ndarray as argument despite...
* `#14608 <https://github.com/scipy/scipy/issues/14608>`__: BUG: scipy.stats.multivariate_t distribution math documentation
* `#14623 <https://github.com/scipy/scipy/issues/14623>`__: BUG: Error constructing sparse matrix with indices larger than...
* `#14654 <https://github.com/scipy/scipy/issues/14654>`__: DOC: Linux Devdocs workflow requires installing packages that...
* `#14680 <https://github.com/scipy/scipy/issues/14680>`__: BUG: misleading documentation in scipy.stats.entropy
* `#14683 <https://github.com/scipy/scipy/issues/14683>`__: DOC: OptimizeResult Notes are placed before attribute section,...
* `#14733 <https://github.com/scipy/scipy/issues/14733>`__: BUG: resample_poly does not preserve dtype
* `#14746 <https://github.com/scipy/scipy/issues/14746>`__: site.cfg: [ALL] or [DEFAULT]?
* `#14770 <https://github.com/scipy/scipy/issues/14770>`__: BUG: lpmn ref broken link
* `#14807 <https://github.com/scipy/scipy/issues/14807>`__: BUG: wrong weights of the 7-point gauss rule in QUADPACK: dqk15w.f
* `#14830 <https://github.com/scipy/scipy/issues/14830>`__: do CDF inversion methods have to be public?
* `#14859 <https://github.com/scipy/scipy/issues/14859>`__: BUG: constraint function is overwritten when equal bounds are...
* `#14873 <https://github.com/scipy/scipy/issues/14873>`__: ENH: get the driver used in scipy.linalg.eigh
* `#14879 <https://github.com/scipy/scipy/issues/14879>`__: BUG: TNC output is different if a callback is used.
* `#14891 <https://github.com/scipy/scipy/issues/14891>`__: DOC: \`directed_hausdorff\` expects 2D array despite docs stating...
* `#14910 <https://github.com/scipy/scipy/issues/14910>`__: \`stats.contingency\` not listed as public API
* `#14911 <https://github.com/scipy/scipy/issues/14911>`__: MAINT, DOC: CI failure for doc building
* `#14942 <https://github.com/scipy/scipy/issues/14942>`__: DOC: Ambiguous command instruction for running tests in Mac docs
* `#14984 <https://github.com/scipy/scipy/issues/14984>`__: BUG: scipy.sparse.linalg.spsolve: runtime memory error caused...
* `#14987 <https://github.com/scipy/scipy/issues/14987>`__: ENH: The knot interval lookup for BSpline.design_matrix is inefficient
* `#15025 <https://github.com/scipy/scipy/issues/15025>`__: Might be j<=i+k?
* `#15033 <https://github.com/scipy/scipy/issues/15033>`__: BUG: scipy.fft.dct type I with norm = "ortho" leads to wrong...
* `#15051 <https://github.com/scipy/scipy/issues/15051>`__: BUG: test failures on aarch in wheel builder repo
* `#15064 <https://github.com/scipy/scipy/issues/15064>`__: MAINT: \`interpolation\` keyword is renamed to \`method\` in...
* `#15103 <https://github.com/scipy/scipy/issues/15103>`__: BUG: scipy.stats.chi.mean returns nan for large df due to use...

***********************
Pull requests for 1.8.0
***********************

* `#4607 <https://github.com/scipy/scipy/pull/4607>`__: Add Chirp Z-transform, zoom FFT
* `#10504 <https://github.com/scipy/scipy/pull/10504>`__: ENH: Carlson symmetric elliptic integrals.
* `#11263 <https://github.com/scipy/scipy/pull/11263>`__: MAINT:optimize: Comply with user-specified rel_step
* `#11754 <https://github.com/scipy/scipy/pull/11754>`__: ENH: stats: Updates to \`variation\`.
* `#11954 <https://github.com/scipy/scipy/pull/11954>`__: ENH: improve ARGUS rv generation in scipy.stats
* `#12146 <https://github.com/scipy/scipy/pull/12146>`__: DOC: add docs to explain behaviour of newton's mehod on arrays
* `#12197 <https://github.com/scipy/scipy/pull/12197>`__: BUG: fix moments method to support arrays and list
* `#12889 <https://github.com/scipy/scipy/pull/12889>`__: MAINT: deal with cases in \`minimize\` for \`(bounds.lb == bounds.ub).any()
* `#13002 <https://github.com/scipy/scipy/pull/13002>`__: ENH: add tukey_hsd to scipy.stats
* `#13096 <https://github.com/scipy/scipy/pull/13096>`__: BUG: optimize: alternative fix for minimize issues with lb==ub
* `#13143 <https://github.com/scipy/scipy/pull/13143>`__: MAINT: deal with cases in \`minimize\` for \`(bounds.lb == bounds.ub).any()...
* `#13229 <https://github.com/scipy/scipy/pull/13229>`__: ENH: modernise some Fortran code, needed for nagfor compiler
* `#13312 <https://github.com/scipy/scipy/pull/13312>`__: ENH: stats: add \`axis\` and \`nan_policy\` parameters to functions...
* `#13347 <https://github.com/scipy/scipy/pull/13347>`__: CI: bump gcc from 4.8 to 5.x
* `#13392 <https://github.com/scipy/scipy/pull/13392>`__: MAINT: streamlined kwargs for minimizer in dual_annealing
* `#13419 <https://github.com/scipy/scipy/pull/13419>`__: BUG: Fix group delay singularity check
* `#13471 <https://github.com/scipy/scipy/pull/13471>`__: ENH: LHS based OptimalDesign (scipy.stats.qmc)
* `#13581 <https://github.com/scipy/scipy/pull/13581>`__: MAINT: stats: fix truncnorm stats with array shapes
* `#13839 <https://github.com/scipy/scipy/pull/13839>`__: MAINT: set same tolerance between LSMR and LSQR
* `#13864 <https://github.com/scipy/scipy/pull/13864>`__: Array scalar conversion deprecation
* `#13883 <https://github.com/scipy/scipy/pull/13883>`__: MAINT: move LSAP maximization handling into solver code
* `#13899 <https://github.com/scipy/scipy/pull/13899>`__: ENH: stats: add general permutation hypothesis test
* `#13921 <https://github.com/scipy/scipy/pull/13921>`__: BUG: optimize: fix max function call validation for \`minimize\`...
* `#13958 <https://github.com/scipy/scipy/pull/13958>`__: ENH: stats: add \`alternative\` to masked version of T-Tests
* `#13960 <https://github.com/scipy/scipy/pull/13960>`__: ENH: stats: add \`alternative\` to masked normality tests
* `#14007 <https://github.com/scipy/scipy/pull/14007>`__: BUG: Fix root bracketing logic in Brent's method (issue #13737)
* `#14024 <https://github.com/scipy/scipy/pull/14024>`__: ENH: Add annotations for \`scipy.spatial.cKDTree\`
* `#14049 <https://github.com/scipy/scipy/pull/14049>`__: MAINT: Change special.orthogonal.orthopoly1d type hints to ArrayLike
* `#14132 <https://github.com/scipy/scipy/pull/14132>`__: DOC: badge with version of the doc in the navbar
* `#14144 <https://github.com/scipy/scipy/pull/14144>`__: REL: set version to 1.8.0.dev0
* `#14151 <https://github.com/scipy/scipy/pull/14151>`__: BLD: update pyproject.toml - add macOS M1, drop py36
* `#14153 <https://github.com/scipy/scipy/pull/14153>`__: BUG: stats: Implementing boost's hypergeometric distribution...
* `#14160 <https://github.com/scipy/scipy/pull/14160>`__: ENH: sparse.linalg: Add TFQMR algorithm for non-Hermitian sparse...
* `#14163 <https://github.com/scipy/scipy/pull/14163>`__: BENCH: add benchmark for energy_distance and wasserstein_distance
* `#14173 <https://github.com/scipy/scipy/pull/14173>`__: BUG: Fixed an issue wherein \`geometric_slerp\` would return...
* `#14174 <https://github.com/scipy/scipy/pull/14174>`__: ENH: Add annotations to \`scipy.spatial.geometric_slerp\`
* `#14183 <https://github.com/scipy/scipy/pull/14183>`__: DOC: add examples/ update mstats doc of pearsonr in scipy.stats
* `#14186 <https://github.com/scipy/scipy/pull/14186>`__: TST, MAINT: hausdorff test cleanups
* `#14187 <https://github.com/scipy/scipy/pull/14187>`__: DOC: interpolate: rbf has kwargs too.
* `#14191 <https://github.com/scipy/scipy/pull/14191>`__: MAINT:TST:linalg modernize the test assertions
* `#14192 <https://github.com/scipy/scipy/pull/14192>`__: BUG: stats: fix shape handing in multivariate_t.rvs
* `#14197 <https://github.com/scipy/scipy/pull/14197>`__: CI: azure: Fix handling of 'skip azp'.
* `#14200 <https://github.com/scipy/scipy/pull/14200>`__: DOC: Remove link to alpha in scipy.stats.dirichlet
* `#14201 <https://github.com/scipy/scipy/pull/14201>`__: TST: cleanup in lsqr and lsmr tests
* `#14204 <https://github.com/scipy/scipy/pull/14204>`__: Improve error message for index dimension
* `#14208 <https://github.com/scipy/scipy/pull/14208>`__: MAINT: add invalid='ignore' to np.errstate block in PchipInterpolator
* `#14209 <https://github.com/scipy/scipy/pull/14209>`__: ENH: stats: kendalltau: add alternative parameter
* `#14210 <https://github.com/scipy/scipy/pull/14210>`__: BUG: Fix Nelder-Mead logic when using a non-1D x0 and adapative
* `#14211 <https://github.com/scipy/scipy/pull/14211>`__: Fixed doc for gaussian_kde (kde.factor description)
* `#14213 <https://github.com/scipy/scipy/pull/14213>`__: ENH: stats: somersd: add alternative parameter
* `#14214 <https://github.com/scipy/scipy/pull/14214>`__: ENH: Improve the \`scipy.spatial.qhull\` annotations
* `#14215 <https://github.com/scipy/scipy/pull/14215>`__: ENH: stats: Integrate library UNU.RAN in \`scipy.stats\` [GSoC...
* `#14218 <https://github.com/scipy/scipy/pull/14218>`__: DOC: clarify \`ndimage.center_of_mass\` docstring
* `#14219 <https://github.com/scipy/scipy/pull/14219>`__: ENH: sparse.linalg: Use the faster "sqrt" from "math" and be...
* `#14222 <https://github.com/scipy/scipy/pull/14222>`__: MAINT: stats: remove unused 'type: ignore' comment
* `#14224 <https://github.com/scipy/scipy/pull/14224>`__: MAINT: Modify to use new random API in benchmarks
* `#14225 <https://github.com/scipy/scipy/pull/14225>`__: MAINT: fix missing LowLevelCallable in \`dir(scipy)\`
* `#14226 <https://github.com/scipy/scipy/pull/14226>`__: BLD: fix warning for missing dependency, and dev version number
* `#14227 <https://github.com/scipy/scipy/pull/14227>`__: MAINT: fix maybe-uninitialized warnings in lbfgbf.f
* `#14228 <https://github.com/scipy/scipy/pull/14228>`__: BENCH: add more benchmarks for inferential statistics tests
* `#14237 <https://github.com/scipy/scipy/pull/14237>`__: Removes unused variable
* `#14240 <https://github.com/scipy/scipy/pull/14240>`__: ENH: sparse.linalg: Normalize type descriptions
* `#14242 <https://github.com/scipy/scipy/pull/14242>`__: BUG: stats: fix discrete \`.isf\` to work at boundaries when...
* `#14250 <https://github.com/scipy/scipy/pull/14250>`__: Error in parameter checking in cdfbin.f
* `#14254 <https://github.com/scipy/scipy/pull/14254>`__: BUG: Fixed an issue wherein \`SphericalVoronoi\` could raise...
* `#14255 <https://github.com/scipy/scipy/pull/14255>`__: BUG: Numerical stability for large N BarycentricInterpolator
* `#14257 <https://github.com/scipy/scipy/pull/14257>`__: MAINT: Fixed deprecated API calls in scipy.optimize
* `#14258 <https://github.com/scipy/scipy/pull/14258>`__: DOC: fix stats.pearsonr example that was failing in CI
* `#14259 <https://github.com/scipy/scipy/pull/14259>`__: CI: pin mypy to 0.902 and fix one CI failure
* `#14260 <https://github.com/scipy/scipy/pull/14260>`__: BLD: optimize: fix some warnings in moduleTNC and minpack.h
* `#14261 <https://github.com/scipy/scipy/pull/14261>`__: BLD: fix include order and build warnings for \`optimize/_trlib\`
* `#14263 <https://github.com/scipy/scipy/pull/14263>`__: DOC: forward port 1.7.0 relnotes
* `#14268 <https://github.com/scipy/scipy/pull/14268>`__: MAINT: Replaced direct field access in PyArrayObject\* with wrapper...
* `#14274 <https://github.com/scipy/scipy/pull/14274>`__: MAINT: more scalar array conversion fixes for optimize
* `#14275 <https://github.com/scipy/scipy/pull/14275>`__: MAINT: Update vendored uarray, required for auto-dispatching
* `#14278 <https://github.com/scipy/scipy/pull/14278>`__: MAINT: two small fixes for implicit scalar-array-conversions
* `#14281 <https://github.com/scipy/scipy/pull/14281>`__: ENH: Annotate the array dtypes of \`scipy.spatial.qhull\`
* `#14285 <https://github.com/scipy/scipy/pull/14285>`__: DEV: remove scikit-umfpack from environment.yml
* `#14287 <https://github.com/scipy/scipy/pull/14287>`__: TST: Add testing for hyp2f1 for complex values in anticipation...
* `#14291 <https://github.com/scipy/scipy/pull/14291>`__: TST: split combined LSAP input validation tests up
* `#14293 <https://github.com/scipy/scipy/pull/14293>`__: MAINT: remove the last deprecated \`PyEval_\*\` usages
* `#14294 <https://github.com/scipy/scipy/pull/14294>`__: ENH: Annotate array dtypes in \`scipy.spatial.ckdtree\` and \`distance\`
* `#14295 <https://github.com/scipy/scipy/pull/14295>`__: MAINT: move LSAP input validation into lsap_module
* `#14297 <https://github.com/scipy/scipy/pull/14297>`__: DOC: Make code block an Item List
* `#14301 <https://github.com/scipy/scipy/pull/14301>`__: MAINT: fix the last build warning in \`optimize/_trlib/\`
* `#14302 <https://github.com/scipy/scipy/pull/14302>`__: BLD: fix build warnings for \`stats/biasedurn\`
* `#14305 <https://github.com/scipy/scipy/pull/14305>`__: MAINT: silence warning in odepackmodule.c
* `#14308 <https://github.com/scipy/scipy/pull/14308>`__: ENH: use Pythran to speedup somersd and _tau_b
* `#14309 <https://github.com/scipy/scipy/pull/14309>`__: BLD: fix build warnings for scipy.special
* `#14310 <https://github.com/scipy/scipy/pull/14310>`__: ENH: make epsilon optional in optimize.approx_fprime.
* `#14311 <https://github.com/scipy/scipy/pull/14311>`__: MAINT: Corrected NumPy API usage in scipy.spatial
* `#14312 <https://github.com/scipy/scipy/pull/14312>`__: ENH: Using random directional derivative to check grad
* `#14326 <https://github.com/scipy/scipy/pull/14326>`__: MAINT: Removed redifinition of trace1 in spatial/qhull
* `#14328 <https://github.com/scipy/scipy/pull/14328>`__: MAINT: _lib: add __dealloc__ to MessageStream
* `#14331 <https://github.com/scipy/scipy/pull/14331>`__: ENH: Complement \`trace\` method of sparse matrices like \`csr_matrix/csc_matrix/coo_matrix\`
* `#14338 <https://github.com/scipy/scipy/pull/14338>`__: BUG: fix \`stats.binned_statistic_dd\` issue with values close...
* `#14339 <https://github.com/scipy/scipy/pull/14339>`__: TST: fix \`sparse.linalg.spsolve\` test with singular input
* `#14341 <https://github.com/scipy/scipy/pull/14341>`__: MAINT: Add missing parenthesis in _nnls.py
* `#14342 <https://github.com/scipy/scipy/pull/14342>`__: ENH: make \`savgol_coeffs\`, \`savgol_filter\` work for even...
* `#14344 <https://github.com/scipy/scipy/pull/14344>`__: ENH: scipy.interpolate b-splines (design_matrix)
* `#14350 <https://github.com/scipy/scipy/pull/14350>`__: MAINT: make fit method of rv_continuous pickleable
* `#14358 <https://github.com/scipy/scipy/pull/14358>`__: ENH: Dinic's algorithm for maximum_flow
* `#14359 <https://github.com/scipy/scipy/pull/14359>`__: ENH: Set fft backend with try_last=True
* `#14362 <https://github.com/scipy/scipy/pull/14362>`__: Use list comprehension
* `#14367 <https://github.com/scipy/scipy/pull/14367>`__: BUG: Check for NULL pointer in \`memmove\`
* `#14377 <https://github.com/scipy/scipy/pull/14377>`__: Fix behavior of binary morphology with output=input when iterations=1
* `#14378 <https://github.com/scipy/scipy/pull/14378>`__: MAINT: Removing deprecated NumPy C API from \`interpolate\`
* `#14380 <https://github.com/scipy/scipy/pull/14380>`__: ENH: Fixed intercept computation in theilslopes
* `#14381 <https://github.com/scipy/scipy/pull/14381>`__: BENCH: add benchmark for somersd
* `#14387 <https://github.com/scipy/scipy/pull/14387>`__: MAINT: Removed deprecated NumPy C api from \`sparse\`
* `#14392 <https://github.com/scipy/scipy/pull/14392>`__: BUG/ENH: rework maximum flow preprocessing
* `#14393 <https://github.com/scipy/scipy/pull/14393>`__: CI: Lint checks failures are reporting success
* `#14403 <https://github.com/scipy/scipy/pull/14403>`__: Fix off by one error in doc string.
* `#14404 <https://github.com/scipy/scipy/pull/14404>`__: DOC: docstring fix for default of n param of interpolate.pade
* `#14406 <https://github.com/scipy/scipy/pull/14406>`__: MAINT: Use numpy_nodepr_api in \`spatial\`
* `#14411 <https://github.com/scipy/scipy/pull/14411>`__: MAINT: minor cleanups in usage of \`compute_uv\` keyword of \`svd\`
* `#14413 <https://github.com/scipy/scipy/pull/14413>`__: DOC:interpolate: Fix the docstring example of "lagrange"
* `#14419 <https://github.com/scipy/scipy/pull/14419>`__: DEP: deprecate private but non-underscored \`signal.spline\`...
* `#14422 <https://github.com/scipy/scipy/pull/14422>`__: MAINT: csgraph: change Dinic algorithm to iterative implementation
* `#14423 <https://github.com/scipy/scipy/pull/14423>`__: CI: remove printing of skipped and xfailed tests from Azure test...
* `#14426 <https://github.com/scipy/scipy/pull/14426>`__: ENH: Add args argument for callable in quad_vec
* `#14427 <https://github.com/scipy/scipy/pull/14427>`__: MAINT: extra pythran annotation for i686 support
* `#14432 <https://github.com/scipy/scipy/pull/14432>`__: BUG/ENH: more stable recursion for 2-sample ks test exact p-values
* `#14433 <https://github.com/scipy/scipy/pull/14433>`__: ENH: add PROPACK wrapper for improved sparse SVD
* `#14440 <https://github.com/scipy/scipy/pull/14440>`__: MAINT: stats: silence mypy complaints
* `#14441 <https://github.com/scipy/scipy/pull/14441>`__: ENH: TST: add a threadpoolctl hook to limit OpenBLAS parallelism
* `#14442 <https://github.com/scipy/scipy/pull/14442>`__: MAINT: Fix uninitialized warnings in \`sparse/linalg/dsolve\`
* `#14447 <https://github.com/scipy/scipy/pull/14447>`__: MAINT: rename scipy.ndimage modules
* `#14449 <https://github.com/scipy/scipy/pull/14449>`__: ENH: Cythonize van der corput
* `#14454 <https://github.com/scipy/scipy/pull/14454>`__: MAINT: Begin translation of hyp2f1 for complex numbers into Cython
* `#14456 <https://github.com/scipy/scipy/pull/14456>`__: CI: Lint with flake8 instead of pyflakes + pycodestyle
* `#14458 <https://github.com/scipy/scipy/pull/14458>`__: DOC: clarify meaning of rvalue in stats.linregress
* `#14459 <https://github.com/scipy/scipy/pull/14459>`__: MAINT: Fix uninitialized warnings in \`interpolate\` and \`cluster\`
* `#14463 <https://github.com/scipy/scipy/pull/14463>`__: Fix typo in doc overview: "pandas" to "SciPy"
* `#14474 <https://github.com/scipy/scipy/pull/14474>`__: DEP: Deprecate private but non-underscored ndimage.<module> namespace
* `#14477 <https://github.com/scipy/scipy/pull/14477>`__: MAINT: Using Tempita file for bspline (signal)
* `#14479 <https://github.com/scipy/scipy/pull/14479>`__: Added \`Inverse\` word in \`idstn\` and \`idctn\` docstrings
* `#14487 <https://github.com/scipy/scipy/pull/14487>`__: TST: modify flaky test for constrained minimization
* `#14489 <https://github.com/scipy/scipy/pull/14489>`__: MAINT: cleanup of some line_search code
* `#14492 <https://github.com/scipy/scipy/pull/14492>`__: CI: make sure Azure job step fails when building a SciPy wheel...
* `#14496 <https://github.com/scipy/scipy/pull/14496>`__: MAINT: switch to using spmatrix.toarray instead of .todense
* `#14499 <https://github.com/scipy/scipy/pull/14499>`__: DOC: fix toarray/todense docstring
* `#14507 <https://github.com/scipy/scipy/pull/14507>`__: CI: Add lint_diff docs & option to run only on specified files/dirs
* `#14513 <https://github.com/scipy/scipy/pull/14513>`__: DOC: added reference and example in jacobi docstring
* `#14520 <https://github.com/scipy/scipy/pull/14520>`__: BUG: diffev maxfun can be reached partway through population
* `#14524 <https://github.com/scipy/scipy/pull/14524>`__: ENH: Rotation.concatenate
* `#14532 <https://github.com/scipy/scipy/pull/14532>`__: ENH: sparse.linalg: The solution is zero when R.H.S. is zero
* `#14538 <https://github.com/scipy/scipy/pull/14538>`__: CI: Revert "CI: make sure Azure job step fails when building...
* `#14539 <https://github.com/scipy/scipy/pull/14539>`__: DOC: added chebyt and chebyu docstring examples in scipy.special
* `#14546 <https://github.com/scipy/scipy/pull/14546>`__: ENH: Orthogonal Latin Hypercube Sampling to QMC
* `#14547 <https://github.com/scipy/scipy/pull/14547>`__: ENH: __setitem__ method for Rotation class
* `#14549 <https://github.com/scipy/scipy/pull/14549>`__: Small test fixes for pypy + win + mmap
* `#14554 <https://github.com/scipy/scipy/pull/14554>`__: ENH: scipy.interpolate.BSpline from_power_basis
* `#14555 <https://github.com/scipy/scipy/pull/14555>`__: BUG: sparse: fix a DIA.tocsc bug
* `#14556 <https://github.com/scipy/scipy/pull/14556>`__: Fix the link to details of the strongly connected components...
* `#14559 <https://github.com/scipy/scipy/pull/14559>`__: WIP: TST: add tests for Pythran somersd
* `#14561 <https://github.com/scipy/scipy/pull/14561>`__: DOC: added reference and examples in (gen)laguerre docstring...
* `#14564 <https://github.com/scipy/scipy/pull/14564>`__: ENH: Add threaded Van Der Corput
* `#14571 <https://github.com/scipy/scipy/pull/14571>`__: Fix repeated word in _mannwhitneyu.py example
* `#14572 <https://github.com/scipy/scipy/pull/14572>`__: Set min length of the knot array for BSpline.design_matrix
* `#14578 <https://github.com/scipy/scipy/pull/14578>`__: DOC: added examples in spherical Bessel docstrings
* `#14581 <https://github.com/scipy/scipy/pull/14581>`__: MAINT: Refactor \`linalg.tests.test_interpolative::TestInterpolativeDecomposition::test_id\`
* `#14588 <https://github.com/scipy/scipy/pull/14588>`__: ENH: Added \`\`kulczynski1\`\` to \`\`scipy.spatial.distance\`\`
* `#14592 <https://github.com/scipy/scipy/pull/14592>`__: DOC: clarify parameters of norminvgauss in scipy.stats
* `#14595 <https://github.com/scipy/scipy/pull/14595>`__: Removing unused subroutines in \`\`scipy/linalg/src/id_dist/src/prini.f\`\`
* `#14601 <https://github.com/scipy/scipy/pull/14601>`__: Fixed inconsistencies between numpy and scipy interp
* `#14602 <https://github.com/scipy/scipy/pull/14602>`__: MAINT: Fix \`-Wunused-result\` warnings in \`sparse/linalg/dsolve\`
* `#14603 <https://github.com/scipy/scipy/pull/14603>`__: DEV: initialize all submodules in Gitpod Dockerfile
* `#14609 <https://github.com/scipy/scipy/pull/14609>`__: MAINT: Fix \`-Wmaybe-uninitialized\` warnings in \`optimize/_highs\`
* `#14610 <https://github.com/scipy/scipy/pull/14610>`__: MAINT: Ignored \`\`scipy/signal/bspline_util.c\`\`
* `#14613 <https://github.com/scipy/scipy/pull/14613>`__: MAINT: interpolate: Declare type for a Cython indexing variable.
* `#14619 <https://github.com/scipy/scipy/pull/14619>`__: ENH: stats.unuran: add Polynomial interpolation based numerical...
* `#14620 <https://github.com/scipy/scipy/pull/14620>`__: CI: fix Azure job which uses pre-release wheels + Python 3.7
* `#14625 <https://github.com/scipy/scipy/pull/14625>`__: ENH: optimize min max and median scipy.stats.binned_statistic
* `#14626 <https://github.com/scipy/scipy/pull/14626>`__: MAINT: fix type-narrowing addition in sparse.construct.bmat
* `#14627 <https://github.com/scipy/scipy/pull/14627>`__: MAINT: Bumped tolerances to pass \`\`special.tests\`\` on Apple...
* `#14628 <https://github.com/scipy/scipy/pull/14628>`__: DOC: clarify usage of options param in scipy.optimize.linprog
* `#14629 <https://github.com/scipy/scipy/pull/14629>`__: ENH: optimize std in scipy.stats.binned_statistic
* `#14630 <https://github.com/scipy/scipy/pull/14630>`__: DOC: add citation file
* `#14631 <https://github.com/scipy/scipy/pull/14631>`__: Fix unuran builds for older compilers
* `#14633 <https://github.com/scipy/scipy/pull/14633>`__: BUG: scipy.stats._unran: send only strings to include_dirs
* `#14634 <https://github.com/scipy/scipy/pull/14634>`__: DOC: Fix Wikipedia bootstrap link
* `#14635 <https://github.com/scipy/scipy/pull/14635>`__: DOC: stats: fix multivariate_t docs pdf eqn
* `#14637 <https://github.com/scipy/scipy/pull/14637>`__: MAINT: copy discrete dist dict
* `#14643 <https://github.com/scipy/scipy/pull/14643>`__: MAINT: address gh6019, disp for minimize_scalar
* `#14644 <https://github.com/scipy/scipy/pull/14644>`__: DOC: stats: add UNU.RAN references in the tutorial
* `#14649 <https://github.com/scipy/scipy/pull/14649>`__: DOC: clarify SciPy compatibility with Python and NumPy.
* `#14655 <https://github.com/scipy/scipy/pull/14655>`__: MAINT: remove support for Python 3.7 (hence NumPy 1.16)
* `#14656 <https://github.com/scipy/scipy/pull/14656>`__: MAINT: replacing ``assert_`` with assert
* `#14658 <https://github.com/scipy/scipy/pull/14658>`__: DOC: use conda-forge in Ubuntu quickstart
* `#14660 <https://github.com/scipy/scipy/pull/14660>`__: MAINT: refactor "for ... in range(len(" statements
* `#14663 <https://github.com/scipy/scipy/pull/14663>`__: MAINT: update leftover Python and NumPy version from pyproject.toml
* `#14665 <https://github.com/scipy/scipy/pull/14665>`__: BLD: fix confusing "import pip" failure that should be caught
* `#14666 <https://github.com/scipy/scipy/pull/14666>`__: MAINT: remove unnecessary seeding and update \`check_random_state\`
* `#14669 <https://github.com/scipy/scipy/pull/14669>`__: ENH: Refactor GitHub Issue form templates
* `#14673 <https://github.com/scipy/scipy/pull/14673>`__: BLD: fix include order, Python.h before standard headers
* `#14676 <https://github.com/scipy/scipy/pull/14676>`__: BUG: Fixes failing benchmark tests optimize_qap.QuadraticAssignment.track_score
* `#14677 <https://github.com/scipy/scipy/pull/14677>`__: MAINT: github labeler on file paths
* `#14682 <https://github.com/scipy/scipy/pull/14682>`__: DOC: Fix typo in mannwhitneyu docstring
* `#14684 <https://github.com/scipy/scipy/pull/14684>`__: DOC: optimize: fix sporadic linprog doctest failure
* `#14685 <https://github.com/scipy/scipy/pull/14685>`__: MAINT: static typing of entropy
* `#14686 <https://github.com/scipy/scipy/pull/14686>`__: BUG: fix issue in lsqr.py introduced in a recent commit
* `#14689 <https://github.com/scipy/scipy/pull/14689>`__: MAINT: replace IOError alias with OSError or other appropriate...
* `#14692 <https://github.com/scipy/scipy/pull/14692>`__: MAINT: Translation of hyp2f1 for complex numbers into Cython,...
* `#14693 <https://github.com/scipy/scipy/pull/14693>`__: DOC: update OptimizeResult notes
* `#14694 <https://github.com/scipy/scipy/pull/14694>`__: Simplify PythranBuildExt usage
* `#14695 <https://github.com/scipy/scipy/pull/14695>`__: BLD: bump Pythran version to 0.9.12
* `#14697 <https://github.com/scipy/scipy/pull/14697>`__: CI: add \`cffi\` in the benchmark CI job, and in environment.yml
* `#14699 <https://github.com/scipy/scipy/pull/14699>`__: BUG: Fix TypeError in \`stats._discrete_distns\`
* `#14700 <https://github.com/scipy/scipy/pull/14700>`__: DOC: update detailed roadmap
* `#14701 <https://github.com/scipy/scipy/pull/14701>`__: ENH:linalg: Add Cythonized get_array_bandwidth, issymmetric,...
* `#14706 <https://github.com/scipy/scipy/pull/14706>`__: BUG: Fix hyp2f1 to return correct values in regions near exp(±iπ/3).
* `#14707 <https://github.com/scipy/scipy/pull/14707>`__: Update constants.py
* `#14708 <https://github.com/scipy/scipy/pull/14708>`__: BENCH: shorten svds benchmark that is timing out in CI
* `#14709 <https://github.com/scipy/scipy/pull/14709>`__: CI: remove labeler sync
* `#14712 <https://github.com/scipy/scipy/pull/14712>`__: MAINT: special: Updates for _cosine.c.
* `#14720 <https://github.com/scipy/scipy/pull/14720>`__: DOC: optimize hess and consistency
* `#14721 <https://github.com/scipy/scipy/pull/14721>`__: MAINT: correct PR template link
* `#14723 <https://github.com/scipy/scipy/pull/14723>`__: DOC: add note on padding to \`stats.binned_statistic_2d\` docs
* `#14727 <https://github.com/scipy/scipy/pull/14727>`__: ENH: sparse.linalg: Add an useful nonzero initial guess option
* `#14729 <https://github.com/scipy/scipy/pull/14729>`__: DOC: fix documentation for scipy.optimize.brenth
* `#14737 <https://github.com/scipy/scipy/pull/14737>`__: BUG:signal: matching window dtype to input
* `#14739 <https://github.com/scipy/scipy/pull/14739>`__: TST: sparse.linalg: Add test case with 2-D Poisson equations
* `#14743 <https://github.com/scipy/scipy/pull/14743>`__: TST:sparse.linalg: Use the more convenient "assert_normclose"...
* `#14748 <https://github.com/scipy/scipy/pull/14748>`__: DOC: fix matrix representation in scipy.sparse.csgraph
* `#14751 <https://github.com/scipy/scipy/pull/14751>`__: ENH: numpy masked_arrays in refguide-check
* `#14755 <https://github.com/scipy/scipy/pull/14755>`__: BUG: Avoid \`solve_ivp\` failure when \`ts\` is empty
* `#14756 <https://github.com/scipy/scipy/pull/14756>`__: MAINT: LinAlgError from public numpy.linalg
* `#14759 <https://github.com/scipy/scipy/pull/14759>`__: BLD: change section name in site.cfg.example from ALL to DEFAULT
* `#14760 <https://github.com/scipy/scipy/pull/14760>`__: TST: suppress jinja2 deprecation warning
* `#14761 <https://github.com/scipy/scipy/pull/14761>`__: CI: remove \`pre_release_deps_source_dist\` job from Azure CI...
* `#14762 <https://github.com/scipy/scipy/pull/14762>`__: TST: add a seed to the pickling test of RBFInterpolator
* `#14763 <https://github.com/scipy/scipy/pull/14763>`__: MAINT: Make solve_ivp slightly more strict wrt. t_span.
* `#14772 <https://github.com/scipy/scipy/pull/14772>`__: DOC:special: Fix broken links to jburkardt
* `#14787 <https://github.com/scipy/scipy/pull/14787>`__: MAINT: Increase tolerance values to avoid test failures
* `#14789 <https://github.com/scipy/scipy/pull/14789>`__: MAINT: fix a tiny typo in signal/spectral.py
* `#14790 <https://github.com/scipy/scipy/pull/14790>`__: [MRG] BUG: Avoid lobpcg failure when iterations can't continue
* `#14794 <https://github.com/scipy/scipy/pull/14794>`__: Fix typos in bspline docs (and comments)
* `#14796 <https://github.com/scipy/scipy/pull/14796>`__: MAINT: Allow F401 and F403 in module init files
* `#14798 <https://github.com/scipy/scipy/pull/14798>`__: BUG: correct the test loop in test_arpack.eval_evec
* `#14801 <https://github.com/scipy/scipy/pull/14801>`__: CI, MAINT: pin Cython for azure pre-rel
* `#14805 <https://github.com/scipy/scipy/pull/14805>`__: BUG: optimize: fix max function call validation for minimize...
* `#14808 <https://github.com/scipy/scipy/pull/14808>`__: Fix Bug #14807
* `#14814 <https://github.com/scipy/scipy/pull/14814>`__: MAINT:integrate: add upstream quadpack changes
* `#14817 <https://github.com/scipy/scipy/pull/14817>`__: ENH: stats: add geometric zscore
* `#14820 <https://github.com/scipy/scipy/pull/14820>`__: MAINT: Remove \`np.rollaxis\` usage with \`np.moveaxis\` and...
* `#14821 <https://github.com/scipy/scipy/pull/14821>`__: DOC: Updated documentation for interp1d
* `#14822 <https://github.com/scipy/scipy/pull/14822>`__: Add an array API to scipy.sparse
* `#14832 <https://github.com/scipy/scipy/pull/14832>`__: MAINT: py3.10 in more jobs and bump some 3.8 to 3.9
* `#14833 <https://github.com/scipy/scipy/pull/14833>`__: FIX: raise Python OverflowError exception on Boost.Math error
* `#14836 <https://github.com/scipy/scipy/pull/14836>`__: Bug fix: dqc25f.f
* `#14837 <https://github.com/scipy/scipy/pull/14837>`__: DOC: sparse.linalg: Fixed incorrect comments when the initial...
* `#14838 <https://github.com/scipy/scipy/pull/14838>`__: TST: seed a stats test
* `#14841 <https://github.com/scipy/scipy/pull/14841>`__: MAINT: Increase tolerances in tests to avoid Nightly CPython3.10...
* `#14844 <https://github.com/scipy/scipy/pull/14844>`__: DOC: Add refguide_check option details to runtests.rst
* `#14845 <https://github.com/scipy/scipy/pull/14845>`__: DOC: update a type specifier in a docstring in \`radau.py\`
* `#14848 <https://github.com/scipy/scipy/pull/14848>`__: Typo "copmlex"
* `#14852 <https://github.com/scipy/scipy/pull/14852>`__: DOC: Fix documentation bugs in \`lstsq\`
* `#14860 <https://github.com/scipy/scipy/pull/14860>`__: minimize: copy user constraints if parameter is factored out....
* `#14865 <https://github.com/scipy/scipy/pull/14865>`__: BUG: stats: Fix a crash in stats.skew
* `#14868 <https://github.com/scipy/scipy/pull/14868>`__: [MRG] BUG: Update lobpcg.py to validate the accuracy and issue...
* `#14871 <https://github.com/scipy/scipy/pull/14871>`__: MAINT: removed a pitfall where a built-in name was being shadowed
* `#14872 <https://github.com/scipy/scipy/pull/14872>`__: DEP: Deprecate private namespaces in \`scipy.linalg\`
* `#14878 <https://github.com/scipy/scipy/pull/14878>`__: TST: bump rtol for equal_bounds
* `#14881 <https://github.com/scipy/scipy/pull/14881>`__: DEP: Deprecate private namespaces in \`scipy.special\`
* `#14882 <https://github.com/scipy/scipy/pull/14882>`__: BUG: Convert TNC C module to cython
* `#14883 <https://github.com/scipy/scipy/pull/14883>`__: DOC:linalg: Clarify driver defaults in eigh
* `#14884 <https://github.com/scipy/scipy/pull/14884>`__: BUG: optimize: add missing attributes of \`OptimizeResult\` for...
* `#14892 <https://github.com/scipy/scipy/pull/14892>`__: DOC: Correct docs for Hausdorff distance
* `#14898 <https://github.com/scipy/scipy/pull/14898>`__: DEP: Deprecate private namespace in \`scipy.stats\`
* `#14902 <https://github.com/scipy/scipy/pull/14902>`__: MAINT:linalg: Rename func to "bandwidth"
* `#14906 <https://github.com/scipy/scipy/pull/14906>`__: DEP: Deprecate private namespace in \`scipy.constants\`
* `#14913 <https://github.com/scipy/scipy/pull/14913>`__: DEP: Deprecate private namespace in \`scipy.fftpack\`
* `#14916 <https://github.com/scipy/scipy/pull/14916>`__: DEP: Deprecate \`stats.biasedurn\` and make it private
* `#14918 <https://github.com/scipy/scipy/pull/14918>`__: DEP: Deprecate private namespaces in \`\`scipy.interpolate\`\`
* `#14919 <https://github.com/scipy/scipy/pull/14919>`__: DEP: Deprecate private namespaces in \`scipy.integrate\`
* `#14920 <https://github.com/scipy/scipy/pull/14920>`__: Fix for complex Fresnel
* `#14923 <https://github.com/scipy/scipy/pull/14923>`__: DEP: Deprecate private namespaces in \`\`scipy.spatial\`\`
* `#14924 <https://github.com/scipy/scipy/pull/14924>`__: Fix extent for scipy.signal.cwt example
* `#14925 <https://github.com/scipy/scipy/pull/14925>`__: MAINT: Ignore build generated files in \`\`scipy.stats\`\`
* `#14927 <https://github.com/scipy/scipy/pull/14927>`__: DEP: Deprecate private namespaces in \`scipy.misc\`
* `#14928 <https://github.com/scipy/scipy/pull/14928>`__: MAINT: fix runtest.py overriding \`$PYTHONPATH\`: prepend instead
* `#14934 <https://github.com/scipy/scipy/pull/14934>`__: BUG: optimize: add a missing attribute of OptimizeResult in \`basinhopping\`
* `#14939 <https://github.com/scipy/scipy/pull/14939>`__: DEP: Deprecate private namespaces in \`\`scipy.sparse\`\`
* `#14941 <https://github.com/scipy/scipy/pull/14941>`__: ENH: optimize: add optional parameters of adaptive step size...
* `#14943 <https://github.com/scipy/scipy/pull/14943>`__: DOC: clarify mac pytest; add blank line
* `#14944 <https://github.com/scipy/scipy/pull/14944>`__: BUG: MultivariateNormalQMC with specific QMCEngine remove unneeded...
* `#14947 <https://github.com/scipy/scipy/pull/14947>`__: DOC: adding example to decimate function
* `#14950 <https://github.com/scipy/scipy/pull/14950>`__: MAINT: Use matmul binary operator in scipy.sparse.linalg
* `#14954 <https://github.com/scipy/scipy/pull/14954>`__: DOC: Add missing params to minres docstring.
* `#14955 <https://github.com/scipy/scipy/pull/14955>`__: BUG: stats: fix broadcasting behavior of argsreduce
* `#14960 <https://github.com/scipy/scipy/pull/14960>`__: Update links for new site
* `#14961 <https://github.com/scipy/scipy/pull/14961>`__: CI: use https protocol for git in CircleCI
* `#14962 <https://github.com/scipy/scipy/pull/14962>`__: DEP: Deprecate private namespaces in \`scipy.signal\`
* `#14963 <https://github.com/scipy/scipy/pull/14963>`__: MAINT: \`integrate.lsoda\` missing in .gitignore
* `#14965 <https://github.com/scipy/scipy/pull/14965>`__: DOC: update logo and add favicon.
* `#14966 <https://github.com/scipy/scipy/pull/14966>`__: DEP: Deprecate private namespaces in \`\`scipy.optimize\`\`
* `#14969 <https://github.com/scipy/scipy/pull/14969>`__: CI: Fixes pyparsing version in doc build
* `#14972 <https://github.com/scipy/scipy/pull/14972>`__: Don't put space after directive name.
* `#14979 <https://github.com/scipy/scipy/pull/14979>`__: BUG: scipy.sparse.linalg.spsolve: fix memory error caused from...
* `#14988 <https://github.com/scipy/scipy/pull/14988>`__: BLD: update pyproject.toml for Python 3.10
* `#14989 <https://github.com/scipy/scipy/pull/14989>`__: ENH: Speed up knot interval lookup for BSpline.design_matrix
* `#14992 <https://github.com/scipy/scipy/pull/14992>`__: Pythranized version of _matfuncs_sqrtm
* `#14993 <https://github.com/scipy/scipy/pull/14993>`__: MAINT: forward port 1.7.2 relnotes
* `#15004 <https://github.com/scipy/scipy/pull/15004>`__: ENH: Make \`get_matfile_version\` and other \`io.matlab\` objects...
* `#15007 <https://github.com/scipy/scipy/pull/15007>`__: DOC: add missing "regularized" to \`gammainccinv\` documentation
* `#15008 <https://github.com/scipy/scipy/pull/15008>`__: MAINT: restore access to deprecated private namespaces
* `#15010 <https://github.com/scipy/scipy/pull/15010>`__: TST: remove fragile test which checks if g77 is linked
* `#15013 <https://github.com/scipy/scipy/pull/15013>`__: MAINT: Fix use-after-free bug in Py_FindObjects
* `#15018 <https://github.com/scipy/scipy/pull/15018>`__: CI: Work around Sphinx bug
* `#15019 <https://github.com/scipy/scipy/pull/15019>`__: Finite Difference Hessian in Scipy Optimize Solvers (Newton-CG)
* `#15020 <https://github.com/scipy/scipy/pull/15020>`__: ENH: sparse.linalg: Fixed the issue that the initial guess "x0"...
* `#15022 <https://github.com/scipy/scipy/pull/15022>`__: DOC: mitigate newton optimization not converging.
* `#15023 <https://github.com/scipy/scipy/pull/15023>`__: CI: Unpin Sphinx
* `#15027 <https://github.com/scipy/scipy/pull/15027>`__: DOC: linalg: Fix a small condition doc error
* `#15029 <https://github.com/scipy/scipy/pull/15029>`__: DEP: Deprecate private namespaces in \`scipy.sparse.linalg\`
* `#15034 <https://github.com/scipy/scipy/pull/15034>`__: DOC: use numpydoc format for C function in \`_superlumodule.c\`
* `#15035 <https://github.com/scipy/scipy/pull/15035>`__: MAINT: simplify UNU.RAN api in stats
* `#15037 <https://github.com/scipy/scipy/pull/15037>`__: New example for gaussian_filter
* `#15040 <https://github.com/scipy/scipy/pull/15040>`__: MAINT: Add test for public API
* `#15041 <https://github.com/scipy/scipy/pull/15041>`__: DOC: Add warning to dct documentation about norm='ortho'
* `#15045 <https://github.com/scipy/scipy/pull/15045>`__: DOC: update toolchain.rst
* `#15053 <https://github.com/scipy/scipy/pull/15053>`__: TST: Add some test skips to get wheel builder CI green again
* `#15054 <https://github.com/scipy/scipy/pull/15054>`__: MAINT: Remove wminkowski
* `#15055 <https://github.com/scipy/scipy/pull/15055>`__: ENH: allow p>0 for Minkowski distance
* `#15061 <https://github.com/scipy/scipy/pull/15061>`__: MAINT:sparse: expm() fix redundant imports
* `#15062 <https://github.com/scipy/scipy/pull/15062>`__: MAINT:BLD: Open file in text mode for tempita
* `#15066 <https://github.com/scipy/scipy/pull/15066>`__: CI: bump gcc from 4.8 to 6
* `#15067 <https://github.com/scipy/scipy/pull/15067>`__: DOC: Update broken link to SuperLU library.
* `#15078 <https://github.com/scipy/scipy/pull/15078>`__: MAINT: update \`stats.iqr\` for deprecated \`np.percentile\`...
* `#15083 <https://github.com/scipy/scipy/pull/15083>`__: MAINT: stats: separate UNU.RAN functionality to its own submodule
* `#15084 <https://github.com/scipy/scipy/pull/15084>`__: MAINT: Include \`scipy.io.matlab\` in public API
* `#15085 <https://github.com/scipy/scipy/pull/15085>`__: ENH: support creation of analog SOS outputs
* `#15087 <https://github.com/scipy/scipy/pull/15087>`__: TST: Review \`\`_assert_within_tol\`\` positional arguments
* `#15095 <https://github.com/scipy/scipy/pull/15095>`__: MAINT: update gitignore to ignore private directories
* `#15099 <https://github.com/scipy/scipy/pull/15099>`__: MAINT: ScalarFunction remember best_x
* `#15100 <https://github.com/scipy/scipy/pull/15100>`__: MAINT: Include \`stats.contingency\` in public API
* `#15102 <https://github.com/scipy/scipy/pull/15102>`__: ENH: Add orthogonalize argument to DCT/DST
* `#15105 <https://github.com/scipy/scipy/pull/15105>`__: MAINT: Add missing imports in deprecated modules
* `#15107 <https://github.com/scipy/scipy/pull/15107>`__: BUG: Update chi_gen to use scipy.special.gammaln
* `#15109 <https://github.com/scipy/scipy/pull/15109>`__: MAINT: remove NaiveRatioUniforms from scipy.stats
* `#15111 <https://github.com/scipy/scipy/pull/15111>`__: ENH: Add special.log_expit and use it in stats.logistic
* `#15112 <https://github.com/scipy/scipy/pull/15112>`__: DOC: update 'Wn' definition in signal.butter
* `#15114 <https://github.com/scipy/scipy/pull/15114>`__: DOC: added Fermi-Dirac distribution by name
* `#15119 <https://github.com/scipy/scipy/pull/15119>`__: DOC: fix symlink to \`logistic.sf\` in \`stats.logistic\`
* `#15120 <https://github.com/scipy/scipy/pull/15120>`__: MAINT: Install \`sparse.linalg._eigen\` tests and fix test failures
* `#15123 <https://github.com/scipy/scipy/pull/15123>`__: MAINT: interpolate: move the \`sparse\` dependency from cython...
* `#15127 <https://github.com/scipy/scipy/pull/15127>`__: DOC: update linux build instructions to mention C++
* `#15134 <https://github.com/scipy/scipy/pull/15134>`__: DOC: Improve Lomb-Scargle example
* `#15135 <https://github.com/scipy/scipy/pull/15135>`__: ENH: Carlson symmetric elliptic integrals.
* `#15137 <https://github.com/scipy/scipy/pull/15137>`__: DOC: special: Add 'Examples' to multigammaln and roots_legendre...
* `#15139 <https://github.com/scipy/scipy/pull/15139>`__: Use constrained_layout in Lomb-Scargle example
* `#15142 <https://github.com/scipy/scipy/pull/15142>`__: ENH: stats.sampling: add SROU method
* `#15143 <https://github.com/scipy/scipy/pull/15143>`__: MAINT: Remove some unused imports.
* `#15144 <https://github.com/scipy/scipy/pull/15144>`__: BUG: Add missing import of 'errno' to runtests.py
* `#15157 <https://github.com/scipy/scipy/pull/15157>`__: ENH: rebased version of gh-14279
* `#15159 <https://github.com/scipy/scipy/pull/15159>`__: DOC: stats: fix a header in \`stats.sampling\` tutorial

==========================
SciPy 0.16.1 Release Notes
==========================

SciPy 0.16.1 is a bug-fix release with no new features compared to 0.16.0.


Issues closed for 0.16.1
------------------------

- `#5077 <https://github.com/scipy/scipy/issues/5077>`__: cKDTree not indexing properly for arrays with too many elements
- `#5127 <https://github.com/scipy/scipy/issues/5127>`__: Regression in 0.16.0: solve_banded errors out in patsy test suite
- `#5149 <https://github.com/scipy/scipy/issues/5149>`__: linalg tests apparently cause python to crash with numpy 1.10.0b1
- `#5154 <https://github.com/scipy/scipy/issues/5154>`__: 0.16.0 fails to build on OS X; can't find Python.h
- `#5173 <https://github.com/scipy/scipy/issues/5173>`__: failing stats.histogram test with numpy 1.10
- `#5191 <https://github.com/scipy/scipy/issues/5191>`__: Scipy 0.16.x - TypeError: _asarray_validated() got an unexpected...
- `#5195 <https://github.com/scipy/scipy/issues/5195>`__: tarballs missing documentation source
- `#5363 <https://github.com/scipy/scipy/issues/5363>`__: FAIL: test_orthogonal.test_j_roots, test_orthogonal.test_js_roots


Pull requests for 0.16.1
------------------------

- `#5088 <https://github.com/scipy/scipy/pull/5088>`__: BUG: fix logic error in cKDTree.sparse_distance_matrix
- `#5089 <https://github.com/scipy/scipy/pull/5089>`__: BUG: Don't overwrite b in lfilter's FIR path
- `#5128 <https://github.com/scipy/scipy/pull/5128>`__: BUG: solve_banded failed when solving 1x1 systems
- `#5155 <https://github.com/scipy/scipy/pull/5155>`__: BLD: fix missing Python include for Homebrew builds.
- `#5192 <https://github.com/scipy/scipy/pull/5192>`__: BUG: backport as_inexact kwarg to _asarray_validated
- `#5203 <https://github.com/scipy/scipy/pull/5203>`__: BUG: fix uninitialized use in lartg 0.16 backport
- `#5204 <https://github.com/scipy/scipy/pull/5204>`__: BUG: properly return error to fortran from ode_jacobian_function...
- `#5207 <https://github.com/scipy/scipy/pull/5207>`__: TST: Fix TestCtypesQuad failure on Python 3.5 for Windows
- `#5352 <https://github.com/scipy/scipy/pull/5352>`__: TST: sparse: silence warnings about boolean indexing
- `#5355 <https://github.com/scipy/scipy/pull/5355>`__: MAINT: backports for 0.16.1 release
- `#5356 <https://github.com/scipy/scipy/pull/5356>`__: REL: update Paver file to ensure sdist contents are OK for releases.
- `#5382 <https://github.com/scipy/scipy/pull/5382>`__: 0.16.x backport: MAINT: work around a possible numpy ufunc loop...
- `#5393 <https://github.com/scipy/scipy/pull/5393>`__: TST:special: bump tolerance levels for test_j_roots and test_js_roots
- `#5417 <https://github.com/scipy/scipy/pull/5417>`__: MAINT: stats: move namedtuple creating outside function calls.
==========================
SciPy 1.6.0 Release Notes
==========================

.. contents::

SciPy 1.6.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been a number of deprecations and API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning`` s).
Our development attention will now shift to bug-fix releases on the
1.6.x branch, and on adding new features on the master branch.

This release requires Python 3.7+ and NumPy 1.16.5 or greater.

For running on PyPy, PyPy3 6.0+ is required.

Highlights of this release
--------------------------

- `scipy.ndimage` improvements: Fixes and ehancements to boundary extension 
  modes for interpolation functions. Support for complex-valued inputs in many
  filtering and interpolation functions. New ``grid_mode`` option for 
  `scipy.ndimage.zoom` to enable results consistent with scikit-image's 
  ``rescale``.
- `scipy.optimize.linprog` has fast, new methods for large, sparse problems 
  from the ``HiGHS`` library.
- `scipy.stats` improvements including new distributions, a new test, and
  enhancements to existing distributions and tests


New features
============

`scipy.special` improvements
----------------------------
`scipy.special` now has improved support for 64-bit ``LAPACK`` backend

`scipy.odr` improvements
------------------------
`scipy.odr` now has support for 64-bit integer ``BLAS``

`scipy.odr.ODR` has gained an optional ``overwrite`` argument so that existing
files may be overwritten.

`scipy.integrate` improvements
------------------------------
Some renames of functions with poor names were done, with the old names 
retained without being in the reference guide for backwards compatibility 
reasons:
- ``integrate.simps`` was renamed to ``integrate.simpson``
- ``integrate.trapz`` was renamed to ``integrate.trapezoid``
- ``integrate.cumtrapz`` was renamed to ``integrate.cumulative_trapezoid``

`scipy.cluster` improvements
------------------------------
`scipy.cluster.hierarchy.DisjointSet` has been added for incremental 
connectivity queries.

`scipy.cluster.hierarchy.dendrogram` return value now also includes leaf color
information in `leaves_color_list`.

`scipy.interpolate` improvements
--------------------------------
`scipy.interpolate.interp1d` has a new method ``nearest-up``, similar to the 
existing method ``nearest`` but rounds half-integers up instead of down.

`scipy.io` improvements
-----------------------
Support has been added for reading arbitrary bit depth integer PCM WAV files 
from 1- to 32-bit, including the commonly-requested 24-bit depth.

`scipy.linalg` improvements
---------------------------
The new function `scipy.linalg.matmul_toeplitz` uses the FFT to compute the 
product of a Toeplitz matrix with another matrix.

`scipy.linalg.sqrtm` and `scipy.linalg.logm` have performance improvements
thanks to additional Cython code.

Python ``LAPACK`` wrappers have been added for ``pptrf``, ``pptrs``, ``ppsv``,
``pptri``, and ``ppcon``.

`scipy.linalg.norm` and the ``svd`` family of functions will now use 64-bit
integer backends when available.

`scipy.ndimage` improvements
----------------------------
`scipy.ndimage.convolve`, `scipy.ndimage.correlate` and their 1d counterparts 
now accept both complex-valued images and/or complex-valued filter kernels. All 
convolution-based filters also now accept complex-valued inputs 
(e.g. ``gaussian_filter``, ``uniform_filter``, etc.).

Multiple fixes and enhancements to boundary handling were introduced to 
`scipy.ndimage` interpolation functions (i.e. ``affine_transform``,
``geometric_transform``, ``map_coordinates``, ``rotate``, ``shift``, ``zoom``).

A new boundary mode, ``grid-wrap`` was added which wraps images periodically,
using a period equal to the shape of the input image grid. This is in contrast 
to the existing ``wrap`` mode which uses a period that is one sample smaller 
than the original signal extent along each dimension.

A long-standing bug in the ``reflect`` boundary condition has been fixed and 
the mode ``grid-mirror`` was introduced as a synonym for ``reflect``.

A new boundary mode, ``grid-constant`` is now available. This is similar to 
the existing ndimage ``constant`` mode, but interpolation will still performed 
at coordinate values outside of the original image extent. This 
``grid-constant`` mode is consistent with OpenCV's ``BORDER_CONSTANT`` mode 
and scikit-image's ``constant`` mode.

Spline pre-filtering (used internally by ``ndimage`` interpolation functions 
when ``order >= 2``), now supports all boundary modes rather than always 
defaulting to mirror boundary conditions. The standalone functions 
``spline_filter`` and ``spline_filter1d`` have analytical boundary conditions 
that match modes ``mirror``, ``grid-wrap`` and ``reflect``.

`scipy.ndimage` interpolation functions now accept complex-valued inputs. In
this case, the interpolation is applied independently to the real and 
imaginary components.

The ``ndimage`` tutorials 
(https://docs.scipy.org/doc/scipy/reference/tutorial/ndimage.html) have been 
updated with new figures to better clarify the exact behavior of all of the 
interpolation boundary modes.

`scipy.ndimage.zoom` now has a ``grid_mode`` option that changes the coordinate 
of the center of the first pixel along an axis from 0 to 0.5. This allows 
resizing in a manner that is consistent with the behavior of scikit-image's 
``resize`` and ``rescale`` functions (and OpenCV's ``cv2.resize``).

`scipy.optimize` improvements
-----------------------------
`scipy.optimize.linprog` has fast, new methods for large, sparse problems from 
the ``HiGHS`` C++ library. ``method='highs-ds'`` uses a high performance dual 
revised simplex implementation (HSOL), ``method='highs-ipm'`` uses an 
interior-point method with crossover, and ``method='highs'`` chooses between 
the two automatically. These methods are typically much faster and often exceed 
the accuracy of other ``linprog`` methods, so we recommend explicitly 
specifying one of these three method values when using ``linprog``.

`scipy.optimize.quadratic_assignment` has been added for approximate solution 
of the quadratic assignment problem.

`scipy.optimize.linear_sum_assignment` now has a substantially reduced overhead
for small cost matrix sizes

`scipy.optimize.least_squares` has improved performance when the user provides
the jacobian as a sparse jacobian already in ``csr_matrix`` format

`scipy.optimize.linprog` now has an ``rr_method`` argument for specification
of the method used for redundancy handling, and a new method for this purpose
is available based on the interpolative decomposition approach.

`scipy.signal` improvements
---------------------------
`scipy.signal.gammatone` has been added to design FIR or IIR filters that 
model the human auditory system.

`scipy.signal.iircomb` has been added to design IIR peaking/notching comb 
filters that can boost/attenuate a frequency from a signal.

`scipy.signal.sosfilt` performance has been improved to avoid some previously-
observed slowdowns

`scipy.signal.windows.taylor` has been added--the Taylor window function is
commonly used in radar digital signal processing

`scipy.signal.gauss_spline` now supports ``list`` type input for consistency
with other related SciPy functions

`scipy.signal.correlation_lags` has been added to allow calculation of the lag/
displacement indices array for 1D cross-correlation.

`scipy.sparse` improvements
---------------------------
A solver for the minimum weight full matching problem for bipartite graphs,
also known as the linear assignment problem, has been added in
`scipy.sparse.csgraph.min_weight_full_bipartite_matching`. In particular, this
provides functionality analogous to that of
`scipy.optimize.linear_sum_assignment`, but with improved performance for sparse
inputs, and the ability to handle inputs whose dense representations would not
fit in memory.

The time complexity of `scipy.sparse.block_diag` has been improved dramatically
from quadratic to linear.

`scipy.sparse.linalg` improvements
----------------------------------
The vendored version of ``SuperLU`` has been updated

`scipy.fft` improvements
------------------------

The vendored ``pocketfft`` library now supports compiling with ARM neon vector
extensions and has improved thread pool behavior.

`scipy.spatial` improvements
----------------------------
The python implementation of ``KDTree`` has been dropped and ``KDTree`` is now 
implemented in terms of ``cKDTree``. You can now expect ``cKDTree``-like 
performance by default. This also means ``sys.setrecursionlimit`` no longer 
needs to be increased for querying large trees.

``transform.Rotation`` has been updated with support for Modified Rodrigues 
Parameters alongside the existing rotation representations (PR gh-12667).

`scipy.spatial.transform.Rotation` has been partially cythonized, with some
performance improvements observed

`scipy.spatial.distance.cdist` has improved performance with the ``minkowski``
metric, especially for p-norm values of 1 or 2.

`scipy.stats` improvements
--------------------------
New distributions have been added to `scipy.stats`:

- The asymmetric Laplace continuous distribution has been added as 
  `scipy.stats.laplace_asymmetric`.
- The negative hypergeometric distribution has been added as `scipy.stats.nhypergeom`.
- The multivariate t distribution has been added as `scipy.stats.multivariate_t`.
- The multivariate hypergeometric distribution has been added as `scipy.stats.multivariate_hypergeom`.

The ``fit`` method has been overridden for several distributions (``laplace``,
``pareto``, ``rayleigh``, ``invgauss``, ``logistic``, ``gumbel_l``, 
``gumbel_r``); they now use analytical, distribution-specific maximum 
likelihood estimation results for greater speed and accuracy than the generic 
(numerical optimization) implementation.

The one-sample Cramér-von Mises test has been added as 
`scipy.stats.cramervonmises`.

An option to compute one-sided p-values was added to `scipy.stats.ttest_1samp`, 
`scipy.stats.ttest_ind_from_stats`, `scipy.stats.ttest_ind` and 
`scipy.stats.ttest_rel`.

The function `scipy.stats.kendalltau` now has an option to compute Kendall's 
tau-c (also known as Stuart's tau-c), and support has been added for exact
p-value calculations for sample sizes ``> 171``.

`stats.trapz` was renamed to `stats.trapezoid`, with the former name retained 
as an alias for backwards compatibility reasons.

The function `scipy.stats.linregress` now includes the standard error of the 
intercept in its return value.

The ``_logpdf``, ``_sf``, and ``_isf`` methods have been added to
`scipy.stats.nakagami`; ``_sf`` and ``_isf`` methods also added to
`scipy.stats.gumbel_r`

The ``sf`` method has been added to `scipy.stats.levy` and `scipy.stats.levy_l`
for improved precision.

`scipy.stats.binned_statistic_dd` performance improvements for the following
computed statistics: ``max``, ``min``, ``median``, and ``std``.

We gratefully acknowledge the Chan-Zuckerberg Initiative Essential Open Source 
Software for Science program for supporting many of these improvements to 
`scipy.stats`.

Deprecated features
===================

`scipy.spatial` changes
-----------------------
Calling ``KDTree.query`` with ``k=None`` to find all neighbours is deprecated. 
Use ``KDTree.query_ball_point`` instead.

``distance.wminkowski`` was deprecated; use ``distance.minkowski`` and supply 
weights with the ``w`` keyword instead.

Backwards incompatible changes
==============================

`scipy` changes
---------------
Using `scipy.fft` as a function aliasing ``numpy.fft.fft`` was removed after 
being deprecated in SciPy ``1.4.0``. As a result, the `scipy.fft` submodule 
must be explicitly imported now, in line with other SciPy subpackages.

`scipy.interpolate` changes
---------------------------

`scipy.linalg` changes
----------------------

`scipy.signal` changes
----------------------
The output of ``decimate``, ``lfilter_zi``, ``lfiltic``, ``sos2tf``, and 
``sosfilt_zi`` have been changed to match ``numpy.result_type`` of their inputs. 

The window function ``slepian`` was removed. It had been deprecated since SciPy 
``1.1``.

`scipy.spatial` changes
-----------------------
``cKDTree.query`` now returns 64-bit rather than 32-bit integers on Windows,
making behaviour consistent between platforms (PR gh-12673).


`scipy.stats` changes
---------------------
The ``frechet_l`` and ``frechet_r`` distributions were removed. They were 
deprecated since SciPy ``1.0``.

Other changes
=============
``setup_requires`` was removed from ``setup.py``. This means that users 
invoking ``python setup.py install`` without having numpy already installed 
will now get an error, rather than having numpy installed for them via 
``easy_install``. This install method was always fragile and problematic, users 
are encouraged to use ``pip`` when installing from source.

- Fixed a bug in `scipy.optimize.dual_annealing` ``accept_reject`` calculation 
  that caused uphill jumps to be accepted less frequently.
- The time required for (un)pickling of `scipy.stats.rv_continuous`, 
  `scipy.stats.rv_discrete`, and `scipy.stats.rv_frozen` has been significantly
  reduced (gh12550). Inheriting subclasses should note that ``__setstate__`` no 
  longer calls ``__init__`` upon unpickling.

Authors
=======

* @endolith
* @vkk800
* aditya +
* George Bateman +
* Christoph Baumgarten
* Peter Bell
* Tobias Biester +
* Keaton J. Burns +
* Evgeni Burovski
* Rüdiger Busche +
* Matthias Bussonnier
* Dominic C +
* Corallus Caninus +
* CJ Carey
* Thomas A Caswell
* chapochn +
* Lucía Cheung
* Zach Colbert +
* Coloquinte +
* Yannick Copin +
* Devin Crowley +
* Terry Davis +
* Michaël Defferrard +
* devonwp +
* Didier +
* divenex +
* Thomas Duvernay +
* Eoghan O'Connell +
* Gökçen Eraslan
* Kristian Eschenburg +
* Ralf Gommers
* Thomas Grainger +
* GreatV +
* Gregory Gundersen +
* h-vetinari +
* Matt Haberland
* Mark Harfouche +
* He He +
* Alex Henrie
* Chun-Ming Huang +
* Martin James McHugh III +
* Alex Izvorski +
* Joey +
* ST John +
* Jonas Jonker +
* Julius Bier Kirkegaard
* Marcin Konowalczyk +
* Konrad0
* Sam Van Kooten +
* Sergey Koposov +
* Peter Mahler Larsen
* Eric Larson
* Antony Lee
* Gregory R. Lee
* Loïc Estève
* Jean-Luc Margot +
* MarkusKoebis +
* Nikolay Mayorov
* G. D. McBain
* Andrew McCluskey +
* Nicholas McKibben
* Sturla Molden
* Denali Molitor +
* Eric Moore
* Shashaank N +
* Prashanth Nadukandi +
* nbelakovski +
* Andrew Nelson
* Nick +
* Nikola Forró +
* odidev
* ofirr +
* Sambit Panda
* Dima Pasechnik
* Tirth Patel +
* Matti Picus
* Paweł Redzyński +
* Vladimir Philipenko +
* Philipp Thölke +
* Ilhan Polat
* Eugene Prilepin +
* Vladyslav Rachek
* Ram Rachum +
* Tyler Reddy
* Martin Reinecke +
* Simon Segerblom Rex +
* Lucas Roberts
* Benjamin Rowell +
* Eli Rykoff +
* Atsushi Sakai
* Moritz Schulte +
* Daniel B. Smith
* Steve Smith +
* Jan Soedingrekso +
* Victor Stinner +
* Jose Storopoli +
* Diana Sukhoverkhova +
* Søren Fuglede Jørgensen
* taoky +
* Mike Taves +
* Ian Thomas +
* Will Tirone +
* Frank Torres +
* Seth Troisi
* Ronald van Elburg +
* Hugo van Kemenade
* Paul van Mulbregt
* Saul Ivan Rivas Vega +
* Pauli Virtanen
* Jan Vleeshouwers
* Samuel Wallan
* Warren Weckesser
* Ben West +
* Eric Wieser
* WillTirone +
* Levi John Wolf +
* Zhiqing Xiao
* Rory Yorke +
* Yun Wang (Maigo) +
* Egor Zemlyanoy +
* ZhihuiChen0903 +
* Jacob Zhong +

A total of 122 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.6.0
-----------------------

* `#1323 <https://github.com/scipy/scipy/issues/1323>`__: ndimage.shift destroys data from edges (Trac #796)
* `#1892 <https://github.com/scipy/scipy/issues/1892>`__: using rptfile= with an existing file causes a Fortran runtime...
* `#1903 <https://github.com/scipy/scipy/issues/1903>`__: ndimage.rotate misses some values (Trac #1378)
* `#1930 <https://github.com/scipy/scipy/issues/1930>`__: scipy.io.wavfile should be able to read 24 bit signed wave (Trac...
* `#3158 <https://github.com/scipy/scipy/issues/3158>`__: Odd casting behaviour of signal.filtfilt
* `#3203 <https://github.com/scipy/scipy/issues/3203>`__: interpolation.zoom incorrect output for certain cases
* `#3645 <https://github.com/scipy/scipy/issues/3645>`__: BUG: stats: mstats.pearsonr calculation is wrong if the masks...
* `#3665 <https://github.com/scipy/scipy/issues/3665>`__: Return Bunch objects from stats functions
* `#4922 <https://github.com/scipy/scipy/issues/4922>`__: unexpected zero output values from zoom
* `#5202 <https://github.com/scipy/scipy/issues/5202>`__: BUG: stats: Spurious warnings from the pdf method of several...
* `#5223 <https://github.com/scipy/scipy/issues/5223>`__: Zoom does not return the same values when resizing a sub-array...
* `#5396 <https://github.com/scipy/scipy/issues/5396>`__: scipy.spatial.distance.pdist documention bug
* `#5489 <https://github.com/scipy/scipy/issues/5489>`__: ValueError: failed to create intent(cache|hide)|optional array--...
* `#6096 <https://github.com/scipy/scipy/issues/6096>`__: loadmat drops dtype of empty arrays when squeeze_me=True
* `#6713 <https://github.com/scipy/scipy/issues/6713>`__: sicpy.ndimage.zoom returns artefacts and boundaries in some cases
* `#7125 <https://github.com/scipy/scipy/issues/7125>`__: Impossible to know number of dimensions in c function used by...
* `#7324 <https://github.com/scipy/scipy/issues/7324>`__: scipy.ndimage.zoom bad interpolation when downsampling (zoom...
* `#8131 <https://github.com/scipy/scipy/issues/8131>`__: BUG: geometric_transform wrap mode possible bug
* `#8163 <https://github.com/scipy/scipy/issues/8163>`__: LSMR fails on some random values when providing an x0
* `#8210 <https://github.com/scipy/scipy/issues/8210>`__: Why should I choose order > 1 for scipy.ndimage.zoom?
* `#8465 <https://github.com/scipy/scipy/issues/8465>`__: Unexpected behavior with reflect mode of ndimage.rotate
* `#8776 <https://github.com/scipy/scipy/issues/8776>`__: cdist behavior with Minkowsky and np.inf
* `#9168 <https://github.com/scipy/scipy/issues/9168>`__: documentation of pearson3 in scipy.stats unclear
* `#9223 <https://github.com/scipy/scipy/issues/9223>`__: Faster implementation of scipy.sparse.block_diag
* `#9476 <https://github.com/scipy/scipy/issues/9476>`__: Invalid index in signal.medfilt2d's QUICK_SELECT
* `#9857 <https://github.com/scipy/scipy/issues/9857>`__: scipy.odr.Output.sd_beta is not standard error
* `#9865 <https://github.com/scipy/scipy/issues/9865>`__: Strange behavior of \`ndimage.shift\` and \`ndimage.affine_transform\`
* `#10042 <https://github.com/scipy/scipy/issues/10042>`__: Consider support for multivariate student-t distribution?
* `#10134 <https://github.com/scipy/scipy/issues/10134>`__: gausshyper distribution accepts invalid parameters
* `#10179 <https://github.com/scipy/scipy/issues/10179>`__: str+bytes concatenation error in test_lapack.py
* `#10216 <https://github.com/scipy/scipy/issues/10216>`__: cKDTree.query_ball_point speed regression
* `#10463 <https://github.com/scipy/scipy/issues/10463>`__: ENH: vectorize scipy.fft for more CPU architectures
* `#10593 <https://github.com/scipy/scipy/issues/10593>`__: Rename \`sum\` ndimage function
* `#10595 <https://github.com/scipy/scipy/issues/10595>`__: scipy.stats.ttest_1samp should support alternative hypothesis
* `#10610 <https://github.com/scipy/scipy/issues/10610>`__: ndimage.interpolation.spline_filter1d default value of mode
* `#10620 <https://github.com/scipy/scipy/issues/10620>`__: ndimage.interpolation.zoom() option to work like skimage.transform.resize()
* `#10711 <https://github.com/scipy/scipy/issues/10711>`__: Array Shapes Not Aligned Bug in scipy.optimize._lsq.lsq_linear.py
* `#10782 <https://github.com/scipy/scipy/issues/10782>`__: BUG: optimize: methods unknown to \`scipy.optimize.show_options\`
* `#10892 <https://github.com/scipy/scipy/issues/10892>`__: Possible typo in an equation of optimize/dual_annealing
* `#11020 <https://github.com/scipy/scipy/issues/11020>`__: signal.fftconvolve return a tuple including lag information
* `#11093 <https://github.com/scipy/scipy/issues/11093>`__: scipy.interpolate.interp1d can not handle datetime64
* `#11170 <https://github.com/scipy/scipy/issues/11170>`__: Use manylinux2014 to get aarch64/ppc64le support
* `#11186 <https://github.com/scipy/scipy/issues/11186>`__: BUG: stats: pearson3 CDF and SF functions incorrect when skew...
* `#11366 <https://github.com/scipy/scipy/issues/11366>`__: DeprecationWarning due to invalid escape sequences
* `#11403 <https://github.com/scipy/scipy/issues/11403>`__: Optimize raises "ValueError: \`x0\` violates bound constraints"...
* `#11558 <https://github.com/scipy/scipy/issues/11558>`__: ENH: IIR comb filter
* `#11559 <https://github.com/scipy/scipy/issues/11559>`__: BUG: iirdesign doesn't fail for frequencies above Nyquist
* `#11567 <https://github.com/scipy/scipy/issues/11567>`__: scipy.signal.iirdesign doesn't check consistency of wp and ws...
* `#11654 <https://github.com/scipy/scipy/issues/11654>`__: ENH: Add Negative Hypergeometric Distribution
* `#11720 <https://github.com/scipy/scipy/issues/11720>`__: BUG: stats: wrong shape from median_absolute_deviation for arrays...
* `#11746 <https://github.com/scipy/scipy/issues/11746>`__: BUG: stats: pearson3 returns size 1 arrays where other distributions...
* `#11756 <https://github.com/scipy/scipy/issues/11756>`__: Improve and fix \*Spline docstrings and code
* `#11758 <https://github.com/scipy/scipy/issues/11758>`__: BUG: of scipy.interpolate.CubicSpline when \`bc_type' is set...
* `#11925 <https://github.com/scipy/scipy/issues/11925>`__: MAINT: remove character encoding check in CI?
* `#11963 <https://github.com/scipy/scipy/issues/11963>`__: Test failures - TestLinprogIPSparseCholmod
* `#12102 <https://github.com/scipy/scipy/issues/12102>`__: incorrect first moment of non central t-distribution
* `#12113 <https://github.com/scipy/scipy/issues/12113>`__: scipy.stats.poisson docs for rate = 0
* `#12152 <https://github.com/scipy/scipy/issues/12152>`__: ENH: signal.gauss_spline should accept a list
* `#12157 <https://github.com/scipy/scipy/issues/12157>`__: BUG: Iteration index initialisation is wrong in scipy.optimize.linesearch.scalar_search_wolfe2
* `#12162 <https://github.com/scipy/scipy/issues/12162>`__: Storing Rotation object in NumPy array returns an array with...
* `#12176 <https://github.com/scipy/scipy/issues/12176>`__: cannot modify the slice of an array returned by \`wavfile.read\`
* `#12190 <https://github.com/scipy/scipy/issues/12190>`__: retrieve leave colors from dendrogram
* `#12196 <https://github.com/scipy/scipy/issues/12196>`__: PERF: scipy.linalg.pinv is very slow compared to numpy.linalg.pinv
* `#12222 <https://github.com/scipy/scipy/issues/12222>`__: Interpolating categorical data (interp1d)
* `#12231 <https://github.com/scipy/scipy/issues/12231>`__: Is the p-value of the Kruskal-Wallis test two-sided?
* `#12249 <https://github.com/scipy/scipy/issues/12249>`__: ENH: least_squares: should not re-instanciate csr_matrix if already...
* `#12264 <https://github.com/scipy/scipy/issues/12264>`__: DOC: optimize: linprog method-specific function signature
* `#12290 <https://github.com/scipy/scipy/issues/12290>`__: DOC: Convex Hull areas are actually perimeters for 2-dimensional...
* `#12308 <https://github.com/scipy/scipy/issues/12308>`__: integrate.solve_ivp with DOP853 method fails when yDot = 0
* `#12326 <https://github.com/scipy/scipy/issues/12326>`__: BUG: stats.exponnorm.pdf returns 0 for small K
* `#12337 <https://github.com/scipy/scipy/issues/12337>`__: scipy.sparse.linalg.eigsh documentation is misleading
* `#12339 <https://github.com/scipy/scipy/issues/12339>`__: scipy.io.wavfile.write documentation has wrong example
* `#12340 <https://github.com/scipy/scipy/issues/12340>`__: sparse.lil_matrix.tocsr() fails silently on matrices with nzn...
* `#12350 <https://github.com/scipy/scipy/issues/12350>`__: Create a 2-parameter version of the gamma distribution
* `#12369 <https://github.com/scipy/scipy/issues/12369>`__: scipy.signal.correlate has an error in the documentation, examples...
* `#12373 <https://github.com/scipy/scipy/issues/12373>`__: interp1d returns incorrect values for step functions
* `#12378 <https://github.com/scipy/scipy/issues/12378>`__: interpolate.NearestNDInterpolator.__call__ & LinearNDInterpolator.__call__...
* `#12411 <https://github.com/scipy/scipy/issues/12411>`__: scipy.stats.spearmanr mishandles nan variables with "propogate"
* `#12413 <https://github.com/scipy/scipy/issues/12413>`__: DOC: Remove the "Basic functions" section from the SciPy tutorial.
* `#12415 <https://github.com/scipy/scipy/issues/12415>`__: scipy.stats.dirichlet documentation issue
* `#12419 <https://github.com/scipy/scipy/issues/12419>`__: least_squares ValueError with 'lm' method - regression from 1.4.1...
* `#12431 <https://github.com/scipy/scipy/issues/12431>`__: Request for Python wrapper for LAPACK's ?pptrf (Cholesky factorization...
* `#12458 <https://github.com/scipy/scipy/issues/12458>`__: spearmanr with entire NaN columns produces errors
* `#12477 <https://github.com/scipy/scipy/issues/12477>`__: WIP: Addition of MLE for stats.invgauss/wald
* `#12483 <https://github.com/scipy/scipy/issues/12483>`__: reading .wav fails when the file is too big on python 3.6.0
* `#12490 <https://github.com/scipy/scipy/issues/12490>`__: BUG: stats: logistic and genlogistic logpdf overflow for large...
* `#12499 <https://github.com/scipy/scipy/issues/12499>`__: LinearNDInterpolator raises ValueError when value array has writeable=False...
* `#12523 <https://github.com/scipy/scipy/issues/12523>`__: Wrong key in __odrpack.c
* `#12547 <https://github.com/scipy/scipy/issues/12547>`__: typo in scipy/cluster/_hierarchy.pyx
* `#12549 <https://github.com/scipy/scipy/issues/12549>`__: DOC: least_squares return type is poorly formatted.
* `#12578 <https://github.com/scipy/scipy/issues/12578>`__: TST: test_bounds_infeasible_2 failing on wheels repo cron jobs
* `#12585 <https://github.com/scipy/scipy/issues/12585>`__: ENH: Add Multivariate Hypergeometric Distribution
* `#12604 <https://github.com/scipy/scipy/issues/12604>`__: unintuitive conversion in \`scipy.constants.lambda2nu\`
* `#12606 <https://github.com/scipy/scipy/issues/12606>`__: DOC: Invalid syntax in example.
* `#12665 <https://github.com/scipy/scipy/issues/12665>`__: List of possible bugs found by automated code analysis
* `#12696 <https://github.com/scipy/scipy/issues/12696>`__: scipy.optimize.fminbound, numpy depreciation warning Creating...
* `#12699 <https://github.com/scipy/scipy/issues/12699>`__: TestProjections.test_iterative_refinements_dense failure
* `#12701 <https://github.com/scipy/scipy/issues/12701>`__: TestDifferentialEvolutionSolver::test_L4 failing
* `#12719 <https://github.com/scipy/scipy/issues/12719>`__: Misleading scipy.signal.get_window() docstring with 'exponential'...
* `#12740 <https://github.com/scipy/scipy/issues/12740>`__: circstd doesn't handle R = hypot(S, C) > 1
* `#12749 <https://github.com/scipy/scipy/issues/12749>`__: ENH: interp1d Matlab compatibility
* `#12773 <https://github.com/scipy/scipy/issues/12773>`__: Meta-issue: ndimage spline boundary handling (NumFOCUS proposal)
* `#12813 <https://github.com/scipy/scipy/issues/12813>`__: optimize.root(method="krylov") fails if options["tol_norm"] expects...
* `#12815 <https://github.com/scipy/scipy/issues/12815>`__: stats.zscore inconsistent behavior when all values are the same
* `#12840 <https://github.com/scipy/scipy/issues/12840>`__: scipy.signal.windows.dpss docstring typo
* `#12874 <https://github.com/scipy/scipy/issues/12874>`__: Rotation.random vs stats.special_ortho_group
* `#12881 <https://github.com/scipy/scipy/issues/12881>`__: FFT - documentation - examples - linspace construction
* `#12904 <https://github.com/scipy/scipy/issues/12904>`__: BUG: parsing in loadarff()
* `#12917 <https://github.com/scipy/scipy/issues/12917>`__: GitHub Actions nightly build triggered on forks
* `#12919 <https://github.com/scipy/scipy/issues/12919>`__: BUG: numerical precision, use gammaln in nct.mean
* `#12924 <https://github.com/scipy/scipy/issues/12924>`__: Rename Sample Based Integration Methods to Comply with Code of...
* `#12940 <https://github.com/scipy/scipy/issues/12940>`__: Should the minimum numpy for AIX be bumped to 1.16.5
* `#12951 <https://github.com/scipy/scipy/issues/12951>`__: A possible typo in scipy.stats.weightedtau
* `#12952 <https://github.com/scipy/scipy/issues/12952>`__: [Documentation question] Would it be more precise to specify...
* `#12970 <https://github.com/scipy/scipy/issues/12970>`__: Documentation presents second order sections as the correct choice...
* `#12982 <https://github.com/scipy/scipy/issues/12982>`__: Calculate standard error of the intercept in linregress
* `#12985 <https://github.com/scipy/scipy/issues/12985>`__: Possible wrong link in scipy.stats.wilcoxon doc
* `#12991 <https://github.com/scipy/scipy/issues/12991>`__: least_squares broken with float32
* `#13001 <https://github.com/scipy/scipy/issues/13001>`__: \`OptimizeResult.message\` from \`L-BFGS-B\` is a bytes, not...
* `#13030 <https://github.com/scipy/scipy/issues/13030>`__: BUG: lint_diff.py still fails for backport PRs
* `#13077 <https://github.com/scipy/scipy/issues/13077>`__: CI: codecov proper patch diffs
* `#13085 <https://github.com/scipy/scipy/issues/13085>`__: Build failing on main branch after HiGHS solver merge
* `#13088 <https://github.com/scipy/scipy/issues/13088>`__: BLD, BUG: wheel builds failure with HiGHS/optimize
* `#13099 <https://github.com/scipy/scipy/issues/13099>`__: Wrong output format for empty sparse results of kron
* `#13108 <https://github.com/scipy/scipy/issues/13108>`__: TST, CI: GitHub Actions MacOS Failures
* `#13111 <https://github.com/scipy/scipy/issues/13111>`__: BUG, DOC: refguide check is failing
* `#13127 <https://github.com/scipy/scipy/issues/13127>`__: ODR output file writing broken in conda env with system compilers
* `#13134 <https://github.com/scipy/scipy/issues/13134>`__: FromTravis migration tracker
* `#13140 <https://github.com/scipy/scipy/issues/13140>`__: BUG: signal: \`ss2tf\` incorrectly truncates output to integers.
* `#13179 <https://github.com/scipy/scipy/issues/13179>`__: CI: lint is failing because of output to stderr
* `#13182 <https://github.com/scipy/scipy/issues/13182>`__: Key appears twice in \`test_optimize.test_show_options\`
* `#13191 <https://github.com/scipy/scipy/issues/13191>`__: \`scipy.linalg.lapack.dgesjv\` overwrites original arrays if...
* `#13207 <https://github.com/scipy/scipy/issues/13207>`__: TST: Erratic test failure in test_cossin_separate
* `#13221 <https://github.com/scipy/scipy/issues/13221>`__: BUG: pavement.py glitch
* `#13239 <https://github.com/scipy/scipy/issues/13239>`__: Segmentation fault with \`eigh(..., driver="evx")\` for 10x10...
* `#13248 <https://github.com/scipy/scipy/issues/13248>`__: ndimage: improper cval handling for complex-valued inputs

Pull requests for 1.6.0
-----------------------

* `#8032 <https://github.com/scipy/scipy/pull/8032>`__: ENH: Add in taylor window common in Radar processing
* `#8779 <https://github.com/scipy/scipy/pull/8779>`__: CI: Run benchmarks
* `#9361 <https://github.com/scipy/scipy/pull/9361>`__: ENH: Add Kendall's tau-a and tau-c variants to scipy.stats.kendalltau()
* `#11068 <https://github.com/scipy/scipy/pull/11068>`__: ENH: Adds correlation_lags function to scipy.signal
* `#11119 <https://github.com/scipy/scipy/pull/11119>`__: ENH: add Cramer-von-Mises (one-sample) test to scipy.stats
* `#11249 <https://github.com/scipy/scipy/pull/11249>`__: ENH: optimize: interpolative decomposition redundancy removal...
* `#11346 <https://github.com/scipy/scipy/pull/11346>`__: ENH: add fast toeplitz matrix multiplication using FFT
* `#11413 <https://github.com/scipy/scipy/pull/11413>`__: ENH: Multivariate t-distribution (stale)
* `#11563 <https://github.com/scipy/scipy/pull/11563>`__: ENH: exact p-value in stats.kendalltau() for sample sizes > 171
* `#11691 <https://github.com/scipy/scipy/pull/11691>`__: ENH: add a stack of reversal functions to linprog
* `#12043 <https://github.com/scipy/scipy/pull/12043>`__: ENH: optimize: add HiGHS methods to linprog - continued
* `#12061 <https://github.com/scipy/scipy/pull/12061>`__: Check parameter consistensy in signal.iirdesign
* `#12067 <https://github.com/scipy/scipy/pull/12067>`__: MAINT: Cleanup OLDAPI in ndimage/src/_ctest.c
* `#12069 <https://github.com/scipy/scipy/pull/12069>`__: DOC: Add developer guidelines for implementing the nan_policy...
* `#12077 <https://github.com/scipy/scipy/pull/12077>`__: MAINT: malloc return value checks for cython
* `#12080 <https://github.com/scipy/scipy/pull/12080>`__: MAINT: Remove suppress_warnings
* `#12085 <https://github.com/scipy/scipy/pull/12085>`__: ENH: special: support ILP64 Lapack
* `#12086 <https://github.com/scipy/scipy/pull/12086>`__: MAINT: Cleanup PyMODINIT_FUNC used during 2to3
* `#12097 <https://github.com/scipy/scipy/pull/12097>`__: ENH: stats: override stats.rayleigh.fit with analytical MLE
* `#12112 <https://github.com/scipy/scipy/pull/12112>`__: DOC: Improve integrate.nquad docstring
* `#12125 <https://github.com/scipy/scipy/pull/12125>`__: TST: Add a test for stats.gmean with negative input
* `#12139 <https://github.com/scipy/scipy/pull/12139>`__: TST: Reduce flakiness in lsmr test
* `#12142 <https://github.com/scipy/scipy/pull/12142>`__: DOC: add a note in poisson distribution when mu=0 and k=0 in...
* `#12144 <https://github.com/scipy/scipy/pull/12144>`__: DOC: Update ndimage.morphology.distance_transform\*
* `#12154 <https://github.com/scipy/scipy/pull/12154>`__: ENH: scipy.signal: allow lists in gauss_spline
* `#12170 <https://github.com/scipy/scipy/pull/12170>`__: ENH: scipy.stats: add negative hypergeometric distribution
* `#12177 <https://github.com/scipy/scipy/pull/12177>`__: MAINT: Correctly add input line to ValueError
* `#12183 <https://github.com/scipy/scipy/pull/12183>`__: ENH: Use fromfile where possible
* `#12186 <https://github.com/scipy/scipy/pull/12186>`__: MAINT: generalize tests in SphericalVoronoi
* `#12198 <https://github.com/scipy/scipy/pull/12198>`__: TST: Fix str + bytes error
* `#12199 <https://github.com/scipy/scipy/pull/12199>`__: ENH: match np.result_type behaviour in some scipy.signal functions
* `#12200 <https://github.com/scipy/scipy/pull/12200>`__: ENH: add FIR and IIR gammatone filters to scipy.signal
* `#12204 <https://github.com/scipy/scipy/pull/12204>`__: ENH: Add overwrite argument for odr.ODR() and its test.
* `#12206 <https://github.com/scipy/scipy/pull/12206>`__: MAINT:lstsq: Switch to tranposed problem if the array is tall
* `#12208 <https://github.com/scipy/scipy/pull/12208>`__: wavfile bugfixes and maintenance
* `#12214 <https://github.com/scipy/scipy/pull/12214>`__: DOC: fix docstring of "sd_beta" of odr.Output.
* `#12234 <https://github.com/scipy/scipy/pull/12234>`__: MAINT: prevent divide by zero warnings in scipy.optimize BFGS...
* `#12235 <https://github.com/scipy/scipy/pull/12235>`__: REL: set version to 1.6.0.dev0
* `#12237 <https://github.com/scipy/scipy/pull/12237>`__: BUG: Fix exit condition for QUICK_SELECT pivot
* `#12242 <https://github.com/scipy/scipy/pull/12242>`__: ENH: Rename ndimage.sum to ndimage.sum_labels (keep sum as alias)
* `#12243 <https://github.com/scipy/scipy/pull/12243>`__: EHN: Update SuperLU
* `#12244 <https://github.com/scipy/scipy/pull/12244>`__: MAINT: stats: avoid spurious warnings in ncx2.pdf
* `#12245 <https://github.com/scipy/scipy/pull/12245>`__: DOC: Fixed incorrect default for mode in scipy.ndimage.spline_filter1d
* `#12248 <https://github.com/scipy/scipy/pull/12248>`__: MAINT: clean up pavement.py
* `#12250 <https://github.com/scipy/scipy/pull/12250>`__: ENH: Replaced csr_matrix() by tocsr() and complemented docstring
* `#12253 <https://github.com/scipy/scipy/pull/12253>`__: TST, CI: turn on codecov patch diffs
* `#12259 <https://github.com/scipy/scipy/pull/12259>`__: MAINT: Remove duplicated test for import cycles
* `#12263 <https://github.com/scipy/scipy/pull/12263>`__: ENH: Rename LocalSearchWrapper bounds
* `#12265 <https://github.com/scipy/scipy/pull/12265>`__: BUG optimize: Accept np.matrix in lsq_linear
* `#12266 <https://github.com/scipy/scipy/pull/12266>`__: BUG: Fix paren error in dual annealing accept_reject calculation
* `#12269 <https://github.com/scipy/scipy/pull/12269>`__: MAINT: Included mismatched shapes in error messages.
* `#12279 <https://github.com/scipy/scipy/pull/12279>`__: MAINT: \`__array__\` and array protocols cannot be used in sparse.
* `#12281 <https://github.com/scipy/scipy/pull/12281>`__: DOC: update wheel DL docs
* `#12283 <https://github.com/scipy/scipy/pull/12283>`__: ENH: odr: ILP64 Blas support in ODR
* `#12284 <https://github.com/scipy/scipy/pull/12284>`__: ENH: linalg: support for ILP64 BLAS/LAPACK in f2py wrappers
* `#12286 <https://github.com/scipy/scipy/pull/12286>`__: ENH: Cythonize scipy.spatial.transform.Rotation
* `#12287 <https://github.com/scipy/scipy/pull/12287>`__: ENH: Read arbitrary bit depth (including 24-bit) WAVs
* `#12292 <https://github.com/scipy/scipy/pull/12292>`__: BLD: fix musl compilation
* `#12293 <https://github.com/scipy/scipy/pull/12293>`__: MAINT: Fix a DeprecationWarning in validate_runtests_log.py.
* `#12296 <https://github.com/scipy/scipy/pull/12296>`__: DOC: Clarify area/volume in scipy.spatial.ConvexHull docstrings
* `#12302 <https://github.com/scipy/scipy/pull/12302>`__: CI: Run travis builds on master to keep cache up to date
* `#12305 <https://github.com/scipy/scipy/pull/12305>`__: TST: Cleanup print statements in tests
* `#12323 <https://github.com/scipy/scipy/pull/12323>`__: ENH: Add a Bunch-like class to use as a backwards compatible...
* `#12324 <https://github.com/scipy/scipy/pull/12324>`__: BUG: io: Fix an error that occurs when attempting to raise a...
* `#12327 <https://github.com/scipy/scipy/pull/12327>`__: DOC: clarify docstrings of \`query_ball_tree\` and \`query_pairs\`
* `#12334 <https://github.com/scipy/scipy/pull/12334>`__: PERF: Improve cKDTree.query_ball_point constant time cython overhead
* `#12338 <https://github.com/scipy/scipy/pull/12338>`__: DOC: improve consistency and clarity of docs in linalg and sparse/linalg
* `#12341 <https://github.com/scipy/scipy/pull/12341>`__: DOC: add Examples for KDTree query_ball_tree and query_pairs
* `#12343 <https://github.com/scipy/scipy/pull/12343>`__: DOC: add examples for special.eval_legendre()
* `#12349 <https://github.com/scipy/scipy/pull/12349>`__: BUG: avoid overflow in sum() for 32-bit systems
* `#12351 <https://github.com/scipy/scipy/pull/12351>`__: DOC: Fix example wavfile to be 16bit
* `#12352 <https://github.com/scipy/scipy/pull/12352>`__: [BUG] Consider 0/0 division in DOP853 error estimation
* `#12353 <https://github.com/scipy/scipy/pull/12353>`__: Fix exception causes in vq.py
* `#12354 <https://github.com/scipy/scipy/pull/12354>`__: MAINT: Cleanup unneeded void\* cast in setlist.pxd
* `#12355 <https://github.com/scipy/scipy/pull/12355>`__: TST: Remove hack for old win-amd64 bug
* `#12356 <https://github.com/scipy/scipy/pull/12356>`__: ENH: Faster implementation of scipy.sparse.block_diag (#9411...
* `#12357 <https://github.com/scipy/scipy/pull/12357>`__: MAINT,TST: update and run scipy/special/utils/convert.py
* `#12358 <https://github.com/scipy/scipy/pull/12358>`__: TST: Check mstat.skewtest pvalue
* `#12359 <https://github.com/scipy/scipy/pull/12359>`__: TST: Sparse matrix test with int64 indptr and indices
* `#12363 <https://github.com/scipy/scipy/pull/12363>`__: DOC: ref. in CloughTocher2DInterpolator
* `#12364 <https://github.com/scipy/scipy/pull/12364>`__: DOC: \`sparse_distance_matrix\` and \`count_neighbors\` examples
* `#12371 <https://github.com/scipy/scipy/pull/12371>`__: MAINT, CI: bump to latest stable OpenBLAS
* `#12372 <https://github.com/scipy/scipy/pull/12372>`__: MAINT: Minor cleanup of (c)KDTree tests
* `#12374 <https://github.com/scipy/scipy/pull/12374>`__: DEP: Deprecate \`distance.wminkowski\`
* `#12375 <https://github.com/scipy/scipy/pull/12375>`__: ENH: Add fast path for minkowski distance with p=1,2 and support...
* `#12376 <https://github.com/scipy/scipy/pull/12376>`__: Fix exception causes in most of the codebase
* `#12377 <https://github.com/scipy/scipy/pull/12377>`__: DOC: Quick fix - adds newline to correlation_lags docstring Examples...
* `#12381 <https://github.com/scipy/scipy/pull/12381>`__: BENCH: remove obsolete goal_time param
* `#12382 <https://github.com/scipy/scipy/pull/12382>`__: ENH: Replace KDTree with a thin wrapper over cKDTree
* `#12385 <https://github.com/scipy/scipy/pull/12385>`__: DOC: improve docstrings of interpolate.NearestNDInterpolator.__call__...
* `#12387 <https://github.com/scipy/scipy/pull/12387>`__: DOC/STY: add example to scipy.signal.correlate
* `#12393 <https://github.com/scipy/scipy/pull/12393>`__: CI: Replace the existing check for non-ASCII characters with...
* `#12394 <https://github.com/scipy/scipy/pull/12394>`__: CI: arm64 numpy now available
* `#12395 <https://github.com/scipy/scipy/pull/12395>`__: ENH: improve stats.binned_statistic_dd performance
* `#12396 <https://github.com/scipy/scipy/pull/12396>`__: DOC, MAINT: forward port 1.5.0 relnotes
* `#12398 <https://github.com/scipy/scipy/pull/12398>`__: API: Disable len() and indexing of Rotation instances with single...
* `#12399 <https://github.com/scipy/scipy/pull/12399>`__: MAINT: Replace some Unicode dash-like chars with an ASCII hyphen.
* `#12402 <https://github.com/scipy/scipy/pull/12402>`__: update .mailmap
* `#12404 <https://github.com/scipy/scipy/pull/12404>`__: MAINT: io: Change the encoding comment of test_mio.py to utf-8.
* `#12416 <https://github.com/scipy/scipy/pull/12416>`__: CI: cache mingw, azure pipelines
* `#12427 <https://github.com/scipy/scipy/pull/12427>`__: BUG: logic error in loop unrolling (cKDTree)
* `#12432 <https://github.com/scipy/scipy/pull/12432>`__: DOC: Remove the "Basic functions" section from the SciPy tutorial.
* `#12434 <https://github.com/scipy/scipy/pull/12434>`__: ENH:linalg: Add LAPACK wrappers pptrf/pptrs/ppsv/pptri/ppcon
* `#12435 <https://github.com/scipy/scipy/pull/12435>`__: DOC: fix simplex math for scipy.stats.dirichlet documentation
* `#12439 <https://github.com/scipy/scipy/pull/12439>`__: DOC: add API methods summary for NdPPoly
* `#12443 <https://github.com/scipy/scipy/pull/12443>`__: BUG: stats: Improve calculation of exponnorm.pdf
* `#12448 <https://github.com/scipy/scipy/pull/12448>`__: DOC: stats: Add "Examples" to the ansari docstring.
* `#12450 <https://github.com/scipy/scipy/pull/12450>`__: ENH: add \`leaves_color_list\` for cluster.dendrogram dictionary.
* `#12451 <https://github.com/scipy/scipy/pull/12451>`__: MAINT: remove "blacklist" terminology from code base
* `#12452 <https://github.com/scipy/scipy/pull/12452>`__: DOC: clarify the meaning of whitening for cluster.vq.whiten()
* `#12455 <https://github.com/scipy/scipy/pull/12455>`__: MAINT: clearer error message in setup.py
* `#12457 <https://github.com/scipy/scipy/pull/12457>`__: ENH: stats: override stats.pareto.fit with analytical MLE
* `#12460 <https://github.com/scipy/scipy/pull/12460>`__: check if column in spearman rho is entirely NaN or Inf
* `#12463 <https://github.com/scipy/scipy/pull/12463>`__: DOC: improve and clean up \*Spline docstrings in fitpack2.py
* `#12474 <https://github.com/scipy/scipy/pull/12474>`__: ENH: linalg: speedup _sqrtm_triu by moving tight loop to Cython
* `#12476 <https://github.com/scipy/scipy/pull/12476>`__: ENH: add IIR comb filter to scipy.signal
* `#12484 <https://github.com/scipy/scipy/pull/12484>`__: Fix documentation for minimize
* `#12486 <https://github.com/scipy/scipy/pull/12486>`__: DOC: add a note in poisson distribution when mu=0 and k=0 in...
* `#12491 <https://github.com/scipy/scipy/pull/12491>`__: MAINT: forward port 1.5.1 release notes
* `#12508 <https://github.com/scipy/scipy/pull/12508>`__: Fix exception causes all over the codebase
* `#12514 <https://github.com/scipy/scipy/pull/12514>`__: ENH: stats: override stats.invgauss.fit with analytical MLE
* `#12519 <https://github.com/scipy/scipy/pull/12519>`__: PERF: Avoid np.zeros when custom initialization is needed anyway
* `#12520 <https://github.com/scipy/scipy/pull/12520>`__: DOC: Minor RST section renaming.
* `#12521 <https://github.com/scipy/scipy/pull/12521>`__: MAINT: Remove unused imports
* `#12522 <https://github.com/scipy/scipy/pull/12522>`__: PERF: Get rid of unnececssary allocation in VarReader5.cread_fieldnames
* `#12524 <https://github.com/scipy/scipy/pull/12524>`__: DOC: special: Set Axes3D rect to avoid clipping labels in plot.
* `#12525 <https://github.com/scipy/scipy/pull/12525>`__: Fix large sparse nnz
* `#12526 <https://github.com/scipy/scipy/pull/12526>`__: DOC: Remove double section and too long header underline.
* `#12527 <https://github.com/scipy/scipy/pull/12527>`__: Improve error message for wrong interpolation type
* `#12530 <https://github.com/scipy/scipy/pull/12530>`__: Move redundant logic outside loop for conditional speedup in...
* `#12532 <https://github.com/scipy/scipy/pull/12532>`__: ENH: Add norm={"forward", "backward"} to \`scipy.fft\`
* `#12535 <https://github.com/scipy/scipy/pull/12535>`__: MAINT: Avoid sphinx deprecated aliases for SeeAlso and Only
* `#12540 <https://github.com/scipy/scipy/pull/12540>`__: BUG: fix odr.output.work_ind key bug and add its test.
* `#12541 <https://github.com/scipy/scipy/pull/12541>`__: ENH: add solver for minimum weight full bipartite matching
* `#12550 <https://github.com/scipy/scipy/pull/12550>`__: PERF: pickling speed of rv\*
* `#12551 <https://github.com/scipy/scipy/pull/12551>`__: DOC: fix typo in cluster/_hierarchy.pyx
* `#12552 <https://github.com/scipy/scipy/pull/12552>`__: CI: Cleanup travis pip installs
* `#12556 <https://github.com/scipy/scipy/pull/12556>`__: BUG: Fix problem with Scipy.integrate.solve_bvp for big problems
* `#12557 <https://github.com/scipy/scipy/pull/12557>`__: MAINT: Use extern templates to improve sparsetools compile time
* `#12558 <https://github.com/scipy/scipy/pull/12558>`__: MAINT: Remove hack to allow scipy.fft to act like a function
* `#12563 <https://github.com/scipy/scipy/pull/12563>`__: MAINT: Remove unused mu0 in special/orthogonal.py
* `#12564 <https://github.com/scipy/scipy/pull/12564>`__: DOC: fix return type docstring for least_squares
* `#12565 <https://github.com/scipy/scipy/pull/12565>`__: DOC: stats: respond to query about Kruskal-Wallis test being...
* `#12566 <https://github.com/scipy/scipy/pull/12566>`__: BUG: Interpolate: use stable sort
* `#12568 <https://github.com/scipy/scipy/pull/12568>`__: Updated documentation for as_quat
* `#12571 <https://github.com/scipy/scipy/pull/12571>`__: DEP: remove deprecated slepian window
* `#12573 <https://github.com/scipy/scipy/pull/12573>`__: DEP: remove \`frechet_l\` and \`frechet_r\`
* `#12575 <https://github.com/scipy/scipy/pull/12575>`__: BUG: stats: fix multinomial.pmf NaNs when params sum > 1
* `#12576 <https://github.com/scipy/scipy/pull/12576>`__: MAINT: remove warning from LSQSphereBivariateSpline
* `#12582 <https://github.com/scipy/scipy/pull/12582>`__: ENH: Multivariate t-distribution
* `#12587 <https://github.com/scipy/scipy/pull/12587>`__: ENH: speed up rvs of gengamma in scipy.stats
* `#12588 <https://github.com/scipy/scipy/pull/12588>`__: DOC: add Examples add see also sections for LinearNDInterpolator,...
* `#12597 <https://github.com/scipy/scipy/pull/12597>`__: ENH: Add single-sided p-values to t-tests
* `#12599 <https://github.com/scipy/scipy/pull/12599>`__: Small update to scipy FFT tutorial
* `#12600 <https://github.com/scipy/scipy/pull/12600>`__: ENH: disjoint set data structure
* `#12602 <https://github.com/scipy/scipy/pull/12602>`__: BUG: add const for Read-only views in interpnd.pyx
* `#12605 <https://github.com/scipy/scipy/pull/12605>`__: BUG: correct \`np.asanyarray\` use in \`scipy.constants.lambda2nu\`
* `#12610 <https://github.com/scipy/scipy/pull/12610>`__: MAINT: forward port 1.5.2 release notes
* `#12612 <https://github.com/scipy/scipy/pull/12612>`__: MAINT: stats: Use explicit keyword parameters instead of \`\*\*kwds\`.
* `#12616 <https://github.com/scipy/scipy/pull/12616>`__: DOC: make explicit docstring that interpolate.interp1d only accepts...
* `#12618 <https://github.com/scipy/scipy/pull/12618>`__: DOC: Minor doc formatting.
* `#12640 <https://github.com/scipy/scipy/pull/12640>`__: MAINT: stats: fix issues with scipy.stats.pearson3 docs, moment,...
* `#12647 <https://github.com/scipy/scipy/pull/12647>`__: TST: Add Boost ellipr[cdfgj]_data test data
* `#12648 <https://github.com/scipy/scipy/pull/12648>`__: DOC: Update special/utils/README with instructions
* `#12649 <https://github.com/scipy/scipy/pull/12649>`__: DOC: simplified pip quickstart guide
* `#12650 <https://github.com/scipy/scipy/pull/12650>`__: DOC: stats: Fix boxcox docstring: lambda can be negative.
* `#12655 <https://github.com/scipy/scipy/pull/12655>`__: DOC: update Steering Council members listed in governance docs
* `#12659 <https://github.com/scipy/scipy/pull/12659>`__: rv_sample expect bug
* `#12663 <https://github.com/scipy/scipy/pull/12663>`__: DOC: optimize: try to fix linprog method-specific documentation
* `#12664 <https://github.com/scipy/scipy/pull/12664>`__: BUG: stats: Fix logpdf with large negative values for logistic...
* `#12666 <https://github.com/scipy/scipy/pull/12666>`__: MAINT: Fixes from static analysis
* `#12667 <https://github.com/scipy/scipy/pull/12667>`__: ENH: Adding Modified Rodrigues Parameters to the Rotation class
* `#12670 <https://github.com/scipy/scipy/pull/12670>`__: DOC: Update documentation for Gamma distribution
* `#12673 <https://github.com/scipy/scipy/pull/12673>`__: API: Unconditionally return np.intp from cKDTree.query
* `#12677 <https://github.com/scipy/scipy/pull/12677>`__: MAINT: Add Autogenerated notice to ufuncs.pyi
* `#12682 <https://github.com/scipy/scipy/pull/12682>`__: MAINT: Remove _util._valarray
* `#12688 <https://github.com/scipy/scipy/pull/12688>`__: MAINT: add f2py-generated scipy.integrate files to .gitignore
* `#12689 <https://github.com/scipy/scipy/pull/12689>`__: BENCH: simplify benchmark setup, remove benchmarks/run.py
* `#12694 <https://github.com/scipy/scipy/pull/12694>`__: scipy/stats: Add laplace_asymmetric continuous distribution
* `#12695 <https://github.com/scipy/scipy/pull/12695>`__: DOC: update Ubuntu quickstart; conda compilers now work!
* `#12698 <https://github.com/scipy/scipy/pull/12698>`__: MAINT: Replace np.max with np.maximum
* `#12700 <https://github.com/scipy/scipy/pull/12700>`__: TST: bump test precision for constrained trustregion test
* `#12702 <https://github.com/scipy/scipy/pull/12702>`__: TST: bump test tolerance for \`DifferentialEvolutionSolver.test_L4\`
* `#12703 <https://github.com/scipy/scipy/pull/12703>`__: BUG: Improve input validation for sepfir2d
* `#12708 <https://github.com/scipy/scipy/pull/12708>`__: MAINT: fix a typo in scipy.sparse
* `#12709 <https://github.com/scipy/scipy/pull/12709>`__: BUG: bvls can fail catastrophically to converge
* `#12711 <https://github.com/scipy/scipy/pull/12711>`__: MAINT: Use platform.python_implementation to determine IS_PYPY
* `#12713 <https://github.com/scipy/scipy/pull/12713>`__: TST: Fix flaky test_lgmres
* `#12716 <https://github.com/scipy/scipy/pull/12716>`__: DOC: add examples and tutorial links for interpolate functions...
* `#12717 <https://github.com/scipy/scipy/pull/12717>`__: DOC: Fix Issue #5396
* `#12725 <https://github.com/scipy/scipy/pull/12725>`__: ENH: Support complex-valued images and kernels for many ndimage...
* `#12729 <https://github.com/scipy/scipy/pull/12729>`__: DEP: remove setup_requires
* `#12732 <https://github.com/scipy/scipy/pull/12732>`__: BENCH: skip benchmarks instead of hiding them when SCIPY_XSLOW=0
* `#12734 <https://github.com/scipy/scipy/pull/12734>`__: CI: Don't ignore line-length in the lint_diff check.
* `#12736 <https://github.com/scipy/scipy/pull/12736>`__: DOC: Fix signal.windows.get_window() 'exponential' docstring
* `#12737 <https://github.com/scipy/scipy/pull/12737>`__: ENH: stats: override stats.gumbel_r.fit and stats.gumbel_l.fit...
* `#12738 <https://github.com/scipy/scipy/pull/12738>`__: ENH: stats: override stats.logistic.fit with system of equations...
* `#12743 <https://github.com/scipy/scipy/pull/12743>`__: BUG: Avoid negative variances in circular statistics
* `#12744 <https://github.com/scipy/scipy/pull/12744>`__: Prevent build error on GNU/Hurd
* `#12746 <https://github.com/scipy/scipy/pull/12746>`__: TST: parameterize the test cases in test_ndimage.py
* `#12752 <https://github.com/scipy/scipy/pull/12752>`__: DOC: Add examples for some root finding functions.
* `#12754 <https://github.com/scipy/scipy/pull/12754>`__: MAINT, CI: Azure windows deps multiline
* `#12756 <https://github.com/scipy/scipy/pull/12756>`__: ENH: stats: Add an sf method to levy for improved precision in...
* `#12757 <https://github.com/scipy/scipy/pull/12757>`__: ENH: stats: Add an sf method to levy_l for improved precision.
* `#12765 <https://github.com/scipy/scipy/pull/12765>`__: TST, MAINT: infeasible_2 context
* `#12767 <https://github.com/scipy/scipy/pull/12767>`__: Fix spline interpolation boundary handling for modes reflect...
* `#12769 <https://github.com/scipy/scipy/pull/12769>`__: DOC: syntax error in scipy.interpolate.bspl
* `#12770 <https://github.com/scipy/scipy/pull/12770>`__: ENH: add nearest-up rounding to scipy.interpolate.interp1d
* `#12771 <https://github.com/scipy/scipy/pull/12771>`__: TST: fix invalid input unit test for scipy.signal.gammatone
* `#12775 <https://github.com/scipy/scipy/pull/12775>`__: ENH: Adds quadratic_assignment with two methods
* `#12776 <https://github.com/scipy/scipy/pull/12776>`__: ENH: add grid-constant boundary handling in ndimage interpolation...
* `#12777 <https://github.com/scipy/scipy/pull/12777>`__: Add Taylor Window function - Common in Radar DSP
* `#12779 <https://github.com/scipy/scipy/pull/12779>`__: ENH: Improvements to pocketfft thread pool and ARM neon vectorization
* `#12788 <https://github.com/scipy/scipy/pull/12788>`__: API: Rename cKDTree n_jobs argument to workers
* `#12792 <https://github.com/scipy/scipy/pull/12792>`__: DOC: remove THANKS.txt file in favor of scipy.org
* `#12793 <https://github.com/scipy/scipy/pull/12793>`__: Add new flag to authors tool
* `#12802 <https://github.com/scipy/scipy/pull/12802>`__: BENCH: add scipy.ndimage.interpolation benchmarks
* `#12803 <https://github.com/scipy/scipy/pull/12803>`__: Do not pin the version of numpy in unsupported python versions
* `#12810 <https://github.com/scipy/scipy/pull/12810>`__: CI: fix 32-bit Linux build failure on Azure CI runs
* `#12812 <https://github.com/scipy/scipy/pull/12812>`__: ENH: support interpolation of complex-valued images
* `#12814 <https://github.com/scipy/scipy/pull/12814>`__: BUG: nonlin_solve shouldn't pass non-vector dx to tol_norm
* `#12818 <https://github.com/scipy/scipy/pull/12818>`__: Update ckdtree.pyx
* `#12822 <https://github.com/scipy/scipy/pull/12822>`__: MAINT: simplify directed_hausdorff
* `#12827 <https://github.com/scipy/scipy/pull/12827>`__: DOC: Fix wrong name w being used instead of worN in docs.
* `#12831 <https://github.com/scipy/scipy/pull/12831>`__: DOC: fix typo in sparse/base.py
* `#12835 <https://github.com/scipy/scipy/pull/12835>`__: MAINT: stats: Improve vonmises PDF calculation.
* `#12839 <https://github.com/scipy/scipy/pull/12839>`__: ENH: scipy.stats: add multivariate hypergeometric distribution
* `#12843 <https://github.com/scipy/scipy/pull/12843>`__: changed M to N in windows.dpss
* `#12846 <https://github.com/scipy/scipy/pull/12846>`__: MAINT: update minimum NumPy version to 1.16.5
* `#12847 <https://github.com/scipy/scipy/pull/12847>`__: DOC: Unify the formula in docs of scipy.stats.pearsonr()
* `#12849 <https://github.com/scipy/scipy/pull/12849>`__: DOC: polish QAP docs for consistency and readability
* `#12852 <https://github.com/scipy/scipy/pull/12852>`__: ENH, MAINT: Bring KDTree interface to feature-parity with cKDTree
* `#12858 <https://github.com/scipy/scipy/pull/12858>`__: DOC: use :doi: and :arxiv: directives for references
* `#12872 <https://github.com/scipy/scipy/pull/12872>`__: lazily import multiprocessing.Pool in MapWrapper
* `#12878 <https://github.com/scipy/scipy/pull/12878>`__: DOC: document ScalarFunction
* `#12882 <https://github.com/scipy/scipy/pull/12882>`__: MAINT: stats: Change a test to use <= instead of strictly less...
* `#12885 <https://github.com/scipy/scipy/pull/12885>`__: numpy.linspace calls edited to ensure correct spacing.
* `#12886 <https://github.com/scipy/scipy/pull/12886>`__: DOC: stats: Add 'versionadded' to cramervonmises docstring.
* `#12899 <https://github.com/scipy/scipy/pull/12899>`__: TST: make a couple of tests expected to fail on 32-bit architectures
* `#12903 <https://github.com/scipy/scipy/pull/12903>`__: DOC: update Windows build guide and move into contributor guide
* `#12907 <https://github.com/scipy/scipy/pull/12907>`__: DOC: clarify which array the precenter option applies to
* `#12908 <https://github.com/scipy/scipy/pull/12908>`__: MAINT: spatial: Remove two occurrences of unused variables in...
* `#12909 <https://github.com/scipy/scipy/pull/12909>`__: ENH: stats: Add methods gumbel_r._sf and gumbel_r._isf
* `#12910 <https://github.com/scipy/scipy/pull/12910>`__: CI: travis: Remove some unnecessary code from .travis.yml.
* `#12911 <https://github.com/scipy/scipy/pull/12911>`__: Minor fixes to dendrogram plotting
* `#12921 <https://github.com/scipy/scipy/pull/12921>`__: CI: don't run GitHub Actions on fork or in cron job
* `#12927 <https://github.com/scipy/scipy/pull/12927>`__: MAINT: rename integrate.simps to simpson
* `#12934 <https://github.com/scipy/scipy/pull/12934>`__: MAINT: rename trapz and cumtrapz to (cumulative\_)trapezoid
* `#12936 <https://github.com/scipy/scipy/pull/12936>`__: MAINT: fix numerical precision in nct.stats
* `#12938 <https://github.com/scipy/scipy/pull/12938>`__: MAINT: fix linter on master
* `#12941 <https://github.com/scipy/scipy/pull/12941>`__: Update minimum AIX pinnings to match non AIX builds
* `#12955 <https://github.com/scipy/scipy/pull/12955>`__: BUG: Fixed wrong NaNs check in scipy.stats.weightedtau
* `#12958 <https://github.com/scipy/scipy/pull/12958>`__: ENH: stats: Implement _logpdf, _sf and _isf for nakagami.
* `#12962 <https://github.com/scipy/scipy/pull/12962>`__: Correcting that p should be in [0,1] for a variety of discrete...
* `#12964 <https://github.com/scipy/scipy/pull/12964>`__: BUG: added line.strip() to split_data_line()
* `#12968 <https://github.com/scipy/scipy/pull/12968>`__: ENH: stats: Use only an analytical formula or scalar root-finding...
* `#12971 <https://github.com/scipy/scipy/pull/12971>`__: MAINT: Declare support for Python 3.9
* `#12972 <https://github.com/scipy/scipy/pull/12972>`__: MAINT: Remove redundant Python < 3.6 code
* `#12980 <https://github.com/scipy/scipy/pull/12980>`__: DOC: Update documentation on optimize.rosen
* `#12983 <https://github.com/scipy/scipy/pull/12983>`__: ENH: improvements to stats.linregress
* `#12990 <https://github.com/scipy/scipy/pull/12990>`__: DOC: Clarify that using sos as output type for iirdesign can...
* `#12992 <https://github.com/scipy/scipy/pull/12992>`__: DOC: capitalization and formatting in lsmr
* `#12995 <https://github.com/scipy/scipy/pull/12995>`__: DOC: stats: Several documentation fixes.
* `#12996 <https://github.com/scipy/scipy/pull/12996>`__: BUG: Improve error messages for \`range\` arg of binned_statistic_dd
* `#12998 <https://github.com/scipy/scipy/pull/12998>`__: MAINT: approx_derivative with FP32 closes #12991
* `#13004 <https://github.com/scipy/scipy/pull/13004>`__: TST: isinstance(OptimizeResult.message, str) closes #13001
* `#13006 <https://github.com/scipy/scipy/pull/13006>`__: Keep correct dtype when loading empty mat arrays.
* `#13009 <https://github.com/scipy/scipy/pull/13009>`__: MAINT: clip SLSQP step within bounds
* `#13012 <https://github.com/scipy/scipy/pull/13012>`__: DOC: fix bilinear_zpk example labels
* `#13013 <https://github.com/scipy/scipy/pull/13013>`__: ENH: Add \`subset\` and \`subsets\` methods to \`DisjointSet\`...
* `#13029 <https://github.com/scipy/scipy/pull/13029>`__: MAINT: basinhopping callback for initial mininmisation
* `#13032 <https://github.com/scipy/scipy/pull/13032>`__: DOC: fix docstring errors in in stats.wilcoxon
* `#13036 <https://github.com/scipy/scipy/pull/13036>`__: BUG: forward port lint_diff shims
* `#13041 <https://github.com/scipy/scipy/pull/13041>`__: MAINT: dogbox ensure x is within bounds closes #11403
* `#13042 <https://github.com/scipy/scipy/pull/13042>`__: MAINT: forward port 1.5.4 release notes
* `#13046 <https://github.com/scipy/scipy/pull/13046>`__: DOC: Update optimize.least_squares doc for all tolerance must...
* `#13052 <https://github.com/scipy/scipy/pull/13052>`__: Typo fix for cluster documentation
* `#13054 <https://github.com/scipy/scipy/pull/13054>`__: BUG: fix \`scipy.optimize.show_options\` for unknown methods....
* `#13056 <https://github.com/scipy/scipy/pull/13056>`__: MAINT: fft: Fix a C++ compiler warning.
* `#13057 <https://github.com/scipy/scipy/pull/13057>`__: Minor fixes on doc of function csr_tocsc
* `#13058 <https://github.com/scipy/scipy/pull/13058>`__: DOC: stats: Replace np.float with np.float64 in a tutorial file.
* `#13059 <https://github.com/scipy/scipy/pull/13059>`__: DOC: stats: Update the "Returns" section of the linregress docstring.
* `#13060 <https://github.com/scipy/scipy/pull/13060>`__: MAINT: clip_x_for_func should be private
* `#13061 <https://github.com/scipy/scipy/pull/13061>`__: DOC: signal.win -> signal.windows.win in Examples
* `#13063 <https://github.com/scipy/scipy/pull/13063>`__: MAINT: Add suite-sparse and sksparse installation check
* `#13070 <https://github.com/scipy/scipy/pull/13070>`__: MAINT: stats: Remove a couple obsolete comments.
* `#13073 <https://github.com/scipy/scipy/pull/13073>`__: BUG: Fix scalar_search_wolfe2 to resolve #12157
* `#13078 <https://github.com/scipy/scipy/pull/13078>`__: CI, MAINT: migrate Lint to Azure
* `#13081 <https://github.com/scipy/scipy/pull/13081>`__: BLD: drop Python 3.6 support (NEP 29)
* `#13082 <https://github.com/scipy/scipy/pull/13082>`__: MAINT: update minimum NumPy version to 1.16.5 in a couple more...
* `#13083 <https://github.com/scipy/scipy/pull/13083>`__: DOC: update toolchain.rst
* `#13086 <https://github.com/scipy/scipy/pull/13086>`__: DOC: Update the Parameters section of the correlation docstring
* `#13087 <https://github.com/scipy/scipy/pull/13087>`__: ENH:signal: Speed-up Cython implementation of _sosfilt
* `#13089 <https://github.com/scipy/scipy/pull/13089>`__: BLD, BUG: add c99 compiler flag to HiGHS basiclu library
* `#13091 <https://github.com/scipy/scipy/pull/13091>`__: BUG: Fix GIL handling in _sosfilt
* `#13094 <https://github.com/scipy/scipy/pull/13094>`__: DOC: clarify "location" in docstring of cKDTree.query
* `#13095 <https://github.com/scipy/scipy/pull/13095>`__: Zoom resize update
* `#13097 <https://github.com/scipy/scipy/pull/13097>`__: BUG: fix CubicSpline(..., bc_type="periodic") #11758
* `#13100 <https://github.com/scipy/scipy/pull/13100>`__: BUG: sparse: Correct output format of kron
* `#13107 <https://github.com/scipy/scipy/pull/13107>`__: ENH: faster linear_sum_assignment for small cost matrices
* `#13110 <https://github.com/scipy/scipy/pull/13110>`__: CI, MAINT: refguide/asv checks to azure
* `#13112 <https://github.com/scipy/scipy/pull/13112>`__: CI: fix MacOS CI
* `#13113 <https://github.com/scipy/scipy/pull/13113>`__: CI: Install word list package for refguide-check
* `#13115 <https://github.com/scipy/scipy/pull/13115>`__: BUG: add value range check for signal.iirdesign()
* `#13116 <https://github.com/scipy/scipy/pull/13116>`__: CI: Don't report name errors after an exception in refguide-check
* `#13117 <https://github.com/scipy/scipy/pull/13117>`__: CI: move sdist/pre-release test Azure
* `#13119 <https://github.com/scipy/scipy/pull/13119>`__: Improve error message on friedmanchisquare function
* `#13121 <https://github.com/scipy/scipy/pull/13121>`__: Fix factorial() for NaN on Python 3.10
* `#13123 <https://github.com/scipy/scipy/pull/13123>`__: BLD: Specify file extension for language standard version tests
* `#13128 <https://github.com/scipy/scipy/pull/13128>`__: TST: skip Fortran I/O test for ODR
* `#13130 <https://github.com/scipy/scipy/pull/13130>`__: TST: skip factorial() float tests on Python 3.10
* `#13136 <https://github.com/scipy/scipy/pull/13136>`__: CI:Add python dbg run to GH Actions
* `#13138 <https://github.com/scipy/scipy/pull/13138>`__: CI: Port coverage, 64-bit BLAS, GCC 4.8 build to azure
* `#13139 <https://github.com/scipy/scipy/pull/13139>`__: Fix edge case for mode='nearest' in ndimage.interpolation functions
* `#13141 <https://github.com/scipy/scipy/pull/13141>`__: BUG: signal: Fix data type of the numerator returned by ss2tf.
* `#13144 <https://github.com/scipy/scipy/pull/13144>`__: MAINT: stats: restrict gausshyper z > -1
* `#13146 <https://github.com/scipy/scipy/pull/13146>`__: typo in csr.py
* `#13148 <https://github.com/scipy/scipy/pull/13148>`__: BUG: stats: fix typo in stable rvs per gh-12870
* `#13149 <https://github.com/scipy/scipy/pull/13149>`__: DOC: spatial/stats: cross-ref random rotation matrix functions
* `#13151 <https://github.com/scipy/scipy/pull/13151>`__: MAINT: stats: Fix a test and a couple PEP-8 issues.
* `#13152 <https://github.com/scipy/scipy/pull/13152>`__: MAINT: stats: Use np.take_along_axis in the private function...
* `#13154 <https://github.com/scipy/scipy/pull/13154>`__: ENH: stats: Implement defined handling of constant inputs in...
* `#13156 <https://github.com/scipy/scipy/pull/13156>`__: DOC: maintain equal display range for ndimage.zoom example
* `#13159 <https://github.com/scipy/scipy/pull/13159>`__: CI: Azure: Don't run tests on merge commits, except for coverage
* `#13160 <https://github.com/scipy/scipy/pull/13160>`__: DOC: stats: disambiguate location-shifted/noncentral
* `#13161 <https://github.com/scipy/scipy/pull/13161>`__: BUG: DifferentialEvolutionSolver.__del__ can fail in garbage...
* `#13163 <https://github.com/scipy/scipy/pull/13163>`__: BUG: stats: fix bug in spearmanr nan propagation
* `#13167 <https://github.com/scipy/scipy/pull/13167>`__: MAINT: stats: Fix a test.
* `#13169 <https://github.com/scipy/scipy/pull/13169>`__: BUG: stats: Fix handling of misaligned masks in mstats.pearsonr.
* `#13178 <https://github.com/scipy/scipy/pull/13178>`__: CI: testing.yml --> macos.yml
* `#13181 <https://github.com/scipy/scipy/pull/13181>`__: CI: fix lint
* `#13190 <https://github.com/scipy/scipy/pull/13190>`__: BUG: optimize: fix a duplicate key bug for \`test_show_options\`
* `#13192 <https://github.com/scipy/scipy/pull/13192>`__: BUG:linalg: Add overwrite option to gejsv wrapper
* `#13194 <https://github.com/scipy/scipy/pull/13194>`__: BUG: slsqp should be able to use rel_step
* `#13199 <https://github.com/scipy/scipy/pull/13199>`__: [skip travis] DOC: 1.6.0 release notes
* `#13203 <https://github.com/scipy/scipy/pull/13203>`__: fix typos
* `#13209 <https://github.com/scipy/scipy/pull/13209>`__: TST:linalg: set the seed for cossin test
* `#13212 <https://github.com/scipy/scipy/pull/13212>`__: [DOC] Backtick and directive consistency.
* `#13217 <https://github.com/scipy/scipy/pull/13217>`__: REL: add necessary setuptools and numpy version pins in pyproject.toml...
* `#13226 <https://github.com/scipy/scipy/pull/13226>`__: BUG: pavement.py file handle fixes
* `#13249 <https://github.com/scipy/scipy/pull/13249>`__: Handle cval correctly for ndimage functions with complex-valued...
* `#13253 <https://github.com/scipy/scipy/pull/13253>`__: BUG,MAINT: Ensure all Pool objects are closed
* `#13255 <https://github.com/scipy/scipy/pull/13255>`__: BUG:linalg: Fix heevx wrappers and add new tests
* `#13260 <https://github.com/scipy/scipy/pull/13260>`__: CI: fix macOS testing
* `#13269 <https://github.com/scipy/scipy/pull/13269>`__: CI: github actions: In the linux dbg tests, update apt before...
* `#13279 <https://github.com/scipy/scipy/pull/13279>`__: MAINT: 1.6.0 rc2 backports
==========================
SciPy 0.12.0 Release Notes
==========================

.. contents::

SciPy 0.12.0 is the culmination of 7 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.12.x branch, and on adding
new features on the master branch.

Some of the highlights of this release are:

  - Completed QHull wrappers in scipy.spatial.
  - cKDTree now a drop-in replacement for KDTree.
  - A new global optimizer, basinhopping.
  - Support for Python 2 and Python 3 from the same code base (no more 2to3).

This release requires Python 2.6, 2.7 or 3.1-3.3 and NumPy 1.5.1 or greater.
Support for Python 2.4 and 2.5 has been dropped as of this release.


New features
============

``scipy.spatial`` improvements
------------------------------

cKDTree feature-complete
^^^^^^^^^^^^^^^^^^^^^^^^
Cython version of KDTree, cKDTree, is now feature-complete.  Most operations
(construction, query, query_ball_point, query_pairs, count_neighbors and
sparse_distance_matrix) are between 200 and 1000 times faster in cKDTree than
in KDTree.  With very minor caveats, cKDTree has exactly the same interface as
KDTree, and can be used as a drop-in replacement.

Voronoi diagrams and convex hulls
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
`scipy.spatial` now contains functionality for computing Voronoi
diagrams and convex hulls using the Qhull library. (Delaunay
triangulation was available since Scipy 0.9.0.)

Delaunay improvements
^^^^^^^^^^^^^^^^^^^^^
It's now possible to pass in custom Qhull options in Delaunay
triangulation. Coplanar points are now also recorded, if present.
Incremental construction of Delaunay triangulations is now also
possible.

Spectral estimators (``scipy.signal``)
--------------------------------------
The functions ``scipy.signal.periodogram`` and ``scipy.signal.welch`` were
added, providing DFT-based spectral estimators.


``scipy.optimize`` improvements
-------------------------------

Callback functions in L-BFGS-B and TNC
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
A callback mechanism was added to L-BFGS-B and TNC minimization solvers.

Basin hopping global optimization (``scipy.optimize.basinhopping``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
A new global optimization algorithm.  Basinhopping is designed to efficiently
find the global minimum of a smooth function.


``scipy.special`` improvements
------------------------------

Revised complex error functions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The computation of special functions related to the error function now uses a
new `Faddeeva library from MIT <http://ab-initio.mit.edu/Faddeeva>`__ which
increases their numerical precision. The scaled and imaginary error functions
``erfcx`` and ``erfi`` were also added, and the Dawson integral ``dawsn`` can
now be evaluated for a complex argument.

Faster orthogonal polynomials
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Evaluation of orthogonal polynomials (the ``eval_*`` routines) in now
faster in ``scipy.special``, and their ``out=`` argument functions
properly.


``scipy.sparse.linalg`` features
--------------------------------
- In ``scipy.sparse.linalg.spsolve``, the ``b`` argument can now be either
  a vector or a matrix.
- ``scipy.sparse.linalg.inv`` was added.  This uses ``spsolve`` to compute
  a sparse matrix inverse.
- ``scipy.sparse.linalg.expm`` was added.  This computes the exponential of
  a sparse matrix using a similar algorithm to the existing dense array
  implementation in ``scipy.linalg.expm``.


Listing Matlab(R) file contents in ``scipy.io``
-----------------------------------------------
A new function ``whosmat`` is available in ``scipy.io`` for inspecting contents
of MAT files without reading them to memory.


Documented BLAS and LAPACK low-level interfaces (``scipy.linalg``)
------------------------------------------------------------------
The modules `scipy.linalg.blas` and `scipy.linalg.lapack` can be used
to access low-level BLAS and LAPACK functions.


Polynomial interpolation improvements (``scipy.interpolate``)
-------------------------------------------------------------
The barycentric, Krogh, piecewise and pchip polynomial interpolators in
``scipy.interpolate`` accept now an ``axis`` argument.


Deprecated features
===================

`scipy.lib.lapack`
------------------
The module `scipy.lib.lapack` is deprecated. You can use `scipy.linalg.lapack`
instead. The module `scipy.lib.blas` was deprecated earlier in Scipy 0.10.0.


`fblas` and `cblas`
-------------------
Accessing the modules `scipy.linalg.fblas`, `cblas`, `flapack`, `clapack` is
deprecated. Instead, use the modules `scipy.linalg.lapack` and
`scipy.linalg.blas`.


Backwards incompatible changes
==============================

Removal of ``scipy.io.save_as_module``
--------------------------------------
The function ``scipy.io.save_as_module`` was deprecated in Scipy 0.11.0, and is
now removed.

Its private support modules ``scipy.io.dumbdbm_patched`` and
``scipy.io.dumb_shelve`` are also removed.

`axis` argument added to `scipy.stats.scoreatpercentile`
--------------------------------------------------------

The function `scipy.stats.scoreatpercentile` has been given an `axis`
argument.  The default argument is `axis=None`, which means the calculation
is done on the flattened array.  Before this change, `scoreatpercentile`
would act as if `axis=0` had been given.  Code using `scoreatpercentile`
with a multidimensional array will need to add `axis=0` to the function call
to preserve the old behavior.  (This API change was not noticed until
long after the release of 0.12.0.)


Authors
=======
* Anton Akhmerov +
* Alexander Eberspächer +
* Anne Archibald
* Jisk Attema +
* K.-Michael Aye +
* bemasc +
* Sebastian Berg +
* François Boulogne +
* Matthew Brett
* Lars Buitinck
* Steven Byrnes +
* Tim Cera +
* Christian +
* Keith Clawson +
* David Cournapeau
* Nathan Crock +
* endolith
* Bradley M. Froehle +
* Matthew R Goodman
* Christoph Gohlke
* Ralf Gommers
* Robert David Grant +
* Yaroslav Halchenko
* Charles Harris
* Jonathan Helmus
* Andreas Hilboll
* Hugo +
* Oleksandr Huziy
* Jeroen Demeyer +
* Johannes Schönberger +
* Steven G. Johnson +
* Chris Jordan-Squire
* Jonathan Taylor +
* Niklas Kroeger +
* Jerome Kieffer +
* kingson +
* Josh Lawrence
* Denis Laxalde
* Alex Leach +
* Tim Leslie
* Richard Lindsley +
* Lorenzo Luengo +
* Stephen McQuay +
* MinRK
* Sturla Molden +
* Eric Moore +
* mszep +
* Matt Newville +
* Vlad Niculae
* Travis Oliphant
* David Parker +
* Fabian Pedregosa
* Josef Perktold
* Zach Ploskey +
* Alex Reinhart +
* Gilles Rochefort +
* Ciro Duran Santillli +
* Jan Schlueter +
* Jonathan Scholz +
* Anthony Scopatz
* Skipper Seabold
* Fabrice Silva +
* Scott Sinclair
* Jacob Stevenson +
* Sturla Molden +
* Julian Taylor +
* thorstenkranz +
* John Travers +
* True Price +
* Nicky van Foreest
* Jacob Vanderplas
* Patrick Varilly
* Daniel Velkov +
* Pauli Virtanen
* Stefan van der Walt
* Warren Weckesser

A total of 75 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.

==========================
SciPy 1.7.0 Release Notes
==========================

.. contents::

SciPy 1.7.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been a number of deprecations and API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning`` s).
Our development attention will now shift to bug-fix releases on the
1.7.x branch, and on adding new features on the master branch.

This release requires Python 3.7+ and NumPy 1.16.5 or greater.

For running on PyPy, PyPy3 6.0+ is required.


**************************
Highlights of this release
**************************

- A new submodule for quasi-Monte Carlo, `scipy.stats.qmc`, was added
- The documentation design was updated to use the same PyData-Sphinx theme as
  NumPy and other ecosystem libraries.
- We now vendor and leverage the Boost C++ library to enable numerous
  improvements for long-standing weaknesses in `scipy.stats`
- `scipy.stats` has six new distributions, eight new (or overhauled)
  hypothesis tests, a new function for bootstrapping, a class that enables
  fast random variate sampling and percentile point function evaluation,
  and many other enhancements.
- ``cdist`` and ``pdist`` distance calculations are faster for several metrics,
  especially weighted cases, thanks to a rewrite to a new C++ backend framework
- A new class for radial basis function interpolation, `RBFInterpolator`, was
  added to address issues with the `Rbf` class.

*We gratefully acknowledge the Chan-Zuckerberg Initiative Essential Open Source
Software for Science program for supporting many of the improvements to*
`scipy.stats`.

************
New features
************

`scipy.cluster` improvements
============================

An optional argument, ``seed``, has been added to ``kmeans`` and ``kmeans2`` to
set the random generator and random state.

`scipy.interpolate` improvements
================================

Improved input validation and error messages for ``fitpack.bispev`` and
``fitpack.parder`` for scenarios that previously caused substantial confusion
for users.

The class `RBFInterpolator` was added to supersede the `Rbf` class. The new
class has usage that more closely follows other interpolator classes, corrects
sign errors that caused unexpected smoothing behavior, includes polynomial
terms in the interpolant (which are necessary for some RBF choices), and
supports interpolation using only the k-nearest neighbors for memory
efficiency.

`scipy.linalg` improvements
===========================

An LAPACK wrapper was added for access to the ``tgexc`` subroutine.

`scipy.ndimage` improvements
============================

`scipy.ndimage.affine_transform` is now able to infer the ``output_shape`` from
the ``out`` array.

`scipy.optimize` improvements
=============================

The optional parameter ``bounds`` was added to
``_minimize_neldermead`` to support bounds constraints
for the Nelder-Mead solver.

``trustregion`` methods ``trust-krylov``, ``dogleg`` and ``trust-ncg`` can now
estimate ``hess`` by finite difference using one of
``["2-point", "3-point", "cs"]``.

``halton`` was added as a ``sampling_method`` in `scipy.optimize.shgo`.
``sobol`` was fixed and is now using `scipy.stats.qmc.Sobol`.

``halton`` and ``sobol`` were added as ``init`` methods in
`scipy.optimize.differential_evolution.`

``differential_evolution`` now accepts an ``x0`` parameter to provide an
initial guess for the minimization.

``least_squares`` has a modest performance improvement when SciPy is built
with Pythran transpiler enabled.

When ``linprog`` is used with ``method`` ``'highs'``, ``'highs-ipm'``, or
``'highs-ds'``, the result object now reports the marginals (AKA shadow
prices, dual values) and residuals associated with each constraint.

`scipy.signal` improvements
===========================

``get_window`` supports ``general_cosine`` and ``general_hamming`` window
functions.

`scipy.signal.medfilt2d` now releases the GIL where appropriate to enable
performance gains via multithreaded calculations.

`scipy.sparse` improvements
===========================

Addition of ``dia_matrix`` sparse matrices is now faster.


`scipy.spatial` improvements
============================

``distance.cdist`` and ``distance.pdist`` performance has greatly improved for
certain weighted metrics. Namely: ``minkowski``, ``euclidean``, ``chebyshev``,
``canberra``, and ``cityblock``.

Modest performance improvements for many of the unweighted ``cdist`` and
``pdist`` metrics noted above.

The parameter ``seed`` was added to `scipy.spatial.vq.kmeans` and
`scipy.spatial.vq.kmeans2`.

The parameters ``axis`` and ``keepdims`` where added to
`scipy.spatial.distance.jensenshannon`.

The ``rotation`` methods ``from_rotvec`` and ``as_rotvec`` now accept a
``degrees`` argument to specify usage of degrees instead of radians.

`scipy.special` improvements
============================

Wright's generalized Bessel function for positive arguments was added as
`scipy.special.wright_bessel.`

An implementation of the inverse of the Log CDF of the Normal Distribution is
now available via `scipy.special.ndtri_exp`.

`scipy.stats` improvements
==========================

Hypothesis Tests
----------------

The Mann-Whitney-Wilcoxon test, ``mannwhitneyu``, has been rewritten. It now
supports n-dimensional input, an exact test method when there are no ties,
and improved documentation. Please see "Other changes" for adjustments to
default behavior.

The new function `scipy.stats.binomtest` replaces `scipy.stats.binom_test`. The
new function returns an object that calculates a confidence intervals of the
proportion parameter. Also, performance was improved from O(n) to O(log(n)) by
using binary search.

The two-sample version of the Cramer-von Mises test is implemented in
`scipy.stats.cramervonmises_2samp`.

The Alexander-Govern test is implemented in the new function
`scipy.stats.alexandergovern`.

The new functions `scipy.stats.barnard_exact` and  `scipy.stats. boschloo_exact`
respectively perform Barnard's exact test and Boschloo's exact test
for 2x2 contingency tables.

The new function `scipy.stats.page_trend_test` performs Page's test for ordered
alternatives.

The new function `scipy.stats.somersd` performs Somers' D test for ordinal
association between two variables.

An option, ``permutations``, has been added in `scipy.stats.ttest_ind` to
perform permutation t-tests. A ``trim`` option was also added to perform
a trimmed (Yuen's) t-test.

The ``alternative`` parameter was added to the ``skewtest``, ``kurtosistest``,
``ranksums``, ``mood``, ``ansari``, ``linregress``, and ``spearmanr`` functions
to allow one-sided hypothesis testing.

Sample statistics
-----------------

The new function `scipy.stats.differential_entropy` estimates the differential
entropy of a continuous distribution from a sample.

The ``boxcox`` and ``boxcox_normmax`` now allow the user to control the
optimizer used to minimize the negative log-likelihood function.

A new function `scipy.stats.contingency.relative_risk` calculates the
relative risk, or risk ratio, of a 2x2 contingency table. The object
returned has a method to compute the confidence interval of the relative risk.

Performance improvements in the ``skew`` and ``kurtosis`` functions achieved
by removal of repeated/redundant calculations.

Substantial performance improvements in `scipy.stats.mstats.hdquantiles_sd`.

The new function `scipy.stats.contingency.association` computes several
measures of association for a contingency table: Pearsons contingency
coefficient, Cramer's V, and Tschuprow's T.

The parameter ``nan_policy`` was added to `scipy.stats.zmap` to provide options
for handling the occurrence of ``nan`` in the input data.

The parameter ``ddof`` was added to `scipy.stats.variation` and
`scipy.stats.mstats.variation`.

The parameter ``weights`` was added to `scipy.stats.gmean`.

Statistical Distributions
-------------------------

We now vendor and leverage the Boost C++ library to address a number of
previously reported issues in ``stats``. Notably, ``beta``, ``binom``,
``nbinom`` now have Boost backends, and it is straightforward to leverage
the backend for additional functions.

The skew Cauchy probability distribution has been implemented as
`scipy.stats.skewcauchy`.

The Zipfian probability distribution has been implemented as
`scipy.stats.zipfian`.

The new distributions ``nchypergeom_fisher`` and ``nchypergeom_wallenius``
implement the Fisher and Wallenius versions of the noncentral hypergeometric
distribution, respectively.

The generalized hyperbolic distribution was added in
`scipy.stats.genhyperbolic`.

The studentized range distribution was added in `scipy.stats.studentized_range`.

`scipy.stats.argus` now has improved handling for small parameter values.

Better argument handling/preparation has resulted in performance improvements
for many distributions.

The ``cosine`` distribution has added ufuncs for ``ppf``, ``cdf``, ``sf``, and
``isf`` methods including numerical precision improvements at the edges of the
support of the distribution.

An option to fit the distribution to data by the method of moments has been
added to the ``fit`` method of the univariate continuous distributions.

Other
-----
`scipy.stats.bootstrap` has been added to allow estimation of the confidence
interval and standard error of a statistic.

The new function `scipy.stats.contingency.crosstab` computes a contingency
table (i.e. a table of counts of unique entries) for the given data.

`scipy.stats.NumericalInverseHermite` enables fast random variate sampling
and percentile point function evaluation of an arbitrary univariate statistical
distribution.

New `scipy.stats.qmc` module
----------------------------

This new module provides Quasi-Monte Carlo (QMC) generators and associated
helper functions.

It provides a generic class `scipy.stats.qmc.QMCEngine` which defines a QMC
engine/sampler. An engine is state aware: it can be continued, advanced and
reset. 3 base samplers are available:

- `scipy.stats.qmc.Sobol` the well known Sobol low discrepancy sequence.
  Several warnings have been added to guide the user into properly using this
  sampler. The sequence is scrambled by default.
- `scipy.stats.qmc.Halton`: Halton low discrepancy sequence. The sequence is
  scrambled by default.
- `scipy.stats.qmc.LatinHypercube`: plain LHS design.

And 2 special samplers are available:

- `scipy.stats.qmc.MultinomialQMC`: sampling from a multinomial distribution
  using any of the base `scipy.stats.qmc.QMCEngine`.
- `scipy.stats.qmc.MultivariateNormalQMC`: sampling from a multivariate Normal
  using any of the base `scipy.stats.qmc.QMCEngine`.

The module also provide the following helpers:

- `scipy.stats.qmc.discrepancy`: assess the quality of a set of points in terms
  of space coverage.
- `scipy.stats.qmc.update_discrepancy`: can be used in an optimization loop to
  construct a good set of points.
- `scipy.stats.qmc.scale`: easily scale a set of points from (to) the unit
  interval to (from) a given range.


*******************
Deprecated features
*******************

`scipy.linalg` deprecations
===========================

- `scipy.linalg.pinv2` is deprecated and its functionality is completely
  subsumed into `scipy.linalg.pinv`
- Both ``rcond``, ``cond`` keywords of `scipy.linalg.pinv` and
  `scipy.linalg.pinvh` were not working and now are deprecated. They are now
  replaced with functioning ``atol`` and ``rtol`` keywords with clear usage.

`scipy.spatial` deprecations
============================

- `scipy.spatial.distance` metrics expect 1d input vectors but will call
  ``np.squeeze`` on their inputs to accept any extra length-1 dimensions. That
  behaviour is now deprecated.


******************************
Backwards incompatible changes
******************************

*************
Other changes
*************

We now accept and leverage performance improvements from the ahead-of-time
Python-to-C++ transpiler, Pythran, which can be optionally disabled (via
``export SCIPY_USE_PYTHRAN=0``) but is enabled by default at build time.

There are two changes to the default behavior of `scipy.stats.mannwhitenyu`:

- For years, use of the default ``alternative=None`` was deprecated; explicit
  ``alternative`` specification was required. Use of the new default value of
  ``alternative``, "two-sided", is now permitted.
- Previously, all p-values were based on an asymptotic approximation. Now, for
  small samples without ties, the p-values returned are exact by default.

Support has been added for PEP 621 (project metadata in ``pyproject.toml``)

We now support a Gitpod environment to reduce the barrier to entry for SciPy
development; for more details see :ref:`quickstart-gitpod`.


*******
Authors
*******

* @endolith
* Jelle Aalbers +
* Adam +
* Tania Allard +
* Sven Baars +
* Max Balandat +
* baumgarc +
* Christoph Baumgarten
* Peter Bell
* Lilian Besson
* Robinson Besson +
* Max Bolingbroke
* Blair Bonnett +
* Jordão Bragantini
* Harm Buisman +
* Evgeni Burovski
* Matthias Bussonnier
* Dominic C
* CJ Carey
* Ramón Casero +
* Chachay +
* charlotte12l +
* Benjamin Curtice Corbett +
* Falcon Dai +
* Ian Dall +
* Terry Davis
* droussea2001 +
* DWesl +
* dwight200 +
* Thomas J. Fan +
* Joseph Fox-Rabinovitz
* Max Frei +
* Laura Gutierrez Funderburk +
* gbonomib +
* Matthias Geier +
* Pradipta Ghosh +
* Ralf Gommers
* Evan H +
* h-vetinari
* Matt Haberland
* Anselm Hahn +
* Alex Henrie
* Piet Hessenius +
* Trever Hines +
* Elisha Hollander +
* Stephan Hoyer
* Tom Hu +
* Kei Ishikawa +
* Julien Jerphanion
* Robert Kern
* Shashank KS +
* Peter Mahler Larsen
* Eric Larson
* Cheng H. Lee +
* Gregory R. Lee
* Jean-Benoist Leger +
* lgfunderburk +
* liam-o-marsh +
* Xingyu Liu +
* Alex Loftus +
* Christian Lorentzen +
* Cong Ma
* Marc +
* MarkPundurs +
* Markus Löning +
* Liam Marsh +
* Nicholas McKibben
* melissawm +
* Jamie Morton
* Andrew Nelson
* Nikola Forró
* Tor Nordam +
* Olivier Gauthé +
* Rohit Pandey +
* Avanindra Kumar Pandeya +
* Tirth Patel
* paugier +
* Alex H. Wagner, PhD +
* Jeff Plourde +
* Ilhan Polat
* pranavrajpal +
* Vladyslav Rachek
* Bharat Raghunathan
* Recursing +
* Tyler Reddy
* Lucas Roberts
* Gregor Robinson +
* Pamphile Roy +
* Atsushi Sakai
* Benjamin Santos
* Martin K. Scherer +
* Thomas Schmelzer +
* Daniel Scott +
* Sebastian Wallkötter +
* serge-sans-paille +
* Namami Shanker +
* Masashi Shibata +
* Alexandre de Siqueira +
* Albert Steppi +
* Adam J. Stewart +
* Kai Striega
* Diana Sukhoverkhova
* Søren Fuglede Jørgensen
* Mike Taves
* Dan Temkin +
* Nicolas Tessore +
* tsubota20 +
* Robert Uhl
* christos val +
* Bas van Beek +
* Ashutosh Varma +
* Jose Vazquez +
* Sebastiano Vigna
* Aditya Vijaykumar
* VNMabus
* Arthur Volant +
* Samuel Wallan
* Stefan van der Walt
* Warren Weckesser
* Anreas Weh
* Josh Wilson
* Rory Yorke
* Egor Zemlyanoy
* Marc Zoeller +
* zoj613 +
* 秋纫 +

A total of 126 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


***********************
Issues closed for 1.7.0
***********************

* `#636 <https://github.com/scipy/scipy/issues/636>`__: Statistics Review: mannwhitneyu (Trac #109)
* `#1346 <https://github.com/scipy/scipy/issues/1346>`__: signal.medfilt2d should fall back on signal.medfilt for types...
* `#2118 <https://github.com/scipy/scipy/issues/2118>`__: Mann-Whitney statistic returns incorrect results (Trac #1593)
* `#2158 <https://github.com/scipy/scipy/issues/2158>`__: special.chndtrix (ncx2.ppf) gives wrong results (Trac #1633)
* `#3284 <https://github.com/scipy/scipy/issues/3284>`__: build_sphinx weirdness
* `#3352 <https://github.com/scipy/scipy/issues/3352>`__: beta distribution sf
* `#4067 <https://github.com/scipy/scipy/issues/4067>`__: Mannwhitneyu with arrays full of nan still reports significance
* `#4080 <https://github.com/scipy/scipy/issues/4080>`__: entropy in Scipy
* `#4641 <https://github.com/scipy/scipy/issues/4641>`__: mstats.mannwhitneyu and stats.mannwhitneyu return inconsistent...
* `#5122 <https://github.com/scipy/scipy/issues/5122>`__: scipy.stats.binom.ppf Incorrect for p=0
* `#5180 <https://github.com/scipy/scipy/issues/5180>`__: Rbf interpolation - use only K nearest neighbors
* `#5258 <https://github.com/scipy/scipy/issues/5258>`__: affine_transform complains about output_shape when output array...
* `#5562 <https://github.com/scipy/scipy/issues/5562>`__: Wishart degrees of freedom should be $v > p-1$ instead of $v...
* `#5933 <https://github.com/scipy/scipy/issues/5933>`__: mstats_basic.py - mannwhitneyu [scipy/scipy/stats/mstats_basic.py]
* `#6409 <https://github.com/scipy/scipy/issues/6409>`__: _unequal_var_ttest_denom causes ZeroDivisionError in early samples
* `#6682 <https://github.com/scipy/scipy/issues/6682>`__: negative binomial survival function is imprecise
* `#6897 <https://github.com/scipy/scipy/issues/6897>`__: scipy.stats.mannwhitneyu of empty sets gives p=0.0 and does not...
* `#7303 <https://github.com/scipy/scipy/issues/7303>`__: stats.describe with nan_policy=omit returns matrix-wide minmax...
* `#7406 <https://github.com/scipy/scipy/issues/7406>`__: scipy.stats.binom.ppf returns nan for q between 0 and 1 if n...
* `#7437 <https://github.com/scipy/scipy/issues/7437>`__: ENH: add skewed Cauchy distribution to stats
* `#7542 <https://github.com/scipy/scipy/issues/7542>`__: DOC: stats tutorials: Questions on arcsine and Student t formulae
* `#7593 <https://github.com/scipy/scipy/issues/7593>`__: Meaning of \`tol\` argument in \`scipy.optimize.minimize\` is...
* `#8565 <https://github.com/scipy/scipy/issues/8565>`__: Error in SmoothSphereBivariateSpline(): "ValueError: Error code...
* `#8665 <https://github.com/scipy/scipy/issues/8665>`__: \`scipy.ncx2.sf\` should be monotone decreasing
* `#8836 <https://github.com/scipy/scipy/issues/8836>`__: scipy.optimize.linprog(method='simplex') needs to return duals
* `#9184 <https://github.com/scipy/scipy/issues/9184>`__: Mann-Whitney implementation wrong?
* `#9450 <https://github.com/scipy/scipy/issues/9450>`__: allow seeding of init methods in vq.kmeans2
* `#9704 <https://github.com/scipy/scipy/issues/9704>`__: RectSphereBivariateSpline fails for negative longitude
* `#9836 <https://github.com/scipy/scipy/issues/9836>`__: scipy.stats.rice gives incorrect results when s is very low compared...
* `#9904 <https://github.com/scipy/scipy/issues/9904>`__: Request/Proposal: Greatly improve scipy.interpolate.Rbf
* `#9981 <https://github.com/scipy/scipy/issues/9981>`__: stats.kruskal : add a warning for an input with 2 or more columns
* `#10358 <https://github.com/scipy/scipy/issues/10358>`__: DOC: linprog and linear_sum_assignment tutorials needed
* `#10908 <https://github.com/scipy/scipy/issues/10908>`__: Nakami fitting doesn't converge (scipy.stats)
* `#10933 <https://github.com/scipy/scipy/issues/10933>`__: Add scaled inverse chi2 distribution
* `#11014 <https://github.com/scipy/scipy/issues/11014>`__: Barnard's Test for More Powerful Hypothesis Testing of 2x2 Contingency...
* `#11050 <https://github.com/scipy/scipy/issues/11050>`__: Feature request: Nelder-Mead with bounds
* `#11086 <https://github.com/scipy/scipy/issues/11086>`__: scipy.stats.skew doesn't work correctly for float point numbers
* `#11113 <https://github.com/scipy/scipy/issues/11113>`__: inconsistent result from ttest_ind and mannwhitneyu when used...
* `#11134 <https://github.com/scipy/scipy/issues/11134>`__: Wrong confidence interval for binomial distribution with p=0
* `#11325 <https://github.com/scipy/scipy/issues/11325>`__: Add axis parameter for scipy.spatial.distance.jensenshannon
* `#11474 <https://github.com/scipy/scipy/issues/11474>`__: scipy.stats.skellam.cdf(0) returns 0 for large mu1 = mu2
* `#11523 <https://github.com/scipy/scipy/issues/11523>`__: scipy.stats.zipf doesn't implement zipf distribution
* `#11848 <https://github.com/scipy/scipy/issues/11848>`__: How to get Lagrange / lambda multipliers out of 'linprog' optimize...
* `#11909 <https://github.com/scipy/scipy/issues/11909>`__: Enable bounds for lambda in boxcox
* `#12118 <https://github.com/scipy/scipy/issues/12118>`__: Docstring missing defaults
* `#12132 <https://github.com/scipy/scipy/issues/12132>`__: Slow tests to be trimmed or moved to test('full')
* `#12230 <https://github.com/scipy/scipy/issues/12230>`__: Dendrogram: enable leaves labelling with 'labels' when using...
* `#12282 <https://github.com/scipy/scipy/issues/12282>`__: scipy.stats.chisquare test does not check that observed and expected...
* `#12298 <https://github.com/scipy/scipy/issues/12298>`__: BUG: fmin_powell missing squeeze in 1.5.0rc
* `#12403 <https://github.com/scipy/scipy/issues/12403>`__: Add nan_policy to stats.zmap
* `#12518 <https://github.com/scipy/scipy/issues/12518>`__: Null hypothesis of Kolmogorov Smirnov test is not correctly described
* `#12534 <https://github.com/scipy/scipy/issues/12534>`__: Feature request: scipy.linalg.norm to deal with 0-size array
* `#12622 <https://github.com/scipy/scipy/issues/12622>`__: scipy.interpolate.interpn docstring example
* `#12635 <https://github.com/scipy/scipy/issues/12635>`__: scipy.stats.beta.ppf gives unexpexted results
* `#12669 <https://github.com/scipy/scipy/issues/12669>`__: Median-averaging of complex CSDs
* `#12731 <https://github.com/scipy/scipy/issues/12731>`__: stats.ncx2.cdf fails for nc >> x >> 1
* `#12778 <https://github.com/scipy/scipy/issues/12778>`__: Confusing documentation of scipy.stats.weightedtau
* `#12794 <https://github.com/scipy/scipy/issues/12794>`__: [Bug] The result of stats.beta.isf is inconsistent with stats.beta.sf
* `#12837 <https://github.com/scipy/scipy/issues/12837>`__: stats.mannwhitneyu could support arrays
* `#12868 <https://github.com/scipy/scipy/issues/12868>`__: Vector-valued interpolation in \`interp2d\`
* `#12922 <https://github.com/scipy/scipy/issues/12922>`__: Minimize with trust-constr method leads to TypeError if option...
* `#12929 <https://github.com/scipy/scipy/issues/12929>`__: The use of starred expressions to create data detracts from understanding...
* `#12965 <https://github.com/scipy/scipy/issues/12965>`__: domain of argument of scipy.interpolate.RectSphereBivariateSpline(u,...
* `#13025 <https://github.com/scipy/scipy/issues/13025>`__: Generalized Hyperbolic Distribution
* `#13090 <https://github.com/scipy/scipy/issues/13090>`__: Broken link in doc for signal.max_len_seq
* `#13101 <https://github.com/scipy/scipy/issues/13101>`__: MAINT: Upgrade python version in docker file
* `#13158 <https://github.com/scipy/scipy/issues/13158>`__: \`signal.get_window()\` has a missing doc link and cannot get...
* `#13173 <https://github.com/scipy/scipy/issues/13173>`__: Uninformative error message from bisplev function
* `#13234 <https://github.com/scipy/scipy/issues/13234>`__: BUG: stats: Wrong shape of burr.moment() and fisk.moment() when...
* `#13242 <https://github.com/scipy/scipy/issues/13242>`__: Does kmeans "drop" clusters?
* `#13243 <https://github.com/scipy/scipy/issues/13243>`__: tgsen uses an output argument for computing a default argument
* `#13245 <https://github.com/scipy/scipy/issues/13245>`__: Kurtosis returning 1 for array of same elements
* `#13257 <https://github.com/scipy/scipy/issues/13257>`__: GitHub Actions test failures for MacOS
* `#13272 <https://github.com/scipy/scipy/issues/13272>`__: scipy.stats.yeojohnson_llf doc mistake
* `#13280 <https://github.com/scipy/scipy/issues/13280>`__: Wrong results with hypergeom cdf
* `#13285 <https://github.com/scipy/scipy/issues/13285>`__: description correction in scipy.stats.t
* `#13287 <https://github.com/scipy/scipy/issues/13287>`__: Generate binomial CDF with mu instead of prob
* `#13294 <https://github.com/scipy/scipy/issues/13294>`__: BUG: stats: wrong bounds returned by 'support' method for distributions...
* `#13299 <https://github.com/scipy/scipy/issues/13299>`__: Typing for scipy.spatial
* `#13300 <https://github.com/scipy/scipy/issues/13300>`__: Add a single individual to a latinhypercube initial population...
* `#13311 <https://github.com/scipy/scipy/issues/13311>`__: MAINT: pavement.py PYVER is outdated
* `#13339 <https://github.com/scipy/scipy/issues/13339>`__: savemat discards dimension information if any dimension is zero
* `#13341 <https://github.com/scipy/scipy/issues/13341>`__: add scipy.stats.variation with an ddof parameter
* `#13353 <https://github.com/scipy/scipy/issues/13353>`__: Documentation: in scipy.stats.johnsonsu, parameter \`a\` can...
* `#13405 <https://github.com/scipy/scipy/issues/13405>`__: TST: add a few tests for sparse BSR ctor
* `#13410 <https://github.com/scipy/scipy/issues/13410>`__: BUG: skew for empty array raises
* `#13417 <https://github.com/scipy/scipy/issues/13417>`__: 10,000 times speedup for generating random numbers from the cosine...
* `#13440 <https://github.com/scipy/scipy/issues/13440>`__: python runtest.py -t path-to-test.py failed
* `#13454 <https://github.com/scipy/scipy/issues/13454>`__: Scipy cosine distance can be greater than 2
* `#13459 <https://github.com/scipy/scipy/issues/13459>`__: Broken link in cramervonmises documentation
* `#13494 <https://github.com/scipy/scipy/issues/13494>`__: One-word typo in the documentation of optimize.linprog_simplex
* `#13501 <https://github.com/scipy/scipy/issues/13501>`__: minimize using Powell methods with Bounds leads to "TypeError:...
* `#13509 <https://github.com/scipy/scipy/issues/13509>`__: signal.medfilt2d vs ndimage.median_filter
* `#13511 <https://github.com/scipy/scipy/issues/13511>`__: DOC: error in description of "direc" parameter of "fmin_powell"
* `#13526 <https://github.com/scipy/scipy/issues/13526>`__: TST: stats: intermittent \`test_ttest_ind_randperm_alternative2...
* `#13536 <https://github.com/scipy/scipy/issues/13536>`__: \`_within_tolerance\` seems an unnecessary repetition of \`numpy.isclose\`
* `#13540 <https://github.com/scipy/scipy/issues/13540>`__: missing python 3.8 manylinux wheels on scipy-wheels-nightly
* `#13559 <https://github.com/scipy/scipy/issues/13559>`__: shape error in linprog with revised simplex
* `#13587 <https://github.com/scipy/scipy/issues/13587>`__: binned_statistic unreliable with single precision
* `#13589 <https://github.com/scipy/scipy/issues/13589>`__: Better argument preparation for distributions in stats package.
* `#13602 <https://github.com/scipy/scipy/issues/13602>`__: The crystallball distribution entropy is sometimes minus infinity
* `#13606 <https://github.com/scipy/scipy/issues/13606>`__: MAINT: mypy: some typing errors while running mypy + adding mypy...
* `#13608 <https://github.com/scipy/scipy/issues/13608>`__: Why does stats.binned_statistic_2d convert its values argument...
* `#13609 <https://github.com/scipy/scipy/issues/13609>`__: BUG: SciPy pip install -e gets unusable version spec
* `#13610 <https://github.com/scipy/scipy/issues/13610>`__: Highs solver did not provide a solution nor did it report a failure
* `#13614 <https://github.com/scipy/scipy/issues/13614>`__: BUG: invgauss.cdf should return the correct value when \`mu\`...
* `#13628 <https://github.com/scipy/scipy/issues/13628>`__: 1-letter typo in the definition of scipy.special.spence function...
* `#13634 <https://github.com/scipy/scipy/issues/13634>`__: mmwrite fails on dense, skew-symmetric array
* `#13646 <https://github.com/scipy/scipy/issues/13646>`__: Sparse matrix argmax() integer overflow on Windows 10
* `#13647 <https://github.com/scipy/scipy/issues/13647>`__: \`scipy.stats.qmc.LatinHypercube\` cannot sample single sample...
* `#13651 <https://github.com/scipy/scipy/issues/13651>`__: Documentation wrong in scipy.linalg.eigvalsh
* `#13664 <https://github.com/scipy/scipy/issues/13664>`__: BUG: gamma distribution's inverse survival function overflows...
* `#13693 <https://github.com/scipy/scipy/issues/13693>`__: BUG: sokalmichener appears to incorrectly apply weights
* `#13697 <https://github.com/scipy/scipy/issues/13697>`__: BUG: stats: Spurious warning generated by arcsine.pdf at the...
* `#13704 <https://github.com/scipy/scipy/issues/13704>`__: Make it possible to pass a rank cut-off value relatively to the...
* `#13707 <https://github.com/scipy/scipy/issues/13707>`__: Kullback Leibler Divergence broadcasting no longer works
* `#13740 <https://github.com/scipy/scipy/issues/13740>`__: Scipy.optimize x0 out of bounds when it is within bounds.
* `#13744 <https://github.com/scipy/scipy/issues/13744>`__: scipy.interpolate.interp1d has inconsistent behavior for non-unique...
* `#13754 <https://github.com/scipy/scipy/issues/13754>`__: optimize.minimize 'trust' methods and finite difference Hessian...
* `#13762 <https://github.com/scipy/scipy/issues/13762>`__: MAINT, TST: aarch64 stats test failures showing up in wheels...
* `#13769 <https://github.com/scipy/scipy/issues/13769>`__: probplot draws fit line even when fit=False
* `#13791 <https://github.com/scipy/scipy/issues/13791>`__: BUG: stats: wrapcauchy.cdf does not broadcast the shape parameter...
* `#13793 <https://github.com/scipy/scipy/issues/13793>`__: CI: CircleCI doc build failure
* `#13840 <https://github.com/scipy/scipy/issues/13840>`__: manylinux1 builds are failing because of C99 usage in \`special/_cosine.c\`
* `#13850 <https://github.com/scipy/scipy/issues/13850>`__: CI: Homebrew is failing due to bintray
* `#13875 <https://github.com/scipy/scipy/issues/13875>`__: BUG: chi2_contingency with Yates correction
* `#13878 <https://github.com/scipy/scipy/issues/13878>`__: BUG: \`signal.get_window\` argument handling issue
* `#13880 <https://github.com/scipy/scipy/issues/13880>`__: Remove all usages of numpy.compat
* `#13896 <https://github.com/scipy/scipy/issues/13896>`__: Boschloo's Test for More Powerful Hypothesis Testing of 2x2 Contingency...
* `#13923 <https://github.com/scipy/scipy/issues/13923>`__: Inverse of Log CDF of Normal Distribution
* `#13933 <https://github.com/scipy/scipy/issues/13933>`__: \`signal.get_window\` does not support \`general_cosine\` and...
* `#13950 <https://github.com/scipy/scipy/issues/13950>`__: DOC: scipy.spatial.KDTree.query
* `#13969 <https://github.com/scipy/scipy/issues/13969>`__: N=4 must not exceed M=3
* `#13970 <https://github.com/scipy/scipy/issues/13970>`__: Pearson's original paper on chi-square test could be referenced.
* `#13984 <https://github.com/scipy/scipy/issues/13984>`__: Faster addition of sparse diagonal matrices
* `#13988 <https://github.com/scipy/scipy/issues/13988>`__: An error occurred when using scipy.io.wavfile of scipy 1.6 version...
* `#13997 <https://github.com/scipy/scipy/issues/13997>`__: BUG: sparse: Incorrect result from \`dia_matrix.diagonal()\`
* `#14005 <https://github.com/scipy/scipy/issues/14005>`__: MAINT: optimize: \`curve_fit\` input error msg can be improved.
* `#14038 <https://github.com/scipy/scipy/issues/14038>`__: MAINT: add type annotations for _sobol.pyx
* `#14048 <https://github.com/scipy/scipy/issues/14048>`__: DOC: missing git submodule information
* `#14055 <https://github.com/scipy/scipy/issues/14055>`__: linalg.solve: Unclear error when using assume_a='her' with real...
* `#14093 <https://github.com/scipy/scipy/issues/14093>`__: DOC: Inconsistency in the definition of default values in the...
* `#14158 <https://github.com/scipy/scipy/issues/14158>`__: TST, BUG: test_rbfinterp.py -- test_interpolation_misfit_1d fails...
* `#14170 <https://github.com/scipy/scipy/issues/14170>`__: TST: signal submodule test_filtfilt_gust failing on 32-bit amd64...
* `#14194 <https://github.com/scipy/scipy/issues/14194>`__: MAINT: download-wheels.py missing import
* `#14199 <https://github.com/scipy/scipy/issues/14199>`__: Generated sources for biasedurn extension are broken in 1.7.0rc1


***********************
Pull requests for 1.7.0
***********************

* `#4824 <https://github.com/scipy/scipy/pull/4824>`__: Permutation Ttest (new PR)
* `#4933 <https://github.com/scipy/scipy/pull/4933>`__: ENH: Update the Mann-Whitney-Wilcoxon test
* `#7702 <https://github.com/scipy/scipy/pull/7702>`__: ENH: stats: Add Skewed Cauchy Distribution
* `#8306 <https://github.com/scipy/scipy/pull/8306>`__: Optional Pythran support for scipy.signal.max_len_seq_inner
* `#10170 <https://github.com/scipy/scipy/pull/10170>`__: MAINT: stats: Implement cdf and ppf as ufuncs for the cosine...
* `#10454 <https://github.com/scipy/scipy/pull/10454>`__: ENH: Extend find_peaks_cwt to take numbers and iterables for...
* `#10844 <https://github.com/scipy/scipy/pull/10844>`__: ENH: add stats.qmc module with quasi Monte Carlo functionality
* `#11313 <https://github.com/scipy/scipy/pull/11313>`__: ENH: add Wright's generalized Bessel function
* `#11352 <https://github.com/scipy/scipy/pull/11352>`__: ENH: stats: Add crosstab function.
* `#11477 <https://github.com/scipy/scipy/pull/11477>`__: FIX: bounded parameter in cdfchn.f gives bad results
* `#11695 <https://github.com/scipy/scipy/pull/11695>`__: ENH: stats: add method of moments to \`rv_continuous.fit\`
* `#11911 <https://github.com/scipy/scipy/pull/11911>`__: ENH: Added bounds to boxcox and boxcox_normmax
* `#12438 <https://github.com/scipy/scipy/pull/12438>`__: BUG: use ellipkm1 in elliptical filter design to prevent numerical...
* `#12531 <https://github.com/scipy/scipy/pull/12531>`__: ENH: stats: add Page's L test
* `#12603 <https://github.com/scipy/scipy/pull/12603>`__: ENH: stats: Add \`binomtest\` to replace \`binom_test\`.
* `#12653 <https://github.com/scipy/scipy/pull/12653>`__: ENH: stats: add Somers' D test
* `#12676 <https://github.com/scipy/scipy/pull/12676>`__: BUG: update median averaging in signal.csd
* `#12760 <https://github.com/scipy/scipy/pull/12760>`__: BUG: special: erfinv(x<<1) loses precision
* `#12801 <https://github.com/scipy/scipy/pull/12801>`__: ENH: Add single-sided p-values to remaining spearmanr and linregress
* `#12873 <https://github.com/scipy/scipy/pull/12873>`__: ENH: Stats: add Alexander Govern Test
* `#13008 <https://github.com/scipy/scipy/pull/13008>`__: ENH: Add 'alternative' to functions using normal CDF for p-value
* `#13040 <https://github.com/scipy/scipy/pull/13040>`__: BUG: Allow RectSphereBivariateSpline to accept negative longitude
* `#13048 <https://github.com/scipy/scipy/pull/13048>`__: ENH: stats: Add a function that computes the relative risk.
* `#13067 <https://github.com/scipy/scipy/pull/13067>`__: ENH: Add weights parameter to stats.gmean
* `#13084 <https://github.com/scipy/scipy/pull/13084>`__: ENH: fast Hankel transform
* `#13104 <https://github.com/scipy/scipy/pull/13104>`__: MAINT: upgrade python version (drop python 3.6) for docker dev...
* `#13153 <https://github.com/scipy/scipy/pull/13153>`__: ENH: added association measurements Pearsons Contingency Coefficient,...
* `#13166 <https://github.com/scipy/scipy/pull/13166>`__: ENH: stats: Add nan_policy to zmap.
* `#13175 <https://github.com/scipy/scipy/pull/13175>`__: MAINT: tests for tall cost matrices in \`linear_sum_assignment\`
* `#13177 <https://github.com/scipy/scipy/pull/13177>`__: BUG: raise NotImplementedError in fourier_ellipsoid when ndim...
* `#13184 <https://github.com/scipy/scipy/pull/13184>`__: BUG: stats: Fix min and max calculation of mstats.describe with...
* `#13188 <https://github.com/scipy/scipy/pull/13188>`__: DOC: stats: make null and alternative hypotheses of kstest more...
* `#13193 <https://github.com/scipy/scipy/pull/13193>`__: MAINT: stats: chisquare check sum of observed/expected frequencies
* `#13197 <https://github.com/scipy/scipy/pull/13197>`__: ENH/MAINT: HiGHS upstream enhancements and bug fixes
* `#13198 <https://github.com/scipy/scipy/pull/13198>`__: ENH: allow inference of output_shape from out array in affine_transform
* `#13204 <https://github.com/scipy/scipy/pull/13204>`__: ENH: stats: add Zipfian (different from Zipf/zeta) distribution
* `#13208 <https://github.com/scipy/scipy/pull/13208>`__: REL: set version to 1.7.0.dev0
* `#13216 <https://github.com/scipy/scipy/pull/13216>`__: TST: stats: break up and mark slow tests
* `#13224 <https://github.com/scipy/scipy/pull/13224>`__: Update docs for the weighted τ
* `#13230 <https://github.com/scipy/scipy/pull/13230>`__: ENH: linalg: Add LAPACK wrapper for tgexc.
* `#13232 <https://github.com/scipy/scipy/pull/13232>`__: MAINT: stats: raise error when input to kruskal has >1 dim
* `#13233 <https://github.com/scipy/scipy/pull/13233>`__: DOC: stats: fix MGF of arcsine and entropy of t in tutorial
* `#13236 <https://github.com/scipy/scipy/pull/13236>`__: MAINT: reorganize shared linear assignment tests
* `#13237 <https://github.com/scipy/scipy/pull/13237>`__: BENCH: Refactor stats.Distribution to easily add new distributions
* `#13238 <https://github.com/scipy/scipy/pull/13238>`__: BUG: stats: fix wrong shape output of burr and fisk distributions
* `#13240 <https://github.com/scipy/scipy/pull/13240>`__: MAINT: add tests of trivial cost matrices for linear sum assignment
* `#13252 <https://github.com/scipy/scipy/pull/13252>`__: DOC: optimize: add \`optimize.linear_sum_assignment\` tutorial.
* `#13254 <https://github.com/scipy/scipy/pull/13254>`__: BUG: Fix precision issues for constant input in skew and kurtosis
* `#13262 <https://github.com/scipy/scipy/pull/13262>`__: BUG: scipy.medfilt and .medfilt2d fixes
* `#13263 <https://github.com/scipy/scipy/pull/13263>`__: ENH: add Cramer-von Mises test for two samples
* `#13264 <https://github.com/scipy/scipy/pull/13264>`__: fix a minor typo in \`stats.anderson\` doc
* `#13268 <https://github.com/scipy/scipy/pull/13268>`__: ENH: stats: Add implementation of _entropy for the t distr.
* `#13273 <https://github.com/scipy/scipy/pull/13273>`__: DOC: stats: fix typo in Yeo-Johnson LL function documentation
* `#13275 <https://github.com/scipy/scipy/pull/13275>`__: MAINT: stats: Correct a comment in the _fitstart method of gamma.
* `#13283 <https://github.com/scipy/scipy/pull/13283>`__: BUG: stats: fix the cdf method of rv_discrete class
* `#13286 <https://github.com/scipy/scipy/pull/13286>`__: DOC: stats: clairify rv_continuous/discrete.stats example
* `#13288 <https://github.com/scipy/scipy/pull/13288>`__: DOC: stats: discrete distribution shape parameter restrictions
* `#13289 <https://github.com/scipy/scipy/pull/13289>`__: MAINT: fix a build warning in sigtoolsmodule.c
* `#13290 <https://github.com/scipy/scipy/pull/13290>`__: DOC: Expand the discussion of the nan_policy API.
* `#13291 <https://github.com/scipy/scipy/pull/13291>`__: MAINT: signal, stats: Use keepdims where appropriate.
* `#13292 <https://github.com/scipy/scipy/pull/13292>`__: DOC: stats: note another common parameterization of nbinom
* `#13293 <https://github.com/scipy/scipy/pull/13293>`__: DOC: Change broken link for default values to archived link
* `#13295 <https://github.com/scipy/scipy/pull/13295>`__: BUG: stats: fix the support method to return correct bounds
* `#13296 <https://github.com/scipy/scipy/pull/13296>`__: DOC: stats: Fix latex markup in the kstwo docstring.
* `#13297 <https://github.com/scipy/scipy/pull/13297>`__: TST: mark kde.logpdf overflow test as xslow
* `#13298 <https://github.com/scipy/scipy/pull/13298>`__: Generalized Hyperbolic Distribution
* `#13301 <https://github.com/scipy/scipy/pull/13301>`__: DOC: cluster: Add cluster number note to the docstring of cluster.vq.kmeans
* `#13302 <https://github.com/scipy/scipy/pull/13302>`__: BUG: Fix ndimage.morphology.distance_transform\_\* argument handling
* `#13303 <https://github.com/scipy/scipy/pull/13303>`__: CI: prevent Codecov giving false CI failures and wrong PR annotations
* `#13313 <https://github.com/scipy/scipy/pull/13313>`__: ENH: static typing for qhull
* `#13316 <https://github.com/scipy/scipy/pull/13316>`__: Pythran implementation of scipy.signal._spectral
* `#13317 <https://github.com/scipy/scipy/pull/13317>`__: DOC: forward port 1.6.0 relnotes
* `#13319 <https://github.com/scipy/scipy/pull/13319>`__: ENH: stats: add fast numerical inversion of distribution CDF
* `#13320 <https://github.com/scipy/scipy/pull/13320>`__: ENH: x0 for differential_evolution
* `#13324 <https://github.com/scipy/scipy/pull/13324>`__: DOC correct linprog highs versionadded to 1.6
* `#13326 <https://github.com/scipy/scipy/pull/13326>`__: MAINT: update numpydoc to v1.1.0
* `#13327 <https://github.com/scipy/scipy/pull/13327>`__: DOC: interpolate: improved docstring examples of \`interpolate.interpn()\`...
* `#13328 <https://github.com/scipy/scipy/pull/13328>`__: ENH: Boost stats distributions
* `#13330 <https://github.com/scipy/scipy/pull/13330>`__: ENH: stats: add noncentral hypergeometric distributions (Fisher's...
* `#13331 <https://github.com/scipy/scipy/pull/13331>`__: MAINT/ENH: resolve mypy warnings/errors
* `#13332 <https://github.com/scipy/scipy/pull/13332>`__: DOC: interpolate: improved docstring of \`interpolate.interp2d\`...
* `#13333 <https://github.com/scipy/scipy/pull/13333>`__: ENH: stats: Some more _sf and _isf implementations.
* `#13334 <https://github.com/scipy/scipy/pull/13334>`__: MAINT: stats: Clean up a few defunct comments in _continuous_distns.py
* `#13336 <https://github.com/scipy/scipy/pull/13336>`__: Pythran version of scipy.optimize._group_columns
* `#13337 <https://github.com/scipy/scipy/pull/13337>`__: DOC|ENH: type hinting in scipy.integrate.simpson
* `#13346 <https://github.com/scipy/scipy/pull/13346>`__: ENH: stats: add 'ddof' parameter to the 'variation' function
* `#13355 <https://github.com/scipy/scipy/pull/13355>`__: ENH: stats: implement _logpdf, _sf and _isf for loggamma.
* `#13360 <https://github.com/scipy/scipy/pull/13360>`__: ENH|DOC: fix docstring and input validation in interpolate.RectSphereBivariateSpline
* `#13366 <https://github.com/scipy/scipy/pull/13366>`__: BUG: stats: Don't raise ZeroDivisionError in _unequal_var_ttest_denom
* `#13370 <https://github.com/scipy/scipy/pull/13370>`__: ENH: fix ARGUS distribution for small parameters in stats
* `#13371 <https://github.com/scipy/scipy/pull/13371>`__: ENH: stats: add \`bootstrap\` for estimating confidence interval...
* `#13373 <https://github.com/scipy/scipy/pull/13373>`__: BUG: io/matlab: preserve dimensions of empty >=2D arrays
* `#13374 <https://github.com/scipy/scipy/pull/13374>`__: ENH: stats: add skewed Cauchy distribution
* `#13379 <https://github.com/scipy/scipy/pull/13379>`__: BUG: sparse: fix verbosity in sparse lsqr
* `#13383 <https://github.com/scipy/scipy/pull/13383>`__: TST: stats: mark many dimension permutation t-test slow
* `#13384 <https://github.com/scipy/scipy/pull/13384>`__: MAINT: Make keywords array static
* `#13388 <https://github.com/scipy/scipy/pull/13388>`__: PERF: Avoid duplicate mean calculations in skew and kurtosis
* `#13389 <https://github.com/scipy/scipy/pull/13389>`__: DOC: Fix deprecated directive syntax
* `#13390 <https://github.com/scipy/scipy/pull/13390>`__: DOC: Correct line length for Parameter Section underline
* `#13393 <https://github.com/scipy/scipy/pull/13393>`__: MAINT: stats: allow wishart dim - 1 < df < dim
* `#13395 <https://github.com/scipy/scipy/pull/13395>`__: DOC: fix typo in setup.py warning message
* `#13396 <https://github.com/scipy/scipy/pull/13396>`__: BUG: Fix MLE for Nakagami \`nakagami_gen.fit\`
* `#13397 <https://github.com/scipy/scipy/pull/13397>`__: MAINT:linalg: Fix tgsen family wrapper and ordqz
* `#13406 <https://github.com/scipy/scipy/pull/13406>`__: TST: add error handling tests for sparse BSR ctor
* `#13413 <https://github.com/scipy/scipy/pull/13413>`__: DOC: ultra-quickstart guide
* `#13418 <https://github.com/scipy/scipy/pull/13418>`__: BUG: Fix moment returning inconsistent types and shapes
* `#13423 <https://github.com/scipy/scipy/pull/13423>`__: DOC: Update example for leaf_label_func/dendrogram
* `#13431 <https://github.com/scipy/scipy/pull/13431>`__: ENH: stats: override _rvs for nhypergeom
* `#13432 <https://github.com/scipy/scipy/pull/13432>`__: Add indicator in NDInterpolator docstring that N must be > 1
* `#13434 <https://github.com/scipy/scipy/pull/13434>`__: DOC: stats: note relationship between scaled-inv-chi2 and invgamma
* `#13436 <https://github.com/scipy/scipy/pull/13436>`__: ENH: interpolate: add input validation to check input x-y is...
* `#13441 <https://github.com/scipy/scipy/pull/13441>`__: ENH: add functionality \`barnard_exact\` test to scipy.stats.
* `#13443 <https://github.com/scipy/scipy/pull/13443>`__: MAINT: stats: Updates for skewcauchy
* `#13444 <https://github.com/scipy/scipy/pull/13444>`__: DOC: clarify range of \`a\` parameter fpr johnsonsu/johnsonsb
* `#13445 <https://github.com/scipy/scipy/pull/13445>`__: DOC: fix runtests guidelines.
* `#13446 <https://github.com/scipy/scipy/pull/13446>`__: MAINT: stats: Add _fitstart method to wrapcauchy.
* `#13447 <https://github.com/scipy/scipy/pull/13447>`__: DEV: Update development Docker image
* `#13448 <https://github.com/scipy/scipy/pull/13448>`__: ENH: Add annotations for \`scipy.spatial.distance\`
* `#13451 <https://github.com/scipy/scipy/pull/13451>`__: DOC: minor formatting.
* `#13458 <https://github.com/scipy/scipy/pull/13458>`__: DOC: indent see also.
* `#13460 <https://github.com/scipy/scipy/pull/13460>`__: DOC: stats: Fix link to Cramer-von Mises wikipedia article.
* `#13461 <https://github.com/scipy/scipy/pull/13461>`__: DOC: reorganize scipy.stats overview docs page
* `#13463 <https://github.com/scipy/scipy/pull/13463>`__: DOC: misc formatting fixes
* `#13466 <https://github.com/scipy/scipy/pull/13466>`__: DOC: Typo in see also s/SmoothUni/SmoothBi/g
* `#13467 <https://github.com/scipy/scipy/pull/13467>`__: DOC: optimize: add description about \`tol\` argument for \`minimize\`.
* `#13469 <https://github.com/scipy/scipy/pull/13469>`__: MAINT: Refactor optimization methods to use scipy.stats.qmc
* `#13477 <https://github.com/scipy/scipy/pull/13477>`__: CI: pin numpy to 1.19.5 for the three macOS CI jobs
* `#13478 <https://github.com/scipy/scipy/pull/13478>`__: DOC: fix typos where double :: for Sphinx directives were missing
* `#13481 <https://github.com/scipy/scipy/pull/13481>`__: CI: pin numpy to 1.19.5 in the 4 parallel Windows builds on Azure
* `#13482 <https://github.com/scipy/scipy/pull/13482>`__: CI: use numpy 1.20.0 again in macOS CI
* `#13483 <https://github.com/scipy/scipy/pull/13483>`__: DOC: Multiple documentation syntax fixes.
* `#13484 <https://github.com/scipy/scipy/pull/13484>`__: Move some pythran config from CI to setup
* `#13487 <https://github.com/scipy/scipy/pull/13487>`__: DOC: add a tutorial about scipy.stats.qmc
* `#13492 <https://github.com/scipy/scipy/pull/13492>`__: ENH: GH actions should not run on forks
* `#13493 <https://github.com/scipy/scipy/pull/13493>`__: DEV: Enable gitpod for SciPy
* `#13495 <https://github.com/scipy/scipy/pull/13495>`__: DOC One-word typo in the documentation of optimize.linprog_simplex
* `#13499 <https://github.com/scipy/scipy/pull/13499>`__: DOC: describe LSAP implementation
* `#13502 <https://github.com/scipy/scipy/pull/13502>`__: BUG: Bounds created with lists weren't working for Powell
* `#13507 <https://github.com/scipy/scipy/pull/13507>`__: MAINT, TST: stats: centralize invalid parameters list for all...
* `#13510 <https://github.com/scipy/scipy/pull/13510>`__: DOC: stats: fix small doc errors in 'multivariate_hypergeom'
* `#13513 <https://github.com/scipy/scipy/pull/13513>`__: DOC: Added math notation in examples in ltisys.py
* `#13514 <https://github.com/scipy/scipy/pull/13514>`__: ENH: simplify low_0_bit function for Sobol
* `#13515 <https://github.com/scipy/scipy/pull/13515>`__: ENH: optimize: add bound constraint support for nelder-mead solver
* `#13516 <https://github.com/scipy/scipy/pull/13516>`__: DOC: reduce LaTeX usage for johnsonb docstring
* `#13519 <https://github.com/scipy/scipy/pull/13519>`__: BLD: remove build_sphinx support from setup.py
* `#13527 <https://github.com/scipy/scipy/pull/13527>`__: TST: stats: xfail ttest_ind_randperm_alternative2 on 32 bit
* `#13530 <https://github.com/scipy/scipy/pull/13530>`__: DOC: correct comparisons between median filter functions
* `#13532 <https://github.com/scipy/scipy/pull/13532>`__: ENH: release the GIL inside medfilt2d
* `#13538 <https://github.com/scipy/scipy/pull/13538>`__: DOC: optimize: fix minor doc error in 'fmin_powell' (#13511)
* `#13546 <https://github.com/scipy/scipy/pull/13546>`__: DOC: fix list of "mode" options for ndimage
* `#13549 <https://github.com/scipy/scipy/pull/13549>`__: ENH: stats: add 'alternative' keyword to some normality tests.
* `#13551 <https://github.com/scipy/scipy/pull/13551>`__: MAINT: add git to docker env
* `#13552 <https://github.com/scipy/scipy/pull/13552>`__: MAINT: stats: remove float_power shim
* `#13553 <https://github.com/scipy/scipy/pull/13553>`__: DOC: use support rather than a/b in stats tutorial
* `#13560 <https://github.com/scipy/scipy/pull/13560>`__: MAINT: optimize: improve linprog error message for sparse input...
* `#13562 <https://github.com/scipy/scipy/pull/13562>`__: MAINT: optimize: using np.isclose instead of _within_tolerance.
* `#13566 <https://github.com/scipy/scipy/pull/13566>`__: ENH: Speed up hdquantiles_sd()
* `#13569 <https://github.com/scipy/scipy/pull/13569>`__: BENCH: optimize: benchmark only HiGHS methods; add bigger linprog...
* `#13574 <https://github.com/scipy/scipy/pull/13574>`__: DOC: In description of cluster.hierarchy.dendrogram 'level' parameter,...
* `#13576 <https://github.com/scipy/scipy/pull/13576>`__: ENH: improve discrepancy performance
* `#13579 <https://github.com/scipy/scipy/pull/13579>`__: TST: Add pybind11 to tox environments
* `#13583 <https://github.com/scipy/scipy/pull/13583>`__: BUG: Fix Dockerfile apt-get installs
* `#13588 <https://github.com/scipy/scipy/pull/13588>`__: MAINT: forward port 1.6.1 relnotes.
* `#13593 <https://github.com/scipy/scipy/pull/13593>`__: BUG: stats: preserve sample dtype for bin edges
* `#13595 <https://github.com/scipy/scipy/pull/13595>`__: ENH: interpolate: add RBFInterpolator
* `#13596 <https://github.com/scipy/scipy/pull/13596>`__: DOC: Fix indentation in new_stats_distribution.rst.inc
* `#13601 <https://github.com/scipy/scipy/pull/13601>`__: Add dpss for get_window function
* `#13604 <https://github.com/scipy/scipy/pull/13604>`__: DOC: Correct dual annealing visiting param range.
* `#13605 <https://github.com/scipy/scipy/pull/13605>`__: Add Codecov badge to README
* `#13607 <https://github.com/scipy/scipy/pull/13607>`__: MAINT: stats: fix crystalball entropy
* `#13611 <https://github.com/scipy/scipy/pull/13611>`__: Better argument preparation for distributions in stats package.
* `#13612 <https://github.com/scipy/scipy/pull/13612>`__: Add docker run command for Windows cmd
* `#13613 <https://github.com/scipy/scipy/pull/13613>`__: MAINT, CI: mypy: fix typing errors + add mypy to CI
* `#13616 <https://github.com/scipy/scipy/pull/13616>`__: FIX: Return correct output for invgauss.cdf when mu is very small
* `#13617 <https://github.com/scipy/scipy/pull/13617>`__: MAINT: accept numbers and iterables for width in find_peaks_cwt
* `#13620 <https://github.com/scipy/scipy/pull/13620>`__: CI: disable the mypy CI job (partial revert of gh-13613)
* `#13621 <https://github.com/scipy/scipy/pull/13621>`__: DOC: signal: use array_like for input types
* `#13622 <https://github.com/scipy/scipy/pull/13622>`__: MAINT: clean up some unused files, make \`mypy scipy\` pass
* `#13623 <https://github.com/scipy/scipy/pull/13623>`__: CI: enable Mypy CI job again
* `#13624 <https://github.com/scipy/scipy/pull/13624>`__: TST: test more values for \`visiting_param\` input to \`dual_annealing\`
* `#13625 <https://github.com/scipy/scipy/pull/13625>`__: Rename integrate.simps to integrate.simpsons in documentation...
* `#13631 <https://github.com/scipy/scipy/pull/13631>`__: ENH: add a \`stats.differential_entropy\` function
* `#13633 <https://github.com/scipy/scipy/pull/13633>`__: BUG: stats.binned_statistic_2d user function expecting arrays
* `#13641 <https://github.com/scipy/scipy/pull/13641>`__: ENH: Added degrees parameter to rotvec
* `#13645 <https://github.com/scipy/scipy/pull/13645>`__: MAINT: mypy: don't install numpy-stubs
* `#13649 <https://github.com/scipy/scipy/pull/13649>`__: BUG: sparse: csc_matrix.argmax() integer overflow
* `#13650 <https://github.com/scipy/scipy/pull/13650>`__: ENH: stats: add 'alternative' parameter to ansari
* `#13652 <https://github.com/scipy/scipy/pull/13652>`__: DOC: fix eigvalsh documentation (#13651)
* `#13654 <https://github.com/scipy/scipy/pull/13654>`__: BUG: Fix LatinHypercubes
* `#13656 <https://github.com/scipy/scipy/pull/13656>`__: DOC: Fix PCHIP references
* `#13657 <https://github.com/scipy/scipy/pull/13657>`__: TST: remove IPython warning in debug session
* `#13658 <https://github.com/scipy/scipy/pull/13658>`__: Remove spurious quotes in docstring
* `#13661 <https://github.com/scipy/scipy/pull/13661>`__: ENH: stats: improve efficiency of / fix bug in exact permutation...
* `#13667 <https://github.com/scipy/scipy/pull/13667>`__: MAINT: Make latest Docker image default
* `#13668 <https://github.com/scipy/scipy/pull/13668>`__: MAINT: add .theia/ to .gitignore
* `#13669 <https://github.com/scipy/scipy/pull/13669>`__: BLD: change SCIPY_USE_PYTHRAN default to \`1\`
* `#13676 <https://github.com/scipy/scipy/pull/13676>`__: ENH Small improvements for LSQR with damp
* `#13678 <https://github.com/scipy/scipy/pull/13678>`__: MAINT: add Pythran-generated files to .gitignore
* `#13679 <https://github.com/scipy/scipy/pull/13679>`__: MAINT: move the \`conda develop .\` in the Gitpod config
* `#13680 <https://github.com/scipy/scipy/pull/13680>`__: DOC: Add cKDTree note comparing it with KDTree
* `#13681 <https://github.com/scipy/scipy/pull/13681>`__: DOC: build doc updates on Pythran, compiled code, and cleanups
* `#13683 <https://github.com/scipy/scipy/pull/13683>`__: BUG: mmwrite correctly serializes non skew-symmetric arrays
* `#13684 <https://github.com/scipy/scipy/pull/13684>`__: FIX: fix numerical overflow in gamma.isf method
* `#13685 <https://github.com/scipy/scipy/pull/13685>`__: BUG: fix cosine distance range to 0-2
* `#13694 <https://github.com/scipy/scipy/pull/13694>`__: MAINT: fix warning emitted when NumPy version is incorrect
* `#13696 <https://github.com/scipy/scipy/pull/13696>`__: ENH: support trimming in ttest_ind
* `#13698 <https://github.com/scipy/scipy/pull/13698>`__: BUG: stats: Fix spurious warnings generated by arcsine.pdf
* `#13701 <https://github.com/scipy/scipy/pull/13701>`__: DEV: scipy.interpolate b-splines (periodic case)
* `#13702 <https://github.com/scipy/scipy/pull/13702>`__: DEP: Clean up spent deprecations in spatial.distance
* `#13703 <https://github.com/scipy/scipy/pull/13703>`__: MAINT: fix issues found by static code analysis
* `#13706 <https://github.com/scipy/scipy/pull/13706>`__: ENH: stats: Implement sf and isf for the laplace distribution.
* `#13711 <https://github.com/scipy/scipy/pull/13711>`__: MAINT: stats: fix broadcasting for scipy.stats.entropy
* `#13712 <https://github.com/scipy/scipy/pull/13712>`__: BUG: stats: Override _fitstart for the invweibull distribution.
* `#13713 <https://github.com/scipy/scipy/pull/13713>`__: DOC: update toolchain.rst to reflect windows universal C runtime
* `#13714 <https://github.com/scipy/scipy/pull/13714>`__: MAINT: stats: Remove an unused list from test_continuous_basic.py.
* `#13715 <https://github.com/scipy/scipy/pull/13715>`__: MAINT: stats: No need to suppress frechet deprecation warnings.
* `#13716 <https://github.com/scipy/scipy/pull/13716>`__: MAINT: use super() as described by PEP 3135
* `#13718 <https://github.com/scipy/scipy/pull/13718>`__: MAINT: new-style class, removing inheritance to object
* `#13721 <https://github.com/scipy/scipy/pull/13721>`__: MAINT: add a type-ignore for mpmath (#13721)
* `#13723 <https://github.com/scipy/scipy/pull/13723>`__: MAINT: mypy: ignore mpmath imports in mypy.ini
* `#13724 <https://github.com/scipy/scipy/pull/13724>`__: DOC: pydata sphinx theme
* `#13725 <https://github.com/scipy/scipy/pull/13725>`__: BENCH: add benchmark for Kendalltau
* `#13727 <https://github.com/scipy/scipy/pull/13727>`__: CI: simplify Pythran configuration setup for Azure
* `#13731 <https://github.com/scipy/scipy/pull/13731>`__: MAINT: stats: Some flake8-driven clean up.
* `#13732 <https://github.com/scipy/scipy/pull/13732>`__: ENH: stats: Studentized Range Distribution
* `#13735 <https://github.com/scipy/scipy/pull/13735>`__: DOC: correct Voronoi docstring
* `#13738 <https://github.com/scipy/scipy/pull/13738>`__: DOC: add example to wright_bessel
* `#13739 <https://github.com/scipy/scipy/pull/13739>`__: ENH: stats: Implement _sf and _isf for the chi distribution.
* `#13741 <https://github.com/scipy/scipy/pull/13741>`__: MAINT: prevent overwriting of x in minimize
* `#13747 <https://github.com/scipy/scipy/pull/13747>`__: DOC: Add note for interp1d for non-unique x-values
* `#13749 <https://github.com/scipy/scipy/pull/13749>`__: MAINT: forward port 1.6.2 relnotes
* `#13759 <https://github.com/scipy/scipy/pull/13759>`__: MAINT: simpson small performance speedups
* `#13765 <https://github.com/scipy/scipy/pull/13765>`__: FIX: npymath missing causing npy_log1p to be unknown
* `#13768 <https://github.com/scipy/scipy/pull/13768>`__: BENCH: Add missing pythran dependency
* `#13770 <https://github.com/scipy/scipy/pull/13770>`__: ENH: stats.contingency: Add the sparse option to crosstab.
* `#13774 <https://github.com/scipy/scipy/pull/13774>`__: DEP: Deprecate squeezing input vectors in spatial.distance
* `#13775 <https://github.com/scipy/scipy/pull/13775>`__: Enable trust region methods to use a finite difference Hessian...
* `#13777 <https://github.com/scipy/scipy/pull/13777>`__: DOC: Fix Ubuntu/Debian installation instructions
* `#13778 <https://github.com/scipy/scipy/pull/13778>`__: DOC: remove references to RandomState
* `#13782 <https://github.com/scipy/scipy/pull/13782>`__: MAINT: LBFGSB err msg on MAXLS changed closes #11718
* `#13785 <https://github.com/scipy/scipy/pull/13785>`__: BENCH: Add benchmark for cdist/pdist with weights
* `#13786 <https://github.com/scipy/scipy/pull/13786>`__: MAINT: Prepare cdist/pdist for C++ rework
* `#13787 <https://github.com/scipy/scipy/pull/13787>`__: MAINT: stats: move entropy and differential_entropy functions...
* `#13790 <https://github.com/scipy/scipy/pull/13790>`__: DOC: Add some dependencies for Dockerfile doc of scipy development.
* `#13792 <https://github.com/scipy/scipy/pull/13792>`__: BUG: stats: Fix broadcasting in wrapcauchy.cdf
* `#13795 <https://github.com/scipy/scipy/pull/13795>`__: MAINT: stats: add hypotests to __all__ in init.py, not stats.py
* `#13797 <https://github.com/scipy/scipy/pull/13797>`__: MAINT: stats: probplot: don't plot least-squares fit line unless...
* `#13798 <https://github.com/scipy/scipy/pull/13798>`__: MAINT: fix incorrect code comment in \`hierarchy.to_tree\`
* `#13802 <https://github.com/scipy/scipy/pull/13802>`__: DEV: add environment.yml file for development with conda/mamba
* `#13803 <https://github.com/scipy/scipy/pull/13803>`__: DOC: fix doc build warning about arxiv role already being registered
* `#13804 <https://github.com/scipy/scipy/pull/13804>`__: DOC+MAINT: optimize: lb and ub in the Bounds constructor are...
* `#13807 <https://github.com/scipy/scipy/pull/13807>`__: MAINT: Dont use parallel Sphinx
* `#13808 <https://github.com/scipy/scipy/pull/13808>`__: MAINT: cluster.to_tree: more idiomatic looping over rows of matrix...
* `#13810 <https://github.com/scipy/scipy/pull/13810>`__: MAINT: add a CODEOWNERS file
* `#13811 <https://github.com/scipy/scipy/pull/13811>`__: MAINT: Add ci skip to azp
* `#13814 <https://github.com/scipy/scipy/pull/13814>`__: ENH/DOC: pydata sphinx theme polishing
* `#13817 <https://github.com/scipy/scipy/pull/13817>`__: DOC: Misc parameter typo and casing in scipy/linalg/_decomp_ldl.py
* `#13818 <https://github.com/scipy/scipy/pull/13818>`__: MAINT: stats: keep \`entropy\` importable from \`scipy.stats.distributions\`
* `#13820 <https://github.com/scipy/scipy/pull/13820>`__: BUG: update _kendall_p_exact ValueError to f-string
* `#13831 <https://github.com/scipy/scipy/pull/13831>`__: FIX:DEP: Allow better tolerance control for pinv and pinvh and...
* `#13832 <https://github.com/scipy/scipy/pull/13832>`__: BUG: stats: Fix rvs for levy_stable when alpha=1
* `#13833 <https://github.com/scipy/scipy/pull/13833>`__: MAINT: Add inline type hintings for stats.qmc
* `#13836 <https://github.com/scipy/scipy/pull/13836>`__: MAINT: Fix a couple compiler warnings.
* `#13838 <https://github.com/scipy/scipy/pull/13838>`__: TST: relax test tolerances for BinomTest
* `#13841 <https://github.com/scipy/scipy/pull/13841>`__: BLD: add \`-std=c99\` flag to scipy.special extensions using...
* `#13845 <https://github.com/scipy/scipy/pull/13845>`__: ENH: stats: add \`method\` parameter to \`differential_entropy\`...
* `#13847 <https://github.com/scipy/scipy/pull/13847>`__: TST: skip on optimize failure on macOS, mark one as xfail
* `#13848 <https://github.com/scipy/scipy/pull/13848>`__: DOC: optimize: move Nelder Mead doc from Unconstrained minimization...
* `#13849 <https://github.com/scipy/scipy/pull/13849>`__: DOC: Roadmap update
* `#13852 <https://github.com/scipy/scipy/pull/13852>`__: CI: fix temporary wrong brew version from GitHub
* `#13854 <https://github.com/scipy/scipy/pull/13854>`__: ENH: Update Scipy Gitpod
* `#13859 <https://github.com/scipy/scipy/pull/13859>`__: TST: fix ultra-slow ttest permutations test
* `#13860 <https://github.com/scipy/scipy/pull/13860>`__: MAINT: clean up LSAP error checking
* `#13863 <https://github.com/scipy/scipy/pull/13863>`__: DOC: remove seed in examples
* `#13865 <https://github.com/scipy/scipy/pull/13865>`__: DOC: optimize: The bounds param of differential_evolution is...
* `#13866 <https://github.com/scipy/scipy/pull/13866>`__: MAINT: special: Remove an unused variable from _poly_approx in...
* `#13867 <https://github.com/scipy/scipy/pull/13867>`__: DOC: stats: Explain meaning of alternatives for fisher_exact.
* `#13868 <https://github.com/scipy/scipy/pull/13868>`__: CI: fix the failing job on linux.
* `#13870 <https://github.com/scipy/scipy/pull/13870>`__: MAINT: move LSAP rectangular matrix handling into solver code
* `#13871 <https://github.com/scipy/scipy/pull/13871>`__: DOC: Add Gitpod documentation
* `#13876 <https://github.com/scipy/scipy/pull/13876>`__: Workflow : Add nightly release of NumPy in linux workflows
* `#13877 <https://github.com/scipy/scipy/pull/13877>`__: DOC: Conform to numpydoc + uniformity.
* `#13879 <https://github.com/scipy/scipy/pull/13879>`__: BUG: signal: fix get_window argument handling and add tests.
* `#13881 <https://github.com/scipy/scipy/pull/13881>`__: CI: remove .travis.yml, remove codecov from CircleCI
* `#13882 <https://github.com/scipy/scipy/pull/13882>`__: BLD: ensure incrementing dev version strings
* `#13886 <https://github.com/scipy/scipy/pull/13886>`__: TST: optimize: skip test_network_flow_limited_capacity w/ UMFPACK...
* `#13888 <https://github.com/scipy/scipy/pull/13888>`__: MAINT: Fix issues involving elif conditions
* `#13891 <https://github.com/scipy/scipy/pull/13891>`__: Rename InivariateSpline to UnivariateSpline
* `#13893 <https://github.com/scipy/scipy/pull/13893>`__: ENH: linprog HiGHS marginals/sensitivy analysis
* `#13894 <https://github.com/scipy/scipy/pull/13894>`__: DOC: Add blank line before \`Return\` section.
* `#13897 <https://github.com/scipy/scipy/pull/13897>`__: DOC: BLD: fix doc build version check, and improve build time
* `#13903 <https://github.com/scipy/scipy/pull/13903>`__: MAINT: Gitpod fixes
* `#13907 <https://github.com/scipy/scipy/pull/13907>`__: ENH: Rewrite minkowski metric in C++ with pybind11
* `#13909 <https://github.com/scipy/scipy/pull/13909>`__: Revert "Workflow : Add nightly release of NumPy in linux workflows"
* `#13910 <https://github.com/scipy/scipy/pull/13910>`__: DOC: update Readme
* `#13911 <https://github.com/scipy/scipy/pull/13911>`__: MAINT: use dict built-in rather than OrderedDict
* `#13920 <https://github.com/scipy/scipy/pull/13920>`__: BUG: Reactivate conda environment in init
* `#13925 <https://github.com/scipy/scipy/pull/13925>`__: BUG: stats: magnitude of Yates' correction <= abs(observed-expected)...
* `#13926 <https://github.com/scipy/scipy/pull/13926>`__: DOC: correct return type in disjoint_set.subsets docstring
* `#13927 <https://github.com/scipy/scipy/pull/13927>`__: DOC/MAINT: Add copyright notice to qmc.primes_from_2_to
* `#13928 <https://github.com/scipy/scipy/pull/13928>`__: BUG: DOC: signal: fix need argument config and add missing doc...
* `#13929 <https://github.com/scipy/scipy/pull/13929>`__: REL: add PEP 621 (project metadata in pyproject.toml) support
* `#13931 <https://github.com/scipy/scipy/pull/13931>`__: MAINT: special: get rid of _logit.c.src
* `#13934 <https://github.com/scipy/scipy/pull/13934>`__: ENH: signal: make \`get_window\` supports \`general_cosine\`...
* `#13940 <https://github.com/scipy/scipy/pull/13940>`__: MAINT: QMCEngine d input validation
* `#13941 <https://github.com/scipy/scipy/pull/13941>`__: MAINT: forward port 1.6.3 relnotes
* `#13944 <https://github.com/scipy/scipy/pull/13944>`__: BUG: spatial: fix weight handling of \`distance.sokalmichener\`.
* `#13947 <https://github.com/scipy/scipy/pull/13947>`__: MAINT: Remove duplicate calculations in sokalmichener
* `#13949 <https://github.com/scipy/scipy/pull/13949>`__: DOC: minor grammar fixes in minimize and KDTree.query
* `#13951 <https://github.com/scipy/scipy/pull/13951>`__: ENH: Add Boschloo exact test to stats
* `#13956 <https://github.com/scipy/scipy/pull/13956>`__: ENH: spatial: add \`axis\` and \`keepdims\` optional argument...
* `#13963 <https://github.com/scipy/scipy/pull/13963>`__: MAINT: stats: Fix unused imports and a few other issues related...
* `#13971 <https://github.com/scipy/scipy/pull/13971>`__: DOC: Add Karl Pearson's reference to chi-square test
* `#13972 <https://github.com/scipy/scipy/pull/13972>`__: ENH: cluster: add an optional argument \`seed\` for \`kmeans\`...
* `#13973 <https://github.com/scipy/scipy/pull/13973>`__: BLD: fix build warnings for causal/anticausal pointers in ndimage
* `#13975 <https://github.com/scipy/scipy/pull/13975>`__: ENH: set empty array norm to zero.
* `#13977 <https://github.com/scipy/scipy/pull/13977>`__: MAINT: signal: replace distutils templating with tempita
* `#13978 <https://github.com/scipy/scipy/pull/13978>`__: MAINT: improve validations and keyword only arguments for some...
* `#13979 <https://github.com/scipy/scipy/pull/13979>`__: ENH: Add Inverse of Log CDF of Normal Distribution
* `#13983 <https://github.com/scipy/scipy/pull/13983>`__: Fixing \`ndimage.watershed_ift\` tutorial's documentation
* `#13987 <https://github.com/scipy/scipy/pull/13987>`__: DOC: Adding examples to docstrings in morphology: white_tophat,...
* `#13989 <https://github.com/scipy/scipy/pull/13989>`__: DOC: interpolate: improve examples of \`RegularGridInterpolator\`...
* `#13990 <https://github.com/scipy/scipy/pull/13990>`__: MAINT, DOC: optimize: Make the input validation explanation clear...
* `#13992 <https://github.com/scipy/scipy/pull/13992>`__: Workflow : Add nightly release of NumPy in linux workflows
* `#13995 <https://github.com/scipy/scipy/pull/13995>`__: Doc: Continuous integration information
* `#14000 <https://github.com/scipy/scipy/pull/14000>`__: BUG: sparse: Fix DIA.diagonal bug and add a regression test
* `#14004 <https://github.com/scipy/scipy/pull/14004>`__: ENH: Fast addition dia matrix
* `#14006 <https://github.com/scipy/scipy/pull/14006>`__: MAINT: optimize: add validation to check func parameter number...
* `#14008 <https://github.com/scipy/scipy/pull/14008>`__: BUG: Raise exception for inconsistent WAV header
* `#14009 <https://github.com/scipy/scipy/pull/14009>`__: DEP: Remove usage of numpy.compat
* `#14010 <https://github.com/scipy/scipy/pull/14010>`__: MAINT: add support for wheel DL proxy
* `#14012 <https://github.com/scipy/scipy/pull/14012>`__: DOC: Broaden Exact Test Reference
* `#14015 <https://github.com/scipy/scipy/pull/14015>`__: MAINT: remove brew update
* `#14017 <https://github.com/scipy/scipy/pull/14017>`__: BENCH: Add more formats for sparse arithmetic
* `#14018 <https://github.com/scipy/scipy/pull/14018>`__: BENCH: add benchmark for f_oneway
* `#14020 <https://github.com/scipy/scipy/pull/14020>`__: MAINT: modify np.int\_ to np.int32 to make it the same for 32/64...
* `#14023 <https://github.com/scipy/scipy/pull/14023>`__: MAINT: Fix clang build and remove some unicode characters
* `#14025 <https://github.com/scipy/scipy/pull/14025>`__: BUG: sparse: fix DIA.setdiag issue
* `#14026 <https://github.com/scipy/scipy/pull/14026>`__: TST: optimize: xfail part of test_powell
* `#14029 <https://github.com/scipy/scipy/pull/14029>`__: CI: github macos fix
* `#14030 <https://github.com/scipy/scipy/pull/14030>`__: MAINT: use 'yield from <expr>' (PEP 380)
* `#14031 <https://github.com/scipy/scipy/pull/14031>`__: MAINT: new-style class, removing inheritance to object
* `#14032 <https://github.com/scipy/scipy/pull/14032>`__: MAINT: CXXFLAGS for Pythran
* `#14033 <https://github.com/scipy/scipy/pull/14033>`__: ENH: Port sqeuclidean and braycurtis to _distance_pybind
* `#14034 <https://github.com/scipy/scipy/pull/14034>`__: MAINT: Clean-up 'next = __next__'
* `#14045 <https://github.com/scipy/scipy/pull/14045>`__: MAINT: bump PYVER pavement.py
* `#14047 <https://github.com/scipy/scipy/pull/14047>`__: DEV: initialize boost submodule in Gitpod Dockerfile
* `#14051 <https://github.com/scipy/scipy/pull/14051>`__: BLD: if boost submodule content is missing, error out early
* `#14052 <https://github.com/scipy/scipy/pull/14052>`__: DOC: missing submodule init information
* `#14057 <https://github.com/scipy/scipy/pull/14057>`__: DOC: special: Add Examples to \`psi\` docstring
* `#14058 <https://github.com/scipy/scipy/pull/14058>`__: BUG: fixed a dtype bug in linalg.solve.
* `#14060 <https://github.com/scipy/scipy/pull/14060>`__: Doc: Fix typo in documentation of spence function.
* `#14061 <https://github.com/scipy/scipy/pull/14061>`__: MAINT:stats: Type annotations for _sobol.pyx
* `#14062 <https://github.com/scipy/scipy/pull/14062>`__: DOC: A few small fixes in quickstart_gitpod.rst
* `#14063 <https://github.com/scipy/scipy/pull/14063>`__: DOC: signal: add Add Examples to \`cont2discrete\` docstring
* `#14064 <https://github.com/scipy/scipy/pull/14064>`__: DOC: optimize: Add Examples to fmin_bfgs docstring
* `#14065 <https://github.com/scipy/scipy/pull/14065>`__: Add example for scipy stats.trim1 under docstring
* `#14066 <https://github.com/scipy/scipy/pull/14066>`__: DOC add example to scipy.special.hermite
* `#14067 <https://github.com/scipy/scipy/pull/14067>`__: DOC add alpha docstring description, add example to docstring
* `#14070 <https://github.com/scipy/scipy/pull/14070>`__: DOC add parameters, return, and example to docstring
* `#14072 <https://github.com/scipy/scipy/pull/14072>`__: MAINT/TST: Fix tests failing with the nightly build of numpy.
* `#14075 <https://github.com/scipy/scipy/pull/14075>`__: DOC Improve the code snippet in signal.hilbert docstring.
* `#14076 <https://github.com/scipy/scipy/pull/14076>`__: DOC: Document Jensen-Shannon distance being accepted by cdist/pdist
* `#14079 <https://github.com/scipy/scipy/pull/14079>`__: BLD: Avoid importing scipy.stats during cythonize stage
* `#14082 <https://github.com/scipy/scipy/pull/14082>`__: MAINT: Remove old, commented extract_diagonal
* `#14083 <https://github.com/scipy/scipy/pull/14083>`__: MAINT: sparse: Remove defunct function extract_diagonal
* `#14085 <https://github.com/scipy/scipy/pull/14085>`__: ENH: Implement canberra distance in _distance_pybind
* `#14086 <https://github.com/scipy/scipy/pull/14086>`__: MAINT: Clear scipy namespace of entries better imported from...
* `#14088 <https://github.com/scipy/scipy/pull/14088>`__: Install Pythran from sources for python 3.10
* `#14092 <https://github.com/scipy/scipy/pull/14092>`__: BUG: Fixes issue with clang.
* `#14094 <https://github.com/scipy/scipy/pull/14094>`__: DOC: Correct the inconsistence definition of Default in class...
* `#14105 <https://github.com/scipy/scipy/pull/14105>`__: TST: stats: mannwhitneyu: check that mstats and stats mannwhitneyu...
* `#14106 <https://github.com/scipy/scipy/pull/14106>`__: DOC: stats.mstats: mannwhitneyu: the returned statistic is the...
* `#14107 <https://github.com/scipy/scipy/pull/14107>`__: ENH: stats: bootstrap: add \`vectorized\` parameter; automatically...
* `#14109 <https://github.com/scipy/scipy/pull/14109>`__: BUG: fix two issues in the fblas signature files
* `#14110 <https://github.com/scipy/scipy/pull/14110>`__: DOC: mailmap update
* `#14113 <https://github.com/scipy/scipy/pull/14113>`__: ENH: stats: bootstrap: add \`paired\` parameter
* `#14116 <https://github.com/scipy/scipy/pull/14116>`__: MAINT: fix deprecated Python C API usage in odr
* `#14118 <https://github.com/scipy/scipy/pull/14118>`__: DOC: 1.7.0 release notes
* `#14125 <https://github.com/scipy/scipy/pull/14125>`__: DOC: fix typo
* `#14126 <https://github.com/scipy/scipy/pull/14126>`__: ENH: stats: bootstrap: add \`batch\` parameter to control batch...
* `#14127 <https://github.com/scipy/scipy/pull/14127>`__: CI: upgrade pip in benchmarks CI run
* `#14130 <https://github.com/scipy/scipy/pull/14130>`__: BUG: Fix trust-constr report TypeError if verbose is set to 2...
* `#14133 <https://github.com/scipy/scipy/pull/14133>`__: MAINT: interpolate: raise NotImplementedError not ValueError
* `#14139 <https://github.com/scipy/scipy/pull/14139>`__: FIX/DOC: lsqr doctests print failure
* `#14145 <https://github.com/scipy/scipy/pull/14145>`__: MAINT: 1.7.x version pins ("backport")
* `#14146 <https://github.com/scipy/scipy/pull/14146>`__: MAINT: commit count if no tag
* `#14164 <https://github.com/scipy/scipy/pull/14164>`__: TST, BUG: fix rbf matrix value
* `#14166 <https://github.com/scipy/scipy/pull/14166>`__: CI, MAINT: restrictions on pre-release CI
* `#14171 <https://github.com/scipy/scipy/pull/14171>`__: TST: signal: Bump tolerances for a test of Gustafsson's...
* `#14175 <https://github.com/scipy/scipy/pull/14175>`__: TST: stats: Loosen tolerance in some binomtest tests.
* `#14182 <https://github.com/scipy/scipy/pull/14182>`__: MAINT: stats: Update ppcc_plot and ppcc_max docstring.
* `#14195 <https://github.com/scipy/scipy/pull/14195>`__: MAINT: download-wheels missing import
* `#14230 <https://github.com/scipy/scipy/pull/14230>`__: REL: stop shipping generated Cython sources in sdist
==========================
SciPy 1.7.2 Release Notes
==========================

.. contents::

SciPy 1.7.2 is a bug-fix release with no new features
compared to 1.7.1. Notably, the release includes wheels
for Python 3.10, and wheels are now built with a newer
version of OpenBLAS, 0.3.17. Python 3.10 wheels are provided
for MacOS x86_64 (thin, not universal2 or arm64 at this time),
and Windows/Linux 64-bit. Many wheels are now built with newer
versions of manylinux, which may require newer versions of pip.

Authors
=======

* Peter Bell
* da-woods +
* Isuru Fernando
* Ralf Gommers
* Matt Haberland
* Nicholas McKibben
* Ilhan Polat
* Judah Rand +
* Tyler Reddy
* Pamphile Roy
* Charles Harris
* Matti Picus
* Hugo van Kemenade
* Jacob Vanderplas

A total of 14 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.7.2
-----------------------

* `#6019 <https://github.com/scipy/scipy/issues/6019>`__: minimize_scalar doesn't seem to honor "disp" option
* `#14321 <https://github.com/scipy/scipy/issues/14321>`__: BUG: Indexing of CSR matrices with many rows is much slower than...
* `#14465 <https://github.com/scipy/scipy/issues/14465>`__: BUG: n-d interpolation parameter provided to geometric_slerp
* `#14599 <https://github.com/scipy/scipy/issues/14599>`__: SciPy 1.7 builds as zipped egg, ruining imports
* `#14606 <https://github.com/scipy/scipy/issues/14606>`__: BUG: crash / core dump when calling scipy.stats.beta.ppf with...
* `#14732 <https://github.com/scipy/scipy/issues/14732>`__: CI, TST: pre-release failures for scipy/interpolate/tests/test_rbfinterp.py
* `#14802 <https://github.com/scipy/scipy/issues/14802>`__: CI: Azure Main coverage job failure
* `#14829 <https://github.com/scipy/scipy/issues/14829>`__: macOS CI failing with \`ld: library not found for -lSystem\`
* `#14887 <https://github.com/scipy/scipy/issues/14887>`__: BUG: scipy.stats.multivariate_normal.logpdf mutates some inputs

Pull requests for 1.7.2
-----------------------

* `#14207 <https://github.com/scipy/scipy/pull/14207>`__: DOC: stats: remove 'Methods' section from \`binomtest\` docstring...
* `#14316 <https://github.com/scipy/scipy/pull/14316>`__: MAINT: Update \`openblas_support.py\` to support Apple Silicon
* `#14323 <https://github.com/scipy/scipy/pull/14323>`__: BUG: Speed up sparse compressed indexing with very many rows
* `#14333 <https://github.com/scipy/scipy/pull/14333>`__: MAINT: Use /usr/bin/linux32 so that sysconfig.get_platform()...
* `#14478 <https://github.com/scipy/scipy/pull/14478>`__: BUG: geometric_slerp t ndim guard
* `#14605 <https://github.com/scipy/scipy/pull/14605>`__: MAINT: Skip some interpolative decomposition tests
* `#14616 <https://github.com/scipy/scipy/pull/14616>`__: REL: update build dependency versions in pyproject.toml for 1.7.2
* `#14618 <https://github.com/scipy/scipy/pull/14618>`__: FIX: raise RuntimeWarning when Boost evaluation_error is encountered
* `#14672 <https://github.com/scipy/scipy/pull/14672>`__: BLD: add \`zip_safe=False\` to the \`setup()\` call
* `#14791 <https://github.com/scipy/scipy/pull/14791>`__: MAINT: SciPy 1.7.2 prep/backports
* `#14803 <https://github.com/scipy/scipy/pull/14803>`__: MAINT: disable include/source coverage warning.
* `#14813 <https://github.com/scipy/scipy/pull/14813>`__: Added missing np.import_array()
* `#14831 <https://github.com/scipy/scipy/pull/14831>`__: CI: Add stdlib to LD_LIBRARY_PATH
* `#14893 <https://github.com/scipy/scipy/pull/14893>`__: BUG: Fix alignment errors due to relaxed stride checking
* `#14897 <https://github.com/scipy/scipy/pull/14897>`__: BUG: avoid mutating inputs in multivariate distributions
* `#14921 <https://github.com/scipy/scipy/pull/14921>`__: MAINT: "backport" 3.10 support
* `#14937 <https://github.com/scipy/scipy/pull/14937>`__: MAINT: backports for 1.7.2, plus update Pythran min version to...
* `#14938 <https://github.com/scipy/scipy/pull/14938>`__: TST: silence test failures on macOS for \`beta.ppf\` overflow
==========================
SciPy 0.13.2 Release Notes
==========================

SciPy 0.13.2 is a bug-fix release with no new features compared to 0.13.1.


Issues fixed
------------

- 3096: require Cython 0.19, earlier versions have memory leaks in fused types
- 3079: ``ndimage.label`` fix swapped 64-bitness test
- 3108: ``optimize.fmin_slsqp`` constraint violation
==========================
SciPy 1.5.1 Release Notes
==========================

.. contents::

SciPy 1.5.1 is a bug-fix release with no new features
compared to 1.5.0. In particular, an issue where DLL loading
can fail for SciPy wheels on Windows with Python 3.6 has been
fixed.

Authors
=======

* Peter Bell
* Loïc Estève
* Philipp Thölke +
* Tyler Reddy
* Paul van Mulbregt
* Pauli Virtanen
* Warren Weckesser

A total of 7 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 1.5.1
-----------------------

* `#9108 <https://github.com/scipy/scipy/issues/9108>`__: documentation: scipy.spatial.KDTree vs. scipy.spatial.cKDTree
* `#12218 <https://github.com/scipy/scipy/issues/12218>`__: Type error in stats.ks_2samp when alternative != 'two-sided-
* `#12406 <https://github.com/scipy/scipy/issues/12406>`__: DOC: Docstring in stats.anderson function not properly formatted
* `#12418 <https://github.com/scipy/scipy/issues/12418>`__: Regression in hierarchy.dendogram


Pull requests for 1.5.1
-----------------------

* `#12280 <https://github.com/scipy/scipy/pull/12280>`__: BUG: Fixes gh-12218, TypeError converting int to float inside...
* `#12336 <https://github.com/scipy/scipy/pull/12336>`__: BUG: KDTree should reject complex input points
* `#12344 <https://github.com/scipy/scipy/pull/12344>`__: MAINT: Don't use numpy's aliases of Python builtin objects.
* `#12407 <https://github.com/scipy/scipy/pull/12407>`__: DOC: Fix docstring for dist param in anderson function
* `#12410 <https://github.com/scipy/scipy/pull/12410>`__: CI: Run the Azure Windows Python36 32bit tests with mode 'fast'
* `#12421 <https://github.com/scipy/scipy/pull/12421>`__: Fix regression in scipy 1.5.0 in dendogram when labels is a numpy...
* `#12462 <https://github.com/scipy/scipy/pull/12462>`__: MAINT: move distributor_init import after __config__ import

==========================
SciPy 1.5.4 Release Notes
==========================

.. contents::

SciPy 1.5.4 is a bug-fix release with no new features
compared to 1.5.3. Importantly, wheels are now available
for Python 3.9 and a more complete fix has been applied for
issues building with XCode 12.

Authors
=======

* Peter Bell
* CJ Carey
* Andrew McCluskey +
* Andrew Nelson
* Tyler Reddy
* Eli Rykoff +
* Ian Thomas +

A total of 7 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.5.4
-----------------------

* `#12763 <https://github.com/scipy/scipy/issues/12763>`__: ndimage.fourier_ellipsoid segmentation fault
* `#12789 <https://github.com/scipy/scipy/issues/12789>`__: TestConvolve2d.test_large_array failing on Windows ILP64 CI job
* `#12857 <https://github.com/scipy/scipy/issues/12857>`__: sparse A[0,:] = ndarray is ok, A[:,0] = ndarray ValueError from...
* `#12860 <https://github.com/scipy/scipy/issues/12860>`__: BUG: Build failure with Xcode 12
* `#12935 <https://github.com/scipy/scipy/issues/12935>`__: Failure to build with Python 3.9.0 on macOS
* `#12966 <https://github.com/scipy/scipy/issues/12966>`__: MAINT: lint_diff.py on some backport PRs
* `#12988 <https://github.com/scipy/scipy/issues/12988>`__: BUG: Highly multi-dimensional \`gaussian_kde\` giving \`-inf\`...

Pull requests for 1.5.4
-----------------------

* `#12790 <https://github.com/scipy/scipy/pull/12790>`__: TST: Skip TestConvolve2d.test_large_array if not enough memory
* `#12851 <https://github.com/scipy/scipy/pull/12851>`__: BUG: sparse: fix inner indexed assignment of a 1d array
* `#12875 <https://github.com/scipy/scipy/pull/12875>`__: BUG: segfault in ndimage.fourier_ellipsoid with length-1 dims
* `#12937 <https://github.com/scipy/scipy/pull/12937>`__: CI: macOS3.9 testing
* `#12957 <https://github.com/scipy/scipy/pull/12957>`__: MAINT: fixes XCode 12/ python 3.9.0 build for 1.5.x maint branch
* `#12959 <https://github.com/scipy/scipy/pull/12959>`__: CI: add Windows Python 3.9 to CI
* `#12974 <https://github.com/scipy/scipy/pull/12974>`__: MAINT: Run lint_diff.py against the merge target and only for...
* `#12978 <https://github.com/scipy/scipy/pull/12978>`__: DOC: next_fast_len output doesn't match docstring
* `#12979 <https://github.com/scipy/scipy/pull/12979>`__: BUG: fft.next_fast_len should accept keyword arguments
* `#12989 <https://github.com/scipy/scipy/pull/12989>`__: BUG: improved the stability of kde for highly (1000s) multi-dimension...
* `#13017 <https://github.com/scipy/scipy/pull/13017>`__: BUG: Add explicit cast to _tmp sum.
* `#13022 <https://github.com/scipy/scipy/pull/13022>`__: TST: xfail test_maxiter_worsening()
==========================
SciPy 1.3.3 Release Notes
==========================

.. contents::

SciPy 1.3.3 is a bug-fix release with no new features
compared to 1.3.2. In particular, a test suite issue
involving multiprocessing was fixed for Windows and
Python 3.8 on macOS. 

Wheels were also updated to place msvcp140.dll at the 
appropriate location, which was previously causing issues.

Authors
=======

Ilhan Polat
Tyler Reddy
Ralf Gommers

Issues closed for 1.3.3
-----------------------

* `#11033 <https://github.com/scipy/scipy/issues/11033>`__: deadlock on osx for python 3.8


Pull requests for 1.3.3
-----------------------

* `#11034 <https://github.com/scipy/scipy/pull/11034>`__: MAINT: TST: Skip tests with multiprocessing that use "spawn" start method
==========================
SciPy 1.3.0 Release Notes
==========================

.. contents::

SciPy 1.3.0 is the culmination of 5 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been some API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning`` s).
Our development attention will now shift to bug-fix releases on the
1.3.x branch, and on adding new features on the master branch.

This release requires Python 3.5+ and NumPy 1.13.3 or greater.

For running on PyPy, PyPy3 6.0+ and NumPy 1.15.0 are required.

Highlights of this release
==========================

- Three new ``stats`` functions, a rewrite of ``pearsonr``, and an exact
  computation of the Kolmogorov-Smirnov two-sample test.
- A new Cython API for bounded scalar-function root-finders in `scipy.optimize`.
- Substantial ``CSR`` and ``CSC`` sparse matrix indexing performance
  improvements.
- Added support for interpolation of rotations with continuous angular
  rate and acceleration in ``RotationSpline``.


New features
============

`scipy.interpolate` improvements
--------------------------------

A new class ``CubicHermiteSpline`` is introduced. It is a piecewise-cubic
interpolator which matches observed values and first derivatives. Existing
cubic interpolators ``CubicSpline``, ``PchipInterpolator`` and
``Akima1DInterpolator`` were made subclasses of ``CubicHermiteSpline``.

`scipy.io` improvements
-----------------------

For the Attribute-Relation File Format (ARFF) `scipy.io.arff.loadarff`
now supports relational attributes.

`scipy.io.mmread` can now parse Matrix Market format files with empty lines.

`scipy.linalg` improvements
---------------------------

Added wrappers for ``?syconv`` routines, which convert a symmetric matrix
given by a triangular matrix factorization into two matrices and vice versa.

`scipy.linalg.clarkson_woodruff_transform` now uses an algorithm that leverages
sparsity. This may provide a 60-90 percent speedup for dense input matrices.
Truly sparse input matrices should also benefit from the improved sketch
algorithm, which now correctly runs in ``O(nnz(A))`` time.

Added new functions to calculate symmetric Fiedler matrices and
Fiedler companion matrices, named `scipy.linalg.fiedler` and
`scipy.linalg.fiedler_companion`, respectively. These may be used
for root finding.

`scipy.ndimage` improvements
----------------------------

Gaussian filter performances may improve by an order of magnitude in
some cases, thanks to the removal of a dependence on ``np.polynomial``. This
may impact `scipy.ndimage.gaussian_filter` for example.

`scipy.optimize` improvements
-----------------------------

The `scipy.optimize.brute` minimizer obtained a new keyword ``workers``, which
can be used to parallelize computation.

A Cython API for bounded scalar-function root-finders in `scipy.optimize`
is available in a new module `scipy.optimize.cython_optimize` via ``cimport``.
This API may be used with ``nogil`` and ``prange`` to loop
over an array of function arguments to solve for an array of roots more
quickly than with pure Python.

``'interior-point'`` is now the default method for ``linprog``, and
``'interior-point'`` now uses SuiteSparse for sparse problems when the
required scikits  (scikit-umfpack and scikit-sparse) are available.
On benchmark problems (gh-10026), execution time reductions by factors of 2-3
were typical. Also, a new ``method='revised simplex'`` has been added.
It is not as fast or robust as ``method='interior-point'``, but it is a faster,
more robust, and equally accurate substitute for the legacy
``method='simplex'``.

``differential_evolution`` can now use a ``Bounds`` class to specify the
bounds for the optimizing argument of a function.

`scipy.optimize.dual_annealing` performance improvements related to
vectorization of some internal code.

`scipy.signal` improvements
---------------------------

Two additional methods of discretization are now supported by
`scipy.signal.cont2discrete`: ``impulse`` and ``foh``.

`scipy.signal.firls` now uses faster solvers.

`scipy.signal.detrend` now has a lower physical memory footprint in some
cases, which may be leveraged using the new ``overwrite_data`` keyword argument.

`scipy.signal.firwin` ``pass_zero`` argument now accepts new string arguments
that allow specification of the desired filter type: ``'bandpass'``,
``'lowpass'``, ``'highpass'``, and ``'bandstop'``.

`scipy.signal.sosfilt` may have improved performance due to lower retention
of the global interpreter lock (GIL) in the algorithm.

`scipy.sparse` improvements
---------------------------

A new keyword was added to ``csgraph.dijsktra`` that
allows users to query the shortest path to ANY of the passed-in indices,
as opposed to the shortest path to EVERY passed index.

`scipy.sparse.linalg.lsmr` performance has been improved by roughly 10 percent
on large problems.

Improved performance and reduced physical memory footprint of the algorithm
used by `scipy.sparse.linalg.lobpcg`.

``CSR`` and ``CSC`` sparse matrix fancy indexing performance has been
improved substantially.

`scipy.spatial` improvements
----------------------------

`scipy.spatial.ConvexHull` now has a ``good`` attribute that can be used
alongsize the ``QGn`` Qhull options to determine which external facets of a
convex hull are visible from an external query point.

`scipy.spatial.cKDTree.query_ball_point` has been modernized to use some newer
Cython features, including GIL handling and exception translation. An issue
with ``return_sorted=True`` and scalar queries was fixed, and a new mode named
``return_length`` was added. ``return_length`` only computes the length of the
returned indices list instead of allocating the array every time.

`scipy.spatial.transform.RotationSpline` has been added to enable interpolation
of rotations with continuous angular rates and acceleration.

`scipy.stats` improvements
--------------------------

Added a new function to compute the Epps-Singleton test statistic,
`scipy.stats.epps_singleton_2samp`, which can be applied to continuous and
discrete distributions.

New functions `scipy.stats.median_absolute_deviation` and `scipy.stats.gstd`
(geometric standard deviation) were added. The `scipy.stats.combine_pvalues`
method now supports ``pearson``,  ``tippett`` and ``mudholkar_george`` pvalue
combination methods.

The `scipy.stats.ortho_group` and `scipy.stats.special_ortho_group`
``rvs(dim)`` functions' algorithms were updated from a ``O(dim^4)``
implementation to a ``O(dim^3)`` which gives large speed improvements
for ``dim>100``.

A rewrite of `scipy.stats.pearsonr` to use a more robust algorithm,
provide meaningful exceptions and warnings on potentially pathological input,
and fix at least five separate reported issues in the original implementation.

Improved the precision of ``hypergeom.logcdf`` and ``hypergeom.logsf``.

Added exact computation for Kolmogorov-Smirnov (KS) two-sample test, replacing
the previously approximate computation for the two-sided test `stats.ks_2samp`.
Also added a one-sided, two-sample KS test, and a keyword ``alternative`` to
`stats.ks_2samp`.

Backwards-incompatible changes
==============================

`scipy.interpolate` changes
---------------------------

Functions from ``scipy.interpolate`` (``spleval``, ``spline``, ``splmake``,
and ``spltopp``) and functions from ``scipy.misc`` (``bytescale``,
``fromimage``, ``imfilter``, ``imread``, ``imresize``, ``imrotate``,
``imsave``, ``imshow``, ``toimage``) have been removed. The former set has
been deprecated since v0.19.0 and the latter has been deprecated since v1.0.0.
Similarly, aliases from ``scipy.misc`` (``comb``, ``factorial``,
``factorial2``, ``factorialk``, ``logsumexp``, ``pade``, ``info``, ``source``,
``who``) which have been deprecated since v1.0.0 are removed.
`SciPy documentation for
v1.1.0 <https://docs.scipy.org/doc/scipy-1.1.0/reference/misc.html>`__
can be used to track the new import locations for the relocated functions.

`scipy.linalg` changes
----------------------

For ``pinv``, ``pinv2``, and ``pinvh``, the default cutoff values are changed
for consistency (see the docs for the actual values).

`scipy.optimize` changes
---------------------------

The default method for ``linprog`` is now ``'interior-point'``. The method's
robustness and speed come at a cost: solutions may not be accurate to
machine precision or correspond with a vertex of the polytope defined
by the constraints. To revert to the original simplex method,
include the argument ``method='simplex'``.

`scipy.stats` changes
---------------------

Previously, ``ks_2samp(data1, data2)`` would run a two-sided test and return
the approximated p-value. The new signature, ``ks_2samp(data1, data2,
alternative="two-sided", method="auto")``, still runs the two-sided test by
default but returns the exact p-value for small samples and the approximated
value for large samples. ``method="asymp"`` would be equivalent to the
old version but ``auto`` is the better choice.

Other changes
=============

Our tutorial has been expanded with a new section on global optimizers.

There has been a rework of the ``stats.distributions`` tutorials.

`scipy.optimize` now correctly sets the convergence flag of the result to
``CONVERR``, a convergence error, for bounded scalar-function root-finders
if the maximum iterations has been exceeded, ``disp`` is false, and
``full_output`` is true.

`scipy.optimize.curve_fit` no longer fails if ``xdata`` and ``ydata`` dtypes
differ; they are both now automatically cast to ``float64``.

`scipy.ndimage` functions including ``binary_erosion``, ``binary_closing``, and
``binary_dilation`` now require an integer value for the number of iterations,
which alleviates a number of reported issues.

Fixed normal approximation in case ``zero_method == "pratt"`` in
`scipy.stats.wilcoxon`.

Fixes for incorrect probabilities, broadcasting issues and thread-safety
related to stats distributions setting member variables inside ``_argcheck()``.

`scipy.optimize.newton` now correctly raises a ``RuntimeError`` in the following cases: when default
arguments are used and if a derivative of value zero is obtained (which is a special case of failing to converge).

A draft toolchain roadmap is now available, laying out a compatibility plan
including Python versions, C standards, and NumPy versions.


Authors
=======

* ananyashreyjain +
* ApamNapat +
* Scott Calabrese Barton +
* Christoph Baumgarten
* Peter Bell +
* Jacob Blomgren +
* Doctor Bob +
* Mana Borwornpadungkitti +
* Matthew Brett
* Evgeni Burovski
* CJ Carey
* Vega Theil Carstensen +
* Robert Cimrman
* Forrest Collman +
* Pietro Cottone +
* David +
* Idan David +
* Christoph Deil
* Dieter Werthmüller
* Conner DiPaolo +
* Dowon
* Michael Dunphy +
* Peter Andreas Entschev +
* Gökçen Eraslan +
* Johann Faouzi +
* Yu Feng
* Piotr Figiel +
* Matthew H Flamm
* Franz Forstmayr +
* Christoph Gohlke
* Richard Janis Goldschmidt +
* Ralf Gommers
* Lars Grueter
* Sylvain Gubian
* Matt Haberland
* Yaroslav Halchenko
* Charles Harris
* Lindsey Hiltner
* JakobStruye +
* He Jia +
* Jwink3101 +
* Greg Kiar +
* Julius Bier Kirkegaard
* John Kirkham +
* Thomas Kluyver
* Vladimir Korolev +
* Joseph Kuo +
* Michael Lamparski +
* Eric Larson
* Denis Laxalde
* Katrin Leinweber
* Jesse Livezey
* ludcila +
* Dhruv Madeka +
* Magnus +
* Nikolay Mayorov
* Mark Mikofski
* Jarrod Millman
* Markus Mohrhard +
* Eric Moore
* Andrew Nelson
* Aki Nishimura +
* OGordon100 +
* Petar Mlinarić +
* Stefan Peterson
* Matti Picus +
* Ilhan Polat
* Aaron Pries +
* Matteo Ravasi +
* Tyler Reddy
* Ashton Reimer +
* Joscha Reimer
* rfezzani +
* Riadh +
* Lucas Roberts
* Heshy Roskes +
* Mirko Scholz +
* Taylor D. Scott +
* Srikrishna Sekhar +
* Kevin Sheppard +
* Sourav Singh
* skjerns +
* Kai Striega
* SyedSaifAliAlvi +
* Gopi Manohar T +
* Albert Thomas +
* Timon +
* Paul van Mulbregt
* Jacob Vanderplas
* Daniel Vargas +
* Pauli Virtanen
* VNMabus +
* Stefan van der Walt
* Warren Weckesser
* Josh Wilson
* Nate Yoder +
* Roman Yurchak

A total of 97 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.3.0
-----------------------

* `#1320 <https://github.com/scipy/scipy/issues/1320>`__: scipy.stats.distribution: problem with self.a, self.b if they...
* `#2002 <https://github.com/scipy/scipy/issues/2002>`__: members set in scipy.stats.distributions.##._argcheck (Trac #1477)
* `#2823 <https://github.com/scipy/scipy/issues/2823>`__: distribution methods add tmp
* `#3220 <https://github.com/scipy/scipy/issues/3220>`__: Scipy.opimize.fmin_powell direc argument syntax unclear
* `#3728 <https://github.com/scipy/scipy/issues/3728>`__: scipy.stats.pearsonr: possible bug with zero variance input
* `#6805 <https://github.com/scipy/scipy/issues/6805>`__: error-in-scipy-wilcoxon-signed-rank-test-for-equal-series
* `#6873 <https://github.com/scipy/scipy/issues/6873>`__: 'stats.boxcox' return all same values
* `#7117 <https://github.com/scipy/scipy/issues/7117>`__: Warn users when using float32 input data to curve_fit and friends
* `#7632 <https://github.com/scipy/scipy/issues/7632>`__: it's not possible to tell the \`optimize.least_squares\` solver...
* `#7730 <https://github.com/scipy/scipy/issues/7730>`__: stats.pearsonr: Potential division by zero for dataset of length...
* `#7933 <https://github.com/scipy/scipy/issues/7933>`__: stats.truncnorm fails when providing values outside truncation...
* `#8033 <https://github.com/scipy/scipy/issues/8033>`__: Add standard filter types to firwin to set pass_zero intuitively...
* `#8600 <https://github.com/scipy/scipy/issues/8600>`__: lfilter.c.src zfill has erroneous header
* `#8692 <https://github.com/scipy/scipy/issues/8692>`__: Non-negative values of \`stats.hypergeom.logcdf\`
* `#8734 <https://github.com/scipy/scipy/issues/8734>`__: Enable pip build isolation
* `#8861 <https://github.com/scipy/scipy/issues/8861>`__: scipy.linalg.pinv gives wrong result while scipy.linalg.pinv2...
* `#8915 <https://github.com/scipy/scipy/issues/8915>`__: need to fix macOS build against older numpy versions
* `#8980 <https://github.com/scipy/scipy/issues/8980>`__: scipy.stats.pearsonr overflows with high values of x and y
* `#9226 <https://github.com/scipy/scipy/issues/9226>`__: BUG: signal: SystemError: <built-in function _linear_filter>...
* `#9254 <https://github.com/scipy/scipy/issues/9254>`__: BUG: root finders brentq, etc, flag says "converged" even if...
* `#9308 <https://github.com/scipy/scipy/issues/9308>`__: Test failure - test_initial_constraints_as_canonical
* `#9353 <https://github.com/scipy/scipy/issues/9353>`__: scipy.stats.pearsonr returns r=1 if r_num/r_den = inf
* `#9359 <https://github.com/scipy/scipy/issues/9359>`__: Planck distribution is a geometric distribution
* `#9381 <https://github.com/scipy/scipy/issues/9381>`__: linregress should warn user in 2x2 array case
* `#9406 <https://github.com/scipy/scipy/issues/9406>`__: BUG: stats: In pearsonr, when r is nan, the p-value must also...
* `#9437 <https://github.com/scipy/scipy/issues/9437>`__: Cannot create sparse matrix from size_t indexes
* `#9518 <https://github.com/scipy/scipy/issues/9518>`__: Relational attributes in loadarff
* `#9551 <https://github.com/scipy/scipy/issues/9551>`__: BUG: scipy.optimize.newton says the root of x^2+1 is zero.
* `#9564 <https://github.com/scipy/scipy/issues/9564>`__: rv_sample accepts invalid input in scipy.stats
* `#9565 <https://github.com/scipy/scipy/issues/9565>`__: improper handling of multidimensional input in stats.rv_sample
* `#9581 <https://github.com/scipy/scipy/issues/9581>`__: Least-squares minimization fails silently when x and y data are...
* `#9587 <https://github.com/scipy/scipy/issues/9587>`__: Outdated value for scipy.constants.au
* `#9611 <https://github.com/scipy/scipy/issues/9611>`__: Overflow error with new way of p-value calculation in kendall...
* `#9645 <https://github.com/scipy/scipy/issues/9645>`__: \`scipy.stats.mode\` crashes with variable length arrays (\`dtype=object\`)
* `#9734 <https://github.com/scipy/scipy/issues/9734>`__: PendingDeprecationWarning for np.matrix with pytest
* `#9786 <https://github.com/scipy/scipy/issues/9786>`__: stats.ks_2samp() misleading for small data sets.
* `#9790 <https://github.com/scipy/scipy/issues/9790>`__: Excessive memory usage on detrend
* `#9801 <https://github.com/scipy/scipy/issues/9801>`__: dual_annealing does not set the success attribute in OptimizeResult
* `#9833 <https://github.com/scipy/scipy/issues/9833>`__: IntegrationWarning from mielke.stats() during build of html doc.
* `#9835 <https://github.com/scipy/scipy/issues/9835>`__: scipy.signal.firls seems to be inefficient versus MATLAB firls
* `#9864 <https://github.com/scipy/scipy/issues/9864>`__: Curve_fit does not check for empty input data if called with...
* `#9869 <https://github.com/scipy/scipy/issues/9869>`__: scipy.ndimage.label: Minor documentation issue
* `#9882 <https://github.com/scipy/scipy/issues/9882>`__: format at the wrong paranthesis in scipy.spatial.transform
* `#9889 <https://github.com/scipy/scipy/issues/9889>`__: scipy.signal.find_peaks minor documentation issue
* `#9890 <https://github.com/scipy/scipy/issues/9890>`__: Minkowski p-norm Issues in cKDTree For Values Other Than 2 Or...
* `#9896 <https://github.com/scipy/scipy/issues/9896>`__: scipy.stats._argcheck sets (not just checks) values
* `#9905 <https://github.com/scipy/scipy/issues/9905>`__: Memory error in ndimage.binary_erosion
* `#9909 <https://github.com/scipy/scipy/issues/9909>`__: binary_dilation/erosion/closing crashes when iterations is float
* `#9919 <https://github.com/scipy/scipy/issues/9919>`__: BUG: \`coo_matrix\` does not validate the \`shape\` argument.
* `#9982 <https://github.com/scipy/scipy/issues/9982>`__: lsq_linear hangs/infinite loop with 'trf' method
* `#10003 <https://github.com/scipy/scipy/issues/10003>`__: exponnorm.pdf returns NAN for small K
* `#10011 <https://github.com/scipy/scipy/issues/10011>`__: Incorrect check for invalid rotation plane in scipy.ndimage.rotate
* `#10024 <https://github.com/scipy/scipy/issues/10024>`__: Fails to build from git
* `#10048 <https://github.com/scipy/scipy/issues/10048>`__: DOC: scipy.optimize.root_scalar
* `#10068 <https://github.com/scipy/scipy/issues/10068>`__: DOC: scipy.interpolate.splev
* `#10074 <https://github.com/scipy/scipy/issues/10074>`__: BUG: \`expm\` calculates the wrong coefficients in the backward...


Pull requests for 1.3.0
-----------------------

* `#7827 <https://github.com/scipy/scipy/pull/7827>`__: ENH: sparse: overhaul of sparse matrix indexing
* `#8431 <https://github.com/scipy/scipy/pull/8431>`__: ENH: Cython optimize zeros api
* `#8743 <https://github.com/scipy/scipy/pull/8743>`__: DOC: Updated linalg.pinv, .pinv2, .pinvh docstrings
* `#8744 <https://github.com/scipy/scipy/pull/8744>`__: DOC: added examples to remez docstring
* `#9227 <https://github.com/scipy/scipy/pull/9227>`__: DOC: update description of "direc" parameter of "fmin_powell"
* `#9263 <https://github.com/scipy/scipy/pull/9263>`__: ENH: optimize: added "revised simplex" for scipy.optimize.linprog
* `#9325 <https://github.com/scipy/scipy/pull/9325>`__: DEP: Remove deprecated functions for 1.3.0
* `#9330 <https://github.com/scipy/scipy/pull/9330>`__: Add note on push and pull affine transformations
* `#9423 <https://github.com/scipy/scipy/pull/9423>`__: DOC: Clearly state how 2x2 input arrays are handled in stats.linregress
* `#9428 <https://github.com/scipy/scipy/pull/9428>`__: ENH: parallelised brute
* `#9438 <https://github.com/scipy/scipy/pull/9438>`__: BUG: Initialize coo matrix with size_t indexes
* `#9455 <https://github.com/scipy/scipy/pull/9455>`__: MAINT: Speed up get_(lapack,blas)_func
* `#9465 <https://github.com/scipy/scipy/pull/9465>`__: MAINT: Clean up optimize.zeros C solvers interfaces/code.
* `#9477 <https://github.com/scipy/scipy/pull/9477>`__: DOC: linalg: fix lstsq docstring on residues shape
* `#9478 <https://github.com/scipy/scipy/pull/9478>`__: DOC: Add docstring examples for rosen functions
* `#9479 <https://github.com/scipy/scipy/pull/9479>`__: DOC: Add docstring example for ai_zeros and bi_zeros
* `#9480 <https://github.com/scipy/scipy/pull/9480>`__: MAINT: linalg: lstsq clean up
* `#9489 <https://github.com/scipy/scipy/pull/9489>`__: DOC: roadmap update for changes over the last year.
* `#9492 <https://github.com/scipy/scipy/pull/9492>`__: MAINT: stats: Improve implementation of chi2 ppf method.
* `#9497 <https://github.com/scipy/scipy/pull/9497>`__: DOC: Improve docstrings sparse.linalg.isolve
* `#9499 <https://github.com/scipy/scipy/pull/9499>`__: DOC: Replace "Scipy" with "SciPy" in the .rst doc files for consistency.
* `#9500 <https://github.com/scipy/scipy/pull/9500>`__: DOC: Document the toolchain and its roadmap.
* `#9505 <https://github.com/scipy/scipy/pull/9505>`__: DOC: specify which definition of skewness is used
* `#9511 <https://github.com/scipy/scipy/pull/9511>`__: DEP: interpolate: remove deprecated interpolate_wrapper
* `#9517 <https://github.com/scipy/scipy/pull/9517>`__: BUG: improve error handling in stats.iqr
* `#9522 <https://github.com/scipy/scipy/pull/9522>`__: ENH: Add Fiedler and fiedler companion to special matrices
* `#9526 <https://github.com/scipy/scipy/pull/9526>`__: TST: relax precision requirements in signal.correlate tests
* `#9529 <https://github.com/scipy/scipy/pull/9529>`__: DOC: fix missing random seed in optimize.newton example
* `#9533 <https://github.com/scipy/scipy/pull/9533>`__: MAINT: Use list comprehension when possible
* `#9537 <https://github.com/scipy/scipy/pull/9537>`__: DOC: add a "big picture" roadmap
* `#9538 <https://github.com/scipy/scipy/pull/9538>`__: DOC: Replace "Numpy" with "NumPy" in .py, .rst and .txt doc files...
* `#9539 <https://github.com/scipy/scipy/pull/9539>`__: ENH: add two-sample test (Epps-Singleton) to scipy.stats
* `#9559 <https://github.com/scipy/scipy/pull/9559>`__: DOC: add section on global optimizers to tutorial
* `#9561 <https://github.com/scipy/scipy/pull/9561>`__: ENH: remove noprefix.h, change code appropriately
* `#9562 <https://github.com/scipy/scipy/pull/9562>`__: MAINT: stats: Rewrite pearsonr.
* `#9563 <https://github.com/scipy/scipy/pull/9563>`__: BUG: Minor bug fix Callback in linprog(method='simplex')
* `#9568 <https://github.com/scipy/scipy/pull/9568>`__: MAINT: raise runtime error for newton with zeroder if disp true,...
* `#9570 <https://github.com/scipy/scipy/pull/9570>`__: Correct docstring in show_options in optimize. Fixes #9407
* `#9573 <https://github.com/scipy/scipy/pull/9573>`__: BUG fixes range of pk variable pre-check
* `#9577 <https://github.com/scipy/scipy/pull/9577>`__: TST: fix minor issue in a signal.stft test.
* `#9580 <https://github.com/scipy/scipy/pull/9580>`__: Included blank line before list - Fixes #8658
* `#9582 <https://github.com/scipy/scipy/pull/9582>`__: MAINT: drop Python 2.7 and 3.4
* `#9588 <https://github.com/scipy/scipy/pull/9588>`__: MAINT: update \`constants.astronomical_unit\` to new 2012 value.
* `#9592 <https://github.com/scipy/scipy/pull/9592>`__: TST: Add 32-bit testing to CI
* `#9593 <https://github.com/scipy/scipy/pull/9593>`__: DOC: Replace cumulative density with cumulative distribution
* `#9596 <https://github.com/scipy/scipy/pull/9596>`__: TST: remove VC 9.0 from Azure CI
* `#9599 <https://github.com/scipy/scipy/pull/9599>`__: Hyperlink DOI to preferred resolver
* `#9601 <https://github.com/scipy/scipy/pull/9601>`__: DEV: try to limit GC memory use on PyPy
* `#9603 <https://github.com/scipy/scipy/pull/9603>`__: MAINT: improve logcdf and logsf of hypergeometric distribution
* `#9605 <https://github.com/scipy/scipy/pull/9605>`__: Reference to pylops in LinearOperator notes and ARPACK example
* `#9617 <https://github.com/scipy/scipy/pull/9617>`__: TST: reduce max memory usage for sparse.linalg.lgmres test
* `#9619 <https://github.com/scipy/scipy/pull/9619>`__: FIX: Sparse matrix addition/subtraction eliminates explicit zeros
* `#9621 <https://github.com/scipy/scipy/pull/9621>`__: bugfix in rv_sample in scipy.stats
* `#9622 <https://github.com/scipy/scipy/pull/9622>`__: MAINT: Raise error in directed_hausdorff distance
* `#9623 <https://github.com/scipy/scipy/pull/9623>`__: DOC: Build docs with warnings as errors
* `#9625 <https://github.com/scipy/scipy/pull/9625>`__: Return the number of calls to 'hessp' (not just 'hess') in trust...
* `#9627 <https://github.com/scipy/scipy/pull/9627>`__: BUG: ignore empty lines in mmio
* `#9637 <https://github.com/scipy/scipy/pull/9637>`__: Function to calculate the MAD of an array
* `#9646 <https://github.com/scipy/scipy/pull/9646>`__: BUG: stats: mode for objects w/ndim > 1
* `#9648 <https://github.com/scipy/scipy/pull/9648>`__: Add \`stats.contingency\` to refguide-check
* `#9650 <https://github.com/scipy/scipy/pull/9650>`__: ENH: many lobpcg() algorithm improvements
* `#9652 <https://github.com/scipy/scipy/pull/9652>`__: Move misc.doccer to _lib.doccer
* `#9660 <https://github.com/scipy/scipy/pull/9660>`__: ENH: add pearson, tippett, and mudholkar-george to combine_pvalues
* `#9661 <https://github.com/scipy/scipy/pull/9661>`__: BUG: Fix ksone right-hand endpoint, documentation and tests.
* `#9664 <https://github.com/scipy/scipy/pull/9664>`__: ENH: adding multi-target dijsktra performance enhancement
* `#9670 <https://github.com/scipy/scipy/pull/9670>`__: MAINT: link planck and geometric distribution in scipy.stats
* `#9676 <https://github.com/scipy/scipy/pull/9676>`__: ENH: optimize: change default linprog method to interior-point
* `#9685 <https://github.com/scipy/scipy/pull/9685>`__: Added reference to ndimage.filters.median_filter
* `#9705 <https://github.com/scipy/scipy/pull/9705>`__: Fix coefficients in expm helper function
* `#9711 <https://github.com/scipy/scipy/pull/9711>`__: Release the GIL during sosfilt processing for simple types
* `#9721 <https://github.com/scipy/scipy/pull/9721>`__: ENH: Convexhull visiblefacets
* `#9723 <https://github.com/scipy/scipy/pull/9723>`__: BLD: Modify rv_generic._construct_doc to print out failing distribution...
* `#9726 <https://github.com/scipy/scipy/pull/9726>`__: BUG: Fix small issues with \`signal.lfilter'
* `#9729 <https://github.com/scipy/scipy/pull/9729>`__: BUG: Typecheck iterations for binary image operations
* `#9730 <https://github.com/scipy/scipy/pull/9730>`__: ENH: reduce sizeof(NI_WatershedElement) by 20%
* `#9731 <https://github.com/scipy/scipy/pull/9731>`__: ENH: remove suspicious sequence of type castings
* `#9739 <https://github.com/scipy/scipy/pull/9739>`__: BUG: qr_updates fails if u is exactly in span Q
* `#9749 <https://github.com/scipy/scipy/pull/9749>`__: BUG: MapWrapper.__exit__ should terminate
* `#9753 <https://github.com/scipy/scipy/pull/9753>`__: ENH: Added exact computation for Kolmogorov-Smirnov two-sample...
* `#9755 <https://github.com/scipy/scipy/pull/9755>`__: DOC: Added example for signal.impulse, copied from impulse2
* `#9756 <https://github.com/scipy/scipy/pull/9756>`__: DOC: Added docstring example for iirdesign
* `#9757 <https://github.com/scipy/scipy/pull/9757>`__: DOC: Added examples for step functions
* `#9759 <https://github.com/scipy/scipy/pull/9759>`__: ENH: Allow pass_zero to act like btype
* `#9760 <https://github.com/scipy/scipy/pull/9760>`__: DOC: Added docstring for lp2bs
* `#9761 <https://github.com/scipy/scipy/pull/9761>`__: DOC: Added docstring and example for lp2bp
* `#9764 <https://github.com/scipy/scipy/pull/9764>`__: BUG: Catch internal warnings for matrix
* `#9766 <https://github.com/scipy/scipy/pull/9766>`__: ENH: Speed up _gaussian_kernel1d by removing dependence on np.polynomial
* `#9769 <https://github.com/scipy/scipy/pull/9769>`__: BUG: Fix Cubic Spline Read Only issues
* `#9773 <https://github.com/scipy/scipy/pull/9773>`__: DOC: Several docstrings
* `#9774 <https://github.com/scipy/scipy/pull/9774>`__: TST: bump Azure CI OpenBLAS version to match wheels
* `#9775 <https://github.com/scipy/scipy/pull/9775>`__: DOC: Improve clarity of cov_x documentation for scipy.optimize.leastsq
* `#9779 <https://github.com/scipy/scipy/pull/9779>`__: ENH: dual_annealing vectorise visit_fn
* `#9788 <https://github.com/scipy/scipy/pull/9788>`__: TST, BUG: f2py-related issues with NumPy < 1.14.0
* `#9791 <https://github.com/scipy/scipy/pull/9791>`__: BUG: fix amax constraint not enforced in scalar_search_wolfe2
* `#9792 <https://github.com/scipy/scipy/pull/9792>`__: ENH: Allow inplace copying in place in "detrend" function
* `#9795 <https://github.com/scipy/scipy/pull/9795>`__: DOC: Fix/update docstring for dstn and dst
* `#9796 <https://github.com/scipy/scipy/pull/9796>`__: MAINT: Allow None tolerances in least_squares
* `#9798 <https://github.com/scipy/scipy/pull/9798>`__: BUG: fixes abort trap 6 error in scipy issue 9785 in unit tests
* `#9807 <https://github.com/scipy/scipy/pull/9807>`__: MAINT: improve doc and add alternative keyword to wilcoxon in...
* `#9808 <https://github.com/scipy/scipy/pull/9808>`__: Fix PPoly integrate and test for CubicSpline
* `#9810 <https://github.com/scipy/scipy/pull/9810>`__: ENH: Add the geometric standard deviation function
* `#9811 <https://github.com/scipy/scipy/pull/9811>`__: MAINT: remove invalid derphi default None value in scalar_search_wolfe2
* `#9813 <https://github.com/scipy/scipy/pull/9813>`__: Adapt hamming distance in C to support weights
* `#9817 <https://github.com/scipy/scipy/pull/9817>`__: DOC: Copy solver description to solver modules
* `#9829 <https://github.com/scipy/scipy/pull/9829>`__: ENH: Add FOH and equivalent impulse response discretizations...
* `#9831 <https://github.com/scipy/scipy/pull/9831>`__: ENH: Implement RotationSpline
* `#9834 <https://github.com/scipy/scipy/pull/9834>`__: DOC: Change mielke distribution default parameters to ensure...
* `#9838 <https://github.com/scipy/scipy/pull/9838>`__: ENH: Use faster solvers for firls
* `#9854 <https://github.com/scipy/scipy/pull/9854>`__: ENH: loadarff now supports relational attributes.
* `#9856 <https://github.com/scipy/scipy/pull/9856>`__: integrate.bvp - improve handling of nonlinear boundary conditions
* `#9862 <https://github.com/scipy/scipy/pull/9862>`__: TST: reduce Appveyor CI load
* `#9874 <https://github.com/scipy/scipy/pull/9874>`__: DOC: Update requirements in release notes
* `#9883 <https://github.com/scipy/scipy/pull/9883>`__: BUG: fixed parenthesis in spatial.rotation
* `#9884 <https://github.com/scipy/scipy/pull/9884>`__: ENH: Use Sparsity in Clarkson-Woodruff Sketch
* `#9888 <https://github.com/scipy/scipy/pull/9888>`__: MAINT: Replace NumPy aliased functions
* `#9892 <https://github.com/scipy/scipy/pull/9892>`__: BUG: Fix 9890 query_ball_point returns wrong result when p is...
* `#9893 <https://github.com/scipy/scipy/pull/9893>`__: BUG: curve_fit doesn't check for empty input if called with bounds
* `#9894 <https://github.com/scipy/scipy/pull/9894>`__: scipy.signal.find_peaks documentation error
* `#9898 <https://github.com/scipy/scipy/pull/9898>`__: BUG: Set success attribute in OptimizeResult. See #9801
* `#9900 <https://github.com/scipy/scipy/pull/9900>`__: BUG: Restrict rv_generic._argcheck() and its overrides from setting...
* `#9906 <https://github.com/scipy/scipy/pull/9906>`__: fixed a bug in kde logpdf
* `#9911 <https://github.com/scipy/scipy/pull/9911>`__: DOC: replace example for "np.select" with the one from numpy...
* `#9912 <https://github.com/scipy/scipy/pull/9912>`__: BF(DOC): point to numpy.select instead of plain (python) .select
* `#9914 <https://github.com/scipy/scipy/pull/9914>`__: DOC: change ValueError message in _validate_pad of signaltools.
* `#9915 <https://github.com/scipy/scipy/pull/9915>`__: cKDTree query_ball_point improvements
* `#9918 <https://github.com/scipy/scipy/pull/9918>`__: Update ckdtree.pyx with boxsize argument in docstring
* `#9920 <https://github.com/scipy/scipy/pull/9920>`__: BUG: sparse: Validate explicit shape if given with dense argument...
* `#9924 <https://github.com/scipy/scipy/pull/9924>`__: BLD: add back pyproject.toml
* `#9931 <https://github.com/scipy/scipy/pull/9931>`__: Fix empty constraint
* `#9935 <https://github.com/scipy/scipy/pull/9935>`__: DOC: fix references for stats.f_oneway
* `#9936 <https://github.com/scipy/scipy/pull/9936>`__: Revert gh-9619: "FIX: Sparse matrix addition/subtraction eliminates...
* `#9937 <https://github.com/scipy/scipy/pull/9937>`__: MAINT: fix PEP8 issues and update to pycodestyle 2.5.0
* `#9939 <https://github.com/scipy/scipy/pull/9939>`__: DOC: correct \`structure\` description in \`ndimage.label\` docstring
* `#9940 <https://github.com/scipy/scipy/pull/9940>`__: MAINT: remove extraneous distutils copies
* `#9945 <https://github.com/scipy/scipy/pull/9945>`__: ENH: differential_evolution can use Bounds object
* `#9949 <https://github.com/scipy/scipy/pull/9949>`__: Added 'std' to add doctstrings since it is a \`known_stats\`...
* `#9953 <https://github.com/scipy/scipy/pull/9953>`__: DOC: Documentation cleanup for stats tutorials.
* `#9962 <https://github.com/scipy/scipy/pull/9962>`__: __repr__ for Bounds
* `#9971 <https://github.com/scipy/scipy/pull/9971>`__: ENH: Improve performance of lsmr
* `#9987 <https://github.com/scipy/scipy/pull/9987>`__: CI: pin Sphinx version to 1.8.5
* `#9990 <https://github.com/scipy/scipy/pull/9990>`__: ENH: constraint violation
* `#9991 <https://github.com/scipy/scipy/pull/9991>`__: BUG: Avoid inplace modification of input array in newton
* `#9995 <https://github.com/scipy/scipy/pull/9995>`__: MAINT: sparse.csgraph: Add cdef to stop build warning.
* `#9996 <https://github.com/scipy/scipy/pull/9996>`__: BUG: Make minimize_quadratic_1d work with infinite bounds correctly
* `#10004 <https://github.com/scipy/scipy/pull/10004>`__: BUG: Fix unbound local error in linprog - simplex.
* `#10007 <https://github.com/scipy/scipy/pull/10007>`__: BLD: fix Python 3.7 build with build isolation
* `#10009 <https://github.com/scipy/scipy/pull/10009>`__: BUG: Make sure that _binary_erosion only accepts an integer number...
* `#10016 <https://github.com/scipy/scipy/pull/10016>`__: Update link to airspeed-velocity
* `#10017 <https://github.com/scipy/scipy/pull/10017>`__: DOC: Update \`interpolate.LSQSphereBivariateSpline\` to include...
* `#10018 <https://github.com/scipy/scipy/pull/10018>`__: MAINT: special: Fix a few warnings that occur when compiling...
* `#10019 <https://github.com/scipy/scipy/pull/10019>`__: TST: Azure summarizes test failures
* `#10021 <https://github.com/scipy/scipy/pull/10021>`__: ENH: Introduce CubicHermiteSpline
* `#10022 <https://github.com/scipy/scipy/pull/10022>`__: BENCH: Increase cython version in asv to fix benchmark builds
* `#10023 <https://github.com/scipy/scipy/pull/10023>`__: BUG: Avoid exponnorm producing nan for small K values.
* `#10025 <https://github.com/scipy/scipy/pull/10025>`__: BUG: optimize: tweaked linprog status 4 error message
* `#10026 <https://github.com/scipy/scipy/pull/10026>`__: ENH: optimize: use SuiteSparse in linprog interior-point when...
* `#10027 <https://github.com/scipy/scipy/pull/10027>`__: MAINT: cluster: clean up the use of malloc() in the function...
* `#10028 <https://github.com/scipy/scipy/pull/10028>`__: Fix rotate invalid plane check
* `#10040 <https://github.com/scipy/scipy/pull/10040>`__: MAINT: fix pratt method of wilcox test in scipy.stats
* `#10041 <https://github.com/scipy/scipy/pull/10041>`__: MAINT: special: Fix a warning generated when building the AMOS...
* `#10044 <https://github.com/scipy/scipy/pull/10044>`__: DOC: fix up spatial.transform.Rotation docstrings
* `#10047 <https://github.com/scipy/scipy/pull/10047>`__: MAINT: interpolate: Fix a few build warnings.
* `#10051 <https://github.com/scipy/scipy/pull/10051>`__: Add project_urls to setup
* `#10052 <https://github.com/scipy/scipy/pull/10052>`__: don't set flag to "converged" if max iter exceeded
* `#10054 <https://github.com/scipy/scipy/pull/10054>`__: MAINT: signal: Fix a few build warnings and modernize some C...
* `#10056 <https://github.com/scipy/scipy/pull/10056>`__: BUG: Ensure factorial is not too large in kendaltau
* `#10058 <https://github.com/scipy/scipy/pull/10058>`__: Small speedup in samping from ortho and special_ortho groups
* `#10059 <https://github.com/scipy/scipy/pull/10059>`__: BUG: optimize: fix #10038 by increasing tol
* `#10061 <https://github.com/scipy/scipy/pull/10061>`__: BLD: DOC: make building docs easier by parsing python version.
* `#10064 <https://github.com/scipy/scipy/pull/10064>`__: ENH: Significant speedup for ortho and special ortho group
* `#10065 <https://github.com/scipy/scipy/pull/10065>`__: DOC: Reword parameter descriptions in \`optimize.root_scalar\`
* `#10066 <https://github.com/scipy/scipy/pull/10066>`__: BUG: signal: Fix error raised by savgol_coeffs when deriv > polyorder.
* `#10067 <https://github.com/scipy/scipy/pull/10067>`__: MAINT: Fix the cutoff value inconsistency for pinv2 and pinvh
* `#10072 <https://github.com/scipy/scipy/pull/10072>`__: BUG: stats: Fix boxcox_llf to avoid loss of precision.
* `#10075 <https://github.com/scipy/scipy/pull/10075>`__: ENH: Add wrappers for ?syconv routines
* `#10076 <https://github.com/scipy/scipy/pull/10076>`__: BUG: optimize: fix curve_fit for mixed float32/float64 input
* `#10077 <https://github.com/scipy/scipy/pull/10077>`__: DOC: Replace undefined \`k\` in \`interpolate.splev\` docstring
* `#10079 <https://github.com/scipy/scipy/pull/10079>`__: DOC: Fixed typo, rearranged some doc of stats.morestats.wilcoxon.
* `#10080 <https://github.com/scipy/scipy/pull/10080>`__: TST: install scikit-sparse for full TravisCI tests
* `#10083 <https://github.com/scipy/scipy/pull/10083>`__: Clean \`\`_clean_inputs\`\` in optimize.linprog
* `#10088 <https://github.com/scipy/scipy/pull/10088>`__: ENH: optimize: linprog test CHOLMOD/UMFPACK solvers when available
* `#10090 <https://github.com/scipy/scipy/pull/10090>`__: MAINT: Fix CubicSplinerInterpolator for pandas
* `#10091 <https://github.com/scipy/scipy/pull/10091>`__: MAINT: improve logcdf and logsf of hypergeometric distribution
* `#10095 <https://github.com/scipy/scipy/pull/10095>`__: MAINT: Clean \`\`_clean_inputs\`\` in linprog
* `#10116 <https://github.com/scipy/scipy/pull/10116>`__: MAINT: update scipy-sphinx-theme
* `#10135 <https://github.com/scipy/scipy/pull/10135>`__: BUG: fix linprog revised simplex docstring problem failure
==========================
SciPy 0.17.1 Release Notes
==========================

SciPy 0.17.1 is a bug-fix release with no new features compared to 0.17.0.


Issues closed for 0.17.1
------------------------

- `#5817 <https://github.com/scipy/scipy/issues/5817>`__: BUG: skew, kurtosis return np.nan instead of "propagate"
- `#5850 <https://github.com/scipy/scipy/issues/5850>`__: Test failed with sgelsy
- `#5898 <https://github.com/scipy/scipy/issues/5898>`__: interpolate.interp1d crashes using float128
- `#5953 <https://github.com/scipy/scipy/issues/5953>`__: Massive performance regression in cKDTree.query with L_inf distance...
- `#6062 <https://github.com/scipy/scipy/issues/6062>`__: mannwhitneyu breaks backward compatibility in 0.17.0
- `#6134 <https://github.com/scipy/scipy/issues/6134>`__: T test does not handle nans


Pull requests for 0.17.1
------------------------

- `#5902 <https://github.com/scipy/scipy/pull/5902>`__: BUG: interpolate: make interp1d handle np.float128 again
- `#5957 <https://github.com/scipy/scipy/pull/5957>`__: BUG: slow down with p=np.inf in 0.17 cKDTree.query
- `#5970 <https://github.com/scipy/scipy/pull/5970>`__: Actually propagate nans through stats functions with nan_policy="propagate"
- `#5971 <https://github.com/scipy/scipy/pull/5971>`__: BUG: linalg: fix lwork check in ``*gelsy``
- `#6074 <https://github.com/scipy/scipy/pull/6074>`__: BUG: special: fixed violation of strict aliasing rules.
- `#6083 <https://github.com/scipy/scipy/pull/6083>`__: BUG: Fix dtype for sum of linear operators
- `#6100 <https://github.com/scipy/scipy/pull/6100>`__: BUG: Fix mannwhitneyu to be backward compatible
- `#6135 <https://github.com/scipy/scipy/pull/6135>`__: Don't pass null pointers to LAPACK, even during workspace queries.
- `#6148 <https://github.com/scipy/scipy/pull/6148>`__: stats: fix handling of nan values in T tests and kendalltau


==========================
SciPy 1.7.3 Release Notes
==========================

.. contents::

SciPy 1.7.3 is a bug-fix release that provides binary wheels
for MacOS arm64 with Python 3.8, 3.9, and 3.10. The MacOS arm64 wheels
are only available for MacOS version 12.0 and greater, as explained
in Issue 14688, linked below.

Authors
=======

* Anirudh Dagar
* Ralf Gommers
* Tyler Reddy
* Pamphile Roy
* Olivier Grisel
* Isuru Fernando

A total of 6 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.7.3
-----------------------

* `#13364 <https://github.com/scipy/scipy/issues/13364>`__: Segmentation fault on import of scipy.integrate on Apple M1 ARM...
* `#14688 <https://github.com/scipy/scipy/issues/14688>`__: BUG: ARPACK's eigsh & OpenBLAS from Apple Silicon M1 (arm64)...
* `#14991 <https://github.com/scipy/scipy/issues/14991>`__: four CI failures on pre-release job
* `#15077 <https://github.com/scipy/scipy/issues/15077>`__: Remaining test failures for macOS arm64 wheel
* `#15081 <https://github.com/scipy/scipy/issues/15081>`__: BUG: Segmentation fault caused by scipy.stats.qmc.qmc.update_discrepancy


Pull requests for 1.7.3
-----------------------

* `#14990 <https://github.com/scipy/scipy/pull/14990>`__: BLD: update pyproject.toml for Python 3.10 changes
* `#15086 <https://github.com/scipy/scipy/pull/15086>`__: BUG: out of bounds indexing in stats.qmc.update_discrepancy
* `#15090 <https://github.com/scipy/scipy/pull/15090>`__: MAINT: skip a few failing tests in \`1.7.x\` for macOS arm64
==========================
SciPy 0.18.0 Release Notes
==========================

.. contents::

SciPy 0.18.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.19.x branch, and on adding
new features on the master branch.

This release requires Python 2.7 or 3.4-3.5 and NumPy 1.7.1 or greater.

Highlights of this release include:

- A new ODE solver for two-point boundary value problems,
  `scipy.optimize.solve_bvp`.
- A new class, `CubicSpline`, for cubic spline interpolation of data.
- N-dimensional tensor product polynomials, `scipy.interpolate.NdPPoly`.
- Spherical Voronoi diagrams, `scipy.spatial.SphericalVoronoi`.
- Support for discrete-time linear systems, `scipy.signal.dlti`.


New features
============

`scipy.integrate` improvements
------------------------------

A solver of two-point boundary value problems for ODE systems has been
implemented in `scipy.integrate.solve_bvp`. The solver allows for non-separated
boundary conditions, unknown parameters and certain singular terms. It finds
a C1 continious solution using a fourth-order collocation algorithm.


`scipy.interpolate` improvements
--------------------------------

Cubic spline interpolation is now available via `scipy.interpolate.CubicSpline`.
This class represents a piecewise cubic polynomial passing through given points
and C2 continuous. It is represented in the standard polynomial basis on each
segment.

A representation of n-dimensional tensor product piecewise polynomials is
available as the `scipy.interpolate.NdPPoly` class.

Univariate piecewise polynomial classes, `PPoly` and `Bpoly`, can now be
evaluated on periodic domains. Use ``extrapolate="periodic"`` keyword
argument for this.


`scipy.fftpack` improvements
----------------------------

`scipy.fftpack.next_fast_len` function computes the next "regular" number for
FFTPACK. Padding the input to this length can give significant performance
increase for `scipy.fftpack.fft`.


`scipy.signal` improvements
---------------------------

Resampling using polyphase filtering has been implemented in the function
`scipy.signal.resample_poly`. This method upsamples a signal, applies a
zero-phase low-pass FIR filter, and downsamples using `scipy.signal.upfirdn`
(which is also new in 0.18.0).  This method can be faster than FFT-based
filtering provided by `scipy.signal.resample` for some signals.

`scipy.signal.firls`, which constructs FIR filters using least-squares error
minimization, was added.

`scipy.signal.sosfiltfilt`, which does forward-backward filtering like
`scipy.signal.filtfilt` but for second-order sections, was added.


Discrete-time linear systems
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

`scipy.signal.dlti` provides an implementation of discrete-time linear systems.
Accordingly, the `StateSpace`, `TransferFunction` and `ZerosPolesGain` classes
have learned a the new keyword, `dt`, which can be used to create discrete-time
instances of the corresponding system representation.


`scipy.sparse` improvements
---------------------------

The functions `sum`, `max`, `mean`, `min`, `transpose`, and `reshape` in
`scipy.sparse` have had their signatures augmented with additional arguments
and functionality so as to improve compatibility with analogously defined
functions in `numpy`.

Sparse matrices now have a `count_nonzero` method, which counts the number of
nonzero elements in the matrix. Unlike `getnnz()` and ``nnz`` property,
which return the number of stored entries (the length of the data attribute),
this method counts the actual number of non-zero entries in data.


`scipy.optimize` improvements
-----------------------------

The implementation of Nelder-Mead minimization,
`scipy.minimize(..., method="Nelder-Mead")`, obtained a new keyword,
`initial_simplex`, which can be used to specify the initial simplex for the
optimization process.

Initial step size selection in CG and BFGS minimizers has been improved. We
expect that this change will improve numeric stability of optimization in some
cases. See pull request gh-5536 for details.

Handling of infinite bounds in SLSQP optimization has been improved. We expect
that this change will improve numeric stability of optimization in the some
cases. See pull request gh-6024 for details.

A large suite of global optimization benchmarks has been added to
``scipy/benchmarks/go_benchmark_functions``. See pull request gh-4191 for details.

Nelder-Mead and Powell minimization will now only set defaults for
maximum iterations or function evaluations if neither limit is set by
the caller. In some cases with a slow converging function and only 1
limit set, the minimization may continue for longer than with previous
versions and so is more likely to reach convergence. See issue gh-5966.

`scipy.stats` improvements
--------------------------

Trapezoidal distribution has been implemented as ``scipy.stats.trapz``.
Skew normal distribution has been implemented as `scipy.stats.skewnorm`.
Burr type XII distribution has been implemented as `scipy.stats.burr12`.
Three- and four-parameter kappa distributions have been implemented as
`scipy.stats.kappa3` and `scipy.stats.kappa4`, respectively.

New `scipy.stats.iqr` function computes the interquartile region of a
distribution.

Random matrices
~~~~~~~~~~~~~~~

`scipy.stats.special_ortho_group` and `scipy.stats.ortho_group` provide
generators of random matrices in the SO(N) and O(N) groups, respectively. They
generate matrices in the Haar distribution, the only uniform distribution on
these group manifolds.

`scipy.stats.random_correlation` provides a generator for random
correlation matrices, given specified eigenvalues.


`scipy.linalg` improvements
---------------------------

`scipy.linalg.svd` gained a new keyword argument, ``lapack_driver``. Available
drivers are ``gesdd`` (default) and ``gesvd``.

`scipy.linalg.lapack.ilaver` returns the version of the LAPACK library SciPy
links to.


`scipy.spatial` improvements
----------------------------

Boolean distances, `scipy.spatial.pdist`, have been sped up. Improvements vary
by the function and the input size. In many cases, one can expect a speed-up
of x2--x10.

New class `scipy.spatial.SphericalVoronoi` constructs Voronoi diagrams on the
surface of a sphere. See pull request gh-5232 for details.

`scipy.cluster` improvements
----------------------------

A new clustering algorithm, the nearest neighbor chain algorithm, has been
implemented for `scipy.cluster.hierarchy.linkage`. As a result, one can expect
a significant algorithmic improvement (:math:`O(N^2)` instead of :math:`O(N^3)`)
for several linkage methods.


`scipy.special` improvements
----------------------------

The new function `scipy.special.loggamma` computes the principal branch of the
logarithm of the Gamma function. For real input, ``loggamma`` is compatible
with `scipy.special.gammaln`. For complex input, it has more consistent
behavior in the complex plane and should be preferred over ``gammaln``.

Vectorized forms of spherical Bessel functions have been implemented as
`scipy.special.spherical_jn`, `scipy.special.spherical_kn`,
`scipy.special.spherical_in` and `scipy.special.spherical_yn`.
They are recommended for use over ``sph_*`` functions, which are now deprecated.

Several special functions have been extended to the complex domain and/or
have seen domain/stability improvements. This includes `spence`, `digamma`,
`log1p` and several others.


Deprecated features
===================

The cross-class properties of `lti` systems have been deprecated. The
following properties/setters will raise a `DeprecationWarning`:

Name - (accessing/setting raises warning) - (setting raises warning)
* StateSpace - (`num`, `den`, `gain`) - (`zeros`, `poles`)
* TransferFunction (`A`, `B`, `C`, `D`, `gain`) - (`zeros`, `poles`)
* ZerosPolesGain (`A`, `B`, `C`, `D`, `num`, `den`) - ()

Spherical Bessel functions, ``sph_in``, ``sph_jn``, ``sph_kn``, ``sph_yn``,
``sph_jnyn`` and ``sph_inkn`` have been deprecated in favor of
`scipy.special.spherical_jn` and ``spherical_kn``, ``spherical_yn``,
``spherical_in``.

The following functions in `scipy.constants` are deprecated: ``C2K``, ``K2C``,
``C2F``, ``F2C``, ``F2K`` and ``K2F``.  They are superceded by a new function
`scipy.constants.convert_temperature` that can perform all those conversions
plus to/from the Rankine temperature scale.


Backwards incompatible changes
==============================

`scipy.optimize`
----------------

The convergence criterion for ``optimize.bisect``,
``optimize.brentq``, ``optimize.brenth``, and ``optimize.ridder`` now
works the same as ``numpy.allclose``.

`scipy.ndimage`
---------------

The offset in ``ndimage.iterpolation.affine_transform``
is now consistently added after the matrix is applied,
independent of if the matrix is specified using a one-dimensional
or a two-dimensional array.

`scipy.stats`
-------------

``stats.ks_2samp`` used to return nonsensical values if the input was
not real or contained nans.  It now raises an exception for such inputs.

Several deprecated methods of `scipy.stats` distributions have been removed:
``est_loc_scale``, ``vecfunc``, ``veccdf`` and ``vec_generic_moment``.

Deprecated functions ``nanmean``, ``nanstd`` and ``nanmedian`` have been removed
from `scipy.stats`. These functions were deprecated in scipy 0.15.0 in favor
of their `numpy` equivalents.

A bug in the ``rvs()`` method of the distributions in `scipy.stats` has
been fixed.  When arguments to ``rvs()`` were given that were shaped for
broadcasting, in many cases the returned random samples were not random.
A simple example of the problem is ``stats.norm.rvs(loc=np.zeros(10))``.
Because of the bug, that call would return 10 identical values.  The bug
only affected code that relied on the broadcasting of the shape, location
and scale parameters.

The ``rvs()`` method also accepted some arguments that it should not have.
There is a potential for backwards incompatibility in cases where ``rvs()``
accepted arguments that are not, in fact, compatible with broadcasting.
An example is

    stats.gamma.rvs([2, 5, 10, 15], size=(2,2))

The shape of the first argument is not compatible with the requested size,
but the function still returned an array with shape (2, 2).  In scipy 0.18,
that call generates a ``ValueError``.

`scipy.io`
----------

``scipy.io.netcdf`` masking now gives precedence to the ``_FillValue`` attribute
over the ``missing_value`` attribute, if both are given. Also, data are only
treated as missing if they match one of these attributes exactly: values that
differ by roundoff from ``_FillValue`` or ``missing_value`` are no longer
treated as missing values.

`scipy.interpolate`
-------------------

`scipy.interpolate.PiecewisePolynomial` class has been removed. It has been
deprecated in scipy 0.14.0, and `scipy.interpolate.BPoly.from_derivatives` serves
as a drop-in replacement.


Other changes
=============

Scipy now uses ``setuptools`` for its builds instead of plain distutils.  This
fixes usage of ``install_requires='scipy'`` in the ``setup.py`` files of
projects that depend on Scipy (see Numpy issue gh-6551 for details).  It
potentially affects the way that build/install methods for Scipy itself behave
though.  Please report any unexpected behavior on the Scipy issue tracker.

PR `#6240 <https://github.com/scipy/scipy/pull/6240>`__
changes the interpretation of the `maxfun` option in `L-BFGS-B` based routines
in the `scipy.optimize` module.
An `L-BFGS-B` search consists of multiple iterations,
with each iteration consisting of one or more function evaluations.
Whereas the old search strategy terminated immediately upon reaching `maxfun`
function evaluations, the new strategy allows the current iteration
to finish despite reaching `maxfun`.

The bundled copy of Qhull in the `scipy.spatial` subpackage has been upgraded to
version 2015.2.

The bundled copy of ARPACK in the `scipy.sparse.linalg` subpackage has been
upgraded to arpack-ng 3.3.0.

The bundled copy of SuperLU in the `scipy.sparse` subpackage has been upgraded
to version 5.1.1.


Authors
=======

* @endolith
* @yanxun827 +
* @kleskjr +
* @MYheavyGo +
* @solarjoe +
* Gregory Allen +
* Gilles Aouizerate +
* Tom Augspurger +
* Henrik Bengtsson +
* Felix Berkenkamp
* Per Brodtkorb
* Lars Buitinck
* Daniel Bunting +
* Evgeni Burovski
* CJ Carey
* Tim Cera
* Grey Christoforo +
* Robert Cimrman
* Philip DeBoer +
* Yves Delley +
* Dávid Bodnár +
* Ion Elberdin +
* Gabriele Farina +
* Yu Feng
* Andrew Fowlie +
* Joseph Fox-Rabinovitz
* Simon Gibbons +
* Neil Girdhar +
* Kolja Glogowski +
* Christoph Gohlke
* Ralf Gommers
* Todd Goodall +
* Johnnie Gray +
* Alex Griffing
* Olivier Grisel
* Thomas Haslwanter +
* Michael Hirsch +
* Derek Homeier
* Golnaz Irannejad +
* Marek Jacob +
* InSuk Joung +
* Tetsuo Koyama +
* Eugene Krokhalev +
* Eric Larson
* Denis Laxalde
* Antony Lee
* Jerry Li +
* Henry Lin +
* Nelson Liu +
* Loïc Estève
* Lei Ma +
* Osvaldo Martin +
* Stefano Martina +
* Nikolay Mayorov
* Matthieu Melot +
* Sturla Molden
* Eric Moore
* Alistair Muldal +
* Maniteja Nandana
* Tavi Nathanson +
* Andrew Nelson
* Joel Nothman
* Behzad Nouri
* Nikolai Nowaczyk +
* Juan Nunez-Iglesias +
* Ted Pudlik
* Eric Quintero
* Yoav Ram
* Jonas Rauber +
* Tyler Reddy +
* Juha Remes
* Garrett Reynolds +
* Ariel Rokem +
* Fabian Rost +
* Bill Sacks +
* Jona Sassenhagen +
* Kari Schoonbee +
* Marcello Seri +
* Sourav Singh +
* Martin Spacek +
* Søren Fuglede Jørgensen +
* Bhavika Tekwani +
* Martin Thoma +
* Sam Tygier +
* Meet Udeshi +
* Utkarsh Upadhyay
* Bram Vandekerckhove +
* Sebastián Vanrell +
* Ze Vinicius +
* Pauli Virtanen
* Stefan van der Walt
* Warren Weckesser
* Jakub Wilk +
* Josh Wilson
* Phillip J. Wolfram +
* Nathan Woods
* Haochen Wu
* G Young +

A total of 99 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.


Issues closed for 0.18.0
------------------------

- `#1484 <https://github.com/scipy/scipy/issues/1484>`__: SVD using ``*GESVD`` lapack drivers (Trac #957)
- `#1547 <https://github.com/scipy/scipy/issues/1547>`__: Inconsistent use of offset in ndimage.interpolation.affine_transform()...
- `#1609 <https://github.com/scipy/scipy/issues/1609>`__: special.hyp0f1 returns nan (Trac #1082)
- `#1656 <https://github.com/scipy/scipy/issues/1656>`__: fmin_slsqp enhancement (Trac #1129)
- `#2069 <https://github.com/scipy/scipy/issues/2069>`__: stats broadcasting in rvs (Trac #1544)
- `#2165 <https://github.com/scipy/scipy/issues/2165>`__: sph_jn returns false results for some orders/values (Trac #1640)
- `#2255 <https://github.com/scipy/scipy/issues/2255>`__: Incorrect order of translation and rotation in affine_transform...
- `#2332 <https://github.com/scipy/scipy/issues/2332>`__: hyp0f1 args and return values are unnumpyic (Trac #1813)
- `#2534 <https://github.com/scipy/scipy/issues/2534>`__: The sparse .sum() method with uint8 dtype does not act like the...
- `#3113 <https://github.com/scipy/scipy/issues/3113>`__: Implement ufuncs for CSPHJY, SPHJ, SPHY, CSPHIK, SPHI, SPHIK...
- `#3568 <https://github.com/scipy/scipy/issues/3568>`__: SciPy 0.13.3 - CentOS5 - Errors in test_arpack
- `#3581 <https://github.com/scipy/scipy/issues/3581>`__: optimize: stepsize in fmin_bfgs is "bad"
- `#4476 <https://github.com/scipy/scipy/issues/4476>`__: scipy.sparse non-native endian bug
- `#4484 <https://github.com/scipy/scipy/issues/4484>`__: ftol in optimize.fmin fails to work
- `#4510 <https://github.com/scipy/scipy/issues/4510>`__: sparsetools.cxx call_thunk can segfault due to out of bounds...
- `#5051 <https://github.com/scipy/scipy/issues/5051>`__: ftol and xtol for _minimize_neldermead are absolute instead of...
- `#5097 <https://github.com/scipy/scipy/issues/5097>`__: proposal: spherical Voronoi diagrams
- `#5123 <https://github.com/scipy/scipy/issues/5123>`__: Call to `scipy.sparse.coo_matrix` fails when passed Cython typed...
- `#5220 <https://github.com/scipy/scipy/issues/5220>`__: scipy.cluster.hierarchy.{ward,median,centroid} does not work...
- `#5379 <https://github.com/scipy/scipy/issues/5379>`__: Add a build step at the end of .travis.yml that uploads working...
- `#5440 <https://github.com/scipy/scipy/issues/5440>`__: scipy.optimize.basinhopping: accept_test returning ``numpy.bool_``...
- `#5452 <https://github.com/scipy/scipy/issues/5452>`__: Error in scipy.integrate.nquad when using variable integration...
- `#5520 <https://github.com/scipy/scipy/issues/5520>`__: Cannot inherit csr_matrix properly
- `#5533 <https://github.com/scipy/scipy/issues/5533>`__: Kendall tau implementation uses Python mergesort
- `#5553 <https://github.com/scipy/scipy/issues/5553>`__: stats.tiecorrect overflows
- `#5589 <https://github.com/scipy/scipy/issues/5589>`__: Add the Type XII Burr distribution to stats.
- `#5612 <https://github.com/scipy/scipy/issues/5612>`__: sparse.linalg factorizations slow for small k due to default...
- `#5626 <https://github.com/scipy/scipy/issues/5626>`__: io.netcdf masking should use masked_equal rather than masked_value
- `#5637 <https://github.com/scipy/scipy/issues/5637>`__: Simple cubic spline interpolation?
- `#5683 <https://github.com/scipy/scipy/issues/5683>`__: BUG: Akima1DInterpolator may return nans given multidimensional...
- `#5686 <https://github.com/scipy/scipy/issues/5686>`__: scipy.stats.ttest_ind_from_stats does not accept arrays
- `#5702 <https://github.com/scipy/scipy/issues/5702>`__: scipy.ndimage.interpolation.affine_transform lacks documentation...
- `#5718 <https://github.com/scipy/scipy/issues/5718>`__: Wrong computation of weighted minkowski distance in cdist
- `#5745 <https://github.com/scipy/scipy/issues/5745>`__: move to setuptools for next release
- `#5752 <https://github.com/scipy/scipy/issues/5752>`__: DOC: solve_discrete_lyapunov equation puts transpose in wrong...
- `#5760 <https://github.com/scipy/scipy/issues/5760>`__: signal.ss2tf doesn't handle zero-order state-space models
- `#5764 <https://github.com/scipy/scipy/issues/5764>`__: Hypergeometric function hyp0f1 behaves incorrectly for complex...
- `#5814 <https://github.com/scipy/scipy/issues/5814>`__: stats NaN Policy Error message inconsistent with code
- `#5833 <https://github.com/scipy/scipy/issues/5833>`__: docstring of stats.binom_test() needs an update
- `#5853 <https://github.com/scipy/scipy/issues/5853>`__: Error in scipy.linalg.expm for complex matrix with shape (1,1)
- `#5856 <https://github.com/scipy/scipy/issues/5856>`__: Specify Nelder-Mead initial simplex
- `#5865 <https://github.com/scipy/scipy/issues/5865>`__: scipy.linalg.expm fails for certain numpy matrices
- `#5915 <https://github.com/scipy/scipy/issues/5915>`__: optimize.basinhopping - variable referenced before assignment.
- `#5916 <https://github.com/scipy/scipy/issues/5916>`__: LSQUnivariateSpline fitting failed with knots generated from...
- `#5927 <https://github.com/scipy/scipy/issues/5927>`__: unicode vs. string comparison in scipy.stats.binned_statistic_dd
- `#5936 <https://github.com/scipy/scipy/issues/5936>`__: faster implementation of ks_2samp
- `#5948 <https://github.com/scipy/scipy/issues/5948>`__: csc matrix .mean returns single element matrix rather than scalar
- `#5959 <https://github.com/scipy/scipy/issues/5959>`__: BUG: optimize test error for root when using lgmres
- `#5972 <https://github.com/scipy/scipy/issues/5972>`__: Test failures for sparse sum tests on 32-bit Python
- `#5976 <https://github.com/scipy/scipy/issues/5976>`__: Unexpected exception in scipy.sparse.bmat while using 0 x 0 matrix
- `#6008 <https://github.com/scipy/scipy/issues/6008>`__: scipy.special.kl_div not available in 0.14.1
- `#6011 <https://github.com/scipy/scipy/issues/6011>`__: The von-Mises entropy is broken
- `#6016 <https://github.com/scipy/scipy/issues/6016>`__: python crashes for linalg.interpolative.svd with certain large...
- `#6017 <https://github.com/scipy/scipy/issues/6017>`__: Wilcoxon signed-rank test with zero_method="pratt" or "zsplit"...
- `#6028 <https://github.com/scipy/scipy/issues/6028>`__: stats.distributions does not have trapezoidal distribution
- `#6035 <https://github.com/scipy/scipy/issues/6035>`__: Wrong link in f_oneway
- `#6056 <https://github.com/scipy/scipy/issues/6056>`__: BUG: signal.decimate should only accept discrete LTI objects
- `#6093 <https://github.com/scipy/scipy/issues/6093>`__: Precision error on Linux 32 bit with openblas
- `#6101 <https://github.com/scipy/scipy/issues/6101>`__: Barycentric transforms test error on Python3, 32-bit Linux
- `#6105 <https://github.com/scipy/scipy/issues/6105>`__: scipy.misc.face docstring is incorrect
- `#6113 <https://github.com/scipy/scipy/issues/6113>`__: scipy.linalg.logm fails for a trivial matrix
- `#6128 <https://github.com/scipy/scipy/issues/6128>`__: Error in dot method of sparse COO array, when used with numpy...
- `#6132 <https://github.com/scipy/scipy/issues/6132>`__: Failures with latest MKL
- `#6136 <https://github.com/scipy/scipy/issues/6136>`__: Failures on `master` with MKL
- `#6162 <https://github.com/scipy/scipy/issues/6162>`__: fmin_l_bfgs_b returns inconsistent results (fmin ≠ f(xmin)) and...
- `#6165 <https://github.com/scipy/scipy/issues/6165>`__: optimize.minimize infinite loop with Newton-CG
- `#6167 <https://github.com/scipy/scipy/issues/6167>`__: incorrect distribution fitting for data containing boundary values.
- `#6194 <https://github.com/scipy/scipy/issues/6194>`__: lstsq() and others detect numpy.complex256 as real
- `#6216 <https://github.com/scipy/scipy/issues/6216>`__: ENH: improve accuracy of ppf cdf roundtrip for bradford
- `#6217 <https://github.com/scipy/scipy/issues/6217>`__: BUG: weibull_min.logpdf return nan for c=1 and x=0
- `#6218 <https://github.com/scipy/scipy/issues/6218>`__: Is there a method to cap shortest path search distances?
- `#6222 <https://github.com/scipy/scipy/issues/6222>`__: PchipInterpolator no longer handles a 2-element array
- `#6226 <https://github.com/scipy/scipy/issues/6226>`__: ENH: improve accuracy for logistic.ppf and logistic.isf
- `#6227 <https://github.com/scipy/scipy/issues/6227>`__: ENH: improve accuracy for rayleigh.logpdf and rayleigh.logsf...
- `#6228 <https://github.com/scipy/scipy/issues/6228>`__: ENH: improve accuracy of ppf cdf roundtrip for gumbel_l
- `#6235 <https://github.com/scipy/scipy/issues/6235>`__: BUG: alpha.pdf and alpha.logpdf returns nan for x=0
- `#6245 <https://github.com/scipy/scipy/issues/6245>`__: ENH: improve accuracy for ppf-cdf and sf-isf roundtrips for invgamma
- `#6263 <https://github.com/scipy/scipy/issues/6263>`__: BUG: stats: Inconsistency in the multivariate_normal docstring
- `#6292 <https://github.com/scipy/scipy/issues/6292>`__: Python 3 unorderable type errors in test_sparsetools.TestInt32Overflow
- `#6316 <https://github.com/scipy/scipy/issues/6316>`__: TestCloughTocher2DInterpolator.test_dense crashes python3.5.2rc1_64bit...
- `#6318 <https://github.com/scipy/scipy/issues/6318>`__: Scipy interp1d 'nearest' not working for high values on x-axis


Pull requests for 0.18.0
------------------------

- `#3226 <https://github.com/scipy/scipy/pull/3226>`__: DOC: Change `nb` and `na` to conventional m and n
- `#3867 <https://github.com/scipy/scipy/pull/3867>`__: allow cKDTree.query taking a list input in k.
- `#4191 <https://github.com/scipy/scipy/pull/4191>`__: ENH: Benchmarking global optimizers
- `#4356 <https://github.com/scipy/scipy/pull/4356>`__: ENH: add PPoly.solve(y) for solving ``p(x) == y``
- `#4370 <https://github.com/scipy/scipy/pull/4370>`__: DOC separate boolean distance functions for clarity
- `#4678 <https://github.com/scipy/scipy/pull/4678>`__: BUG: sparse: ensure index dtype is large enough to pass all parameters...
- `#4881 <https://github.com/scipy/scipy/pull/4881>`__: scipy.signal: Add the class dlti for linear discrete-time systems....
- `#4901 <https://github.com/scipy/scipy/pull/4901>`__: MAINT: add benchmark and improve docstring for signal.lfilter
- `#5043 <https://github.com/scipy/scipy/pull/5043>`__: ENH: sparse: add count_nonzero method
- `#5136 <https://github.com/scipy/scipy/pull/5136>`__: Attribute kurtosistest() to Anscombe & Glynn (1983)
- `#5186 <https://github.com/scipy/scipy/pull/5186>`__: ENH: Port upfirdn
- `#5232 <https://github.com/scipy/scipy/pull/5232>`__: ENH: adding spherical Voronoi diagram algorithm to scipy.spatial
- `#5279 <https://github.com/scipy/scipy/pull/5279>`__: ENH: Bessel filters with different normalizations, high order
- `#5384 <https://github.com/scipy/scipy/pull/5384>`__: BUG: Closes #5027 distance function always casts bool to double
- `#5392 <https://github.com/scipy/scipy/pull/5392>`__: ENH: Add zero_phase kwarg to signal.decimate
- `#5394 <https://github.com/scipy/scipy/pull/5394>`__: MAINT: sparse: non-canonical test cleanup and fixes
- `#5424 <https://github.com/scipy/scipy/pull/5424>`__: DOC: add Scipy developers guide
- `#5442 <https://github.com/scipy/scipy/pull/5442>`__: STY: PEP8 amendments
- `#5472 <https://github.com/scipy/scipy/pull/5472>`__: Online QR in LGMRES
- `#5526 <https://github.com/scipy/scipy/pull/5526>`__: BUG: stats: Fix broadcasting in the rvs() method of the distributions.
- `#5530 <https://github.com/scipy/scipy/pull/5530>`__: MAINT: sparse: set `format` attr explicitly
- `#5536 <https://github.com/scipy/scipy/pull/5536>`__: optimize: fix up cg/bfgs initial step sizes
- `#5548 <https://github.com/scipy/scipy/pull/5548>`__: PERF: improves performance in stats.kendalltau
- `#5549 <https://github.com/scipy/scipy/pull/5549>`__: ENH: Nearest-neighbor chain algorithm for hierarchical clustering
- `#5554 <https://github.com/scipy/scipy/pull/5554>`__: MAINT/BUG: closes overflow bug in stats.tiecorrect
- `#5557 <https://github.com/scipy/scipy/pull/5557>`__: BUG: modify optimize.bisect to achieve desired tolerance
- `#5581 <https://github.com/scipy/scipy/pull/5581>`__: DOC: Tutorial for least_squares
- `#5606 <https://github.com/scipy/scipy/pull/5606>`__: ENH: differential_evolution - moving core loop of solve method...
- `#5609 <https://github.com/scipy/scipy/pull/5609>`__: [MRG] test against numpy dev
- `#5611 <https://github.com/scipy/scipy/pull/5611>`__: use setuptools for bdist_egg distributions
- `#5615 <https://github.com/scipy/scipy/pull/5615>`__: MAINT: linalg: tighten _decomp_update + special: remove unused...
- `#5622 <https://github.com/scipy/scipy/pull/5622>`__: Add SO(N) rotation matrix generator
- `#5623 <https://github.com/scipy/scipy/pull/5623>`__: ENH: special: Add vectorized spherical Bessel functions.
- `#5627 <https://github.com/scipy/scipy/pull/5627>`__: Response to issue #5160, implements the skew normal distribution...
- `#5628 <https://github.com/scipy/scipy/pull/5628>`__: DOC: Align the description and operation
- `#5632 <https://github.com/scipy/scipy/pull/5632>`__: DOC: special: Expanded docs for Airy, elliptic, Bessel functions.
- `#5633 <https://github.com/scipy/scipy/pull/5633>`__: MAINT: linalg: unchecked malloc in _decomp_update
- `#5634 <https://github.com/scipy/scipy/pull/5634>`__: MAINT: optimize: tighten _group_columns
- `#5640 <https://github.com/scipy/scipy/pull/5640>`__: Fixes for io.netcdf masking
- `#5645 <https://github.com/scipy/scipy/pull/5645>`__: MAINT: size 0 vector handling in cKDTree range queries
- `#5649 <https://github.com/scipy/scipy/pull/5649>`__: MAINT: update license text
- `#5650 <https://github.com/scipy/scipy/pull/5650>`__: DOC: Clarify Exponent Order in ltisys.py
- `#5651 <https://github.com/scipy/scipy/pull/5651>`__: DOC: Clarify Documentation for scipy.special.gammaln
- `#5652 <https://github.com/scipy/scipy/pull/5652>`__: DOC: Fixed scipy.special.betaln Doc
- `#5653 <https://github.com/scipy/scipy/pull/5653>`__: [MRG] ENH: CubicSpline interpolator
- `#5654 <https://github.com/scipy/scipy/pull/5654>`__: ENH: Burr12 distribution to stats module
- `#5659 <https://github.com/scipy/scipy/pull/5659>`__: DOC: Define BEFORE/AFTER in runtests.py -h for bench-compare
- `#5660 <https://github.com/scipy/scipy/pull/5660>`__: MAINT: remove functions deprecated before 0.16.0
- `#5662 <https://github.com/scipy/scipy/pull/5662>`__: ENH: Circular statistic optimization
- `#5663 <https://github.com/scipy/scipy/pull/5663>`__: MAINT: remove uses of np.testing.rand
- `#5665 <https://github.com/scipy/scipy/pull/5665>`__: MAINT: spatial: remove matching distance implementation
- `#5667 <https://github.com/scipy/scipy/pull/5667>`__: Change some HTTP links to HTTPS
- `#5669 <https://github.com/scipy/scipy/pull/5669>`__: DOC: zpk2sos can't do analog, array_like, etc.
- `#5670 <https://github.com/scipy/scipy/pull/5670>`__: Update conf.py
- `#5672 <https://github.com/scipy/scipy/pull/5672>`__: MAINT: move a sample distribution to a subclass of rv_discrete
- `#5678 <https://github.com/scipy/scipy/pull/5678>`__: MAINT: stats: remove est_loc_scale method
- `#5679 <https://github.com/scipy/scipy/pull/5679>`__: MAINT: DRY up generic computations for discrete distributions
- `#5680 <https://github.com/scipy/scipy/pull/5680>`__: MAINT: stop shadowing builtins in stats.distributions
- `#5681 <https://github.com/scipy/scipy/pull/5681>`__: forward port ENH: Re-enable broadcasting of fill_value
- `#5684 <https://github.com/scipy/scipy/pull/5684>`__: BUG: Fix Akima1DInterpolator returning nans
- `#5690 <https://github.com/scipy/scipy/pull/5690>`__: BUG: fix stats.ttest_ind_from_stats to handle arrays.
- `#5691 <https://github.com/scipy/scipy/pull/5691>`__: BUG: fix generator in io._loadarff to comply with PEP 0479
- `#5693 <https://github.com/scipy/scipy/pull/5693>`__: ENH: use math.factorial for exact factorials
- `#5695 <https://github.com/scipy/scipy/pull/5695>`__: DOC: dx might be a float, not only an integer
- `#5699 <https://github.com/scipy/scipy/pull/5699>`__: MAINT: io: micro-optimize Matlab reading code for size
- `#5701 <https://github.com/scipy/scipy/pull/5701>`__: Implement OptimizeResult.__dir__
- `#5703 <https://github.com/scipy/scipy/pull/5703>`__: ENH: stats: make R² printing optional in probplot
- `#5704 <https://github.com/scipy/scipy/pull/5704>`__: MAINT: typo ouf->out
- `#5705 <https://github.com/scipy/scipy/pull/5705>`__: BUG: fix typo in query_pairs
- `#5707 <https://github.com/scipy/scipy/pull/5707>`__: DOC:Add some explanation for ftol xtol in scipy.optimize.fmin
- `#5708 <https://github.com/scipy/scipy/pull/5708>`__: DOC: optimize: PEP8 minimize docstring
- `#5709 <https://github.com/scipy/scipy/pull/5709>`__: MAINT: optimize Cython code for speed and size
- `#5713 <https://github.com/scipy/scipy/pull/5713>`__: [DOC] Fix broken link to reference
- `#5717 <https://github.com/scipy/scipy/pull/5717>`__: DOC: curve_fit raises RuntimeError on failure.
- `#5724 <https://github.com/scipy/scipy/pull/5724>`__: forward port gh-5720
- `#5728 <https://github.com/scipy/scipy/pull/5728>`__: STY: remove a blank line
- `#5729 <https://github.com/scipy/scipy/pull/5729>`__: ENH: spatial: speed up boolean distances
- `#5732 <https://github.com/scipy/scipy/pull/5732>`__: MAINT: differential_evolution changes to default keywords break...
- `#5733 <https://github.com/scipy/scipy/pull/5733>`__: TST: differential_evolution - population initiation tests
- `#5736 <https://github.com/scipy/scipy/pull/5736>`__: Complex number support in log1p, expm1, and xlog1py
- `#5741 <https://github.com/scipy/scipy/pull/5741>`__: MAINT: sparse: clean up extraction functions
- `#5742 <https://github.com/scipy/scipy/pull/5742>`__: DOC: signal: Explain fftbins in get_window
- `#5748 <https://github.com/scipy/scipy/pull/5748>`__: ENH: Add O(N) random matrix generator
- `#5749 <https://github.com/scipy/scipy/pull/5749>`__: ENH: Add polyphase resampling
- `#5756 <https://github.com/scipy/scipy/pull/5756>`__: RFC: Bump the minimum numpy version, drop older python versions
- `#5761 <https://github.com/scipy/scipy/pull/5761>`__: DOC: Some improvements to least squares docstrings
- `#5762 <https://github.com/scipy/scipy/pull/5762>`__: MAINT: spatial: distance refactoring
- `#5768 <https://github.com/scipy/scipy/pull/5768>`__: DOC: Fix io.loadmat docstring for mdict param
- `#5770 <https://github.com/scipy/scipy/pull/5770>`__: BUG: Accept anything np.dtype can handle for a dtype in sparse.random
- `#5772 <https://github.com/scipy/scipy/pull/5772>`__: Update sparse.csgraph.laplacian docstring
- `#5777 <https://github.com/scipy/scipy/pull/5777>`__: BUG: fix special.hyp0f1 to work correctly for complex inputs.
- `#5780 <https://github.com/scipy/scipy/pull/5780>`__: DOC: Update PIL error install URL
- `#5781 <https://github.com/scipy/scipy/pull/5781>`__: DOC: Fix documentation on solve_discrete_lyapunov
- `#5782 <https://github.com/scipy/scipy/pull/5782>`__: DOC: cKDTree and KDTree now reference each other
- `#5783 <https://github.com/scipy/scipy/pull/5783>`__: DOC: Clarify finish behaviour in scipy.optimize.brute
- `#5784 <https://github.com/scipy/scipy/pull/5784>`__: MAINT: Change default tolerances of least_squares to 1e-8
- `#5787 <https://github.com/scipy/scipy/pull/5787>`__: BUG: Allow Processing of Zero Order State Space Models in signal.ss2tf
- `#5788 <https://github.com/scipy/scipy/pull/5788>`__: DOC, BUG: Clarify and Enforce Input Types to 'Data' Objects
- `#5789 <https://github.com/scipy/scipy/pull/5789>`__: ENH: sparse: speedup LIL matrix slicing (was #3338)
- `#5791 <https://github.com/scipy/scipy/pull/5791>`__: DOC: README: remove coveralls.io
- `#5792 <https://github.com/scipy/scipy/pull/5792>`__: MAINT: remove uses of deprecated np.random.random_integers
- `#5794 <https://github.com/scipy/scipy/pull/5794>`__: fix affine_transform (fixes #1547 and #5702)
- `#5795 <https://github.com/scipy/scipy/pull/5795>`__: DOC: Removed uniform method from kmeans2 doc
- `#5797 <https://github.com/scipy/scipy/pull/5797>`__: DOC: Clarify the computation of weighted minkowski
- `#5798 <https://github.com/scipy/scipy/pull/5798>`__: BUG: Ensure scipy's _asfarray returns ndarray
- `#5799 <https://github.com/scipy/scipy/pull/5799>`__: TST: Mpmath testing patch
- `#5801 <https://github.com/scipy/scipy/pull/5801>`__: allow reading of certain IDL 8.0 .sav files
- `#5803 <https://github.com/scipy/scipy/pull/5803>`__: DOC: fix module name in error message
- `#5804 <https://github.com/scipy/scipy/pull/5804>`__: DOC: special: Expanded docs for special functions.
- `#5805 <https://github.com/scipy/scipy/pull/5805>`__: DOC: Fix order of returns in _spectral_helper
- `#5806 <https://github.com/scipy/scipy/pull/5806>`__: ENH: sparse: vectorized coo_matrix.diagonal
- `#5808 <https://github.com/scipy/scipy/pull/5808>`__: ENH: Added iqr function to compute IQR metric in scipy/stats/stats.py
- `#5810 <https://github.com/scipy/scipy/pull/5810>`__: MAINT/BENCH: sparse: Benchmark cleanup and additions
- `#5811 <https://github.com/scipy/scipy/pull/5811>`__: DOC: sparse.linalg: shape, not size
- `#5813 <https://github.com/scipy/scipy/pull/5813>`__: Update sparse ARPACK functions min `ncv` value
- `#5815 <https://github.com/scipy/scipy/pull/5815>`__: BUG: Error message contained wrong values
- `#5816 <https://github.com/scipy/scipy/pull/5816>`__: remove dead code from stats tests
- `#5820 <https://github.com/scipy/scipy/pull/5820>`__: "in"->"a" in order_filter docstring
- `#5821 <https://github.com/scipy/scipy/pull/5821>`__: DOC: README: INSTALL.txt was renamed in 2014
- `#5825 <https://github.com/scipy/scipy/pull/5825>`__: DOC: typo in the docstring of least_squares
- `#5826 <https://github.com/scipy/scipy/pull/5826>`__: MAINT: sparse: increase test coverage
- `#5827 <https://github.com/scipy/scipy/pull/5827>`__: NdPPoly rebase
- `#5828 <https://github.com/scipy/scipy/pull/5828>`__: Improve numerical stability of hyp0f1 for large orders
- `#5829 <https://github.com/scipy/scipy/pull/5829>`__: ENH: sparse: Add copy parameter to all .toXXX() methods in sparse...
- `#5830 <https://github.com/scipy/scipy/pull/5830>`__: DOC: rework INSTALL.rst.txt
- `#5831 <https://github.com/scipy/scipy/pull/5831>`__: Adds plotting options to voronoi_plot_2d
- `#5834 <https://github.com/scipy/scipy/pull/5834>`__: Update stats.binom_test() docstring
- `#5836 <https://github.com/scipy/scipy/pull/5836>`__: ENH, TST: Allow SIMO tf's for tf2ss
- `#5837 <https://github.com/scipy/scipy/pull/5837>`__: DOC: Image examples
- `#5838 <https://github.com/scipy/scipy/pull/5838>`__: ENH: sparse: add eliminate_zeros() to coo_matrix
- `#5839 <https://github.com/scipy/scipy/pull/5839>`__: BUG: Fixed name of NumpyVersion.__repr__
- `#5845 <https://github.com/scipy/scipy/pull/5845>`__: MAINT: Fixed typos in documentation
- `#5847 <https://github.com/scipy/scipy/pull/5847>`__: Fix bugs in sparsetools
- `#5848 <https://github.com/scipy/scipy/pull/5848>`__: BUG: sparse.linalg: add locks to ensure ARPACK threadsafety
- `#5849 <https://github.com/scipy/scipy/pull/5849>`__: ENH: sparse.linalg: upgrade to superlu 5.1.1
- `#5851 <https://github.com/scipy/scipy/pull/5851>`__: ENH: expose lapack's ilaver to python to allow lapack verion...
- `#5852 <https://github.com/scipy/scipy/pull/5852>`__: MAINT: runtests.py: ensure Ctrl-C interrupts the build
- `#5854 <https://github.com/scipy/scipy/pull/5854>`__: DOC: Minor update to documentation
- `#5855 <https://github.com/scipy/scipy/pull/5855>`__: Pr 5640
- `#5859 <https://github.com/scipy/scipy/pull/5859>`__: ENH: Add random correlation matrix generator
- `#5862 <https://github.com/scipy/scipy/pull/5862>`__: BUG: Allow expm for complex matrix with shape (1, 1)
- `#5863 <https://github.com/scipy/scipy/pull/5863>`__: FIX: Fix test
- `#5864 <https://github.com/scipy/scipy/pull/5864>`__: DOC: add a little note about the Normal survival function (Q-function)
- `#5867 <https://github.com/scipy/scipy/pull/5867>`__: Fix for #5865
- `#5869 <https://github.com/scipy/scipy/pull/5869>`__: extend normal distribution cdf to complex domain
- `#5872 <https://github.com/scipy/scipy/pull/5872>`__: DOC: Note that morlet and cwt don't work together
- `#5875 <https://github.com/scipy/scipy/pull/5875>`__: DOC: interp2d class description
- `#5876 <https://github.com/scipy/scipy/pull/5876>`__: MAINT: spatial: remove a stray print statement
- `#5878 <https://github.com/scipy/scipy/pull/5878>`__: MAINT: Fixed noisy UserWarnings in ndimage tests. Fixes #5877
- `#5879 <https://github.com/scipy/scipy/pull/5879>`__: MAINT: sparse.linalg/superlu: add explicit casts to resolve compiler...
- `#5880 <https://github.com/scipy/scipy/pull/5880>`__: MAINT: signal: import gcd from math and not fractions when on...
- `#5887 <https://github.com/scipy/scipy/pull/5887>`__: Neldermead initial simplex
- `#5894 <https://github.com/scipy/scipy/pull/5894>`__: BUG: _CustomLinearOperator unpickalable in python3.5
- `#5895 <https://github.com/scipy/scipy/pull/5895>`__: DOC: special: slightly improve the multigammaln docstring
- `#5900 <https://github.com/scipy/scipy/pull/5900>`__: Remove duplicate assignment.
- `#5901 <https://github.com/scipy/scipy/pull/5901>`__: Update bundled ARPACK
- `#5904 <https://github.com/scipy/scipy/pull/5904>`__: ENH: Make convolve and correlate order-agnostic
- `#5905 <https://github.com/scipy/scipy/pull/5905>`__: ENH: sparse.linalg: further LGMRES cleanups
- `#5906 <https://github.com/scipy/scipy/pull/5906>`__: Enhancements and cleanup in scipy.integrate (attempt #2)
- `#5907 <https://github.com/scipy/scipy/pull/5907>`__: ENH: Change sparse `.sum` and `.mean` dtype casting to match...
- `#5909 <https://github.com/scipy/scipy/pull/5909>`__: changes for convolution symmetry
- `#5913 <https://github.com/scipy/scipy/pull/5913>`__: MAINT: basinhopping remove instance test closes #5440
- `#5919 <https://github.com/scipy/scipy/pull/5919>`__: MAINT: uninitialised var if basinhopping niter=0. closes #5915
- `#5920 <https://github.com/scipy/scipy/pull/5920>`__: BLD: Fix missing lsame.c error for MKL
- `#5921 <https://github.com/scipy/scipy/pull/5921>`__: DOC: interpolate: add example showing how to work around issue...
- `#5926 <https://github.com/scipy/scipy/pull/5926>`__: MAINT: spatial: upgrade to Qhull 2015.2
- `#5928 <https://github.com/scipy/scipy/pull/5928>`__: MAINT: sparse: optimize DIA sum/diagonal, csgraph.laplacian
- `#5929 <https://github.com/scipy/scipy/pull/5929>`__: Update info/URL for octave-maintainers discussion
- `#5930 <https://github.com/scipy/scipy/pull/5930>`__: TST: special: silence DeprecationWarnings from sph_yn
- `#5931 <https://github.com/scipy/scipy/pull/5931>`__: ENH: implement the principle branch of the logarithm of Gamma.
- `#5934 <https://github.com/scipy/scipy/pull/5934>`__: Typo: "mush" => "must"
- `#5935 <https://github.com/scipy/scipy/pull/5935>`__: BUG:string comparison stats._binned_statistic closes #5927
- `#5938 <https://github.com/scipy/scipy/pull/5938>`__: Cythonize stats.ks_2samp for a ~33% gain in speed.
- `#5939 <https://github.com/scipy/scipy/pull/5939>`__: DOC: fix optimize.fmin convergence docstring
- `#5941 <https://github.com/scipy/scipy/pull/5941>`__: Fix minor typo in squareform docstring
- `#5942 <https://github.com/scipy/scipy/pull/5942>`__: Update linregress stderr description.
- `#5943 <https://github.com/scipy/scipy/pull/5943>`__: ENH: Improve numerical accuracy of lognorm
- `#5944 <https://github.com/scipy/scipy/pull/5944>`__: Merge vonmises into stats pyx
- `#5945 <https://github.com/scipy/scipy/pull/5945>`__: MAINT: interpolate: Tweak declaration to avoid cython warning...
- `#5946 <https://github.com/scipy/scipy/pull/5946>`__: MAINT: sparse: clean up format conversion methods
- `#5949 <https://github.com/scipy/scipy/pull/5949>`__: BUG: fix sparse .mean to return a scalar instead of a matrix
- `#5955 <https://github.com/scipy/scipy/pull/5955>`__: MAINT: Replace calls to `hanning` with `hann`
- `#5956 <https://github.com/scipy/scipy/pull/5956>`__: DOC: Missing periods interfering with parsing
- `#5958 <https://github.com/scipy/scipy/pull/5958>`__: MAINT: add a test for lognorm.sf underflow
- `#5961 <https://github.com/scipy/scipy/pull/5961>`__: MAINT _centered(): rename size to shape
- `#5962 <https://github.com/scipy/scipy/pull/5962>`__: ENH: constants: Add multi-scale temperature conversion function
- `#5965 <https://github.com/scipy/scipy/pull/5965>`__: ENH: special: faster way for calculating comb() for exact=True
- `#5975 <https://github.com/scipy/scipy/pull/5975>`__: ENH: Improve FIR path of signal.decimate
- `#5977 <https://github.com/scipy/scipy/pull/5977>`__: MAINT/BUG: sparse: remove overzealous bmat checks
- `#5978 <https://github.com/scipy/scipy/pull/5978>`__: minimize_neldermead() stop at user requested maxiter or maxfev
- `#5983 <https://github.com/scipy/scipy/pull/5983>`__: ENH: make sparse `sum` cast dtypes like NumPy `sum` for 32-bit...
- `#5985 <https://github.com/scipy/scipy/pull/5985>`__: BUG, API: Add `jac` parameter to curve_fit
- `#5989 <https://github.com/scipy/scipy/pull/5989>`__: ENH: Add firls least-squares fitting
- `#5990 <https://github.com/scipy/scipy/pull/5990>`__: BUG: read tries to handle 20-bit WAV files but shouldn't
- `#5991 <https://github.com/scipy/scipy/pull/5991>`__: DOC: Cleanup wav read/write docs and add tables for common types
- `#5994 <https://github.com/scipy/scipy/pull/5994>`__: ENH: Add gesvd method for svd
- `#5996 <https://github.com/scipy/scipy/pull/5996>`__: MAINT: Wave cleanup
- `#5997 <https://github.com/scipy/scipy/pull/5997>`__: TST: Break up upfirdn tests & compare to lfilter
- `#6001 <https://github.com/scipy/scipy/pull/6001>`__: Filter design docs
- `#6002 <https://github.com/scipy/scipy/pull/6002>`__: COMPAT: Expand compatibility fromnumeric.py
- `#6007 <https://github.com/scipy/scipy/pull/6007>`__: ENH: Skip conversion of TF to TF in freqresp
- `#6009 <https://github.com/scipy/scipy/pull/6009>`__: DOC: fix incorrect versionadded for entr, rel_entr, kl_div
- `#6013 <https://github.com/scipy/scipy/pull/6013>`__: Fixed the entropy calculation of the von Mises distribution.
- `#6014 <https://github.com/scipy/scipy/pull/6014>`__: MAINT: make gamma, rgamma use loggamma for complex arguments
- `#6020 <https://github.com/scipy/scipy/pull/6020>`__: WIP: ENH: add exact=True factorial for vectors
- `#6022 <https://github.com/scipy/scipy/pull/6022>`__: Added 'lanczos' to the image interpolation function list.
- `#6024 <https://github.com/scipy/scipy/pull/6024>`__: BUG: optimize: do not use dummy constraints in SLSQP when no...
- `#6025 <https://github.com/scipy/scipy/pull/6025>`__: ENH: Boundary value problem solver for ODE systems
- `#6029 <https://github.com/scipy/scipy/pull/6029>`__: MAINT: Future imports for optimize._lsq
- `#6030 <https://github.com/scipy/scipy/pull/6030>`__: ENH: stats.trap - adding trapezoidal distribution closes #6028
- `#6031 <https://github.com/scipy/scipy/pull/6031>`__: MAINT: Some improvements to optimize._numdiff
- `#6032 <https://github.com/scipy/scipy/pull/6032>`__: MAINT: Add special/_comb.c to .gitignore
- `#6033 <https://github.com/scipy/scipy/pull/6033>`__: BUG: check the requested approximation rank in interpolative.svd
- `#6034 <https://github.com/scipy/scipy/pull/6034>`__: DOC: Doc for mannwhitneyu in stats.py corrected
- `#6040 <https://github.com/scipy/scipy/pull/6040>`__: FIX: Edit the wrong link in f_oneway
- `#6044 <https://github.com/scipy/scipy/pull/6044>`__: BUG: (ordqz) always increase parameter lwork by 1.
- `#6047 <https://github.com/scipy/scipy/pull/6047>`__: ENH: extend special.spence to complex arguments.
- `#6049 <https://github.com/scipy/scipy/pull/6049>`__: DOC: Add documentation of PR #5640 to the 0.18.0 release notes
- `#6050 <https://github.com/scipy/scipy/pull/6050>`__: MAINT: small cleanups related to loggamma
- `#6070 <https://github.com/scipy/scipy/pull/6070>`__: Add asarray to explicitly cast list to numpy array in wilcoxon...
- `#6071 <https://github.com/scipy/scipy/pull/6071>`__: DOC: antialiasing filter and link decimate resample, etc.
- `#6075 <https://github.com/scipy/scipy/pull/6075>`__: MAINT: reimplement special.digamma for complex arguments
- `#6080 <https://github.com/scipy/scipy/pull/6080>`__: avoid multiple computation in kstest
- `#6081 <https://github.com/scipy/scipy/pull/6081>`__: Clarified pearson correlation return value
- `#6085 <https://github.com/scipy/scipy/pull/6085>`__: ENH: allow long indices of sparse matrix with umfpack in spsolve()
- `#6086 <https://github.com/scipy/scipy/pull/6086>`__: fix description for associated Laguerre polynomials
- `#6087 <https://github.com/scipy/scipy/pull/6087>`__: Corrected docstring of splrep.
- `#6094 <https://github.com/scipy/scipy/pull/6094>`__: ENH: special: change zeta signature to zeta(x, q=1)
- `#6095 <https://github.com/scipy/scipy/pull/6095>`__: BUG: fix integer overflow in special.spence
- `#6106 <https://github.com/scipy/scipy/pull/6106>`__: Fixed Issue #6105
- `#6116 <https://github.com/scipy/scipy/pull/6116>`__: BUG: matrix logarithm edge case
- `#6119 <https://github.com/scipy/scipy/pull/6119>`__: TST: DeprecationWarnings in stats on python 3.5 closes #5885
- `#6120 <https://github.com/scipy/scipy/pull/6120>`__: MAINT: sparse: clean up sputils.isintlike
- `#6122 <https://github.com/scipy/scipy/pull/6122>`__: DOC: optimize: linprog docs should say minimize instead of maximize
- `#6123 <https://github.com/scipy/scipy/pull/6123>`__: DOC: optimize: document the `fun` field in `scipy.optimize.OptimizeResult`
- `#6124 <https://github.com/scipy/scipy/pull/6124>`__: Move FFT zero-padding calculation from signaltools to fftpack
- `#6125 <https://github.com/scipy/scipy/pull/6125>`__: MAINT: improve special.gammainc in the ``a ~ x`` regime.
- `#6130 <https://github.com/scipy/scipy/pull/6130>`__: BUG: sparse: Fix COO dot with zero columns
- `#6138 <https://github.com/scipy/scipy/pull/6138>`__: ENH: stats: Improve behavior of genextreme.sf and genextreme.isf
- `#6146 <https://github.com/scipy/scipy/pull/6146>`__: MAINT: simplify the expit implementation
- `#6151 <https://github.com/scipy/scipy/pull/6151>`__: MAINT: special: make generate_ufuncs.py output deterministic
- `#6152 <https://github.com/scipy/scipy/pull/6152>`__: TST: special: better test for gammainc at large arguments
- `#6153 <https://github.com/scipy/scipy/pull/6153>`__: ENH: Make next_fast_len public and faster
- `#6154 <https://github.com/scipy/scipy/pull/6154>`__: fix typo "mush"-->"must"
- `#6155 <https://github.com/scipy/scipy/pull/6155>`__: DOC: Fix some incorrect RST definition lists
- `#6160 <https://github.com/scipy/scipy/pull/6160>`__: make logsumexp error out on a masked array
- `#6161 <https://github.com/scipy/scipy/pull/6161>`__: added missing bracket to rosen documentation
- `#6163 <https://github.com/scipy/scipy/pull/6163>`__: ENH: Added "kappa4" and "kappa3" distributions.
- `#6164 <https://github.com/scipy/scipy/pull/6164>`__: DOC: Minor clean-up in integrate._bvp
- `#6169 <https://github.com/scipy/scipy/pull/6169>`__: Fix mpf_assert_allclose to handle iterable results, such as maps
- `#6170 <https://github.com/scipy/scipy/pull/6170>`__: Fix pchip_interpolate convenience function
- `#6172 <https://github.com/scipy/scipy/pull/6172>`__: Corrected misplaced bracket in doc string
- `#6175 <https://github.com/scipy/scipy/pull/6175>`__: ENH: sparse.csgraph: Pass indices to shortest_path
- `#6178 <https://github.com/scipy/scipy/pull/6178>`__: TST: increase test coverage of sf and isf of a generalized extreme...
- `#6179 <https://github.com/scipy/scipy/pull/6179>`__: TST: avoid a deprecation warning from numpy
- `#6181 <https://github.com/scipy/scipy/pull/6181>`__: ENH: Boundary conditions for CubicSpline
- `#6182 <https://github.com/scipy/scipy/pull/6182>`__: DOC: Add examples/graphs to max_len_seq
- `#6183 <https://github.com/scipy/scipy/pull/6183>`__: BLD: update Bento build config files for recent changes.
- `#6184 <https://github.com/scipy/scipy/pull/6184>`__: BUG: fix issue in io/wavfile for float96 input.
- `#6186 <https://github.com/scipy/scipy/pull/6186>`__: ENH: Periodic extrapolation for PPoly and BPoly
- `#6192 <https://github.com/scipy/scipy/pull/6192>`__: MRG: Add circle-CI
- `#6193 <https://github.com/scipy/scipy/pull/6193>`__: ENH: sparse: avoid setitem densification
- `#6196 <https://github.com/scipy/scipy/pull/6196>`__: Fixed missing sqrt in docstring of Mahalanobis distance in cdist,...
- `#6206 <https://github.com/scipy/scipy/pull/6206>`__: MAINT: Minor changes in solve_bvp
- `#6207 <https://github.com/scipy/scipy/pull/6207>`__: BUG: linalg: for BLAS, downcast complex256 to complex128, not...
- `#6209 <https://github.com/scipy/scipy/pull/6209>`__: BUG: io.matlab: avoid buffer overflows in read_element_into
- `#6210 <https://github.com/scipy/scipy/pull/6210>`__: BLD: use setuptools when building.
- `#6214 <https://github.com/scipy/scipy/pull/6214>`__: BUG: sparse.linalg: fix bug in LGMRES breakdown handling
- `#6215 <https://github.com/scipy/scipy/pull/6215>`__: MAINT: special: make loggamma use zdiv
- `#6220 <https://github.com/scipy/scipy/pull/6220>`__: DOC: Add parameter
- `#6221 <https://github.com/scipy/scipy/pull/6221>`__: ENH: Improve Newton solver for solve_bvp
- `#6223 <https://github.com/scipy/scipy/pull/6223>`__: pchip should work for length-2 arrays
- `#6224 <https://github.com/scipy/scipy/pull/6224>`__: signal.lti: deprecate cross-class properties/setters
- `#6229 <https://github.com/scipy/scipy/pull/6229>`__: BUG: optimize: avoid an infinite loop in Newton-CG
- `#6230 <https://github.com/scipy/scipy/pull/6230>`__: Add example for application of gaussian filter
- `#6236 <https://github.com/scipy/scipy/pull/6236>`__: MAINT: gumbel_l accuracy
- `#6237 <https://github.com/scipy/scipy/pull/6237>`__: MAINT: rayleigh accuracy
- `#6238 <https://github.com/scipy/scipy/pull/6238>`__: MAINT: logistic accuracy
- `#6239 <https://github.com/scipy/scipy/pull/6239>`__: MAINT: bradford distribution accuracy
- `#6240 <https://github.com/scipy/scipy/pull/6240>`__: MAINT: avoid bad fmin in l-bfgs-b due to maxfun interruption
- `#6241 <https://github.com/scipy/scipy/pull/6241>`__: MAINT: weibull_min accuracy
- `#6246 <https://github.com/scipy/scipy/pull/6246>`__: ENH: Add _support_mask to distributions
- `#6247 <https://github.com/scipy/scipy/pull/6247>`__: fixed a print error for an example of ode
- `#6249 <https://github.com/scipy/scipy/pull/6249>`__: MAINT: change x-axis label for stats.probplot to "theoretical...
- `#6250 <https://github.com/scipy/scipy/pull/6250>`__: DOC: fix typos
- `#6251 <https://github.com/scipy/scipy/pull/6251>`__: MAINT: constants: filter out test noise from deprecated conversions
- `#6252 <https://github.com/scipy/scipy/pull/6252>`__: MAINT: io/arff: remove unused variable
- `#6253 <https://github.com/scipy/scipy/pull/6253>`__: Add examples to scipy.ndimage.filters
- `#6254 <https://github.com/scipy/scipy/pull/6254>`__: MAINT: special: fix some build warnings
- `#6258 <https://github.com/scipy/scipy/pull/6258>`__: MAINT: inverse gamma distribution accuracy
- `#6260 <https://github.com/scipy/scipy/pull/6260>`__: MAINT: signal.decimate - Use discrete-time objects
- `#6262 <https://github.com/scipy/scipy/pull/6262>`__: BUG: odr: fix string formatting
- `#6267 <https://github.com/scipy/scipy/pull/6267>`__: TST: fix some test issues in interpolate and stats.
- `#6269 <https://github.com/scipy/scipy/pull/6269>`__: TST: fix some warnings in the test suite
- `#6274 <https://github.com/scipy/scipy/pull/6274>`__: ENH: Add sosfiltfilt
- `#6276 <https://github.com/scipy/scipy/pull/6276>`__: DOC: update release notes for 0.18.0
- `#6277 <https://github.com/scipy/scipy/pull/6277>`__: MAINT: update the author name mapping
- `#6282 <https://github.com/scipy/scipy/pull/6282>`__: DOC: Correcting references for scipy.stats.normaltest
- `#6283 <https://github.com/scipy/scipy/pull/6283>`__: DOC: some more additions to 0.18.0 release notes.
- `#6284 <https://github.com/scipy/scipy/pull/6284>`__: Add `.. versionadded::` directive to `loggamma`.
- `#6285 <https://github.com/scipy/scipy/pull/6285>`__: BUG: stats: Inconsistency in the multivariate_normal docstring...
- `#6290 <https://github.com/scipy/scipy/pull/6290>`__: Add author list, gh-lists to 0.18.0 release notes
- `#6293 <https://github.com/scipy/scipy/pull/6293>`__: TST: special: relax a test's precision
- `#6295 <https://github.com/scipy/scipy/pull/6295>`__: BUG: sparse: stop comparing None and int in bsr_matrix constructor
- `#6313 <https://github.com/scipy/scipy/pull/6313>`__: MAINT: Fix for python 3.5 travis-ci build problem.
- `#6327 <https://github.com/scipy/scipy/pull/6327>`__: TST: signal: use assert_allclose for testing near-equality in...
- `#6330 <https://github.com/scipy/scipy/pull/6330>`__: BUG: spatial/qhull: allocate qhT via malloc to ensure CRT likes...
- `#6332 <https://github.com/scipy/scipy/pull/6332>`__: TST: fix stats.iqr test to not emit warnings, and fix line lengths.
- `#6334 <https://github.com/scipy/scipy/pull/6334>`__: MAINT: special: fix a test for hyp0f1
- `#6347 <https://github.com/scipy/scipy/pull/6347>`__: TST: spatial.qhull: skip a test on 32-bit platforms
- `#6350 <https://github.com/scipy/scipy/pull/6350>`__: BUG: optimize/slsqp: don't overwrite an array out of bounds
- `#6351 <https://github.com/scipy/scipy/pull/6351>`__: BUG: #6318 Interp1d 'nearest' integer x-axis overflow issue fixed
- `#6355 <https://github.com/scipy/scipy/pull/6355>`__: Backports for 0.18.0

==========================
SciPy 0.11.0 Release Notes
==========================

.. contents::

SciPy 0.11.0 is the culmination of 8 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  Highlights of this release are:

  - A new module has been added which provides a number of common sparse graph
    algorithms.
  - New unified interfaces to the existing optimization and root finding
    functions have been added.

All users are encouraged to upgrade to this release, as there are a large
number of bug-fixes and optimizations.  Our development attention will now
shift to bug-fix releases on the 0.11.x branch, and on adding new features on
the master branch.

This release requires Python 2.4-2.7 or 3.1-3.2 and NumPy 1.5.1 or greater.


New features
============

.. currentmodule:: scipy.sparse.csgraph

Sparse Graph Submodule
----------------------
The new submodule :mod:`scipy.sparse.csgraph` implements a number of efficient
graph algorithms for graphs stored as sparse adjacency matrices.  Available
routines are:

   - :func:`connected_components` - determine connected components of a graph
   - :func:`laplacian` - compute the laplacian of a graph
   - :func:`shortest_path` - compute the shortest path between points on a
     positive graph
   - :func:`dijkstra` - use Dijkstra's algorithm for shortest path
   - :func:`floyd_warshall` - use the Floyd-Warshall algorithm for
     shortest path
   - :func:`breadth_first_order` - compute a breadth-first order of nodes
   - :func:`depth_first_order` - compute a depth-first order of nodes
   - :func:`breadth_first_tree` - construct the breadth-first tree from
     a given node
   - :func:`depth_first_tree` - construct a depth-first tree from a given node
   - :func:`minimum_spanning_tree` - construct the minimum spanning
     tree of a graph


``scipy.optimize`` improvements
-------------------------------

The optimize module has received a lot of attention this release.  In addition
to added tests, documentation improvements, bug fixes and code clean-up, the
following improvements were made:

- A unified interface to minimizers of univariate and multivariate
  functions has been added.
- A unified interface to root finding algorithms for multivariate functions
  has been added.
- The L-BFGS-B algorithm has been updated to version 3.0.


Unified interfaces to minimizers
````````````````````````````````

.. currentmodule:: scipy.optimize

Two new functions ``scipy.optimize.minimize`` and
``scipy.optimize.minimize_scalar`` were added to provide a common interface
to minimizers of multivariate and univariate functions respectively.
For multivariate functions, ``scipy.optimize.minimize`` provides an
interface to methods for unconstrained optimization (`fmin`, `fmin_powell`,
`fmin_cg`, `fmin_ncg`, `fmin_bfgs` and `anneal`) or constrained
optimization (`fmin_l_bfgs_b`, `fmin_tnc`, `fmin_cobyla` and `fmin_slsqp`).
For univariate functions, ``scipy.optimize.minimize_scalar`` provides an
interface to methods for unconstrained and bounded optimization (`brent`,
`golden`, `fminbound`).
This allows for easier comparing and switching between solvers.

Unified interface to root finding algorithms
````````````````````````````````````````````

The new function ``scipy.optimize.root`` provides a common interface to
root finding algorithms for multivariate functions, embedding `fsolve`,
`leastsq` and ``nonlin`` solvers.


``scipy.linalg`` improvements
-----------------------------

New matrix equation solvers
```````````````````````````

Solvers for the Sylvester equation (``scipy.linalg.solve_sylvester``, discrete
and continuous Lyapunov equations (``scipy.linalg.solve_lyapunov``,
``scipy.linalg.solve_discrete_lyapunov``) and discrete and continuous algebraic
Riccati equations (``scipy.linalg.solve_continuous_are``,
``scipy.linalg.solve_discrete_are``) have been added to ``scipy.linalg``.
These solvers are often used in the field of linear control theory.

QZ and QR Decomposition
````````````````````````

It is now possible to calculate the QZ, or Generalized Schur, decomposition
using ``scipy.linalg.qz``. This function wraps the LAPACK routines sgges,
dgges, cgges, and zgges.

The function ``scipy.linalg.qr_multiply``, which allows efficient computation
of the matrix product of Q (from a QR decomposition) and a vector, has been
added.

Pascal matrices
```````````````

A function for creating Pascal matrices, ``scipy.linalg.pascal``, was added.


Sparse matrix construction and operations
-----------------------------------------

Two new functions, ``scipy.sparse.diags`` and ``scipy.sparse.block_diag``, were
added to easily construct diagonal and block-diagonal sparse matrices
respectively.

``scipy.sparse.csc_matrix`` and ``csr_matrix`` now support the operations
``sin``, ``tan``, ``arcsin``, ``arctan``, ``sinh``, ``tanh``, ``arcsinh``,
``arctanh``, ``rint``, ``sign``, ``expm1``, ``log1p``, ``deg2rad``, ``rad2deg``,
``floor``, ``ceil`` and ``trunc``.  Previously, these operations had to be
performed by operating on the matrices' ``data`` attribute.


LSMR iterative solver
---------------------

LSMR, an iterative method for solving (sparse) linear and linear
least-squares systems, was added as ``scipy.sparse.linalg.lsmr``.


Discrete Sine Transform
-----------------------

Bindings for the discrete sine transform functions have been added to
``scipy.fftpack``.


``scipy.interpolate`` improvements
----------------------------------

For interpolation in spherical coordinates, the three classes
``scipy.interpolate.SmoothSphereBivariateSpline``,
``scipy.interpolate.LSQSphereBivariateSpline``, and
``scipy.interpolate.RectSphereBivariateSpline`` have been added.


Binned statistics (``scipy.stats``)
-----------------------------------

The stats module has gained functions to do binned statistics, which are a
generalization of histograms, in 1-D, 2-D and multiple dimensions:
``scipy.stats.binned_statistic``, ``scipy.stats.binned_statistic_2d`` and
``scipy.stats.binned_statistic_dd``.


Deprecated features
===================

``scipy.sparse.cs_graph_components`` has been made a part of the sparse graph
submodule, and renamed to ``scipy.sparse.csgraph.connected_components``.
Calling the former routine will result in a deprecation warning.

``scipy.misc.radon`` has been deprecated.  A more full-featured radon transform
can be found in scikits-image.

``scipy.io.save_as_module`` has been deprecated.  A better way to save multiple
Numpy arrays is the ``numpy.savez`` function.

The `xa` and `xb` parameters for all distributions in
``scipy.stats.distributions`` already weren't used; they have now been
deprecated.


Backwards incompatible changes
==============================

Removal of ``scipy.maxentropy``
-------------------------------

The ``scipy.maxentropy`` module, which was deprecated in the 0.10.0 release,
has been removed.  Logistic regression in scikits.learn is a good and modern
alternative for this functionality.


Minor change in behavior of ``splev``
-------------------------------------

The spline evaluation function now behaves similarly to ``interp1d``
for size-1 arrays.  Previous behavior::

    >>> from scipy.interpolate import splev, splrep, interp1d
    >>> x = [1,2,3,4,5]
    >>> y = [4,5,6,7,8]
    >>> tck = splrep(x, y)
    >>> splev([1], tck)
    4.
    >>> splev(1, tck)
    4.

Corrected behavior::

    >>> splev([1], tck)
    array([ 4.])
    >>> splev(1, tck)
    array(4.)

This affects also the ``UnivariateSpline`` classes.


Behavior of ``scipy.integrate.complex_ode``
-------------------------------------------

The behavior of the ``y`` attribute of ``complex_ode`` is changed.
Previously, it expressed the complex-valued solution in the form::

    z = ode.y[::2] + 1j * ode.y[1::2]

Now, it is directly the complex-valued solution::

    z = ode.y


Minor change in behavior of T-tests
-----------------------------------

The T-tests ``scipy.stats.ttest_ind``, ``scipy.stats.ttest_rel`` and
``scipy.stats.ttest_1samp`` have been changed so that 0 / 0 now returns NaN
instead of 1.


Other changes
=============

The SuperLU sources in ``scipy.sparse.linalg`` have been updated to version 4.3
from upstream.

The function ``scipy.signal.bode``, which calculates magnitude and phase data
for a continuous-time system, has been added.

The two-sample T-test ``scipy.stats.ttest_ind`` gained an option to compare
samples with unequal variances, i.e. Welch's T-test.

``scipy.misc.logsumexp`` now takes an optional ``axis`` keyword argument.


Authors
=======

This release contains work by the following people (contributed at least
one patch to this release, names in alphabetical order):

* Jeff Armstrong
* Chad Baker
* Brandon Beacher +
* behrisch +
* borishim +
* Matthew Brett
* Lars Buitinck
* Luis Pedro Coelho +
* Johann Cohen-Tanugi
* David Cournapeau
* dougal +
* Ali Ebrahim +
* endolith +
* Bjørn Forsman +
* Robert Gantner +
* Sebastian Gassner +
* Christoph Gohlke
* Ralf Gommers
* Yaroslav Halchenko
* Charles Harris
* Jonathan Helmus +
* Andreas Hilboll +
* Marc Honnorat +
* Jonathan Hunt +
* Maxim Ivanov +
* Thouis (Ray) Jones
* Christopher Kuster +
* Josh Lawrence +
* Denis Laxalde +
* Travis Oliphant
* Joonas Paalasmaa +
* Fabian Pedregosa
* Josef Perktold
* Gavin Price +
* Jim Radford +
* Andrew Schein +
* Skipper Seabold
* Jacob Silterra +
* Scott Sinclair
* Alexis Tabary +
* Martin Teichmann
* Matt Terry +
* Nicky van Foreest +
* Jacob Vanderplas
* Patrick Varilly +
* Pauli Virtanen
* Nils Wagner +
* Darryl Wally +
* Stefan van der Walt
* Liming Wang +
* David Warde-Farley +
* Warren Weckesser
* Sebastian Werk +
* Mike Wimmer +
* Tony S Yu +

A total of 55 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.

=========================
SciPy 0.9.0 Release Notes
=========================

.. contents::

SciPy 0.9.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.9.x branch, and on adding
new features on the development trunk.

This release requires Python 2.4 - 2.7 or 3.1 - and NumPy 1.5 or greater.

Please note that SciPy is still considered to have "Beta" status, as
we work toward a SciPy 1.0.0 release.  The 1.0.0 release will mark a
major milestone in the development of SciPy, after which changing the
package structure or API will be much more difficult.  Whilst these
pre-1.0 releases are considered to have "Beta" status, we are
committed to making them as bug-free as possible.

However, until the 1.0 release, we are aggressively reviewing and
refining the functionality, organization, and interface. This is being
done in an effort to make the package as coherent, intuitive, and
useful as possible.  To achieve this, we need help from the community
of users.  Specifically, we need feedback regarding all aspects of the
project - everything - from which algorithms we implement, to details
about our function's call signatures.


Python 3
========

Scipy 0.9.0 is the first SciPy release to support Python 3. The only module
that is not yet ported is ``scipy.weave``.


Scipy source code location to be changed
========================================

Soon after this release, Scipy will stop using SVN as the version control
system, and move to Git. The development source code for Scipy can from then on
be found at

    https://github.com/scipy/scipy


New features
============

Delaunay tessellations (``scipy.spatial``)
------------------------------------------

Scipy now includes routines for computing Delaunay tessellations in N
dimensions, powered by the Qhull_ computational geometry library. Such
calculations can now make use of the new ``scipy.spatial.Delaunay``
interface.

.. _Qhull: http://www.qhull.org/

N-dimensional interpolation (``scipy.interpolate``)
---------------------------------------------------

Support for scattered data interpolation is now significantly
improved.  This version includes a ``scipy.interpolate.griddata``
function that can perform linear and nearest-neighbour interpolation
for N-dimensional scattered data, in addition to cubic spline
(C1-smooth) interpolation in 2D and 1D.  An object-oriented interface
to each interpolator type is also available.

Nonlinear equation solvers (``scipy.optimize``)
-----------------------------------------------

Scipy includes new routines for large-scale nonlinear equation solving
in ``scipy.optimize``.  The following methods are implemented:

* Newton-Krylov (``scipy.optimize.newton_krylov``)

* (Generalized) secant methods:

  - Limited-memory Broyden methods (``scipy.optimize.broyden1``,
    ``scipy.optimize.broyden2``)

  - Anderson method (``scipy.optimize.anderson``)

* Simple iterations (``scipy.optimize.diagbroyden``,
  ``scipy.optimize.excitingmixing``, ``scipy.optimize.linearmixing``)

The ``scipy.optimize.nonlin`` module was completely rewritten, and
some of the functions were deprecated (see above).


New linear algebra routines (``scipy.linalg``)
----------------------------------------------

Scipy now contains routines for effectively solving triangular
equation systems (``scipy.linalg.solve_triangular``).


Improved FIR filter design functions (``scipy.signal``)
-------------------------------------------------------

The function ``scipy.signal.firwin`` was enhanced to allow the
design of highpass, bandpass, bandstop and multi-band FIR filters.

The function ``scipy.signal.firwin2`` was added.  This function
uses the window method to create a linear phase FIR filter with
an arbitrary frequency response.

The functions ``scipy.signal.kaiser_atten`` and ``scipy.signal.kaiser_beta``
were added.


Improved statistical tests (``scipy.stats``)
--------------------------------------------

A new function ``scipy.stats.fisher_exact`` was added, that provides Fisher's
exact test for 2x2 contingency tables.

The function ``scipy.stats.kendalltau`` was rewritten to make it much faster
(O(n log(n)) vs O(n^2)).


Deprecated features
===================

Obsolete nonlinear solvers (in ``scipy.optimize``)
--------------------------------------------------

The following nonlinear solvers from ``scipy.optimize`` are
deprecated:

- ``broyden_modified`` (bad performance)
- ``broyden1_modified`` (bad performance)
- ``broyden_generalized`` (equivalent to ``anderson``)
- ``anderson2`` (equivalent to ``anderson``)
- ``broyden3`` (obsoleted by new limited-memory broyden methods)
- ``vackar`` (renamed to ``diagbroyden``)


Removed features
================

The deprecated modules ``helpmod``, ``pexec`` and ``ppimport`` were removed
from ``scipy.misc``.

The ``output_type`` keyword in many ``scipy.ndimage`` interpolation functions
has been removed.

The ``econ`` keyword in ``scipy.linalg.qr`` has been removed. The same
functionality is still available by specifying ``mode='economic'``.


Old correlate/convolve behavior (in ``scipy.signal``)
-----------------------------------------------------

The old behavior for ``scipy.signal.convolve``, ``scipy.signal.convolve2d``,
``scipy.signal.correlate`` and ``scipy.signal.correlate2d`` was deprecated in
0.8.0 and has now been removed.  Convolve and correlate used to swap their
arguments if the second argument has dimensions larger than the first one, and
the mode was relative to the input with the largest dimension. The current
behavior is to never swap the inputs, which is what most people expect, and is
how correlation is usually defined.


``scipy.stats``
---------------

Many functions in ``scipy.stats`` that are either available from numpy or have
been superseded, and have been deprecated since version 0.7, have been removed:
`std`, `var`, `mean`, `median`, `cov`, `corrcoef`, `z`, `zs`, `stderr`,
`samplestd`, `samplevar`, `pdfapprox`, `pdf_moments` and `erfc`.  These changes
are mirrored in ``scipy.stats.mstats``.


``scipy.sparse``
----------------

Several methods of the sparse matrix classes in ``scipy.sparse`` which had
been deprecated since version 0.7 were removed: `save`, `rowcol`, `getdata`,
`listprint`, `ensure_sorted_indices`, `matvec`, `matmat` and `rmatvec`.

The functions ``spkron``, ``speye``, ``spidentity``, ``lil_eye`` and
``lil_diags`` were removed from ``scipy.sparse``.  The first three functions
are still available as ``scipy.sparse.kron``, ``scipy.sparse.eye`` and
``scipy.sparse.identity``.

The `dims` and `nzmax` keywords were removed from the sparse matrix
constructor. The `colind` and `rowind` attributes were removed from CSR and CSC
matrices respectively.

``scipy.sparse.linalg.arpack.speigs``
-------------------------------------

A duplicated interface to the ARPACK library was removed.


Other changes
=============

ARPACK interface changes
------------------------

The interface to the ARPACK eigenvalue routines in
``scipy.sparse.linalg`` was changed for more robustness.

The eigenvalue and SVD routines now raise ``ArpackNoConvergence`` if
the eigenvalue iteration fails to converge. If partially converged results
are desired, they can be accessed as follows::

    import numpy as np
    from scipy.sparse.linalg import eigs, ArpackNoConvergence

    m = np.random.randn(30, 30)
    try:
        w, v = eigs(m, 6)
    except ArpackNoConvergence, err:
        partially_converged_w = err.eigenvalues
        partially_converged_v = err.eigenvectors

Several bugs were also fixed.

The routines were moreover renamed as follows:

    - eigen --> eigs
    - eigen_symmetric --> eigsh
    - svd --> svds
=========================
SciPy 0.7.0 Release Notes
=========================

.. contents::

SciPy 0.7.0 is the culmination of 16 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and
better documentation.  There have been a number of deprecations and
API changes in this release, which are documented below.  All users
are encouraged to upgrade to this release, as there are a large number
of bug-fixes and optimizations.  Moreover, our development attention
will now shift to bug-fix releases on the 0.7.x branch, and on adding
new features on the development trunk.  This release requires Python
2.4 or 2.5 and NumPy 1.2 or greater.

Please note that SciPy is still considered to have "Beta" status, as
we work toward a SciPy 1.0.0 release.  The 1.0.0 release will mark a
major milestone in the development of SciPy, after which changing the
package structure or API will be much more difficult.  Whilst these
pre-1.0 releases are considered to have "Beta" status, we are
committed to making them as bug-free as possible.  For example, in
addition to fixing numerous bugs in this release, we have also doubled
the number of unit tests since the last release.

However, until the 1.0 release, we are aggressively reviewing and
refining the functionality, organization, and interface. This is being
done in an effort to make the package as coherent, intuitive, and
useful as possible.  To achieve this, we need help from the community
of users.  Specifically, we need feedback regarding all aspects of the
project - everything - from which algorithms we implement, to details
about our function's call signatures.

Over the last year, we have seen a rapid increase in community
involvement, and numerous infrastructure improvements to lower the
barrier to contributions (e.g., more explicit coding standards,
improved testing infrastructure, better documentation tools).  Over
the next year, we hope to see this trend continue and invite everyone
to become more involved.

Python 2.6 and 3.0
==================

A significant amount of work has gone into making SciPy compatible
with Python 2.6; however, there are still some issues in this regard.
The main issue with 2.6 support is NumPy.  On UNIX (including Mac OS
X), NumPy 1.2.1 mostly works, with a few caveats.  On Windows, there
are problems related to the compilation process.  The upcoming NumPy
1.3 release will fix these problems.  Any remaining issues with 2.6
support for SciPy 0.7 will be addressed in a bug-fix release.

Python 3.0 is not supported at all; it requires NumPy to be ported to
Python 3.0.  This requires immense effort, since a lot of C code has
to be ported.  The transition to 3.0 is still under consideration;
currently, we don't have any timeline or roadmap for this transition.

Major documentation improvements
================================

SciPy documentation is greatly improved; you can view a HTML reference
manual `online <https://docs.scipy.org/>`__ or download it as a PDF
file. The new reference guide was built using the popular `Sphinx tool
<http://www.sphinx-doc.org>`__.

This release also includes an updated tutorial, which hadn't been
available since SciPy was ported to NumPy in 2005.  Though not
comprehensive, the tutorial shows how to use several essential parts
of Scipy.  It also includes the ``ndimage`` documentation from the
``numarray`` manual.

Nevertheless, more effort is needed on the documentation front.
Luckily, contributing to Scipy documentation is now easier than
before: if you find that a part of it requires improvements, and want
to help us out, please register a user name in our web-based
documentation editor at https://docs.scipy.org/ and correct the issues.

Running Tests
=============

NumPy 1.2 introduced a new testing framework based on `nose
<http://somethingaboutorange.com/mrl/projects/nose/>`__.  Starting with
this release, SciPy now uses the new NumPy test framework as well.
Taking advantage of the new testing framework requires ``nose``
version 0.10, or later.  One major advantage of the new framework is
that it greatly simplifies writing unit tests - which has all ready
paid off, given the rapid increase in tests.  To run the full test
suite::

    >>> import scipy
    >>> scipy.test('full')

For more information, please see `The NumPy/SciPy Testing Guide
<https://github.com/numpy/numpy/blob/main/doc/TESTS.rst.txt>`__.

We have also greatly improved our test coverage.  There were just over
2,000 unit tests in the 0.6.0 release; this release nearly doubles
that number, with just over 4,000 unit tests.

Building SciPy
==============

Support for NumScons has been added. NumScons is a tentative new build
system for NumPy/SciPy, using `SCons <https://www.scons.org/>`__ at its
core.

SCons is a next-generation build system, intended to replace the
venerable ``Make`` with the integrated functionality of
``autoconf``/``automake`` and ``ccache``.  Scons is written in Python
and its configuration files are Python scripts.  NumScons is meant to
replace NumPy's custom version of ``distutils`` providing more
advanced functionality, such as ``autoconf``, improved fortran
support, more tools, and support for ``numpy.distutils``/``scons``
cooperation.

Sandbox Removed
===============

While porting SciPy to NumPy in 2005, several packages and modules
were moved into ``scipy.sandbox``.  The sandbox was a staging ground
for packages that were undergoing rapid development and whose APIs
were in flux.  It was also a place where broken code could live.  The
sandbox has served its purpose well, but was starting to create
confusion.  Thus ``scipy.sandbox`` was removed.  Most of the code was
moved into ``scipy``, some code was made into a ``scikit``, and the
remaining code was just deleted, as the functionality had been
replaced by other code.

Sparse Matrices
===============

Sparse matrices have seen extensive improvements.  There is now
support for integer dtypes such ``int8``, ``uint32``, etc.  Two new
sparse formats were added:

* new class ``dia_matrix`` : the sparse DIAgonal format
* new class ``bsr_matrix`` : the Block CSR format

Several new sparse matrix construction functions were added:

* ``sparse.kron`` : sparse Kronecker product
* ``sparse.bmat`` : sparse version of ``numpy.bmat``
* ``sparse.vstack`` : sparse version of ``numpy.vstack``
* ``sparse.hstack`` : sparse version of ``numpy.hstack``

Extraction of submatrices and nonzero values have been added:

* ``sparse.tril`` : extract lower triangle
* ``sparse.triu`` : extract upper triangle
* ``sparse.find`` : nonzero values and their indices

``csr_matrix`` and ``csc_matrix`` now support slicing and fancy
indexing (e.g., ``A[1:3, 4:7]`` and ``A[[3,2,6,8],:]``).  Conversions
among all sparse formats are now possible:

* using member functions such as ``.tocsr()`` and ``.tolil()``
* using the ``.asformat()`` member function, e.g. ``A.asformat('csr')``
* using constructors ``A = lil_matrix([[1,2]]); B = csr_matrix(A)``

All sparse constructors now accept dense matrices and lists of lists.
For example:

* ``A = csr_matrix( rand(3,3) )`` and ``B = lil_matrix( [[1,2],[3,4]] )``

The handling of diagonals in the ``spdiags`` function has been changed.
It now agrees with the MATLAB(TM) function of the same name.
  
Numerous efficiency improvements to format conversions and sparse
matrix arithmetic have been made.  Finally, this release contains
numerous bugfixes.

Statistics package
==================

Statistical functions for masked arrays have been added, and are
accessible through ``scipy.stats.mstats``. The functions are similar
to their counterparts in ``scipy.stats`` but they have not yet been
verified for identical interfaces and algorithms.

Several bugs were fixed for statistical functions, of those,
``kstest`` and ``percentileofscore`` gained new keyword arguments.

Added deprecation warning for ``mean``, ``median``, ``var``, ``std``,
``cov``, and ``corrcoef``. These functions should be replaced by their
numpy counterparts.  Note, however, that some of the default options
differ between the ``scipy.stats`` and numpy versions of these
functions.

Numerous bug fixes to ``stats.distributions``: all generic methods now
work correctly, several methods in individual distributions were
corrected. However, a few issues remain with higher moments (``skew``,
``kurtosis``) and entropy.  The maximum likelihood estimator, ``fit``,
does not work out-of-the-box for some distributions - in some cases,
starting values have to be carefully chosen, in other cases, the
generic implementation of the maximum likelihood method might not be
the numerically appropriate estimation method.

We expect more bugfixes, increases in numerical precision and
enhancements in the next release of scipy.

Reworking of IO package
=======================

The IO code in both NumPy and SciPy is being extensively
reworked. NumPy will be where basic code for reading and writing NumPy
arrays is located, while SciPy will house file readers and writers for
various data formats (data, audio, video, images, matlab, etc.).

Several functions in ``scipy.io`` have been deprecated and will be
removed in the 0.8.0 release including ``npfile``, ``save``, ``load``,
``create_module``, ``create_shelf``, ``objload``, ``objsave``,
``fopen``, ``read_array``, ``write_array``, ``fread``, ``fwrite``,
``bswap``, ``packbits``, ``unpackbits``, and ``convert_objectarray``.
Some of these functions have been replaced by NumPy's raw reading and
writing capabilities, memory-mapping capabilities, or array methods.
Others have been moved from SciPy to NumPy, since basic array reading
and writing capability is now handled by NumPy.

The Matlab (TM) file readers/writers have a number of improvements:

* default version 5
* v5 writers for structures, cell arrays, and objects
* v5 readers/writers for function handles and 64-bit integers
* new struct_as_record keyword argument to ``loadmat``, which loads
  struct arrays in matlab as record arrays in numpy
* string arrays have ``dtype='U...'`` instead of ``dtype=object``
* ``loadmat`` no longer squeezes singleton dimensions, i.e.
  ``squeeze_me=False`` by default

New Hierarchical Clustering module
==================================

This module adds new hierarchical clustering functionality to the
``scipy.cluster`` package. The function interfaces are similar to the
functions provided MATLAB(TM)'s Statistics Toolbox to help facilitate
easier migration to the NumPy/SciPy framework. Linkage methods
implemented include single, complete, average, weighted, centroid,
median, and ward.

In addition, several functions are provided for computing
inconsistency statistics, cophenetic distance, and maximum distance
between descendants. The ``fcluster`` and ``fclusterdata`` functions
transform a hierarchical clustering into a set of flat clusters. Since
these flat clusters are generated by cutting the tree into a forest of
trees, the ``leaders`` function takes a linkage and a flat clustering,
and finds the root of each tree in the forest. The ``ClusterNode``
class represents a hierarchical clusterings as a field-navigable tree
object. ``to_tree`` converts a matrix-encoded hierarchical clustering
to a ``ClusterNode`` object. Routines for converting between MATLAB
and SciPy linkage encodings are provided. Finally, a ``dendrogram``
function plots hierarchical clusterings as a dendrogram, using
matplotlib.

New Spatial package
===================

The new spatial package contains a collection of spatial algorithms
and data structures, useful for spatial statistics and clustering
applications. It includes rapidly compiled code for computing exact
and approximate nearest neighbors, as well as a pure-python kd-tree
with the same interface, but that supports annotation and a variety of
other algorithms. The API for both modules may change somewhat, as
user requirements become clearer.

It also includes a ``distance`` module, containing a collection of
distance and dissimilarity functions for computing distances between
vectors, which is useful for spatial statistics, clustering, and
kd-trees.  Distance and dissimilarity functions provided include
Bray-Curtis, Canberra, Chebyshev, City Block, Cosine, Dice, Euclidean,
Hamming, Jaccard, Kulsinski, Mahalanobis, Matching, Minkowski,
Rogers-Tanimoto, Russell-Rao, Squared Euclidean, Standardized
Euclidean, Sokal-Michener, Sokal-Sneath, and Yule.

The ``pdist`` function computes pairwise distance between all
unordered pairs of vectors in a set of vectors. The ``cdist`` computes
the distance on all pairs of vectors in the Cartesian product of two
sets of vectors.  Pairwise distance matrices are stored in condensed
form; only the upper triangular is stored. ``squareform`` converts
distance matrices between square and condensed forms.

Reworked fftpack package
========================

FFTW2, FFTW3, MKL and DJBFFT wrappers have been removed. Only (NETLIB)
fftpack remains. By focusing on one backend, we hope to add new
features - like float32 support - more easily.

New Constants package
=====================

``scipy.constants`` provides a collection of physical constants and
conversion factors.  These constants are taken from CODATA Recommended
Values of the Fundamental Physical Constants: 2002. They may be found
at physics.nist.gov/constants. The values are stored in the dictionary
physical_constants as a tuple containing the value, the units, and the
relative precision - in that order. All constants are in SI units,
unless otherwise stated.  Several helper functions are provided.

New Radial Basis Function module
================================

``scipy.interpolate`` now contains a Radial Basis Function module.
Radial basis functions can be used for smoothing/interpolating
scattered data in n-dimensions, but should be used with caution for
extrapolation outside of the observed data range.

New complex ODE integrator
==========================

``scipy.integrate.ode`` now contains a wrapper for the ZVODE
complex-valued ordinary differential equation solver (by Peter
N. Brown, Alan C. Hindmarsh, and George D. Byrne).

New generalized symmetric and hermitian eigenvalue problem solver
=================================================================

``scipy.linalg.eigh`` now contains wrappers for more LAPACK symmetric
and hermitian eigenvalue problem solvers. Users can now solve
generalized problems, select a range of eigenvalues only, and choose
to use a faster algorithm at the expense of increased memory
usage. The signature of the ``scipy.linalg.eigh`` changed accordingly.

Bug fixes in the interpolation package
======================================

The shape of return values from ``scipy.interpolate.interp1d`` used to
be incorrect, if interpolated data had more than 2 dimensions and the
axis keyword was set to a non-default value. This has been fixed.
Moreover, ``interp1d`` returns now a scalar (0D-array) if the input
is a scalar. Users of ``scipy.interpolate.interp1d`` may need to
revise their code if it relies on the previous behavior.

Weave clean up
==============

There were numerous improvements to ``scipy.weave``.  ``blitz++`` was
relicensed by the author to be compatible with the SciPy license.
``wx_spec.py`` was removed.

Known problems
==============

Here are known problems with scipy 0.7.0:

* weave test failures on windows: those are known, and are being revised.
* weave test failure with gcc 4.3 (std::labs): this is a gcc 4.3 bug. A
  workaround is to add #include <cstdlib> in
  scipy/weave/blitz/blitz/funcs.h (line 27). You can make the change in
  the installed scipy (in site-packages).
==========================
SciPy 1.2.3 Release Notes
==========================

.. contents::

SciPy 1.2.3 is a bug-fix release with no new features compared to 1.2.2. It is
part of the long-term support (LTS) release series for Python 2.7.

Authors
=======

* Geordie McBain
* Matt Haberland
* David Hagen
* Tyler Reddy
* Pauli Virtanen
* Eric Larson
* Yu Feng
* ananyashreyjain
* Nikolay Mayorov
* Evgeni Burovski 
* Warren Weckesser

Issues closed for 1.2.3
-----------------------
* `#4915 <https://github.com/scipy/scipy/issues/4915>`__: Bug in unique_roots in scipy.signal.signaltools.py for roots with same magnitude
* `#5546 <https://github.com/scipy/scipy/issues/5546>`__: ValueError raised if scipy.sparse.linalg.expm recieves array larger than 200x200
* `#7117 <https://github.com/scipy/scipy/issues/7117>`__: Warn users when using float32 input data to curve_fit and friends
* `#7906 <https://github.com/scipy/scipy/issues/7906>`__: Wrong result from scipy.interpolate.UnivariateSpline.integral for out-of-bounds 
* `#9581 <https://github.com/scipy/scipy/issues/9581>`__: Least-squares minimization fails silently when x and y data are different types
* `#9901 <https://github.com/scipy/scipy/issues/9901>`__: lsoda fails to detect stiff problem when called from solve_ivp
* `#9988 <https://github.com/scipy/scipy/issues/9988>`__: doc build broken with Sphinx 2.0.0
* `#10303 <https://github.com/scipy/scipy/issues/10303>`__: BUG: optimize: `linprog` failing TestLinprogSimplexBland::test_unbounded_below_no_presolve_corrected 
* `#10376 <https://github.com/scipy/scipy/issues/10376>`__: TST: Travis CI fails (with pytest 5.0 ?)
* `#10384 <https://github.com/scipy/scipy/issues/10384>`__: CircleCI doc build failing on new warnings
* `#10535 <https://github.com/scipy/scipy/issues/10535>`__: TST: master branch CI failures 
* `#11121 <https://github.com/scipy/scipy/issues/11121>`__: Calls to `scipy.interpolate.splprep` increase RAM usage.
* `#11198 <https://github.com/scipy/scipy/issues/11198>`__: BUG: sparse eigs (arpack) shift-invert drops the smallest eigenvalue for some k
* `#11266 <https://github.com/scipy/scipy/issues/11266>`__: Sparse matrix constructor data type detection changes on Numpy 1.18.0

Pull requests for 1.2.3
-----------------------
* `#9992 <https://github.com/scipy/scipy/pull/9992>`__: MAINT: Undo Sphinx pin 
* `#10071 <https://github.com/scipy/scipy/pull/10071>`__: DOC: reconstruct SuperLU permutation matrices avoiding SparseEfficiencyWarning
* `#10076 <https://github.com/scipy/scipy/pull/10076>`__: BUG: optimize: fix curve_fit for mixed float32/float64 input
* `#10138 <https://github.com/scipy/scipy/pull/10138>`__: BUG: special: Invalid arguments to ellip_harm can crash Python.
* `#10306 <https://github.com/scipy/scipy/pull/10306>`__: BUG: optimize: Fix for 10303
* `#10309 <https://github.com/scipy/scipy/pull/10309>`__: BUG: Pass jac=None directly to lsoda
* `#10377 <https://github.com/scipy/scipy/pull/10377>`__: TST, MAINT: adjustments for pytest 5.0
* `#10379 <https://github.com/scipy/scipy/pull/10379>`__: BUG: sparse: set writeability to be forward-compatible with numpy>=1.17
* `#10426 <https://github.com/scipy/scipy/pull/10426>`__: MAINT: Fix doc build bugs
* `#10540 <https://github.com/scipy/scipy/pull/10540>`__: MAINT: Fix Travis and Circle 
* `#10633 <https://github.com/scipy/scipy/pull/10633>`__: BUG: interpolate: integral(a, b) should be zero when both limits are outside of the interpolation range
* `#10833 <https://github.com/scipy/scipy/pull/10833>`__: BUG: Fix subspace_angles for complex values
* `#10882 <https://github.com/scipy/scipy/pull/10882>`__: BUG: sparse/arpack: fix incorrect code for complex hermitian M
* `#10906 <https://github.com/scipy/scipy/pull/10906>`__: BUG: sparse/linalg: fix expm for np.matrix inputs
* `#10961 <https://github.com/scipy/scipy/pull/10961>`__: BUG: Fix signal.unique_roots
* `#11126 <https://github.com/scipy/scipy/pull/11126>`__: BUG: interpolate/fitpack: fix memory leak in splprep
* `#11199 <https://github.com/scipy/scipy/pull/11199>`__: BUG: sparse.linalg: mistake in unsymm. real shift-invert ARPACK eigenvalue selection
* `#11269 <https://github.com/scipy/scipy/pull/11269>`__: Fix: Sparse matrix constructor data type detection changes on Numpy 1.18.0


==========================
SciPy 0.15.1 Release Notes
==========================

SciPy 0.15.1 is a bug-fix release with no new features compared to 0.15.0.

Issues fixed
------------

* `#4413 <https://github.com/scipy/scipy/pull/4413>`__: BUG: Tests too strict, f2py doesn't have to overwrite this array
* `#4417 <https://github.com/scipy/scipy/pull/4417>`__: BLD: avoid using NPY_API_VERSION to check not using deprecated...
* `#4418 <https://github.com/scipy/scipy/pull/4418>`__: Restore and deprecate scipy.linalg.calc_work
==========================
SciPy 1.5.0 Release Notes
==========================

.. contents::

SciPy 1.5.0 is the culmination of 6 months of hard work. It contains
many new features, numerous bug-fixes, improved test coverage and better
documentation. There have been a number of deprecations and API changes
in this release, which are documented below. All users are encouraged to
upgrade to this release, as there are a large number of bug-fixes and
optimizations. Before upgrading, we recommend that users check that
their own code does not use deprecated SciPy functionality (to do so,
run your code with ``python -Wd`` and check for ``DeprecationWarning`` s).
Our development attention will now shift to bug-fix releases on the
1.5.x branch, and on adding new features on the master branch.

This release requires Python 3.6+ and NumPy 1.14.5 or greater.

For running on PyPy, PyPy3 6.0+ and NumPy 1.15.0 are required.

Highlights of this release
--------------------------

- wrappers for more than a dozen new ``LAPACK`` routines are now available
  in `scipy.linalg.lapack`
- Improved support for leveraging 64-bit integer size from linear algebra
  backends
- addition of the probability distribution for two-sided one-sample
  Kolmogorov-Smirnov tests


New features
============

`scipy.cluster` improvements
------------------------------
Initialization of `scipy.cluster.vq.kmeans2` using ``minit="++"`` had a
quadratic complexity in the number of samples. It has been improved, resulting
in a much faster initialization with quasi-linear complexity.

`scipy.cluster.hierarchy.dendrogram` now respects the ``matplotlib`` color
palette

`scipy.fft` improvements
------------------------------
A new keyword-only argument ``plan`` is added to all FFT functions in this
module. It is reserved for passing in a precomputed plan from libraries
providing a FFT backend (such as ``PyFFTW`` and ``mkl-fft``), and it is
currently not used in SciPy.

`scipy.integrate` improvements
------------------------------


`scipy.interpolate` improvements
--------------------------------

`scipy.io` improvements
-----------------------
`scipy.io.wavfile` error messages are more explicit about what's wrong, and
extraneous bytes at the ends of files are ignored instead of raising an error
when the data has successfully been read.

`scipy.io.loadmat` gained a ``simplify_cells`` parameter, which if set to
``True`` simplifies the structure of the return value if the ``.mat`` file
contains cell arrays.

``pathlib.Path`` objects are now supported in `scipy.io` Matrix Market I/O
functions

`scipy.linalg` improvements
---------------------------
`scipy.linalg.eigh` has been improved. Now various ``LAPACK`` drivers can be
selected at will and also subsets of eigenvalues can be requested via
``subset_by_value`` keyword. Another keyword ``subset_by_index`` is introduced.
Keywords ``turbo`` and ``eigvals`` are deprecated.

Similarly, standard and generalized Hermitian eigenvalue ``LAPACK`` routines
``?<sy/he>evx`` are added and existing ones now have full ``_lwork``
counterparts.

Wrappers for the following ``LAPACK`` routines have been added to
`scipy.linalg.lapack`:

- ``?getc2``: computes the LU factorization of a general matrix with complete
    pivoting
- ``?gesc2``: solves a linear system given an LU factorization from ``?getc2``
- ``?gejsv``: computes the singular value decomposition of a general matrix
    with higher accuracy calculation of tiny singular values and their
    corresponding singular vectors
- ``?geqrfp``: computes the QR factorization of a general matrix with
    non-negative elements on the diagonal of R
- ``?gtsvx``: solves a linear system with general tridiagonal matrix
- ``?gttrf``: computes the LU factorization of a tridiagonal matrix
- ``?gttrs``: solves a linear system given an LU factorization from ``?gttrf``
- ``?ptsvx``: solves a linear system with symmetric positive definite
    tridiagonal matrix
- ``?pttrf``: computes the LU factorization of a symmetric positive definite
    tridiagonal matrix
- ``?pttrs``: solves a linear system given an LU factorization from ``?pttrf``
- ``?pteqr``: computes the eigenvectors and eigenvalues of a positive definite
    tridiagonal matrix
- ``?tbtrs``: solves a linear system with a triangular banded matrix
- ``?csd``: computes the Cosine Sine decomposition of an orthogonal/unitary
    matrix

Generalized QR factorization routines (``?geqrf``) now have full ``_lwork``
counterparts.

`scipy.linalg.cossin` Cosine Sine decomposition of unitary matrices has been
added.

The function `scipy.linalg.khatri_rao`, which computes the Khatri-Rao product,
was added.

The new function `scipy.linalg.convolution_matrix` constructs the Toeplitz
matrix representing one-dimensional convolution.

`scipy.ndimage` improvements
----------------------------


`scipy.optimize` improvements
-----------------------------
The finite difference numerical differentiation used in various ``minimize``
methods that use gradients has several new features:

- 2-point, 3-point, or complex step finite differences can be used. Previously
  only a 2-step finite difference was available.
- There is now the possibility to use a relative step size, previously only an
  absolute step size was available.
- If the ``minimize`` method uses bounds the numerical differentiation strictly
  obeys those limits.
- The numerical differentiation machinery now makes use of a simple cache,
  which in some cases can reduce the number of function evaluations.
- ``minimize``'s ``method= 'powell'`` now supports simple bound constraints

There have been several improvements to `scipy.optimize.linprog`:

- The ``linprog`` benchmark suite has been expanded considerably.
- ``linprog``'s dense pivot-based redundancy removal routine and sparse
  presolve are faster
- When ``scikit-sparse`` is available, solving sparse problems with
  ``method='interior-point'`` is faster

The caching of values when optimizing a function returning both value and
gradient together has been improved, avoiding repeated function evaluations
when using a ``HessianApproximation`` such as ``BFGS``.

``differential_evolution`` can now use the modern ``np.random.Generator`` as
well as the legacy ``np.random.RandomState`` as a seed.

`scipy.signal` improvements
---------------------------
A new optional argument ``include_nyquist`` is added to ``freqz`` functions in
this module. It is used for including the last frequency (Nyquist frequency).

`scipy.signal.find_peaks_cwt` now accepts a ``window_size`` parameter for the
size of the window used to calculate the noise floor.

`scipy.sparse` improvements
---------------------------
Outer indexing is now faster when using a 2d column vector to select column
indices.

`scipy.sparse.lil.tocsr` is faster

Fixed/improved comparisons between pydata sparse arrays and sparse matrices

BSR format sparse multiplication performance has been improved.

`scipy.sparse.linalg.LinearOperator` has gained the new ``ndim`` class
attribute

`scipy.spatial` improvements
----------------------------
`scipy.spatial.geometric_slerp` has been added to enable geometric
spherical linear interpolation on an n-sphere

`scipy.spatial.SphericalVoronoi` now supports calculation of region areas in 2D
and 3D cases

The tree building algorithm used by ``cKDTree`` has improved from quadratic
worst case time complexity to loglinear. Benchmarks are also now available for
building and querying of balanced/unbalanced kd-trees.

`scipy.special` improvements
----------------------------
The following functions now have Cython interfaces in `cython_special`:

- `scipy.special.erfinv`
- `scipy.special.erfcinv`
- `scipy.special.spherical_jn`
- `scipy.special.spherical_yn`
- `scipy.special.spherical_in`
- `scipy.special.spherical_kn`

`scipy.special.log_softmax` has been added to calculate the logarithm of softmax
function. It provides better accuracy than ``log(scipy.special.softmax(x))`` for
inputs that make softmax saturate.

`scipy.stats` improvements
--------------------------
The function for generating random samples in `scipy.stats.dlaplace` has been
improved. The new function is approximately twice as fast with a memory
footprint reduction between 25 % and 60 % (see gh-11069).

`scipy.stats` functions that accept a seed for reproducible calculations using
random number generation (e.g. random variates from distributions) can now use
the modern ``np.random.Generator`` as well as the legacy
``np.random.RandomState`` as a seed.

The ``axis`` parameter was added to `scipy.stats.rankdata`. This allows slices
of an array along the given axis to be ranked independently.

The ``axis`` parameter was added to `scipy.stats.f_oneway`, allowing it to
compute multiple one-way ANOVA tests for data stored in n-dimensional
arrays.  The performance of ``f_oneway`` was also improved for some cases.

The PDF and CDF methods for ``stats.geninvgauss`` are now significantly faster
as  the numerical integration to calculate the CDF uses a Cython based
``LowLevelCallable``.

Moments of the normal distribution (`scipy.stats.norm`) are now calculated using
analytical formulas instead of numerical integration for greater speed and
accuracy

Moments and entropy trapezoidal distribution (``scipy.stats.trapz``) are now
calculated using analytical formulas instead of numerical integration for
greater speed and accuracy

Methods of the truncated normal distribution (`scipy.stats.truncnorm`),
especially ``_rvs``, are significantly faster after a complete rewrite.

The `fit` method of the Laplace distribution,  `scipy.stats.laplace`, now uses
the analytical formulas for the maximum likelihood estimates of the parameters.

Generation of random variates is now thread safe for all SciPy distributions.
3rd-party distributions may need to modify the signature of the ``_rvs()``
method to conform to ``_rvs(self, ..., size=None, random_state=None)``. (A
one-time VisibleDeprecationWarning is emitted when using non-conformant
distributions.)

The Kolmogorov-Smirnov two-sided test statistic distribution
(`scipy.stats.kstwo`) was added. Calculates the distribution of the K-S
two-sided statistic ``D_n`` for a sample of size n, using a mixture of exact
and asymptotic algorithms.

The new function ``median_abs_deviation`` replaces the deprecated
``median_absolute_deviation``.

The ``wilcoxon`` function now computes the p-value for Wilcoxon's signed rank
test using the exact distribution for inputs up to length 25.  The function has
a new ``mode`` parameter to specify how the p-value is to be computed.  The
default is ``"auto"``, which uses the exact distribution for inputs up to length
25 and the normal approximation for larger inputs.

Added a new Cython-based implementation to evaluate guassian kernel estimates,
which should improve the performance of ``gaussian_kde``

The ``winsorize`` function now has a ``nan_policy`` argument for refined
handling of ``nan`` input values.

The ``binned_statistic_dd`` function with ``statistic="std"`` performance was
improved by ~4x.

``scipy.stats.kstest(rvs, cdf,...)`` now handles both one-sample and
two-sample testing. The one-sample variation uses `scipy.stats.ksone`
(or `scipy.stats.kstwo` with back off to `scipy.stats.kstwobign`) to calculate
the p-value. The two-sample variation, invoked if ``cdf`` is array_like, uses
an algorithm described by Hodges to compute the probability directly, only
backing off to `scipy.stats.kstwo` in case of overflow. The result in both
cases is more accurate p-values, especially for two-sample testing with
smaller (or quite different) sizes.

`scipy.stats.maxwell` performance improvements include a 20 % speed up for
`fit()`` and 5 % for ``pdf()``

`scipy.stats.shapiro` and `scipy.stats.jarque_bera` now return a named tuple
for greater consistency with other ``stats`` functions

Deprecated features
===================

`scipy` deprecations
--------------------

`scipy.special` changes
-----------------------
The ``bdtr``, ``bdtrc``, and ``bdtri`` functions are deprecating non-negative
non-integral ``n`` arguments.

`scipy.stats` changes
---------------------
The function ``median_absolute_deviation`` is deprecated. Use
``median_abs_deviation`` instead.

The use of the string ``"raw"`` with the ``scale`` parameter of ``iqr`` is
deprecated. Use ``scale=1`` instead.

Backwards incompatible changes
==============================

`scipy.interpolate` changes
---------------------------

`scipy.linalg` changes
----------------------
The output signatures of ``?syevr``, ``?heevr`` have been changed from
``w, v, info`` to ``w, v, m, isuppz, info``

The order of output arguments ``w``, ``v`` of ``<sy/he>{gv, gvd, gvx}`` is
swapped.

`scipy.signal` changes
----------------------
The output length of `scipy.signal.upfirdn` has been corrected, resulting
outputs may now be shorter for some combinations of up/down ratios and input
signal and filter lengths.

`scipy.signal.resample` now supports a ``domain`` keyword argument for
specification of time or frequency domain input.

`scipy.stats` changes
---------------------


Other changes
=============
Improved support for leveraging 64-bit integer size from linear algebra backends
in several parts of the SciPy codebase.

Shims designed to ensure the compatibility of SciPy with Python 2.7 have now
been removed.

Many warnings due to unused imports and unused assignments have been addressed.

Many usage examples were added to function docstrings, and many input
validations and intuitive exception messages have been added throughout the
codebase.

Early stage adoption of type annotations in a few parts of the codebase


Authors
=======

* @endolith
* Hameer Abbasi
* ADmitri +
* Wesley Alves +
* Berkay Antmen +
* Sylwester Arabas +
* Arne Küderle +
* Christoph Baumgarten
* Peter Bell
* Felix Berkenkamp
* Jordão Bragantini +
* Clemens Brunner +
* Evgeni Burovski
* Matthias Bussonnier +
* CJ Carey
* Derrick Chambers +
* Leander Claes +
* Christian Clauss
* Luigi F. Cruz +
* dankleeman
* Andras Deak
* Milad Sadeghi DM +
* jeremie du boisberranger +
* Stefan Endres
* Malte Esders +
* Leo Fang +
* felixhekhorn +
* Isuru Fernando
* Andrew Fowlie
* Lakshay Garg +
* Gaurav Gijare +
* Ralf Gommers
* Emmanuelle Gouillart +
* Kevin Green +
* Martin Grignard +
* Maja Gwozdz
* Sturla Molden
* gyu-don +
* Matt Haberland
* hakeemo +
* Charles Harris
* Alex Henrie
* Santi Hernandez +
* William Hickman +
* Till Hoffmann +
* Joseph T. Iosue +
* Anany Shrey Jain
* Jakob Jakobson
* Charles Jekel +
* Julien Jerphanion +
* Jiacheng-Liu +
* Christoph Kecht +
* Paul Kienzle +
* Reidar Kind +
* Dmitry E. Kislov +
* Konrad +
* Konrad0
* Takuya KOUMURA +
* Krzysztof Pióro
* Peter Mahler Larsen
* Eric Larson
* Antony Lee
* Gregory Lee +
* Gregory R. Lee
* Chelsea Liu
* Cong Ma +
* Kevin Mader +
* Maja Gwóźdź +
* Alex Marvin +
* Matthias Kümmerer
* Nikolay Mayorov
* Mazay0 +
* G. D. McBain
* Nicholas McKibben +
* Sabrina J. Mielke +
* Sebastian J. Mielke +
* Miloš Komarčević +
* Shubham Mishra +
* Santiago M. Mola +
* Grzegorz Mrukwa +
* Peyton Murray
* Andrew Nelson
* Nico Schlömer
* nwjenkins +
* odidev +
* Sambit Panda
* Vikas Pandey +
* Rick Paris +
* Harshal Prakash Patankar +
* Balint Pato +
* Matti Picus
* Ilhan Polat
* poom +
* Siddhesh Poyarekar
* Vladyslav Rachek +
* Bharat Raghunathan
* Manu Rajput +
* Tyler Reddy
* Andrew Reed +
* Lucas Roberts
* Ariel Rokem
* Heshy Roskes
* Matt Ruffalo
* Atsushi Sakai +
* Benjamin Santos +
* Christoph Schock +
* Lisa Schwetlick +
* Chris Simpson +
* Leo Singer
* Kai Striega
* Søren Fuglede Jørgensen
* Kale-ab Tessera +
* Seth Troisi +
* Robert Uhl +
* Paul van Mulbregt
* Vasiliy +
* Isaac Virshup +
* Pauli Virtanen
* Shakthi Visagan +
* Jan Vleeshouwers +
* Sam Wallan +
* Lijun Wang +
* Warren Weckesser
* Richard Weiss +
* wenhui-prudencemed +
* Eric Wieser
* Josh Wilson
* James Wright +
* Ruslan Yevdokymov +
* Ziyao Zhang +

A total of 129 people contributed to this release.
People with a "+" by their names contributed a patch for the first time.
This list of names is automatically generated, and may not be fully complete.

Issues closed for 1.5.0
-----------------------

* `#1455 <https://github.com/scipy/scipy/issues/1455>`__: ellipord does returns bogus values if gstop or gpass are negative...
* `#1968 <https://github.com/scipy/scipy/issues/1968>`__: correlate2d's output does not agree with correlate's output in...
* `#2744 <https://github.com/scipy/scipy/issues/2744>`__: BUG: optimize: '\*\*kw' argument of 'newton_krylov' is not documented
* `#4755 <https://github.com/scipy/scipy/issues/4755>`__: TypeError: data type "<i0" not understood
* `#4921 <https://github.com/scipy/scipy/issues/4921>`__: scipy.optimize maxiter option not working as expected
* `#5144 <https://github.com/scipy/scipy/issues/5144>`__: RuntimeWarning on csgraph.shortest_path when edge lengths are...
* `#5309 <https://github.com/scipy/scipy/issues/5309>`__: Documentation of 'hybr' and 'lm' inconsistent in optimize.root
* `#6026 <https://github.com/scipy/scipy/issues/6026>`__: Replace approx_grad with _numdiff.approx_derivative in scipy.optimize
* `#6502 <https://github.com/scipy/scipy/issues/6502>`__: Computing Eigenvalues in an Interval with LAPACK
* `#7058 <https://github.com/scipy/scipy/issues/7058>`__: Errors in special.bdtri and special.bdtr for non-integer k values
* `#7700 <https://github.com/scipy/scipy/issues/7700>`__: SuperLU does not respect perm_c="NATURAL"
* `#7895 <https://github.com/scipy/scipy/issues/7895>`__: Improvements to io.loadmat
* `#8205 <https://github.com/scipy/scipy/issues/8205>`__: ValueError in scipy.linalg.eigvalsh for large matrix
* `#8278 <https://github.com/scipy/scipy/issues/8278>`__: Memory limit for scipy.sparse.linalg.spsolve with scikit-umfpack
* `#8327 <https://github.com/scipy/scipy/issues/8327>`__: scipy.stats.mstats.winsorize NaN handling
* `#8341 <https://github.com/scipy/scipy/issues/8341>`__: scipy.stats.ks_2samp for masked and unmasked data give different...
* `#8748 <https://github.com/scipy/scipy/issues/8748>`__: scipy.stats.kstest for same distribution: p-values nonuniform
* `#9042 <https://github.com/scipy/scipy/issues/9042>`__: optimize: Incorrect statement about \`jac\` in the \`minimize\`...
* `#9197 <https://github.com/scipy/scipy/issues/9197>`__: problem with scipy.signal.butter with 1000+ points array
* `#9212 <https://github.com/scipy/scipy/issues/9212>`__: EIGH very very slow --> suggesting an easy fix
* `#9553 <https://github.com/scipy/scipy/issues/9553>`__: ndimage routines behave badly when output has memory overlap...
* `#9632 <https://github.com/scipy/scipy/issues/9632>`__: ndimage.maximum_filter undocumented behaviour using footprint...
* `#9658 <https://github.com/scipy/scipy/issues/9658>`__: `scipy.optimize.minimize(method='COBYLA')` not threadsafe
* `#9710 <https://github.com/scipy/scipy/issues/9710>`__: stats.weightedtau([1], [1.0]) SEGFAULTs
* `#9797 <https://github.com/scipy/scipy/issues/9797>`__: Master Tracker for some Kolmogorov-Smirnov test Issues
* `#9844 <https://github.com/scipy/scipy/issues/9844>`__: scipy.signal.upfirdn gives different length matrix versus MATLAB...
* `#9872 <https://github.com/scipy/scipy/issues/9872>`__: scipy.signal.convolve is slower when vectorized
* `#9913 <https://github.com/scipy/scipy/issues/9913>`__: BUG: No dt in StateSpace operations
* `#10014 <https://github.com/scipy/scipy/issues/10014>`__: Distribution names \`weibull_min\`and \`weibull_max\` should...
* `#10159 <https://github.com/scipy/scipy/issues/10159>`__: BUG: stats: chisquare returns incorrect results for arrays of...
* `#10302 <https://github.com/scipy/scipy/issues/10302>`__: scipy.fft: Add a \`plan\` argument
* `#10332 <https://github.com/scipy/scipy/issues/10332>`__: 'Incomplete wav chunk' inconsistent/reason unknown
* `#10441 <https://github.com/scipy/scipy/issues/10441>`__: Remove uses of \`numpy.dual\`?
* `#10558 <https://github.com/scipy/scipy/issues/10558>`__: Document implicit sum in csr_matrix() constructor
* `#10788 <https://github.com/scipy/scipy/issues/10788>`__: LU with full pivoting
* `#10841 <https://github.com/scipy/scipy/issues/10841>`__: Unexpected behavior in linalg.blas.dtrmm wrapper
* `#10919 <https://github.com/scipy/scipy/issues/10919>`__: optimize._lbfgsb setulb() function violates parameter bounds
* `#10963 <https://github.com/scipy/scipy/issues/10963>`__: kstest, ks_2samp: confusing \`mode\` argument descriptions
* `#11022 <https://github.com/scipy/scipy/issues/11022>`__: Unexpected Result in factorial function with NaN input
* `#11028 <https://github.com/scipy/scipy/issues/11028>`__: Documentation error in optimize.minimize
* `#11058 <https://github.com/scipy/scipy/issues/11058>`__: Adding logsoftmax function
* `#11076 <https://github.com/scipy/scipy/issues/11076>`__: ValueError: Unknown wave file format
* `#11090 <https://github.com/scipy/scipy/issues/11090>`__: Misconception of the median absolute deviation in stats?
* `#11095 <https://github.com/scipy/scipy/issues/11095>`__: BUG: find_peaks_cwt test failures in 32-bit Linux wheels
* `#11107 <https://github.com/scipy/scipy/issues/11107>`__: scipy.io.mmread generated an error "TypeError: startswith first...
* `#11123 <https://github.com/scipy/scipy/issues/11123>`__: Add wrapper for ?gttrf/?gttrs
* `#11128 <https://github.com/scipy/scipy/issues/11128>`__: OverflowError in resample_poly (upfirdn)
* `#11132 <https://github.com/scipy/scipy/issues/11132>`__: Possible bug: rv_discret.ppf for percentiles 0 and 100 and loc...
* `#11163 <https://github.com/scipy/scipy/issues/11163>`__: Comparisons between scipy spmatrix and can sparse.SparseArray...
* `#11168 <https://github.com/scipy/scipy/issues/11168>`__: Generalized Pareto variance inaccurate for concentrations near...
* `#11169 <https://github.com/scipy/scipy/issues/11169>`__: Add wrapper for ?geqrfp
* `#11184 <https://github.com/scipy/scipy/issues/11184>`__: 2-sided Kolmogorov Smirnov returns p-value of 1
* `#11185 <https://github.com/scipy/scipy/issues/11185>`__: The .roots() or solve() function of scipy.interpolate.CubicHermiteSpline...
* `#11190 <https://github.com/scipy/scipy/issues/11190>`__: Add wrapper for ?tbtrs
* `#11200 <https://github.com/scipy/scipy/issues/11200>`__: Can no longer slice csr_matrix in 1.3.0
* `#11207 <https://github.com/scipy/scipy/issues/11207>`__: _minimize_scalar_bounded: reference before assignment
* `#11216 <https://github.com/scipy/scipy/issues/11216>`__: linprog: interior-point: Cholmod reordering can be reused
* `#11223 <https://github.com/scipy/scipy/issues/11223>`__: Add wrappers for ?pttrf, ?pttrs
* `#11224 <https://github.com/scipy/scipy/issues/11224>`__: Add wrapperfor ?pteqr
* `#11235 <https://github.com/scipy/scipy/issues/11235>`__: MAINT: Missleading Error Message for IIR Filter
* `#11244 <https://github.com/scipy/scipy/issues/11244>`__: Missing reference in \`scipy.optimize.line_search\`
* `#11262 <https://github.com/scipy/scipy/issues/11262>`__: Hermitian Eigenvalue Problem eigh() API and wrapper change proposal
* `#11266 <https://github.com/scipy/scipy/issues/11266>`__: Sparse matrix constructor data type detection changes on Numpy...
* `#11270 <https://github.com/scipy/scipy/issues/11270>`__: CI failing: Travis CI Py36 refguide and Linux_Python_36_32bit_full...
* `#11279 <https://github.com/scipy/scipy/issues/11279>`__: linalg.eigh checks whole array for finite values
* `#11295 <https://github.com/scipy/scipy/issues/11295>`__: CI: azure does not auto-cancel old jobs on pushes
* `#11299 <https://github.com/scipy/scipy/issues/11299>`__: stats.truncnorm.rvs 100x slower in v1.4.x than v1.3.3
* `#11315 <https://github.com/scipy/scipy/issues/11315>`__: BUG: special: rgamma on negative integers smaller -34
* `#11319 <https://github.com/scipy/scipy/issues/11319>`__: Missing \`int64_t\` declaration in rectangular_lsap.cpp
* `#11323 <https://github.com/scipy/scipy/issues/11323>`__: Compilation failure due to missing symbol pthread_atfork
* `#11332 <https://github.com/scipy/scipy/issues/11332>`__: BUG: directed_hausdorff distance on sets u and v when u is a...
* `#11350 <https://github.com/scipy/scipy/issues/11350>`__: Khatri-Rao product
* `#11354 <https://github.com/scipy/scipy/issues/11354>`__: ENH: Add wrapper for ?gejsv
* `#11361 <https://github.com/scipy/scipy/issues/11361>`__: Dropped NaN in eval_genlaguerre function
* `#11363 <https://github.com/scipy/scipy/issues/11363>`__: Dropped NaN in hyperu function
* `#11365 <https://github.com/scipy/scipy/issues/11365>`__: scipy.stats.binned_statistic regressed in v1.4.0
* `#11369 <https://github.com/scipy/scipy/issues/11369>`__: Dropped NaN in eval_hermite
* `#11370 <https://github.com/scipy/scipy/issues/11370>`__: Dropped NaN in eval_gegenbauer
* `#11373 <https://github.com/scipy/scipy/issues/11373>`__: Add wrapper for ?gtsvx
* `#11374 <https://github.com/scipy/scipy/issues/11374>`__: Add wrapper for ?ptsvx
* `#11391 <https://github.com/scipy/scipy/issues/11391>`__: csgraph.minimum_spanning_tree loses precision
* `#11398 <https://github.com/scipy/scipy/issues/11398>`__: Update stats to cope with \`np.random.Generator\` machinery
* `#11412 <https://github.com/scipy/scipy/issues/11412>`__: Array copying causes unwanted type casting from complex to float...
* `#11415 <https://github.com/scipy/scipy/issues/11415>`__: Where is the Wiener Filter derived from?
* `#11416 <https://github.com/scipy/scipy/issues/11416>`__: _lib._util.getargspec_no_self is missing KEYWORD_ONLY support
* `#11428 <https://github.com/scipy/scipy/issues/11428>`__: Documentation on SHGO inequality constraints appears contradictory
* `#11429 <https://github.com/scipy/scipy/issues/11429>`__: Add LAPACK's ZUNCSD cosine sine decomposition
* `#11438 <https://github.com/scipy/scipy/issues/11438>`__: run_dualannealing passes bounds incorrectly in benchmarks/optimize.py
* `#11441 <https://github.com/scipy/scipy/issues/11441>`__: Can't run optimize benchmarks
* `#11442 <https://github.com/scipy/scipy/issues/11442>`__: Chebyshev weights
* `#11448 <https://github.com/scipy/scipy/issues/11448>`__: Wrongly typed comparison in integrate.quad
* `#11458 <https://github.com/scipy/scipy/issues/11458>`__: BUG: maximum_bipartite_matching produces infeasible solution
* `#11460 <https://github.com/scipy/scipy/issues/11460>`__: CI failing: 2 Travis CI tests fail with numpy build or version...
* `#11462 <https://github.com/scipy/scipy/issues/11462>`__: Bug on "++" initialization on "kmeans2"
* `#11464 <https://github.com/scipy/scipy/issues/11464>`__: Shouldn't data type of KDE evaluation should be like in the input...
* `#11468 <https://github.com/scipy/scipy/issues/11468>`__: performance of binned_statistics_2d 100x slowdown from 1.3.2...
* `#11484 <https://github.com/scipy/scipy/issues/11484>`__: Callback function doesn't give the same value as the one being...
* `#11492 <https://github.com/scipy/scipy/issues/11492>`__: Confusing dendrogram labelling
* `#11493 <https://github.com/scipy/scipy/issues/11493>`__: scipy.optimize.least_squares fails if the return array of the...
* `#11494 <https://github.com/scipy/scipy/issues/11494>`__: Error performing kronecker product between large sparse vectors
* `#11503 <https://github.com/scipy/scipy/issues/11503>`__: medfilt produces 0 on input of length 1
* `#11529 <https://github.com/scipy/scipy/issues/11529>`__: Pyflakes generates almost 700 warnings.
* `#11566 <https://github.com/scipy/scipy/issues/11566>`__: irfft/irfft2/irfftn docs are slightly confusing re: input type.
* `#11572 <https://github.com/scipy/scipy/issues/11572>`__: least_squares: too small tolerances not catched with method='lm'
* `#11581 <https://github.com/scipy/scipy/issues/11581>`__: DOC: scipy.interpolate.RectSphereBivariateSpline
* `#11586 <https://github.com/scipy/scipy/issues/11586>`__: Differential evolution breaks with LinearConstraints with sparse...
* `#11595 <https://github.com/scipy/scipy/issues/11595>`__: scipy.spatial.cKDTree construction slow for some datasets
* `#11598 <https://github.com/scipy/scipy/issues/11598>`__: output of special.voigt_profile when sigma=0
* `#11601 <https://github.com/scipy/scipy/issues/11601>`__: linalg tests failing in runtests.py
* `#11602 <https://github.com/scipy/scipy/issues/11602>`__: scipy.optimize.linear_sum_assignment returns reverse diagonal...
* `#11610 <https://github.com/scipy/scipy/issues/11610>`__: Analytic formula for normal moments
* `#11611 <https://github.com/scipy/scipy/issues/11611>`__: Build failure with gfortran 10
* `#11613 <https://github.com/scipy/scipy/issues/11613>`__: TST, MAINT: test_quadpack TestCtypesQuad wasn't fully migrated...
* `#11630 <https://github.com/scipy/scipy/issues/11630>`__: SmoothBivariateSpline bbox parameter
* `#11635 <https://github.com/scipy/scipy/issues/11635>`__: typo in docstring of scipy.stats.norminvgauss
* `#11637 <https://github.com/scipy/scipy/issues/11637>`__: BUG: core dumps when calling scipy.interpolate.interp1d with...
* `#11638 <https://github.com/scipy/scipy/issues/11638>`__: better documentation for 'return_all' option in minimize(Nelder...
* `#11652 <https://github.com/scipy/scipy/issues/11652>`__: TST, MAINT: CI failures for pre-release NumPy wheels
* `#11659 <https://github.com/scipy/scipy/issues/11659>`__: optimize.fmin_l_bfgs_b needs bound check and appropiate error...
* `#11660 <https://github.com/scipy/scipy/issues/11660>`__: BUG/ENH: distribution.ncf with nc=0 returns nan
* `#11661 <https://github.com/scipy/scipy/issues/11661>`__: scipy.ndimage.convolve1d and correlate1d don't behave properly...
* `#11669 <https://github.com/scipy/scipy/issues/11669>`__: p-value varies with the order of the data
* `#11676 <https://github.com/scipy/scipy/issues/11676>`__: documentation of scipy.spatial.HalfspaceIntersection: wrong method...
* `#11685 <https://github.com/scipy/scipy/issues/11685>`__: Rotation cannot be expressed as matrix
* `#11686 <https://github.com/scipy/scipy/issues/11686>`__: MAINT: mypy imports of Cython "modules"
* `#11693 <https://github.com/scipy/scipy/issues/11693>`__: TestDifferentialEvolutionSolver::test_L4 failing in CI
* `#11696 <https://github.com/scipy/scipy/issues/11696>`__: DOC: incorrect compiler information for macOS in docs
* `#11709 <https://github.com/scipy/scipy/issues/11709>`__: eigh() tests fail to pass, crash Python with seemingly ramdom...
* `#11763 <https://github.com/scipy/scipy/issues/11763>`__: Small error in gamma continuous rv fit comments
* `#11769 <https://github.com/scipy/scipy/issues/11769>`__: truncnorm.rvs Weird Behaviors
* `#11770 <https://github.com/scipy/scipy/issues/11770>`__: crash in TestEigh::test_value_subsets
* `#11795 <https://github.com/scipy/scipy/issues/11795>`__: trapz distribution mean computed using single precision
* `#11800 <https://github.com/scipy/scipy/issues/11800>`__: Segmentation fault in scipy.odr for multidimensional independent...
* `#11811 <https://github.com/scipy/scipy/issues/11811>`__: pyflakes silently failing on travis-ci
* `#11826 <https://github.com/scipy/scipy/issues/11826>`__: Error with _fblas
* `#11827 <https://github.com/scipy/scipy/issues/11827>`__: \`fft.tests.test_numpy.test_multiprocess\` hangs on Python3.8...
* `#11835 <https://github.com/scipy/scipy/issues/11835>`__: tests with \`multiprocessing\` hang on Python 3.8 on macOS
* `#11839 <https://github.com/scipy/scipy/issues/11839>`__: linalg.expm returns nans with RuntimeWarning: overflow encountered...
* `#11856 <https://github.com/scipy/scipy/issues/11856>`__: Documentation of fit methods for \`weibull_min\` and \`exponweib\`...
* `#11868 <https://github.com/scipy/scipy/issues/11868>`__: Function always evaluated twice when using HessianUpdateStrategy...
* `#11875 <https://github.com/scipy/scipy/issues/11875>`__: Typo in the docstring of simps()
* `#11877 <https://github.com/scipy/scipy/issues/11877>`__: kmeans2 '++' method is orders of magnitude slower than sklearn.cluster.KMeans()
* `#11884 <https://github.com/scipy/scipy/issues/11884>`__: The upper code lines are dead code
* `#11886 <https://github.com/scipy/scipy/issues/11886>`__: Array shape mismatch in scipy.optimize
* `#11892 <https://github.com/scipy/scipy/issues/11892>`__: BUG: stats: Incorrect handling of edges cases by ttest_rel and...
* `#11908 <https://github.com/scipy/scipy/issues/11908>`__: LinearOperator should have ndim attribute
* `#11910 <https://github.com/scipy/scipy/issues/11910>`__: Documentation missing for what M is in init argument
* `#11922 <https://github.com/scipy/scipy/issues/11922>`__: macOS actions CI has started failing in last couple of days.
* `#11928 <https://github.com/scipy/scipy/issues/11928>`__: DOC: signal: Wrong description for sepfir2d, cspline2d, qspline2d
* `#11944 <https://github.com/scipy/scipy/issues/11944>`__: curve_fit documentation unclear on default value of absolute_sigma
* `#11945 <https://github.com/scipy/scipy/issues/11945>`__: Add a (potentially temporary) py.typed file?
* `#11949 <https://github.com/scipy/scipy/issues/11949>`__: ValueError 'k exceeds matrix dimensions' for sparse.diagonal()...
* `#11951 <https://github.com/scipy/scipy/issues/11951>`__: BUG: asv benchmark failed because of cython version
* `#11967 <https://github.com/scipy/scipy/issues/11967>`__: BLD: Azure windows runs complain about drives
* `#11973 <https://github.com/scipy/scipy/issues/11973>`__: oaconvolve(a,b,'same') differs in shape from convolve(a,b,'same')...
* `#12002 <https://github.com/scipy/scipy/issues/12002>`__: pybind11 license
* `#12003 <https://github.com/scipy/scipy/issues/12003>`__: MAINT: circular SphericalVoronoi input
* `#12015 <https://github.com/scipy/scipy/issues/12015>`__: Reordering of CSC matrix breaks when you go above int32 limits
* `#12031 <https://github.com/scipy/scipy/issues/12031>`__: Documentation Rendering Issues Visible in CircleCI Artifacts
* `#12037 <https://github.com/scipy/scipy/issues/12037>`__: MAINT, CI: new Cython 3.0a4 issue
* `#12087 <https://github.com/scipy/scipy/issues/12087>`__: DOC: some odr models are missing docs
* `#12119 <https://github.com/scipy/scipy/issues/12119>`__: signal.fftconvolve no longer convolves types f8 and numpy.float64
* `#12149 <https://github.com/scipy/scipy/issues/12149>`__: Documentation of Rosenbrock function
* `#12173 <https://github.com/scipy/scipy/issues/12173>`__: Large memory usage when indexing sparse matrices with \`np.ix_\`
* `#12178 <https://github.com/scipy/scipy/issues/12178>`__: BUG: stats: Some discrete distributions don't accept lists of...
* `#12220 <https://github.com/scipy/scipy/issues/12220>`__: BUG, REL: gh_lists.py compromised scraping
* `#12239 <https://github.com/scipy/scipy/issues/12239>`__: BUG: median absolute deviation handling of nan
* `#12301 <https://github.com/scipy/scipy/issues/12301>`__: integer overflow in scipy.sparse.sputils.check_shape when matrix size > 2^32
* `#12314 <https://github.com/scipy/scipy/issues/12314>`__: scipy.spatial.transform.Rotation multiplication does not normalize quaternion

Pull requests for 1.5.0
-----------------------

* `#6510 <https://github.com/scipy/scipy/pull/6510>`__: Add Eigenvalue Range Functionality for Symmetric Eigenvalue Problems
* `#9525 <https://github.com/scipy/scipy/pull/9525>`__: BUG: SuperLU 'NATURAL' order applies a column permutation
* `#9634 <https://github.com/scipy/scipy/pull/9634>`__: Add the number of Jacobian evaluations to the output of L-BFGS-B.
* `#9719 <https://github.com/scipy/scipy/pull/9719>`__: ENH: Added kstwo probability distribution for two-sided one-sample...
* `#9783 <https://github.com/scipy/scipy/pull/9783>`__: WIP: optimize: added (dense) interpolative decomposition redundancy...
* `#10053 <https://github.com/scipy/scipy/pull/10053>`__: Adding docstring to weibull_min and weibull_max based on issue...
* `#10136 <https://github.com/scipy/scipy/pull/10136>`__: DEP: Add warning to linprog_verbose_callback
* `#10380 <https://github.com/scipy/scipy/pull/10380>`__: ENH: add geometric_slerp
* `#10602 <https://github.com/scipy/scipy/pull/10602>`__: MAINT: optimize: refactor common linprog arguments into namedtuple
* `#10648 <https://github.com/scipy/scipy/pull/10648>`__: Bounds for the Powell minimization method
* `#10673 <https://github.com/scipy/scipy/pull/10673>`__: ENH: approx_fprime --> approx_derivative
* `#10759 <https://github.com/scipy/scipy/pull/10759>`__: ENH: calculation of region areas in spatial.SphericalVoronoi
* `#10762 <https://github.com/scipy/scipy/pull/10762>`__: BENCH: optimize: more comprehensive linprog benchmarking
* `#10796 <https://github.com/scipy/scipy/pull/10796>`__: ENH exact p-values of wilcoxon test in scipy.stats
* `#10797 <https://github.com/scipy/scipy/pull/10797>`__: ENH: linalg: LU with full pivoting (wrappers for ?getc2/?gesc2)
* `#10824 <https://github.com/scipy/scipy/pull/10824>`__: ENH: Fast gaussian kernel estimator
* `#10942 <https://github.com/scipy/scipy/pull/10942>`__: BUG: prevent bound violation in L-BFGS-B optimize method
* `#11003 <https://github.com/scipy/scipy/pull/11003>`__: ENH: add scipy.linalg.convolution_matrix
* `#11023 <https://github.com/scipy/scipy/pull/11023>`__: improving error message for cubic-interpolate with duplicates
* `#11045 <https://github.com/scipy/scipy/pull/11045>`__: MAINT: make bdt{r,rc,ri}() functions accept double n,k args +...
* `#11063 <https://github.com/scipy/scipy/pull/11063>`__: Fix documentation error in optimize.minimize
* `#11069 <https://github.com/scipy/scipy/pull/11069>`__: ENH: stats.dlaplace.rvs improvements
* `#11071 <https://github.com/scipy/scipy/pull/11071>`__: DOC: Added examples to maximum_position in ndimage
* `#11075 <https://github.com/scipy/scipy/pull/11075>`__: DOC: Update stylistic consistency in multiple files
* `#11097 <https://github.com/scipy/scipy/pull/11097>`__: BUG: stats: fixing chisquare to return correct results for arrays...
* `#11110 <https://github.com/scipy/scipy/pull/11110>`__: ENH: special: Cythonise erfinv, erfcinv
* `#11112 <https://github.com/scipy/scipy/pull/11112>`__: BUG: special: Return NaN outside the domain of \`eval_hermite\`
* `#11114 <https://github.com/scipy/scipy/pull/11114>`__: BUG: special: fix \`hyp1f1\` for nonnegative integral \`a\` and...
* `#11115 <https://github.com/scipy/scipy/pull/11115>`__: DOC: special: add docstrings for \`kei\`, \`ker\`, \`keip\`,...
* `#11130 <https://github.com/scipy/scipy/pull/11130>`__: ENH: support for circular input
* `#11136 <https://github.com/scipy/scipy/pull/11136>`__: BUG: expm handling of empty input
* `#11138 <https://github.com/scipy/scipy/pull/11138>`__: DOC: stylistic consistency, punctuation, etc.
* `#11139 <https://github.com/scipy/scipy/pull/11139>`__: MAINT: cluster: use cython_blas, remove handwritten BLAS wrappers
* `#11146 <https://github.com/scipy/scipy/pull/11146>`__: DOC: update docs on bp parameter for detrend
* `#11151 <https://github.com/scipy/scipy/pull/11151>`__: DOC: special: add docstrings for \`bei\`, \`ber\`, \`beip\`,...
* `#11156 <https://github.com/scipy/scipy/pull/11156>`__: ENH: add input validation for ellipord.
* `#11157 <https://github.com/scipy/scipy/pull/11157>`__: DOC: stylistic revision, punctuation, consistency
* `#11160 <https://github.com/scipy/scipy/pull/11160>`__: ignore warning on 0 \* inf in basin hopping
* `#11162 <https://github.com/scipy/scipy/pull/11162>`__: DOC: minor stylistic revision, undo changes
* `#11164 <https://github.com/scipy/scipy/pull/11164>`__: ENH/ BUG: Pydata sparse equality
* `#11171 <https://github.com/scipy/scipy/pull/11171>`__: Fix dtype validation of "seuclidean" metric V parameter
* `#11177 <https://github.com/scipy/scipy/pull/11177>`__: BUG: stats: Improve genpareto stats calculations.
* `#11180 <https://github.com/scipy/scipy/pull/11180>`__: MAINT: stats: Some clean up in test_distributions.py.
* `#11187 <https://github.com/scipy/scipy/pull/11187>`__: ENH: add functionality log_softmax to SciPy.special.
* `#11188 <https://github.com/scipy/scipy/pull/11188>`__: MAINT: add rvs method to argus in scipy.stats
* `#11196 <https://github.com/scipy/scipy/pull/11196>`__: DOC: special: add to docstrings of Kelvin zeros functions
* `#11202 <https://github.com/scipy/scipy/pull/11202>`__: BUG: fix edge counting in shortest_path
* `#11218 <https://github.com/scipy/scipy/pull/11218>`__: BUG: scipy/interpolate: fix PPoly/Cubic\*Spline roots() extrapolation...
* `#11225 <https://github.com/scipy/scipy/pull/11225>`__: Add a warning to constant input for spearmanr() function
* `#11226 <https://github.com/scipy/scipy/pull/11226>`__: Speed up of interior-point method for cholesky solver
* `#11229 <https://github.com/scipy/scipy/pull/11229>`__: BUG: Explicit dtype specification in _upfirdn.py
* `#11230 <https://github.com/scipy/scipy/pull/11230>`__: Additional citation for optimize tutorial
* `#11231 <https://github.com/scipy/scipy/pull/11231>`__: Adds SLSQP test for duplicate f-evals (#10738)
* `#11236 <https://github.com/scipy/scipy/pull/11236>`__: MAINT: Improved error message for Wn range in iirfilter.
* `#11245 <https://github.com/scipy/scipy/pull/11245>`__: ENH: optimize: dense redundancy removal routine optimizations
* `#11247 <https://github.com/scipy/scipy/pull/11247>`__: MAINT: Remove _lib/_numpy_compat.py
* `#11248 <https://github.com/scipy/scipy/pull/11248>`__: BUG: rv_discrete.ppf() to handle loc
* `#11251 <https://github.com/scipy/scipy/pull/11251>`__: DOC: add reference for linesearch zoom algorithm
* `#11253 <https://github.com/scipy/scipy/pull/11253>`__: BUG: fix kendalltau issue where p-value becomes >1
* `#11254 <https://github.com/scipy/scipy/pull/11254>`__: MAINT: make special.factorial handle nan correctly
* `#11256 <https://github.com/scipy/scipy/pull/11256>`__: DOC: Updated documentation for scipy.linalg.qr
* `#11265 <https://github.com/scipy/scipy/pull/11265>`__: Fix: Can no longer slice csr_matrix in 1.3.0
* `#11267 <https://github.com/scipy/scipy/pull/11267>`__: BUG: Rework the scaling in the ks_2samp two-sided exact test.
* `#11268 <https://github.com/scipy/scipy/pull/11268>`__: DOC: example of NonLinearConstraint
* `#11269 <https://github.com/scipy/scipy/pull/11269>`__: Fix: Sparse matrix constructor data type detection changes on...
* `#11276 <https://github.com/scipy/scipy/pull/11276>`__: BLD: update minimum Python, NumPy, Cython, Pybind11 versions
* `#11277 <https://github.com/scipy/scipy/pull/11277>`__: MAINT: Cleanup conditionals for unsupported numpy verisons
* `#11278 <https://github.com/scipy/scipy/pull/11278>`__: MAINT: Cleanup stats.iqr workarounds for unsupported NumPy versions
* `#11282 <https://github.com/scipy/scipy/pull/11282>`__: TST/CI: improve traceback formatting for test failures
* `#11284 <https://github.com/scipy/scipy/pull/11284>`__: fix docs & behavior for mode sequences in ndimage filters
* `#11285 <https://github.com/scipy/scipy/pull/11285>`__: DOC: special: complete the docstrings of Chi-square functions
* `#11286 <https://github.com/scipy/scipy/pull/11286>`__: BUG: make loadmat/savemat file opening close resources correctly
* `#11287 <https://github.com/scipy/scipy/pull/11287>`__: CI: skip Azure and TravisCI builds on merges and direct pushes...
* `#11288 <https://github.com/scipy/scipy/pull/11288>`__: DOC: Fix import in scipy.io.wavfile.read sample code
* `#11289 <https://github.com/scipy/scipy/pull/11289>`__: BUG: Use context manager for open
* `#11290 <https://github.com/scipy/scipy/pull/11290>`__: MAINT: Remove _lib._version in favour of _lib._pep440
* `#11292 <https://github.com/scipy/scipy/pull/11292>`__: DOC: special: add docstrings for various convenience functions
* `#11293 <https://github.com/scipy/scipy/pull/11293>`__: DOC: special: fix typo in \`chdtri\` docstring
* `#11296 <https://github.com/scipy/scipy/pull/11296>`__: DOC: special: add to docstrings of Bessel zeros and derivatives
* `#11297 <https://github.com/scipy/scipy/pull/11297>`__: DOC: special: add parameters/returns sections for Bessel integrals
* `#11300 <https://github.com/scipy/scipy/pull/11300>`__: MAINT: Update vendored uarray version
* `#11301 <https://github.com/scipy/scipy/pull/11301>`__: CI: azure conditions should require succeeded()
* `#11302 <https://github.com/scipy/scipy/pull/11302>`__: ENH: build infrastructure for ILP64 BLAS + ARPACK conversion
* `#11303 <https://github.com/scipy/scipy/pull/11303>`__: DOC: special: fix typo in \`besselpoly\` docstring
* `#11304 <https://github.com/scipy/scipy/pull/11304>`__: ENH: MAINT: Rewrite of eigh() and relevant wrappers
* `#11306 <https://github.com/scipy/scipy/pull/11306>`__: TST: skip test_aligned_mem linalg test that is crashing on ppcle64
* `#11307 <https://github.com/scipy/scipy/pull/11307>`__: MAINT: Fix typo 'solutuion' -> 'solution'
* `#11308 <https://github.com/scipy/scipy/pull/11308>`__: ENH: do not create 1d array out of a scalar
* `#11310 <https://github.com/scipy/scipy/pull/11310>`__: MAINT: clean up object array creation, scalar/1d confusion
* `#11311 <https://github.com/scipy/scipy/pull/11311>`__: DOC: Specify custom callable option for metric in cluster.hierarchy.fclusterdata
* `#11316 <https://github.com/scipy/scipy/pull/11316>`__: BUG: special: fix behavior for \`rgamma\` zeros
* `#11317 <https://github.com/scipy/scipy/pull/11317>`__: BUG: fix floating-point literal comparisons under C99
* `#11318 <https://github.com/scipy/scipy/pull/11318>`__: TST: optimize: mark two linprog tests for skipping
* `#11320 <https://github.com/scipy/scipy/pull/11320>`__: BUG: Include \`int64_t\` declaration to \`rectangular_lsap.cpp\`
* `#11330 <https://github.com/scipy/scipy/pull/11330>`__: MAINT: Update vendored pypocketfft version
* `#11333 <https://github.com/scipy/scipy/pull/11333>`__: BUG: directed_hausdorff subset fix
* `#11335 <https://github.com/scipy/scipy/pull/11335>`__: [ENH] sparse: Loosen check for sparse outer indexing fast path
* `#11337 <https://github.com/scipy/scipy/pull/11337>`__: Undefined name 'e' in pavement.py
* `#11338 <https://github.com/scipy/scipy/pull/11338>`__: scipyoptdoc.py: Remove unused variable 'sixu'
* `#11340 <https://github.com/scipy/scipy/pull/11340>`__: xrange() was removed in Python 3 in favor of range()
* `#11342 <https://github.com/scipy/scipy/pull/11342>`__: range() was removed in Py3 in _binned_statistic.py
* `#11343 <https://github.com/scipy/scipy/pull/11343>`__: BUG: constants: fix 'exact' values table
* `#11347 <https://github.com/scipy/scipy/pull/11347>`__: ENH: add input validation function and apply it to needed functions
* `#11348 <https://github.com/scipy/scipy/pull/11348>`__: MAINT: remove six.string_types usages
* `#11349 <https://github.com/scipy/scipy/pull/11349>`__: MAINT: minor doc fix _minimize_trustregion_constr
* `#11353 <https://github.com/scipy/scipy/pull/11353>`__: MAINT: py3 remove various six usages
* `#11358 <https://github.com/scipy/scipy/pull/11358>`__: ENH: optimize: Use CSR format instead of LIL for speed
* `#11362 <https://github.com/scipy/scipy/pull/11362>`__: MAINT: sys.version_info >= 3.5
* `#11364 <https://github.com/scipy/scipy/pull/11364>`__: ENH: cache square of sums for f_oneway
* `#11368 <https://github.com/scipy/scipy/pull/11368>`__: ENH: add optional argument, "include_nyquist", for freqz()
* `#11372 <https://github.com/scipy/scipy/pull/11372>`__: BENCH: optimize: added linprog presolve benchmarks
* `#11376 <https://github.com/scipy/scipy/pull/11376>`__: ENH: Add wrapper for ?gttrf/?gttrs
* `#11377 <https://github.com/scipy/scipy/pull/11377>`__: MAINT: Remove Python 2 code from tools/authors.py
* `#11378 <https://github.com/scipy/scipy/pull/11378>`__: ENH (WIP): Python wrapper for ?tbtrs
* `#11379 <https://github.com/scipy/scipy/pull/11379>`__: MAINT: Remove six.with_metaclass from benchmarks/cython_special.py
* `#11380 <https://github.com/scipy/scipy/pull/11380>`__: BUG: sparse/isolve: bicg and qmr don't treat x0 correctly
* `#11382 <https://github.com/scipy/scipy/pull/11382>`__: MAINT: remove error throw in binned_statistic_dd() on non-finite...
* `#11383 <https://github.com/scipy/scipy/pull/11383>`__: MAINT: _lib: remove py2 compat shims in getargspec
* `#11384 <https://github.com/scipy/scipy/pull/11384>`__: MAINT: Use numpy scalar types directly
* `#11385 <https://github.com/scipy/scipy/pull/11385>`__: ENH: special: add spherical Bessel functions to \`cython_special\`
* `#11389 <https://github.com/scipy/scipy/pull/11389>`__: MAINT: line.startswith shouldn't be bytes
* `#11393 <https://github.com/scipy/scipy/pull/11393>`__: ENH: Speed up truncnorm's ppf()and rvs() methods
* `#11394 <https://github.com/scipy/scipy/pull/11394>`__: MAINT: Remove self._size (and self._random_state) from stats...
* `#11395 <https://github.com/scipy/scipy/pull/11395>`__: correction in error message (%d->%g format)
* `#11396 <https://github.com/scipy/scipy/pull/11396>`__: DOC: revert gh10540, removing mtrand
* `#11397 <https://github.com/scipy/scipy/pull/11397>`__: MAINT: differential_evolution accepts np.random.Generator
* `#11402 <https://github.com/scipy/scipy/pull/11402>`__: ENH: stats can use np.random.Generator
* `#11404 <https://github.com/scipy/scipy/pull/11404>`__: ENH: add docstring of butter() for transfer function syntax problem
* `#11405 <https://github.com/scipy/scipy/pull/11405>`__: DOC: Fix "see also" for SmoothBivariateSpline
* `#11408 <https://github.com/scipy/scipy/pull/11408>`__: ENH: Add a \`plan\` argument to FFT functions in \`scipy.fft\`
* `#11411 <https://github.com/scipy/scipy/pull/11411>`__: MAINT: check minimize duplicate evaluations
* `#11418 <https://github.com/scipy/scipy/pull/11418>`__: ENH: Linalg: Python wrapper for ?geqrfp
* `#11419 <https://github.com/scipy/scipy/pull/11419>`__: TST: Python 3.7 mac OS gcc multibuild fix
* `#11423 <https://github.com/scipy/scipy/pull/11423>`__: ENH: Add tool to lint diffs
* `#11425 <https://github.com/scipy/scipy/pull/11425>`__: FIX: _array_newton should preserve complex inputs
* `#11426 <https://github.com/scipy/scipy/pull/11426>`__: MAINT: licence for global optimization benchmarks
* `#11431 <https://github.com/scipy/scipy/pull/11431>`__: Make median_absolute_deviation scale argument aligned w/iqr
* `#11432 <https://github.com/scipy/scipy/pull/11432>`__: Fix error message typo
* `#11433 <https://github.com/scipy/scipy/pull/11433>`__: DOC: Remove L from longs
* `#11434 <https://github.com/scipy/scipy/pull/11434>`__: MAINT: Python3 improvements to refguide_check.py
* `#11435 <https://github.com/scipy/scipy/pull/11435>`__: DOC: Update runtest --parallel help
* `#11436 <https://github.com/scipy/scipy/pull/11436>`__: MAINT: Remove checks for sys.version < 3.5
* `#11437 <https://github.com/scipy/scipy/pull/11437>`__: DOC: Fix documentation issue
* `#11439 <https://github.com/scipy/scipy/pull/11439>`__: Support path objects (PEP 519) in mmio functions
* `#11440 <https://github.com/scipy/scipy/pull/11440>`__: correct bounds pass in run_dualannealing for benchmarks/optimize.py
* `#11443 <https://github.com/scipy/scipy/pull/11443>`__: BENCH: optimize_linprog remove ImportError exception
* `#11453 <https://github.com/scipy/scipy/pull/11453>`__: BUG: sparse: convert csc/csr indices to int64 as needed
* `#11454 <https://github.com/scipy/scipy/pull/11454>`__: DOC: Remove caveat on \`maximum_bipartite_matching\`
* `#11455 <https://github.com/scipy/scipy/pull/11455>`__: BUG: Fix _lib._util.getargspec_no_self lack of KEYWORD_ONLY support.
* `#11456 <https://github.com/scipy/scipy/pull/11456>`__: Implementation of khatri_rao product
* `#11459 <https://github.com/scipy/scipy/pull/11459>`__: BUG: fix augmentation being broken in maximum_bipartite_matching
* `#11461 <https://github.com/scipy/scipy/pull/11461>`__: MAINT: minor spelling corrections in comments in SciPy.sparse.linalg.arpack
* `#11467 <https://github.com/scipy/scipy/pull/11467>`__: [MRG] Make result data type of KDE evaluation like in the input...
* `#11469 <https://github.com/scipy/scipy/pull/11469>`__: Update integrate.quad documentation
* `#11472 <https://github.com/scipy/scipy/pull/11472>`__: Fixed result typo
* `#11476 <https://github.com/scipy/scipy/pull/11476>`__: DOC: stats: Copy-edit the anderson docstring.
* `#11478 <https://github.com/scipy/scipy/pull/11478>`__: ENH: avoid unnecessary array copies in matrix product
* `#11481 <https://github.com/scipy/scipy/pull/11481>`__: BUG: Make special.hyperu return nan if any argument is nan
* `#11483 <https://github.com/scipy/scipy/pull/11483>`__: BUG: Fixed \`_kpp\` initialization on \`scipy.cluster.vq\`, closing...
* `#11485 <https://github.com/scipy/scipy/pull/11485>`__: ENH: Update docstring of class KrylovJacobian to fix #2744
* `#11486 <https://github.com/scipy/scipy/pull/11486>`__: BUG: make special.eval_hermite return nan if second argument...
* `#11487 <https://github.com/scipy/scipy/pull/11487>`__: ENH: improve docstring of correlate and correlate2d to fix #1968
* `#11488 <https://github.com/scipy/scipy/pull/11488>`__: FIX: change "func -> fun" of scipy.optimize _root.py to solve...
* `#11489 <https://github.com/scipy/scipy/pull/11489>`__: BUG: fixes typo introduced in PR #11253 in stats.mstats.kendalltau()
* `#11490 <https://github.com/scipy/scipy/pull/11490>`__: DOC: fix typo in scipy/io/matlab/mio4.py
* `#11495 <https://github.com/scipy/scipy/pull/11495>`__: MAINT: refactor slsqp to fix issue in callback function
* `#11498 <https://github.com/scipy/scipy/pull/11498>`__: [DOC] mention graph cuts in maximum flow docstring
* `#11499 <https://github.com/scipy/scipy/pull/11499>`__: DOC: Improve documentation of scipy.signal.signaltools.wiener
* `#11506 <https://github.com/scipy/scipy/pull/11506>`__: DOC: Fix typo in documentation of scipy.stats.morestats
* `#11508 <https://github.com/scipy/scipy/pull/11508>`__: ENH: avoid copy on sparse __init__ when dtype is given
* `#11509 <https://github.com/scipy/scipy/pull/11509>`__: ENH: avoid unnecessary array copies in matrix product (again)
* `#11510 <https://github.com/scipy/scipy/pull/11510>`__: [DOC] An ex. for creating arbitrary size tri-diagonal
* `#11511 <https://github.com/scipy/scipy/pull/11511>`__: TST: pin numba for Travis/sparse
* `#11513 <https://github.com/scipy/scipy/pull/11513>`__: TST: disable NumPy cache dir ppc64le
* `#11514 <https://github.com/scipy/scipy/pull/11514>`__: BUG: make special.eval_genlaguerre return nan if passed nan
* `#11517 <https://github.com/scipy/scipy/pull/11517>`__: ENH: improve sparse.lil.tocsr performance
* `#11519 <https://github.com/scipy/scipy/pull/11519>`__: Fix fresnel documentation
* `#11520 <https://github.com/scipy/scipy/pull/11520>`__: BUG: make special.eval_gegenbauer return nan if passed nan
* `#11524 <https://github.com/scipy/scipy/pull/11524>`__: ENH: Cosine Sine Decomposition
* `#11526 <https://github.com/scipy/scipy/pull/11526>`__: BUG: fix SLSQP max iteration setting to fix #4921
* `#11527 <https://github.com/scipy/scipy/pull/11527>`__: ENH: improve docstring of weibull_min_gen and weibull_max_gen...
* `#11530 <https://github.com/scipy/scipy/pull/11530>`__: MAINT: Removed 3 unused imports, 3 unused assignments from ndimage.
* `#11531 <https://github.com/scipy/scipy/pull/11531>`__: DOC: fix typos in bdtr and bdtrc from gh PR 11045
* `#11532 <https://github.com/scipy/scipy/pull/11532>`__: MAINT: Fixed several unused imports and unused assignments from...
* `#11533 <https://github.com/scipy/scipy/pull/11533>`__: MAINT: Fixed about 100 unused imports, unused assignment warnings...
* `#11534 <https://github.com/scipy/scipy/pull/11534>`__: FIX: Allow non-native byte order inputs to scipy.fft
* `#11535 <https://github.com/scipy/scipy/pull/11535>`__: MAINT: Fixed several unused imports in _lib.
* `#11536 <https://github.com/scipy/scipy/pull/11536>`__: MAINT: Fixed several unused imports and unused assignments in...
* `#11537 <https://github.com/scipy/scipy/pull/11537>`__: MAINT: Removed an unused import in scipy/constants.
* `#11538 <https://github.com/scipy/scipy/pull/11538>`__: MAINT: Fixed several unused imports in scipy/fft.
* `#11539 <https://github.com/scipy/scipy/pull/11539>`__: MAINT: Fixed several unused imports and unused assignments in...
* `#11540 <https://github.com/scipy/scipy/pull/11540>`__: MAINT: Fixed two unused imports in scipy/misc.
* `#11541 <https://github.com/scipy/scipy/pull/11541>`__: MAINT: Fixed several unused imports and unused assignments in...
* `#11542 <https://github.com/scipy/scipy/pull/11542>`__: MAINT: Fixed an unused import in scipy/odr.
* `#11543 <https://github.com/scipy/scipy/pull/11543>`__: MAINT: Fixed several unused imports and unused assignments in...
* `#11544 <https://github.com/scipy/scipy/pull/11544>`__: MAINT: Fixed unused imports and unused assignments in scipy/integrate.
* `#11545 <https://github.com/scipy/scipy/pull/11545>`__: MAINT: Removed unused imports and fixed unused assignments in...
* `#11546 <https://github.com/scipy/scipy/pull/11546>`__: MAINT: Removed unused imports; fixed unused assignments in scipy/signal.
* `#11547 <https://github.com/scipy/scipy/pull/11547>`__: MAINT: Removed unused imports; fixed unused assignments in scipy/spatial
* `#11548 <https://github.com/scipy/scipy/pull/11548>`__: MAINT: Removed unused imports; fixed unused assignments in scipy.sparse.
* `#11549 <https://github.com/scipy/scipy/pull/11549>`__: MAINT: Replace xrange with range
* `#11560 <https://github.com/scipy/scipy/pull/11560>`__: MAINT: stats: remove an _argcheck call
* `#11573 <https://github.com/scipy/scipy/pull/11573>`__: MAINT: Removed unused imports; fixed unused assignments in scipy/stats.
* `#11574 <https://github.com/scipy/scipy/pull/11574>`__: MAINT: Small change to \`optimize.nnls\` error messages.
* `#11575 <https://github.com/scipy/scipy/pull/11575>`__: MAINT: Update sytrd/hetrd tests
* `#11582 <https://github.com/scipy/scipy/pull/11582>`__: MAINT: fix typo in quadpack.py closes #11448
* `#11585 <https://github.com/scipy/scipy/pull/11585>`__: TST: add openblas_support.py
* `#11587 <https://github.com/scipy/scipy/pull/11587>`__: BUG: Differential evolution with LinearConstraint with sparse...
* `#11588 <https://github.com/scipy/scipy/pull/11588>`__: MAINT: Fully display problem size in lsmr/lsqr.
* `#11589 <https://github.com/scipy/scipy/pull/11589>`__: MAINT: Remove Python 2 workarounds
* `#11590 <https://github.com/scipy/scipy/pull/11590>`__: MAINT: Remove Python2 module init
* `#11605 <https://github.com/scipy/scipy/pull/11605>`__: Standardization of bounds in _linprog_util.py
* `#11608 <https://github.com/scipy/scipy/pull/11608>`__: BUG: fix use of is in DE callback
* `#11614 <https://github.com/scipy/scipy/pull/11614>`__: TST, MAINT: TestCtypesQuad skip with pytest
* `#11619 <https://github.com/scipy/scipy/pull/11619>`__: ENH: add nan_policy argument and functionality to stats.mstats.winsorize
* `#11621 <https://github.com/scipy/scipy/pull/11621>`__: MAINT: Cleanup uses of PY_VERSION_HEX, NPY_PY3K in ndimage
* `#11622 <https://github.com/scipy/scipy/pull/11622>`__: MAINT: Cleanup uses of PY_VERSION_HEX, NPY_PY3K in sparse
* `#11623 <https://github.com/scipy/scipy/pull/11623>`__: MAINT: Remove unnecessary 'from __future__ import ...' statements
* `#11626 <https://github.com/scipy/scipy/pull/11626>`__: MAINT: Cleanup uses of PY_VERSION_HEX
* `#11627 <https://github.com/scipy/scipy/pull/11627>`__: ENH: add analytic formula for normal moments
* `#11628 <https://github.com/scipy/scipy/pull/11628>`__: MAINT, TST: adjust azure for matplotlib release
* `#11631 <https://github.com/scipy/scipy/pull/11631>`__: Revert to old behaviour for constant cost matrices in \`linear_sum_assignment\`
* `#11632 <https://github.com/scipy/scipy/pull/11632>`__: MAINT: Define ARRAY_ANYORDER with DEF instead of cdef
* `#11639 <https://github.com/scipy/scipy/pull/11639>`__: BUG: interpolate/interp1d: fail gracefully on all-nan inputs
* `#11640 <https://github.com/scipy/scipy/pull/11640>`__: MAINT: Fix BLAS3 trmm wrapper for "side" arg
* `#11642 <https://github.com/scipy/scipy/pull/11642>`__: TST, MAINT: remove dead code in Travis CI
* `#11643 <https://github.com/scipy/scipy/pull/11643>`__: MAINT: fix conversion in binom_test
* `#11645 <https://github.com/scipy/scipy/pull/11645>`__: MAINT: Assorted clean up.
* `#11646 <https://github.com/scipy/scipy/pull/11646>`__: MAINT: Remove unnecessary 'from __future__ import ...' statements
* `#11647 <https://github.com/scipy/scipy/pull/11647>`__: DOC: document return_all arguments
* `#11648 <https://github.com/scipy/scipy/pull/11648>`__: Perform geometric slerp in quaternion space
* `#11651 <https://github.com/scipy/scipy/pull/11651>`__: DOC: Update paper URL in lambertw documentation
* `#11653 <https://github.com/scipy/scipy/pull/11653>`__: PERF: Switch to C++ STL std::nth_element
* `#11655 <https://github.com/scipy/scipy/pull/11655>`__: MAINT: Remove Python2 cStringStream
* `#11657 <https://github.com/scipy/scipy/pull/11657>`__: ENH: Add wrapper for ?pttrf/?pttrs
* `#11664 <https://github.com/scipy/scipy/pull/11664>`__: ENH: Add wrapper for ?gejsv
* `#11665 <https://github.com/scipy/scipy/pull/11665>`__: ENH: Add wrapper for ?pteqr
* `#11667 <https://github.com/scipy/scipy/pull/11667>`__: BUG: Non-central Fisher distribution (fix nan-values when nc=0)
* `#11668 <https://github.com/scipy/scipy/pull/11668>`__: ENH: Add wrapper for ?gtsvx
* `#11671 <https://github.com/scipy/scipy/pull/11671>`__: TST, CI: restore Azure temporarily
* `#11672 <https://github.com/scipy/scipy/pull/11672>`__: Add warning to medfilt when array size < kernel_size
* `#11674 <https://github.com/scipy/scipy/pull/11674>`__: TST: bump test precision for two np.dot related linalg tests.
* `#11675 <https://github.com/scipy/scipy/pull/11675>`__: MAINT: pycodestyle clean-up
* `#11677 <https://github.com/scipy/scipy/pull/11677>`__: ENH: Add wrapper for ?ptsvx
* `#11679 <https://github.com/scipy/scipy/pull/11679>`__: BENCH: cKDTree benchmarks added: balanced/unbalanced tree (related...
* `#11680 <https://github.com/scipy/scipy/pull/11680>`__: MAINT: rng_integers allows RandomState.randint or Generator.integers
* `#11683 <https://github.com/scipy/scipy/pull/11683>`__: BUG: fix mode='mirror' on length 1 axes
* `#11684 <https://github.com/scipy/scipy/pull/11684>`__: BUG: fix scipy.special.voigt_profile
* `#11687 <https://github.com/scipy/scipy/pull/11687>`__: MAINT: sparse.linalg: avoid importing from \`np.core\`
* `#11688 <https://github.com/scipy/scipy/pull/11688>`__: ENH: mypy: get specific about ignoring missing imports
* `#11690 <https://github.com/scipy/scipy/pull/11690>`__: MAINT: mypy: fix errors about incompatible types in lists
* `#11692 <https://github.com/scipy/scipy/pull/11692>`__: MAINT: mypy: fix remaining type errors
* `#11694 <https://github.com/scipy/scipy/pull/11694>`__: TST, MAINT: bump to OpenBLAS 0.3.9 stable, raise tol for Win...
* `#11697 <https://github.com/scipy/scipy/pull/11697>`__: DOC: fix pdf of norminvgauss in scipy.stats
* `#11701 <https://github.com/scipy/scipy/pull/11701>`__: MAINT: special: add rudimentary types for \`_ufuncs\` extension...
* `#11702 <https://github.com/scipy/scipy/pull/11702>`__: BUG: Fixed a post-merge bug for eigh()
* `#11703 <https://github.com/scipy/scipy/pull/11703>`__: Improves docstring with consistent L2-norm
* `#11705 <https://github.com/scipy/scipy/pull/11705>`__: DOC: Slerp the SphericalVoronoi docstring
* `#11706 <https://github.com/scipy/scipy/pull/11706>`__: ENH: mypy: add \`--mypy\` option to \`runtests.py\`
* `#11710 <https://github.com/scipy/scipy/pull/11710>`__: ENH: Modified stats.kstest() to use the exact stats.kstwo.sf()...
* `#11715 <https://github.com/scipy/scipy/pull/11715>`__: DOC: add .. versionadded:: to as_matrix/from_matrix in spatial/transf…
* `#11716 <https://github.com/scipy/scipy/pull/11716>`__: BENCH: fix benchmark imports for \`\`optimize_linprog.py\`\`
* `#11721 <https://github.com/scipy/scipy/pull/11721>`__: MAINT: io: Remove now-unnecessary \`# type: ignore\`
* `#11722 <https://github.com/scipy/scipy/pull/11722>`__: MAINT: mypy: remove mpmath from the ratchet
* `#11726 <https://github.com/scipy/scipy/pull/11726>`__: Handle constant input for scipy.stats.f_oneway
* `#11729 <https://github.com/scipy/scipy/pull/11729>`__: BENCH: optimize: added infeasible benchmarks for linprog
* `#11731 <https://github.com/scipy/scipy/pull/11731>`__: fix inaccurate information about Mac OS compiler (#11696)
* `#11733 <https://github.com/scipy/scipy/pull/11733>`__: Fix inaccurate docstring example of HalfspaceIntersection
* `#11734 <https://github.com/scipy/scipy/pull/11734>`__: Doc: fix inaccurate docstring of SmoothBivariateSpline.
* `#11735 <https://github.com/scipy/scipy/pull/11735>`__: Bug: stats: fix wrong shape from median_absolute_deviation for...
* `#11736 <https://github.com/scipy/scipy/pull/11736>`__: ENH: add input validations and its tests for FITPACK in fitpack2.py
* `#11737 <https://github.com/scipy/scipy/pull/11737>`__: BUG: Prevent crashes due to MKL bug in ?heevr
* `#11739 <https://github.com/scipy/scipy/pull/11739>`__: MAINT: special: add type stubs for \`_test_round.pyx\`
* `#11740 <https://github.com/scipy/scipy/pull/11740>`__: MAINT: special: remove unused specfun f2py wrappers
* `#11741 <https://github.com/scipy/scipy/pull/11741>`__: BUG: fix small tolerances handling for minpack and add a test.
* `#11743 <https://github.com/scipy/scipy/pull/11743>`__: Doc: fix docstring of rfft, rfft2, rfftn, irfft, irfft2, irfftn...
* `#11744 <https://github.com/scipy/scipy/pull/11744>`__: MAINT: Remove unused py3k.h code
* `#11745 <https://github.com/scipy/scipy/pull/11745>`__: DOC: stats: Clean up ncf documentation.
* `#11748 <https://github.com/scipy/scipy/pull/11748>`__: MAINT: special: type \`cython_special\` as \`Any\`
* `#11750 <https://github.com/scipy/scipy/pull/11750>`__: MAINT: type hints for \`_spherical_voronoi\`
* `#11752 <https://github.com/scipy/scipy/pull/11752>`__: DOC: fix docstring of scipy.optimize.least_squares
* `#11753 <https://github.com/scipy/scipy/pull/11753>`__: ENH: add input validation for dendrogram and a test.
* `#11755 <https://github.com/scipy/scipy/pull/11755>`__: MAINT: Replace uses of tostring with tobytes
* `#11757 <https://github.com/scipy/scipy/pull/11757>`__: ENH: improve binned_statistics_2d performance.
* `#11759 <https://github.com/scipy/scipy/pull/11759>`__: ENH: optimize: add HiGHS methods to linprog
* `#11760 <https://github.com/scipy/scipy/pull/11760>`__: MAINT: Remove FileStream replaced by GenericStream
* `#11761 <https://github.com/scipy/scipy/pull/11761>`__: MAINT: Replace npy_3kcompat.h shims
* `#11765 <https://github.com/scipy/scipy/pull/11765>`__: TST: Speedup test_pascal which is VERY slow on Azure
* `#11766 <https://github.com/scipy/scipy/pull/11766>`__: TST: speed up differential_evolution L8 test
* `#11767 <https://github.com/scipy/scipy/pull/11767>`__: Change comment in continuous rv gamma fit function
* `#11776 <https://github.com/scipy/scipy/pull/11776>`__: Add domain option for resample.
* `#11784 <https://github.com/scipy/scipy/pull/11784>`__: BUG: Fixed calculation of nonzero elements in scipy.sparse.random
* `#11786 <https://github.com/scipy/scipy/pull/11786>`__: ENH: stats: add axis keyword argument to scipy.stats.rankdata
* `#11789 <https://github.com/scipy/scipy/pull/11789>`__: Doc: fix docstring of scipy.spatial.chebyshev
* `#11792 <https://github.com/scipy/scipy/pull/11792>`__: DOC: dev: add guidelines for developing public Cython APIs
* `#11794 <https://github.com/scipy/scipy/pull/11794>`__: MAINT: add comments explaining a problem in cython_optimize organization
* `#11796 <https://github.com/scipy/scipy/pull/11796>`__: DOC: add a note about precision losing in csgraph.minimum_spanning_tree...
* `#11797 <https://github.com/scipy/scipy/pull/11797>`__: ENH: Allow negative \`axis\` in \`interpolate.BSpline\`. Also...
* `#11798 <https://github.com/scipy/scipy/pull/11798>`__: Add simplify_cells parameter to scipy.io.loadmat
* `#11801 <https://github.com/scipy/scipy/pull/11801>`__: MAINT, DOC: minor changes of ratio-of-uniforms in scipy.stats
* `#11802 <https://github.com/scipy/scipy/pull/11802>`__: BUG: fix scipy.odr to handle multidimensional independent and...
* `#11803 <https://github.com/scipy/scipy/pull/11803>`__: scipy.stats.trapz: Use analytic formulas for stats and entropy.
* `#11808 <https://github.com/scipy/scipy/pull/11808>`__: DOC: add Examples in the scipy.interpolate.interpn docstring.
* `#11809 <https://github.com/scipy/scipy/pull/11809>`__: Duplicate entries are added together in csr_matrix constructor
* `#11813 <https://github.com/scipy/scipy/pull/11813>`__: MAINT: bump pyflakes to version 2.1.1
* `#11814 <https://github.com/scipy/scipy/pull/11814>`__: BUG: scipy.sparse.csr doctest failing with incorrect output value
* `#11817 <https://github.com/scipy/scipy/pull/11817>`__: DOC: add Examples in the scipy.optimize.leastsq docstring
* `#11820 <https://github.com/scipy/scipy/pull/11820>`__: ENH: Raise an error on incorrect bounds format in optimize.fmin_l_bfgs_b
* `#11822 <https://github.com/scipy/scipy/pull/11822>`__: CI: add github actions for macOS
* `#11824 <https://github.com/scipy/scipy/pull/11824>`__: DOC: add Examples in scipy.optimize.line_search docstring (line_search_wolfe2)
* `#11830 <https://github.com/scipy/scipy/pull/11830>`__: TST: Always use fork for multiprocessing in fft tests
* `#11831 <https://github.com/scipy/scipy/pull/11831>`__: DOC: add Examples and Returns in scipy.misc.central_diff_weights...
* `#11832 <https://github.com/scipy/scipy/pull/11832>`__: DOC: stats: Some small corrections to a couple docstrings.
* `#11833 <https://github.com/scipy/scipy/pull/11833>`__: BUG: Fix compiler_name when there are paths used in flags
* `#11836 <https://github.com/scipy/scipy/pull/11836>`__: MAINT: re-introduce multiprocessing tests on Python3.8
* `#11837 <https://github.com/scipy/scipy/pull/11837>`__: Doc: add Examples in scipy.optimize.fsolve docstring
* `#11838 <https://github.com/scipy/scipy/pull/11838>`__: Doc: add Examples in scipy.sparse.linalg.minres docstring
* `#11840 <https://github.com/scipy/scipy/pull/11840>`__: BUG: sparse.linalg: fix overflow in expm intermediate computation
* `#11842 <https://github.com/scipy/scipy/pull/11842>`__: BLD: fix build with gfortran 10
* `#11843 <https://github.com/scipy/scipy/pull/11843>`__: MAINT: Simplify floats in constants.py
* `#11847 <https://github.com/scipy/scipy/pull/11847>`__: DOC: add a tutorial of scipy.optimize.linprog
* `#11849 <https://github.com/scipy/scipy/pull/11849>`__: ENH: speed up geninvgauss by using cython
* `#11852 <https://github.com/scipy/scipy/pull/11852>`__: CI: remove osx from travisCI
* `#11857 <https://github.com/scipy/scipy/pull/11857>`__: BUG: Change parameter fc of gausspulse to float.
* `#11861 <https://github.com/scipy/scipy/pull/11861>`__: order = degree + 1 for splines
* `#11863 <https://github.com/scipy/scipy/pull/11863>`__: Make g77 ABI wrapper work with gfortran ABI lapack
* `#11866 <https://github.com/scipy/scipy/pull/11866>`__: MAINT: add type ignores to sympy and matplotlib imports
* `#11867 <https://github.com/scipy/scipy/pull/11867>`__: CI: Add arm64 in travis-ci
* `#11869 <https://github.com/scipy/scipy/pull/11869>`__: DOC: signal: Add an example to the lsim2 docstring.
* `#11870 <https://github.com/scipy/scipy/pull/11870>`__: DOC: signal: Use impulse instead of impulse2 in the impulse example...
* `#11871 <https://github.com/scipy/scipy/pull/11871>`__: ENH: type ufuncs in special as ufuncs instead of Any
* `#11872 <https://github.com/scipy/scipy/pull/11872>`__: BUG: avoid recomputing in scipy.optimize.optimize.MemoizeJac
* `#11873 <https://github.com/scipy/scipy/pull/11873>`__: DOC: signal: Fix ODE in impulse and impulse2 docstrings.
* `#11874 <https://github.com/scipy/scipy/pull/11874>`__: DOC: add Examples of docstring for scipy.interpolate.approximate_taylor_polynomial
* `#11878 <https://github.com/scipy/scipy/pull/11878>`__: DOC: fixed a typo under scipy/integrate/quadrature.py
* `#11879 <https://github.com/scipy/scipy/pull/11879>`__: BUG: Fix index arrays overflow in sparse.kron
* `#11880 <https://github.com/scipy/scipy/pull/11880>`__: DOC: stats: Add Examples for bartlett, fligner, levene.
* `#11881 <https://github.com/scipy/scipy/pull/11881>`__: MAINT: normalise numpy-->np in optimize.py
* `#11882 <https://github.com/scipy/scipy/pull/11882>`__: DOC: add Examples for scipy.io.readsav docstring.
* `#11883 <https://github.com/scipy/scipy/pull/11883>`__: DOC: add Returns and Examples for scipy.ndimage.correlate() docstring
* `#11885 <https://github.com/scipy/scipy/pull/11885>`__: BUG: stats: Handle multidimensional arrays in f_oneway, and more.
* `#11889 <https://github.com/scipy/scipy/pull/11889>`__: DOC: signal: Unify lsim and lsim2 examples.
* `#11896 <https://github.com/scipy/scipy/pull/11896>`__: BUG: stats: Fix handling of size 0 inputs for ttest_rel and ttest_ind.
* `#11897 <https://github.com/scipy/scipy/pull/11897>`__: DOC: Remove misleading default values from fit method
* `#11898 <https://github.com/scipy/scipy/pull/11898>`__: MAINT: LinearVectorFunction.J is ndarray closes #11886
* `#11902 <https://github.com/scipy/scipy/pull/11902>`__: BUG: linalg: test_heequb failure
* `#11904 <https://github.com/scipy/scipy/pull/11904>`__: fix real-to-real transforms for complex inputs and overwrite_x=True
* `#11906 <https://github.com/scipy/scipy/pull/11906>`__: DOC: stats: fix error caused by trapz docstring
* `#11907 <https://github.com/scipy/scipy/pull/11907>`__: BUG: stats: fixed SEGFAULT from Issue #9710
* `#11912 <https://github.com/scipy/scipy/pull/11912>`__: ENH: Respect matplotlib color palette with hierarchy/dendrogram.
* `#11914 <https://github.com/scipy/scipy/pull/11914>`__: DOC: refine doc for spatial.distance.squareform
* `#11915 <https://github.com/scipy/scipy/pull/11915>`__: ENH: Ndim linear operator
* `#11919 <https://github.com/scipy/scipy/pull/11919>`__: ENH: expose "window_size" parameter in find_peaks_cwt()
* `#11920 <https://github.com/scipy/scipy/pull/11920>`__: DOC: explain M, diffev
* `#11923 <https://github.com/scipy/scipy/pull/11923>`__: CI: macOS install swig closes #11922
* `#11924 <https://github.com/scipy/scipy/pull/11924>`__: DOC: add Examples for scipy.optimize.bracket() docstring
* `#11930 <https://github.com/scipy/scipy/pull/11930>`__: DOC: add Examples and clean up for signal.qspline1d and signal.qspline_eval...
* `#11931 <https://github.com/scipy/scipy/pull/11931>`__: DOC: add Examples for sparse.linalg.bicg docstring.
* `#11933 <https://github.com/scipy/scipy/pull/11933>`__: DOC: Add original reference for Yao-Liu objective functions
* `#11934 <https://github.com/scipy/scipy/pull/11934>`__: DOC, MAINT: mailmap update
* `#11935 <https://github.com/scipy/scipy/pull/11935>`__: DOC: make scipy.stats.mode documentation reflect that the function...
* `#11936 <https://github.com/scipy/scipy/pull/11936>`__: ENH: special: add type stubs for \`orthogonal.py\`
* `#11937 <https://github.com/scipy/scipy/pull/11937>`__: DOC: Add docstring examples to fft2, ifft2, io.savemat
* `#11938 <https://github.com/scipy/scipy/pull/11938>`__: MAINT: add helper function for deprecating Cython API functions
* `#11942 <https://github.com/scipy/scipy/pull/11942>`__: MAINT: ignore conditional import in _lib/_util
* `#11943 <https://github.com/scipy/scipy/pull/11943>`__: MAINT: special: add types for geterr/seterr/errstate
* `#11946 <https://github.com/scipy/scipy/pull/11946>`__: MAINT: add py.typed marker
* `#11950 <https://github.com/scipy/scipy/pull/11950>`__: TST:MAINT: separated and stabilized heequb tests
* `#11952 <https://github.com/scipy/scipy/pull/11952>`__: DOC: update toolchain roadmap for py38, C99, C++11/14
* `#11957 <https://github.com/scipy/scipy/pull/11957>`__: MAINT: Use np.errstate context manager instead of np.seterr.
* `#11958 <https://github.com/scipy/scipy/pull/11958>`__: MAINT: interpolate: Remove some trailing spaces.
* `#11960 <https://github.com/scipy/scipy/pull/11960>`__: MAINT: Cleanup Python2 compatibility code
* `#11961 <https://github.com/scipy/scipy/pull/11961>`__: MAINT: Remove numpy/npy_3kcompat.h from _superluobject.c
* `#11962 <https://github.com/scipy/scipy/pull/11962>`__: DOC: Fix type of \`codes\` in docstring of \`_vq._vq()\`
* `#11964 <https://github.com/scipy/scipy/pull/11964>`__: MAINT: Cleanup unused IS_PYPY
* `#11969 <https://github.com/scipy/scipy/pull/11969>`__: DOC: add Examples and fix docstring for special.airye
* `#11970 <https://github.com/scipy/scipy/pull/11970>`__: BUG: sparse: 'diagonal' of sparse matrices fixed to match numpy's...
* `#11974 <https://github.com/scipy/scipy/pull/11974>`__: BUG: Reshape oaconvolve output even when no axes are convolved
* `#11976 <https://github.com/scipy/scipy/pull/11976>`__: MAINT: add logo for github actions
* `#11977 <https://github.com/scipy/scipy/pull/11977>`__: CI: test bleeding edge Python
* `#11979 <https://github.com/scipy/scipy/pull/11979>`__: DOC: add Examples for stats.ranksums() docstring.
* `#11982 <https://github.com/scipy/scipy/pull/11982>`__: Fix KMeans++ initialisation slowness
* `#11983 <https://github.com/scipy/scipy/pull/11983>`__: DOC: add Examples for stats.mstats.argstoarray() docstring.
* `#11986 <https://github.com/scipy/scipy/pull/11986>`__: Avoid bugs in ndimage when the output and input arrays overlap...
* `#11988 <https://github.com/scipy/scipy/pull/11988>`__: ENH: Override fit method of Laplace distribution with Maximum...
* `#11993 <https://github.com/scipy/scipy/pull/11993>`__: TST, CI: Azure Windows path fixups
* `#11995 <https://github.com/scipy/scipy/pull/11995>`__: MAINT, CI: remove custom mingw Azure
* `#11996 <https://github.com/scipy/scipy/pull/11996>`__: DOC: add Examples and fix pep warning for fft.set_global_backend...
* `#11997 <https://github.com/scipy/scipy/pull/11997>`__: MAINT, CI: Azure OpenBLAS simplify
* `#11998 <https://github.com/scipy/scipy/pull/11998>`__: BENCH: Run against current HEAD instead of master
* `#12001 <https://github.com/scipy/scipy/pull/12001>`__: ENH: stats: Implement _logpdf for the maxwell distribution.
* `#12004 <https://github.com/scipy/scipy/pull/12004>`__: DOC: add examples for integrate.quad_vec() and integrate.quad_explain()
* `#12005 <https://github.com/scipy/scipy/pull/12005>`__: MAINT: Use helper functions in ?tbtrs tests
* `#12007 <https://github.com/scipy/scipy/pull/12007>`__: MAINT: updated LICENSES_bundled for pybind11 and six
* `#12008 <https://github.com/scipy/scipy/pull/12008>`__: DOC: roadmap update
* `#12009 <https://github.com/scipy/scipy/pull/12009>`__: ENH: optimize: support 64-bit BLAS in lbfgsb
* `#12010 <https://github.com/scipy/scipy/pull/12010>`__: ENH: sparse.linalg: support 64-bit BLAS in isolve
* `#12012 <https://github.com/scipy/scipy/pull/12012>`__: DOC: add Examples for interpolate.barycentric_interpolate(),...
* `#12013 <https://github.com/scipy/scipy/pull/12013>`__: MAINT: remove last uses of numpy.dual
* `#12014 <https://github.com/scipy/scipy/pull/12014>`__: CI: print 10 slowest tests
* `#12020 <https://github.com/scipy/scipy/pull/12020>`__: MAINT: Removed handling of circular input in SphericalVoronoi
* `#12022 <https://github.com/scipy/scipy/pull/12022>`__: DOC : added default value of absolute_sigma to False in scipy.optimize.curve_fit docs
* `#12024 <https://github.com/scipy/scipy/pull/12024>`__: DOC: add Examples for io.hb_read() and io.hb_write()
* `#12025 <https://github.com/scipy/scipy/pull/12025>`__: MAINT: Remove numpy/npy_3kcompat.h from nd_image
* `#12028 <https://github.com/scipy/scipy/pull/12028>`__: Spelling correction
* `#12030 <https://github.com/scipy/scipy/pull/12030>`__: ENH: optimize/_trlib: support ILP64 blas/lapack
* `#12036 <https://github.com/scipy/scipy/pull/12036>`__: MAINT: Add some generated C files .gitignore
* `#12038 <https://github.com/scipy/scipy/pull/12038>`__: MAINT, CI: Travis rackcdn->conda.org
* `#12039 <https://github.com/scipy/scipy/pull/12039>`__: MAINT: signal: Lower the resolution of the plots in the chirp...
* `#12040 <https://github.com/scipy/scipy/pull/12040>`__: DOC: add Examples for ndimage.spline_filter1d() and spline_filter()...
* `#12044 <https://github.com/scipy/scipy/pull/12044>`__: MAINT: combine apt-get update and apt-get install into one RUN
* `#12045 <https://github.com/scipy/scipy/pull/12045>`__: TST: Reduce size of test_diagonal_types to speed up tests
* `#12046 <https://github.com/scipy/scipy/pull/12046>`__: MAINT: Remove unused npy_3kcompat.h
* `#12047 <https://github.com/scipy/scipy/pull/12047>`__: MAINT: Cython 3.0 compat
* `#12050 <https://github.com/scipy/scipy/pull/12050>`__: DOC: add download number badges of PyPI and conda-forge in README.rst
* `#12052 <https://github.com/scipy/scipy/pull/12052>`__: DOC: add Examples odr.models.polynomial() and fix odr.odr docstring...
* `#12056 <https://github.com/scipy/scipy/pull/12056>`__: ENH: Modifies shapiro to return a named tuple
* `#12057 <https://github.com/scipy/scipy/pull/12057>`__: Adding my name into THANKS.txt
* `#12060 <https://github.com/scipy/scipy/pull/12060>`__: TST: Reduce number of test_diagonal_types configs
* `#12062 <https://github.com/scipy/scipy/pull/12062>`__: TST: Change dec.slow to pytest.mark.slow
* `#12068 <https://github.com/scipy/scipy/pull/12068>`__: ENH: Modifies jarque_bera to return a named tuple
* `#12070 <https://github.com/scipy/scipy/pull/12070>`__: MAINT, CI: appveyor rack->conda.org
* `#12072 <https://github.com/scipy/scipy/pull/12072>`__: TST: filter out factorial(float) deprecation warning
* `#12078 <https://github.com/scipy/scipy/pull/12078>`__: TST: Skip test on colab with large memory alloc
* `#12079 <https://github.com/scipy/scipy/pull/12079>`__: DOC: Remove Python2 reference from stats tutorial
* `#12081 <https://github.com/scipy/scipy/pull/12081>`__: DOC: add Examples docstring for optimize.show_options()
* `#12084 <https://github.com/scipy/scipy/pull/12084>`__: BUG: interpolate: fix BarycentricInterpolator with integer input...
* `#12089 <https://github.com/scipy/scipy/pull/12089>`__: ENH: spatial/qhull: support ILP64 Lapack
* `#12090 <https://github.com/scipy/scipy/pull/12090>`__: ENH: integrate: support ILP64 BLAS in odeint/vode/lsoda
* `#12091 <https://github.com/scipy/scipy/pull/12091>`__: ENH: integrate: support ILP64 in quadpack
* `#12092 <https://github.com/scipy/scipy/pull/12092>`__: BUG: Fix dropping dt in signal.StateSpace
* `#12093 <https://github.com/scipy/scipy/pull/12093>`__: MAINT: Rollback python2.6 workaround
* `#12094 <https://github.com/scipy/scipy/pull/12094>`__: MAINT: \`openblas_support\` hash checks
* `#12095 <https://github.com/scipy/scipy/pull/12095>`__: MAINT: ndimage: change \`shares_memory\` to \`may_share_memory\`
* `#12098 <https://github.com/scipy/scipy/pull/12098>`__: Doc: change 4 model instances of odr to be instances of \`Model\`...
* `#12101 <https://github.com/scipy/scipy/pull/12101>`__: Removed more unused imports and assignments.
* `#12107 <https://github.com/scipy/scipy/pull/12107>`__: ENH: Area calculation for 2D inputs in SphericalVoronoi
* `#12108 <https://github.com/scipy/scipy/pull/12108>`__: MAINT: ensure attributes have correct data type in \`SphericalVoronoi\`
* `#12109 <https://github.com/scipy/scipy/pull/12109>`__: degree is not order in splines
* `#12110 <https://github.com/scipy/scipy/pull/12110>`__: ENH: More helpful/forgiving io.wavfile errors
* `#12117 <https://github.com/scipy/scipy/pull/12117>`__: BUG: fix newline
* `#12123 <https://github.com/scipy/scipy/pull/12123>`__: [MAINT] Fix error on PyData/Sparse import.
* `#12124 <https://github.com/scipy/scipy/pull/12124>`__: TST: Always test matmul now that Python3.5+ is required
* `#12126 <https://github.com/scipy/scipy/pull/12126>`__: TST: Cleanup unused matplotlib code.
* `#12127 <https://github.com/scipy/scipy/pull/12127>`__: DOC: update docstrings of signal.cspline2d, qspline2d, sepfir2d
* `#12130 <https://github.com/scipy/scipy/pull/12130>`__: MAINT: Fixing broken links with linkchecker
* `#12135 <https://github.com/scipy/scipy/pull/12135>`__: ENH: linalg: Add the function convolution_matrix.
* `#12136 <https://github.com/scipy/scipy/pull/12136>`__: MAINT: Cleanup np.poly1d hack
* `#12137 <https://github.com/scipy/scipy/pull/12137>`__: TST, CI: reproduce wheels 32-bit setup
* `#12140 <https://github.com/scipy/scipy/pull/12140>`__: TST: stats: add kstwo, ksone to slow tests.
* `#12141 <https://github.com/scipy/scipy/pull/12141>`__: Support 64-bit integer size in Fitpack
* `#12151 <https://github.com/scipy/scipy/pull/12151>`__: DOC: Correct Rosenbrock function sum
* `#12159 <https://github.com/scipy/scipy/pull/12159>`__: BUG: Fix length calculation in upfirdn
* `#12160 <https://github.com/scipy/scipy/pull/12160>`__: BUG: Fix M_PI
* `#12168 <https://github.com/scipy/scipy/pull/12168>`__: DOC: add an obsolete version checking javascript to doc release...
* `#12171 <https://github.com/scipy/scipy/pull/12171>`__: CI, MAINT: Azure OpenBLAS drive flip
* `#12172 <https://github.com/scipy/scipy/pull/12172>`__: ENH: Bounds for the Powell minimization method
* `#12175 <https://github.com/scipy/scipy/pull/12175>`__: BLD: support more Fortran compilers for ilp64 and macro expansion...
* `#12179 <https://github.com/scipy/scipy/pull/12179>`__: BUG: stats: A few distributions didn't accept lists as arguments.
* `#12180 <https://github.com/scipy/scipy/pull/12180>`__: MAINT: removed redundant import in SphericalVoronoi tests
* `#12181 <https://github.com/scipy/scipy/pull/12181>`__: DOC: for versionwarning don't use $.getScript
* `#12182 <https://github.com/scipy/scipy/pull/12182>`__: MAINT: random sampling on the hypersphere in SphericalVoronoi...
* `#12194 <https://github.com/scipy/scipy/pull/12194>`__: MAINT: Module and example cleanups for doc build
* `#12202 <https://github.com/scipy/scipy/pull/12202>`__: ENH: tool to DL release wheels from Anaconda
* `#12210 <https://github.com/scipy/scipy/pull/12210>`__: Remove py.typed marker (at least for the release)
* `#12217 <https://github.com/scipy/scipy/pull/12217>`__: BUG: stats: Fix handling of edge cases in median_abs_deviation.
* `#12223 <https://github.com/scipy/scipy/pull/12223>`__: BUG: stats: wilcoxon returned p > 1 for certain inputs.
* `#12227 <https://github.com/scipy/scipy/pull/12227>`__: BLD: Set macos min version when building rectangular_lsap
* `#12229 <https://github.com/scipy/scipy/pull/12229>`__: MAINT: tools/gh_lists.py: fix http header case sensitivity issue
* `#12236 <https://github.com/scipy/scipy/pull/12236>`__: DOC: Fix a couple grammatical mistakes in 1.5.0-notes.rst.
* `#12276 <https://github.com/scipy/scipy/pull/12276>`__: TST: skip `test_heequb`, it fails intermittently.
* `#12285 <https://github.com/scipy/scipy/pull/12285>`__: CI: split travis arm64 run into two
* `#12317 <https://github.com/scipy/scipy/pull/12317>`__: BUG: prevent error accumulation in `Rotation` multiplication
* `#12318 <https://github.com/scipy/scipy/pull/12318>`__: BUG: sparse: avoid np.prod overflow in check_shape
* `#12319 <https://github.com/scipy/scipy/pull/12319>`__: BUG: Make cobyla threadsafe
* `#12335 <https://github.com/scipy/scipy/pull/12335>`__: MAINT: Work around Sphinx bug

