See https://github.com/meren/anvio/releases
<p align="center"><img src="https://github.com/merenlab/anvio/raw/master/anvio/data/interactive/images/logo-fancy.png" height="256" /></p>

### Releases

Github [releases page](https://github.com/meren/anvio/releases) lists all the stable releases of anvi'o.

### Installation and tutorials

The [anvi'o project page](http://merenlab.org/software/anvio/) gives access to installation manuals, user tutorials, and other sweets. 

### Help on anvi'o programs and artifacts

[The anvi'o help pages](http://merenlab.org/software/anvio/help) describe individual anvi'o programs as well as artifacts they consume or produce.

### Coding style considerations

Please see [relevant discussions](https://github.com/merenlab/anvio/issues?q=label%3A%22coding+style%22+).

### Community chat

Click [this link](https://join.slack.com/t/anvio/shared_invite/zt-hrzx35df-vgYwfik0VxaObQuME_XLwg) to join our Slack team.

### Others on anvi'o

Read our [user testimonials](http://merenlab.org/2017/07/12/testimonials/).
# v7, "hope" is out! (04.01.2021) #
We are happy to announce anvi'o v7, with the code name 'hope' after 'Hope E. Hopps'.

This release adds more than 35,000 new lines of code and a myriad of new toys into anvi'o.

Please see the release notes [here](https://github.com/merenlab/anvio/releases/tag/v7), and our updated installation instructions [here](http://merenlab.org/install-anvio).
***

# v6.2: a critical update for "esther" (06.04.2020) #
We have a minor release that contains a set of bug fixes and critical performance improvements for the program `anvi-profile`. Please see the [installation](http://merenlab.org/2016/06/26/installation-v2/) page to upgrade your anvi'o.

In addition, here are some blog posts that you may be interested:

- [Visualizing contig coverages to better understand microbial population structures](http://merenlab.org/2019/11/25/visualizing-coverages/).
- [To dereplicate or not to dereplicate?](http://merenlab.org/2019/12/12/dereplicate-or-not/).
- [Visualizing the fate of contigs across metagenomic binning algorithms](http://merenlab.org/2020/01/02/visualizing-metagenomic-bins/).
***

# v6.1: a minor update for "esther" (28.10.2019) #
This is a minor release that contains a set of bug fixes our users identified in `v6`. Please see our up-to-date [installation](http://merenlab.org/2016/06/26/installation-v2/) document to upgrade your anvi'o.

In addition, here is a new blog post on our new tool, [anvi-export-locus](http://merenlab.org/2019/10/17/export-locus/)!
***

# v6, "esther" is out! (11.10.2019) #
We are happy to announce anvi'o v6, "esther":

This release adds more than 16,000 lines of code to v6, and makes available new tools for those who study microbial 'omics.

Please see the release notes [here](https://github.com/merenlab/anvio/releases/tag/v6), and our updated installation instructions [here](http://merenlab.org/install-anvio).
***

# Working with NCBI genomes (18.03.2019) #
[A new blog post](http://merenlab.org/2019/03/14/ncbi-genome-download-magic/) by [@Alon Shaiber](https://twitter.com/alon_shaiber) on how to download microbial genomes from the NCBI and include them in anvi'o 'omics analyses.
***

# v5.3: a minor but important update for "margaret" (28.02.2019) #
Please see our up-to-date [installation](http://merenlab.org/2016/06/26/installation-v2/) document to upgrade your anvi'o.
***

# v5, "margaret" is out! (25.06.2018) #
We are happy to announce #anvio v5, "margaret":

This release adds more than 10,000 lines of code to v4, and makes available new tools for those who study metagenomes and pangenomes, and are interested in microbial evolution, ecology, and biochemistry.

Please see the release notes [here](https://github.com/merenlab/anvio/releases/tag/v5), and see why you _must_ update your installation yourself! ðŸ˜‡
***

# v4, "rosalind" is out! (24.02.2018) #
This version adds about 15,000 new lines of code since the previous, while removing about 7,500, streamlining the anvi'o codebase while making available a plethora of improvements and new toys!

Please see the release notes [here](https://github.com/merenlab/anvio/releases/tag/v4), and keep your installation up-to-date!
***

# Slack for anvi'o (15.01.2018) #
We now have a public Slack workspace for anvi'o. [Come join us](https://slackin-ezbpfhwsmh.now.sh/) to ask questions about anvi'o, follow its development, or participate conversations on how to survive and make sense of 'omics data.
***

# An anvi'o workshop at UC Irvine (10.01.2018) #
We are are happy to announce a free 2-day anvi'o workshop at the University of California, Irvine. [Click here](http://merenlab.org/2017/12/25/anvio-workshop-at-uc-irvine/) for more information.
***

# v3, "Eden" is out!" (05.10.2017) #
Welcome, Eden! See the release notes [here](https://github.com/merenlab/anvio/releases/tag/v3), and keep your installation up-to-date!
***

# v2.4.0, "Pyrenees" is out!" (27.07.2017) #
A new anvi'o version with many bug fixes and new features is out! See the release notes [here](https://github.com/merenlab/anvio/releases/tag/v2.4.0).
***

# Anvi'o workshop at the JGI (25.07.2017) #
Join us at the Joint Genome Institute for a 2-day anvi'o workshop. The deadline for applications is August 1st. [Click here](http://merenlab.org/2017/05/17/anvio-workshop-at-jgi/) for more information.
***

# Welcome to anvi'o news! (16.05.2017) #
Starting from the anvi'o release `v2.3.2`, you will have access to the anvi'o news through the interactive interface.

Please refer to this blog post if you have any questions or concerns regarding this feature: [http://merenlab.org/2017/05/16/anvio-news-panel/](http://merenlab.org/2017/05/16/anvio-news-panel/)
***
<img src="https://github.com/merenlab/anvio/blob/master/anvio/data/interactive/images/logo.png?raw=true" style="width: 150px; float: right;" />

**If you are reading these lines, it means your test was successful, and your system is able to run anvi'o (yay) :)**

If this is your first time with anvi'o, or if you are not familiar with the platform, please take a moment to read the rest of this document.

---

### Learning anvi'o

Anvi'o has a relatively steep learning curve, but once you get the basics, the rest comes quite rapidly.

* You can start by taking a look at the [anvi'o programs and artifacts](https://merenlab.org/software/anvio/help/main/).

* [Take a look at this short paper](https://doi.org/10.1038/s41564-020-00834-3) to have an idea about the principles behind the platform.

[<img src="http://merenlab.org/images/anvio-network.png" style="width: 100%;" />](http://merenlab.org/software/anvio/network/)

* [This page](http://merenlab.org/software/anvio/) offers theoretical and practical insights into 'omics analyses you can perform with anvi'o through tutorials and blog posts.

* If you are new to microbial 'omics, you can [watch these introductory videos](https://www.youtube.com/playlist?list=PL7133RHfhW-MwCLz-c2DZxAmtoHipqBcL) to get yourself familiarized with common concepts.

### Join the conversation

[Developers of anvi'o](https://github.com/merenlab/anvio/blob/master/AUTHORS.txt) strive to tailor this platform to **your** needs. Please do not hesitate to get in touch with us if you need technical help, have suggestions, or simply in need of bouncing computational and experimental 'omics ideas from others.

* Here you can find [most up-to-date ways to get help from the anvi'o community](https://merenlab.org/2019/10/07/getting-help/), which includes options to reach out to us through the anvi'o Slack and Google Groups.

* If you run into technical problems despite our best efforts, you can always [file an issue report on GitHub](https://github.com/merenlab/anvio/issues).MAKE SURE YOU RUN EVERYTHING DIRECTLY IN THIS DIRECTORY THIS WAY:

    ./00_RUN.sh

If everything goes well, running `00_RUN.sh` will generate BAM files and a
`contigs.fa` for anvi'o mini test using all the contigs that are under
`contigs/` directory and all samples that are declared through their .ini
files under `samples` directory.

Please note that you will need `bowtie2` and the program `reads-for-assembly`
for this to run. If you don't have reads-for-assembly, you can get it this way:

    mkdir ~/github
    cd ~/github
    git clone https://github.com/merenlab/reads-for-assembly.git
    cd -

Only contigs in `_orig.fa` files are going to be used for read recruitment. Which
means, you can copy a contig into a new file that does not end with `_orig.fa`,
create a variant of it by modifying it with nucleotide-level or structural changes,
and set the desired coverage of this new variant in a given sample by mentioning
it in an `.ini` file.

Once it is done running, you can copy `output/contigs.fa` and `output/*-RAW.bam` to
`anvio/tests/sandbox` directory, and run the following to see the effect:

    cd
    anvi-self-test --suite mini -o NEW_MINI_TEST_RESULTS

If you add new samples, you will have change all test sh files accordingly.

Unless you manually move `output/contigs.fa` and `output/*-RAW.bam` into the
`anvio/tests/sandbox` directory, these files will have no effect on future
tests.
# What is this?

This directory contains HMM profiles and related data for anvi'o to be able to identify bacterial, archaeal, and eukaryotic rRNA genes in contigs.

The source of these profiles is [Torsten Seemann](https://scholar.google.com/citations?user=PuH3Yp4AAAAJ)'s [Barrnap repository](https://github.com/tseemann/barrnap/tree/master/db).

# How to rebuild the genes.hmm.gz file

The HMM files in Torsten's repo is not immediately usable from within anvi'o due to a number of anvi'o- and HMMER-specific non-trivial reasons. So I had to fix a couple of things.

First checkout the repo, and make sure you are on the right time and right place for everything to work:

``` bash
cd /tmp
git clone https://github.com/tseemann/barrnap.git
cd barrnap/
git checkout acf3198a2e671f79107d8221bc32c110a6272ca6
```

Go into the databases directory. You can double check every change that will follow with `git diff`:

``` bash
cd db
```

Remove all DESC lines. HMMER converts those spaces into TABs, extending number of TAB characters arbitrarily:

``` bash
sed -i '' '/^DESC / d' *.hmm
```

Make those names look better and distinguishable:

``` bash
sed -i '' '/^NAME/ s/$/_arc/' arc.hmm
sed -i '' '/^NAME/ s/$/_bac/' bac.hmm
sed -i '' '/^NAME/ s/$/_euk/' euk.hmm
sed -i '' '/^NAME/ s/$/_mit/' mito.hmm
sed -i '' '/^ACC/ s/$/_arc/' arc.hmm
sed -i '' '/^ACC/ s/$/_bac/' bac.hmm
sed -i '' '/^ACC/ s/$/_euk/' euk.hmm
sed -i '' '/^ACC/ s/$/_mit/' mito.hmm

```

We will first split each HMM model into its own file using this Python code:

```
cat <<EOF >>split_hmms.py
import sys
with open(sys.argv[1]) as input_f:
    for section in input_f.read().split('//\n'):
        for line in section.split('\n'):
            if line.find('NAME') > -1:
                name = line.split(' ')[-1]
                with open(name + '.hmm', 'w') as output:
                    output.write(section + '//\n')
                    break
EOF
```

Then we will run it on each file:

```
for f in euk.hmm arc.hmm bac.hmm mito.hmm
do
    python split_hmms.py $f
done
```

This should result in the following files in the working directory:

```
12S_rRNA_mit.hmm  16S_rRNA_bac.hmm  18S_rRNA_euk.hmm  23S_rRNA_bac.hmm  5S_rRNA_arc.hmm  5S_rRNA_euk.hmm    5_8S_rRNA_euk.hmm
16S_rRNA_arc.hmm  16S_rRNA_mit.hmm  23S_rRNA_arc.hmm  28S_rRNA_euk.hmm  5S_rRNA_bac.hmm  5_8S_rRNA_arc.hmm
```

Now it is time to merge them into final models we will use in anvi'o:

```
cat 16S_rRNA_bac.hmm 16S_rRNA_arc.hmm 16S_rRNA_mit.hmm > Ribosomal_RNA_16S.hmm
cat 23S_rRNA_bac.hmm 23S_rRNA_arc.hmm > Ribosomal_RNA_23S.hmm
cat 18S_rRNA_euk.hmm > Ribosomal_RNA_18S.hmm
cat 28S_rRNA_euk.hmm > Ribosomal_RNA_28S.hmm
cat 5S_rRNA_arc.hmm 5S_rRNA_euk.hmm 5S_rRNA_bac.hmm 5_8S_rRNA_euk.hmm 5_8S_rRNA_arc.hmm > Ribosomal_RNA_5S.hmm
cat 12S_rRNA_mit.hmm > Ribosomal_RNA_12S.hmm

rm 12S_rRNA_mit.hmm  16S_rRNA_bac.hmm  18S_rRNA_euk.hmm  23S_rRNA_bac.hmm  5S_rRNA_arc.hmm  5S_rRNA_euk.hmm    5_8S_rRNA_euk.hmm
rm 16S_rRNA_arc.hmm  16S_rRNA_mit.hmm  23S_rRNA_arc.hmm  28S_rRNA_euk.hmm  5S_rRNA_bac.hmm  5_8S_rRNA_arc.hmm
```

At this point, one should make sure that the number of lines between these two are identical:

```
wc -l arc.hmm bac.hmm euk.hmm mito.hmm
wc -l Ribosomal_RNA_*
```


Add noise cutoffs. totally arbitrary :/ maybe at some point we will fix this behavior and the HMM framework in anvi'o will be able to use HMM profiles without any model noise cutoffs. but for now, this is it:

``` bash
sed -i '' '/CKSUM /a \
GA    750 750;\
TC    750 750;\
NC    750 750;\
' Ribosomal*.hmm
```

And ensure unique ACC ids for each HMM entry:

```
```

For each of the Ribosomal RNA classes, create individual directories (which will become anvi'o HMM data directories):

``` bash
for RNA in Ribosomal_RNA_12S  Ribosomal_RNA_16S  Ribosomal_RNA_18S  Ribosomal_RNA_23S  Ribosomal_RNA_28S  Ribosomal_RNA_5S
do
    mkdir $RNA

    mv $RNA.hmm $RNA/genes.hmm

    echo "gene accession hmmsource" > $RNA/genes.txt

    for i in `grep NAME $RNA/genes.hmm | awk '{print $2}'`
    do
        echo "$i None barrnap"
    done >> $RNA/genes.txt

    perl -p -i -e 's/ /\t/g' $RNA/genes.txt

    gzip $RNA/genes.hmm

    echo "--cut_ga" > $RNA/noise_cutoff_terms.txt
    echo $RNA > $RNA/kind.txt
    echo "Seeman T, https://github.com/tseemann/barrnap" > $RNA/reference.txt
    echo "RNA:CONTIG" > $RNA/target.txt
done
```

You are done. Now one can run `anvi-run-hmms` to test one of these:

``` bash
anvi-run-hmms -c CONTIGS.db -H Ribosomal_RNA_16S
```

And get those matchin sequences back:

```
anvi-get-sequences-for-hmm-hits -c CONTIGS.db --hmm Ribosomal_RNA_16S
```
How to regenerate the contents of this directory
================================================

## Note

For a briefing on what the purpose of this folder is, please review these pull requests:

https://github.com/merenlab/anvio/pull/1428
https://github.com/merenlab/anvio/pull/1590

In brief, these files are numpy arrays of Markov models used to identify which items (nucleotides,
amino acids, codons) are likely to follow one another in a string of sequence.

## Reproducing the AA dir

These models (the `.npy` files) were generated from a large database called
[UniRef50](https://gtdb.ecogenomic.org/). I used ~23K bacterial genomes from v89, each which had
their own contigs database. If you want to generate your own Markov model, you can follow similar
steps with your own set of contigs databases.

To begin, I created this file:

```python
#! /usr/bin/env python

import anvio
import anvio.db as db
import anvio.fastalib as u

import argparse

from pathlib import Path

ap = argparse.ArgumentParser()
ap.add_argument("-c", "--contigs-db-paths")
ap.add_argument("-o", "--output-fasta")

args = ap.parse_args()

# ---------------------------------------

output = u.FastaOutput(args.output_fasta)
contigs_db_paths = [x.strip() for x in open(args.contigs_db_paths, 'r').readlines()]
gc_dist = []

count = 0
for contigs_db_path in contigs_db_paths:
    print(count)

    try:
        cdb = db.DB(contigs_db_path, None, ignore_version=True)
        name = Path(contigs_db_path).stem

        basic_info = cdb.get_table_as_dataframe('contigs_basic_info')
        gc = (basic_info['gc_content'] * basic_info['length'] / basic_info['length'].sum()).sum()
        gc_dist.append(gc)

        seqs = cdb.get_table_as_dataframe('gene_amino_acid_sequences')
    except:
        count += 1
        continue

    for i, row in seqs.iterrows():
        if row['sequence'] is not '':
            output.write_id(f"{name}|{row['gene_callers_id']}|{gc:.4f}")
            output.write_seq(row['sequence'], split = False)

    count += 1

output.close()

with open('gc_distribution', 'w') as f:
    f.write('\n'.join([str(gc) for gc in gc_dist]))
```

and ran it with `python create_aa_seq_db.py -c db_paths -o aa_seq_db.fa`, where `db_paths` is the
23k db paths, one per line. The whole thing took 3 hours. As a strange artifact of my investigation,
the best Markov model is created using only the genes from these genomes that have average GC
content < 39%.  The pull request https://github.com/merenlab/anvio/pull/1590 details the evidence
for this, though it is still a mystery why. To isolate these protein sequences, we split up
`aa_seq_db.fa` with the following script:


```python
#! /usr/bin/env python

import anvio
import anvio.db as db
import anvio.fastalib as u

import argparse
import numpy as np

from pathlib import Path

ap = argparse.ArgumentParser()
ap.add_argument("-f", "--fasta")
ap.add_argument("-b", "--bins")

args = ap.parse_args()

# ---------------------------------------

bins = np.array([float(x) for x in args.bins.split(',')])
prefix = Path(args.fasta).stem

fasta = u.SequenceSource(args.fasta)
outputs = {k: u.FastaOutput(prefix + f'_GC_{bins[k-1]:.4f}-{bins[k]:.4f}.fa') for k in range(1, len(bins))}

while next(fasta):
    b = int(np.digitize(float(fasta.id.split('|')[-1]), bins))
    outputs[b].store(fasta)

fasta.close()
for output in outputs:
    outputs[output].close()
```

And run it with `python partition_aa_seq_db.py -f aa_seq_db.fa -b 0,0.387,0.46,0.561,0.645,1.00`

Half an hour later, you end up with a couple files, most important being `aa_seq_db_GC_0.0000-0.3870.fa`.

Ok so you've got the FASTA. Take a look if you want. When you're ready, create the following script,
naming it `gen_transition_matrix.py` and putting in your current working dir:

```python
#! /usr/bin/env python

import numpy as np
import argparse
import anvio.fastalib as u
import anvio.constants as c

ap = argparse.ArgumentParser()
ap.add_argument('--fasta', '-f', required=True, help="FASTA to generate transition matrix from.")
ap.add_argument('--order', '-n', required=True, type=int, help="What order? Set -n 1 to include self. -n 2 to include nearest neighbor, etc.")
ap.add_argument('--output', '-o', required=True, help="Output matrix")
args = ap.parse_args()

fasta = u.SequenceSource(args.fasta)
aas = [c.AA_to_single_letter_code[aa] for aa in c.amino_acids if aa != 'STP']
aa_to_array_index = {aa: i for i, aa in enumerate(aas)}
num_aas = len(aas)

matrix = np.zeros(tuple([num_aas] * args.order))

while next(fasta):
    seq = fasta.seq
    for i in range(len(fasta.seq) - args.order):
        try:
            state = tuple([aa_to_array_index[aa] for aa in seq[i:i+args.order]])
            matrix[state] += 1
        except KeyError:
            # Catches bizzarre sequence characters
            pass

matrix /= matrix.sum()
np.save(args.output, matrix)
```

Then run the script to generate various orders of the model. It will take around 3 hours. If that's too long,
consider using only a portion of the fasta file (e.g. `head -n 50000 aa_seq_db_GC_0.0000-0.3870.fa >
uniref50_subset.fasta`). For example, the model currently used was generated from:

```
python gen_transition_matrix.py --fasta aa_seq_db_GC_0.0000-0.3870.fa --order 1 --output AA/MM_GC_0-39.npy
```

If you run into any problems let us know!
# README

This is a directory for _substitution scoring matrices_ for AA and NT engines.

They are utilized to score the competing AAs or NTs during the variability
profiling step via the program `anvi-gen-variability-profile`.

You can simply put a new matrix file in one of these directories, and they
will be automatically utilized.
The configuration file provides a recipe to anvio to mix multiple sources of information. For instance, when there are multiple metagenomic samples, reliance on coverage to order contigs is very efficient to determine the correct genome bins based on distribution patterns of contigs across samples. However when there are small number of samples from similar environments, the confidence of coverage values decrease quickly. In these cases tetra-nucleotide frequency information could be more useful than coverage. This creates a necessity to combine multiple sources of information. Also, the influence of the pieces of this information should be somehow maintained. For instance, if there are 3 samples, the contribution of TNF should be more compared to how much it would have contributed to the ordering of samples if there were 12 samples. anvio uses these configuration files to mix multiple sources of information by relying on dimension reduction through multidimensional scaling with a distance metric (euclidean, by default), and combining resulting normalized coordinats prior to clustering.

If it there is only one matrix, the scaling step will be ommitted, and the clustering would be done on the single full matrix with all or a subset of the columns specified by `columns_to_use` variable. When there is only one matrix to order contigs, declaring a `ratio` for the only matrix, or declaring the `num_components` variable under the general section would be irrelevant, and for the sake of clarity, the config handler class would raise an exception. This setup is appropriate for ordering contigs based on tetranucleotide-frequency or coverage *alone*. 

More information to come.

# Basic structure of the config file #

Following is a sample config file:

     [general]
     num_components = 16
     output_file = OUTPUT_TREE.txt
     seed = 42
     
     [TETRANUCLEOTIDE-FREQ-MATRIX.txt]
     alias = tnf
     ratio=2
     
     [METADATA-mean_coverage.txt]
     ratio=3
     alias = coverage
     columns_to_use = 204-6M,204-7M,204-9M

There will be more information here.


# Parameters #

* `alias` (string, single word): a one word descriptior of the matrix. This alias will be used for reporting, therefore it is important for it to be brief and accurate. 

* `ratio` (integer): this is an optional parameter that can be set under matrices to  specify how many of the `num_components` (under the 'general' section) should be assigned for a given matrix. if there are more than one matrices, leaving them blank will let the software handling the config file to determine how ratios should be arranged. The default behavior of anvio for merging will be to use TFN and Coverage information. It will increase the influence of Coverage with increasing number of samples. For instance, if there are 16 samples, the influence of TNF will be minimal, if there are two samples, the influence of coverage will be minimal, etc.

* `columns_to_use` (`column_name_1,...,column_name_n`)  this variable defines which columns should be taken into account for scaling. some files may contain multiple sources of information, some of which may be irrelevant for scaling (such as a column of taxanomical strings in the METADATA file for coverage of each contig. the column names of interest (such as sample names in this case) can be listed with this variable. If this does not exist, then all columns that return True for `anvio.constants.IS_ESSENTIAL_FIELD` is considered.  

* `seed` (int)  Seed for reproducable results for testing purposes. If none defined, no seed will be passed to scaling functions. You don't need it if you don't know what it is.   

How to re-train anvi'o domain classifier
========================================

Anvi'o uses SCGDOMAINCLASSIFIER.rf to predict domains for real time estimation
of completion and redundancy of a given genome bin. This subsystem is commonly
used by many programs including `anvi-interactive` and `anvi-estimate-genome-completeness`.

To re-train the classifier, you need to download the necessary datapack, and use
the program `anvi-script-gen-scg-domain-classifier`. To do that go to any directory:

```
cd ~/Downloads
```

Download the genomes:

```
wget https://ndownloader.figshare.com/files/15230837 -O GENOMES-TO-TRAIN-ANVIO-SCG-DOMAIN-PREDICTOR.tar.gz
tar -zxvf GENOMES-TO-TRAIN-ANVIO-SCG-DOMAIN-PREDICTOR.tar.gz
cd GENOMES-TO-TRAIN-ANVIO-SCG-DOMAIN-PREDICTOR/
```

The training data is organized into sub-directories,

```
ls
archaea  bacteria eukarya
```

Each of which contains *anvi'o contigs databases for single genomes*:

```
ls bacteria/
Acaryochloris_marina_5.db                     Aster_yellows_1606.db
Acetobacter_pasteurianus_13.db                Borrelia_afzelii_3199.db
Acetobacterium_woodii_32.db                   Calditerrivibrio_nitroreducens_4210.db
Acholeplasma_brassicae_35.db                  Candidatus_Nitrospira_defluvii_4551.db
Acidimicrobium_ferrooxidans_105.db            Candidatus_Protochlamydia_amoebophila_4582.db
Acidobacterium_capsulatum_123.db              Chlorobaculum_parvum_4919.db
Aequorivita_sublithincola_1254.db             Defluviitoga_tunisiensis_5522.db
Akkermansia_muciniphila_1366.db               Deinococcus_deserti_5540.db
Aminobacterium_colombiense_1442.db            Fusobacterium_nucleatum_9790.db
Anaerolinea_thermophila_1477.db               Isosphaera_pallida_10718.db
Aquifex_aeolicus_1539.db
```

The purpose of this is to have enough examples for each domain of life, so anvi'o
can learn about how to recognize similar genomes later based on single-copy core
genes.

To train the classifier, you can simply run the following command:

```
anvi-script-gen-scg-domain-classifier --genomes-dir . \
                                      --output $(python -c 'import anvio; import os; print(os.path.join(os.path.dirname(anvio.__file__), "data/misc/SCGDOMAINCLASSIFIER.rf"));')
```

How to add a new SCG collection for a new domain
================================================

In addition to the data pack directory, at this point you should have your SCG collection
for this domain in anvi'o HMM directory form. Examples to these directories can be found here:

    https://github.com/merenlab/anvio/tree/master/anvio/data/hmm

First, put your HMM directory to the proper place in the anvi'o codebase you are using.
You can learn the location by running this command:

```
DATA_DIR=`python -c 'import anvio.data.hmm as hmm_data; import os; print(os.path.dirname(hmm_data.__file__))'`

cp -r MY_HMM_DIR/ $DATA_DIR/
```

Once it is in place, you create a new directory in the data pack with the name matching to the
domain name listed in `MY_HMM_DIR/kind.txt` file, and add into this directory new contigs databases
that represent individual genomes that match to that domain.

Once you have the new directory in place, you should run `anvi-run-hmms` on all genomes in the datapack
from scratch. You can do it this way:

```
for i in `find . -name '*.db'`
do
    anvi-run-hmms -c $i -T 6
done
```

Once this is done, you are golden. Run the trainer again,

```
anvi-script-gen-scg-domain-classifier --genomes-dir . \
                                      --output $(python -c 'import anvio; import os; print(os.path.join(os.path.dirname(anvio.__file__), "data/misc/SCGDOMAINCLASSIFIER.rf"));')
```

And test one of your new genomes with `anvi-estimate-genome-completeness`.

If you run into any problems let us know!
The purpose of this directory is to keep track of people who are a
part of the anvi'o project. If you see someone who is missing,
please add them into the relevant file.

# How to add a new individual?

If you are adding a new anvi'o developer or contributor into either
of these YAML files, please send a PR with the relevant changes,
which include,

* Edit `DEVELOPERS.yaml` **or** `CONTRIBUTORS.yaml` files to add
a new entry for the new person (please benefit from previous examples).
* Add a new photo under the the `AVATARS` directory. It should be
a 900px x 900px head-shot (see previous examples).

Most fields are optional, but please note that every person mentioned
in either YAML files must have a GitHub username.

## A template to make things easeir

Feel free to use this **template** for new entries:

```
- github: (github username)
  name: (full name)
  twitter: (twitter username)
  web: (http://your-web-page)
  avatar: (your-avatar.png that is in the AVATARS directory)
  email: (email address)
  linkedin: (linkedin username)
  orcid: (ORCiD, not the url, just the numbers)
  bio: "A one-sentence short and descriptive bio -- see examples"
  affiliations:
    - title: (your title: Graduate Student / Post-doctoral scientist / Assistant Professor / etc)
      inst: (name of the institution you are affiliated with)
      inst_link: (the link to the institution or group page)
      current: (if this is a 'current' affiliation, put the word true here, if not, remove the line completely)
```

The purpose of affiliations is to keep track of every anvi'o person
starting from their first contribution to the platform. You can add
as many affiliations as you like. Please order them in such a way
that they are ordered from new to old.

# General things to consider developing this resource further

## Developers vs Contributors

`DEVELOPERS.yaml` contains individuals who has made literal contributions
to the anvi'o codebase. The information in this file can be used to
tag people in `__authors__` directives in anvi'o programs under the
`bin/` and `sandbox/` directories, which then can be used via the
`anvio/authors.py` module that serves other programs such as
`anvi-script-gen-help-pages` that generates anvi'o help pages at
https://anvio.org/help/main

`CONTRIBUTORS.yaml` contains individuals has made indirect contributions
to the anvi'o community, including writing blog posts or tutorials, or
pushing the boundaries of the platform with their intellectual
contributions and guidance.

## Intellectual contributions

We have manually curated 'intellectual contributions' sections for
individuals listed in both `DEVELOPERS.yaml` and `CONTRIBUTORS.yaml`.
At any given time, they will be inevitably incomplete. So please help
expand these entries to keep track of key contributions even for
those who are no longer around the project. Here are a few right-hand
rules to add more:

* Keep each contributions statement as concise and accurate as possible.
HTML notation is supported, but please limit the use of HTML to `a`
tags to link relevant documentation, PRs, help pages, or articles from
within the contrib statement.

* Each contributions statement must list a single contribution.

* If someone implemented an entirely new concept, program, workflow,
document, or framework in anvi'o, use the term 'Spearheaded'. I.e.,
"Spearheaded the development of anvi'o snakemake workflows". This
indicates that others may have contributed to it, or may contribute
in the future.

* If someone made notable contributions anything listed above, use
the phares "Made significant contributions". I.e., "Made significant
contributions to anvi'o snakemake workflows". What is notable and
what is not notable is not clear. Common sense is your best guidance,
but when you are unsure, discuss a given case with other developers.
A contribution may be notable only by you, so if you see something,
say something!
This artifact is a TAB-delimited file that **associates genes and functions**. 

The user can generate this file to import gene functions into a %(contigs-db)s via %(anvi-import-functions)s or can acquire this file by recovering it from a %(contigs-db)s via %(anvi-export-functions)s. It is also the output of %(anvi-search-functions)s which searches for specific terms in your functional annotations.

In general, this is the simplest way to get gene functions into anvi'o, and all downstream analyses, including pangenomics. For other ways to get gene functions into anvi'o you can take a look at [this page](http://merenlab.org/2016/06/18/importing-functions/). 


## Simple matrix file format


The TAB-delimited file for this artifact has five columns:

1. `gene_callers_id`: The gene caller ID recognized by anvi'o (see the note below).
2. `source`: The name of the functional annotation source (i.e., the database that you got this function data from).
3. `accession`: A unique accession id per function, better if a single word.
4. `function`: Full name / description of the function.
5. `e_value`: The significance score of this annotation, where zero is maximum significance. This information may be used by anvi'o in operations that require filtering of functions based on their significance.

Through this file format **you can import functions from any source** into anvi'o, whether those sources are commonly used programs to annotate genes with functions or your ad hoc manual curations for genes of interest. But **please note while there are many ways to have your genes annotated with functions, there is only one way to make sure the gene caller ids anvi'o knows will match perfectly to the gene caller ids in your input file**. The best way to ensure that linkage is to export your gene DNA or amino acid sequences for your an %(contigs-db)s using the anvi'o program `anvi-get-sequences-for-gene-calls`.

## An example matrix

Here is an example file that matches to this format that can be used with %(anvi-import-functions)s to import functions into a %(contigs-db)s:

|gene_callers_id|source|accession|function|e_value|
|:--|:--:|:--:|:--|:--:|
|1|Pfam|PF01132|Elongation factor P (EF-P) OB domain|4e-23|
|1|Pfam|PF08207|Elongation factor P (EF-P) KOW-like domain|3e-25|
|1|TIGRFAM|TIGR00038|efp: translation elongation factor P|1.5e-75|
|2|Pfam|PF01029|NusB family|2.5e-30|
|2|TIGRFAM|TIGR01951|nusB: transcription antitermination factor NusB|1.5e-36|
|3|Pfam|PF00117|Glutamine amidotransferase class-I|2e-36|
|3|Pfam|PF00988|Carbamoyl-phosphate synthase small chain, CPSase domain|1.2e-48|
|3|TIGRFAM|TIGR01368|CPSaseIIsmall: carbamoyl-phosphate synthase, small subunit|1.5e-132|
|4|Pfam|PF02787|Carbamoyl-phosphate synthetase large chain, oligomerisation domain|1.4e-31|
|4|TIGRFAM|TIGR01369|CPSaseII_lrg: carbamoyl-phosphate synthase, large subunit|0|
|5|TIGRFAM|TIGR02127|pyrF_sub2: orotidine 5'-phosphate decarboxylase|1.9e-59|
|6|Pfam|PF00625|Guanylate kinase|5.7e-39|
|6|TIGRFAM|TIGR03263|guanyl_kin: guanylate kinase|3.5e-62|
|8|Pfam|PF01192|RNA polymerase Rpb6|4.9e-13|
|8|TIGRFAM|TIGR00690|rpoZ: DNA-directed RNA polymerase, omega subunit|1.7e-20|
|9|TIGRFAM|TIGR01034|metK: methionine adenosyltransferase|2.5e-169|
|11|Pfam|PF13419|Haloacid dehalogenase-like hydrolase|2.8e-27|
|11|TIGRFAM|TIGR01509|HAD-SF-IA-v3: HAD hydrolase, family IA, variant 3|1.2e-11|
|12|Pfam|PF00551|Formyl transferase|1.4e-34|
|12|TIGRFAM|TIGR00460|fmt: methionyl-tRNA formyltransferase|2.9e-70|
|13|Pfam|PF12710|haloacid dehalogenase-like hydrolase|2.3e-14|
|13|TIGRFAM|TIGR00338|serB: phosphoserine phosphatase SerB|4.9e-76|
|13|TIGRFAM|TIGR01488|HAD-SF-IB: HAD phosphoserine phosphatase-like hydrolase, family IB|6e-29|
|14|Pfam|PF00004|ATPase family associated with various cellular activities (AAA)|7.7e-45|
|14|Pfam|PF16450|Proteasomal ATPase OB/ID domain|1.8e-34|
|14|TIGRFAM|TIGR03689|pup_AAA: proteasome ATPase|1e-206|
|(...)|(...)|(...)|(...)|(...)|


Please note that,

* Not every gene call has to be present in the matrix,

* It is OK if there are multiple annotations from the same source for a given gene call,

* It is OK if a give gene is annotated only by a single source.

* If the **accession** information is not available to you, it is OK to leave it blank (but it will prevent you from being able to use some toys, such as functional enrichment analyses later for pangenomes).

* If you have no e-values associated with your annotations, it is OK to put `0` for every entry (you should make sure you keep this in mind for your downstream analyses that may require filtering of weak hits).

* If there are multiple annotations from a single source for a single gene call, anvi'o uses e-values in this file to use only the most significant one to show in interfaces.The search results for an %(hmm-source)s in a %(contigs-db)s. Essentially, this is the part of a %(contigs-db)s that handles the HMM data. In anvi'o, this is usually functional annotations, such as identifying specfic ribosomal RNAs, various single-copy core genes, and transfer RNAs, though the user can also define their own HMM sources. 

Upon creation, a %(contigs-db)s will not contain any HMM results. In order to populate it, users can run %(anvi-run-hmms)s using any %(hmm-source)s. The program %(anvi-scan-trnas)s also populates a %(contigs-db)s's hmm-hits with potential tranfer RNA hits.
A %(trnaseq-fasta)s is a %(fasta)s file of sequences from a single tRNA-seq sample of split that is suitable to be used by %(anvi-trnaseq)s to create a %(trnaseq-db)s.

Like %(contigs-fasta)s files, this file **is required to have simple deflines**. Take a look at your deflines prior to mapping, and remove anything that is not a digit, an ASCII letter, an underscore, or a dash character. The program %(anvi-script-reformat-fasta)s can do this automatically for you with the flag `--simplify-names`.

We recommend using %(anvi-run-workflow)s to create this file from paired-end tRNA-seq reads. The %(trnaseq-workflow)s uses [illumina-utils](https://github.com/merenlab/illumina-utils) to merge FASTQ files that may contain a mixture of fully and partially overlapping reads, which both occur using 100 bp (or shorter) reads containing barcodes due to the length of tRNA. Even with 150 bp reads, there may be pre-tRNA covered by partially but not fully overlapping reads. %(anvi-script-reformat-fasta)s comes after illumina-utils in the workflow.
This artifact represents the [GTDB](https://gtdb.ecogenomic.org/) data (from [Parks et al. 2018](https://doi.org/10.1038/nbt.4229)) downloaded by %(anvi-setup-trna-taxonomy)s. This information is required to run %(anvi-run-trna-taxonomy)s and %(anvi-estimate-trna-taxonomy)s. 

{:.notice}
If the results from this tRNA taxonomy search end up in a paper, make sure to cite [Parks et al. 2018](https://doi.org/10.1038/nbt.4229) for their information.

By default, it is stored at `anvio/data/misc/TRNA-TAXONOMY`. This directory contains a few files for each anticodon, each forming a fancy search database so that you can associate tRNA reads in your %(contigs-db)s with taxonomy information. 
This directory contains information about anvi'o artifacts.

A complete list of artifacts is listed in the `__init__.py` file located in the upper
directory. You can also access to the list of artifacts programmatically this way:

```
python -c 'import anvio.docs; print(anvio.docs.ANVIO_ARTIFACTS);'
```

Information in this directory is compiled into help text shown in the following URL:

http://merenlab.org/software/anvio/help/
This is the output tables that are displayed when you run %(anvi-estimate-scg-taxonomy)s or %(anvi-estimate-trna-taxonomy)s, but formatted as a tab-delimited text file. 

To get this output, just provide the `-o` or the `-O` flag when running %(anvi-estimate-scg-taxonomy)s or %(anvi-estimate-trna-taxonomy)s. 

These contain the exact same information as is normally displayed in the terminal, just in a separate file that is easier to share or include as supplemental data. To see an explination of the data within this file, you can look at the page for %(genome-taxonomy)s. 
This tabular file contains data on predicted modifications in tRNA-seq seeds.

This file is produced by %(anvi-tabulate-trnaseq)s. The artifact for that program describes this and related tables in detail.

This tab-delimited file can be easily manipulated by the user. It is required input for %(anvi-plot-trnaseq)s.

## Example

The modifications shown in this table are from the seeds represented in the %(seeds-specific-txt)s and %(seeds-non-specific-txt)s example tables.

| gene_callers_id | contig_name | anticodon | aa | domain | phylum | class | order | family | genus | species | taxon_percent_id | seed_position | ordinal_name | ordinal_position | canonical_position | reference | sample_name | A | C | G | T |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | 19 | d_loop_beta_1 | 22 | 20 | G | DB_01 | 142 | 589 | 69411 | 1315 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | 19 | d_loop_beta_1 | 22 | 20 | G | DB_03 | 217 | 1056 | 83751 | 2592 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | 19 | d_loop_beta_1 | 22 | 20 | G | DB_05 | 42 | 212 | 28784 | 515 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | 19 | d_loop_beta_1 | 22 | 20 | G | DB_07 | 102 | 429 | 45633 | 977 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | 32 | anticodon_loop_1 | 36 | 32 | T | DB_01 | 0 | 51 | 14 | 77 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | 32 | anticodon_loop_1 | 36 | 32 | T | DB_03 | 1 | 274 | 97 | 642 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | 32 | anticodon_loop_1 | 36 | 32 | T | DB_05 | 0 | 78 | 17 | 137 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | 32 | anticodon_loop_1 | 36 | 32 | T | DB_07 | 0 | 19 | 18 | 87 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | 37 | anticodon_loop_6 | 41 | 37 | G | DB_01 | 0 | 1 | 137 | 5 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | 37 | anticodon_loop_6 | 41 | 37 | G | DB_03 | 5 | 18 | 916 | 64 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | 37 | anticodon_loop_6 | 41 | 37 | G | DB_05 | 6 | 3 | 222 | 7 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | 37 | anticodon_loop_6 | 41 | 37 | G | DB_07 | 0 | 15 | 104 | 1 |
The GenBank file format was created by NCBI. 

You can find an [explination](https://www.ncbi.nlm.nih.gov/genbank/) and [example](https://www.ncbi.nlm.nih.gov/genbank/samplerecord/) on the NCBI website. 

In anvi'o, this is used by %(anvi-script-process-genbank)s to convert the information in the genbank file to a %(contigs-fasta)s, %(external-gene-calls)s, and %(functions-txt)s. 
This file contains **the frequency of each amino acid for some reference context in your %(contigs-db)s**.  

This is a tab-delimited table where each column represents an amino acid and each row represents a specific reference context (most often this will be a gene after running %(anvi-get-codon-frequencies)s). The numbers will either refer to counts of each amino acid or precent normalizations depending on the parameters with which you ran %(anvi-get-codon-frequencies)s. 

You can also use %(anvi-get-aa-counts)s to get this information for a %(bin)s, %(collection)s, or %(splits-txt)s. 

### Example

    gene_caller_id  Ala Arg Thr Asp ...
        1           0   0   1   2
        2           1   0   0   2
        .
        .
        .
This contains the taxonomic annotations for each of the tRNA sequences found in your %(contigs-db)s, which are the results of running %(anvi-run-trna-taxonomy)s. 

You can use this information to estimate the taxnomy of genomes, metagenomes, or collections stored in your %(contigs-db)s using the program %(anvi-estimate-trna-taxonomy)s

Recall that this information was calculated using [GTDB](https://gtdb.ecogenomic.org/), so it might not be entirely accurate for Eukaryotic tRNAs. 
SVG stands for scalable vector graphics, which is a vector-based image format. In anvi'o programs that give you pretty-looking outputs will also give you an svg, so you can look at the beauty of your data without having to open anvi'o for analysis. This also makes it easier to share with others (so you don't have to use screenshots in your poster).

As of now, %(anvi-display-contigs-stats)s, %(anvi-display-pan)s, and %(anvi-interactive)s will give you an svg output every time you click the little save button at the bottom-left corner of the settings panel in the interface. You can even customize the location of that output using the flag `--export-svg`. 

Take a look at [this blogpost](http://merenlab.org/2016/10/27/high-resolution-figures/) for an outline of how to get this svg file into a publication-quality figure. 

This artifact contains various information about the SNVs, SCVs, and SAAVs across a %(profile-db)s that is thoroughly described [on this blogpost](http://merenlab.org/2015/07/20/analyzing-variability/#the-output-matrix).  

This is generated by %(anvi-gen-variability-profile)s, which is also described in [that blogpost](http://merenlab.org/2015/07/20/analyzing-variability/#the-anvio-way).  

{:.notice}
Unsure what SNV, SCV, and SAAVs are or looking for a refresher? You can find that information [on the same blogpost](http://merenlab.org/2015/07/20/analyzing-variability/#an-intro-to-single-nucleotidecodonamino-acid-variation).  

In summary, [go to the blogpost](http://merenlab.org/2015/07/20/analyzing-variability/). Because the blogpost preceded this document by 5 years, most of the pertinent information that should be in here is actually over there. One day we will remedy this situation. Until then, this document serves as a quick reference for content more verbosely explained in the blog post.


%(variability-profile-txt)s is the output matrix for your SNVs, SCVs, or SAAVs. What you do with your %(variability-profile-txt)s is entirely up to your discretion. We maintain the stance that this output should be as raw as possible, so that you can analyze it how you please. Attached to each SNV, SCV, and SAAV is a plethora of annotated information.


### What kinds of information?  

#### SNVs 

For each of your SNVs, this matrix include their position in the contig and gene, sample, coverage data, the A, C, G, and T counts, the reference and consensus nucleotides, entropy value, and more.  

#### SCVs 

This information will only appear if you requested it when running your earlier analysis. To do this, use the flag `--profile-SCVs` when you run %(anvi-profile)s. Then, when running %(anvi-gen-variability-profile)s use the flag `--engine CDN`.  

For each SCVs, this matrix details the position, sample, coverage data, count for each of the 64 codons (AAA, AAC, ..., TTG, TTT), entropy, synonymity, etc.  

#### SAAVs 

Like the information about SCVs, this information will only appear if you requested it when running your earlier analysis. To do this, use the flag `--profile-SCVs` when you run %(anvi-profile)s or %(anvi-merge)s. Then, when running %(anvi-gen-variability-profile)s use the flag `--engine AA`.  

For each SCVs, this matrix details the position, sample, coverage data, count for each of the 20 amino acids (as well as the stop codon), entropy, BLOSUM62, etc.  

#### Structural information 

If you provided %(anvi-gen-variability-profile)s with a %(structure-db)s, then you'll also have some additional columns to your matrices. These include structural annotations, the residue's solvent accessibility, information about bond angles, and a list of residues that are in physical contact with the residue you're looking at. 


For more information on any of this, check out [this page](http://merenlab.org/2015/07/20/analyzing-variability/#the-output-matrix), where every column in these matrices is not only listed, but explained.


#### Additional amino acid and nucleotide data 

If you provided %(anvi-gen-variability-profile)s with the flag `--include-additional-data` and you have any %(misc-data-amino-acids)s data stored in your %(contigs-db)s, that data will added as additional columns to the matrix.


{:.notice}
This is currently only implemented for `--engine AA` and `--engine CDN`. `--include-additional-data` will not currently append %(misc-data-nucleotides)s data to your matrix output when `--engine NT` is used.



## What is this thing?  

This is a comprehensive database of protein structures downloaded from the PDB RSCB that are non-redundant. Currently, it is used for those who want to run %(anvi-gen-structure-database)s without an internet connection.


## Where does it come from?  

A %(pdb-db)s can be created via the program %(anvi-setup-pdb-database)s. Alternatively, a %(pdb-db)s that contains custom structures not found in the [RCSB PDB](https://www.rcsb.org/) can in theory be generated by the user, but anvi'o currrently offers no reasonable way of doing this.


## Notes 

The %(pdb-db)s generated via %(anvi-setup-pdb-database)s is ~20GB.  

This is a tab-delimited table where each row represents a a short read that mapped to a specific position in a reference contig. This is the output of %(anvi-report-linkmers)s, where those reference positions are given by the user.

For instance, if %(anvi-report-linkmers)s was run on three samples (`SAMPLE-01.bam`, `SAMPLE-02.bam`, and `SAMPLE-03.bam`) with this contigs-and-positions file,

<table>
  <tbody>
    <tr>
      <td> contig_1720 </td>
      <td> 7111,7115,7120 </td>
    </tr>
  </tbody>
</table>

Then the output would be the following: 

|entry_id|sample_id|request_id|contig_name|pos_in_contig|pos_in_read|base|read_unique_id|read_X|reverse|sequence|
|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--|
|000000001|SAMPLE-01|001|contig_1720|7111|160|G|bc3aa6b95ce110067|read-2|True|ATTGGTTTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTA|
|000000002|SAMPLE-01|001|contig_1720|7111|160|G|156295ff5928fc055|read-2|True|ATTGGTTTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTT|
|000000003|SAMPLE-01|001|contig_1720|7111|141|G|7a8947678111bb905|read-2|True|TTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACA|
|000000004|SAMPLE-01|001|contig_1720|7111|135|A|2a3de408930252949|read-2|False|TGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTAGGAGTGTTT|
|000000005|SAMPLE-01|001|contig_1720|7111|130|G|5f995d129fdabe64f|read-2|True|ATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATT|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|
|000000033|SAMPLE-01|001|contig_1720|7115|164|A|bc3aa6b95ce110067|read-2|True|ATTGGTTTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTA|
|000000034|SAMPLE-01|001|contig_1720|7115|164|A|156295ff5928fc055|read-2|True|ATTGGTTTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTT|
|000000035|SAMPLE-01|001|contig_1720|7115|145|A|7a8947678111bb905|read-2|True|TTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACA|
|000000036|SAMPLE-01|001|contig_1720|7115|139|G|2a3de408930252949|read-2|False|TGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTAGGAGTGTTT|
|000000064|SAMPLE-01|001|contig_1720|7115|16|A|28a3a440fda5142b9|read-2|True|AGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGTGCAATAATTATTATTTTTGTACCGGTAATGTTAGGAATTATCTATTTAGCTAGTAAGGGTGTGGTTAAA|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|
|000000065|SAMPLE-01|001|contig_1720|7120|169|T|bc3aa6b95ce110067|read-2|True|ATTGGTTTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTA|
|000000066|SAMPLE-01|001|contig_1720|7120|169|T|156295ff5928fc055|read-2|True|ATTGGTTTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTT|
|000000067|SAMPLE-01|001|contig_1720|7120|150|T|7a8947678111bb905|read-2|True|TTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACA|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|
|000000097|SAMPLE-02|001|contig_1720|7111|140|G|ddb72ab632d753591|read-2|True|TGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCA|
|000000098|SAMPLE-02|001|contig_1720|7111|75|G|e7506ec6da1f08697|read-2|False|TAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGTGCA|
|000000099|SAMPLE-02|001|contig_1720|7111|65|G|07f926c7d8dd57e03|read-2|True|TCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGTGCAATAATTATTATTTTTGTACC|
|000000100|SAMPLE-02|001|contig_1720|7111|54|G|97fb9b743bbe5d89a|read-2|True|GTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGTGCAATAATTATTATTTTTGTACCGGTAATGTTA|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|
|000000103|SAMPLE-02|001|contig_1720|7115|69|A|07f926c7d8dd57e03|read-2|True|TCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGTGCAATAATTATTATTTTTGTACC|
|000000104|SAMPLE-02|001|contig_1720|7115|58|A|97fb9b743bbe5d89a|read-2|True|GTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGTGCAATAATTATTATTTTTGTACCGGTAATGTTA|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|
|000000105|SAMPLE-02|001|contig_1720|7120|149|T|ddb72ab632d753591|read-2|True|TGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCA|
|000000106|SAMPLE-02|001|contig_1720|7120|84|T|e7506ec6da1f08697|read-2|False|TAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGTGCA|
|000000107|SAMPLE-02|001|contig_1720|7120|74|T|07f926c7d8dd57e03|read-2|True|TCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGTGCAATAATTATTATTTTTGTACC|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|
|000000109|SAMPLE-03|001|contig_1720|7111|181|G|5b30beaad5028d9be|read-2|False|CATCATAGTAATATTGCAACTATTGGTTTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTT|
|000000110|SAMPLE-03|001|contig_1720|7111|167|G|a74a16460eee34549|read-2|False|TGCAACTATTGGTTTTGCTATTGGGTTTGTCGTGATGATGATGATAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTT|
|000000111|SAMPLE-03|001|contig_1720|7111|158|G|3ec0b8a88b8cf6f6b|read-2|False|TGGTTTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTA|
|000000112|SAMPLE-03|001|contig_1720|7111|158|G|237828c6637b1648e|read-2|False|TGGTTTTGCTATTGGGTTTGTCGGGATGATGATGTTAGATGTCGCCTTAGGTTAATCTGTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTA|
|000000113|SAMPLE-03|001|contig_1720|7111|154|G|006dfcf9742b2a323|read-2|True|TTTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGATGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTA|
|000000114|SAMPLE-03|001|contig_1720|7111|153|G|ab174bde7a9f86013|read-2|False|TTGCTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAA|
|000000115|SAMPLE-03|001|contig_1720|7111|150|G|4fdd1e6de2a10c923|read-2|True|CTATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTT|
|000000116|SAMPLE-03|001|contig_1720|7111|149|G|cc5f916935b4b42be|read-2|False|TATTGGGTTTTTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAA|
|000000117|SAMPLE-03|001|contig_1720|7111|148|G|857199a218edef55d|read-2|False|ATTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACGGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTT|
|000000118|SAMPLE-03|001|contig_1720|7111|147|G|7f5890d7daeb66d06|read-2|False|TTGGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAA|
|000000119|SAMPLE-03|001|contig_1720|7111|145|G|e1f31dfa0435ffb78|read-2|True|GGGTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAATAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTT|
|000000120|SAMPLE-03|001|contig_1720|7111|143|G|8204d0adc702d99ba|read-2|True|GTTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAA|
|000000121|SAMPLE-03|001|contig_1720|7111|142|G|baaa46d85f2425750|read-2|False|TTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTCAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAAT|
|000000122|SAMPLE-03|001|contig_1720|7111|142|G|571209d8eacfbec10|read-2|True|TTTGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAATAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAA|
|000000123|SAMPLE-03|001|contig_1720|7111|140|T|3dda82d075cb90188|read-2|False|TGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTTGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGG|
|000000124|SAMPLE-03|001|contig_1720|7111|140|G|4cc7969a78d30d313|read-2|False|TGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTA|
|000000125|SAMPLE-03|001|contig_1720|7111|140|G|418eca79d0630e0fe|read-2|False|TGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTATGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTC|
|000000126|SAMPLE-03|001|contig_1720|7111|140|G|6f72cff910f80d2c5|read-2|True|TGTCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTT|
|000000127|SAMPLE-03|001|contig_1720|7111|138|G|3fd470af01ec4eb4f|read-2|True|TCGTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTC|
|000000128|SAMPLE-03|001|contig_1720|7111|136|G|a533ced1530eea9a8|read-2|True|GTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCA|
|000000129|SAMPLE-03|001|contig_1720|7111|136|G|6a9f13baa13e23d0a|read-2|True|GTGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCA|
|000000130|SAMPLE-03|001|contig_1720|7111|135|G|72d19ae35f5136c1a|read-2|False|TGATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTA|
|000000131|SAMPLE-03|001|contig_1720|7111|134|G|529c1460d824e9bef|read-2|False|GATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTT|
|000000132|SAMPLE-03|001|contig_1720|7111|134|G|69c5dbf13623487fb|read-2|False|GATGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATTGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTCTATCTAA|
|000000133|SAMPLE-03|001|contig_1720|7111|132|G|fcd57363c61946297|read-2|False|TGATGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTG|
|000000134|SAMPLE-03|001|contig_1720|7111|129|G|c462177c026ee961e|read-2|True|TGATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTA|
|000000135|SAMPLE-03|001|contig_1720|7111|128|G|2295d9de5ef4cf13e|read-2|False|GATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGGGTTATGG|
|000000136|SAMPLE-03|001|contig_1720|7111|127|G|305879fc8883daf8d|read-2|True|ATGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAAT|
|000000137|SAMPLE-03|001|contig_1720|7111|126|G|5df2a0285fcc03a9e|read-2|False|TGTTAGATGTCGCCTTAGGTTAAGCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTATGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGG|
|000000138|SAMPLE-03|001|contig_1720|7111|126|G|ee2961de43ccb9aa1|read-2|False|TGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCATGAG|
|000000139|SAMPLE-03|001|contig_1720|7111|126|G|3c7c5b2afc9694223|read-2|True|TGTTAGATGTCGCCTTAGGTTAATCTCTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCT|
|000000140|SAMPLE-03|001|contig_1720|7111|126|G|0b0eb68568f992851|read-2|True|TGTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAACAACAATTTTATCTAATATGTCAGGAGTTATG|
|000000141|SAMPLE-03|001|contig_1720|7111|125|G|6ad74742e16c874d9|read-2|False|GTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATG|
|000000142|SAMPLE-03|001|contig_1720|7111|125|G|d8a10c29daa22874a|read-2|False|GTTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTA|
|000000143|SAMPLE-03|001|contig_1720|7111|124|G|2fcdca66158af9cc9|read-2|False|TTAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATC|
|000000144|SAMPLE-03|001|contig_1720|7111|123|G|eb182dc3869777d40|read-2|True|TAGATGTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTA|
|000000145|SAMPLE-03|001|contig_1720|7111|118|G|07067ba83a92c090d|read-2|False|GTCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAG|
|000000146|SAMPLE-03|001|contig_1720|7111|117|G|221720449a9df5f2e|read-2|False|TCGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTAT|
|000000147|SAMPLE-03|001|contig_1720|7111|116|G|6a32ac39d688c9342|read-2|True|CGCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTAT|
|000000148|SAMPLE-03|001|contig_1720|7111|115|G|7a35d6e5df5c0313c|read-2|True|GCCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGATGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTA|
|000000149|SAMPLE-03|001|contig_1720|7111|114|G|d71843e1b8dfc97c1|read-2|False|CCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGATATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATT|
|000000150|SAMPLE-03|001|contig_1720|7111|114|G|97810094800c2730d|read-2|False|CCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTT|
|000000151|SAMPLE-03|001|contig_1720|7111|114|G|a1a82ff1ac7d6c00a|read-2|True|CCTTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGTAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCT|
|000000152|SAMPLE-03|001|contig_1720|7111|113|G|e79875a99e454d374|read-2|False|CTTAGGTTAATCTTTACATAATCGTAAGGACCGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTT|
|000000153|SAMPLE-03|001|contig_1720|7111|112|G|6b818ac19ef9992b2|read-2|False|TTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTAT|
|000000154|SAMPLE-03|001|contig_1720|7111|112|G|33a1ab1044fbce5d2|read-2|True|TTAGGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCT|
|000000155|SAMPLE-03|001|contig_1720|7111|109|G|ed19fd79f7f532930|read-2|False|GGTTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAAT|
|000000156|SAMPLE-03|001|contig_1720|7111|107|G|2eb280af5a55f65d2|read-2|False|TTAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTT|
|000000157|SAMPLE-03|001|contig_1720|7111|106|G|d6295261bd3682093|read-2|False|TAATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAAT|
|000000158|SAMPLE-03|001|contig_1720|7111|106|G|e1324c70548d7aac2|read-2|False|TAATCTTTACATAATCTTAAGCAGAGTTGTATAGTTTCGTTTCTGTAGTTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAAT|
|000000159|SAMPLE-03|001|contig_1720|7111|106|G|e0ec923db2ffe9978|read-2|True|TAATCTTTACATAATCTTAAGCACAGTTGTATAGCTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGG|
|000000160|SAMPLE-03|001|contig_1720|7111|104|G|7cc251d99ddec1738|read-2|False|ATCTTTACATAATCTTAAGCACAGTTGTATAGTTTCGTTTCTGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAAT|
|000000161|SAMPLE-03|001|contig_1720|7111|100|G|18f3cf83405581ea6|read-2|False|TTACATAATCGTAAGCACAGTTGTATAGTTTCGTTTCAGTAATTAAGTAAAATGAGGTTAAAGAGGTGACAGAAATGAAAAAGAGATTAGGGTTAGGTTTGGGAATGTTTTTAATAACAATTTTATCTAATTTGTCAGGAGTTATGGCTTATAGTGGTAATAGTAATTTACCGGGAAGT|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|

Where

* `sample_id` matches to the input BAM file name,

* `request_id` matches to the order of the contig name in the input file,

* `pos_in_contig` marks the position of interest declared in the input file,

* and `pos_in_read` marks the actual location of the nucleotide in the short reads that corresponds to the position of interest.

This database contains the protein structural data for genes in a corresponding %(contigs-db)s and can be generated with %(anvi-gen-structure-database)s.


Currently, this database is best utilized for visualizing 3D structures with %(anvi-display-structure)s.  

For more information on the structure database, see [this blog post](http://merenlab.org/2018/09/04/getting-started-with-anvio-structure/#the-structure-database). 


{:.notice}
This artifact is currently a stub. I'm looking at you, Evan. - Evan

[Kegg Orthology](https://www.genome.jp/kegg/ko.html) (KO) functional annotations, produced by finding HMM hits to the KEGG KOfam database.

You can annotate a %(contigs-db)s with these KEGG functions by running %(anvi-run-kegg-kofams)s. They will be added to the gene functions table under the source 'KOfam'.

Another program that relies on these annotations is %(anvi-estimate-metabolism)s, which uses them to determine presence and completeness of metabolic pathways that are defined by KOs.
By default, anvi'o predicts protein structures using MODELLER when creating a %(structure-db)s. Yet, if the user provides an external structures file, then anvi'o does not perform template-based homology modelling, and instead uses this file to obtain the structure information for the %(structure-db)s.

External structures is a user-provided TAB-delimited file that should follow this format:

|gene_callers_id|path|
|:---:|:---|
|1|path/to/gene1/structure.pdb|
|2|path/to/gene2/structure.pdb|
|3|path/to/gene3/structure.pdb|
|4|path/to/gene4/structure.pdb|
|7|path/to/gene5/structure.pdb|
|8|path/to/gene6/structure.pdb|
|(...)|(...)|

Each path should point to a %(protein-structure-txt)s.

{:.notice}
Please note that anvi'o will try its best to test the integrity of each file, and work with any limitations, however ultimately the user may be subject to the strict requirements set forth by anvi'o. For example, if a structure has a missing residue, you will hear about it.

A gene call file from [AUGUSTUS](http://bioinf.uni-greifswald.de/augustus/). 

[AUGUSTUS](http://bioinf.uni-greifswald.de/augustus/) is a tool to predict genes from a variety of Eurkaryotic genomes. This includes predicting the 5' UTR and 3' UTR, as well as introns. You can search a sequence in the [Augustus web interface](http://bioinf.uni-greifswald.de/augustus/submission.php). After a search, you can export the results as a `.gff` text file.  

{:.notice}
As of now, Anvi'o (specifically %(anvi-script-augustus-output-to-external-gene-calls)s) is only tested with AUGUSTUS v3.3.3. Feel free to be adventurous and try other versions if you feel so inclined. 

You can convert this file into an anvi'o %(external-gene-calls)s file using %(anvi-script-augustus-output-to-external-gene-calls)s. 

Here is an example of a `.gff` file for the [Homo sapiens RNAP III subunit D sequence](https://www.ncbi.nlm.nih.gov/nuccore/NM_001722.3?report=fasta): 

    # This output was generated with AUGUSTUS (version 3.3.3).
    # AUGUSTUS is a gene prediction tool written by M. Stanke (mario.stanke@uni-greifswald.de),
    # O. Keller, S. KÃƒÂ¶nig, L. Gerischer, L. Romoth and Katharina Hoff.
    # Please cite: Mario Stanke, Mark Diekhans, Robert Baertsch, David Haussler (2008),
    # Using native and syntenically mapped cDNA alignments to improve de novo gene finding
    # Bioinformatics 24: 637-644, doi 10.1093/bioinformatics/btn013
    # No extrinsic information on sequences given.
    # Initializing the parameters using config directory /data/www/augustus/augustus/config/ ...
    # human version. Using default transition matrix.
    # Looks like /data/www/augustus/webservice/data/AUG-707407769/input.fa is in fasta format.
    # We have hints for 0 sequences and for 0 of the sequences in the input set.
    #
    # ----- prediction on sequence number 1 (length = 5336, name = unnamed-1) -----
    #
    # Predicted genes for sequence number 1 on both strands
    # start gene g1
    unnamed-1    AUGUSTUS    gene    57    1253    1    +    .    g1
    unnamed-1    AUGUSTUS    transcript    57    1253    1    +    .    g1.t1
    unnamed-1    AUGUSTUS    start_codon    57    59    .    +    0    transcript_id "g1.t1"; gene_id "g1";
    unnamed-1    AUGUSTUS    single    57    1253    1    +    0    transcript_id "g1.t1"; gene_id "g1";
    unnamed-1    AUGUSTUS    CDS    57    1253    1    +    0    transcript_id "g1.t1"; gene_id "g1";
    unnamed-1    AUGUSTUS    stop_codon    1251    1253    .    +    0    transcript_id "g1.t1"; gene_id "g1";
    # coding sequence = [atgtcggaaggaaacgccgccggcgagcccagcacgccgggagggccccgacctctcctgactggggcccgggggctca
    # tcgggcggcggccggcgcctcccctcacccccggccgccttccctccatccgttccagggacctcaccctcgggggagtcaagaagaaaaccttcacc
    # ccaaatatcatcagtcggaagatcaaggaagagcccaaggaagaagtaactgtcaagaaggagaagcgtgaaagggacagagaccgacaacgagaggg
    # gcatggacgagggcgaggccgtccagaagtgatccagtctcactccatctttgagcagggcccagctgaaatgatgaagaaaaaagggaactgggata
    # agacagtggatgtgtcagacatgggaccttctcatatcatcaacatcaaaaaagagaagagagagacagacgaagaaactaaacagatcttgcgtatg
    # ctggagaaggacgatttcctcgatgaccccggcctgaggaacgacactcgaaatatgcctgtgcagctgccgctggctcactcaggatggctttttaa
    # ggaagaaaatgacgaaccagatgttaaaccttggctggctggccccaaggaagaggacatggaggtggacatacctgctgtgaaagtgaaagaggagc
    # cacgagatgaggaggaagaggccaagatgaaggctcctcccaaagcagccaggaagactccaggcctcccgaaggatgtatctgtggcagagctgctg
    # agggagctgagcctcaccaaggaagaggaactgctgtttctgcagctgccagacaccctccctggccagccacccacccaggacatcaagcctatcaa
    # gacagaggtgcagggcgaggacggacaggtggtgctcatcaagcaggagaaagaccgagaagccaaattggcagagaatgcttgtaccctggctgacc
    # tgacagagggtcaggttggcaagctactcatccgcaagtctggaagggtgcaactcctcttgggcaaggtgactctggacgtgaccatgggaactgcc
    # tgctccttcctgcaggagctggtgtccgtgggccttggagacagtaggacaggggagatgacagtcctgggacacgtgaagcacaaacttgtatgttc
    # ccctgattttgaatccctcttggatcacaaacaccggtaa]
    # protein sequence = [MSEGNAAGEPSTPGGPRPLLTGARGLIGRRPAPPLTPGRLPSIRSRDLTLGGVKKKTFTPNIISRKIKEEPKEEVTVK
    # KEKRERDRDRQREGHGRGRGRPEVIQSHSIFEQGPAEMMKKKGNWDKTVDVSDMGPSHIINIKKEKRETDEETKQILRMLEKDDFLDDPGLRNDTRNM
    # PVQLPLAHSGWLFKEENDEPDVKPWLAGPKEEDMEVDIPAVKVKEEPRDEEEEAKMKAPPKAARKTPGLPKDVSVAELLRELSLTKEEELLFLQLPDT
    # LPGQPPTQDIKPIKTEVQGEDGQVVLIKQEKDREAKLAENACTLADLTEGQVGKLLIRKSGRVQLLLGKVTLDVTMGTACSFLQELVSVGLGDSRTGE
    # MTVLGHVKHKLVCSPDFESLLDHKHR]
    # end gene g1
    ###
    # command line:
    # /data/www/augustus/augustus/bin/augustus --species=human --strand=both --singlestrand=false --genemodel=partial --codingseq=on --sample=100 --keep_viterbi=true --alternatives-from-sampling=true --minexonintronprob=0.2 --minmeanexonintronprob=0.5 --maxtracks=2 /data/www/augustus/webservice/data/AUG-707407769/input.fa --exonnames=on

By default, anvi'o uses Prodigal for gene calling when the user is generating a %(contigs-db)s. Yet, if the user provides an external gene calls file, then anvi'o does not perform gene calling, and uses this file to store the gene information into the new %(contigs-db)s.

External gene calls is a user-provided TAB-delimited file that should follow this format:

|gene_callers_id|contig|start|stop|direction|partial|call_type|source|version|
|:---:|:---|:---:|:---:|:---:|:---:|:--:|:---:|
|1|contig_01|1113|1677|f|0|1|program|v1.0|
|2|contig_01|1698|2142|f|0|1|program|v1.0|
|3|contig_01|2229|3447|f|0|1|program|v1.0|
|4|contig_01|3439|6820|r|0|1|program|v1.0|
|7|contig_01|8496|10350|r|1|1|program|v1.0|
|8|contig_02|306|1650|f|0|1|program|v1.0|
|9|contig_02|1971|3132|f|0|1|program|v1.0|
|10|contig_02|3230|4007|f|0|1|program|v1.0|
|11|contig_02|4080|5202|f|0|1|program|v1.0|
|12|contig_02|5194|5926|f|0|1|program|v1.0|
|13|contig_03|606|2514|f|0|1|program|v1.0|
|14|contig_03|2751|3207|f|0|1|program|v1.0|
|15|contig_03|3219|5616|f|0|1|program|v1.0|
|16|contig_03|5720|6233|f|0|1|program|v1.0|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|

Please note that while anvi'o will not perform any gene prediction, it will still try to translate DNA sequence found in start-stop positions of each gene using the standard genetic code. You can prevent that by providing your own amino acid sequences by adding an optional column to your external gene calls file, `aa_sequence`:

|gene_callers_id|contig|start|stop|direction|partial|call_type|source|version|aa_sequence|
|:---:|:---|:---:|:---:|:---:|:---:|:---:|:--:|:--|
|1|contig_01|1113|1677|f|0|1|program|v1.0|MAQTTNDIKNGSVLNLDGQLWTVI(...)|
|2|contig_01|1698|2142|f|0|1|program|v1.0|MARSTARKRALNTLYEADEKGQDI(...)|
|3|contig_01|2229|3447|f|0|1|program|v1.0|MNQYDSEAVMFDPQDAVLVLEDGQ(...)|
|4|contig_01|3439|6820|r|0|1|program|v1.0|MPKRTDIKSVMVIGSGPIVIGQAA(...)|
|7|contig_01|8496|10350|r|1|1|program|v1.0|MMSSPSSEEVNAQRSDFGLRLSNS(...)|
|8|contig_02|306|1650|f|0|1|program|v1.0|MADSQHGRLIVLCGPAGVGKGTVL(...)|
|9|contig_02|1971|3132|f|0|1|program|v1.0|MRSAKLMNGRVFAGARALYRAAGV(...)|
|10|contig_02|3230|4007|f|0|1|program|v1.0|MAFGTEPTPTGLADPPIDDLMEHA(...)|
|11|contig_02|4080|5202|f|0|1|program|v1.0|MAELKLISAESVTEGHPDKVCDQI(...)|
|12|contig_02|5194|5926|f|0|1|program|v1.0|MRYPCIMTNEDAEQLALDGLAPRK(...)|
|13|contig_03|606|2514|f|0|1|program|v1.0|MTLTLRMEKRMKGWPGEPQMEYDV(...)|
|14|contig_03|2751|3207|f|0|1|program|v1.0|MLKVLFAGTPDVAVPSLKLLAQDT(...)|
|15|contig_03|3219|5616|f|0|1|program|v1.0|MLEQETPNIASMASLPTLSAPGLL(...)|
|16|contig_03|5720|6233|f|0|1|program|v1.0|MLESEVDMNDHDEETLASLQQAND(...)|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|

Explicitly defining amino acid sequences could be particularly useful when working with eukaryotic genomes, and/or genomes that use non-standard genetic code. Sections below discuss specific information about columns of this file.

### Gene start/stop positions

Anvi'o follows the convention of string indexing and splicing that is identical to the way one does it in Python or C. This means that the index of the first nucleotide in any contig should be `0`. In other words, for a gene call that starts at the position `x`th position and ends at position `y`th position, we start counting from `x-1`, and not from `x` (but we still end at `y`). The `start` and `stop` positions in the input file should comply with this criterion. Here is an example gene in a contig:

``` bash
                 1         2         3
nt pos: 12345678901234567890123456789012 (...)
contig: NNNATGNNNNNNNNNNNNNNNNNTAGAAAAAA (...)
           |______ gene X _______|
```

The `start` and `stop` positions in the input file for this gene should be `3` and `26`, respectively. Which means, if you are trying to generate an external gene calls file from gene calls produced by a gene caller that reports start/stop positions starting with the index of `1` rather than `0`, you basically need to subtract one from the start position of every gene call for a matching anvi'o external gene calls file.

Gene `start` and `stop` positions do not care about the direction of the gene as they simply address how the gene sequence should be sliced out from a longer sequence. Whether a gene is forward or reverse is defined in the column `direction`.

{:.notice}
You can read the previous discussions regarding this behavior in [this issue](https://github.com/meren/anvio/issues/374)). Thanks for your patience!

### Call type

{:.notice}
This is a feature added after anvi'o `v6.2`. If you are using anvi'o `v6.2` or earlier, please remove `call_type` column from your external gene calls file.

The column `call_type` declares the nature of the call. It can take one of the following three integer values:

* `1`, indicates that the gene call is for a CODING gene. For gene calls marked as CODING genes, anvi'o will try to predict the proper coding frame when %(anvi-gen-contigs-database)s is run using Markov models trained on a large number of protein sequences and was first described in this [pull request](https://github.com/merenlab/anvio/pull/1428). This is the default behavior for CODING sequences regardless of whether the gene call is partial or not. However, there are two ways the user can change this: (1) by providing an amino acid sequence for the call in the `aa_sequence` column or (2) by asking %(anvi-gen-contigs-database)s to `--skip-predict-frame`.

* `2`, indicates that the gene call is for a NONCODING gene. This is used for non-coding RNAs (transfer RNAs or ribosomal RNAs). For gene calls marked as NONCODING, anvi'o will not attempt to predict an amino acid sequence (nor it will tolerate entries in the `aa_sequence` column).

* `3`, indicates that the gene call is for an UNKNOWN genomic region. This is currently reserved for experimental purposes.
This describes **the taxonomy information for the genes in your %(contigs-db)s**. 

You can use %(anvi-import-taxonomy-for-genes)s to import this information through a %(gene-taxonomy-txt)s, either from external data or by using software like [Kaiju](https://github.com/bioinformatics-centre/kaiju) or [Centrifuge](https://github.com/infphilo/centrifuge). See [this blog post](http://merenlab.org/2016/06/18/importing-taxonomy/) for a comprehensive tutorial. 

Once this information is populated, it will be displayed in most downstream interfaces, including %(anvi-interactive)s. 

You can also add taxonomy information for the layers in your interface (most likely sections of your sample when analyzing a single sample) using %(anvi-import-taxonomy-for-layers)s, or at the genome or metagenome level using %(anvi-estimate-scg-taxonomy)s. 
An HMM source is a collection of one or more hidden Markov models. HMM sources can be used to identify and recover genes in a %(contigs-db)s that match to those described in the model.

Models in a given HMM source can be searched in a given %(contigs-db)s via the program %(anvi-run-hmms)s which would yield an %(hmm-hits)s artifact. An anvi'o installation will include multiple HMM sources by default. But HMMs for any set of genes can also be put together by the end user and run on any anvi'o %(contigs-db)s.

HMM hits in a %(contigs-db)s for a given %(hmm-source)s source will be accessible to anvi'o programs globally. Sequences that match to HMM hits can be recovered in an aligned or non-aligned fashion as %(fasta)s files for downstream analyses including phylogenomics, they can be displayed in anvi'o interfaces, reported in summary outputs, and so on.

Running %(anvi-db-info)s on a %(contigs-db)s will list HMM sources available in it.

### Default HMM sources

An anvi'o installation will include [multiple HMM sources](https://github.com/meren/anvio/tree/master/anvio/data/hmm) by default. These HMM sources can be run on any %(contigs-db)s with %(anvi-run-hmms)s to identify and store %(hmm-hits)s:

{{ codestart }}
%(anvi-run-hmms)s -c %(contigs-db)s
{{ codestop }}

The default HMM sources in anvi'o include:

* **Bacteria_71**: 71 single-copy core genes for domain bacteria that represent a modified version of the HMM profiles published by [Mike Lee](https://doi.org/10.1093/bioinformatics/btz188). The anvi'o collection excludes `Ribosomal_S20p`, `PseudoU_synth_1`, `Exonuc_VII_S`, `5-FTHF_cyc-lig`, `YidD` and `Peptidase_A8` occurred in Lee collection (as they were exceptionally redundant or rare among MAGs from various habitats), and includes `Ribosomal_S3_C`, `Ribosomal_L5`, `Ribosomal_L2` to make it more compatible with [Hug et al](https://www.nature.com/articles/nmicrobiol201648)'s set of ribosomal proteins.
* **Archaea_76**: 76 single-copy core genes for domain archaea by [Mike Lee](https://doi.org/10.1093/bioinformatics/btz188).
* **Protista_83**: 83 single-copy core genes for protists (domain eukarya) by [Tom O. Delmont](http://merenlab.org/delmont-euk-scgs).

Apart from these, anvi'o also includes a number of HMM profiles for individual ribosomal RNA classes derived from [Torsten Seemann's tool](https://github.com/tseemann/barrnap) (we split them into individual classes after [this](https://github.com/merenlab/anvio/issues/1411)):

* **Ribosomal\_RNA\_5S** (eukarya + archaea + bacteria; also includes 5.8S).
* **Ribosomal\_RNA\_12S** (mitochondria)
* **Ribosomal\_RNA\_16S** (bacteria + archaea + mitochondria)
* **Ribosomal\_RNA\_18S** (eukarya)
* **Ribosomal\_RNA\_23S** (bacteria + archaea)
* **Ribosomal\_RNA\_28S** (eukarya)

When %(anvi-run-hmms)s is run on an anvi'o %(contigs-db)s without providing any further arguments, it automatically utilizes all the default HMM sources.

{:.notice}
Similar to Ribosomal RNAs, anvi'o can also identify Transfer RNAs. Even though Transfer RNAs will also appear as an HMM source for all downstream analyses, their initial identification will require running %(anvi-scan-trnas)s program on a %(contigs-db)s.

### User-defined HMM sources

The user can employ additional HMM sources to identify matching genes in a given %(contigs-db)s.

Any directory with expected files in it will serve as an HMM source:

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              --hmm-source /PATH/TO/USER-HMM-DIRECTORY/
{{ codestop }}

Anvi'o will expect the HMM source directory to contain six files (see this for [an example directory](https://github.com/merenlab/anvio/tree/master/anvio/data/hmm/Protista_83)). These files are explicitly defined as follows:

* **genes.hmm.gz**: A gzip of concatenated HMM profiles. One can (1) obtain one or more HMMs by computing them from sequence alignments or by downloading previously computed ones from online resources such as [Pfams](https://pfam.xfam.org/family/browse?browse=new), (2) concatenate all profiles into a single file called `genes.hmm`, and finally (3) compress this file using `gzip`.
* **genes.txt**: A TAB-delimited file that must contain three columns: `gene` (gene name), `accession` (gene accession number (can be anything unique)), and `hmmsource` (source of HMM profiles listed in genes.hmm.gz). The list of gene names in this file must perfectly match to the list of gene names in genes.hmm.gz.
* **kind.txt**: A flat text file which contains a single word identifying what type of profile the directory contains. This information will appear in interfaces. Use a single, descriptive word for your collection.
* **reference.txt**: A file containing source information for this profile to cite it properly.
* **target.txt**: A file that specifies the target *alphabet* and  *context* that defines how HMMs should be searched (this is a function of the HMM source that is used). The proper notation is 'alphabet:context'. Alphabet can be `AA`, `DNA`, or `RNA`. Context can be `GENE` or `CONTIG`. The content of this file should be any combination of one alphabet and one context term. For instance, if the content of this file is `AA:GENE`, anvi'o will search genes amino acid sequences, and so on. An exception is `AA:CONTIG`, which is an improper target since anvi'o can't translate contigs to amino acid sequences. See [this](https://github.com/meren/anvio/pull/402) for more details. Please note that HMMs that target `DNA:CONTIG` will result in new gene calls in the contigs database to describe their hits.
* **noise_cutoff_terms.txt**: A file to specify how to deal with noise. [See this comment](https://github.com/merenlab/anvio/issues/498#issuecomment-362115921) for more information on the contents of this file.


### Creating anvi'o HMM sources from ad hoc PFAM accessions

It is also possible to generate an anvi'o compatible HMMs directory for a given set of PFAM accession ids. For instance, the following command will result in a new directory that can be used immediately with the program %(anvi-run-hmms)s:

{{ codestart }}
%(anvi-script-pfam-accessions-to-hmms-directory)s --pfam-accessions-list PF00705 PF00706 \
                                               -O AD_HOC_HMMs
{{ codestop }}

These IDs can be given through the command line as a list, or through an input file where every line is a unique accession id.

An example. Let's assume we have a genome or a metagenome that looks like this:

![PFAM example](../../images/p214-wo-upxz.png)

And we wish to identify locations of genes that match to this model: [http://pfam.xfam.org/family/PF06603](http://pfam.xfam.org/family/PF06603)

One can run this command:

{{ codestart }}
%(anvi-script-pfam-accessions-to-hmms-directory)s --pfam-accessions-list PF06603 \
                                                -O UpxZ
{{ codestop }}

which would createa a directory called `UpxZ`. Then, one would run this command to find matches to this model in a given contigs database:

{{ codestart }}
%(anvi-run-hmms)s -c CONTIGS.db \
               -H UpxZ/ \
               --num-threads 4
{{ codestop }}

Now it is possible to get the sequences matching to this model:

{{ codestart }}
%(anvi-get-sequences-for-hmm-hits)s -c CONTIGS.db \
                                 --hmm-source UpxZ \
                                 -o UpxZ.fa
{{ codestop }}

```
Contigs DB ...................................: Initialized: CONTIGS.db (v. 19)
Hits .........................................: 8 hits for 1 source(s)
Mode .........................................: DNA sequences
Genes are concatenated .......................: False
Output .......................................: UpxZ.fa
```

Or see where they are by visualizing the project using again:

{{ codestart }}
%(anvi-interactive)s -p PROFILE.db \
                  -c CONTIGS.db
{{ codestop }}

![PFAM example](../../images/p214-w-upxz.png)
A single sequence in DNA alphabet that is **not** stored in or provided by a standard file, such as a %(fasta)s file.

A typical sequence artifact in the anvi'o ecosystem will be provided by the user to a sequence accepting program through the command line, or will be printed out into the terminal environment by a program that provides it.
A [FASTA](https://en.wikipedia.org/wiki/FASTA_format) file that does not necessarily meet the standards of a %(contigs-fasta)s. While it is not necessary for all programs, if a given anvi'o program requires a %(contigs-fasta)s, the program %(anvi-script-reformat-fasta)s can turn a regular fasta into a %(contigs-fasta)s with the flag `--simplify-names`.

### What is a FASTA file?

A FASTA file typically contains one or more DNA, RNA, or amino acid sequences that are formatted as follows:

```
>SEQUENCE_ID VARIOUS_SEQUENCE_DATA
SEQUENCE
(...)
```

The line that starts with the character `>` is also known as the 'defline' for a given sequence. The `VARIOUS_SEQUENCE_DATA` region of the defline can be empty, or contain additional data such as the NCBI taxon ID, GI accession number, a text description of the sequence, or the start and end positions if the sequence is a portion of a larger sample. Because the FASTA file format was designed before there weren't even enough electronic calculators on the planet, there is no actual standard format to organize additional information shared in the defline.

The sequence itself is typically written in standard [IUPAC format](https://en.wikipedia.org/wiki/Nucleic_acid_notation), although you may find FASTA files with sequences that contain lower-case letter, mixed letters, no letters, or pretty much anything really. Over the years we have seen everything, and suggest you to take a careful look at your FASTA files before doing anything with them unless you generated them yourself.

You can learn more about the FASTA format on its [glorious Wikipedia page](https://en.wikipedia.org/wiki/FASTA_format).
This artifact contains all of the information provided in the interface of %(anvi-display-contigs-stats)s in a series of tab-delimited files. See that page for more information. 
A fixation index matrix is what it sounds like (a matrix of fixation indices) and is generated by %(anvi-gen-fixation-index-matrix)s. 

This is a distance matrix where each column represnts a metagenome/sample and each row represents a metagenome/sample, so each cell represents the fixation index between two samples. The fixation index is a number from 0 (maximum similiarity) to 1 (maximum distance). 

This is a form of %(view-data)s, so it can be provided to %(anvi-matrix-to-newick)s as is done in the [Infant Gut tutorial](https://merenlab.org/tutorials/infant-gut/#measuring-distances-between-metagenomes-with-fst). 

For example, here is the fixation index matrix based off of a few random genes (1, 2, 3, 5, 6, 7, 8, 9, 21, 32, 35, 56, 567) in the infant gut tutorial: 

               DAY_15A               DAY_15B                DAY_16                 DAY_17A                 DAY_17B               DAY_18                  DAY_19                  DAY_22A                 DAY_22B                DAY_23                  DAY_24
    DAY_15A    0.0                   0.04918776635439459    0.11098963862572608    0.047199977957045336    0.0                   0.08439930158545839     0.06141920095408482     0.09624218229853498     0.0                    0.04711838006230529     0.08709060259498314
    DAY_15B    0.04918776635439459   0.0                    0.07095764349628797    0.04742239843190177     0.04918776635439459   0.058754132113538526    0.012860485049109083    0.056111593790529324    0.04918776635439459    0.012757678005705375    0.05031628777187558

    ...
A TAB-delimited file of [palindromic sequences](https://en.wikipedia.org/wiki/Palindromic_sequence) reported by %(anvi-search-palindromes)s.

The following example is the output generated by the command below when it was run on %(contigs-db)s of the [Infant Gut Dataset](/tutorials/infant-gut/#downloading-the-pre-packaged-infant-gut-dataset):

{{ codestart }}
%(anvi-search-palindromes)s -c CONTIGS.db \
                         --min-palindrome-length 50 \
                         --max-num-mismatches 1 \
                         --output-file palindromes.txt
{{ codestop }}

|sequence_name|length|distance|num_mismatches|first_start|first_end|first_sequence|second_start|second_end|second_sequence|midline|
|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|Day17a_QCcontig1|48|0|0|195100|195148|AAGAGAAGAGGAGAAGTTCATCCATGGATGAACTTCTCCTCTTCTCTT|195100|195148|AAGAGAAGAGGAGAAGTTCATCCATGGATGAACTTCTCCTCTTCTCTT|`||||||||||||||||||||||||||||||||||||||||||||||||`|
|Day17a_QCcontig4|147|759|1|268872|269019|TTTCGTAATACTTTTTTGCAGTAGGCATCAAATTGGTGTTGTATAGATTTCTCATTATAATTTTGTTGCATGATAATATGCTCCTTTTTCCCCTTTCCACTAATACAACAATCAGAGAGCCCCTTTTTTTCGAAAAAGCTAGAAAAA|269631|269778|TTTCGTAATACTTTTTTGCAGTAGGCATCAAATTGGTGTTGTATAGATTTCTCATTATAATTTTGTTGCATGATAATATGCTCCTTTTTCCCCTTTCCACTAATACAACAATCAGAGAGCCCCTTTTTTTCGAAAAAACTAGAAAAA|`|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||x|||||||||`|
|Day17a_QCcontig4|53|1956|1|268237|268290|CAGCTGCTTTTGTCAAAAGCACATAGGAATTTCACCTCTCCCCAAGTTTACGG|270193|270246|CAGCTGCTTTTGTCAAAAGCACATAGGAATTTCACCTCTCTCCAAGTTTACGG|`||||||||||||||||||||||||||||||||||||||||x||||||||||||`|
|Day17a_QCcontig4|66|1956|1|268325|268391|ATCATCACTTTTTATTGACTATAAAAATTATTTTAGAATATTTATCGCTCCTTCTTTACGATAAGA|270281|270347|ATCATCACTTTTTATTGACTATAAAAATTATTTTAGAATGTTTATCGCTCCTTCTTTACGATAAGA|`|||||||||||||||||||||||||||||||||||||||x||||||||||||||||||||||||||`|
|Day17a_QCcontig4|60|98694|1|16368|16428|AGAACAATTTTCGGAAATTCCTTCTTATTTCTCGGAGTTAAACGCTTCTGTCCCGACCTC|115062|115122|AGAACAATTTTCGGAAATTCCTTCTTATTTCTCGGAGTTAAACACTTCTGTCCCGACCTC|`|||||||||||||||||||||||||||||||||||||||||||x||||||||||||||||`|
|Day17a_QCcontig16|42|0|0|105735|105777|AAAAAGAACGCTCTTTTGCTTAAGCAAAAGAGCGTTCTTTTT|105735|105777|AAAAAGAACGCTCTTTTGCTTAAGCAAAAGAGCGTTCTTTTT|`||||||||||||||||||||||||||||||||||||||||||`|
|Day17a_QCcontig23|50|0|0|51287|51337|ATAAATAAACAGAGGCCTTAGAAATATTTCTAAGGCCTCTGTTTATTTAT|51287|51337|ATAAATAAACAGAGGCCTTAGAAATATTTCTAAGGCCTCTGTTTATTTAT|`||||||||||||||||||||||||||||||||||||||||||||||||||`|

In which,

* `sequence_name` is the sequence name on which a given palindrome was found.
* `length` is the the length of the palindrome.
* `distance` is the number of nucleotides between the location of the palindromic sequences in the larger seqeunce.
* `num_mismatches` is the number of actual nucleotides in the palindrome sequence that did not match to its counterpart when the sequence was reverse-complemented.
* `first_start` is the start position of the first palindrome in the reference sequence.
* `first_end` is the end position of the first palindrome.
* `second_start` and `second_end` are just like `first_start` and `first_end` but for the second sequence. For perfect palindromes (i.e., palindromes with zero distance), these values will be identical to their counterparts in the first sequence.
* `first_sequence` and `second_sequence` are the actual nucleotide sequences of both. They will be identical if number of mismatches are zero. Please note that only the reverse complement of the `second_sequence` will be found in the reference sequnce.
* `midline` an array of letters that are composed of `|` and `x` characters that show where the matching and mismatching nucleotides were (if any).

**Please note** that the `sequence_name` column may not have unique sequence names if multiple palindromes found on the same sequence (which almost certainly be the case for most searches on circular genomes).

**Please also note** that the `start` and `end` positions are *0-indexed*, which means (1) the first nucleotide in the sequence should be counted as the zeroth element, and (2) if you do this in Python using the example above, you will get the matching palindrome from the larger sequence context:

``` python
contig_sequences[Day17a_QCcontig1][195100: 195148]

>>> AAGAGAAGAGGAGAAGTTCATCCATGGATGAACTTCTCCTCTTCTCTT
```This is the output of %(anvi-export-splits-taxonomy)s. It is in the same format as a %(gene-taxonomy-txt)s, namely the first column identifies splits and the following columns describe the taxonomy hit associated with that split. 

For example:

    split_id  t_domain     t_phylum       t_class      ...
    1         Eukarya      Chordata       Mammalia
    2         Prokarya     Bacteroidetes  Bacteroidia
    ...

This file describes all of the gene calls contained in a %(contigs-db)s from a specified list of sources. It is the output of %(anvi-export-gene-calls)s. 

For each gene identified, this file provides various information, including the caller ID, [start and stop position](http://merenlab.org/software/anvio/help/artifacts/external-gene-calls/#gene-startstop-positions), direction, whether or not the gene is partial, the [call type](http://merenlab.org/software/anvio/help/artifacts/external-gene-calls/#call-type), source and version (if available ), and the amino acid sequence. 

{:.notice}
Want more information? This file is in the same format as an %(external-gene-calls)s, so check out that page. 

Here is an example from the Infant Gut Dataset: 

    gene_callers_id    contig              start    stop    direction    partial    call_type    source     version   aa_sequence
    0                  Day17a_QCcontig1    0        186     f            1          1            prodigal   v2.60     GSSPTAGVEQKQKPTWFLLFLFYSLFFDKLEEGTLKTFIRLKGSYRRMNTSNFSYGIMCLL
    1                  Day17a_QCcontig1    214      1219    f            0          1            prodigal   v2.60     MKILLYFEGEKILAKSGIGRALDHQKRALSEVGIEYTLDADCSDYDILHINTYGVNSHRMVRKARKLGKKVIYHAHSTEEDFRNSFIGSNQLAPLVKKYLISLYSKADHLITPTPYSKTLLEGYGIKVPISAISNGIDLSRFYPSEEKEQKFREYFKIDEEKKVIICVGLFFERKGITDFIEVARQLPEYQFIWFGDTPMYSIPKNIRQLVKEDHPENVIFPGYIKGDVIEGAYAAANLFFFPSREETEGIVVLEALASQQQVLVRDIPVYQGWLVANENCYMGHSIEEFKKYIEGLLEGKIPSTREAGYQVAEQRSIKQIGYELKEVYETVLS
    2                  Day17a_QCcontig1    1265     2489    f            0          1            prodigal   v2.60     MKIGFFTDTYFPQVSGVATSIKTLKDELEKHGHEVYIFTTTDPNATDFEEDVIRMPSVPFVSFKDRRVVVRGMWYAYLIAKELELDLIHTHTEFGAGILGKMVGKKMKIPVIHTYHTMYEDYLHYIAKGKVVRPSHVKFFSRVFTNHTTGVVCPSERVIEKLRDYGVTAPMRIIPTGIEIDKFLRPDITEEMIAGMRQQLGIEEQQIMLLSLSRISYEKNIQAIIQGLPQVIEKLPQTRLVIVGNGPYLEDLKELAEELEVSEYVQFTGEVPNEEVAIYYKAADYFVSASTSETQGLTYTEAMAAGVQCVAEGNAYLNNLFDHESLGKTFKTDSDFAPTLIDYIQANIKMDQTILDEKLFEISSTNFGNKMIEFYQDTLIYFDQLQMEKENADSIKKIKVKFTSLRK
    ...

A state describes the configuration of the anvi'o %(interactive)s interface (i.e. the cosmetic and organizational settings that you have enabled). 

From the interface, the bottom section of the left panel enables you to save and load states. You also have the option to import states with %(anvi-import-state)s or export them with %(anvi-export-state)s. You can also delete states you no longer need anymore with %(anvi-delete-state)s. 

Here is the information stored in a state:
* The current item (see %(misc-data-items)s) and layers (see %(misc-data-layers)s) displayed
    * related information, like the minimum and maximum value for the data displayed in each layer, 
* The current items order (see %(misc-data-items-order)s) and layers order (see %(misc-data-layer-orders)s)
* The views you have available 
* Any sample groups you have 
* Various cosmetic settings, like font size, angles, dimensions, colors, whether or not labels are displayed, etc. 
    * This includes whether your display is in circles or rectangles 
    
No more having to manually set parameters like your layer order for each bin you look at! Just save a state when the interface is adjusted to your liking, and using anvi'o will be that much easier. 

This artifact is the output tables that are displayed when you run %(anvi-estimate-scg-taxonomy)s or %(anvi-estimate-trna-taxonomy)s. 

By default, they won't be outputed anywhere, just displayed in the terminal for your viewing pleasure. If you want them in a tab-delimited file (as a %(genome-taxonomy-txt)s), just provide the `-o` or the `-O` prefix and anvi'o will do that for you.

The content of these tables will depend on how you ran %(anvi-estimate-trna-taxonomy)s or %(anvi-estimate-scg-taxonomy)s. [This blog post](http://merenlab.org/2019/10/08/anvio-scg-taxonomy/#estimating-taxonomy-in-the-terminal) gives you examples of what this looks like for each of the input scenarios for anvi-estimate-scg-taxonomy. Anvi-estimate-scg-taxonomy's output is very similar, just with the results coming from different gene types. They will also be briefly described below. 

When you run %(anvi-estimate-scg-taxonomy)s or %(anvi-estimate-scg-taxonomy)s on 

- a single genome, this table will contain a single line telling you the taxonomy estimate for your genome. It will also show the number of single-copy core genes or tRNA genes that support this estimate. If you run the `--debug` flag, it will also display the hits for all of the single-copy core genes.  
- a single metagenome, this table will list all of the hits for the chosen single-copy core gene or anticodon (by default, the one with the most hits) and their taxonomy information.   
- a %(contigs-db)s and %(profile-db)s with the flag `--compute-scg-coverages`, additional columns will be added that describe the coverage values for your single-copy core gene or tRNA gene hits across your samples.   
- a %(collection)s, this table will show you each of your bins, and the best taxonomy estimate for each one, similarly to how it's displayed for a run on a single genome. 
- a %(metagenomes)s artifact, this table will give a gene entry ID, its taxonomy, and its corresponding coverage in your metagenomes. This format is essentially identical to the output for a single metagenome. If you provide the flag `--matrix-format`, then it will list taxonomy information in each row, and tell you the coverage of each in each of your metagenomes.   

This may sound confusing, but it is easier to understand when looking at the functionality of %(anvi-estimate-scg-taxonomy)s and the comprehensive examples given on [this page](http://merenlab.org/2019/10/08/anvio-scg-taxonomy/#estimating-taxonomy-in-the-terminal).
An anvi'o database that **contains key information about the mapping of short reads *from multiple samples* to your contigs.** 

You can think of this as a extension of a %(contigs-db)s that contains information about how your contigs align with each of your samples. The vast majority of programs that use a profile database will also ask for the contigs database associated with it. 

A profile database contains information about how short reads map to the contigs in a %(contigs-db)s. Specificially, for each sample, a profile database contains
* the coverage and abundance per nucleotide position for each contig
* variants of various kinds (single-nucleotide, single-codon, and single-amino acid)
* structural variants (ex. insertions and deletions)
These terms are explained on the [anvi'o vocabulary page](http://merenlab.org/vocabulary/)

This information is neccessary to run anvi'o programs like %(anvi-cluster-contigs)s, %(anvi-estimate-metabolism)s, and %(anvi-gen-gene-level-stats-databases)s. You can also interact with a profile database using programs like %(anvi-interactive)s.

Technically, "profile-db" refers to a profile database that contains the data from several samples -- in other words, the result of running %(anvi-merge)s on several %(single-profile-db)s. However, since a %(single-profile-db)s has a lot of the functionality of a profile-db, it might be easier to think of a profile database as a header referring to both single-profile-dbs and profile-dbs (which can also be called a merged-profile-dbs). For simplicity's sake, since most users are dealing with multiple samples, the name was shortened to just profile-db. The following are a list of differences in functionality between a single profile database and a merged profile database:
* You can run %(anvi-cluster-contigs)s or %(anvi-mcg-classifier)s on only a merged profile database (or profile-db), since they look at the allignment data in many samples
* You cannot run %(anvi-merge)s or %(anvi-import-taxonomy-for-layers)s on a merged profile database, only on a %(single-profile-db)s.

## How to make a profile database

### If you have multiple samples
1. Prepare your %(contigs-db)s
2. Run %(anvi-profile)s with an appropriate %(bam-file)s. The output of this will give you a %(single-profile-db)s. You will need to do this for each of your samples, which have been converted into a %(bam-file)s with your short reads.
3. Run %(anvi-merge)s on your %(contigs-db)s (from step 1) and your %(single-profile-db)ss (from step 2). The output of this is a profile-db.

### If you have a single sample
1. Prepare your %(contigs-db)s
2. Run %(anvi-profile)s with an appropriate %(bam-file)s. The output of this will give you a %(single-profile-db)s. You can see that page for more information, but essentially you can use a single-profile-db instead of a profile database to run most anvi'o functions.

## Variants

Profile databases, like %(contigs-db)ss, are allowed to have different variants, though the only currently implemented variant, the %(trnaseq-profile-db)s, is for tRNA transcripts from tRNA-seq experiments. The default variant stored for "standard" profile databases is `unknown`. Variants should indicate that substantially different information is stored in the database. For instance, single codon variability is applicable to protein-coding genes but not tRNA transcripts, so SCV data is not recorded for the `trnaseq` variant. The $(trnaseq-workflow)s generates %(trnaseq-profile-db)ss using a very different approach to %(anvi-profile)s.
A type of database containing information from either A) the [KEGG MODULE database](https://www.genome.jp/kegg/module.html), or B) user-defined metabolic modules, for use in metabolism estimation and/or functional annotation of KEGG Orthologs (KOs).

These databases are part of the %(kegg-data)s and %(user-modules-data)s directories. You can get one on your computer by running %(anvi-setup-kegg-kofams)s or %(anvi-setup-user-modules)s. Programs that rely on this type of database include %(anvi-run-kegg-kofams)s and %(anvi-estimate-metabolism)s.

Most users will never have to interact directly with this kind of database. However, for the brave few who want to try this (or who are figuring out how anvi'o works under the hood), there is some relevant information below.

## Database Contents

### The modules table

In the current implementation, data about each metabolic pathway (from the KEGG MODULE database, or from user-defined modules) is present in the `modules` table, which looks like this:

| module | data_name | data_value | data_definition | line |
|:--|:--|:--|:--|:--|
| M00001 | ENTRY	| M00001 | Pathway | 1 |
| M00001 | NAME	| Glycolysis (Embden-Meyerhof pathway), glucose => pyruvate | _NULL_ | 2 |
| M00001 | DEFINITION | (K00844,K12407,K00845,K00886,K08074,K00918) (K01810,K06859,K13810,K15916) (K00850,K16370,K21071,K00918) (K01623,K01624,K11645,K16305,K16306) K01803 ((K00134,K00150) K00927,K11389) (K01834,K15633,K15634,K15635) K01689 (K00873,K12406) | _NULL_ | 3 |
| M00001 | ORTHOLOGY | K00844	| hexokinase/glucokinase [EC:2.7.1.1 2.7.1.2] [RN:R01786] | 4 |
| M00001 | ORTHOLOGY | K12407	| hexokinase/glucokinase [EC:2.7.1.1 2.7.1.2] [RN:R01786] | 4 |
| (...) | (...) | (...) | (...) | (...) |

For the MODULES.db that comes out of %(anvi-setup-kegg-kofams)s, these data correspond to the information that can be found on the KEGG website for each metabolic module - for an example, you can see the page for [M00001](https://www.genome.jp/dbget-bin/www_bget?md:M00001) (or, alternatively, its [flat text file version](http://rest.kegg.jp/get/M00001) from the KEGG REST API).

The USER_MODULES.db that comes out of %(anvi-setup-user-modules)s contains similar information, but defined by the user instead of downloaded from the KEGG website.

In either case, the `module` column indicates the module ID number while the `data_name` column indicates what type of data the row is describing about the module. These data names are usually fairly self-explanatory - for instance, the `DEFINITION` rows describe the module definition and the `ORTHOLOGY` rows describe the enzymes belonging to the module - however, for an official explanation, you can check [the KEGG help page](https://www.genome.jp/kegg/document/help_bget_module.html).

The `data_value` and `data_definition` columns hold the information corresponding to the row's `data_name`; for `ORTHOLOGY` fields these are the enzyme accession number and its functional annotation, respectively. Not all rows have a `data_definition` field.

Finally, some rows of data originate from the same line in the original KEGG MODULE text file; these rows will have the same number in the `line` column. Perhaps this is a useless field. But it is there.

### The database hash value

In the `self` table of this database, there is an entry called `hash`. This string is a hash of the contents of the database, and it allows us to identify the version of the data within the database. This value is important for ensuring that the same MODULES.db is used both for annotating a contigs database with %(anvi-run-kegg-kofams)s and for estimating metabolism on that contigs database with %(anvi-estimate-metabolism)s.

You can easily check the hash value by running the following:

{{ codestart }}
anvi-db-info %(modules-db)s
{{ codestop }}

It will appear in the `DB Info` section of the output, like so:
```
DB Info (no touch also)
===============================================
num_modules ..................................: 443
total_entries ................................: 13720
creation_date ................................: 1608740335.30248
hash .........................................: 45b7cc2e4fdc
```

If you have annotated a %(contigs-db)s using %(anvi-run-kegg-kofams)s, you would find that the corresponding hash in that contigs database matches to this one:

{{ codestart }}
anvi-db-info %(contigs-db)s
{{ codestop }}

```
DB Info (no touch also)
===============================================
[....]
modules_db_hash ..............................: 45b7cc2e4fdc
```

### Other important values in the self table

The `data_source` key will tell you if the current database was generated from KEGG data using %(anvi-setup-kegg-kofams)s or from user-defined metabolic modules using %(anvi-setup-user-modules)s.

The `annotation_sources` key will list the functional annotation sources that are required to annotate all enzymes found in the module definitions.

Here is an example of what these fields look like for a KEGG MODULES.db:
```
DB Info (no touch also)
===============================================
data_source ..................................: KEGG
annotation_sources ...........................: KOfam
```

And here is an example of what they look like for a USER_MODULES.db:
```
DB Info (no touch also)
===============================================
data_source ..................................: USER
annotation_sources ...........................: KOfam,UpxZ,COG20_FUNCTION
```

## Querying the database

If you want to extract information directly from a modules database, you can do it with a bit of SQL :)

Here is one example, which obtains the name of every module in the default KEGG database:

```
# learn where the MODULES.db is:
export ANVIO_MODULES_DB=`python -c "import anvio; import os; print(os.path.join(os.path.dirname(anvio.__file__), 'data/misc/KEGG/MODULES.db'))"`
# get module names:
sqlite3 $ANVIO_MODULES_DB "select module,data_value from modules where data_name='NAME'" | \
    tr '|' '\t' > module_names.txt
```

## Loading the database in Python

The modules database class has plenty of helpful functions defined for it. You can easily load one in Python and use these functions to access the data within. Here is how you load the database:

```python
import anvio
import argparse
import os
from anvio import kegg

args = argparse.Namespace()
# CHANGE THIS PATH IF YOU WANT TO LOAD A MODULES DB AT A NON-DEFAULT LOCATION
path_to_db = os.path.join(os.path.dirname(anvio.__file__), 'data/misc/KEGG/MODULES.db')
db = kegg.KeggModulesDatabase(path_to_db, args)
```
Once you have done this, you can start to use the helper functions. For example, the following function will return a list of all paths through a module:
```python
db.unroll_module_definition('M00001')
```

A locus-fasta is one of the outputs of %(anvi-export-locus)s, which creates exports specific regions of interest out of a %(contigs-db)s. 

This artifact specifically describes the %(fasta)s file that contains the sequence of one of the hits to the locus. 

This file is contained within the directory specified by the `-o` parameter and is named with the prefix defined by the `-O` parameter, followed by a numerical identifier for this particular hit. The sequence in this fasta file is also contained in the %(contigs-db)s of the same name. 
This is the section of your %(profile-db)s/%(pan-db)s that contains custom additional information about each of the items in the central section of the interactive interface. When you run %(anvi-interactive)s, this data will appear as additional concentric circles. 

As also defined in [this blog post](http://merenlab.org/2017/12/11/additional-data-tables/#views-items-layers-orders-some-anvio-terminology), this type of data will include information about each item (whether that's a contig, gene, or bin). This data is either numerical or categorical and can be imported into another database from a %(misc-data-items-txt)s using %(anvi-import-misc-data)s. It is also displayed when you run %(anvi-show-misc-data)s and can be exported or deleted with %(anvi-export-misc-data)s and %(anvi-delete-misc-data)s respectively. 

To change the order that the items are displayed in, take a look at %(anvi-import-items-order)s.

For example, this information could describe whether or not each bin reached a certain completion threshold, the e-score of the function annotation on each gene, or different categories that the total length of a contig could fall into (1-1.5 kb, 1.5-2 kb, 2-2.5 kb, and so on). 
A `JSON`-formated configuration file that describes steps and parameters to be considered by an anvio workflow, which includes %(contigs-workflow)s, %(metagenomics-workflow)s, %(pangenomics-workflow)s, %(phylogenomics-workflow)s, and %(trnaseq-workflow)s.

You can create a default config file for a given workflow using the following command:

```
anvi-run-workflow --workflow ANVIO-WORKFLOW \
                  --get-default-config CONFIG.json
```

Following this, the file `CONFIG.json` will contain all configurable flags and parameters set to their default value for that workflow. From there, you can edit this file to your hearts content. 

### What's in this file? 

The config file contains three types of information:

1. **General parameters**, including the name of the workflow, the version of this config file, and links to the %(fasta-txt)s or %(samples-txt)s file) 
2. **Rule specific parameters** which allow you to set the parameters on individual anvi'o programs that are run in the workflow. 
3. **Output directory names** which just tell anvi'o what to name all of the intermediate and final outputs (to help keep things organized). 

For example, the default config file for the %(contigs-workflow) has no rule specific parameters and looks like this: 

    {
        "workflow_name": "contigs",
        "config_version": 1,
        "fasta_txt": "fasta.txt",
        "output_dirs": {
            "FASTA_DIR":   "01_FASTA_contigs_workflow",
            "CONTIGS_DIR": "02_CONTIGS_contigs_workflow",
            "LOGS_DIR":    "00_LOGS_contigs_workflow"
        }
    }

On the other hand, the default config file for the %(metagenomics-workflow)s is much longer, because it has sections for each rule specific parameter. For example, its section on parameters for the program %(anvi-gen-contigs-database)s looks like this:

    "anvi_gen_contigs_database": {
       "--project-name": "{group}",
       "threads": 5,
       "--description": "",
       "--skip-gene-calling": "",
       "--ignore-internal-stop-codons": "",
       "--skip-mindful-splitting": "",
       "--contigs-fasta": "",
       "--split-length": "",
       "--kmer-size": ""
    },

Note that the empty string `""` here means that the default parameter for the program %(anvi-gen-contigs-database)s will be used. 

For more details on the anvi'o snakemake workflows, please refer to [this tutorial](https://merenlab.org/2018/07/09/anvio-snakemake-workflows/).

A metagenome is any set of sequences that collectively describes multiple different populations (rather than just one genome) and has been converted into a %(contigs-db)s.

The metagenomes file format enables anvi'o to work with one or more metagenomes. A TAB-delimited external genomes file will be composed of at least the following two columns:

|name|contigs_db_path|
|:--|:--|
|Name_01|/path/to/contigs-01.db|
|Name_02|/path/to/contigs-02.db|
|Name_03|/path/to/contigs-03.db|
|(...)|(...)|

In some cases, (for example when running %(anvi-estimate-scg-taxonomy)s), you may also want to provide the %(profile-db)s that is associated with the %(contigs-db)s. Then the metagenomes file will be composed of three columns:

|name|contigs_db_path|profile_db_path|
|:--|:--|:--|
|Name_01|/path/to/contigs-01.db|/path/to/profile.db|
|Name_02|/path/to/contigs-02.db|/path/to/profile.db|
|Name_03|/path/to/contigs-03.db|/path/to/profile.db|
|(...)|(...)|(...)|

{:.warning}
Please make sure names in the `name` column does not include any special characters (underscore is fine). It is also a good idea to keep these names short and descriptive as they will appear in various figures in downstream analyses.

Also see **%(internal-genomes)s** and **%(external-genomes)s**.
This is a text file that **contains the information for a %(misc-data-items-order)s**, used for importing into and exporting this information from your anvi'o project.

## NEWICK order

If you intend to import a tree order, the contents of your file should look something like this (but probably much more complicated depending on the number of items in your anvi'o database): 

```
(contig_4, ((contig_1, contig_2), contig_3))
```

When a NEWICK order is imported into an anvi'o project, the contigs will be displayed in the order `contig_4, contig_1, contig_2, contig_3`, and the following tree will be generated in the interface:

```
    contig_4    contig_1    contig_2    contig_3
        |           |           |           |
        |           -------------           |
        |                 |                 |
        |                 -------------------
        |                           |
        -----------------------------
                    |
                    |
```

## LIST order

Alternative to the NEWICK order, you can provide a list of items in flat form. For instance, if you want to order your items this way, your text file should look like the following, where each line contains a single item name in your database:

```
contig_4
contig_1
contig_2
contig_3
```

{:.warning}
After importing an order into a database, you may need to specifically select that order in the interactive interface through the "Item orders" dropbox and re-draw your display to change the default order.
This is a text file containing **the average coverage for each contig in each sample** that was in the %(profile-db)s and %(contigs-db)s that you used when you ran %(anvi-export-splits-and-coverages)s or %(anvi-export-gene-coverage-and-detection)s. 

This is a tab-delimited file where each row describes a specific split/gene and each column describes one of your samples. Each cell contains the average coverage of that contig in that sample. 

This artifact is really only used when taking information out of anvi'o, so enjoy your coverage information :) 

### Example for splits

(the type of output you would get from %(anvi-export-splits-and-coverages)s)

    contig                  sample_1    sample_2    sample_3 ...
    Day1_contig1_split1     5.072727    4.523432    1.2343243         
    Day1_contig1_split2     6.895844    5.284812    9.3721947
    Day1_contig2_split1     2.357049    3.519150    8.2385691
    ...


### Example for genes

(the type of output you would get from %(anvi-export-gene-coverage-and-detection)s)

    key       sample_1    sample_2    sample_3 ...
    13947     10.29109    1.984394    6.8289432         
    13948     34.89584    6.284812    3.3721947
    23026     23.94938    9.239235    13.238569
    ...




An anvi'o genes database is a %(profile-db)s-like database that contains statistics, such their coverage and detection across samples, rather than contigs in a given %(contigs-db)s.

A gene database for a given %(bin)s stored in a %(collection)s will be automatically generated when %(anvi-interactive)s is run in 'gene mode'. For details, see the [relevant section](../programs/anvi-interactive/#visualizing-genes-instead-of-contigs) in %(anvi-interactive)s

Alternatively, genes databases can be explicitly generated using the program %(anvi-gen-gene-level-stats-databases)s. By default, this program will generate a gene database for each %(bin)s for a given %(collection)s. 

Due to the strucutral similarities between a %(genes-db)s and a %(profile-db)s, many of the anvi'o programs that operate on profile databases will also run on genes databases. These programs include those that import/export states and import/export misc additional data.
View data refers to a matrx where each column represents a specific sample and each row describes some attribute of that sample (most often a sequence's abundance per sample). 

For example, in the [pangenomics tutorial](http://merenlab.org/2016/11/08/pangenomics-v2/#creating-a-quick-pangenome-with-functions), the `PROCHLORO-functions-occurrence-frequency.txt` is a view-data. 

You can use this to compute a distance matrix to generate a dendrogram (using %(anvi-matrix-to-newick)s) or direclty input it to %(anvi-interactive)s to visualize the distribution of your items across samples. 
An external genome is any genome assembly that was converted into a %(contigs-db)s from its original FASTA file format using the program %(anvi-gen-contigs-database)s. You can obtain one of these in a variety of ways, the most common being 1) downloading a genome from a database such as NCBI and 2) assembling a genome yourself from sequencing reads. The key thing is that the sequences in the %(contigs-db)s represent a _single_ microbial population (or species, if you are not working with microbes) - ie, it is not a metagenome.

The external genomes file format enables anvi'o to work with one or more external genomes. A TAB-delimited external genomes file will be composed of at least the following two columns:

|name|contigs_db_path|
|:--|:--|
|Name_01|/path/to/contigs-01.db|
|Name_02|/path/to/contigs-02.db|
|Name_03|/path/to/contigs-03.db|
|(...)|(...)|

{:.warning}
Please make sure names in the `name` column does not include any special characters (underscore is fine). It is also a good idea to keep these names short and descriptive as they will appear in various figures in downstream analyses.

Also see **%(internal-genomes)s** and **%(metagenomes)s**.
A genes-fasta is what it sounds like: a FASTA formatted file that contains genes. In Anvi'o, this is an output for programs that return gene sequences. This includes %(anvi-get-sequences-for-gene-calls)s, %(anvi-get-sequences-for-gene-clusters)s (when working with pan genomes), and %(anvi-get-sequences-for-hmm-hits)s.

If you're unsure what a FASTA file is, check out %(fasta)s.
This tabular file contains data on the nonspecific coverages of tRNA-seq seeds.

Nonspecific coverage represents reads that are not unique to a single tRNA seed. See the %(trnaseq-profile-db)s artifact for a fuller explanation of specific versus nonspecific coverage. The rows and columns of this table are identical to %(seeds-specific-txt)s except for the type of coverage data reported in each.

This file is produced by %(anvi-tabulate-trnaseq)s. The artifact for that program describes this and related tables in detail.

This tab-delimited file can be easily manipulated by the user. It is optional input for %(anvi-plot-trnaseq)s.

## Example

The seeds shown in this table are also shown in the %(seeds-specific-txt)s example. Modifications from these seeds are shown in the %(modifications-txt)s example.

| gene_callers_id | contig_name | anticodon | aa | domain | phylum | class | order | family | genus | species | taxon_percent_id | sample_name | mean_coverage | relative_mean_coverage | relative_discriminator_coverage | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 17a | 18 | 19 | 20 | 20a | 20b | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | 41 | 42 | 43 | 44.01 | 44.02 | 44.03 | 44.04 | 44.05 | 44.06 | 44.07 | 44.08 | 44.09 | 44.1 | 44.11 | 44.12 | 44.13 | 44.14 | 44.15 | 44.16 | 44.17 | 44.18 | 44.19 | 44.2 | 44.21 | 44.22 | 44.23 | 49 | 50 | 51 | 52 | 53 | 54 | 55 | 56 | 57 | 58 | 59 | 60 | 61 | 62 | 63 | 64 | 65 | 66 | 67 | 68 | 69 | 70 | 71 | 72 | 73 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | DB_01 | 100372.4 |  | 14497 | 14608 | 14815 | 14882 | 14985 | 15828 | 15854 | 15895 | 16410 | 16565 | 16840 | 16960 | 16975 | 16990 | 17490 | 18529 | 19087 |  | 19683 | 21763 | 24353 |  |  | 24699 | 25182 | 29097 | 30476 | 30609 | 30612 | 30491 | 30125 | 29973 | 29506 | 29417 | 26259 | 31169 | 145828 | 153750 | 155936 | 156187 | 156518 | 157233 | 157226 | 157178 | 157429 | 158124 | 159941 | 164453 | 167924 | 170595 | 170567 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 170572 | 170577 | 170547 | 170541 | 170326 | 169581 | 169509 | 169509 | 169497 | 169497 | 169494 | 169491 | 168727 | 168721 | 168719 | 168719 | 168719 | 168719 | 168719 | 168719 | 168489 | 168485 | 168480 | 167688 | 155628 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | DB_03 | 203816.6 |  | 10498 | 10599 | 11105 | 11217 | 11255 | 11270 | 11350 | 11444 | 12349 | 12539 | 13028 | 13331 | 13337 | 13390 | 14325 | 15079 | 15603 |  | 15769 | 18168 | 21167 |  |  | 23927 | 24910 | 27041 | 28271 | 28395 | 28604 | 28612 | 28749 | 29242 | 30775 | 32254 | 33570 | 44299 | 319895 | 335328 | 337653 | 341382 | 342776 | 344543 | 345794 | 345762 | 345808 | 346281 | 347647 | 354052 | 360294 | 361948 | 361948 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 362317 | 362317 | 362303 | 362303 | 362226 | 362056 | 362056 | 362056 | 362056 | 362050 | 362046 | 362044 | 362044 | 362044 | 362044 | 362044 | 362032 | 362027 | 362027 | 362027 | 361349 | 361349 | 361349 | 360094 | 345770 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | DB_05 | 26137.9 |  | 5111 | 5184 | 5259 | 5704 | 5979 | 5979 | 5979 | 6011 | 6550 | 6587 | 6587 | 6611 | 6611 | 6611 | 6936 | 7087 | 7090 |  | 7170 | 8243 | 9158 |  |  | 9488 | 9868 | 12268 | 12323 | 12866 | 12616 | 12506 | 12640 | 12630 | 12838 | 12292 | 11336 | 11621 | 36476 | 37479 | 38030 | 38892 | 39018 | 39018 | 39084 | 39068 | 39272 | 39272 | 39272 | 40666 | 41573 | 41879 | 41873 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 42019 | 42019 | 42015 | 42015 | 41996 | 41873 | 41857 | 41695 | 41689 | 41689 | 41689 | 41689 | 41683 | 41683 | 41683 | 41569 | 41569 | 40839 | 40839 | 40839 | 40839 | 40538 | 40495 | 40464 | 36174 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | DB_07 | 182536.6 |  | 16048 | 16134 | 16358 | 16639 | 16664 | 16679 | 16679 | 16757 | 17351 | 17494 | 17494 | 17547 | 17613 | 17737 | 18346 | 18771 | 18776 |  | 19172 | 20831 | 21986 |  |  | 22549 | 22933 | 25352 | 26246 | 26370 | 25534 | 25798 | 25385 | 25277 | 25529 | 25758 | 25079 | 33202 | 289207 | 300224 | 303731 | 306231 | 306774 | 307692 | 307695 | 307604 | 307604 | 307828 | 308578 | 314195 | 317240 | 321017 | 321023 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 321634 | 321634 | 321615 | 321615 | 321596 | 321066 | 321066 | 321066 | 321066 | 321066 | 321066 | 321066 | 321066 | 321066 | 321066 | 321066 | 321066 | 321066 | 321059 | 321059 | 320379 | 320373 | 320363 | 320230 | 303028 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | DB_01 | 3923.1 |  | 32 | 32 | 32 | 32 | 32 | 32 | 32 | 32 | 32 | 32 | 33 | 33 | 33 | 33 | 33 | 33 | 33 |  | 33 | 50 | 79 | 82 |  | 82 | 82 | 82 | 82 | 82 | 82 | 82 | 90 | 90 | 90 | 96 | 109 | 118 | 117 | 125 | 163 | 320 | 7564 | 7948 | 7970 | 7991 | 7991 | 7991 | 8014 | 8014 | 8016 | 8041 | 8041 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 8041 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8046 | 8022 | 8022 | 8022 | 8021 | 7961 | 7955 | 7213 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | DB_03 | 8502 |  | 27 | 27 | 27 | 29 | 29 | 31 | 31 | 43 | 49 | 59 | 59 | 59 | 59 | 59 | 59 | 59 | 59 |  | 59 | 60 | 65 | 65 |  | 65 | 65 | 65 | 65 | 65 | 65 | 65 | 72 | 72 | 78 | 78 | 92 | 116 | 140 | 173 | 236 | 679 | 16238 | 17144 | 17344 | 17428 | 17428 | 17452 | 17482 | 17482 | 17482 | 17482 | 17482 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 17482 | 17482 | 17482 | 17482 | 17482 | 17482 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17480 | 17411 | 17320 | 16198 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | DB_05 | 1254.6 |  | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |  | 0 | 4 | 18 | 18 |  | 18 | 18 | 18 | 18 | 26 | 26 | 26 | 32 | 32 | 32 | 32 | 40 | 45 | 45 | 60 | 62 | 89 | 2379 | 2492 | 2502 | 2562 | 2594 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2604 | 2557 | 2557 | 2557 | 2557 | 2446 | 2426 | 2058 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | DB_07 | 4217.8 |  | 60 | 60 | 60 | 60 | 60 | 60 | 60 | 64 | 72 | 78 | 78 | 78 | 78 | 78 | 78 | 78 | 78 |  | 78 | 90 | 107 | 107 |  | 107 | 113 | 113 | 113 | 113 | 119 | 119 | 117 | 117 | 117 | 120 | 120 | 132 | 140 | 172 | 212 | 410 | 7980 | 8475 | 8539 | 8553 | 8584 | 8594 | 8594 | 8594 | 8594 | 8599 | 8599 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8599 | 8546 | 8546 | 8124 |
This page describes general properties of the gene cluster inspection page. Oligotyping is a computational strategy that **partitions a given set of sequences into homogeneous groups using only a subset of target nucleotide positions**. 

### History

Oligotyping was [first described in 2011](https://doi.org/10.1371/journal.pone.0026732) and has primarily been applied to 16S ribosomal RNA gene amplicons to resolve closely related but distinct that differ as low as one nucleotide at the amplified region, exceeding the sensitivity of the popular strategy of the time, 97%% OTU clustering. Other papers that demonstrate the strengths of this approach include the following: [1](https://doi.org/10.1111/2041-210X.12114), [2](https://doi.org/10.1073/pnas.1409644111), [3](https://doi.org/10.1038/ismej.2014.195), and [4](https://doi.org/10.3389/fmicb.2014.00568).

The following figure from [the oligotyping methods paper](https://doi.org/10.1111/2041-210X.12114) depicts major steps of an oligotyping analysis for amplicon sequences:

![Oligotyping](../../images/oligotyping.jpg)

Although, Shannon entropy is not the only approach to identify highly variable nucleotide positions of interest, and they an also be provided by the user.

### Applications to metagenomics

This strategy also applies to metagenomic sequences that are mapped to a genomic context to describe the diversity of variable regions that are fully covered by short reads. In the context of metagenomic read recruitment, variable nucleotide positions can be chosen by the user from the positions of single-nucleotide variants [anvi'o recovers](https://merenlab.org/2015/07/20/analyzing-variability/) and presents through inspection pages in the interactive interface or through %(variability-profile)s. An example application of oligotyping to metagenomics is demonstrated here:

* [An application of oligotyping in the metagenomic context: Oligotyping AmoC](https://merenlab.org/2015/12/09/musings-over-commamox/#an-application-of-oligotyping-in-the-metagenomic-context-oligotyping-amoc)This page describes general properties of anvi'o interactive displays and programs that offer anvi'o interactive artifacts.

## Terminology

Anvi'o uses a simple terminology to address various aspects of interactive displays it produces, such as items, layers, views, orders, and so on. The purpose of this section is to provide some insights into these terminology using the figure below:

![an anvi'o display](../../images/interactive_interface/anvio_display_template.png){:.center-img}

Even though the figure is a product of %(anvi-display-pan)s, the general terminology does not change across different interfaces, including the default visualizations of %(anvi-interactive)s. Here are the descriptions of numbered areas in the figure:

* The tree denoted by **(1)** shows the organization of each `item`. Items could be contigs, gene clusters, bins, genes, or anything else depending on which mode the anvi'o interactive interface was initiated. The structure that orders items and denoted by **(1)** in the figure can be a phylogenetic or phylogenomic tree, or a dendrogram produced by a hierarchical clustering algorithm. In addition, there may be nothing there, if the user has requested or set a linear items order through %(misc-data-items-order)s.
* Each concentric circle underneath the number **(2)** is called a `layer` and the data shown for items and layers as a whole is called a `view`. A **layer** can be a genome, a metagenome, or anything else depending on which mode the anvi'o interactive was initiated. The **view** is like a data table where a datum is set for each **item** in each **layer**. The view data is typically computed by anviâ€™o and stored in pan databases by %(anvi-pan-genome)s or profile databases by %(anvi-profile)s. The user add another view to the relevant combo box in the interface by providing a TAB-delimited file to %(anvi-interactive)s through the command line argument `--additional-view`, or add new layers to extend these vies with additional data through %(misc-data-items)s.
* The tree denoted by **(3)** shows a specific ordering of layers. Anvi'o will compute various layer orders automatically based on available **view** depending on the analysis or visualization mode, and users can extend available **layer orders** through %(misc-data-layer-orders)s.
* What is shown by **(4)** is the additional data for layers. the user can extend this section with additional information on layers using the %(misc-data-layers)s.

The orchestrated use of %(anvi-import-misc-data)s, %(anvi-export-misc-data)s, and %(anvi-delete-misc-data)s provides a powerful framework to decorate items or layers in a display and enhance visualization of complex data. Please take a look at the following article on how to extend anvi'o displays:

* [https://merenlab.org/2017/12/11/additional-data-tables/](https://merenlab.org/2017/12/11/additional-data-tables/)

## Programs that give interactive access

If you're new to the anvi'o interactive interface, you'll probably want to check out [this tutorial for beginners](http://merenlab.org/tutorials/interactive-interface/) or the other resources on the  %(anvi-interactive)s page.

However, there are more interfaces available in anvi'o than just that one, so let's list them out:

- %(anvi-display-structure)s lets you examine specific protein structures, along with SCV and SAAVs within it. (It even has [its own software page.](http://merenlab.org/software/anvio-structure/). It's kind of a big deal.)

- %(anvi-display-contigs-stats)s shows you various stats about the contigs within a %(contigs-db)s, such as their hmm-hits, lengths, N and L statistics, and so on.

- %(anvi-display-functions)s lets you quickly browse the functional pool for a given set of genomes or metagenomes.

- %(anvi-display-metabolism)s is still under development but will allow you to interactively view metabolism estimation data using %(anvi-estimate-metabolism)s under the hood.

- %(anvi-display-pan)s displays information about the gene clusters that are stored in a %(pan-db)s. It lets you easily view your core and accessory genes, and can even be turned into a metapangenome through importing additional data tables.

- %(anvi-inspect)s lets you look at a single split across your samples, as well as the genes identified within it. This interface can also be opened from the %(anvi-interactive)s interface by asking for details about a specific split.

- %(anvi-interactive)s displays the information in a %(profile-db)s. It lets you view the distribution of your contigs across your samples, manually bin metagenomic data into MAGSs (and refine those bins with %(anvi-refine)s), and much more. You can also use this to look at your genes instead of your contigs or [examine the genomes after a phylogenomic analysis](http://merenlab.org/2017/06/07/phylogenomics/). Just look at that program page for a glimpse of this program's amazingness.

- %(anvi-script-snvs-to-interactive)s lets you view a comprehensive summary of the SNVs, SCVs, and SAAVs within your contigs.

## Artifacts that give interactive access

- %(gene-cluster-inspection)s lets you examine specific gene clusters.

- %(contig-inspection)s shows you detailed contig information.

## An overview of the display

The interactive interface has three major areas of interaction:

* The space for visualization in the middle area,
* The Settings panel on the left of the screen,
* And three additional panels for 'News', 'Description', and 'Mouse' on the right.

Each panel is important, but the most important and functionally rich one is the 'Settings' panel.

### Settings panel

If closed, the settings panel can be opened by clicking on the little button on the left-middle part of your browser. When opened, you will see multiple tabs:

![an anvi'o settings panel](../../images/interactive_interface/interactive-settings-panel-tabs.png){:.center-img}

But before we start talking about these tabs, it is worthwhile to mention that at the bottom of the settings panel you will find a section with tiny controls that are available in all tabs:

![settings panel bottom controls](../../images/interactive_interface/interactive-settings-bottom.png){:.center-img}

Through these controls you can,

* __Create or refresh__ the display when necessary using the draw button (some changes require you to do that),

* __Zoom in, zoom out, and center__ the display.

* __Download your display as an SVG file.__

Finally, at the top-right of the Settings panel header you will find a dropdown menu (hamburger menu) which provides links to external information, resources, and issue-reporting related to anvi'o.

OK. Let's talk about each tab you will find in the settings panel.


### Main Tab

This is one of the most frequently used tabs in the interface, and there are multiple sections in it (keeps growing over time, so things may be missing here).

![an anvi'o main tab](../../images/interactive_interface/interactive-settings-display-additional-settings.png){:.center-img}

* **Display subsection**. Provides high level options for adjusting _items order_, _view_, and _drawing type_.

Clicking the _Show Additional Settings_ button provides access to myriad additional, more-granular adjustments, including,

* **Dendrogram subsection**. _Radius_ and _Angle_ , and _Edge length normalization_ adjustments for the dendrogram.
* **Branch support subsection**. Settings for displaying _bootstrap values_ on the dendrogram.
* **Selections subsection**. To adjust _height_, _grid_ and/or _shade_ display, as well as selection _name_ settings.
* **Layers subsection**. Display and label settings.
* **Performance subsection**. Whether the SVG output is optimized for performance or granularity (very advanced stuff).
* **Layers subsection**. This is arguably the most important subsection in the Main tab that enables you to make very precise adjustments to how things should look like on your screen. You can adjust individual layer attributes like _color_, display _type_, _height_  and _min/max_ values. Click + drag each layer to rearrange how layers are ordered. Or _edit attributes for multiple layers_ as well.

![an anvi'o settings layers](../../images/interactive_interface/interactive-settings-layers.png){:.center-img}

Mastering these in the Main Tab will minimize the post-processing of your anvi'o figures for high-quality and good-looking publication ready images.

### Layers tab

Through the layers tab you can,

- __Change general settings for the tree__ (i.e., switching between circle or rectengular displays, changing tree radius or width), __and layers__ (i.e., editing layer margins, or activating custom layer margins).

- __Load or save states__ to store all visual settings, or load a previously saved state.

- __Customize individual__ layers by switching between different __display modes__ depending on the layer type (i.e., â€˜textâ€™ or â€˜colorâ€™ mode for categorical layers, or â€˜barâ€™ or â€˜intensityâ€™ mode for numerical layers), __set normalization__ (i.e., â€˜square-rootâ€™, or â€˜logâ€™ normalization), __minimum, and maximum cutoff__ values for numerical layers, or set __layer height__, and __layer margin__ (i.e., its distance from the previous layer).

- Use the __multi-selector__ at the bottom to change settings for multiple layers at once.

![an anvi'o layers tab](../../images/interactive_interface/interactive-settings-layers-tab.png){:.center-img}


### Samples tab

Samples tab is for the additional data you provide the interface through a samples database (see samples order and samples information sections above). Through this layer you can,

- __Change the order__ of layers using automatically-generated or user-provided orders of layers using the Sample order combo box,

- __Customize individual samples information entries.__ Changes in this tab can be reflected to the current display without re-drawing the entire tree unless the sample order is changed.

### Bins tab

Anviâ€™o allows you to create selections of items shown in the display (whether they are contigs, gene clusters, or any other type of data shown in the display). Bins tab allow you to maintain these selections. Any selection on the tree will be added to active bin in this tab (the state radio button next to a bin defines its activity). Through this tab you can,

- __Create or delete bins, set bin names, change the color of a given bin__, or sort bins based on their name, the number of units they carry, or completion and contamination estimates (completion / contamination estimates are only computed for genomic or metagenomic analyses).

- View the __number of selected units__ in a given bin, and see the __list of names in the selection__ by clicking the button that shows the number of units described in the bin.

- __Store a collection of bins__, or __load a previously stored collection.__

![an anvi'o bins tab](../../images/interactive_interface/interactive-settings-bins-tab.png){:.center-img}

### Legends tab

The legends tab enables users to easily change individual or batch legend colors for any of their additional data items
<!-- grab legend example from infant gut w/ additional data layer -->

![an anvi'o legends tab](../../images/interactive_interface/interactive-settings-legends-tab.png){:.center-img}

### Search tab

It does what the name suggests. Using this tab you can,

- __Build expressions to search items__ visualized in the main display.

- __Highlight matches__, and __append__ them to, or __remove__ them from the __selected bin__ in the Bins tab.



### Mouse panel

The mouse panel displays the value of items underneath the mouse pointer while the user browse the tree.

Displaying the numerical or categorical value of an item shown on the tree is not an easy task. We originally thought that displaying pop-up windows would solve it, but besides the great overhead, it often became a nuisance while browsing parts of the tree. We could show those pop-up displays only when use clicks on the tree, however click-behavior is much more appropriate to add or remove individual items from a bin, hence, it wasnâ€™t the best solution either. So we came up with the â€˜mouse panelâ€™. You have a better idea? I am not surprised! We would love to try improve your experience: please enter an issue, and letâ€™s discuss.

### News panel
The news panel provides information and external links tracking major Anvi'o releases and development updates.

### Description panel

- The description panel is a flexible, multipurpose space where users can,
- Store notes, comments, and any other stray items related to their project, in a feature-rich markdown environment.
- Display context, references, reproducibility instructions, and any other salient details for published figures.
![The Description panel in action](../../images/interactive_interface/interactive-settings-description-panel.png){:.center-img}

## Interactive interface tips + tricks

Here are some small conveniences that may help the interface serve you better (we are happy to expand these little tricks with your suggestions).

* You can zoom to a section of the display by making a rectangular selection of the area __while the pressing the shift button.__

* You can click an entire branch to add items into the selected bin, and remove them by __right-clicking__ a branch.

* If you click a branch __while pressing the `Command` or `CTRL` button__, it will create a new bin, and add the content of the selection into that bin.

* Tired of selecting items for binning one by one? __right-click__ on an item and select __Mark item as 'range start'__ to set an 'in point', then __right-click__ on another item and select __Add items in range to active bin__ or __Remove items in range from any bin__ to manipulate many items with few clicks. Nice!

* By pressing `1`,`2`,`3`,`4`, and`5`, you can go between Layers, Bins, Samples, Mouse, and Search tabs!

## Keyboard shortcuts

The interactive interface recognizes a handful of keyboard shortcuts to help speed up your workflow

- The `S` key toggles the Settings panel
- The `M` key toggles the Mouse panel
- The `N` key toggles the Description panel
- The `W` key toggles the News panel
- The `D` key triggers a redraw of your visualization
- The `T` key toggles showing the Title panel
- Keys `1` through `5` will toggle between tabs within the Settings panel, granted the Settings panel is currently shown.
- `CTRL`+`Z` and `CTRL`+`SHIFT`+`Z` will undo or redo bin actions, respectively.





A %(contigs-fasta)s is a %(fasta)s file that is suitable to be used by %(anvi-gen-contigs-database)s to create a %(contigs-db)s.

The most critical requirement for this file is that **it must have simple deflines**. If your %(fasta)s file doesn't have simple deflines, it is not a proper %(contigs-fasta)s. If you intend to use this file with anvi'o, **you must fix your FASTA file prior to mapping**.

Take a look at your deflines prior to mapping, and remove anything that is not a digit, an ASCII letter, an underscore, or a dash character. Here are some example deflines that are not suitable for a %(fasta)s to be considered a %(contigs-fasta)s

``` bash
>Contig-123 length:4567 
>Another defline 42
>gi|478446819|gb|JN117275.2|
```

And here are some OK ones:

``` bash
>Contig-123
>Another_defline_42
>gi_478446819_gb_JN117275_2
```

The program %(anvi-script-reformat-fasta)s can do this automatically for you.A tRNA-seq contigs database is a **%(contigs-db)s variant containing information on tRNA transcripts identified from tRNA-seq experiments**.

This database is created by the program, %(anvi-merge-trnaseq)s, which is part of the %(trnaseq-workflow)s. This program also creates %(trnaseq-profile-db)ss. %(anvi-run-trna-taxonomy)s populates the tRNA-seq contigs database with taxonomic annotations.

This database functions in a manner equivalent to the normal metagenomic-style contigs database. As normal contigs databases are associated with a normal %(profile-db)s containing coverage-related data, tRNA-seq contigs databases are associated with %(trnaseq-profile-db)ss. The name can be misleading: tRNA-seq contigs databases do not contain information on assembled contigs as such. Rather, the fundamental type of sequence reconstructed from a tRNA-seq experiment is a **tRNA seed**, representing a mature tRNA sequence (minus the 3'-CCA acceptor) found in one or more samples in the experiment. tRNA seeds are not predicted by assembly at all, but by the specialized software of %(anvi-trnaseq)s and %(anvi-merge-trnaseq)s.

A variety of information on tRNA seeds is contained in a tRNA-seq contigs database, including structural profiles, taxonomic annotations, and user-defined bins.

## Uses

Tabulation of tRNA-seq data by %(anvi-tabulate-trnaseq)s requires a tRNA-seq contigs database and %(trnaseq-profile-db)s.

Interactive visualization of tRNA-seq datasets in %(anvi-interactive)s requires this database and a %(trnaseq-profile-db)s.

Visualization of grouped seeds by %(anvi-plot-trnaseq)s requires this database in addition to files produced by %(anvi-tabulate-trnaseq)s.
This is taxonomy information about the layers stored in a %(single-profile-db)s. When you open this %(single-profile-db)s with %(anvi-interactive)s, this information will appear the same way that %(misc-data-layers)s does: in graphs at the right side of the interface, similarly to how the layer names are displayed. 

You can bring this information into your profile database using %(anvi-import-taxonomy-for-layers)s by providing a %(layer-taxonomy-txt)s. 
A **directory of data** downloaded from the [KEGG database resource](https://www.kegg.jp/) for use in function annotation and metabolism estimation.

It is created by running the program %(anvi-setup-kegg-kofams)s. Not everything from KEGG is included in this directory, only the information relevant to downstream programs. The most critical components of this directory are KOfam HMM profiles and the %(modules-db)s which contains information on metabolic pathways as described in the [KEGG MODULES resource](https://www.genome.jp/kegg/module.html).

Programs that rely on this data directory include %(anvi-run-kegg-kofams)s and %(anvi-estimate-metabolism)s.

## Directory Location
The default location of this data is in the anvi'o folder, at `anvio/anvio/data/misc/KEGG/`. 

You can change this location when you run %(anvi-setup-kegg-kofams)s by providing a different path to the `--kegg-data-dir` parameter:

{{ codestart }}
anvi-setup-kegg-kofams --kegg-data-dir /path/to/directory/KEGG
{{ codestop }}

If you do this, you will need to provide this path to downstream programs that require this data as well.

## Directory Contents

Here is a schematic of how the %(kegg-data)s folder will look after setup:

```
KEGG
 |- MODULES.db
 |- ko_list.txt
 |- modules.keg
 |- HMMs
 |   |- Kofam.hmm
 |   |- Kofam.hmm.h3f
 |   |- (....)
 |
 |- modules
 |   |- M00001
 |   |- M00002
 |   |- (....)
 |
 |- orphan_data
     |- 01_ko_fams_with_no_threshold.txt
     |- 02_hmm_profiles_with_ko_fams_with_no_threshold.hmm

```

Typically, users will not have to work directly with any of these files, as downstream programs will interface directly with the %(modules-db)s. 

However, for the curious:
`ko_list.txt`, `modules.keg`, and all files in the `modules` subfolder are flat text files downloaded from the [KEGG website](https://www.genome.jp/kegg/). The data in these files are processed and organized into the %(modules-db)s for easier programmatic access. 

The `HMMs` subfolder contains a file of concatentated KOfam profiles (also originally downloaded from [KEGG](https://www.genome.jp/ftp/db/kofam/)), as well as the indexes for this file. Some KOfam profiles do not have a score threshold in the `ko_list.txt` file - these profiles and their corresponding entries from that file live in the `orphan_data` directory. Please note that KOs from the `orphan_data` directory will *not* be annotated in your %(contigs-db)s when you run %(anvi-run-kegg-kofams)s.
This file is the output of %(anvi-script-gen-hmm-hits-matrix-across-genomes)s and describes the %(hmm-hits)s across multiple genomes or bins for a single %(hmm-source)s. 

The first column describes each of the genomes (if the input was an %(external-genomes)s) or bins (if the input was an %(internal-genomes)s) that the matrix describes. The following columns describe each of the genes in your %(hmm-source)s. The data within the table describes the number of hits that gene had in that genome or bin. 

For example, if you were to run %(anvi-script-gen-hmm-hits-matrix-across-genomes)s with the `Bacteria_71` %(hmm-source)s on two hypothetical genomes, you would get a file like this:

    genome_or_bin    ADK    AICARFT_IMPCHas    ATP-synt    ATP-synt_A    Adenylsucc_synt    Chorismate_synt    EF_TS    ...
    Genome_1         11     10                 9           9             11                 8                  9        ...
    Genome_2         2      1                  1           2             3                  2                  2        ...
An estimate of the completeness of purity of a genome based on single-copy core genes.

{:.notice}
See [this blog post](http://merenlab.org/2016/06/09/assessing-completion-and-contamination-of-MAGs/) for more information, and [this paper](https://doi.org/10.1038/nbt.3893) for the community standards for metagenome-assembled and single-amplified genomes.

There are two essential features to this metric: **completion** and **redundancy**.

### Completion

A rough estimate of how completely a set of contigs represents a full genome based on the presence or absence of single-copy core genes (SCGs) they contain. 

SCGs are a set of special genes that occur in every single genome once and once only. So theoretically, the higher the percentage of SCGs found in a genome bin, the more likely that the bin represents a complete genome. Of course, SCGs are typically determined by analyzing isolate genomes that are available to find out which genes match to this criterion, hence, the accuracy of their predictions may be limited when this approach is applied to genome bins that represent populations from poorly studies clades of life. Even for genomes of well-studied organisms, our methods to identify these genes in genomes may prevent us from getting to 100%% completeness.

### Redundancy

A measure of how many copies of each single-copy core gene (SCG) are found in a genome or a genome bin.

Usually, we expect to have only one copy of each of these genes (thatâ€™s why theyâ€™re called â€˜single-copyâ€™), and for this reason, redundancy of SCGs is commonly used as an estimate the level of potential â€˜contaminationâ€™ within a bin (i.e., higher values of redundancy may indicate that more than one population may be contributing to a given genome bin).

However, interpretations of â€˜contaminationâ€™ as a function of redundant occurrence of SCGs may not be straightforward as some genomes may have multiple copies of generally single-copy core genes, hence we prefer not to draw conclusions about contamination right away. In addition, lack of redundancy does not necessarily mean the lack of contamination, since contaminant contigs that do not include SCGs will not be in the radar of these estimates.

### Attention

Regardless of their utility to gain quick insights, single-copy core genes are mere approximations to understanding the quality of a genome and [SCGs cannot ensure the absence of contamination or level of true completion](https://doi.org/10.1101/gr.258640.119).
This is a text file containing taxonomy information for your layers (the same information as a %(layer-taxonomy)s). You can bring this information into a %(single-profile-db)s using %(anvi-import-taxonomy-for-layers)s. 

This is a tab-delimited text file that is formatted similarly to a %(gene-taxonomy-txt)s. The first column describes the names of your layers, and the following columns each correspond to the taxonomy level described in the header. Here is an example:

    sample  t_domain    t_phylum    t_class     ...
     c1     Eukaryea    Chordata    Mammalia
     ...
     

This is the result of %(anvi-split)s: self-contained anvi'o projects that contain just the contents of a single %(bin)s from your original database. 

This describes a directory that either contains either a %(genomes-storage-db)s and %(pan-db)s (if that's what you gave %(anvi-split)s as an input) or a %(profile-db)s and %(contigs-db)s pair. The contigs or genomes and gene clusters described in these databases will be only those contained in the bin that the directory's name corresponds to.  
An anvi'o concept that describes one or more %(bin)ss.

You can generate and store a collection by selecting items on any anvi'o %(interactive)s interface or by importing them via %(anvi-import-collection)s into any anvi'o database that can store collections using the file format %(collection-txt)s.

You can always use the program %(anvi-show-collections-and-bins)s to list all collections and bins stored in a given anvi'o database.

Collections are used in many ways in anvi'o depending on your workflow as you can see from the number of programs that require or can make use of the concept %(collection)s.
This describes the BLAST table that is outputted when you run [Protein BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE=Proteins) from the terminal. 

When given to %(anvi-script-filter-fasta-by-blast)s, which is currently the only program that uses this artifact, it expects output form 6. By default, this incldues the following data columns: 

    qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore slen
    
However, you'll have to provide the columns in your file and their order to the program wirth the flag `--outfmt`. For the program to work properly, your table must at least include the columns `qseqid`, `bitscore`, `length`, `qlen`, and `pident`.
An anvi'o database that contains the same information as a merged %(profile-db)s, namely **key information about the mapping of short reads *in a single sample* to your contigs.** 

You can think of this as a extension of a %(contigs-db)s that contains information about how your contigs align with a single one of your individual samples. If you have more than one sample, you'll probably want to use %(anvi-merge)s to merge your databases into a merged %(profile-db)s. The vast majority of programs that use a profile database will also ask for the contigs database associated with it. 

A single profile database contains information about how the short reads in a single BAM-file (see %(bam-file)s) map to the contigs in a %(contigs-db)s. Specificially, a profile database contains 
* the coverage and abundance per nucleotide position for each contig 
* variants of various kinds (single-nucleotide, single-codon, and single-amino acid)
* structural variants (ex insertions and deletions)

Once created, a single profile database is almost interchangable with a %(profile-db)s (even though the names can be a little confusing. Think of a single-profile-db as a type of profile-db, since it has only a few differences). The main differences between the two are as follows: 
* You cannot run %(anvi-cluster-contigs)s or %(anvi-mcg-classifier)s on a single profile db, since these two programs look at the alignment data in many samples. 
* You can run %(anvi-import-taxonomy-for-layers)s on a single profile database but not a merged one. 
* You can only run %(anvi-merge)s on a single profile database.

If you want to look at the contents of a single profile database, you can do so using %(anvi-interactive)s. 
This is the output of the program %(anvi-summarize)s and it comprehensively describes the data stored in a %(contigs-db)s and %(profile-db)s pair. 

By default, this will be a directory called `SUMMARY` that will contain some subdirectories, a text file that summarizes your bins, and an html file that formats the data in the summary nicely. 

#### The bin summary 

By default, this is stored in a tab-delimited matrix called `bins_summary.txt`. In this matrix, the rows represent the %(bin)ss in your %(profile-db)s. The columns represent the following from left to right: the bin name,  the taxon ID (if calculated), the toal number of nucleotides in the bin, the toal number of contigs in the bin, the N50 statistic (see the page for %(anvi-display-contigs-stats)s), the GC content, and the completition and redundency. 

#### Three subdirectories 

The subdirectories in the `SUMMARY` folder are as follows:

- `bin_by_bin`: this directory contains a subdirectory for each of your %(bin)ss. Each of these subdirectories contains various information about the contents of that bin. For example, you get a fasta file that contains the sequences of all of the contigs in your bin, various statistics for that bin (ex coverage and detection) across each of your samples in tab-delimited matrices, and fasta files that contain only sequences of a specific taxa (ex only Archaea sequences)

- `bins_across_samples`: this directory contains various text files, each of which describes a single statistic about your bins across all of your samples. Most of these files are tab-delimited matrices where each row represents a bin and each column describes one of your samples; each cell describes the value of a single stastic like mean coverage, relative abundance, or variaiblity. The only files that are not formatted this way are those describing the hmm-hits in the database, which only give total counts for hmm-hits of a certain kind in your bins and don't break these results down by sample. 

- `misc_data_layers` or `misc_data_items`: this data contains all of the %(misc-data-items)s and %(misc-data-layers)s stored in your database pair, formatted in %(misc-data-items-txt)s and %(misc-data-layers-txt)s files respectively. 

#### The HTML document 

When opened (usualy with an internet browser), you should see a page that looks somewhat like this. 

![An example of the HTML file that results from anvi-summarize.](../../images/summary_example.png)

The top bar provides links to various anvi'o resources, while the large text at the top provides an overall summary of your data, including the name, size, and format of the database. 

Following this, basic information about your databases are listed, such as the parameters used to create the databases and information about when they were created. 

After this, several sections are listed: 

- The description of your database (which you can change with %(anvi-update-db-description)s)

- "Summary of Bins", which contains the information from the `bin_by_bin` subdirectory (but in a format that 's a little easier on the eyes)

-"Across Samples", which contains the information from the `bins_across_samples` subdirectory. Here, you can change which metric you're looking at from the tabs at the top of this section (i.e. under the "Across Samples" header but above the displayed data) 

-"Percent Recruitment": This is also from the `bins_across_samples` subdirectory.  It describes the percent of mapped reads in each sample that mapped to splits within each bin. 

-"Gene Calls": lists all of the gene calls in your database by bin, including their functional annotation and coverage and detectin values. 

-"Hits for non-single-copy gene HMM profiles": This is also from the `bins_across_samples` subdirectory. The first table displays the total number of hits in each bin, while the table underneath provides a breakdown of those HMM hits. Note that each cell in the first table is a link that leads to a fasta file that contains only the relevant sequences.  

-"Misc Data": contains the information from the `misc_data_layers` or `misc_data_items` subdirectories. 
When the user runs %(anvi-run-interacdome)s, it stores binding frequencies directly into the %(contigs-db)s as %(misc-data-amino-acids)s. Yet %(anvi-run-interacdome)s also outputs tabular data directly accessible by the user--this data is what is meant by %(binding-frequencies-txt)s.

Specifically, this artifact refers to 2 files named `INTERACDOME-match_state_contributors.txt` and `INTERACDOME-domain_hits.txt` (the `INTERACDOME` prefix can be changed with `-O`). 

`INTERACDOME-match_state_contributors.txt` displays the binding frequencies in the following format:

|   gene_callers_id |   codon_order_in_gene | pfam_id   |   match_state | ligand   |   binding_freq |
|------------------:|----------------------:|:----------|--------------:|:---------|---------------:|
|                 1 |                   169 | PF00534   |            22 | ADP      |      0.687948  |
|                 1 |                   169 | PF13692   |             8 | ADP      |      0.595441  |
|                 1 |                   174 | PF00534   |            27 | ADP      |      0.735759  |
|                 1 |                   174 | PF13692   |            14 | ADP      |      0.595441  |
|                 1 |                   184 | PF00534   |            37 | ADP      |      0.0697656 |
|                 1 |                   184 | PF13692   |            24 | ADP      |      0.101399  |
|                 1 |                   186 | PF00534   |            39 | ADP      |      0.0697656 |
|                 1 |                   186 | PF13692   |            26 | ADP      |      0.101399  |
|                 1 |                   187 | PF13692   |            27 | ADP      |      0.201761  |
|                 1 |                   189 | PF00534   |            47 | ADP      |      0.0697656 |

Each binding frequency is associated with both the exact residue of the user's gene sequences (from their %(contigs-db)s) and the exact match states (from the Pfam database) that contributed the binding frequency. 

`INTERACDOME-match_state_contributors.txt` is a parsed summary of the `hmmsearch` output in the following format:


| pfam_name       | pfam_id   |   corresponding_gene_call |   domain | qual   |   score |   bias |   c-evalue |   i-evalue |   hmm_start |   hmm_stop | hmm_bounds   |   ali_start |   ali_stop | ali_bounds   |   env_start |   env_stop | env_bounds   |   mean_post_prob | match_state_align                                                                                                                                                                                                     | comparison_align                                                                                                                                                                                                      | sequence_align                                                                                                                                                                                                        |   version |
|:----------------|:----------|--------------------------:|---------:|:-------|--------:|-------:|-----------:|-----------:|------------:|-----------:|:-------------|------------:|-----------:|:-------------|------------:|-----------:|:-------------|-----------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------:|
| Beta_elim_lyase | PF01212   |                      1762 |        1 | !      |    20.9 |    0.1 |    1e-08   |    3.5e-06 |          33 |        169 | ..           |          44 |        177 | ..           |          34 |        215 | ..           |             0.72 | tvnrLedavaelfgke..aalfvpqGtaAnsill.kill.qr..geevivtepahihfdetgaiaelagvklrdlknkeaGkmdlekleaaikevgaheekiklisltvTnntagGqvvsleelrevaaiakkygiplhlDgA                                                                       | ++  +++ael+      + f+  Gt +++  l  + + +r  g+ +i++   h   +et    +  g +l  ++ +++G +++e+l+++i++     e i + +++v n+   G++ +++e+ ev  +a+  +i++h+D+                                                                          | LLQQARKQIAELINVSanEIYFTSGGTEGDNWVLkGTAIeKRefGNHIIISAVEHPAVTETAEQLVELGFELSYAPVDKEGRVKVEELQKLIRK-----ETILVSVMAVNNE--VGTIQPIKEISEV--LAEFPKIHFHVDAV                                                                       |        20 |
| PAPS_reduct     | PF01507   |                      1541 |        1 | !      |    36.1 |    0.1 |    3.6e-13 |    1.3e-10 |           2 |        164 | ..           |          21 |        231 | ..           |          20 |        234 | ..           |             0.79 | lvvsvsgGkdslVllhLalkafkpv....pvvfvdtghefpetiefvdeleeryglrlkvyepeeevaekinaekhgs.slyee.aaeriaKveplkk.................................aLekldedall..tGaRrdesksraklpiveidedfek.........slrvfPllnWteedvwqyilrenipynpLydqgfr | + +s+sgGkds  +++La  + ++      ++ ++ + ++  t++f++++e+  +++ +++     ++++ + + +++ + +   + e+ +   p  k                                   e++ ++a+   +G+R++es +r++     +++ +++          + ++Pl++W+  d+w+   + +++yn +y++ ++ | VYFSFSGGKDSGLMVQLANLVAEKLdrnfDLLILNIEANYTATVDFIKKIEQLPRVKNIYHFCLPFFEDNNTSFFQPQwKMWDPsEKEKWIHSLP--KnaitleniddglkkyyslsngnpdrflryfqnwYKEQYPQSAIScgVGIRAQESLHRHSAVTKGENKYKNRcwinitlegNILFYPLFDWKVGDIWAATFKCELEYNYIYEKMYK |        18 |
| Ank_2           | PF12796   |                      1756 |        1 | !      |    32.2 |    0   |    6.7e-12 |    2.3e-09 |          29 |         84 | .]           |          74 |        135 | ..           |          53 |        135 | ..           |             0.85 | aLhyAakngnleivklLle...h.a..adndgrtpLhyAarsghleivklLlekgadinlkd                                                                                                                                                        | aL  Aa + +++ vk +l+   + +  +d +g+tpL +A+ ++ +ei+k L+++gadinl++                                                                                                                                                        | ALLEAANQRDTKKVKEILQdttYqVdeVDTEGNTPLNIAVHNNDIEIAKALIDRGADINLQN                                                                                                                                                        |         6 |
| Ank_2           | PF12796   |                      1756 |        2 | !      |    28.5 |    0   |    9.5e-11 |    3.3e-08 |          22 |         75 | ..           |         199 |        265 | ..           |         195 |        267 | .]           |             0.76 | pn..k.ngktaLhyAak..ngnl...eivklLleha.....adndgrtpLhyAarsghleivklLle                                                                                                                                                   | ++  + +g taL+ A+   +gn    +ivklL+e++      dn+grt++ yA ++g++ei k+L +                                                                                                                                                   | IDfqNdFGYTALIEAVGlrEGNQlyqDIVKLLMENGadqsiKDNSGRTAMDYANQKGYTEISKILAQ                                                                                                                                                   |         6 |
| IGPS            | PF00218   |                      1615 |        1 | !      |    20.6 |    0.1 |    1.2e-08 |    4e-06   |         202 |        249 | ..           |         195 |        242 | ..           |          73 |        248 | ..           |             0.88 | LaklvpkdvllvaeSGiktredveklkeegvnafLvGeslmrqedvek                                                                                                                                                                      | +++lv+++++++ae  i+t+e+++++k+ gv ++ vG +++r ++ +k                                                                                                                                                                      | IKQLVQENICVIAEGKIHTPEQARQIKKLGVAGIVVGGAITRPQEIAK                                                                                                                                                                      |        20 |
| Ribosomal_L33   | PF00471   |                      1562 |        1 | !      |    66.6 |    1.5 |    1.1e-22 |    3.7e-20 |           2 |         47 | .]           |           4 |         49 | .]           |           3 |         49 | .]           |             0.97 | kvtLeCteCksrnYtttknkrntperLelkKYcprcrkhtlhkEtK                                                                                                                                                                        | +++LeC e+++r Y t+knkrn+perLelkKY p++r++ ++kE K                                                                                                                                                                        | NIILECVETGERLYLTSKNKRNNPERLELKKYSPKLRRRAIFKEVK                                                                                                                                                                        |        19 |
| Ribosomal_S14   | PF00253   |                      1565 |        1 | !      |    83.3 |    0.1 |    3.9e-28 |    1.3e-25 |           2 |         54 | .]           |          36 |         88 | ..           |          35 |         88 | ..           |             0.98 | laklprnssptrirnrCrvtGrprGvirkfgLsRicfRelAlkgelpGvkKaS                                                                                                                                                                 | laklpr+s+p+r+r r++ +GrprG++rkfg+sRi+fRel ++g +pGvkKaS                                                                                                                                                                 | LAKLPRDSNPNRLRLRDQTDGRPRGYMRKFGMSRIKFRELDHQGLIPGVKKAS                                                                                                                                                                 |        20 |
| Polysacc_synt_C | PF14667   |                      1593 |        1 | !      |    61.4 |   19.2 |    5.4e-21 |    1.9e-18 |           2 |        139 | ..           |         371 |        516 | ..           |         370 |        519 | ..           |             0.83 | LailalsiiflslstvlssiLqglgrqkialkalvigalvklilnllliplfgivGaaiatvlallvvavlnlyalrrllgikl...llrrllkpllaalvmgivvylllllllglllla...al..alllavlvgalvYllllll                                                                    | L+  ++s+ +l+++t++ siLq+l  +k+a+ ++ i++l+kli+++++i+lf  +G +iat+++ ++++++ +++l+r++ i++    ++   +++ +++vm i+ +l+l+++ ++   +   +l   + l +++g++v+ + l++                                                                    | LSATIISTSLLGIFTIVLSILQALSFHKKAMQITSITLLLKLIIQIPCIYLFKGYGLSIATIICTMFTTIIAYRFLSRKFDINPikyNRKYYSRLVYSTIVMTILSLLMLKIISSVYKFEstlQLffLISLIGCLGGVVFSVTLFR                                                                    |         5 |

For each hit, this table includes how good the hit was, the alignment of the user gene to the exact HMM match states, and more! In fact, it includes all of hte domain hit summary information, the sequence of the consensus match states, the comparison string for the hit, and the sequence of the user's gene. 

For more information, check out [this blogpost](https://merenlab.org/2020/07/22/interacdome/#6-storing-the-per-residue-binding-frequencies-into-the-contigs-database). 
This a tab-delimited text file that describes information contained in a %(misc-data-layer-orders)s. 

To import this information into a database, use %(anvi-import-misc-data)s. 

This table should contain trees formatted in either basic or newick form, where each branch represents the samples displayed by your layers. The order of the branches from left to right is the order they will be displayed in, from the center moving out. 

For an example, check out [the table on this page](http://merenlab.org/2017/12/11/additional-data-tables/#layer-orders-additional-data-table).
A directory of **user-defined metabolism data**, created by the user for estimating metabolism on custom metabolic pathways. The program %(anvi-setup-user-modules)s takes this directory as input and creates a %(modules-db)s out of the data within, for use by %(anvi-estimate-metabolism)s.

Instructions for creating this data directory and using it to estimate completeness of custom (ie, non-KEGG) metabolic pathways can be found below.

## A step-by-step guide to creating your own metabolic modules for anvi-estimate-metabolism

If you want to define your own metabolic pathway so that you can estimate its completeness in genomes, MAGs, and metagenomes, follow the steps below!

### 1. Find the enzymes

What you need first is a list of enzyme accession numbers. For each reaction in your metabolic pathway, figure out what enzyme(s) or enzyme complexes (if any) are required to catalyze the reaction. Then, for each of these enzymes and/or components of enzyme complexes, figure out if they are present in common databases like [NCBI COG](https://www.ncbi.nlm.nih.gov/research/cog), [KEGG KOfam](https://www.genome.jp/tools/kofamkoala/), or [PFAM](http://pfam.xfam.org/). If so, mark down their accession numbers in those databases. If not, you may need to create your own HMM profile for the enzyme (and create an accession number for it).

Also, think about how you will annotate each enzyme, because for each one you will need to write down its functional annotation source in the module file in step 3. Here is a short guide to common annotation sources:

Enzyme comes from... | annotation program | ANNOTATION_SOURCE
|:---|:---|:---|
KEGG KOfam | %(anvi-run-kegg-kofams)s | Kofam
NCBI COG (2020) | %(anvi-run-ncbi-cogs)s | COG20_FUNCTION
NCBI COG (2014) | %(anvi-run-ncbi-cogs)s | COG14_FUNCTION
PFAM | %(anvi-run-pfams)s | Pfam
custom HMMs | %(anvi-run-hmms)s with `--hmm-source` and `--add-to-functions-table` parameters | name of directory given to `--hmm-source`
other annotation strategy | %(anvi-import-functions)s | source defined in input file

### 2. Define the module

You need to write a DEFINITION string for the module. This string should be in the style of KEGG MODULE definitions, which are described [here](https://merenlab.org/software/anvio/help/main/programs/anvi-estimate-metabolism/#what-data-is-used-for-estimation). Briefly, you will put the enzyme accessions in order of their corresponding reactions in the metabolic pathway. Different steps (reactions) in the pathway should be separated by spaces, and alternative enzymes that can catalyze the same reaction should be separated by commas. You can use parentheses to distinguish alternatives with multiple steps. For enzyme complexes, all components should be in one string, with essential components separated by '+' signs and non-essential components separated by '-' signs.

### 3. Write a module file

Put all the information about your metabolic pathway into a text file. The file format and types of information you need to include are discussed [here](https://merenlab.org/software/anvio/help/main/programs/anvi-setup-user-modules/#how-do-i-format-the-module-files). At minimum, you need to pick an identifier (ENTRY) and NAME for the module, include your DEFINITION string from step 2, write an ORTHOLOGY line and an ANNOTATION_SOURCE line for each enzyme and/or enzyme component, and write a CLASS string to categorize your module into its class/category/subcategory. The module file should be given the same name as the identifier in the ENTRY line, and this identifier should not be the same as any module in the KEGG database.

### 4. Set up the USER_MODULES.db

Once you have created a module file for each metabolic pathway you are interested in, you should put these files within a folder called `modules`, within a parent directory (that can have any name you choose), as described [here](https://merenlab.org/software/anvio/help/main/programs/anvi-setup-user-modules/#input-directory-format). This parent directory is the %(user-modules-data)s directory. Then you should run the program %(anvi-setup-user-modules)s and provide this directory to the `--user-modules` parameter. If all goes well, you will end up with a database called `USER_MODULES.db` in this folder.

### 5. Annotate your contigs database(s)

Before you can estimate metabolism, you will need to annotate your contigs database(s) with each annotation source that you used to define your modules. This will require running one or more annotation programs, as described in the table given for step 1 above. If you want to quickly remind yourself of which annotation sources are required for your metabolic modules, you can run %(anvi-db-info)s on the `USER_MODULES.db`. But don't worry - if you forget one, you will get a helpful error message telling you what you missed when you try to run %(anvi-estimate-metabolism)s.

Since estimation will be run on KEGG data, too, you will have to make sure you also run %(anvi-run-kegg-kofams)s on your database(s), if you haven't already, _UNLESS_ you are choosing to skip KEGG estimation by using the `--only-user-modules` parameter for %(anvi-estimate-metabolism)s.

### 6. Estimate the completeness of your pathways

The last step is to run %(anvi-estimate-metabolism)s and provide this directory to the `--user-modules` parameter. This program will estimate the completeness of the metabolic modules defined in the `USER_MODULES.db` (by default, this will be in addition to the KEGG modules from the %(kegg-data)s directory. But, as mentioned above, you can specify `--only-user-modules` to only estimate on your own data).

## A toy example

For this example, we will be creating a completely FAKE, biologically-nonsensical Frankenstein of a metabolic pathway. This is not anything you should be putting in your own `USER_MODULES.db`; it only exists for demonstrating the steps above, and particularly so you have a reference for how to handle the different annotation sources mentioned in step 1.

First, let's select 5 different enzymes. Typically at this step you would use your biological knowledge of a real metabolic pathway to determine the specific set of enzymes catalyzing the reactions of the pathway - but for this toy example, we're going to use random enzymes that come from a variety of annotation sources, not enzymes that actually work together biologically in a real cell. So we'll go with a couple of KOfams, a COG, a PFAM, and a TIGRFAM (to demonstrate the 'other' annotation strategy). Here is the list of accessions: K01657, K01658, COG1362, PF06603.14, and TIGR01709.2.

It doesn't matter what they are or what they do. What matters is that we will learn how to annotate each one. So let's talk about their annotation sources. K01657 and K01658 will both come from `KOfam`, and COG1362 will come from the 2020 distribution of the COGs database, so its source will be `COG20_FUNCTION`. PF06603.14 is a PFAM, so it _could_ come from the `Pfam` source. But let's suppose we don't want to waste our precious computational resources on running %(anvi-run-pfams)s when we are only interested in one enzyme from this database. Instead, we'll make a custom HMM profile for this particular enzyme by following the directions on [creating HMM sources from ad hoc PFAM accessions](https://merenlab.org/software/anvio/help/main/artifacts/hmm-source/#creating-anvio-hmm-sources-from-ad-hoc-pfam-accessions), and then we will annotate it using %(anvi-run-hmms)s. In this case, the annotation source will be the name of the directory we make using %(anvi-script-pfam-accessions-to-hmms-directory)s, so we need to pick a name for it - let's call it `METABOLISM_HMM`. Last but not least, what about the TIGRFAM enzyme TIGR01709.2? Anvi'o doesn't have a program for annotating TIGRFAMs, but we can annotate our gene sequences with TIGRFAM using [Interproscan](https://www.ebi.ac.uk/interpro/search/sequence/), compile the results into a %(functions-txt)s, and import those annotations into our contigs database using %(anvi-import-functions)s. We'll put the source `TIGRFAM` in the %(functions-txt)s file.

Great, so now that we have our enzymes and we know how we will annotate them, it's time for step 2 - creating the module DEFINITION string. Again, this is not going to be a biologically-realistic metabolic pathway, but an example to demonstrate the different ways of representing steps in a pathway.

Let's say the first reaction in our pathway is catalyzed by an enzyme complex made up of two essential components, K01657 and K01658. We represent this step by the string "K01657+K01658" (no spaces between the components). Suppose the next part of the pathway can _either_ be one reaction catalyzed by the enzyme PF06603.14, _or_ it can be a two-step reaction in which the first reaction is catalyzed by COG1362 and the second is catalyzed by TIGR01709.2. We use a comma to separate the alternatives, and since the second option requires two different steps (that will be separated by a space), we surround the second option with parentheses to make sure both steps are considered as the alternative. It looks like this: "PF06603.14,(COG1362 TIGR01709.2)".

So our full module DEFINITION string is "K01657+K01658 PF06603.14,(COG1362 TIGR01709.2)".

Now we need to put this information into a module file. We'll give the module the identifier `UD0042` (UD for 'user-defined', and 42 because 42 is the answer to life, the universe, and everything), and this will also be the name of the file.

Here is the module file. Any information that we didn't discuss above has been filled in to demonstrate the formatting requirements:
```
ENTRY       UD0042
NAME        Frankenstein pathway for demo purposes
DEFINITION  K01657+K01658 PF06603.14,(COG1362 TIGR01709.2)
ORTHOLOGY   K01657  anthranilate synthase component I [EC:4.1.3.27]
            K01658  anthranilate synthase component II [EC:4.1.3.27]
            PF06603.14  UpxZ
            COG1362  Aspartyl aminopeptidase
            TIGR01709.2  type II secretion system protein GspL
CLASS       User modules; Demo set; Frankenstein metabolism
ANNOTATION_SOURCE  K01657  KOfam
                    K01658  KOfam
                    PF06603.14  METABOLISM_HMM
                    COG1362  COG20_FUNCTION
                    TIGR01709.2  TIGRFAM
///
```

If you were actually going to use this pathway, this is how you could create the %(user-modules-data)s directory and then the `USER_MODULES.db`:

{{ codestart }}
mkdir USER_METABOLISM
mkdir USER_METABOLISM/modules
vi USER_METABOLISM/modules/UD0042
\#copy the above into this file, save and quit
anvi-setup-user-modules --user-modules USER_METABOLISM/
{{ codestop }}

You would see the following output after %(anvi-setup-user-modules)s completed:
```
Modules database .............................: A new database, USER_METABOLISM/USER_MODULES.db, has been created.
Number of modules ............................: 1
Number of entries ............................: 14
Number of parsing errors (corrected) .........: 0
Number of parsing errors (uncorrected) .......: 0
Annotation sources required for estimation ...: COG20_FUNCTION, METABOLISM_HMM, KOfam, TIGRFAM
```
As expected, if we want to use this modules database for estimating completeness of our Frankenstein pathway, we would need to annotate our %(contigs-db)s of interest with the four annotation sources we discussed above. And that, in fact, is the next step.

The first two annotation sources we discussed are easy, because we don't need to do anything besides run the designated anvi'o program for KEGG KOfams and NCBI COGs, respectively:

{{ codestart }}
%(anvi-run-kegg-kofams)s -c CONTIGS.db \
                      --num-threads 4
%(anvi-run-ncbi-cogs)s -c CONTIGS.db \
                    --num-threads 4
{{ codestop }}

Annotating PF06603.14 requires an extra step, because we first need to create a custom HMM for this enzyme. Luckily, there is another anvi'o program to do that. We give the enzyme accession to %(anvi-script-pfam-accessions-to-hmms-directory)s, and we make sure to set the output directory name to be the same as the annotation source string that we put in the module file:

{{ codestart }}
%(anvi-script-pfam-accessions-to-hmms-directory)s --pfam-accessions-list PF06603.14 \
                                               -O METABOLISM_HMM
%(anvi-run-hmms)s -c CONTIGS.db \
               -H METABOLISM_HMM \
               --add-to-functions-table \
               --num-threads 4
{{ codestop }}

Please note that you _must_ use the `--add-to-functions-table` parameter when you use %(anvi-run-hmms)s, otherwise the annotations for PF06603.14 will not be stored in the proper database table and %(anvi-estimate-metabolism)s will not be able to find them later. Also, if you use the %(anvi-script-pfam-accessions-to-hmms-directory)s program to create your custom HMM profiles, you should make sure that the accessions in the resulting `genes.txt` file are matching to the corresponding enzyme accessions in the module file, because those are the accessions that will be put into your contigs database.

Finally, to annotate TIGR01709.2 we need to take our (hypothetical) Interproscan results and convert them into a %(functions-txt)s file. You can visit that page for a lengthier discussion of the file format, but let's say the TIGR01709.2 annotations in that file looked like this:

|gene_callers_id|source|accession|function|e_value|
|:--|:--:|:--:|:--|:--:|
|7|TIGRFAM|TIGR01709.2|type II secretion system protein GspL|1.5e-75|
|23|TIGRFAM|TIGR01709.2|type II secretion system protein GspL|3.4e-20|

The things that are especially critical here is that the `accession` matches to the accession in the module DEFINITION, ORTHOLOGY, and ANNOTATION_SOURCE lines, and that the `source` matches to the source string in the module ANNOTATION_SOURCE line(s).

Suppose the file is called `TIGRFAM_annotations.txt`. Then you can import those annotations, like so:

{{ codestart }}
%(anvi-import-functions)s -c CONTIGS.db \
                       -i TIGRFAM_annotations.txt
{{ codestop }}

Once this is done, you are ready to estimate the pathway's completeness! Here is the command:

{{ codestart }}
%(anvi-estimate-metabolism)s -c CONTIGS.db \
                          --user-modules USER_METABOLISM/ \
                          -O frankenstein
{{ codestop }}

If you did this, the results for module UD0042 would appear at the end of the resulting 'modules' output file, after the estimation results for KEGG modules.
This represents a file in the Variant Call Format, which is a standard format for storing sequence variations like SNVs. 

You can convert the information in a %(variability-profile-txt)s to %(vcf)s with the program %(anvi-script-variability-to-vcf)s. 

### What's in this file? 

For more details, you can check out the [VCF wikipedia page](https://en.wikipedia.org/wiki/Variant_Call_Format). 

#### Header

Briefly, this file's header (marked by `##` at the beginning of each line) contains various metadata. This includes the date, link to the reference file, contig information, etc. It also contains 
- what information will be reported (denoted by `INFO`). 
- what additional filters will be run on each SNV (denoted by `FILTER`). For example, marking which variants are below a certain quality threshold. 
- what format to display additional data in (denoted by `FORMAT`). 

#### Body

The body of the file contains identifying information for the variation (the chromosome, position and ID), the identity of the position in the reference and alternative alleles present in your data. Following this is a quality score for your data and the additional information specified by the header. 
As an artifact, this describes the variability information about a single sample calculated when you ran %(anvi-profile)s. To examine variability across samples, you'll want to use this information (which is stored within your %(profile-db)s) to run %(anvi-gen-variability-profile)s. 

## Details about Variability

In the context of anvi'o, variability means divergence of environmental populations from the reference used to perform metagenomic read recruitment.

Here, the term "population" describes an assemblage of co-existing microbial genomes in an environment that are similar enough to map to the context of the same reference genome.

The variability profile of a metagenome enables studies of [microbial population genetics with anvi'o](http://merenlab.org/2015/07/20/analyzing-variability/).

There are two types of variability the program %(anvi-profile)s can characterize and store: substitutions and indels.

### Substitutions: SNVs, SCVs, SAAVs

Anvi'o can make sense of single-nucleotide variants (SNVs), single-codon variants (SCVs), and single-amino acid variants (SAAVs). See [this article](http://merenlab.org/2015/07/20/analyzing-variability) for more information.

You can learn the name of the table in which anvi'o stores this in a given %(profile-db)s by running this command in your anvi'o environment:

``` bash
python -c 'import anvio.tables as t; print(t.variable_nts_table_name)'
```

This will tell you about its structure:

``` bash
python -c 'import anvio.tables as t; print(t.variable_nts_table_structure)'
```

### Indels: insertions and deletions

Anvi'o can also characterize insertions and deletions found within an environment based on short-read recruitment results and will store in the following table:

``` bash
python -c 'import anvio.tables as t; print(t.indels_table_name)'
```

**Notes for programmers**: The convention for the start position of an insertion is defined like so:

```
    pos_in_contig ...0123456 7890123456
    reference     ...CTACTAC TACTTCATGA...
    read              TACTAC TAC
    insertion               â””â”€â”€ACTG
```

In this case, the start position of the insertion in the contig is 6. The insertion _follows_ the position it is defined by. This is opposite to IGV, in which the insertion _precedes_ the position it is defined by.

For deletions, there is no such ambiguity in the start position, since the deletion starts on a reference position, not in between two reference positions.
This a tab-delimited text file that describes information contained in a %(misc-data-layers)s. 

To import this information into a database, use %(anvi-import-misc-data)s. 

In this table, the first column should match the names of the samples that you're displaying, and the following columns can contain any categorical or numerical data of your choosing. (You can even be fancy and display data as a stacked bar graph.)

For an example, check out [the table on this page](http://merenlab.org/2017/12/11/additional-data-tables/#layers-additional-data-table).
This is a TAB-delimited output file that describes enrichment scores and associated groups for functions or metabolic modules in groups of genomes or samples.

## General format

Each row in the matrix describes an entity (a function, functional association of a gene cluster, or metabolic module) that is associated with one or more groups of samples or genomes. These are listed with the highest enrichment scores displayed first.

The following columns of information are listed in the file:

- the name of the enriched entity, which can be a functional association, metabolic module, or function. The header of this column is either your functional annotation source, OR 'KEGG_MODULE' if you are working with metabolic modules
- enrichment_score: a measure of much this particular entity is enriched in the group it is associated with (i.e., measures how unique this entity [see column 1] is to this group(s) [see column 5])
- unadjusted_p_value: the significance value of the hypothesis test for enrichment, unadjusted for multiple hypothesis testing
- adjusted_q_value: the adjusted p-value after taking into account multiple hypothesis testing
- associated groups: the list of groups that this entity is associated with
- accession: a function accession number or KEGG module number
- a list of gene cluster ids, sample names, or genome names that this entity is found in
- p values for each group: gives the proportion of the group's member genomes or samples in which this entity was found.
- N values for each group: gives the total number of genomes or samples in each group.

## A specific example - enriched functions in pangenomes

When you run %(anvi-compute-functional-enrichment-in-pan)s to compute enrichment scores for functions in a pangenome, the resulting matrix describes the gene cluster-level functional associations that are enriched within specific groups of your pangenome. This is described in more detail [in the pangenomics tutorial](http://merenlab.org/2016/11/08/pangenomics-v2/#making-sense-of-functions-in-your-pangenome).

Here is a more concrete example (the same example as in the [pangenomics tutorial](http://merenlab.org/2016/11/08/pangenomics-v2/#making-sense-of-functions-in-your-pangenome)). Note that that tutorial uses `COG_FUNCTION` as the functional annotation source, and has `LL` (low light) and `HL` (high light) as the two pan-groups.

|COG_FUNCTION | enrichment_score | unadjusted_p_value | adjusted_q_value | associated_groups | accession | gene_clusters_ids | p_LL | p_HL | N_LL | N_HL|
|-- | -- | -- | -- | -- | -- | -- | -- | -- | --| --|
|Proteasome lid subunit RPN8/RPN11, contains Jab1/MPN domain metalloenzyme (JAMM) motif | 31.00002279 | 2.58E-08 | 1.43E-06 | LL | COG1310 | GC_00002219, GC_00003850, GC_00004483 | 1 | 0 | 11 | 20|
|Adenine-specific DNA glycosylase, acts on AG and A-oxoG pairs | 31.00002279 | 2.58E-08 | 1.43E-06 | LL | COG1194 | GC_00001711 | 1 | 0 | 11 | 20|
|Periplasmic beta-glucosidase and related glycosidases | 31.00002279 | 2.58E-08 | 1.43E-06 | LL | COG1472 | GC_00002086, GC_00003909 | 1 | 0 | 11 | 20|
|Single-stranded DNA-specific exonuclease, DHH superfamily, may be involved in archaeal DNA replication intiation | 31.00002279 | 2.58E-08 | 1.43E-06 | LL | COG0608 | GC_00002752, GC_00003786, GC_00004838, GC_00007241 | 1 | 0 | 11 | 20|
|Ser/Thr protein kinase RdoA involved in Cpx stress response, MazF antagonist | 31.00002279 | 2.58E-08 | 1.43E-06 | LL | COG2334 | GC_00002783, GC_00003936, GC_00004631, GC_00005468 | 1 | 0 | 11 | 20|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|
|Signal transduction histidine kinase | -7.34E-41 | 1 | 1 | NA | COG5002 | GC_00000773, GC_00004293 | 1 | 1 | 11 | 20|
|tRNA A37 methylthiotransferase MiaB | -7.34E-41 | 1 | 1 | NA | COG0621 | GC_00000180, GC_00000851 | 1 | 1 | 11 | 20|
This file contains information about your genes. 

It is a tab-delimited text file where each row represents a specific gene and each column provides different information. 

As of now, the only program that returns data in this format is %(anvi-script-gen_stats_for_single_copy_genes.py)s, which returns this information for the single copy core genes in your %(contigs-db)s. 

From left to right, these tell you 
* The source for this gene (ex `Protista_83`)
* The name of the contig that this gene is a part of
* The gene name 
* The e-value (of the HMM hit that was used to find this gene)
This is the output of %(anvi-compute-genome-similarity)s (which describes the level of similarity between all of the input genomes) or %(anvi-script-compute-ani-for-fasta)s (which describes the level of similarity between contigs in a fasta file). 

{:.notice}
The output of %(anvi-compute-genome-similarity)s will only be in this structure if you did not input a %(pan-db)s. Otherwise, the data will be put directly into the additional data tables of the %(pan-db)s. The same is true of %(anvi-script-compute-ani-for-fasta)s. 

This is a directory (named by the user) that contains both a %(dendrogram)s (NEWICK-tree) and a matrix of the similarity scores between each pair for a variety of metrics dependent on the program that you used to run %(anvi-compute-genome-similarity)s or %(anvi-script-compute-ani-for-fasta)s .

For example, if you used `pyANI`'s `ANIb` (the default program), the output directory will contain the following twelve files. These are directly created from the heatmaps generated by PyANI, just converted into matrices and newick files: 

-`ANIb_alignment_coverage.newick` and `ANIb_alignment_coverage.txt`: contains the percent coverage (for query and subject)

-`ANIb_percentage_identity.newick` and `ANIb_percentage_identity.txt`: contains the percent identity

-`ANIb_full_percentage_identity.newick` and `ANIb_full_percentage_identity.txt`: contains the percent identity in the context of the length of the entire query and subject sequences (not just the aligned segment)

-`ANIb_alignment_lengths.newick` and `ANIb_alignment_lengths.txt`: contians the total aligned lengths 

-`ANIb_similarity_errors.newick` and `ANIb_similarity_errors.txt`: contains similarity errors (total number of mismatches, not including indels)

-`ANIb_hadamard.newick` and `ANIb_hadamard.txt`: contians the hadamard matrix (dot product of identity and coverage matrices)

This describes the output of %(anvi-get-pn-ps-ratio)s, which calculates the pN/pS ratio for each gene in a %(contigs-db)s. 

{:.notice}
See the page for %(anvi-get-pn-ps-ratio)s for an explanation of the pN/pS ratio 

This describes a directory that contains the following four files: 

`pNpS.txt`: a long-format table of the pN/pS values, along with the groupby variables:

|   | corresponding_gene_call | sample_id   | pNpS_reference       |
| - | ----------------------- | ----------- | -------------------- |
| 0 | 1744                    | ANE_004_05M | 0.043503524536208836 |
| 1 | 1744                    | ANE_004_40M | 0.043628712253629943 |
| 2 | 1744                    | ANE_150_05M | 0.03810623760551494  |
| 3 | 1744                    | ANE_150_40M | 0.040815421982026576 |

`pN.txt`: a long-format table of the pN values, along with the groupby variables:

|   | corresponding_gene_call | sample_id   | pN_reference       |
| - | ----------------------- | ----------- | ------------------ |
| 0 | 1744                    | ANE_004_05M | 11.827627600424583 |
| 1 | 1744                    | ANE_004_40M | 11.106801744995472 |
| 2 | 1744                    | ANE_150_05M | 9.62355553228605   |
| 3 | 1744                    | ANE_150_40M | 10.067364489809782 |

`pS.txt`: a long-format table of the pS values, along with the groupby variables:

|   | corresponding_gene_call | sample_id   | pS_reference       |
| - | ----------------------- | ----------- | ------------------ |
| 0 | 1744                    | ANE_004_05M | 271.87745651689016 |
| 1 | 1744                    | ANE_004_40M | 254.57551165909962 |
| 2 | 1744                    | ANE_150_05M | 252.54541348089631 |
| 3 | 1744                    | ANE_150_40M | 246.6558962502711  |

`num_SCVs.txt`: a long-format table of the number of SCVs belonging to each group:

|   | corresponding_gene_call | sample_id   | num_SCVs |
| - | ----------------------- | ----------- | -------- |
| 0 | 1744                    | ANE_004_05M | 180      |
| 1 | 1744                    | ANE_004_40M | 166      |
| 2 | 1744                    | ANE_150_05M | 162      |
| 3 | 1744                    | ANE_150_40M | 160      |

This is an artifact that describes **annotation of genes in your %(contigs-db)s with functions**.

Broadly used across anvi'o, functions are one of the most essential pieces of information stored in any %(contigs-db)s. To see what annotation sources for functions are available in a given %(contigs-db)s or %(genomes-storage-db)s, you can use the program %(anvi-db-info)s.

To populate a given %(contigs-db)s with functions, anvi'o includes multiple programs that can annotate genes using various sources of annotation. These programs include,

* %(anvi-run-ncbi-cogs)s, which uses NCBI's [COGs database](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC102395/),
* %(anvi-run-pfams)s, which uses EBI's [Pfam database](https://pfam.xfam.org/),
* %(anvi-run-kegg-kofams)s, which uses the [Kyoto Encyclopedia of Genes and Genomes](https://www.genome.jp/kegg/) (KEGG) database and produces %(kegg-functions)s, which is the necessary annotation information that can be used by the program %(anvi-estimate-metabolism)s.

In addition, you can use the program %(anvi-import-functions)s with a simple %(functions-txt)s to import functions from any other annotation source, or to import any ad hoc, user-defined function to later access through anvi'o interfaces or programs.

{:.notice}
You can use %(anvi-import-functions)s also to import functions from EggNOG or InterProScan as described in [this blog post](http://merenlab.org/2016/06/18/importing-functions/).

You can also use %(anvi-export-functions)s to obtain a file containing these functional annotations through a %(functions-txt)s artifact, and use %(anvi-display-functions)s to show the distribution of functions across multiple %(contigs-db)ss.
This is a NEWICK-formatted tree that describes the phylogenic relationships of your data. 

{:.notice}
Wondering what the NEWICK format is? Then you're in luck! It has its own [Wikipedia page](https://en.wikipedia.org/wiki/Newick_format).

### How to get one of these? 

You can use %(anvi-gen-phylogenomic-tree)s to create a phylogeny based on a series of genes. 

As discussed on the page for %(anvi-gen-phylogenomic-tree)s, you can also use an external program to get a NEWICK-formatted tree and use that. 

### What can I do with it? 

Firstly, you can use it to reorder elements of the interactive interface. To import this to rearrange the orders that your items appear (in other words, as the central phylogenetic tree when you open the interface), import it using %(anvi-import-items-order)s. To import this as a tree describing your layers (the concentric circles in the anvi'o interface), convert this to a %(misc-data-layer-orders-txt)s and use the program %(anvi-import-misc-data)s.

Secondly, as done in the [Phylogenetics tutorial](http://merenlab.org/2017/06/07/phylogenomics/#working-with-fasta-files), you can open it in the interactive interface without an associated %(contigs-db)s. To do this, run %(anvi-interactive)s as so:

{{ codestart }}
anvi-interactive -t %(phylogeny)s \
                 --title "Phylogenomics Tutorial" \
                 --manual
{{ codestop }}

This will create an empty %(profile-db)s to store any %(bin)ss you create and other such data. You can also add various information, such as taxonomy hits, as done in that same [Phylogenetics tutorial](http://merenlab.org/2017/06/07/phylogenomics/#working-with-fasta-files). 
This is a Protein Data Bank (`X.pdb`) file that describes the structure of a protein as stored in your %(structure-db)s. This is the output of running %(anvi-export-structures)s.

This file format has its own [Wikipedia page](https://en.wikipedia.org/wiki/Protein_Data_Bank_(file_format)), as well as pages on PDB-101 [for beginners](https://pdb101.rcsb.org/learn/guide-to-understanding-pdb-data/beginner's-guide-to-pdb-structures-and-the-pdbx-mmcif-format) and for [coordinates specifically](https://pdb101.rcsb.org/learn/guide-to-understanding-pdb-data/dealing-with-coordinates), but is also briefly explained here. 

The header describes the title (if one exists), the type of data (denoted by `EXPDTA`), and any free-form annotations (denoted by `REMARK` ). In Anvi'o, these are primarily MODELLER information calculated when you ran %(anvi-gen-structure-database)s. 

Most of the data will describe the position of individual atoms (denoted by `ATOM`) in your protein, where columns 6, 7, and 8 describe the three dimensional coordinate of the atom. The rest of the columns describe information like what position that atom is in the amno acid. 

`TER` statements separate independent chains from each other.

Here is an example: 

    EXPDTA    THEORETICAL MODEL, MODELLER 9.22 2020/10/13 14:38:54
    REMARK   6 MODELLER OBJECTIVE FUNCTION:       255.0071
    REMARK   6 MODELLER BEST TEMPLATE percent SEQ ID:  73.077
    ATOM      1  N   MET A   1       4.009  -3.600  -0.411  1.00 59.26           N
    ATOM      2  CA  MET A   1       5.250  -3.864  -1.173  1.00 59.26           C
    ATOM      3  CB  MET A   1       6.409  -3.005  -0.631  1.00 59.26           C
    ATOM      4  CG  MET A   1       6.204  -1.504  -0.854  1.00 59.26           C
    ATOM      5  SD  MET A   1       7.545  -0.444  -0.229  1.00 59.26           S
    ATOM      6  CE  MET A   1       6.982  -0.449   1.495  1.00 59.26           C
    ATOM      7  C   MET A   1       5.617  -5.306  -1.058  1.00 59.26           C
    ATOM      8  O   MET A   1       4.900  -6.175  -1.552  1.00 59.26           O
    ATOM      9  N   SER A   2       6.753  -5.603  -0.397  1.00 49.70           N
    ATOM     10  CA  SER A   2       7.165  -6.971  -0.290  1.00 49.70           C
    ATOM     11  CB  SER A   2       8.547  -7.150   0.362  1.00 49.70           C
    ATOM     12  OG  SER A   2       9.546  -6.534  -0.437  1.00 49.70           O
    ATOM     13  C   SER A   2       6.184  -7.694   0.556  1.00 49.70           C
    ATOM     14  O   SER A   2       5.954  -7.346   1.714  1.00 49.70           O
    ATOM     15  N   GLU A   3       5.553  -8.718  -0.037  1.00103.21           N
    ATOM     16  CA  GLU A   3       4.632  -9.540   0.676  1.00103.21           C
    ATOM     17  CB  GLU A   3       3.856 -10.490  -0.249  1.00103.21           C
    ATOM     18  CG  GLU A   3       4.774 -11.467  -0.988  1.00103.21           C
    ATOM     19  CD  GLU A   3       3.918 -12.407  -1.826  1.00103.21           C
    ATOM     20  OE1 GLU A   3       2.672 -12.402  -1.638  1.00103.21           O
    ATOM     21  OE2 GLU A   3       4.502 -13.146  -2.663  1.00103.21           O
    ATOM     22  C   GLU A   3       5.402 -10.410   1.614  1.00103.21           C
    ...
    ATOM    594  C   ASN A  79      19.969 -15.504   4.267  1.00 61.57           C
    ATOM    595  O   ASN A  79      21.042 -14.862   4.423  1.00 61.57           O
    ATOM    596  OXT ASN A  79      19.857 -16.742   4.474  1.00 61.57           O
    TER     597      ASN A  79
    END
A tRNA-seq database **contains information on tRNA sequences predicted from a single tRNA-seq sample**.

This database is the key output of **%(anvi-trnaseq)s**. That program predicts which reads are tRNA through structural profiling, clusters tRNA reads into discrete biological sequences, and predicts the positions of nucleotide modifications.

The series of steps implemented in %(anvi-trnaseq)s sequentially adds the following information to the database.

* Unique sequences predicted to be tRNA, including read counts
* Primary sequence and secondary structural features (stems and loops) predicted in each profiled tRNA
* Unconserved nucleotides in the primary sequence that differ from expectation
* Unpaired nucleotides in the stems
* "Trimmed" tRNA sequences, formed from unique sequences only differing by 3' nucleotides of the CCA acceptor region and 5' nucleotides beyond the acceptor stem
* "Normalized" tRNA sequences, formed by dereplicating trimmed tRNA sequences that are 3' fragments from incomplete reverse transcription and by mapping biological 5' and interior tRNA fragments
* Potentially modified tRNA sequences, formed by clustering normalized tRNA sequences and retaining those clusters that differ by 3-4 nucleotides at aligned positions

This database is the key input to **%(anvi-merge-trnaseq)s**, which takes one or more databases comprising the samples in an experiment and generates a %(trnaseq-contigs-db)s of tRNA seed sequences and %(trnaseq-profile-db)ss. These tRNA-seq variant contigs and profile databases can then be manipulated and displayed in anvi'o like normal %(contigs-db)ss and %(profile-db)ss.
This file contains **the frequency of each codon in each gene in your %(contigs-db)s.** 

This is a tab-delimited table where each column represents a codon and each row represents a specific gene. The numbers will either refer to counts of each codon or precent normalizations depending on the parameters with which you ran %(anvi-get-codon-frequencies)s. 

### Example

    gene_caller_id  GCA GCC GCG GCT ...
        1           0   0   1   2
        2           1   0   0   2
        .
        .
        .
A pan-db is an anviâ€™o database that contains **key information associated with your gene clusters**. This is vital for its pangenomic analysis, hence the name. If you want to learn more about the pangenomic workflow in Anvi'o, it has [its own tutorial here](http://merenlab.org/2016/11/08/pangenomics-v2/).

This is the output of the program %(anvi-pan-genome)s, which can be run after you've created a %(genomes-storage-db)s with the genomes you want to analyze. That script does the brunt of the pangenomic analysis; it caluclates the similarity between all of the genes in your genomes-storage-db, clusters them and organizes the final clusters. All of the results of that analysis are stored in a pan-db.

You can use a pan database to run a variety of pangenomic analyses, including %(anvi-compute-genome-similarity)s, %(anvi-analyze-synteny)s, and %(anvi-compute-functional-enrichment-in-pan)s. You can also view and interact with the data in a pan-db using %(anvi-display-pan)s. 

To add additional information to the pangenome display, you'll probably want to use %(anvi-import-misc-data)s

## Advanced information for programmers

While it is possible to read and write a given anvi'o pan database through SQLite functions directly, one can also use anvi'o libraries to initiate a pan database to read from.

### Initiate a pan database instance

``` python
import argparse

from anvio.dbops import PanSuperclass

args = argparse.Namespace(pan_db="PAN.db", genomes_storage="GENOMES.db")

pan_db = PanSuperclass(args)

```

### Gene clusters dictionary

Once an instance from `PanSuperclass` is initiated, the following member function will give access to gene clusters:

``` pyton
pan_db.init_gene_clusters()
print(pan_db.gene_clusters)
```

```
{
  "GC_00000001": {
    "Genome_A": [19, 21],
    "Genome_B": [30, 32],
    "Genome_C": [122, 125],
    "Genome_D": [44, 42]
  },
  "GC_00000002": {
    "Genome_A": [123],
    "Genome_B": [176],
    "Genome_C": [175],
    "Genome_D": []
  },
  (...)
  "GC_00000036": {
    "Genome_A": [],
    "Genome_B": [24],
    "Genome_C": [],
    "Genome_D": []
  }
  (...)
```

Each item in this dictionary is a gene cluster describes anvi'o gene caller ids of each gene from each genome that contributes to this cluster.

### Sequences in gene clusters

```
gene_clusters_of_interest = set(["GC_00000006", "GC_00000036"])
gene_cluster_sequences = pan_db.get_sequences_for_gene_clusters(gene_cluster_names= gene_clusters_of_interest)

print(gene_cluster_sequences)
```

```
{
  "GC_00000006": {
    "Genome_A": {
      23: "MDVKKGWSGNNLND--NNNGSFTLFNAYLPQAKLANEAMHQKIMEMSAKAPNATMSITGHSLGTMISIQAVANLPQAD"
    },
    "Genome_B": {
      34: "MDVKKGWSGNNLND--NNNGSFTLFNAYLPQAKLANEAMHQKIMEMSAKAPNATMSITGHSLGTMISIQAVANLPQAD"
    },
    "Genome_C": {
      23: "MDVKKGWSGNNLNDWVNNNGSFTLFNAYLPQAKLANEAMHQKIMEMSAKAPNATMSITGHSLGTMISIQAVANLPQAD"
    },
    "Genome_D": {
      23: "MDVKKGWSGNNLNDWVNNAGSFTLFNAYLPQAKLANEAMHQKIMEMSAKAPNATMSITGHSLGTMISIQAVANLPQAD"
    }
  },
  "GC_00000036": {
    "Genome_A": {},
    "Genome_B": {
      24: "MSKRHKFKQFMKKKNLNPMNNRKKVGIILFATSIGLFFLFAFRTTYIVATGKVAGVSLKEKTA"
    },
    "Genome_C": {},
    "Genome_D": {}
  }
}
```
A collection of TAB-delimited text files generated from the profiling of BAM files.

## Example outputs

The number of columns and their content for files that are considered artifact %(bam-stats-txt)s will be variable and depend on the user parameters set for %(anvi-profile-blitz)s.

The column names may be one of these:

* `gene_callers_id`: Unique number assigned by the gene caller during the creation of the %(contigs-db)s.
* `contig`: Contig name as appears in the %(bam-file)s and %(contigs-db)s
* `sample`: The name of the %(bam-file)s without its prefix. I.e., the value *SAMPLE-01* will appear in the *sample* column if the BAM file path was */path/to/SAMPLE-01.bam*.
* `length`: Depending on the context, the length of the gene or contig.
* `detection`: Proportion of nucleotides that have at least 1X coverage.
* `mean_cov`: Mean covearge.
* `q2q3_cov`: Mean of the coverage (inner quartiles).
* `median_cov`: Median coverage.
* `min_cov`: Minimum coverage value observed for the gene or the contig.
* `max_cov`: Minimum coverage value observed for the gene or the contig.
* `std_cov`: Standard deviation of coverage.

### Contig mode, default output

11-column TAB delimited file, where each row represents a single contig x sample pair (so the values in the first column are not unique):

|contig|sample|length|gc_content|detection|mean_cov|q2q3_cov|median_cov|min_cov|max_cov|std_cov|
|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|contig_878|SAMPLE-01|27538|0.608|0.9995|63.61|65.2|65.0|0|107|15.21|
|contig_6515|SAMPLE-01|12315|0.446|0.9985|91.51|92.5|92.0|0|195|23.98|
|contig_1720|SAMPLE-01|16856|0.312|0.9993|37.85|38.25|38.0|0|56|7.961|
|contig_878|SAMPLE-02|27538|0.608|0.9999|9.262|9.161|9.0|0|21|3.42|
|contig_6515|SAMPLE-02|12315|0.446|0.9918|33.05|33.47|33.0|0|56|8.503|
|contig_1720|SAMPLE-02|16856|0.312|0.9986|8.93|8.751|9.0|0|19|3.306|
|contig_878|SAMPLE-03|27538|0.608|1.0|37.32|37.21|37.0|0|75|11.46|
|contig_6515|SAMPLE-03|12315|0.446|0.9276|3.953|3.682|4.0|0|15|2.644|
|contig_1720|SAMPLE-03|16856|0.312|1.0|178.1|178.1|178.0|1|269|29.13|

### Contig mode, minimal output:

6-column TAB delimited file, where each row represents a single contig x sample pair:


|contig|sample|length|gc_content|detection|mean_cov|
|:--|:--:|:--:|:--:|:--:|:--:|
|contig_878|SAMPLE-01|27538|0.608|0.9995|63.61|
|contig_6515|SAMPLE-01|12315|0.446|0.9985|91.51|
|contig_1720|SAMPLE-01|16856|0.312|0.9993|37.85|
|contig_878|SAMPLE-02|27538|0.608|0.9999|9.262|
|contig_6515|SAMPLE-02|12315|0.446|0.9918|33.05|
|contig_1720|SAMPLE-02|16856|0.312|0.9986|8.93|
|contig_878|SAMPLE-03|27538|0.608|1.0|37.32|
|contig_6515|SAMPLE-03|12315|0.446|0.9276|3.953|
|contig_1720|SAMPLE-03|16856|0.312|1.0|178.1|

### Gene mode, default output

11-column TAB delimited file, where each row represents a single gene x sample pair:

|gene_callers_id|contig|sample|length|detection|mean_cov|q2q3_cov|median_cov|min_cov|max_cov|std_cov|
|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|0|contig_878|SAMPLE-01|933|0.9871|53.97|58.9|59.0|0|85|21.18|
|1|contig_878|SAMPLE-01|564|1.0|66.97|66.88|66.0|35|103|20.6|
|2|contig_878|SAMPLE-01|444|1.0|81.72|81.59|82.0|70|95|4.88|
|3|contig_878|SAMPLE-01|1218|1.0|54.45|57.1|58.0|15|87|17.8|
|4|contig_878|SAMPLE-01|3381|1.0|60.89|60.96|61.0|19|95|13.66|
|5|contig_878|SAMPLE-01|942|1.0|64.34|63.98|63.0|38|92|10.49|
|6|contig_878|SAMPLE-01|588|1.0|67.51|66.18|66.0|51|92|9.591|
|7|contig_878|SAMPLE-01|1854|1.0|62.63|63.03|63.0|31|85|10.14|
|8|contig_878|SAMPLE-01|285|1.0|67.43|68.41|70.0|51|80|8.741|
|9|contig_878|SAMPLE-01|1215|1.0|60.96|63.68|64.0|16|83|13.94|
|10|contig_878|SAMPLE-01|2250|1.0|62.36|62.91|62.0|9|107|18.65|
|11|contig_878|SAMPLE-01|741|1.0|70.23|70.42|71.0|44|94|11.49|
|12|contig_878|SAMPLE-01|963|1.0|63.49|65.79|65.0|24|88|13.8|
|13|contig_878|SAMPLE-01|684|1.0|56.33|57.69|58.0|26|85|13.38|
|14|contig_878|SAMPLE-01|1569|1.0|61.79|63.8|64.0|10|95|18.3|
|15|contig_878|SAMPLE-01|1584|1.0|65.69|66.14|67.0|44|88|8.792|
|16|contig_878|SAMPLE-01|831|1.0|67.95|67.82|67.0|48|91|8.154|
|17|contig_878|SAMPLE-01|192|1.0|81.12|81.14|82.0|69|91|5.041|
|18|contig_878|SAMPLE-01|1467|1.0|60.06|60.98|62.0|25|91|14.24|
|19|contig_878|SAMPLE-01|801|1.0|68.31|67.72|68.0|58|86|5.945|
|20|contig_878|SAMPLE-01|360|1.0|71.42|72.38|74.0|53|87|8.963|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|
|0|contig_878|SAMPLE-02|933|1.0|8.17|7.548|8.0|1|21|4.7|
|1|contig_878|SAMPLE-02|564|1.0|8.151|8.28|8.0|2|14|3.13|
|2|contig_878|SAMPLE-02|444|1.0|10.84|10.31|10.0|7|15|2.128|
|3|contig_878|SAMPLE-02|1218|1.0|9.86|10.55|11.0|1|15|3.041|
|4|contig_878|SAMPLE-02|3381|1.0|10.17|9.925|10.0|3|18|2.796|
|5|contig_878|SAMPLE-02|942|1.0|11.07|10.98|11.0|6|17|2.34|
|6|contig_878|SAMPLE-02|588|1.0|10.09|9.296|9.0|5|18|3.169|
|7|contig_878|SAMPLE-02|1854|1.0|9.417|9.186|9.0|2|16|2.75|
|8|contig_878|SAMPLE-02|285|1.0|10.33|10.0|10.0|7|15|2.217|
|9|contig_878|SAMPLE-02|1215|1.0|9.386|8.685|9.0|3|20|3.965|
|10|contig_878|SAMPLE-02|2250|0.9991|7.619|7.98|8.0|0|14|2.97|
|11|contig_878|SAMPLE-02|741|1.0|10.82|11.18|11.0|3|16|3.067|
|12|contig_878|SAMPLE-02|963|1.0|6.849|7.004|7.0|2|12|2.912|
|13|contig_878|SAMPLE-02|684|1.0|7.281|7.029|8.0|2|14|3.168|
|14|contig_878|SAMPLE-02|1569|1.0|6.505|6.345|6.0|1|13|2.363|
|15|contig_878|SAMPLE-02|1584|1.0|9.199|9.064|9.0|4|15|2.398|
|16|contig_878|SAMPLE-02|831|1.0|10.59|10.73|11.0|6|15|2.31|
|17|contig_878|SAMPLE-02|192|1.0|8.208|8.854|9.0|3|11|2.857|
|18|contig_878|SAMPLE-02|1467|1.0|10.67|10.36|11.0|4|20|3.894|
|19|contig_878|SAMPLE-02|801|1.0|10.85|10.74|11.0|5|19|2.706|
|20|contig_878|SAMPLE-02|360|1.0|10.32|10.24|10.0|6|15|1.886|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|

### Gene mode, minimal output:

6-column TAB delimited file, where each row represents a single gene x sample pair:

|gene_callers_id|contig|sample|length|detection|mean_cov|
|:--|:--:|:--:|:--:|:--:|:--:|
|0|contig_878|SAMPLE-01|933|0.9871|53.97|
|1|contig_878|SAMPLE-01|564|1.0|66.97|
|2|contig_878|SAMPLE-01|444|1.0|81.72|
|3|contig_878|SAMPLE-01|1218|1.0|54.45|
|4|contig_878|SAMPLE-01|3381|1.0|60.89|
|5|contig_878|SAMPLE-01|942|1.0|64.34|
|6|contig_878|SAMPLE-01|588|1.0|67.51|
|7|contig_878|SAMPLE-01|1854|1.0|62.63|
|8|contig_878|SAMPLE-01|285|1.0|67.43|
|9|contig_878|SAMPLE-01|1215|1.0|60.96|
|10|contig_878|SAMPLE-01|2250|1.0|62.36|
|11|contig_878|SAMPLE-01|741|1.0|70.23|
|12|contig_878|SAMPLE-01|963|1.0|63.49|
|13|contig_878|SAMPLE-01|684|1.0|56.33|
|14|contig_878|SAMPLE-01|1569|1.0|61.79|
|15|contig_878|SAMPLE-01|1584|1.0|65.69|
|16|contig_878|SAMPLE-01|831|1.0|67.95|
|17|contig_878|SAMPLE-01|192|1.0|81.12|
|18|contig_878|SAMPLE-01|1467|1.0|60.06|
|19|contig_878|SAMPLE-01|801|1.0|68.31|
|20|contig_878|SAMPLE-01|360|1.0|71.42|
|(...)|(...)|(...)|(...)|(...)|(...)|
|0|contig_878|SAMPLE-02|933|1.0|8.17|
|1|contig_878|SAMPLE-02|564|1.0|8.151|
|2|contig_878|SAMPLE-02|444|1.0|10.84|
|3|contig_878|SAMPLE-02|1218|1.0|9.86|
|4|contig_878|SAMPLE-02|3381|1.0|10.17|
|5|contig_878|SAMPLE-02|942|1.0|11.07|
|6|contig_878|SAMPLE-02|588|1.0|10.09|
|7|contig_878|SAMPLE-02|1854|1.0|9.417|
|8|contig_878|SAMPLE-02|285|1.0|10.33|
|9|contig_878|SAMPLE-02|1215|1.0|9.386|
|10|contig_878|SAMPLE-02|2250|0.9991|7.619|
|11|contig_878|SAMPLE-02|741|1.0|10.82|
|12|contig_878|SAMPLE-02|963|1.0|6.849|
|13|contig_878|SAMPLE-02|684|1.0|7.281|
|14|contig_878|SAMPLE-02|1569|1.0|6.505|
|15|contig_878|SAMPLE-02|1584|1.0|9.199|
|16|contig_878|SAMPLE-02|831|1.0|10.59|
|17|contig_878|SAMPLE-02|192|1.0|8.208|
|18|contig_878|SAMPLE-02|1467|1.0|10.67|
|19|contig_878|SAMPLE-02|801|1.0|10.85|
|20|contig_878|SAMPLE-02|360|1.0|10.32|
|(...)|(...)|(...)|(...)|(...)|(...)|

## Reproducing these output files

Examples above generated by running %(anvi-profile-blitz)s in the mini-test output directory. To reproduce them, you can run this command to generate the necessary files,

```
anvi-self-test --suite mini -o TEST
```

then go into the directory,

```
cd TEST
```

and run %(anvi-profile-blitz)s in coresponding modes.This is a **text file containing a list of splits**. 

This file has only one column with one split name per line. For example 

    split_name_1
    split_name_2
    split_name_3
    
    
This kind of file is used when you want to focus your analysis on only a specific set of splits. Just provide one of these and the program will only look at `split_name_1`, `split_name_2`, and `split_name_3`.
A two-column TAB-delimited file **without a header** that describes a %(collection)s by associating items with %(bin)s names.

It can be used to import or export collections in and out of anvi'o databases, and/or transferring them between anvi'o projects seamlessly.

The first column in the file lists item names and the second column associates a given item with a bin. 

{{ codestart }}
item_01    bin_1
item_02    bin_1
item_03    bin_1
item_04    bin_2
item_05    bin_3
item_06    bin_3
{{ codestop }}

### The optinal bins info file

In addition to the essential file above, you can associate an optional TAB-delmited file with three columns with a collection to provide information about 'bins' in it, such as their source, and/or color to be used when they are displayed in %(summary)s outputs or anvi'o %(interactive)s interfaces. Here is an example:

```
bin_1	CONCOCT	 #c9d433
bin_2	CONCOCT	 #e86548
bin_3	anvi-refine	 #0b8500
```

In this file format, the first column is a bin name, the second column is a source, and the third column is an HTML color.

{:.notice}
The source is a free form text and can be anything. We often use `anvi-interactive` or `CONCOCT` or `anvi-refine` for our bins to track which ones were manually refined, and which ones were coming from an automated binning algorithm.

You can provide this optional file to the program %(anvi-import-collection)s with the parameter `--bins-info`.
This basically stores **a local copy of the data from the NCBI [COGs database](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC102395/) for function annotation.** 

It is required to run %(anvi-run-ncbi-cogs)s and is set up on your computer by the program %(anvi-setup-ncbi-cogs)s. 
This is a section of your %(contigs-db)s that contains custom additional information about specific nucleotides. 

Take a look at [this blogpost](http://merenlab.org/2020/07/22/interacdome/#6-storing-the-per-residue-binding-frequencies-into-the-contigs-database) for potential uses in the InteracDome (which will likely be added to anvi'o in v7) and the motivation behind this program. 

Similarly to other types of miscellaneous data (like %(misc-data-items)s), this information is either numerical or categorical and can be populated into a %(contigs-db)s (from a %(misc-data-nucleotides-txt)s) with %(anvi-import-misc-data)s. It is also displayed when you run %(anvi-show-misc-data)s and can be exported or deleted with %(anvi-export-misc-data)s and %(anvi-delete-misc-data)s respectively. 

For example, this information could describe specific nucleotides that are known to be SNVs from another experiment, various key nucleotides for binding to ligands, or positions known to have other modifications (such as m1A or s4U).
This tabular file contains data on the specific coverages of tRNA-seq seeds.

Specific coverage represents reads that are assigned uniquely to a tRNA seed. See the %(trnaseq-profile-db)s artifact for a fuller explanation of specific versus nonspecific coverage. The rows and columns of this table are identical to %(seeds-non-specific-txt)s except the type of coverage data reported in each.

This file is produced by %(anvi-tabulate-trnaseq)s. The artifact for that program describes this and related tables in detail.

This tab-delimited file can be easily manipulated by the user. It is required input for %(anvi-plot-trnaseq)s.

## Example

The seeds shown in this table are also shown in the %(seeds-non-specific-txt)s example. Modifications from these seeds are shown in the %(modifications-txt)s example.

| gene_callers_id | contig_name | anticodon | aa | domain | phylum | class | order | family | genus | species | taxon_percent_id | sample_name | mean_coverage | relative_mean_coverage | relative_discriminator_coverage | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 17a | 18 | 19 | 20 | 20a | 20b | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | 41 | 42 | 43 | 44.01 | 44.02 | 44.03 | 44.04 | 44.05 | 44.06 | 44.07 | 44.08 | 44.09 | 44.1 | 44.11 | 44.12 | 44.13 | 44.14 | 44.15 | 44.16 | 44.17 | 44.18 | 44.19 | 44.2 | 44.21 | 44.22 | 44.23 | 49 | 50 | 51 | 52 | 53 | 54 | 55 | 56 | 57 | 58 | 59 | 60 | 61 | 62 | 63 | 64 | 65 | 66 | 67 | 68 | 69 | 70 | 71 | 72 | 73 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | DB_01 | 71456.2 | 0.25805309 | 0.2578848 |  | 71392 | 71398 | 71398 | 71400 | 71413 | 71414 | 71414 | 71414 | 71419 | 71425 | 71426 | 71426 | 71426 | 71437 | 71445 | 71451 | 71451 |  | 71451 | 71455 | 71457 |  |  | 71460 | 71467 | 71467 | 71471 | 71468 | 71470 | 71470 | 71470 | 71475 | 71489 | 71540 | 71534 | 71529 | 71606 | 71579 | 71582 | 71583 | 71586 | 71586 | 71583 | 71583 | 71583 | 71585 | 71584 | 71584 | 71584 | 71587 | 71587 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 71586 | 71586 | 71572 | 71572 | 71570 | 71504 | 71505 | 71504 | 71503 | 71503 | 71503 | 71503 | 71503 | 71503 | 71503 | 71503 | 71502 | 71500 | 71500 | 71500 | 71497 | 71496 | 71488 | 71466 | 68324 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | DB_03 | 87746.6 | 0.22523292 | 0.22512637 |  | 87568 | 87582 | 87588 | 87594 | 87598 | 87599 | 87596 | 87597 | 87598 | 87606 | 87608 | 87611 | 87611 | 87611 | 87612 | 87615 | 87615 |  | 87614 | 87614 | 87616 |  |  | 87617 | 87619 | 87619 | 87620 | 87620 | 87620 | 87621 | 87619 | 87620 | 87630 | 87689 | 87683 | 87694 | 87732 | 87898 | 87912 | 87921 | 87925 | 87926 | 87926 | 87926 | 87931 | 87924 | 87925 | 87929 | 87981 | 87986 | 87986 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 87985 | 87985 | 87981 | 87980 | 87978 | 87952 | 87952 | 87951 | 87952 | 87954 | 87952 | 87950 | 87946 | 87946 | 87946 | 87943 | 87941 | 87939 | 87939 | 87939 | 87936 | 87935 | 87929 | 87909 | 84530 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | DB_05 | 29533 | 0.22692849 | 0.22190602 |  | 29490 | 29494 | 29499 | 29509 | 29516 | 29516 | 29518 | 29521 | 29525 | 29528 | 29536 | 29536 | 29536 | 29538 | 29539 | 29547 | 29550 |  | 29550 | 29549 | 29553 |  |  | 29552 | 29552 | 29553 | 29552 | 29553 | 29553 | 29549 | 29550 | 29552 | 29553 | 29564 | 29561 | 29559 | 29638 | 29605 | 29602 | 29604 | 29607 | 29607 | 29607 | 29608 | 29607 | 29607 | 29607 | 29607 | 29607 | 29609 | 29609 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 29609 | 29609 | 29606 | 29606 | 29605 | 29601 | 29601 | 29601 | 29601 | 29601 | 29599 | 29599 | 29599 | 29599 | 29596 | 29596 | 29597 | 29595 | 29595 | 29594 | 29593 | 29504 | 29486 | 29451 | 26980 |
0 | c_000000684460_DB_R05_06 | TAC | Val | Bacteria | Firmicutes | Clostridia | Lachnospirales | Lachnospiraceae |  |  | 100 | DB_07 | 47065 | 0.181019 | 0.18087983 |  | 47078 | 47087 | 47105 | 47113 | 47114 | 47114 | 47114 | 47116 | 47124 | 47127 | 47129 | 47129 | 47131 | 47133 | 47139 | 47139 | 47139 |  | 47135 | 47138 | 47141 |  |  | 47145 | 47142 | 47147 | 47145 | 47145 | 47142 | 47143 | 47135 | 47134 | 47133 | 47154 | 47125 | 47093 | 47111 | 47051 | 47058 | 47067 | 47071 | 47073 | 47072 | 47069 | 47069 | 47069 | 47072 | 47072 | 47073 | 47073 | 47074 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 47074 | 47074 | 47073 | 47069 | 47069 | 47042 | 47043 | 47042 | 47038 | 47042 | 47042 | 47042 | 47042 | 47041 | 47041 | 47040 | 47040 | 47040 | 47040 | 47040 | 47033 | 47032 | 47031 | 47018 | 45352 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | DB_01 | 142.4 | 0.00051437 | 0.00052465 |  | 141 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 |  | 142 | 142 | 142 | 142 |  | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 142 | 141 | 141 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 143 | 139 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | DB_03 | 1006.4 | 0.00258316 | 0.00249815 |  | 1010 | 1010 | 1010 | 1010 | 1011 | 1011 | 1011 | 1011 | 1011 | 1010 | 1010 | 1010 | 1010 | 1010 | 1010 | 1010 | 1011 |  | 1011 | 1011 | 1014 | 1014 |  | 1014 | 1014 | 1014 | 1014 | 1014 | 1014 | 1014 | 1014 | 1014 | 1014 | 1014 | 1014 | 1013 | 1012 | 1012 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 1003 | 998 | 998 | 938 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | DB_05 | 297.5 | 0.00228586 | 0.00285402 |  | 225 | 227 | 227 | 227 | 227 | 227 | 225 | 228 | 228 | 230 | 230 | 230 | 230 | 230 | 230 | 230 | 230 |  | 230 | 230 | 230 | 230 |  | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 232 | 233 | 238 | 360 | 367 | 367 | 367 | 370 | 370 | 370 | 370 | 370 | 370 | 370 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 370 | 362 | 362 | 347 |
1 | c_000000805276_DB_R05_05 | ACG | Arg | Bacteria | Firmicutes |  |  |  |  |  | 98.649 | DB_07 | 120 | 0.00046169 | 0.00046664 |  | 116 | 116 | 116 | 116 | 116 | 116 | 116 | 116 | 116 | 119 | 119 | 119 | 118 | 118 | 118 | 118 | 118 |  | 119 | 122 | 126 | 126 |  | 126 | 126 | 126 | 126 | 126 | 126 | 126 | 126 | 126 | 126 | 126 | 124 | 124 | 122 | 123 | 120 | 120 | 120 | 120 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 119 | 117 | 117 | 117 |
Output text files produced by %(anvi-estimate-metabolism)s that describe the presence of **user-defined metabolic pathways** in a %(contigs-db)s.

These files are exactly the same format as those described by %(kegg-metabolism)s, but in addition to (or instead of) information on KEGG modules and KEGG Orthologs, they contain information on user-defined metabolic pathways" (and their component enzymes), as described in %(user-modules-data)s.

## How to get to this output?

You should first read the page on %(user-modules-data)s to learn how to define and set up your own metabolic pathways for use in anvi'o. The program that generates this output is %(anvi-estimate-metabolism)s, and you should run that program with the `--user-modules` parameter to make sure the resulting text files contains the information on your user-defined metabolic pathways. There are two main ways to do it (which are also described on the %(anvi-estimate-metabolism)s help page):

1. To get files describing user-defined metabolic modules _in addition to_ KEGG modules, just use the `--user-modules` parameter.

2. To get files describing _only_ user-defined metabolic modules (instead of KEGG stuff), use both `--user-modules` and `--only-user-modules` parameters.

## What do these files look like?

Check out the %(kegg-metabolism)s page for a comprehensive description of the file formats and various options to customize them. The examples on that page show KEGG data, but the format is the same for user-defined data.
This is a file used by %(anvi-run-workflow)s that lists the name and path of all of the input %(fasta)s files.

As of now, this file is used in the %(contigs-workflow)s, %(pangenomics-workflow)s, and [the reference mode](https://merenlab.org/2018/07/09/anvio-snakemake-workflows/#references-mode) of the %(metagenomics-workflow)s.

In its simplest form, a %(fasta-txt)s is a TAB-delmited file with two columns for `name` and `path`. Here is an example:

|name|path|
|:--|:--|
|SAMPLE_01|path/to/sample_01.fa|
|SAMPLE_02|path/to/sample_02.fa|

Paths can be absolute or relative, and FASTA files can be compressed or not. That's all up to you.

One of the primary users of the %(fasta-txt)s is the [anvi'o snakemake workflows](https://merenlab.org/2018/07/09/anvio-snakemake-workflows/), and to make it more compatible to complex workflow needs, %(fasta-txt)s supports the following additional columns to provide more information for each FASTA file when available, such as %(external-gene-calls)s file and/or a %(functions-txt)s.

Here is an example with those additional columns:

|name|path|external_gene_calls|gene_functional_annotation|
|:--|:--|:--|:--|
|SAMPLE_01|path/to/sample_01.fa|%(external-gene-calls)s_01.txt|%(functions-txt)s_01.txt|
|SAMPLE_02|path/to/sample_02.fa|%(external-gene-calls)s_02.txt|%(functions-txt)s_02.txt|

For more information, check out the [anvi'o workflow tutorial](https://merenlab.org/2018/07/09/anvio-snakemake-workflows/#fastatxt)

This is a section of your %(contigs-db)s that contains custom additional information about specific amino acid residues.  

Take a look at [this blogpost](http://merenlab.org/2020/07/22/interacdome/#6-storing-the-per-residue-binding-frequencies-into-the-contigs-database) for potential uses in the InteracDome (which will likely be added to anvi'o in v7) and the motivation behind this program.  

Similarly to other types of miscellaneous data (like %(misc-data-items)s), this information is either numerical or categorical and can be populated into a %(contigs-db)s (from a %(misc-data-amino-acids-txt)s) with %(anvi-import-misc-data)s. It is also displayed when you run %(anvi-show-misc-data)s and can be exported or deleted with %(anvi-export-misc-data)s and %(anvi-delete-misc-data)s respectively.  

For example, this could describe various key residues for binding to ligands, or residues otherwise determined to be important to the user for whatever reason.  

The output of %(anvi-summarize-blitz)s.

%(anvi-summarize-blitz)s summarizes read-recruitment statistics for a collection of bins across multiple samples. It produces long format output in which each row contains the (weighted) average statistics of a bin in a sample. Each statistic is summarized in a different column of the file.

Here is an example output file from this program, summarizing `detection` and `mean_coverage_Q2Q3` data (the default statistics) for 3 bins across multiple samples:

unique_id | bin_name | sample | detection | mean_coverage_Q2Q3
|:---|:---|:---|:---|:---|
0 | bin_1 | sample_1 | 0.015553023620503776 | 1.0272713907674214
1 | bin_2 | sample_1 | 0.0004871607502275562 | 0.0
2 | bin_3 | sample_1 | 0.0023636043452898497 | 0.0
3 | bin_1 | sample_2 | 0.015767421346662747 | 1.1101759286484367
4 | bin_2 | sample_2 | 0.0004871607502275562 | 0.0
5 | bin_3 | sample_2 | 0.001595914458984989 | 0.0
[...] | [...] |[...] |[...] |[...]

The `unique_id` column is just a unique index for each row. Each column after the `sample` column contains a different statistic (to learn how to include different or additional statistics in this output, read the %(anvi-summarize-blitz)s page.)
This contains the taxonomy annotions for each of the single-copy core genes found in your %(contigs-db)s; in other words, this contains the results of a run of %(anvi-run-scg-taxonomy)s. 

This information was found through the [GTDB](https://gtdb.ecogenomic.org/) database, so it will not work with Eukaryotic genomes. 

This information allows you to quickly estimate the taxonomy of genomes, metagenomes, or bins stored in your contigs-db by using the command %(anvi-estimate-scg-taxonomy)s. 
This basically stores **a local copy of the data from the EBI's [Pfam database](https://pfam.xfam.org/) for function annotation.** 

It is required to run %(anvi-run-pfams)s and is set up on your computer by the program %(anvi-setup-pfams)s. 
An internal genome is any %(bin)s described in an anvi'o %(collection)s stored in an anvi'o %(profile-db)s. You can obtain one of these by binning a metagenome assembly (stored in an anvi'o %(contigs-db)s), which you can do either manually in the interactive interface or automatically with a binning software, and saving or importing it into a %(collection)s.

The internal genomes file format enables anvi'o to work with one or more bins from one or more collections that may be defined in different anvi'o %(profile-db)s files. A TAB-delimited internal genomes file will be composed of at least the following five columns:

|name|bin_id|collection_id|profile_db_path|contigs_db_path|
|:--|:--:|:--:|:--|:--|
|Name_01|Bin_id_01|Collection_A|/path/to/profile.db|/path/to/contigs.db|
|Name_02|Bin_id_02|Collection_A|/path/to/profile.db|/path/to/contigs.db|
|Name_03|Bin_id_03|Collection_B|/path/to/another_profile.db|/path/to/another/contigs.db|
|(...)|(...)|(...)|(...)|(...)|

{:.warning}
Please make sure names in the `name` column does not include any special characters (underscore is fine). It is also a good idea to keep these names short and descriptive as they will appear in various figures in downstream analyses.

Also see **%(external-genomes)s** and **%(metagenomes)s**.
The tRNA-seq workflow **is a [Snakemake](https://snakemake.readthedocs.io/en/stable/) workflow run by the anvi'o script, %(anvi-run-workflow)s**.

The workflow can run the following programs in order.
- [Illumina-utils](https://github.com/merenlab/illumina-utils), for merging paired-end reads and quality control
- %(anvi-script-reformat-fasta)s, for making FASTA deflines anvio-compliant
- %(anvi-trnaseq)s, for predicting tRNA sequences, structures, and modification sites in each sample
- %(anvi-merge-trnaseq)s, for predicting tRNA seed sequences and their modification sites from the set of samples
- %(anvi-run-trna-taxonomy)s, for assigning taxonomy to tRNA seeds
- %(anvi-tabulate-trnaseq)s, for generating tables of seed and modification information that are easily manipulated

## Input

The tRNA-seq workflow requires two files to run: a json-formatted config file and %(samples-txt)s. Generate the default config file, here called `config.json`, with the following command.

{{ codestart }}
anvi-run-workflow -w trnaseq --get-default-config config.json
{{ codestop }}

Different "rules," or steps, of the workflow can be turned on and off as needed in the config file. The workflow can be restarted at intermediate rules without rerunning prior rules that have already completed.

%(samples-txt)s will contain a list of FASTQ or FASTA files and associated information on each library. FASTQ files contain unmerged paired-end tRNA-seq reads. Reads are merged in the workflow by [Illumina-utils](https://github.com/merenlab/illumina-utils). FASTA files contain merged reads, and the initial read-merging steps in the workflow are skipped.

Here is an example tRNA-seq samples file with FASTQ inputs.

| sample | treatment | r1 | r2 | r1_prefix | r2_prefix |
| --- | --- | --- | --- | --- | --- |
| ecoli_A1_noDM | untreated | FASTQ/ecoli_A1_noDM.r1.fq.gz | FASTQ/ecoli_A1_noDM.r2.fq.gz | NNNNNN | TTCCAGT |
| ecoli_A1_DM | demethylase | FASTQ/ecoli_A1_DM.r1.fq.gz | FASTQ/ecoli_A1_DM.r2.fq.gz | NNNNNN | TCTGAGT |
| ecoli_B1_noDM | untreated | FASTQ/ecoli_B1_noDM.r1.fq.gz | FASTQ/ecoli_B1_noDM.r2.fq.gz | NNNNNN | TGGTAGT |
| ecoli_B1_DM | demethylase | FASTQ/ecoli_B1_DM.r1.fq.gz | FASTQ/ecoli_B1_DM.r2.fq.gz | NNNNNN | CTGAAGT |

The treatment column is optional. The treatment indicates a chemical application, such as demethylase, and can be used to have a bearing on seed sequence determination in %(anvi-merge-trnaseq)s. In the absence of a treatment column, all samples are assigned the same treatment, which can be specified in the `anvi_trnaseq` section of the workflow config file and defaults to `untreated`.

Read 1 and 2 prefix columns are also optional. These represent sequences that Illumina-utils should identify and trim from the start of the read. In the example, the read 1 prefix is a unique molecular identifier (UMI) of 6 random nucleotides, and the read 2 prefix is a sample barcode. Illumina-utils will discard the paired-end read if the prefix is not found. In the example, the read 1 UMI will always be found, but the read 2 barcode must match exactly.

Here is an equivalent tRNA-seq samples file with FASTA inputs.

| sample | treatment | fasta |
| --- | --- | --- |
| ecoli_A1_noDM | untreated | FASTA/ecoli_A1_noDM.fa.gz |
| ecoli_A1_DM | demethylase | FASTA/ecoli_A1_DM.fa.gz |
| ecoli_B1_noDM | untreated | FASTA/ecoli_B1_noDM.fa.gz |
| ecoli_B1_DM | demethylase | FASTA/ecoli_B1_DM.fa.gz |

Note that barcodes and other sequence prefixes should already be trimmed from FASTA sequences.
This describes an INI formatted file used to configure a program. 

If you're unsure what the INI format is, you can check out its [Wikipedia page](https://en.wikipedia.org/wiki/INI_file). But it is essentially a text file with sections that defines the values of several keys.

As of now, it is only required in Anvi'o by the program %(anvi-script-gen-short-reads)s, where the file describes various parameters for the short reads that you want to generate, such as the desired length and coverage. Take a look at the page for that program for an example. 
This artifact stores the data downloaded by %(anvi-setup-interacdome)s and is required to run %(anvi-run-interacdome)s.

As described in the [InteracDome blogpost](https://merenlab.org/2020/07/22/interacdome/#anvi-setup-interacdome), this data includes [the tab-separated files](https://interacdome.princeton.edu/#tab-6136-4) from [InteracDome](https://interacdome.princeton.edu/) and the Pfam 31.0 HMMs for the subset of Pfams found in the InteracDome dataset.

By default, this data is stored in `anvio/data/misc/InteracDome`, but a custom path can be set when the user runs %(anvi-setup-interacdome)s if desired.

This is the section of your %(profile-db)s/%(pan-db)s that contains custom additional information about the order that your layers are displayed in and the tree that relates them to each other . When you run %(anvi-interactive)s, this data will determine what order the concentric circles are displayed in, as well as the tree that appears above the %(misc-data-layers)s graphs.

As also defined in [this blog post](http://merenlab.org/2017/12/11/additional-data-tables/#views-items-layers-orders-some-anvio-terminology), this type of data will include information about how your layers are related to each other and determines their order. This data is stored as a tree that is displayed in the top-right. 

This data can be imported from a %(misc-data-layer-orders-txt)s artifact with %(anvi-import-misc-data)s.  It is also displayed when you run %(anvi-show-misc-data)s and can be exported or deleted with %(anvi-export-misc-data)s and %(anvi-delete-misc-data)s respectively. 

For example, you could use this tree to indicate and group together samples that came from the same geographic location, samples that came from the same donor, samples of the same type,  samples collected with the same collection method, and so on. 

This is also used to import the taxonomy information at the end of [the pangenomics and phylogenomics workflow](http://merenlab.org/2017/06/07/phylogenomics/#pangenomic--phylogenomics). 
A tRNA-seq profile database is a **%(profile-db)s variant containing tRNA seed coverage information from one or more samples**.

This database is created by the program, %(anvi-merge-trnaseq)s, which is part of the %(trnaseq-workflow)s. This program also creates a %(trnaseq-contigs-db)s.

## Specific and nonspecific coverage

The coverage of tRNA seeds by tRNA-seq reads is determined differently than the coverage of contigs by metagenomic reads. Metagenomic contigs are constructed by an assembly tool and reads are assigned to contigs by a mapping tool. Reads that map to multiple contigs are randomly assigned to one contig. tRNA-seq seeds and coverages are found simultaneously by %(anvi-trnaseq)s and %(anvi-merge-trnaseq)s. Two types of coverage are tracked: **specific** coverage of reads unique to seeds and **nonspecific** coverage of reads in multiple seeds. tRNA-seq reads are often short fragments found in numerous tRNAs; random assignment of these reads would distort tRNA abundances and coverage patterns.

Separate tRNA-seq profile databases are produced for specific and nonspecific coverages. A "combined" database containing both sets of data is produced by default for convenience, allowing specific and nonspecific coverages to be compared side-by-side in the %(anvi-interactive)s interface. A "summed" database of specific + nonspecific coverage can optionally be produced. The `--nonspecific-output` option of %(anvi-merge-trnaseq)s controls the production of nonspecific, combined, and summed databases.

## Modifications versus SNVs

The other significant difference between a tRNA-seq profile database and a normal %(profile-db)s is that variable nucleotides are restricted to tRNA modification positions predicted from mutation signatures. Single nucleotide variants are purposefully excluded, though they can be mistaken for modifications, especially with permissive parameterization of %(anvi-merge-trnaseq)s (see that artifact for more information).

## Uses

Tabulation of tRNA-seq data by %(anvi-tabulate-trnaseq)s takes a specific and optionally nonspecific profile database in addition to a %(trnaseq-contigs-db)s.

Interactive visualization of tRNA-seq data in %(anvi-interactive)s requires a specific, nonspecific, combined, or summed profile database in addition to a %(trnaseq-contigs-db)s.
A **TAB-delimited** file to describe samples and paired-end FASTQ files associated with them. By doing so, this file type links sample names to raw sequencing reads.

This file type includes required and optional columns.

The following three columns are **required** for this file type:

* `sample`: a single-word sample name,
* `r1`: path to the FASTQ file for pair one, and
* `r2`: path to the FASTQ file for pair two.

While you can use relative paths for `r1` and `r2`, it is always better to have absolute paths to improve reproducibility.

The following is an **optional** column:

* `group`: A single-word categorical variable that assigns two or more samples into two or more groups. This is useful to co-assemble multiple samples so that you can bin them later. 

For more information, see the [anvi'o workflow tutorial](https://merenlab.org/2018/07/09/anvio-snakemake-workflows/#samplestxt)

### Examples samples.txt file

Here is an example file:

|sample|group|r1|r2|
|:--|:--|:--|:--|
|Sample_01|WARM|/path/to/XXX-01-R1.fastq.gz|/path/to/XXX-01-R2.fastq.gz|
|Sample_02|COLD|/path/to/YYY-02-R1.fastq.gz|/path/to/YYY-02-R2.fastq.gz|
|Sample_03|COLD|/path/to/ZZZ-03-R1.fastq.gz|/path/to/ZZZ-03-R2.fastq.gz|
This a tab-delimited text file that describes information contained in a %(misc-data-items)s. 

To import this information into a database, use %(anvi-import-misc-data)s. 

In this table, the first column should match the names of the items that you're displaying, and the following columns can contain any categorical or numerical data of your choosing.  (You can even be fancy and display data as a stacked bar graph.)

For an example, check out [the table on this page](http://merenlab.org/2017/12/11/additional-data-tables/#items-additional-data-table).
A BAM file contains **already aligned sequence data.** However, it is written in binary to save space (so it will look like jibberish if you open it). 

BAM files (and their text file cousin SAM files) are often used in 'omics analysis and are described in more detail in [this file](https://samtools.github.io/hts-specs/SAMv1.pdf), written by the developers of samtools. 

If your BAM file is not indexed, it is actually a %(raw-bam-file)s and you can run %(anvi-init-bam)s to turn it into a BAM file. You can tell if your BAM file is indexed if in the same folder as your `XXXX.bam` file, there is another file with the same name called `XXXX.bam.bai`.

As of now, no anvi'o programs will output results in BAM format, so you'll primary use BAM files to import sequence data into anvi'o. For example, in %(anvi-profile)s (which generates a %(profile-db)s), your BAM file is expected to contain the aligned short reads from your samples. 

In its simplest form, **a group of items** that are put together. Think of a literal bin in which you put data. One or more bins in anvi'o form a %(collection)s.

In anvi'o, a bin may reprsent one or more contigs, or gene clusters, or any item that can be shown in the interactive interface and stored in a %(profile-db)s, %(pan-db)s, or %(genes-db)s.

Bin names become handy to specifically target a group of items to investigate via programs such as %(anvi-refine)s or %(anvi-split)s, specify a group of contigs in files such as %(internal-genomes)s, or find them in output files anvi'o generates via programs such as %(anvi-summarize)s or %(anvi-estimate-genome-completeness)s.

Since they are a part of the umbrella concept %(collection)s, information about bins are stored in various anvi'o databases, each of which can be used with the program %(anvi-show-collections-and-bins)s to see the bin content.
This is an Anvi'o database that **stores information about your genomes, primarily for use in pangenomic analyses.**

You can think of it like this: in a way, a genomes-storage-db is to the [the pangenomic workflow](http://merenlab.org/2016/11/08/pangenomics-v2/#generating-an-anvio-genomes-storage) what a %(contigs-db)s is to the [the metagenomic workflow](http://merenlab.org/2016/06/22/anvio-tutorial-v2/). They both describe key information unique to your particular dataset and are required to run the vast majority of programs. 

### What kind of information? 

A genomes storage database contains information about the genomes that you inputted to create it, as well as the genes within them. 

Specifically, there are three tables stored in a genomes storage database: 

* A table describing the information about each of your genomes, such as their name, type (internal or external), GC content, number of contigs, completition, redunduncy, number of genes, etc. 
* A table describing the genes within your genomes. For each gene, this includes its gene caller id, associated genome and position, sequence, length, and whether or not it is partial. 
* A table describing the functions of your genes, including their sources and e-values. 

### Cool. How do I make one? 

You can generate one of these from an %(internal-genomes)s (genomes described in %(bin)ss), %(external-genomes)s (genomes described in %(contigs-db)ss), or both using the program %(anvi-gen-genomes-storage)s. 

### Cool cool. What can I do with one? 

With one of these, you can run %(anvi-pan-genome)s to get a %(pan-db)s. If a genomes storage database is the %(contigs-db)s of pangenomics, then a %(pan-db)s is the %(profile-db)s. It contains lots of information that is vital for analysis, and most programs will require both the %(pan-db)s and its genomes storage database as an input. 
Similarly to a %(genes-fasta)s, a short reads fasta is what it sounds like: a %(fasta)s file containing short reads.

Short reads usually refer to the initial pieces of sequencing data that you had before you assembled them into longer contigs. In other words, these are the kinds of reads you could get out of a technique like Sanger sequencing. Knowing how those short reads align to your contigs is vital for analysis (In fact, that's a lot of the functionality of a %(profile-db)s!).

In anvi'o, you can currently get short reads from four sources:

* from a %(bam-file)s by running the program %(anvi-get-short-reads-from-bam)s
* from a gene in a %(contigs-db)s by running the program %(anvi-get-short-reads-mapping-to-a-gene)s
* from something (like a contig) within a %(fasta)s file by running the program %(anvi-script-get-primer-matches)s
* by generating mock short read data from assembled contigs (as done in the program %(anvi-script-gen-short-reads)s).
A contigs database is an anvi'o database that **contains key information associated with your sequences**.

In a way, **an anvi'o contigs database is a modern, more talented form of a FASTA file**, where you can store additional information about your sequences in it and others can query and use it. Information storage and access is primarily done by anvi'o programs, however, it can also be done through the command line interface or programmatically.

The information a contigs database contains about its sequences can include the positions of open reading frames, tetra-nucleotide frequencies, functional and taxonomic annotations, information on individual nucleotide or amino acid positions, and more.

### Another (less computation-heavy) way of thinking about it

When working in anvi'o, you'll need to be able to access previous analysis done on a genome or transcriptome. To do this, anvi'o uses tools like contigs databases instead of regular fasta files. So, you'll want to convert the data that you have into a contigs database to use other anvi'o programs (using %(anvi-gen-contigs-database)s). As seen on the page for %(metagenomes)s, you can then use this contigs database instead of your fasta file for all of your anvi'o needs.

In short, to get the most out of your data in anvi'o, you'll want to use your data (which was probably originally in a %(fasta)s file) to create both a %(contigs-db)s and a %(profile-db)s. That way, anvi'o is able to keep track of many different kinds of analysis and you can easily interact with other anvi'o programs.

## Usage Information

### Creating and populating a contigs database

Contigs databases will be initialized using **%(anvi-gen-contigs-database)s** using a %(contigs-fasta)s. This will compute the k-mer frequencies for each contig, soft-split your contigs, and identify open reading frames. To populate a contigs database with more information, you can then run various other programs.

**Key programs that populate an anvi'o contigs database with essential information** include,

* %(anvi-run-hmms)s (which uses HMMs to annotate your genes against an %(hmm-source)s)
* %(anvi-run-scg-taxonomy)s (which associates its single-copy core gene with taxonomic data)
* %(anvi-scan-trnas)s (which identifies the tRNA genes)
* %(anvi-run-ncbi-cogs)s (which tries to assign functions to your genes using the COGs database)

Once an anvi'o contigs database is generated and populated with information, it is **always a good idea to run %(anvi-display-contigs-stats)s** to see a numerical summary of its contents.

Other programs you can run to populate a contigs database with functions include,

* %(anvi-run-kegg-kofams)s (which annotates the genes in the database with the KEGG KOfam database)

### Analysis on a populated contigs database

Other essential programs that read from a contigs database and yield key information include %(anvi-estimate-genome-completeness)s, %(anvi-get-sequences-for-hmm-hits)s, and %(anvi-estimate-scg-taxonomy)s.

If you wish to run programs like %(anvi-cluster-contigs)s, %(anvi-estimate-metabolism)s, and %(anvi-gen-gene-level-stats-databases)s, or view your database with %(anvi-interactive)s, you'll need to first use your contigs database to create a %(profile-db)s.

## Variants

Contigs databases, like %(profile-db)ss, are allowed have different variants, though the only currently implemented variant, the %(trnaseq-contigs-db)s, is for tRNA transcripts from tRNA-seq experiments. The default variant stored for "standard" contigs databases is `unknown`. Variants should indicate that substantially different information is stored in the database. For instance, open reading frames are applicable to protein-coding genes but not tRNA transcripts, so ORF data is not recorded for the `trnaseq` variant. The $(trnaseq-workflow)s generates %(trnaseq-contigs-db)ss using a very different approach to %(anvi-gen-contigs-database)s.

## For programmers

Tips and use cases for programmers. Send us your questions so we can extend this section with useful examples.

### Get number of approximate number of genomes

You can get the number of genomes once %(anvi-run-hmms)s is run on an contigs database. Here are some examples:

``` python
from anvio.hmmops import NumGenomesEstimator

# the raw data, where each key is one of the HMM collections
# of type `singlecopy` run on the contigs-db
NumGenomesEstimator('CONTIGS.db').estimates_dict
>>> {'Bacteria_71': {'num_genomes': 9, 'domain': 'bacteria'},
     'Archaea_76': {'num_genomes': 1, 'domain': 'archaea'},
     'Protista_83': {'num_genomes': 1, 'domain': 'eukarya'}}

# slightly fancier output with a single integer for
# estimated number of genomes summarized, along with
# domains used
num_genomes, domains_included = NumGenomesEstimator('CONTIGS.db').num_genomes()
print(num_genomes)
>>> 11

print(domains_included)
>>> ['bacteria', 'archaea', 'eukarya']

# limiting the domains
num_genomes, domains_included = NumGenomesEstimator('CONTIGS.db').num_genomes(for_domains=['archaea', 'eukarya'])
print(num_genomes)
>>> 2

print(domains_included)
>>> ['archaea', 'eukarya']
```
This is a **%(bam-file)s (which contains aligned sequence data) that has not yet been indexed and sorted**. 

### What does being "indexed" mean? 

Think of your BAM file as a long, complex book. In order to get the most out of it when trying to perform analysis, it will be super helpful to have a table of contents. Indexing your BAM file basically creates a second file that serves as an external table of contents, so that anvi'o doesn't have to keep looking through the entire BAM file during analysis. 

You can tell whether or not your BAM file is indexed based on the presence of this second file, which will have the same title as your BAM file, but end with the extension `.bai`. For example, if your directory contained these files:

{{ codestart }}
Lake_Michigan_Sample_1.bam
Lake_Michigan_Sample_1.bam.bai
Lake_Michigan_Sample_2.bam 
{{ codestop }}

then you would still need to index `Lake_Michigan_Sample_2.bam`. 

### How do you index a BAM file?

You can either do this directly using samtools, or you can just run the anvi'o program %(anvi-init-bam)s (which uses samtools for you). 
A metapangenome is a way of comparing a bunch of genomes based both on the gene clusters they contain (like in a pangenome) and their abundances in different environments/samples (using metagenomic read recruitment).

Here is a [wonderful workflow](http://merenlab.org/data/prochlorococcus-metapangenome/) that takes you through the analysis of 31 *Prochlorococcus* isolate genomes and 93 TARA Oceans metagenomes, based on [this paper](https://peerj.com/articles/4320/). 
A **TAB-delimited** file to describe primer sequences. A primer sequence can be exact (such as `ATCG`), or fuzzy (such as `AT.G`, which would match any combination of `ATAG`, `ATTG`, `ATCG`, or `ATGG`). Fuzzy primers are defined by regular expressions, properties of which are explained best in [the Python documentation](https://docs.python.org/3/library/re.html), or cheatsheets like [this one](https://www.debuggex.com/cheatsheet/regex/python).

This file type includes two required and any number of user-defined optional columns.

The following three columns are **required** for this file type:

* `name`: a single-word name for a given primer,
* `primer_sequence`: the primer sequence.

### An example primers-txt file

Here is an example file with three primers:

|name|primer_sequence|
|:--|:--|
|PR01|AA.A..G..G..G.CCG.C.A.C|
|PR02|AACACCGCAGTCCATGAGA|
|PR03|A[TC]A[CG]T[ATC]TCGAGC|
Output text files produced by %(anvi-estimate-metabolism)s that describe the presence of metabolic pathways in a %(contigs-db)s.

Depending on the output options used when running %(anvi-estimate-metabolism)s, these files will have different formats. This page describes and provides examples of the various output file types.

Please note that the examples below show only KEGG data, but user-defined metabolic pathways (%(user-metabolism)s) can also be included in this output!

### How to get to this output
![A beautiful workflow of metabolism reconstruction in anvi'o](../../images/metabolism_reconstruction.png)

## Long-format output modes

The long-format output option produces tab-delimited files. Different output "modes" will result in output files with different information.

### 'Modules' Mode

The 'modules' mode output file will have the suffix `modules.txt`. Each line in the file will represent information about a metabolic module in a given genome, bin, or contig of a metagenome assembly. Here is one example, produced by running metabolism estimation on the _Enterococcus_ external genomes in the [Infant Gut dataset](http://merenlab.org/tutorials/infant-gut/):

module | genome_name | db_name | module_name | module_class | module_category | module_subcategory | module_definition | module_completeness | module_is_complete | proportion_unique_enzymes_present | enzymes_unique_to_module | unique_enzymes_hit_counts | enzyme_hits_in_module | gene_caller_ids_in_module | warnings
|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|
M00001 | Enterococcus_faecalis_6240 | E_faecalis_6240 | Glycolysis (Embden-Meyerhof pathway), glucose => pyruvate | Pathway modules | Carbohydrate metabolism | Central carbohydrate metabolism | "(K00844,K12407,K00845,K25026,K00886,K08074,K00918) (K01810,K06859,K13810,K15916) (K00850,K16370,K21071,K00918) (K01623,K01624,K11645,K16305,K16306) K01803 ((K00134,K00150) K00927,K11389) (K01834,K15633,K15634,K15635) K01689 (K00873,K12406)" | 1.0 | True | NA | No enzymes unique to module | NA | K00134,K00134,K00850,K00873,K00927,K01624,K01689,K01803,K01803,K01810,K01834,K01834,K25026 | 1044,642,225,226,1043,348,1041,1042,1043,600,2342,2646,1608 | K01624 is present in multiple modules: M00001/M00003/M00165/M00167/M00345/M00344/M00611/M00612,K01810 is present in multiple modules: M00001/M00004/M00892/M00909,K00927 is present in multiple modules: M00001/M00002/M00003/M00308/M00552/M00165/M00166/M00611/M00612,K00873 is present in multiple modules: M00001/M00002,K25026 is present in multiple modules: M00001/M00549/M00909,K01689 is present in multiple modules: M00001/M00002/M00003/M00346,K01834 is present in multiple modules: M00001/M00002/M00003,K01803 is present in multiple modules: M00001/M00002/M00003,K00134 is present in multiple modules: M00001/M00002/M00003/M00308/M00552/M00165/M00166/M00611/M00612,K00850 is present in multiple modules: M00001/M00345
M00002 | Enterococcus_faecalis_6240 | E_faecalis_6240 | Glycolysis, core module involving three-carbon compounds | Pathway modules | Carbohydrate metabolism | Central carbohydrate metabolism | "K01803 ((K00134,K00150) K00927,K11389) (K01834,K15633,K15634,K15635) K01689 (K00873,K12406)" | 1.0 | True | NA | No enzymes unique to module | NA | K00134,K00134,K00873,K00927,K01689,K01803,K01803,K01834,K018341044,642,226,1043,1041,1042,1043,2342,2646 | K00927 is present in multiple modules: M00001/M00002/M00003/M00308/M00552/M00165/M00166/M00611/M00612,K00873 is present in multiple modules: M00001/M00002,K01689 is present in multiple modules: M00001/M00002/M00003/M00346,K01834 is present in multiple modules: M00001/M00002/M00003,K01803 is present in multiple modules: M00001/M00002/M00003,K00134 is present in multiple modules: M00001/M00002/M00003/M00308/M00552/M00165/M00166/M00611/M00612
M00003 | Enterococcus_faecalis_6240 | E_faecalis_6240 | Gluconeogenesis, oxaloacetate => fructose-6P | Pathway modules | Carbohydrate metabolism | Central carbohydrate metabolism | "(K01596,K01610) K01689 (K01834,K15633,K15634,K15635) K00927 (K00134,K00150) K01803 ((K01623,K01624,K11645) (K03841,K02446,K11532,K01086,K04041),K01622)" | 0.875 | True | NA | No enzymes unique to module | NA | K00134,K00134,K00927,K01624,K01689,K01803,K01803,K01834,K01834,K04041 | 1044,642,1043,348,1041,1042,1043,2342,2646,617 | K01624 is present in multiple modules: M00001/M00003/M00165/M00167/M00345/M00344/M00611/M00612,K00927 is present in multiple modules: M00001/M00002/M00003/M00308/M00552/M00165/M00166/M00611/M00612,K04041 is present in multiple modules: M00003/M00611/M00612,K01689 is present in multiple modules: M00001/M00002/M00003/M00346,K01834 is present in multiple modules: M00001/M00002/M00003,K01803 is present in multiple modules: M00001/M00002/M00003,K00134 is present in multiple modules: M00001/M00002/M00003/M00308/M00552/M00165/M00166/M00611/M00612
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|

What are the data in each of these columns?

- `module`: the module identifier for a metabolic pathway (from the KEGG MODULE database or from user-defined modules)
- `genome_name`/`bin_name`/`contig_name`: the identifier for the current sample, whether that is a genome, bin, or contig from a metagenome assembly
- `db_name`: the name of the contigs database from which this data comes (only appears in output from multi-mode, in which multiple DBs are processed at once)
- `module_name`/`module_class`/`module_category`/`module_subcategory`/`module_definition`: metabolic pathway information, from the KEGG MODULE database or from user-defined metabolic modules
- `module_completeness`: a fraction between 0 and 1 indicating the proportion of steps in the metabolic pathway that have an associated enzyme annotation. To learn how this number is calculated, see [the anvi-estimate-metabolism help page](https://merenlab.org/software/anvio/help/main/programs/anvi-estimate-metabolism/#how-is-the-module-completeness-score-calculated)
- `module_is_complete`: a boolean value indicating whether the `module_completeness` score is above a certain threshold or not (the default threshold is 0.75)
- `proportion_unique_enzymes_present`: some enzymes only belong to one metabolic pathway, which means that their presence is a better indicator for the presence of a metabolic capacity than other enzymes that are shared across multiple pathways. This column contains the fraction of these unique enzymes that are present in the sample. For instance, if the module has only 1 unique enzyme and it is present, you will see a 1 in this column. You can find out the denominator of this fraction (ie, the number of unique enzymes for this module) by either calculating the length of the list in the `enzymes_unique_to_module` column, or by requesting custom modules mode output with the `unique_enzymes_context_string` header
- `enzymes_unique_to_module`: a comma-separated list of the enzymes that only belong to the current module (ie, are not shared across multiple metabolic pathways)
- `unique_enzymes_hit_counts`: a comma-separated list of how many times each unique enzyme appears in the sample, in the same order as the `enzymes_unique_to_module` list
- `enzyme_hits_in_module`: a comma-separated list of the enzyme annotations that were found in the current sample and contribute to this metabolic pathway (these will be enzymes from the metabolic pathway definition in the `module_definition` column)
- `gene_caller_ids_in_module`: a comma-separated list of the genes with enzyme annotations that contribute to this pathway, in the same order as the annotations in the `enzyme_hits_in_module` column
- `warnings`: miscellaneous caveats to consider when interpreting the `module_completeness` score. For example, a warning like "No KOfam profile for K00172" would indicate that we cannot annotate K00172 because we have no HMM profile for that gene family, which means that any metabolic pathway containing this KO can never be fully complete (even if a gene from that family does exist in your sequences). Seeing many warnings like "K01810 is present in multiple modules: M00001/M00004/M00892/M00909" indicates that the current module shares many enzymes with other metabolic pathways, meaning that it may appear to be complete only because its component enzymes are common. Extra caution should be taken when considering the completeness of modules with warnings

**Coverage and detection values in the output**

If you use the flag `--add-coverage` and provide a profile database, additional columns containing coverage and detection data will be added for each sample in the profile database. Here is a mock example of the additional columns you will see (for a generic sample called 'SAMPLE_1'):

| SAMPLE_1_gene_coverages | SAMPLE_1_avg_coverage | SAMPLE_1_gene_detection | SAMPLE_1_avg_detection |
|:--|:--|:--|:--|
| 3.0,5.0,10.0,2.0 | 5.0 | 1.0,1.0,1.0,1.0 | 1.0 |

In this mock example, the module in this row has four gene calls in it. The `SAMPLE_1_gene_coverages` column lists the mean coverage of each of those genes in SAMPLE_1 (in the same order as the gene calls are listed in the `gene_caller_ids_in_module` column), and the `SAMPLE_1_avg_coverage` column holds the average of these values. As you probably expected, the `detection` columns are similarly defined, except that they contain detection values instead of coverage.

### 'Hits in Modules' Mode

The 'hits_in_modules' output file will have the suffix `hits_in_modules.txt`. Each line in the file will represent information about one enzyme annotation (ie, one gene) in a given genome, metagenome, or bin - but _only_ enzymes that are a part of at least one module are included in this output. Hits are organized according to the module that they belong to, and more specifically the path through the module in which the enzyme appears.

What is a path through a module, you ask? Well. There is a lengthier explanation of this [here](https://merenlab.org/software/anvio/help/main/programs/anvi-estimate-metabolism/#what-data-is-used-for-estimation), but we will go through it briefly below.

KEGG modules are metabolic pathways defined by a set of KOs. For example, here is the definition of module [M00001](https://www.genome.jp/kegg-bin/show_module?M00001), better known as "Glycolysis (Embden-Meyerhof pathway), glucose => pyruvate":

(K00844,K12407,K00845,K00886,K08074,K00918) (K01810,K06859,K13810,K15916) (K00850,K16370,K21071,K00918) (K01623,K01624,K11645,K16305,K16306) K01803 ((K00134,K00150) K00927,K11389) (K01834,K15633,K15634,K15635) K01689 (K00873,K12406)

Spaces separate steps (reactions) in the metabolic pathway, and commas separate alternative KOs or alternative sub-pathways that can facilitate the same overall reaction. So a definition such as the one above can be "unrolled" into several different linear sequences of KOs, each of which we consider to be a possible "path" through the module. As an example, we can take the first option for every step in the Embden-Meyerhof pathway definition from above:

(**K00844**,K12407,K00845,K00886,K08074,K00918) (**K01810**,K06859,K13810,K15916) (**K00850**,K16370,K21071,K00918) (**K01623**,K01624,K11645,K16305,K16306) **K01803** ((**K00134**,K00150) **K00927**,K11389) (**K01834**,K15633,K15634,K15635) **K01689** (**K00873**,K12406)

to get the following path of KOs (which happens to be the path shown in the output example below):

K00844 K01810 K00850 K01623 K01803 K00134 K00927 K01834 K01689 K00873

For every KO in the path above that has a hit in the %(contigs-db)s, there will be a corresponding line in the 'hits_in_modules' output file. The same will occur for every possible path in every single KEGG module, resulting in a lot of lines and extremely repetitive but nicely parseable information.

The same principle applies to user-defined metabolic modules, except that the enzymes can be from a variety of different annotation sources (not just KOfam).

Without further ado, here is an example of this output mode (also from the Infant Gut dataset):

module | genome_name | db_name | module_is_complete | module_completeness | path_id | path | path_completeness | enzyme_hit | gene_caller_id | contig
|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|
M00001 | Enterococcus_faecalis_6240 | E_faecalis_6240 | True | 1.0 | 0 | K00844,K01810,K00850,K01623,K01803,K00134,K00927,K01834,K01689,K00873 | 0.8 | K00134 | 1044 | Enterococcus_faecalis_6240_contig_00003_chromosome
M00001 | Enterococcus_faecalis_6240 | E_faecalis_6240 | True | 1.0 | 0 | K00844,K01810,K00850,K01623,K01803,K00134,K00927,K01834,K01689,K00873 | 0.8 | K25026 | 642 | Enterococcus_faecalis_6240_contig_00003_chromosome
M00001 | Enterococcus_faecalis_6240 | E_faecalis_6240 | True | 1.0 | 0 | K00844,K01810,K00850,K01623,K01803,K00134,K00927,K01834,K01689,K00873 | 0.8 | K01689 | 1041 | Enterococcus_faecalis_6240_contig_00003_chromosome
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|

Many of the columns in this data overlap with the 'modules' mode columns; you can find descriptions of those in the previous section. Below are the descriptions of new columns in this mode:

- `enzyme_hit`: an enzyme annotation from the contigs database that contributes to a module
- `gene_caller_id`: the ID of the gene that is annotated with this enzyme
- `contig`: the contig on which this gene is present
- `path_id`: a unique identifier of the current path through the module
- `path`: the current path of enzymes through the module (described above), which this enzyme annotation contributes to
- `path_completeness`: a fraction between 0 and 1 indicating the proportion of enzymes in the _current path_ that are annotated. To learn how this number is calculated, see [the anvi-estimate-metabolism help page](https://merenlab.org/software/anvio/help/main/programs/anvi-estimate-metabolism/#how-is-the-module-completeness-score-calculated)

**Coverage and detection values in the output**

The flag `--add-coverage` can also be used for this output mode, but in this case, the columns that are added (for each sample in the profile database) are slightly different. Here is a mock example:

| SAMPLE_1_coverage | SAMPLE_1_detection |
|:--|:--|
| 3.0 | 1.0 |

Since each row is a single gene in this output mode, these columns will contain the coverage/detection values for that gene only.

### Enzyme 'Hits' Mode

The 'hits' output file will have the suffix `hits.txt`. Unlike the previous mode, this output will include ALL enzyme hits (from all annotation sources used for metabolism estimation), regardless of whether the enzyme belongs to a metabolic module or not. Since only a subset of these enzymes belong to modules, this output does not include module-related information like paths and module completeness.

Here is an example of this output mode (also from the Infant Gut dataset):

enzyme | genome_name | db_name | gene_caller_id | contig | modules_with_enzyme | enzyme_definition
|:--|:--|:--|:--|:--|:--|:--|
K25026 | Enterococcus_faecalis_6240 | E_faecalis_6240 | 1608 | Enterococcus_faecalis_6240_contig_00003_chromosome | M00001,M00549,M00909 | glucokinase [EC:2.7.1.2]
K01810 | Enterococcus_faecalis_6240 | E_faecalis_6240 | 600 | Enterococcus_faecalis_6240_contig_00003_chromosome | M00001,M00004,M00892,M00909 | glucose-6-phosphate isomerase [EC:5.3.1.9]
K00850 | Enterococcus_faecalis_6240 | E_faecalis_6240 | 225 | Enterococcus_faecalis_6240_contig_00003_chromosome | M00001,M00345 | 6-phosphofructokinase 1 [EC:2.7.1.11]
(...) |(...)|(...)|(...)|(...)|(...)|(...)|

Here are the descriptions of any new columns not yet discussed in the previous sections:

- `enzyme`: an enzyme that was annotated in the contigs database
- `modules_with_enzyme`: the modules (if any) that this enzyme belongs to
- `enzyme_definition`: the function of this enzyme (often includes the enzyme name and EC number)

**Coverage and detection values in the output**

If you use the flag `--add-coverage` and provide a profile database, you will get the same additional columns per row as described above in for `hits_in_modules` mode. That is, you will get one column per sample for coverage (containing the coverage value of the KO hit in the sample) and one column per sample for detection (containing the detection value of the KO hit in the sample).

### Custom Mode (for module data)

The 'modules_custom' output mode will have user-defined content and the suffix `modules_custom.txt` (we currently only support output customization for modules data). See %(anvi-estimate-metabolism)s for an example command to work with this mode. The output file will look similar to the 'modules' mode output, but with a different (sub)set of columns.

## Matrix format output

Matrix format is an output option when %(anvi-estimate-metabolism)s is working with multiple contigs databases at once. The purpose of this output type is to generate matrices of module statistics for easy visualization and clustering. Currently, the matrix-formatted output includes a module completeness matrix, a matrix of binary module presence/absence values, and a matrix of enzyme annotation counts. In these matrices, each row is a module or enzyme, and each column is an input sample.

Here is an example of a module completeness matrix, for bins in a metagenome:

| module | bin_1 | bin_2 | bin_3 | bin_4 | bin_5 | bin_6 |
|:--|:--|:--|:--|:--|:--|:--|
| M00001 | 1.00 | 0.00 | 1.00 | 1.00 | 1.00 | 0.00 |
| M00002 | 1.00 | 0.00 | 1.00 | 1.00 | 1.00 | 1.00 |
| M00003 | 0.88 | 0.00 | 1.00 | 0.75 | 1.00 | 0.88 |
| M00004 | 0.88 | 0.00 | 0.88 | 0.88 | 0.88 | 0.00 |
| M00005 | 1.00 | 0.00 | 1.00 | 1.00 | 1.00 | 1.00 |
|(...) | (...) | (...) | (...) | (...) | (...) | (...) |

Each cell of the matrix is the completeness score for the corresponding module in the corresponding sample (which is, in this case, a bin).

While the above is the default matrix format, some users may want to include more annotation information in the matrices so that it is easier to know what is going on when looking at the matrix data manually. You can add this metadata to the matrices by using the `--include-metadata` flag when running %(anvi-estimate-metabolism)s, and the output will look something like the following:

| module | module_name | module_class | module_category | module_subcategory | bin_1 | bin_2 | bin_3 | bin_4 | bin_5 | bin_6 |
|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|
| M00001 |Glycolysis (Embden-Meyerhof pathway), glucose => pyruvate | Pathway modules | Carbohydrate metabolism | Central carbohydrate metabolism | 1.00 | 0.00 | 1.00 | 1.00 | 1.00 | 0.00 |
| M00002 | Glycolysis, core module involving three-carbon compounds | Pathway modules | Carbohydrate metabolism | Central carbohydrate metabolism | 1.00 | 0.00 | 1.00 | 1.00 | 1.00 | 1.00 |
| M00003 | Gluconeogenesis, oxaloacetate => fructose-6P | Pathway modules | Carbohydrate metabolism | Central carbohydrate metabolism | 0.88 | 0.00 | 1.00 | 0.75 | 1.00 | 0.88 |
|(...) | (...) | (...) | (...) | (...) | (...) | (...) |

The module completeness matrix files will have the suffix `completeness-MATRIX.txt`.

Module presence/absence matrix files will have the suffix `presence-MATRIX.txt`. In these files, each cell of the matrix will have either a 1.0 or a 0.0. A 1.0 indicates that the module has a completeness score above the module completeness threshold in that sample, while a 0.0 indicates that the module's completeness score is not above the threshold.

Finally, KO hit matrix files will have the suffix `enzyme_hits-MATRIX.txt`. Each row of the matrix will be an enzyme, and each column will be an input sample. Cells in this matrix will contain an integer value, representing the number of times the enzyme was annotated in that sample. (Note: you will also add metadata to this matrix type when you use the `--include-metadata` flag).
This is the section of your %(profile-db)s/%(pan-db)s that contains custom additional information about each of the layers of the interactive interface (usually displayed as the concentric circles). When you run %(anvi-interactive)s, this data will appear as additional graphs in line with your layers, similar to how the sample names are displayed at the top. 

As also defined in [this blog post](http://merenlab.org/2017/12/11/additional-data-tables/#views-items-layers-orders-some-anvio-terminology), this type of data will include information about each layer of the interface (usually representing your samples). This data is either numerical or categorical and can be imported into another database from a %(misc-data-layers-txt)s using %(anvi-import-misc-data)s. It is also displayed when you run %(anvi-show-misc-data)s and can be exported or deleted with %(anvi-export-misc-data)s and %(anvi-delete-misc-data)s respectively. 

If you would like to change the order that your layers are displayed, take a look at %(misc-data-layer-orders)s. Or, if you want to specifically import taxnomic information for your layers (if applicable), check out %(anvi-import-taxonomy-for-layers)s.

For example, this information could describe the salinity of a series of ocean samples, the continent your samples were taken in, or which of several collection methods was used. 
This is a file containing **the taxonomy information for the genes in your %(contigs-db)s**. 

You can use %(anvi-import-taxonomy-for-genes)s to integrate this information into your contigs database. See [this blog post](http://merenlab.org/2016/06/18/importing-taxonomy/) for a comprehensive tutorial. 

In its simplest form, this file is a tab-delimited text file that lists gene caller IDs and their associated taxonomy information. However, anvi'o can also parse outputs from taxonomy-based software like [Kaiju](https://github.com/bioinformatics-centre/kaiju) or [Centrifuge](https://github.com/infphilo/centrifuge). 

For example:

    gene_caller_id  t_domain     t_phylum       t_class      ...
          1         Eukarya      Chordata       Mammalia
          2         Prokarya     Bacteroidetes  Bacteroidia
          ...


An %(ngrams)s object is a DataFrame that contains count data of synteny patterns collected from a group of similar loci or genomes. It is produced by running %(anvi-analyze-synteny)s when given a %(genomes-storage-db)s and an annotation source.

An `ngram` is a group of neighboring genes that include precisely `n` genes, inspired by the term ngram in [linguistics and natural language processing](https://en.wikipedia.org/wiki/N-gram). This object was inspired by kmer count tables but is inherently different because it is counting adjacent genes and not nucleotides.
This is a text file containing **the detection value for each gene in each sample** that was in the %(profile-db)s and %(contigs-db)s that you used when you ran  %(anvi-export-gene-coverage-and-detection)s. 

This is a tab-delimited file where each row describes a specific gene and each column describes one of your samples. Each cell contains the detection of that gene in that sample. 

### Example

    key       sample_1    sample_2    sample_3 ...
    13947     0.291093    0.984394    0.9289432         
    13948     0.895842    0.828481    0.3721947
    23026     0.949383    0.983923    1.0000000
    ...




This is a 2-column TAB-delimited text file to associate a given set of items with a set of groups. Depending on the context, items here may be individual samples or genomes. The first column can have a header name `item`, `sample`, `genome` or anything else that is appropriate, and list the items that are relevant to your input data. The second column should have the header `group`, and associate each item in your data with a group.

Each item should be associated with a single group, and it is always a good idea to define groups using single words without any fancy characters. For instance, `HIGH_TEMPERATURE` or `LOW_FITNESS` are good group names. In contrast, `my group #1` or `IS-THIS-OK?`, are not quite good names for groups and may cause issues downstream depending on who uses this file.

Here is an example %(groups-txt)s file:

|item|group|
|:--|:--|
|item_01|GROUP_A|
|item_02|GROUP_B|
|item_03|GROUP_A|
|(...)|(...)|

{:.warning}
If you are passing this file to the program %(anvi-compute-metabolic-enrichment)s, the names in the `sample` column must match those in the "modules" mode output file that you provide to the program via the `--modules-txt` parameter. If you know that the sample names match but you are still getting errors, you might need to specify which column in the "modules" mode output contains those sample names using the `--sample-header` parameter.
This file **contains the alignment information for multiple genes across different organisms**.

Basically, a single gene alignment compares a single gene's sequence across multiple organisms. For example, you could align some specific rRNA sequence across all of the organisms in your sample. This alignment highlights both mutations and insertions and deletions (indicated with dashes). 

Clustal programs do a great job of visualizing this data, by color coding it. Here is an example from Anvi'o's pangenome display: 

![A lovely clustal-like alignment from the anvi'o pangenome display](../../images/example_alignment.png)

A concatenated gene alignment fasta contains multiple of these gene alignments, in order to generate a tree based off of multiple genes. 

This information can then be used to generate a phylogenomic tree using %(anvi-gen-phylogenomic-tree)s or through programs like [FastTree](http://www.microbesonline.org/fasttree/). 

In Anvi'o, this is an output of %(anvi-get-sequences-for-gene-clusters)s (for generating a tree based off of gene clusters in your workflow) as well as %(anvi-get-sequences-for-hmm-hits)s (for generating a tree based off of the genes that got HMM hits). 

This artifact describes the **order of items in visualization tasks**.

In anvi'o, main display items (such as 'gene clusters' in a pan database, 'contigs' in a profile database, etc) can be ordered either by a NEWICK formatted tree (such as a phylogenetic tree or a hierarchical clustering dendrogram), or by an array (such as a flat list of item names).

When a NEWICK tree is used to order items, it will appear as the tree in the central section of the default anvi'o interactive interface. When a flat list of items are provided to order items, the central display where a tree appears will be blank and the displayed items will still be ordered according to the list. In order words, items order is to %(misc-data-items)s as %(misc-data-layer-orders)s is to %(misc-data-layers)s: a description not of the items themselves, but of what order they go in on the interface. 

Anvi'o programs such as %(anvi-pan-genome)s, %(anvi-merge)s, and %(anvi-profile)s automatically generate NEWICK-formatted items order if possible (i.e., if you have less than 20,000 items). When you run these programs, they will put this information into your resulting %(pan-db)s or %(profile-db)s. 

You can also export this information to give to a fellow anvi'o user or import this information if you have your own phylogenetic tree or desired order for your contigs.

You can use %(anvi-import-items-order)s to import specific orders for your items, or %(anvi-export-items-order)s to export this information.This a tab-delimited text file that describes information contained in a %(misc-data-amino-acids)s. 

To import this information into a database, use %(anvi-import-misc-data)s. 

In this table, the first column should provide two pieces of information, both identifying a specific amino acid residue: the gene caller id (for the gene this residue is on) and its codon order in that gene. These should be separated by a colon. The following columns can contain any categorical or numerical data of your choosing.

Here is an example with very abstract data:

    item_name   categorical_data   numerical_data     data_group
      1:42            group_1          4.3245         cool_data 
      6:3             group_2          1.3542         cool_data
      9:96            group_1          3.2526         cool_data
      ...

There is another example of this table [here](http://merenlab.org/2020/07/22/interacdome/#6-storing-the-per-residue-binding-frequencies-into-the-contigs-database). The second table on this page is what you would provide to %(anvi-import-misc-data)s, whereas the first lays out the same data more conceptually. 
This a tab-delimited text file that describes information contained in a %(misc-data-nucleotides)s. 

To import this information into a database, use %(anvi-import-misc-data)s. 

In this table, the first column should provide two pieces of information, both identifying a specific nucleotide position: the name of the contig the nucleotide is on, and its position on that contig. These should be separated by a colon. The following columns can contain any categorical or numerical data of your choosing.

Here is an example with very abstract data:

    item_name   categorical_data  numerical_data    data_group
    contig_1:4       group_1          4.3245         cool_data 
    contig_4:72      group_2          1.3542         cool_data
    contig_7:24      group_1          3.2526         cool_data
    ...

For a more concrete example, check out the example table for %(misc-data-amino-acids)s (which is formatted very similarly)  [here](http://merenlab.org/2020/07/22/interacdome/#6-storing-the-per-residue-binding-frequencies-into-the-contigs-database). The second table on this page is what you would provide to %(anvi-import-misc-data)s. 
This is a JSON file that describes a %(state)s. It is the output of %(anvi-export-state)s and can be imported into the interface (through a database) using %(anvi-export-state)s. 

This is how you would give a state to a fellow anvi'o user. If opened, you'll be able to view all of the data that's contained in this state. 
This describes the databases downloaded from [The Genome Taxonomy Database](https://gtdb.ecogenomic.org/) when you run %(anvi-setup-scg-taxonomy)s. 

Once you have these databases, you'll want to search the single-copy core genes in your %(contigs-db)s against them. To do this, run %(anvi-run-scg-taxonomy)s. 
This page describes general properties of the interactive inspect page. This described a [NEWICK-formatted](https://en.wikipedia.org/wiki/Newick_format) tree that is not representative of the phylogenic relationships between your samples. 

{:.notice}
If you're looking for phylogenic trees, take a look at %(phylogeny)s 

Instead, the dendrogram artifact most often describes the tree used as a %(misc-data-items-order)s: the order that the items in %(anvi-interactive)s are displayed in (the central tree in the circular display). Often, these are the order of your contigs or genes based on their relatedness to each other (for example by tetranucleotide frequency or differencial coverage). These trees are also contained in %(misc-data-layer-orders)s.

A dendrogram is also listed as the output of programs that are not necessarily related to phylogenetics (like %(anvi-matrix-to-newick)s).  
%(anvi-estimate-metabolism)s predicts the metabolic capabilities of organisms based on their genetic content. It relies upon %(kegg-functions)s and metabolism information from [KEGG](https://www.genome.jp/kegg/) (%(kegg-data)s), which is stored in a %(modules-db)s. It can also use user-defined metabolic pathways, as described in %(user-modules-data)s.

The metabolic pathways that this program considers (by default) are those defined by KEGG Orthologs (KOs) in the [KEGG MODULE resource](https://www.genome.jp/kegg/module.html). Each KO represents a gene function, and a KEGG module is a set of KOs that collectively carry out the steps in a metabolic pathway.

Alternatively or additionally, you can define your own set of metabolic modules and estimate their completeness with this program. Detailed instructions for doing this can be found by looking at the %(user-modules-data)s and  %(anvi-setup-user-modules)s pages.

Given a properly annotated %(contigs-db)s, this program determines which enzymes are present and uses these functions to compute the completeness of each metabolic module. The output is one or more tabular text files - see %(kegg-metabolism)s for the output description and examples.

For a practical tutorial on how to use this program, visit [this link](https://merenlab.org/tutorials/infant-gut/#chapter-v-metabolism-prediction). A more abstract discussion of available parameters, as well as technical details about how the metabolism estimation is done, can be found below.

## What metabolism data can I use?

You have three options when it comes to estimating metabolism.

1. KEGG only (this is the default). In this case, estimation will be run on modules from the KEGG MODULES database, which you must set up on your computer using %(anvi-setup-kegg-kofams)s. If you have a default setup of KEGG, you need not provide any parameters to choose this option. However, if you have your KEGG data in a non-default location on your computer, you will have to use the `--kegg-data-dir` parameter to point out its location.
2. KEGG + USER data. In this case, we estimate on KEGG modules as in (1), but _also_ on user-defined metabolic modules that you set up with %(anvi-setup-user-modules)s and provide to this program with the `--user-modules` parameter.
3. USER data only. You can elect to skip estimation on KEGG modules and _only_ run on your own data by providing both the `--user-modules` and `--only-user-modules` parameters.

## Prerequisites to using this program

Metabolism estimation relies on gene annotations from the functional annotation source 'KOfam', also referred to as %(kegg-functions)s. Therefore, for this to work, you need to have annotated your %(contigs-db)s with hits to the KEGG KOfam database by running %(anvi-run-kegg-kofams)s prior to using this program, unless you are using the `--only-user-modules` option to ONLY estimate on user-defined metabolic modules.

Both %(anvi-run-kegg-kofams)s and %(anvi-estimate-metabolism)s rely on the %(kegg-data)s provided by %(anvi-setup-kegg-kofams)s, so if you do not already have that data on your computer, %(anvi-setup-kegg-kofams)s needs to be run first. To summarize, these are the steps that need to be done before you can use %(anvi-estimate-metabolism)s:

1. Run %(anvi-setup-kegg-kofams)s to get data from KEGG onto your computer. This step only needs to be done once.
2. [If not using `--only-user-modules`] Run %(anvi-run-kegg-kofams)s to annotate your %(contigs-db)s with %(kegg-functions)s. This program must be run on each contigs database that you want to estimate metabolism for.

If you want to estimate for your own metabolism data, then you have a couple of extra steps to go through:

3. Define your own metabolic modules by following the formatting guidelines described [here](https://merenlab.org/software/anvio/help/main/programs/anvi-setup-user-modules/#how-do-i-format-the-module-files) and [here](https://merenlab.org/software/anvio/help/main/artifacts/user-modules-data/#a-step-by-step-guide-to-creating), and then run %(anvi-setup-user-modules)s to parse them into a %(modules-db)s,
4. Annotate your %(contigs-db)s with the functional annotation sources that are required for your module definitions. This may require running a few different programs. For instance, if your modules are defined in terms of NCBI COGS (ie, the `COG20_FUNCTION` annotation source), you will need to run %(anvi-run-ncbi-cogs)s. If you are using a set of custom HMMs, you will need to run %(anvi-run-hmms)s on that set using the `--add-to-functions-table` parameter. If you already have annotations from one or more of these sources, you could also import them into the contigs database using the program %(anvi-import-functions)s.

## Running metabolism estimation

You can run metabolism estimation on any set of annotated sequences, but these sequences typically fall under one of the following categories:

- Single genomes, also referred to as %(external-genomes)s. These can be isolate genomes or metagenome-assembled genomes, for example. Each one is described in its own individual %(contigs-db)s.
- Bins, also referred to as %(internal-genomes)s. These often represent metagenome-assembled genomes, but generally can be any subset of sequences within a database. A single %(contigs-db)s can contain multiple bins.
- Assembled, unbinned metagenomes. There is no distinction between sequences that belong to different microbial populations in the %(contigs-db)s for an unbinned metagenome.

As you can see, %(anvi-estimate-metabolism)s always takes one or more contigs database(s) as input, but the information that is taken from those databases depends on the context (ie, genome, metagenome, bin). In the case of internal genomes (or bins), is possible to have multiple inputs but only one input contigs db. So for clarity's sake, we sometimes refer to the inputs as 'samples' in the descriptions below. If you are getting confused, just try to remember that a 'sample' can be a genome, a metagenome, or a bin.

Different input contexts can require different parameters or additional inputs. The following sections describe what is necessary for each input type.


### Estimation for a single genome

The most basic use-case for this program is when you have one contigs database describing a single genome. Since all of the sequences in this database belong to the same genome, all of the gene annotations will be used for metabolism estimation.

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s
{{ codestop }}

### Estimation for bins in a metagenome

You can estimate metabolism for different subsets of the sequences in your contigs database if you first %(bin)s them and save them as a %(collection)s. For each bin, only the gene annotations from its subset of sequences will contribute to the module completeness scores.

You can estimate metabolism for every individual bin in a collection by providing the profile database that describes the collection as well as the collection name:

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s -p %(profile-db)s -C %(collection)s
{{ codestop }}

The metabolism estimation results for each bin will be printed to the same output file(s). The `bin_name` column in long-format output will distinguish between results from different bins.

If you only want estimation results for a single bin, you can instead provide a specific bin name from that collection using the `-b` parameter:

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s -p %(profile-db)s -C %(collection)s -b %(bin)s
{{ codestop }}

Or, to estimate on a subset of bins in the collection, you can provide a text file containing the specific list of bins that you are interested in:

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s -p %(profile-db)s -C %(collection)s -B bin_ids.txt
{{ codestop }}

Each line in the `bin_ids.txt` file should be a bin name from the collection (there is no header line). Here is an example file containing three bin names:

```
bin_1
bin_3
bin_5
```

### Estimation for a metagenome

If you have an unbinned metagenome assembly, you can estimate metabolism for it using `--metagenome-mode`. In this case, since there is no way to determine which contigs belong to which microbial populations in the sample, estimation will be done on a per-contig basis; that is, for each contig, only the genes present on that contig will be used to determine pathway completeness within the contig.

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --metagenome-mode
{{ codestop }}

{: .notice}
In metagenome mode, this program will estimate metabolism for each contig in the metagenome separately. This will tend to underestimate module completeness because it is likely that many modules will be broken up across multiple contigs belonging to the same population. If you prefer to instead treat all enzyme annotations in the metagenome as belonging to one collective genome, you can do so by simply leaving out the `--metagenome-mode` flag (to effectively pretend that you are doing estimation for a single genome, although in your heart you will know that your contigs database really contains a metagenome). Please note that this will result in the opposite tendency to overestimate module completeness (as the enzymes will in reality be coming from multiple different populations), and there will be a lot of redundancy. We are working on improving our estimation algorithm for metagenome mode. In the meantime, if you are worried about the misleading results from either of these situations, we suggest binning your metagenomes first and running estimation for the bins as described below.

## MULTI-MODE: Running metabolism estimation on multiple contigs databases

If you have a set of contigs databases of the same type (i.e., all of them are single genomes or all are binned metagenomes), you can analyze them all at once. What you need to do is put the relevant information for each %(contigs-db)s into a text file and pass that text file to %(anvi-estimate-metabolism)s. The program will then run estimation individually on each contigs database in the file. The estimation results for each database will be aggregated and printed to the same output file(s).

One advantage that multi-mode unlocks is the ability to generate matrix-formatted output, which is convenient for clustering or visualizing the metabolic potential of multiple samples. See the [Output options](#output-options) section below for more details.

### Estimation for multiple single genomes

Multiple single genomes (also known as %(external-genomes)s) can be analyzed with the same command by providing an external genomes file to %(anvi-estimate-metabolism)s. To see the required format for the external genomes file, see %(external-genomes)s.

{{ codestart }}
anvi-estimate-metabolism -e external-genomes.txt
{{ codestop }}

### Estimation for multiple bins

If you have multiple bins (also known as %(internal-genomes)s), they can be analyzed with the same command by providing an internal genomes file to %(anvi-estimate-metabolism)s. The bins in this file can be from the same collection, from different collections, or even from different metagenomes. To see the required format for the internal genomes file, see %(internal-genomes)s.

{{ codestart }}
anvi-estimate-metabolism -i internal-genomes.txt
{{ codestop }}

### Estimation for multiple metagenomes

Multiple metagenomes can be analyzed with the same command by providing a metagenomes input file. Metagenome mode will be used to analyze each contigs database in the file. To see the required format for the metagenomes file, see %(metagenomes)s.

{{ codestart }}
anvi-estimate-metabolism -M metagenomes.txt
{{ codestop }}

## Adjustable Parameters

There are many ways to alter the behavior of this program to fit your needs. You can find some commonly adjusted parameters below. For a full list of parameters, check the program help (`-h`) output.

### Changing the module completion threshold

As explained in the [technical details section](#how-is-the-module-completeness-score-calculated) below, module completeness is computed as the percentage of steps in the metabolic pathway that are 'present' based on the annotated enzymes in the contigs database. If this completeness is larger than a certain percentage, then the entire module is considered to be 'complete' in the sample and the corresponding row in the long-format modules mode output file will have 'True' under the `module_is_complete` column. By default, the module completion threshold is 0.75, or 75%%.

Changing this parameter doesn't have any effect other than changing the proportions of 'True' and 'False' values in the `module_is_complete` column of long-format modules mode output (or the proportion of 1s and 0s in the module presence-absence matrix for `--matrix-format` output). It does _not_ alter completeness scores. It also does not affect which modules are printed to the output file, unless you use the `--only-complete` flag (described in a later section). Therefore, the purpose of changing this threshold is usually so that you can filter the output later somehow (i.e., by searching for 'True' values in the long-format output).

In this example, we change the threshold to 50 percent.

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --module-completion-threshold 0.5
{{ codestop }}

### Working with a non-default KEGG data directory

If you have previously annotated your contigs databases using a non-default KEGG data directory with `--kegg-data-dir` (see %(anvi-run-kegg-kofams)s), or you have moved the KEGG data directory that you wish to use to a non-default location, then you will need to specify where to find the KEGG data so that this program can use the right one. In that case, this is how you do it:

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --kegg-data-dir /path/to/directory/KEGG
{{ codestop }}

### Working with user-defined metabolism data

If you have defined your own set of metabolic modules and generated a %(modules-db)s for them using %(anvi-setup-user-modules)s, you can estimate the completeness of these pathways (in addition to the KEGG modules) by providing the path to the directory containing this data:

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --user-modules /path/to/USER/directory
{{ codestop }}

The `--user-modules` parameter can be used in conjunction with the `--kegg-data-dir` parameter to control which KEGG data is being used at the same time.

### Skipping KEGG data (ie, only working with user-defined metabolism data)

If you wish to only estimate for your own metabolic modules, you can skip estimating for KEGG modules by providing the `--only-user-modules` flag. The nice thing about doing this is that you can skip running %(anvi-run-kegg-kofams)s on your databases (which will save you lots of time and computational resources).

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --user-modules /path/to/USER/directory --only-user-modules
{{ codestop }}

## Output options
This program has two types of output files: long-format (tab-delimited) output files and matrices. The long-format output is the default. If you are using multi-mode to work with multiple samples, you can request matrix output by using the flag `--matrix-format`.

You can find more details on the output formats by looking at %(kegg-metabolism)s. Below, you will find examples of how to use output-related parameters.

### Long-Format Output
Long-format output has several preset "modes" as well as a "custom" mode in which the user can define the contents of the output file. Multiple modes can be used at once, and each requested "mode" will result in a separate output file. The default output mode is "modules" mode.

**Viewing available output modes**

To see what long-format output modes are currently available, use the `--list-available-modes` flag:

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --list-available-modes
{{ codestop }}

The program will print a list like the one below and then exit.

```
AVAILABLE OUTPUT MODES
===============================================
hits_in_modules ..............................: Information on each enzyme (gene annotation) that belongs to a module
modules ......................................: Information on metabolic modules
modules_custom ...............................: A custom tab-delimited output file where you choose the included modules data using --custom-output-headers
hits .........................................: Information on all enzyme annotations in the contigs DB, regardless of module membership
```

Please note that you _must_ provide your input file(s) for this to work.

**Using a non-default output mode**

You can specify one or more long-format output modes using the `--output-modes` parameter. The mode names must exactly match to one of the available modes from the `--list-available-modes` output.

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --output-modes hits
{{ codestop }}

**Using multiple output modes**

If you want more than one output mode, you can provide multiple comma-separated mode names to the `--output-modes` parameter. There should be no spaces between the mode names.

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --output-modes hits,modules
{{ codestop }}

When multiple output modes are requested, a different output file is produced for each mode. All output files will have the same prefix, and the file suffixes specify the output mode. For example, modules mode output has the suffix `_modules.txt` while hits mode has the suffix `_hits.txt`.

**Viewing available output headers for 'custom' mode**

The `modules_custom` output mode allows you to specify which information to include (as columns) in your long-format output. It is essentially a customizable version of modules mode output. To use this mode, you must specify which columns to include by listing the column names after the `--custom-output-headers` flag.

To find out what column headers are available, use the `--list-available-output-headers` parameter:

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --list-available-output-headers
{{ codestop }}

The program will print a list like the one below and then exit.

```
AVAILABLE OUTPUT HEADERS
===============================================
module .......................................: Module number [modules output mode]
module_is_complete ...........................: Whether a module is considered complete or not based on its percent completeness and the completeness threshold [modules output mode]
module_completeness ..........................: Percent completeness of a module [modules output mode]
enzymes_unique_to_module .....................: A list of enzymes that only belong to this module (ie, they are not members of multiple modules) [modules output mode]
unique_enzymes_hit_counts ....................: How many times each unique enzyme appears in the sample (order of counts corresponds to list in `enzymes_unique_to_module` field) [modules output mode]
proportion_unique_enzymes_present ............: Proportion of enzymes unique to this one module that are present in the sample [modules output mode]
unique_enzymes_context_string ................: Describes the unique enzymes contributing to the `proportion_unique_enzymes_present` field [modules output mode]
module_name ..................................: Name/description of a module [modules output mode]
[.......]
enzyme .......................................: Identifier for an enzyme that is annotated in your database(s), ie a KO or COG number [kofams output mode]
modules_with_enzyme ..........................: A comma-separated list of modules that the enzyme belongs to [kofams output mode]
enzyme_definition ............................: The functional annotation associated with the enzyme [kofams output mode]
genome_name ..................................: Name of genome/bin/metagenome in which we find gene annotations (hits) and/or modules [all output modes]
```

As you can see, this flag is also useful when you want to quickly look up the description of each column of data in your output files.

For each header, the output mode(s) that it is applicable to are listed after the description. The headers you can choose from for `modules_custom` output end in either `[modules output mode]` or `[all output modes]`.

Just as with `--list-available-modes`, you must provide your input file(s) for this to work. In fact, some headers will change depending on which input types you provide.

**Using custom output mode**

Here is an example of defining the modules output to contain columns with the module number, the module name, and the completeness score. The corresponding headers for these columns are provided as a comma-separated list (no spaces) to the `--custom-output-headers` flag.

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --output-modes modules_custom --custom-output-headers module,module_name,module_completeness
{{ codestop }}

**Including modules with 0%% completeness in long-format output**

By default, modules with a completeness score of 0 are not printed to the output files to save on space. But you can explicitly include them by adding the `--include-zeros` flag.

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --include-zeros
{{ codestop }}

**Including coverage and detection in long-format output**

If you have a profile database associated with your contigs database and you would like to include coverage and detection data in the metabolism estimation output files, you can use the `--add-coverage` flag. You will need to provide the profile database as well, of course. :)

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s -p %(profile-db)s --output-modes modules,hits_in_modules,hits --add-coverage
{{ codestop }}

For `hits_in_modules` and `hits` mode output files, in which each row describes one enzyme annotation for a gene in the contigs database, the output will contain two additional columns per sample in the profile database. One column will contain the mean coverage of that particular gene call by reads from that sample and the other will contain the detection of that gene in the sample.

For `modules` mode output files, in which each row describes a metabolic module, the output will contain _four_ additional columns per sample in the profile database. One column will contain comma-separated mean coverage values for each gene call in the module, in the same order as the corresponding gene calls in the `gene_caller_ids_in_module` column. Another column will contain the average of these gene coverage values, which represents the average coverage of the entire module. Likewise, the third and fourth columns will contain comma-separated detection values for each gene call and the average detection, respectively.

Note that you can customize which coverage/detection columns are in the output files if you use `custom` modules mode. Use the following command to find out which coverage/detection headers are available:

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s -p %(profile-db)s --add-coverage --list-available-output-headers
{{ codestop }}

### Matrix Output
Matrix format is only available when working with multiple contigs databases. Several output matrices will be generated, each of which describes one statistic such as module completion score, module presence/absence, or enzyme annotation (hit) counts. As with long-format output, each output file will have the same prefix and the file suffixes will indicate which type of data is present in the file.

In each matrix, the rows will describe modules or enzymes, the columns will describe your input samples (i.e. genomes, metagenomes, bins), and each cell will be the corresponding statistic. You can see examples of this output format by viewing %(kegg-metabolism)s.

**Obtaining matrix-formatted output**

Getting these matrices is as easy as providing the `--matrix-format` flag.

{{ codestart }}
anvi-estimate-metabolism -i internal-genomes.txt --matrix-format
{{ codestop }}

**Including metadata in the matrix output**

By default, the matrix output is a matrix ready for use in other computational applications, like visualizing as a heatmap or performing clustering. That means it has a header line and an index in the right-most column, but all other cells are numerical. However, you may want to instead have a matrix that is annotated with more information, like the names and categories of each module or the functional annotations of each enzyme. To include this additional information in the matrix output (as columns that occur before the sample columns), use the `--include-metadata` flag.

{{ codestart }}
anvi-estimate-metabolism -i internal-genomes.txt --matrix-format --include-metadata
{{ codestop }}

Note that this flag only works for matrix output because, well, the long-format output inherently includes metadata.

**Including rows of all zeros in the matrix output**

The `--include-zeros` flag works for matrix output, too. By default, modules that have 0 completeness (or KOs that have 0 hits) in every input sample will be left out of the matrix files. Using `--include-zeros` results in the inclusion of these items (that is, the inclusion of rows of all zeros).

{{ codestart }}
anvi-estimate-metabolism -i internal-genomes.txt --matrix-format --include-zeros
{{ codestop }}

**Getting module-specific enzyme matrices**

The standard enzyme hit matrix includes all enzymes that were annotated at least once in your input databases (or all enzymes that we know about, if `--include-zeros` is used). But sometimes you might want to see a matrix with only the enzymes from a particular metabolic pathway. To do this, pass a comma-separated (no spaces) list of module numbers to the `--module-specific-matrices` flag, and then your matrix output will include enzyme hit matrices for each module in the list.

For example,

{{ codestart }}
anvi-estimate-metabolism -e input_txt_files/external_genomes.txt \
                         --matrix-format \
                         --module-specific-matrices M00001,M00009 \
                         -O external_genomes
{{ codestop }}

will produce the output files `external_genomes-M00001_enzyme_hits-MATRIX.txt` and `external_genomes-M00009_enzyme_hits-MATRIX.txt` (in addition to the typical output matrices). Each additional output matrix will include one row for each enzyme in the module, in the order it appears in the module definition. It will also include comment lines for each major step (or set of steps) in the module definition, to help with interpreting the output.

Check out this (partial) example for module M00001:
```
enzyme	isolate	E_faecalis_6240	test_2
# (K00844,K12407,K00845,K25026,K00886,K08074,K00918)
K00844	0	0	0
K12407	0	0	0
K00845	0	0	0
K25026	0	1	0
K00886	1	0	1
K08074	0	0	0
K00918	0	0	0
# (K01810,K06859,K13810,K15916)
K01810	1	1	1
K06859	0	0	0
K13810	0	0	0
K15916	0	0	0
# (K00850,K16370,K21071,K00918)
K00850	0	1	0
K16370	0	0	0
K21071	0	0	0
K00918	0	0	0
[....]
```

If you don't want those comment lines in there, you can combine this with the `--no-comments` flag to get a clean matrix. This might be useful if you want to do some downstream processing of the matrices.

{{ codestart }}
anvi-estimate-metabolism -e input_txt_files/external_genomes.txt \
                         --matrix-format \
                         --module-specific-matrices M00001,M00009 \
                         --no-comments \
                         -O external_genomes
{{ codestop }}

In this case, the above file would look like this:
```
enzyme	isolate	E_faecalis_6240	test_2
K00844	0	0	0
K12407	0	0	0
K00845	0	0	0
K25026	0	1	0
K00886	1	0	1
K08074	0	0	0
K00918	0	0	0
K01810	1	1	1
K06859	0	0	0
K13810	0	0	0
K15916	0	0	0
K00850	0	1	0
K16370	0	0	0
K21071	0	0	0
K00918	0	0	0
[....]
```

### Other output options

Regardless of which output type you are working with, there are a few generic options for controlling how the output files look like.

**Changing the output file prefix**

%(anvi-estimate-metabolism)s can produce a variety of output files. All will be prefixed with the same string, which by default is `kegg-metabolism`. If you want to change this prefix, use the `-O` flag.

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s -O my-cool-prefix
{{ codestop }}

**Including only complete modules in the output**

Remember that module completion threshold? Well, you can use that to control which modules make it into your output files. If you provide the `--only-complete` flag, then any module-related output files will only include modules that have a completeness score at or above the module completion threshold. (This doesn't affect enzyme-related outputs, for obvious reasons.)

Here is an example of using this flag with long-format output (which is the default, as described above, but we are asking for it explicitly here just to be clear):

{{ codestart }}
anvi-estimate-metabolism -c %(contigs-db)s --output-modes modules --only-complete
{{ codestop }}

And here is an example of using this flag with matrix output. In this case, we are working with multiple input samples, and the behavior of this flag is slightly different: a module will be included in the matrix if it is at or above the module completion threshold in **at least one sample**. If there are any samples in which that module's completeness is below the threshold, its completeness in that sample will be **represented by a 0.0** in the matrix, regardless of its actual completeness score.

{{ codestart }}
anvi-estimate-metabolism -i internal-genomes.txt --matrix-format --only-complete
{{ codestop }}


## Testing this program
You can see if this program is working on your computer by running the following suite of tests, which will check several common use-cases:

{{ codestart }}
anvi-self-test --suite metabolism
{{ codestop }}


## Help! I'm getting version errors!
If you have gotten an error that looks something like this:

```
Config Error: The contigs DB that you are working with has been annotated with a different version of the MODULES.db than you are working with now.
```

This means that the %(modules-db)s used by %(anvi-run-kegg-kofams)s has different contents (different KOs and/or different modules) than the one you are currently using to estimate metabolism, which would lead to mismatches if metabolism estimation were to continue. There are a few ways this can happen, which of course have different solutions:

1. You annotated your %(contigs-db)s with a former version of %(kegg-data)s, and subsequently set up a new %(anvi-setup-kegg-kofams)s (possibly with the `--kegg-archive` or `--download-from-kegg` options, which get you a non-default version of KEGG data). Then you tried to run %(anvi-estimate-metabolism)s with the new %(kegg-data)s version. If this is you, and you have saved your former version of %(kegg-data)s somewhere, then you are in luck - you can simply direct %(anvi-estimate-metabolism)s to use the old version of KEGG with `--kegg-data-dir`. If you didn't save it, then unfortunately you will most likely have to re-run %(anvi-run-kegg-kofams)s on your %(contigs-db)s to re-annotate it with the new version before continuing with metabolism estimation.
2. You have multiple versions of %(kegg-data)s on your computer in different locations, and you used different ones for %(anvi-run-kegg-kofams)s and %(anvi-estimate-metabolism)s. If this is what you did, then there is an easy fix - simply find the KEGG data directory containing the MODULES.db with the same content hash (you can use %(anvi-db-info)s on the MODULES.db to find the hash value) as the one used by %(anvi-run-kegg-kofams)s and submit that location with `--kegg-data-dir` to this program.
3. Your collaborator gave you some databases that they annotated with a different version of %(kegg-data)s than you have on your computer. In this case, either you or they (or both) have probably been using a non-default (or outdated) version of %(kegg-data)s. If they have the current default snapshot of KEGG data but you do not, then you'll need to get that version onto your computer using the default usage of %(anvi-setup-kegg-kofams)s. Otherwise, your collaborator will need to somehow share all or part of their KEGG data directory with you before you can work on their databases. See %(anvi-setup-kegg-kofams)s for details on how to share non-default setups of %(kegg-data)s.

Note that you can also get this sort of error with user-defined metabolic modules, but only if you are estimating from JSON data (in which case the JSON file was generated using a different user-defined %(modules-db)s).


## What to do if estimation is not working as expected for user-defined metabolic modules?

If you are estimating completeness of user-defined modules and find that the results are not as expected, you should double check your module files to make sure the pathway is defined properly. Are the enzyme accession numbers in the DEFINITION correct? Do you have the proper ANNOTATION_SOURCE for each enzyme, and are these lines spelled properly and matching to the annotation sources in your contigs database(s)? If you are using custom HMM profiles, did you remember to use the `--add-to-functions-table` parameter?

If these things are correct but you are still not finding an annotation for one or more enzymes that you _know_ should be in your sequence data, consider why those annotations might not be there - perhaps the e-values are too low for the annotations to be kept in the database? Keep in mind that you can always try to add enzyme annotations (with the proper sources) to your database using %(anvi-import-functions)s before running %(anvi-estimate-metabolism)s again.

## Technical Details

### What data is used for estimation?

Regardless of which input type is provided to this program, the basic requirements for metabolism estimation are 1) a set of metabolic pathway definitions, and 2) a 'pool' of gene annotations.

#### Module Definitions
One set of metabolic pathway definitions that is always used by this program is the [KEGG MODULE resource](https://www.genome.jp/kegg/module.html). You can also define your own set of metabolic modules, but the definition format and estimation strategy will be the same. So for brevity's sake, the following discussion will cover the KEGG data case.

The program %(anvi-setup-kegg-kofams)s acquires the definitions of these modules using the KEGG API and puts them into the %(modules-db)s. The definitions are strings of KEGG Ortholog (KO) identifiers, representing the functions necessary to carry out each step of the metabolic pathway. Let's use module [M00018](https://www.genome.jp/kegg-bin/show_module?M00018), Threonine Biosynthesis, as an example. Here is the module definition, in picture form:

![Module M00018 Definition](../../images/M00018.png){:.center-img .width-50}

This biosynthesis pathway has five steps, or chemical reactions. The [first reaction](https://www.genome.jp/dbget-bin/www_bget?R00480) in the pathway requires an aspartate kinase enzyme (also known as a homoserine dehydrogenase), and there are four possible orthologs known to encode this function: K00928, K12524, K12525, or K12526. Only one of these genes is required to be able to carry out this step. In contrast, the [second reaction](https://www.genome.jp/dbget-bin/www_bget?R02291) can be fulfilled by only one known KO, the aspartate-semialdehyde dehydrogenase [K00133](https://www.genome.jp/dbget-bin/www_bget?ko:K00133).

The definition string for module M00018 is this:

```
(K00928,K12524,K12525,K12526) K00133 (K00003,K12524,K12525) (K00872,K02204,K02203) K01733
```

Hopefully the correspondence between the picture and text is clear - spaces separate distinct steps in the pathway, while commas separate alternatives.

That was a simple example, so let's look at a more complicated one: [M00011](https://www.genome.jp/kegg-bin/show_module?M00011), the second carbon oxidation phase of the citrate cycle.

![Module M00011 Definition](../../images/M00011.png){:.center-img .width-50}

This pathway also has five steps, but this time, most of the reactions require an _enzyme complex_. Each KO within a multi-KO box is a component of an enzyme. For example, one option for the first reaction is 2-oxoglutarate dehydrogenase, a 3-component enzyme made up of [K00164](https://www.genome.jp/dbget-bin/www_bget?K00164), [K00658](https://www.genome.jp/dbget-bin/www_bget?K00658), and [K00382](https://www.genome.jp/dbget-bin/www_bget?K00382).

This is the definition string for module M00011:

```
(K00164+K00658+K00382,K00174+K00175-K00177-K00176) (K01902+K01903,K01899+K01900,K18118) (K00234+K00235+K00236+K00237,K00239+K00240+K00241-(K00242,K18859,K18860),K00244+K00245+K00246-K00247) (K01676,K01679,K01677+K01678) (K00026,K00025,K00024,K00116)
```

And here is a detail that is difficult to tell from the pictorial definition - not all enzyme components are equally important. You can see in the definition string that KO components of an enzyme are connected with either '+' signs or '-' signs. The '+' sign indicates that the following KO is an essential component of the enzyme, while the '-' sign indicates that it is non-essential. For the purposes of module completeness estimation, we only consider a reaction to be fulfilled if all the _essential_ component KOs are present in the annotation pool (and we don't care about the 'non-essential' components). So, for example, we would consider the first step in this pathway complete if just K00174 and K00175 were present. The presence/absence of either K00177 or K00176 would not affect the module completeness score at all.

Module definitions can be even more complex than this. Both of these examples had exactly five steps, no matter which set of KOs you use to fulfill each reaction. However, in some modules, there can be alternative sets with different numbers of steps. In addition, some modules (such as [M00611](https://www.genome.jp/kegg-bin/show_module?M00611), the module representing photosynthesis), are made up of _other_ modules, in which case they are only complete if their component modules are complete.

Hopefully this information will help you understand our estimation strategies in the next section.

#### KOfam (enzyme) annotations
For metabolism estimation to work properly, gene identifiers in the pool of annotations must match to the gene identifiers used in the pathway definitions. For KEGG MODULEs, we rely on annotations from the [KEGG KOfam database](https://www.genome.jp/tools/kofamkoala/), which is a set of HMM profiles for KEGG Orthologs (KOs). The program %(anvi-run-kegg-kofams)s can annotate your %(contigs-db)s with hits to the KEGG KOfam database. It adds these annotations under the source name 'KOfam'.

Which of the annotations are considered for metabolism estimation depends on the input context. If you are working with isolate genomes (ie, _not_ metagenome mode or bins), then all of the annotations under source 'KOfam' will be used. If you are working with bins in metagenomes, then for each bin, only the 'KOfam' annotations that are present in that bin will be in the annotation pool. Finally, for metagenome mode, since estimation is done for each contig separately, only the annotations present in each contig will be considered at a time.

User-defined metabolic modules must specify the annotation source(s) needed to find their component enzymes in your data. Adding these annotation sources to your contigs databases may require running a variety of programs. However, `anvi-estimate-metabolism` loads these gene annotations and uses them in the same way as it does 'KOfam' annotations for KEGG data.

### How is the module completeness score calculated?

For demonstration purposes, let's talk through the estimation of module completeness for one module, in one 'sample' (ie a genome, bin, or contig in a metagenome). Just keep in mind that the steps described below are followed for each module in each sample.

#### Step 1: Unrolling module definitions
As you saw above in the module examples, there can be multiple alternative KOs for a given step in a pathway. This means that there can be more than one way to have a 'complete' metabolic module. Therefore, to estimate completeness, we first have to identify all possible 'paths' through the module definition, where a 'path' is a set of KOs that could make the module complete (if they were all present in the annotation pool).

`anvi-estimate-metabolism` uses a recursive algorithm to "unroll" the module definition string into a list of all possible paths. First, the definition string is split into its component steps (which are separated by spaces). Each step is either an atomic step, a protein complex (KO components separated by '+' or '-'), or a compound step (multiple alternatives, separated by commas). Compound steps and protein complexes are recursively broken down until we have only atomic steps. An atomic step can be a single KO, a module number, a nonessential KO starting with '-', or '--' (a string indicating that there is a reaction for which we do not have a KO). We use the atomic steps to build a list of alternative paths through the module definition. Protein complexes are split into their respective components using this strategy to find all possible alternative complexes, and then these complexes (with all their component KOs) are used to build the alternative paths.

Let's see this in action, using the Threonine Biosynthesis module from above as an example. We first split the definition on spaces to get all component steps. Here we show each component step on its own line:
```
(K00928,K12524,K12525,K12526)
K00133
(K00003,K12524,K12525)
(K00872,K02204,K02203)
K01733
```
The first step is made up of 4 alternative KOs. We split on the commas to get these, and thus we have the starting KO for 4 possible alternative paths:
```
K00928  K12524  K12525  K12526
  |       |       |       |
```
The second step, K00133, is already an atomic step, so we can simply extend each of the paths with this KO:
```
K00928  K12524  K12525  K12526
  |       |       |       |
K00133  K00133  K00133  K00133
```
The third step is another compound step, but this time we can get 3 atomic steps out of it. That means that our 4 possible paths so far each gets 3 alternatives, bringing our total alternative path count up to 12:
```
       K00928                K12524                K12525                K12526
         |                     |                     |                     |
       K00133                K00133                K00133                K00133
      /  |   \              /  |   \              /  |   \              /  |   \
K00003 K12524 K12525  K00003 K12524 K12525  K00003 K12524 K12525  K00003 K12524 K12525
```
Okay, hopefully you get the picture by now. The end result is a list of lists, like this:
```
[[K00928,K00133,K00003,K00872,K01733],
[K00928,K00133,K00003,K02204,K01733],
......
[K12526,K00133,K12525,K02203,K01733]]
```
in which every inner list is one of the alternative paths through the module definition - one of the possible ways to have a complete module.

By the way, here is one alternative path from the module M00011, just so you know what these look like with protein complexes:
```
[K00164+K00658+K00382,K01902+K01903,K00234+K00235+K00236+K00237,K01676,K00026]
```

#### Step 2: Marking steps complete
Once we have our list of alternative paths through the module, the next task is to compute the completeness of each path. Each alternative path is a list of atomic steps or protein complexes. We loop over every step in the path and use the annotation pool of KOs to decide whether the step is complete (1) or not (0). We have the following cases to handle:

1. A single KO - this is easy. If we have an annotation for this KO in our pool of 'KOfam' annotations, then the step is complete. (In our current implementation, we don't pay attention to multiple annotations of the same KO - we only care if there is at least one.)

2. A protein complex - remember that these are multiple KOs connected with '+' (if they are essential components) or '-' (if they are non-essential)? Well, for these steps, we compute a fractional completeness based on the number of essential components that are present in the annotation pool. We basically ignore the non-essential KOs. For example, the complex 'K00174+K00175-K00177-K00176' would be considered 50%% complete (a score of 0.5) if only 'K00174' were present in the annotation pool.

3. Non-essential KOs - some KOs are marked as non-essential even when they are not part of a protein complex. They look like this: '-K12420', with a minus sign in front of the KO identifier (that particular example comes from module [M00778](https://www.genome.jp/kegg-bin/show_module?M00778)). These steps are ignored for the purposes of computing module completeness.

4. Steps without associated KOs - some reactions do not have a KO identifier, but instead there is the string '--' serving as a placeholder in the module definition. Since we can't annotate the genes required for these steps, we have no idea if they are complete or not, so we always consider them incomplete. Modules that have steps like this can therefore never have 100%% completeness - it is sad, but what can we do? We warn the user about these instances so that they can check manually for any missing steps.

5. Modules - finally, some modules are defined by other modules. We can't determine if these steps are complete until we've estimated completeness for every module, so we ignore these for now.

We add up the completeness of each essential step and divide by the number of essential steps to get the completeness score for a given path through the module.

#### Step 3: Module completeness
By this time, we have a completeness score (a fraction between 0 and 1) for every possible path through the module. To get the completeness score for the module overall, we simply take the maximum of all these completeness scores.

We can then check this number against the module completeness threshold (which is 0.75 by default). If the module completeness score is greater than or equal to the threshold, we mark the module as 'complete'. This boolean value is meant only as a way to easily filter through the modules output, and you shouldn't put too much stock in it because it covers up a lot of nuances, as you can tell from the details above :).

#### Step 4: Adjusting completeness
But don't forget that there are some modules defined by other modules. These are usually what KEGG calls 'Signature Modules', which are collections of KOs that collectively encode some phenotype, rather than a typical pathway of chemical reactions. For these modules, we have to go back and adjust the completeness score after we know the completeness of its component modules. To do this, we basically re-do the previous two tasks to recompute the number of complete steps in each path and the overall completeness of the module. This time, when we reach a 'Module' atomic step (case 5), we take that module's fractional completeness score to be the completeness of the step.

As an example, consider module [M00618](https://www.genome.jp/kegg-bin/show_module?M00618), the Acetogen signature module. Its definition is
```
M00377 M00579
```
Suppose module M00377 had a completeness score of 0.7 and module M00579 had a score of 0.4, based on the prior estimations. Then the completeness score of the `[M00377,M00579]` path would be (0.7+0.4)/2 = 0.55. Since this is the only possible path through the module, M00618 is 55%% complete.


#### Summary
For those who prefer the less long-winded approach: module completeness in a given sample is calculated as the maximum fraction of essential KOs (enzymes) that are annotated in the sample, where the maximum is taken over all possible sets of KOs (enzymes) from the module definition.
This program **associates genes in your %(contigs-db)s with functions using the EBI's [Pfam database](https://pfam.xfam.org/).** 

Before you run this program, you'll have to set up the Pfam database on your computer with the program %(anvi-setup-pfams)s.  

The Pfam database is based on protein sequences, so anvi'o will convert your genetic information into protein sequences and then use HMMs to compare them to the database. 

{:.notice}
Unsure what an HMM is? Check out [our vocab page](http://merenlab.org/vocabulary/#hmm)

To run, you'll need to provide a %(contigs-db)s. If you stored the %(pfams-data)s that you got from running %(anvi-setup-pfams)s in a custom location, you'll need to provide that path as well. The output is a %(functions)s artifact. 

Here is a default run: 

{{ codestart }}
anvi-run-pfams -c %(contigs-db)s \
            --pfam-data-dir %(pfams-data)s 
{{ codestop }}

By default, this uses `hmmsearch` to run HMMs. You can choose to use `hmmscan` instead by running

{{ codestart }}
anvi-run-pfams -c %(contigs-db)s \
            --pfam-data-dir %(pfams-data)s \
            --hmmer-program hmmscan
{{ codestop }}

See [this article](https://cryptogenomicon.org/2011/05/27/hmmscan-vs-hmmsearch-speed-the-numerology/) for a discussion on the performance of the two HMMER programs. 
This program finds all reads in a given set of FASTQ files provided as %(samples-txt)s based on user-provided primer sequences as %(primers-txt)s.

One of many potential uses of this program is to get back short reads that may be extending into hypervariable regions of genomes that often suffer from significant drops in coverage in conventional read-recruitment analyses, thus preventing any meaningful insights into coverage or variability patterns. In such situations, one can identify downstream conserved sequences (typically 15 to 25 nucleotides long) using the anvi'o interactive interface or through other means, and then provide those sequences to this program so it can find all matching sequences in a set of FASTQ files without any mapping.

{:.notice}
To instead get short reads mapping to a gene, use %(anvi-get-short-reads-mapping-to-a-gene)s.

Here is a typical command line to run it:

{{ codestart }}
anvi-script-get-primer-matches --samples-txt %(samples-txt)s \
                               --primers-txt %(primers-txt)s \
                               --output-dir OUTPUT
{{ codestop }}

The %(samples-txt)s file is to list all the samples one is interested in, and the %(primers-txt)s file lists each primer sequence of interest, and their user-defined names. Each of these files can contain a single entry, or multiple ones.

This will output all of the matching sequences into three %(fasta)s files in the directory `OUTPUT`. These %(fasta)s files differ in their format and will include those that describe,

* **Raw sequences**: sequences from the FASTQ files that matched to a primer where each sequence reported as is with no processing.
* **Trimmed sequences**: Raw sequences where the upstream of the primer sequence trimmed, as a result all matching sequences will start at the same position, and
* **Gapped sequences**: Trimmed sequences padded with gap characters to eliminate length variation artificially.

The last two formats provide downstream possibilities to generate %(oligotypes)s and cluster short reads from an hypervariable region to estimate their diversity and oligotype proportion.

There will only be a single FASTA file in the output directory for raw sequences if the user asked only the primer matches to be reported with the flag `--only-report-primer-matches`.
This program estimates the completeness and redundancy of genomes provided to it, based on domain-level single-copy core genes. 

{:.notice}
Wondering what single-copy core genes anvi'o uses? Check out %(hmm-source)s. It uses the tables populated when you ran %(anvi-run-hmms)s on your %(contigs-db)s. 

Genomes provided to this program must be contained in either a %(bin)s (within a %(collection)s) or a %(contigs-db)s (which can be provided alone or as part of an %(external-genomes)s). 

### Running on contigs databases 

For example, calling 

{{ codestart }}
anvi-estimate-genome-completeness -c %(contigs-db)s 
{{ codestop }}

will output to the terminal the completition and redundancy of the single-copy core genes in your %(contigs-db)s, assuming that all of its contigs represent a single genome. To output this information to a file, you can add the flag `-o` and provide an output path. 

To get this information for several contigs databases at once, you can provide them as an %(external-genomes)s, as so:

{{ codestart }}
anvi-estimate-genome-completeness -e %(external-genomes)s \
                                  -o completition.txt
{{ codestop }}

### Running on bins 

To get this data for a series of bins, just provide a %(profile-db)s and %(collection)s. 

{{ codestart }}
anvi-estimate-genome-completeness -c %(contigs-db)s \
                                  -p %(profile-db)s \
                                  -C %(collection)s 
{{ codestop }}

To see what collections are contained in your contigs database, call 

{{ codestart }}
anvi-estimate-genome-completeness -c %(contigs-db)s \
                                  -p %(profile-db)s \
                                  --list-collections
{{ codestop }}

or run %(anvi-show-collections-and-bins)s for a more comprehensive overview. 

If you're looking for a more comprehensive overview of your entire collection and its contents, the completition and redunduncy statistics for your bins are also included when you run %(anvi-summarize)s. 
This program downloads a local copy of a subset of the databases from [GTDB](https://gtdb.ecogenomic.org/) (stored in a %(trna-taxonomy-db)s), so that tRNA sequences in your dataset can be associated with taxonomy information. It is required to run this program before you can run %(anvi-run-trna-taxonomy)s or %(anvi-estimate-trna-taxonomy)s.

Like other `anvi-setup-` programs, this only needs to be run once per anvi'o version. The default path is `anvio/data/misc/TRNA-TAXONOMY`. You can store the resulting %(trna-taxonomy-db)s in a custom location if desired), but then you'll need to provide the path to it whenever you run %(anvi-run-trna-taxonomy)s. 

To run this program, you can simply run

{{ codestart }}
anvi-setup-trna-taxonomy 
{{ codestop }}

If you are trying to redownload these databases, run: 

{{ codestart }}
anvi-setup-trna-taxonomy --reset
{{ codestop }}

Alternatively, you can use `--redo-databases` if you just want to update the database version without redownloading the data. 
This program **provides consensus sequences for the genes within a %(contigs-db)s and %(profile-db)s pair**.

In other words, this collapses variability by assigning the most abundant nucleotide in your sample at each position, giving single consensus sequences for each gene for each sample. 

A basic run of this program will resemble the following: 

{{ codestart }}
anvi-gen-gene-consensus-seuqences -p %(profile-db)s \
                                  -c %(contigs-db)s \
                                  -o %(genes-fasta)s 
{{ codestop }}

The default output is a %(genes-fasta)s, but you can also get a tab-delimited output matrix by adding the flag  `--tab-delimited`.

You also have the option to focus on a subset of the data in your %(contigs-db)s and %(profile-db)s by providing either: 

- A list of gene caller IDs (either as a parameter or through a file with one gene caller ID put line)
- A list of samples to focus on (as a file with a single sample name per line) 

### Additional Parameters 

- You have the option to change the variability engine (i.e. to codons), where variability at this level will be resolved. 
- To compress all variability profiles for each of your samples for a single gene, use the flag `--conpress samples`. This way, the program will only report one consensus sequence for each gene instead of reporting one for each sample. 
- You can get consensus sequences for each contig instead of for each gene with `--contigs-mode`
- To report all consensus sequences (even when there are no variable positions), activate `--quince-mode`
This program **exports the contig sequences from a %(contigs-db)s**, outputting them as a %(contigs-fasta)s. It also has the ability to output the sequences of your splits instead. 

You can run this program as follows: 

{{ codestart }}
anvi-export-contigs -c %(contigs-db)s \
                    -o path/to/%(contigs-fasta)s
{{ codestop }}

To run it on only a named subset of your contigs, you can provide a list of contigs as a separate file (in the same format as a %(splits-txt)s). For example: 

{{ codestart }}
anvi-export-contigs -c %(contigs-db)s \
                    -o path/to/%(contigs-fasta)s \
                    --contigs-of-interest my_favorite_contigs.txt 
{{ codestop }}

where `my_favorite_contigs.txt` looks like this:

    contig_0001
    contig_0005
    contig_0035
    
### Splits mode

Want to look at your splits instead of your contigs? Just run with the flag `splits-mode` attached. 

{{ codestart }}
anvi-export-contigs -c %(contigs-db)s \
                    -o path/to/%(contigs-fasta)s \
                    --splits-mode
{{ codestop }}
A helper script to format TAB-delimited files in markdown for bloggers, tutorial writers, those who wish to share example anvi'o outputs as text on GitHub issues, and so on.

Anvi'o programs often generate TAB-delimited files. While this simple format is useful to pass around to other software or share with others, it is not easily interpretable in visual media. The purpose of this script is to make the sharing part simpler for platforms that can render markdown.

You can pipe any TAB-delimited content to this script:

```
cat file.txt | anvi-sript-as-markdown
```

## Examples

Assume a TAB-delmited file with many lines:

``` bash
wc -l additional_view_data.txt

301 additional_view_data.txt
```

Contents of which look like this:

``` bash
head -n 10 additional_view_data.txt

contig	categorical_1	categorical_2	text_layer_01	numerical	bars_main!A	bars_main!B	bars_main!C
backrest	b	y	nmwje	2.78	278	23	1
backward	b	x	bqmyujr psrd doefhi	2.49	249	52	2
backwind	b	y	hkfer lchpmzix	2.69	269	32	3
backyard	b	x	advoe bfkyhmg	2.05	205	96	4
bacteria	b	x	lqmcwn hywco	2.63	263	38	5
bacterin	b		vxqdmn	2.98	298	3	6
baetylus	b	x	fkgpydi owgyhfx xwlpj	2.19	219	82	7
bagpiped	b	y	ijmnur	2.12	212	89	8
balconet	b	y	ecizgs	2.89	289	12	9
```

### Default run

{{ codestart }}
head -n 10 additional_view_data.txt | %(anvi-script-as-markdown)s
{{ codestop }}

which is rendered as,

|**contig**|**categorical_1**|**categorical_2**|**text_layer_01**|**numerical**|**bars_main!A**|**bars_main!B**|**bars_main!C**|
|:--|:--|:--|:--|:--|:--|:--|:--|
|backrest|b|y|nmwje|2.78|278|23|1|
|backward|b|x|bqmyujr psrd doefhi|2.49|249|52|2|
|backwind|b|y|hkfer lchpmzix|2.69|269|32|3|
|backyard|b|x|advoe bfkyhmg|2.05|205|96|4|
|bacteria|b|x|lqmcwn hywco|2.63|263|38|5|
|bacterin|b||vxqdmn|2.98|298|3|6|
|baetylus|b|x|fkgpydi owgyhfx xwlpj|2.19|219|82|7|
|bagpiped|b|y|ijmnur|2.12|212|89|8|
|balconet|b|y|ecizgs|2.89|289|12|9|

### Limit the number of lines shown

``` bash
cat additional_view_data.txt | anvi-script-as-markdown --max-num-lines-to-show 10
```

which is rendered as,

|**contig**|**categorical_1**|**categorical_2**|**text_layer_01**|**numerical**|**bars_main!A**|**bars_main!B**|**bars_main!C**|
|:--|:--|:--|:--|:--|:--|:--|:--|
|backrest|b|y|nmwje|2.78|278|23|1|
|backward|b|x|bqmyujr psrd doefhi|2.49|249|52|2|
|backwind|b|y|hkfer lchpmzix|2.69|269|32|3|
|backyard|b|x|advoe bfkyhmg|2.05|205|96|4|
|bacteria|b|x|lqmcwn hywco|2.63|263|38|5|
|bacterin|b||vxqdmn|2.98|298|3|6|
|baetylus|b|x|fkgpydi owgyhfx xwlpj|2.19|219|82|7|
|bagpiped|b|y|ijmnur|2.12|212|89|8|
|balconet|b|y|ecizgs|2.89|289|12|9|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|

### Code columns

``` bash
cat additional_view_data.txt | anvi-script-as-markdown --max-num-lines-to-show 10 \
                                                       --code-column contig
```

which is rendered as,

|**contig**|**categorical_1**|**categorical_2**|**text_layer_01**|**numerical**|**bars_main!A**|**bars_main!B**|**bars_main!C**|
|:--|:--|:--|:--|:--|:--|:--|:--|
|`backrest`|b|y|nmwje|2.78|278|23|1|
|`backward`|b|x|bqmyujr psrd doefhi|2.49|249|52|2|
|`backwind`|b|y|hkfer lchpmzix|2.69|269|32|3|
|`backyard`|b|x|advoe bfkyhmg|2.05|205|96|4|
|`bacteria`|b|x|lqmcwn hywco|2.63|263|38|5|
|`bacterin`|b||vxqdmn|2.98|298|3|6|
|`baetylus`|b|x|fkgpydi owgyhfx xwlpj|2.19|219|82|7|
|`bagpiped`|b|y|ijmnur|2.12|212|89|8|
|`balconet`|b|y|ecizgs|2.89|289|12|9|
|(...)|(...)|(...)|(...)|(...)|(...)|(...)|(...)|

### Exclude columns from the output

``` bash
cat additional_view_data.txt | anvi-script-as-markdown --max-num-lines-to-show 10 \
                                                       --code-column contig \
                                                       --exclude-columns 'bars_main!A,bars_main!B,bars_main!C'
```

which is rendered as,

|**contig**|**categorical_1**|**categorical_2**|**text_layer_01**|**numerical**|
|:--|:--|:--|:--|:--|
|`backrest`|b|y|nmwje|2.78|
|`backward`|b|x|bqmyujr psrd doefhi|2.49|
|`backwind`|b|y|hkfer lchpmzix|2.69|
|`backyard`|b|x|advoe bfkyhmg|2.05|
|`bacteria`|b|x|lqmcwn hywco|2.63|
|`bacterin`|b||vxqdmn|2.98|
|`baetylus`|b|x|fkgpydi owgyhfx xwlpj|2.19|
|`bagpiped`|b|y|ijmnur|2.12|
|`balconet`|b|y|ecizgs|2.89|
|(...)|(...)|(...)|(...)|(...)|
This directory contains information about anvi'o programs which is compiled into
help text shown in the following URL:

http://merenlab.org/software/anvio/help/

If you run the program `anvi-script-gen-help-pages` on your computer, you can
learn about the prorams that are missing usage information. It is best if you
are following the anvi'o `master` branch if you consider contributing.
Similarly to %(anvi-get-codon-frequencies)s, this program counts the number of times each amino acid occurs in a given sequence, whether that's a %(collection)s, %(bin)s, set of contigs (listed in a %(splits-txt)s), or a set of genes. The output of this is a %(aa-frequencies-txt)s. 

There are four possible things you can count the amino acid frequencies in: 
* All of the contigs in a %(contigs-db)s
* A series of %(bin)ss
* A list of contigs
* A list of genes

Examples for each are below.

### Option 1: all contigs in a contigs-db

To count the amino acids in all of the contigs in a %(contigs-db)s, you can just provide the %(contigs-db)s of interest, as so:

{{ codestart }}
anvi-get-aa-counts -c %(contigs-db)s \
                   -o path/to/%(aa-frequencies-txt)s
{{ codestop }}

### Option 2: a series of bins in a collection 

To count the amino acid frequencies for a series of %(bin)ss, you'll need to provide three additional parameters: the %(profile-db)s that you used for binning, the %(collection)s that your bins are contained in, and a text file that describes which bins you are interested in. This text file should have only one bin ID per line. 

So, your run would look something like this: 

{{ codestart }}
anvi-get-aa-counts -c %(contigs-db)s \
                   -o path/to/%(aa-frequencies-txt)s \
                   -p %(profile-db)s \
                   -C %(collection)s \
                   -B my_favorite_bins.txt
{{ codestop }}

`my_favorite_bins.txt` would look something like this:

    bin_00001
    bin_00004
    
### Option 3: a list of contigs

Just provide a %(splits-txt)s file that lists the contigs you want to look at. 

{{ codestart }}
anvi-get-aa-counts -c %(contigs-db)s \
                   -o path/to/%(aa-frequencies-txt)s \
                   --contigs-of-interest %(splits-txt)s
{{ codestop }}

### Option 4: a list of genes 

Just provide a list of gene caller ids, straight into the terminal, like so:

{{ codestart }}
anvi-get-aa-counts -c %(contigs-db)s \
                   -o path/to/%(aa-frequencies-txt)s \
                   --gene-caller-ids gene_1,gene_2,gene_3
{{ codestop }}

This program (much like all of the other programs that begin with `anvi-setup`) sets up a local copy of the InteracDome database for %(anvi-run-interacdome)s as well as a local copy of Pfam v31.0, which is what InteracDome is defined for. Note that anvi'o only needs this program to be run once.


Specifically, this downloads [InteracDome](https://interacdome.princeton.edu/)â€™s [tab-separated files](https://interacdome.princeton.edu/#tab-6136-4) and the Pfam v31.0 HMM profiles for the Pfams in your InteracDome data. This data is stored in the %(interacdome-data)s artifact. 


It's easy as 1-2-3:

{{ codestart }}
anvi-setup-interacdome
{{ codestop }}

When running this program, you can provide a path to store your InteracDome data in. The default path is `anvio/data/misc/InteracDome`; if you use a custom path, you will have to provide it to %(anvi-run-interacdome)s with the same parameter. Here is an example run: 


{{ codestart }}
anvi-setup-interacdome --interacdome-data-dir path/to/directory 
{{ codestop }}

If you want to overwrite any data that you have already downloaded (for example if you suspect something went wrong in the download), add the `--reset` flag: 

{{ codestart }}
anvi-setup-interacdome  --interacdome-data-dir path/to/directory \ 
                        --reset
{{ codestop }}

This program, as implied by the name, is used to delete a %(hmm-hits)s from a %(contigs-db)s. This way, you can repopulate the function annotations with a different source or program or just delete data that's clogging up the interface.

It is generally a good idea to export your information before deleting it, just in case. The HMM hits will show up in most displays, so if you've already run %(anvi-summarize)s, you should be good. 

To list available %(hmm-source)ss in a database, call 

{{ codestart }}
anvi-delete-hmms -c %(contigs-db)s \
                 --list-hmm-sources
{{ codestop }}

Then, you can easily delete %(hmm-hits)s from a specific source with the command

{{ codestart }}
anvi-delete-hmms -c %(contigs-db)s \
                 --hmm-source %(hmm-source)s 
{{ codestop }}
This program computes functional enrichment within a pangenome and returns a %(functional-enrichment-txt)s file.

{:.warning}
For its sister programs, see %(anvi-compute-metabolic-enrichment)s and %(anvi-compute-functional-enrichment-across-genomes)s.

{:.notice}
Please also see %(anvi-display-functions)s which can both calculate functional enrichment, AND give you an interactive interface to display the distribution of functions.

## Enriched functions in a pangenome

For this to run, you must provide a %(pan-db)s and %(genomes-storage-db)s pair, as well as a %(misc-data-layers)s that associates genomes in your pan database with categorical data. The program will then find functions that are enriched in each group (i.e., functions that are associated with gene clusters that are characteristic of the genomes in that group). 

{:.notice}
Note that your %(genomes-storage-db)s must have at least one functional annotation source for this to work.

This analysis will help you identify functions that are associated with a specific group of genomes in a pangenome and determine the functional core of your pangenome. For example, in the *Prochlorococcus* pangenome (the one used in [the pangenomics tutorial, where you can find more info about this program](http://merenlab.org/2016/11/08/pangenomics-v2/#making-sense-of-functions-in-your-pangenome)), this program finds that `Exonuclease VII` is enriched in the `low-light` genomes and not in `high-light` genomes. The output file provides various statistics about how confident the program is in making this association.

### How does it work?

What this program does can be broken down into three steps:

1. **Determine groups of genomes**. The program uses a %(misc-data-layers)s variable (containing categorical, not numerical, data) to split genomes in a pangenome into two or more groups. For example, in the pangenome tutorial, the categorical variable name was `light` that partitioned genomes into `low-light` and `high-light `groups.

2.  **Determine the "functional associations" of gene clusters**. In short, this is collecting the functional annotations for all of the genes in each cluster and assigning the one that appears most frequently to represent the entire cluster.

3. **Quantify the distribution of functions in each group of genomes**. For this, the program determines to what extent a particular function is enriched in specific groups of genomes and reports it as a %(functional-enrichment-txt)s file. It does so by running the script `anvi-script-enrichment-stats`. 

{:.notice}
The script `anvi-script-enrichment-stats` was implemented by [Amy Willis](https://github.com/adw96), and described first in [this paper](https://doi.org/10.1186/s13059-020-02195-w).

{:.notice}
Check out [Alon's behind the scenes post](http://merenlab.org/2016/11/08/pangenomics-v2/#making-sense-of-functions-in-your-pangenome), which goes into a lot more detail.

### Basic usage

Here is the simplest way to run this program:

{{ codestart }}
anvi-compute-functional-enrichment-in-pan -p %(pan-db)s\
                                          -g %(genomes-storage-db)s \
                                          -o %(functional-enrichment-txt)s \
                                          --category-variable CATEGORY \
                                          --annotation-source FUNCTION_SOURCE
{{ codestop }}

The %(pan-db)s must contain at least one categorical data layer in %(misc-data-layers)s, and you must choose one of these categories to define your pan-groups with the `--category-variable` parameter. You can see available variables with %(anvi-show-misc-data)s program with the parameters `-t layers --debug`.

Note that by default any genomes not in a category will be ignored; you can instead include these in the analysis by using the flag `--include-ungrouped`.

The %(genomes-storage-db)s must have at least one functional annotation source, and you must choose one of these sources with the `--annotation-source`. If you do not know which functional annotation sources are available in your %(genomes-storage-db)s, you can use the `--list-annotation-sources` parameter to find out.

### Additional options

By default, gene clusters with the same functional annotation will be merged. But if you provide the `--include-gc-identity-as-function` parameter and set the annotation source to be 'IDENTITY', anvi'o will treat gene cluster names as functions and enable you to investigate enrichment of each gene cluster independently. This is how you do it:

{{ codestart }}
anvi-compute-functional-enrichment-in-pan -p %(pan-db)s\
                                          -g %(genomes-storage-db)s \
                                          -o %(functional-enrichment-txt)s \
                                          --category-variable CATEGORY \
                                          --annotation-source IDENTITY \
                                          --include-gc-identity-as-function
{{ codestop }}

To output a functional occurrence table, which describes the number of times each of your functional associations occurs in each genome you're looking at, use the `--functional-occurrence-table-output` parameter, like so:

{{ codestart }}
anvi-compute-functional-enrichment-in-pan -p %(pan-db)s\
                                          -g %(genomes-storage-db)s \
                                          -o %(functional-enrichment-txt)s \
                                          --category-variable CATEGORY \
                                          --annotation-source FUNCTION_SOURCE \
                                          --functional-occurrence-table-output FUNC_OCCURRENCE.TXT
{{ codestop }}
This program finds [palindromes](https://en.wikipedia.org/wiki/Palindromic_sequence) in any DNA sequence. It will search for palindromes that mathes criteria listed by the user (i.e., minimum lenght of the palindromic sequences, maximum number of mismatches, and minimum distance between the two palindromic regions). The program will print out its findings (and tribulations) and will optionally report the search results as a %(palindromes-txt)s.

Please note that this program can find both perfect palindromes (i.e., the identity and order of nucleotides on one strand match to those on the complementary strand) and special cases of palindromes that form [hairpins](https://en.wikipedia.org/wiki/Stem-loop). You can use the minimum distance parameter to target any group of palindromes (i.e., minimum distance of 0 will report only perfect palindromes).

{:.notice}
The speed of the algorithm will depend on the minimum palindrome length parameter. The shorter the palindrome length, the longer the processing time. Searching for palindromes longer than 50 nts in a 10,000,000 nts long sequence takes about 4 seconds on a laptop.

### Sequence input sources

%(anvi-search-palindromes)s can use multiple different sequence sources.

#### Contigs database

In this mode %(anvi-search-palindromes)s will go through every contig sequence in a given %(contigs-db)s.

{{ codestart }}
anvi-search-palindromes -c %(contigs-db)s \
                        --output-file %(palindromes-txt)s
{{ codestop }}

#### FASTA file

Alternatively, you can use a %(fasta)s file as input.

{{ codestart }}
anvi-search-palindromes --fasta-file %(fasta)s \
                        --output-file %(palindromes-txt)s
{{ codestop }}

#### DNA sequence

Those who are lazy can also pass a DNA sequence for quick searches:

{{ codestart }}
anvi-search-palindromes --dna-sequence (.. A DNA SEQUENCE OF ANY LENGTH ..)
{{ codestop }}


### Verbose output

If you provide an `--output-file` parameter, your results will be stored into a %(palindromes-txt)s file for downstream analyses. If you do not provide an output file, or explicitly asked for a verbose output with the flag `--verbose`, you will see all your palindromes listed on your screen.

Here is an example with a single sequence and no output file path:

{{ codestart }}
%(anvi-search-palindromes)s --dna-sequence CATTGACGTTGACGGCGACCGGTCGGTGATCACCGACCGGTCGCCGTCAACGTCAATG
{{ codestop }}

```
SEARCH SETTINGS
===============================================
Minimum palindrome length ....................: 10
Number of mismatches allowed .................: 0
Minimum gap length ...........................: 0
Be verbose? ..................................: Yes


58 nts palindrome"
===============================================
1st sequence [start:stop] ....................: [0:58]
2nd sequence [start:stop] ....................: [0:58]
Number of mismatches .........................: 0
Distance between .............................: 0
1st sequence .................................: CATTGACGTTGACGGCGACCGGTCGGTGATCACCGACCGGTCGCCGTCAACGTCAATG
ALN ..........................................: ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
2nd sequence .................................: CATTGACGTTGACGGCGACCGGTCGGTGATCACCGACCGGTCGCCGTCAACGTCAATG

SEARCH RESULTS
===============================================
Total number of sequences processed ..........: 1
Total number of palindromes found ............: 1
Longest palindrome ...........................: 58
Most distant palindrome ......................: 0
```

Here is another example with a %(contigs-db)s, an output file path, and the `--verbose` flag:

{{ codestart }}
%(anvi-search-palindromes)s -c CONTIGS.db \
                         --min-palindrome-length 50 \
                         --max-num-mismatches 1 \
                         --output-file palindromes.txt \
                         --verbose
{{ codestop }}

```
SEARCH SETTINGS
===============================================
Minimum palindrome length ....................: 50
Number of mismatches allowed .................: 1
Minimum gap length ...........................: 0
Be verbose? ..................................: Yes

147 nts palindrome"
===============================================
1st sequence [start:stop] ....................: [268872:269019]
2nd sequence [start:stop] ....................: [269631:269778]
Number of mismatches .........................: 1
Distance between .............................: 759
1st sequence .................................: TTTCGTAATACTTTTTTGCAGTAGGCATCAAATTGGTGTTGTATAGATTTCTCATTATAATTTTGTTGCATGATAATATGCTCCTTTTTCCCCTTTCCACTAATACAACAATCAGAGAGCCCCTTTTTTTCGAAAAAGCTAGAAAAA
ALN ..........................................: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||x|||||||||
2nd sequence .................................: TTTCGTAATACTTTTTTGCAGTAGGCATCAAATTGGTGTTGTATAGATTTCTCATTATAATTTTGTTGCATGATAATATGCTCCTTTTTCCCCTTTCCACTAATACAACAATCAGAGAGCCCCTTTTTTTCGAAAAAACTAGAAAAA

SEARCH RESULTS
===============================================
Total number of sequences processed ..........: 11
Total number of palindromes found ............: 1
Longest palindrome ...........................: 147
Most distant palindrome ......................: 759

Output file ..................................: palindromes.txt
```


### Programmer access

Just like everything else in anvi'o, you can access the functionality the program `anvi-search-palindromes` offers without using the program itself by inheriting an instance from the `Palindromes` class and use it in your own Python scripts.

Here is an example, first with an input file and then an ad hoc sequence. Starting with the file (i.e., an anvi'o %(contigs-db)s):

``` python
# import argparse to pass arguments to the class
import argparse

# `Palindromes` is the class we need
from anvio.sequencefeatures import Palindromes

# we also import `Progress` and `Run` helper classes from the terminal
# module to ask the class to print no output messages to our workspace
# (this is obviously optional)
from anvio.terminal import Progress, Run

# get an instance for the case of a contigs database, and process everything in it.
# this example is with an anvi'o contigs db, but you can also pass a FASTA file
# via `fasta_file='FILE.fa'` instead of `contigs_db='CONTIGS.db'`:
p = Palindromes(argparse.Namespace(contigs_db='CONTIGS.db', min_palindrome_length=50), run=Run(verbose=False), progress=Progress(verbose=False))
p.process()
```

Once the processing is done, the palindromes are stored in a member dictionary, which contains a key for each sequence:

``` python
print(p.palindromes)

>>> {'Day17a_QCcontig1' : [],
     'Day17a_QCcontig2' : [],
     'Day17a_QCcontig4' : [<anvio.sequencefeatures.Palindrome object at 0x7f8d6072f278>],
     'Day17a_QCcontig6' : [],
     'Day17a_QCcontig10': [], 
     'Day17a_QCcontig16': [],
     'Day17a_QCcontig23': [],
     'Day17a_QCcontig24': [],
     'Day17a_QCcontig45': [],
     'Day17a_QCcontig54': [],
     'Day17a_QCcontig97': []}

```

Non-empty arrays are the proper palindromes found in a given sequence, described with an instance of the class `Palindrome` which is defined as the following:

``` python
class Palindrome:
    def __init__(self, run=terminal.Run()):
        self.run=run
        self.first_start = None
        self.fisrt_end = None
        self.first_sequence = None
        self.second_start = None
        self.second_end = None
        self.second_sequence = None
        self.num_mismatches = None
        self.length = None
        self.distance = None
        self.midline = ''
```

Not only you can access to each member variable to deal with them, you can easily display the contents of one using the `display()` function:

``` python
palindrome = p.palindromes['Day17a_QCcontig4'][0]
print(palindrome)

>>> TTTCGTAATACTTTTTTGCAGTAGGCATCAAATTGGTGTTGTATAGATTTCTCATTATAATTTTGTTGCATGATAATATGCTCCTTTTTCCCCTTTCCACTAATACAACAATCAGAGAGCCCCTTTTTTTCGAAAAA (268872:269009) :: TTTCGTAATACTTTTTTGCAGTAGGCATCAAATTGGTGTTGTATAGATTTCTCATTATAATTTTGTTGCATGATAATATGCTCCTTTTTCCCCTTTCCACTAATACAACAATCAGAGAGCCCCTTTTTTTCGAAAAA (269631:269768)

palindrome.display()

>>> 137 nts palindrome"
>>> ===============================================
>>> 1st sequence [start:stop] ....................: [268872:269009]
>>> 2nd sequence [start:stop] ....................: [269631:269768]
>>> Number of mismatches .........................: 0
>>> Distance between .............................: 759
>>> 1st sequence .................................: TTTCGTAATACTTTTTTGCAGTAGGCATCAAATTGGTGTTGTATAGATTTCTCATTATAATTTTGTTGCATGATAATATGCTCCTTTTTCCCCTTTCCACTAATACAACAATCAGAGAGCCCCTTTTTTTCGAAAAA
>>> ALN ..........................................: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
>>> 2nd sequence .................................: TTTCGTAATACTTTTTTGCAGTAGGCATCAAATTGGTGTTGTATAGATTTCTCATTATAATTTTGTTGCATGATAATATGCTCCTTTTTCCCCTTTCCACTAATACAACAATCAGAGAGCCCCTTTTTTTCGAAAAA
```

Alternatively you can process an ad hoc sequence without any input files,

``` python
p = Palindromes()

# let's set some values for fun,
p.min_palindrome_length = 14
p.max_num_mismatches = 1

# to go through some sequences of your liking:
some_sequences = {'a_sequence': 'CATTGACGTTGACGGCGACCGGTCGGTGATCACCGACCGGTCGCCGTCAACGTCAATG',
                  'antoher_sequence': 'AAATCGGCCGATTT',
                  'sequence_with_no_palindrome': 'AAAAAAAAAAAAAA'}

# in this case (where there are no input files) you can call the function `find`,
# rather than `process`, to populate the `p.palindromes` dictionary:
for sequence_name in some_sequences:
    p.find(some_sequences[sequence_name], sequence_name=sequence_name)

# tadaaa:
print(p.palindromes)

>>> {'a_sequence': [<anvio.sequencefeatures.Palindrome object at 0x7fce807ddb00>],
     'antoher_sequence': [<anvio.sequencefeatures.Palindrome object at 0x7fce807ddc88>],
     'sequence_with_no_palindrome': []}
```

If you are a programmer and need more from this module, please let us know.For a given annotation source for %(functions)s, this program will display distribution patterns of unique function names (or accession numbers) across genomes stored in anvi'o databases.

It is a powerful way to analyze differentially occurring functions for any source of annotation that is shared across all genomes.

Currently, %(anvi-display-functions)s can work with any combination of genomes from %(external-genomes)s, %(internal-genomes)s, and %(genomes-storage-db)s.

### Quick & Simple Run

The simplest way to run this program is as follows:

{{ codestart }}
anvi-display-functions -e %(external-genomes)s \
                       --annotation-source KOfam \
                       --profile-db KOFAM-PROFILE.db
{{ codestop }}

You can replace the annotation source based on what is available across your genomes. You can use the program %(anvi-db-info)s to see all available function annotation sources in a given %(contigs-db)s or %(genomes-storage-db)s. You can also use the program %(anvi-import-functions)s to import ANY kind of functional grouping of your genes and use those ad hoc functional sources to display their distribution across genomes. Please see %(functions)s for more information on functions and how to obtain them.

{:.notice}
Please note that a %(profile-db)s will be automatically generated for you. Once it is generated, the same profile database can be visualized over and over again using %(anvi-interactive)s in manual mode, without having to retain any other files.


### Combining genomes from multiple sources

You can run this program by combining genomes from multiple sources:

{{ codestart }}
anvi-display-functions -e %(external-genomes)s \
                       -i %(internal-genomes)s \
                       -g %(genomes-storage-db)s \
                       --annotation-source KOfam \
                       --profile-db KOFAM-PROFILE.db

{{ codestop }}

This way, you can bring together functions in your metagenome-assembled genomes, the isolates you have acquired from external sources, and even genomes in an anvi'o pangenome into a single framework in a disturbingly easy fashion.

### Performing functional enrichment analysis for free

This is an optional step, but may be very useful for some investigations. If your genomes are divided into meaningful groups, you can also perform a functional enrichment analysis while running this program. All you need to do for this to be included in your analysis is to provide a %(groups-txt)s file that describes which genome belongs to which group:

{{ codestart }}
anvi-display-functions -e %(external-genomes)s \
                       --groups-txt %(groups-txt)s
                       --annotation-source KOfam \
                       --profile-db KOFAM-PROFILE.db
{{ codestop }}

If you are using multiple sources for your genomes, you may not immediately know which genomes to list in your %(groups-txt)s file. In that case, you can first run the program with this additional parameter,

{{ codestart }}
anvi-display-functions -e %(external-genomes)s \
                       -i %(internal-genomes)s \
                       -g %(genomes-storage-db)s \
                       --annotation-source COG20_FUNCTION \
                       --profile-db COGS-PROFILE.db \
                       --print-genome-names-and-quit
{{ codestop }}

In which case anvi'o would report all the functions once it recovers everything from all sources, and print them out for you to create a groups file before re-running the program with it.

This analysis will add the following additional layers in your %(interactive)s display: 'enrichment_score', 'unadjusted_p_value', 'adjusted_q_value', 'associated_groups'. See %(functional-enrichment-txt)s to learn more about these columns.

### Aggregating functions using accession IDs

Once it is run, this program essentially aggregates all function names that occur in one or more genomes among the set of genomes found in input sources. The user can ask the program to use accession IDs to aggregate functions rather than function names:

{{ codestart }}
anvi-display-functions -e %(external-genomes)s \
                       --annotation-source KOfam \
                       --profile-db KOFAM-PROFILE.db \
                       --aggregate-based-on-accession
{{ codestop }}

While the default setting, which is to use function names, will be appropriate for most applications, using accession IDs instead of function names may be important for specific purposes. There may be an actual difference between using functions or accession to aggregate data since multiple accession IDs in various databases may correspond to the same function. This may lead to misleading enrichment analyses downstream as identical function annotations may be over-split into multiple groups. Thus, the default aggregation method uses function names.

### Aggregating functions using all function hits

This is a bit confusing, but actually it is not. In some cases a gene may be annotated with more than one function names. This is a decision often made at the function annotation tool level. For instance %(anvi-run-ncbi-cogs)s may yield two COG annotations for a single gene because the significance score for both hits may exceed the default cutoff. While this can be useful in %(anvi-summarize)s output where things should be most comprehensive, having some genes annotated with multiple functions and others with one function may over-split them (since in this scenario a gene with COGXXX and COGXXX;COGYYY would end up in different bins). Thus, %(anvi-display-functions)s will will use the best hit for any gene that has multiple hits. But this behavior can be turned off the following way:

{{ codestart }}
anvi-display-functions -e %(external-genomes)s \
                       --annotation-source KOfam \
                       --profile-db KOFAM-PROFILE.db \
                       --aggregate-using-all-hits
{{ codestop }}

### The min-occurrence limit

You can choose to limit the number of functions to be considered to those that occur in more than a minimum number of genomes:

{{ codestart }}
anvi-display-functions -e %(external-genomes)s \
                       --annotation-source KOfam \
                       --profile-db KOFAM-PROFILE.db \
                       --min-occurrence 5
{{ codestop }}

Here the `--min-occurrence 5` parameter will exclude any function that appears to occur in less than 5 genomes in your collection.


### A real-world example

Assume we have a list of %(external-genomes)s that include three different species of *Bifidobacterium*. Running the following command,

{{ codestart }}
anvi-display-functions --external-genomes Bifidobacterium.txt \
                       --annotation-source COG20_FUNCTION \
                       --profile-db COG20-PROFILE.db \
                       --min-occurrence 3
{{ codestop }}

Would produce the following display by default, where each layer is one of the genomes described in the %(external-genomes)s file, and each item is a unique function name that occur in `COG20_FUNCTION` (which was obtained by running %(anvi-run-ncbi-cogs)s on each %(contigs-db)s in the external genomes file) that were found in more than three genomes:

[![Example output](../../images/anvi-display-functions-01.png){:.center-img .width-50}](../../images/anvi-display-functions-01.png)

The outermost layer shows the function names:

[![Example output](../../images/anvi-display-functions-02.png){:.center-img .width-50}](../../images/anvi-display-functions-02.png)

After a quick prettification through the %(interactive)s interface, leads to a cleaner display of three distinct species in this group, and functions that are uniquely enriched in either of them:

[![Example output](../../images/anvi-display-functions-03.png){:.center-img .width-80}](../../images/anvi-display-functions-03.png)

Now the resulting %(profile-db)s can be used by %(anvi-interactive)s to re-visualize these data, or can be shared with the community without sharing the underlying contigs databases.
This program is a quicker, but less comprehensive, alternative to %(anvi-summarize)s. It is used to summarize basic read recruitment statistics (like detection and coverage) from many single profiles that are all associated with the same %(contigs-db)s.

Given a list of samples (single profiles) and a collection, `anvi-summary-blitz` will compute the per-sample weighted average of each statistic for each bin in the collection. This is an average of the statistic value over each split in the bin, _weighted by the split length_.

The output will be a text file, and you can find details about its format by clicking on %(quick-summary)s.

### Basic usage

In addition to your list of %(single-profile-db)ss, you must provide this program with their corresponding contigs database and a collection name.
{{ codestart }}
anvi-summary-blitz -c %(contigs-db)s -C %(collection)s PROFILE_1.db PROFILE_2.db PROFILE_3.db [...]
{{ codestop }}

The program will summarize the same collection across all of your profile databases. However, it will use only the first profile database in the argument list to learn about what is in the collection, so it is not exactly necessary to have this collection defined for all of the other profile databases (though one could argue that it is a good idea to do this regardless...). The collection name you provide to this program must be a collection that is present in at least the first profile database in the argument list. In the example above, only `PROFILE_1.db` is strictly required to include the collection you wish to summarize (though all other profiles must contain the same splits as this first profile, which should not be a problem if you generated them all in the same way).

### Choosing a different output prefix

By default, the output file will be prefixed with the collection name that you provided. If you wish to set a different prefix, you can use the `--output-file-prefix`, or `-O`, parameter:
{{ codestart }}
anvi-summary-blitz -c %(contigs-db)s -C %(collection)s -O new_prefix PROFILE_1.db PROFILE_2.db PROFILE_3.db [...]
{{ codestop }}

No matter what, the output will end in `*-quick_summary.txt`. There is no option to change this. Sorry (not sorry).

### Choosing which statistics to summarize

The default statistics that will be summarized are detection and something called 'mean_coverage_Q2Q3' (which is [this](https://merenlab.org/2017/05/08/anvio-views/#mean-overage-q2q3)). You can choose which statistics to summarize by providing them as a comma-separated list (no spaces in the list) to the `--stats-to-summarize`, or `-S`, parameter:
{{ codestart }}
anvi-summary-blitz -c %(contigs-db)s -C %(collection)s -S std_coverage,mean_coverage,detection PROFILE_1.db PROFILE_2.db PROFILE_3.db [...]
{{ codestop }}

Each statistic will get its own column in the output file.

If you are not sure which statistics are available to choose from, just provide some ridiculous, arbitrary string (that cannot possibly be a name of a statistic) to this flag, and you will get an error message that includes a list of the available statistics. Or, you can just look at this example error message (but no guarantees that the list in this example will be the same as whatever you would get by doing it yourself. Just sayin'.)
```
Config Error: The statistic you requested, cattywampus, does not exist. Here are the options
              to choose from: std_coverage, mean_coverage, mean_coverage_Q2Q3, detection,
              abundance, variability
```

If you are curious about the statistics in the list, many of them have definitions in [this blog post](https://merenlab.org/2017/05/08/anvio-views).

## Common errors

### Existing file error

If the output file already exists, you will encounter the following error:
```
File/Path Error: AppendableFile class is refusing to open your file at test-quick_summary.txt
                 because it already exists. If you are a user, you should probably give Anvi'o a
                 different file name to work with. If you are a programmer and you don't want
                 this behavior, init this class with `fail_if_file_exists=False` instead.
```
You can either provide a different file prefix using the `-O` parameter, as the error message suggests, or you can simply delete the existing file and re-run your command.

### Missing table error

If you get an error that looks like this:
```
Config Error: The database at [PROFILE.db] does not seem to have a table named
              `detection_splits` :/ Here is a list of table names this database knows:
              [...]
```

That means your profile databases are not the correct version. The tables we are accessing in this program were introduced in profile database version 36. So the solution to this error is to update your databases to at least that version, using %(anvi-migrate)s. :)
This program lets you look at the %(hmm-hits)s from a single %(hmm-source)s across multiple genomes or bins, by creating a %(hmm-hits-matrix-txt)s. 

The input of this program can be either an %(internal-genomes)s or an %(external-genomes)s. 

Here are two example run on an internal-genomes: 

{{ codestart }}
anvi-script-gen-hmm-hits-matrix-across-genomes -i %(internal-genomes)s \
                                               --hmm-source Bacteria_71 \
                                               -o output.txt
{{ codestop }}

To list the %(hmm-source)ss common to the datasets that you're analyzing, just add the flag `--list-hmm-sources`, as so: 

{{ codestart }}
anvi-script-gen-hmm-hits-matrix-across-genomes -e %(external-genomes)s \
                                               --list-hmm-sources 
{{ codestop }}
This program exports the taxonomy hits for the splits contained in a %(contigs-db)s, outputting them in a %(splits-taxonomy-txt)s. 

To do this, anvi'o examines all of the annotated genes within your splits and returns the taxon ID with the most genes associated with it. For example, a split with 3 genes identified as E. coli, 2 genes identified as Staphylococcus aureus, and 1 as Streptococcus pneumoniae would be annotated as E. coli. 

To run this program, just provide a %(contigs-db)s:

{{ codestart }}
anvi-export-splits-taxonomy -c %(contigs-db)s \
                            -o PATH/TO/%(splits-taxonomy-txt)s

{{ codestop }}
This program **downloads and organizes a local copy of the data from NCBI's [COGs database](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC102395/) for use in function annotation.** This program generates a %(cogs-data)s artifact, which is required to run the program %(anvi-run-ncbi-cogs)s. 

### Set up COGs data
{{ codestart }}
anvi-setup-ncbi-cogs --just-do-it
{{ codestop }}

If you already have a %(cogs-data)s artifact and are trying to redownload this data, run 

{{ codestart }}
anvi-setup-ncbi-cogs --reset
{{ codestop }}
This program **generates a %(genomes-storage-db)s, which stores information about your genomes, primarily for use in pangenomic analysis.** 

Genomes storage databases are to Anvi'o's pangenomic workflow what a %(contigs-db)s is to a metagenomic workflow: it stores vital information and is passed to most programs you'll want to run. 

Once you've generated a %(genomes-storage-db)s, you can run %(anvi-pan-genome)s, which creates a %(pan-db)s and runs various pangenomic analyses (including calculating the similarities between your sequences, identifying gene clusters, and organizing your gene clusters and genomes). After that, you can display your pangenome with %(anvi-display-pan)s For more information, check out [the pangenomic workflow](http://merenlab.org/2016/11/08/pangenomics-v2/#generating-an-anvio-genomes-storage).

### Inputs: internal and external genomes

You can initialize your genomes storage database with %(internal-genomes)s, %(external-genomes)s, or both. 

%(internal-genomes)s describe genomes that are described by a %(bin)s within a %(collection)s that is already within an Anvi'o %(profile-db)s. For example, if you had gone through [the metagenomic workflow](http://merenlab.org/2016/06/22/anvio-tutorial-v2/) and had several MAGs that you wanted to run pangenomic analyses on. 

{{ codestart }}
anvi-gen-genomes-storage -i %(internal-genomes)s \
                         -o %(genomes-storage-db)s
{{ codestop }}

{:.notice}
The name of your genomes storage database (which follows the `-o` flag) must end with `-GENOMES.db`. This just helps differenciate it from other types of Anvi'o databases, such as the %(contigs-db)s and %(profile-db)s. 

In contrast, %(external-genomes)s describe genomes that are contained in a %(fasta)s file that you've turned into a %(contigs-db)s (using %(anvi-gen-contigs-database)s).  For example, if you had downloaded genomes from [NCBI](https://www.ncbi.nlm.nih.gov/). 

{{ codestart }}
anvi-gen-genomes-storage -e %(external-genomes)s \
                         -o %(genomes-storage-db)s
{{ codestop }}

You can also create a genomes storage database from both types of genomes at the same time. For example, if you had MAGs from a metagenomic analysis on an environmental sample and wanted to compare them with the reference genomes on [NCBI](https://www.ncbi.nlm.nih.gov/). To run this, simply provide both types of genomes as parameters, as so: 

{{ codestart }}
anvi-gen-genomes-storage -i %(internal-genomes)s \
                         -e %(external-genomes)s \
                         -o %(genomes-storage-db)s
{{ codestop }}

### Changing the gene caller

By default, Anvi'o will use [Prodigal](https://github.com/hyattpd/Prodigal) and will let you know if you have gene calls identified by other gene callers. However, you are welcome to explicitly use a specific gene caller with the flag `--gene-caller`. 

If you're wondering what gene callers are available in your %(contigs-db)s, you can check by running the program %(anvi-export-gene-calls)s on a specific %(contigs-db)s with the flag `--list-gene-callers`. 
This program **calculates the frequency of each codon or amino acid of every gene in your %(contigs-db)s**. 

To run with all standard parameters, simply provide a %(contigs-db)s and path for the output file as follows: 

{{ codestart }}
anvi-get-codon-frequencies -c %(contigs-db)s \ 
                -o name/of/output_file.txt 
{{ codestop }}

The output of this is a %(codon-frequencies-txt)s that counts the number of times each codon appears in all of your genes.

If instead you want to calculate the data for the amino acids, run 

{{ codestart }}
anvi-get-codon-frequencies -c %(contigs-db)s \ 
                -o name/of/output_file.txt  \
                --return-AA-frequencies-instead \
                --gene-caller-id MY_FAVORITE_GENE
{{ codestop }}

In this example, the flag `gene-caller-id` means that it will only count the amino acid frequencies of a single gene, namely `MY_FAVORITE_GENE`.

You can also return the data as a percent of the total number of codons or amino acids in the gene (with the flag `--percent-normalize`) or calculate the percent that each codon encoding the same amino acid appears in the gene (for example, 0.4 GCT and 0.6 GCC for alanine) (with the flag `--merens-codon-normalization`). 
This program **creates a new %(collection)s from the %(bin)ss in another collection with specific guidelines.** This is especially helpful when you want to merge multiple collections later or share your project with someone, and you want all of your bins to have nicer names than the default `bin_01`, `bin_02`, etc. based on the order you binned them in.

So let's take a look at what this program can do with a simple example.

### Example 1: Renaming all bins in a collection

Let's say you have a collection called `MY_COLLECTION`, which has four bins: `really`, `bad`, `bin`, and `names`. These names just won't do, so let's get to renaming. To rename all of my bins and put them into a collection called `SURFACE_OCEAN_SAMPLES`, you could run

{{ codestart }}
anvi-rename-bins -c %(contigs-db)s \
                 -p %(profile-db)s \
                 --prefix SURFACE_OCEAN \
                 --collection-to-read MY_COLLECTION \
                 --collection-to-write SURFACE_OCEAN_SAMPLES \
                 --report-file rename.txt
{{ codestop }}

And voila! Now you have a second collection named `SURFACE_OCEAN_SAMPLES` that contains your four bins, now named  `SURFACE_OCEAN_Bin_00001`, `SURFACE_OCEAN_Bin_00002`, `SURFACE_OCEAN_Bin_00003`, and `SURFACE_OCEAN_Bin_00004`. The order that the numbers are in represents the quality of the bin as a MAG, given by the completion minus redunancy.

The file `rename.txt` is just a tab-delimited file that contains a summary of your renaming process. The first column has the original name of the bins that you renamed, the second has their new names, and the remaining columns contain information about those bins (like their completion, redundency, and size).

### Example 2: Separating out the MAGs

Okay, but what if you want to label your MAGs separately from your bins? You don't like `SURFACE_OCEAN_bin_00004` since it only has a completition stat of 50 percent, and you're not sure if you want to include `SURFACE_OCEAN_bin_00003`  since it has 50 percent redundency. How can you differenciate these iffy bins in your collection?

Here is the solution:

{{ codestart }}
anvi-rename-bins -c %(contigs-db)s \
                 -p %(profile-db)s \
                 --prefix SURFACE_OCEAN \
                 --collection-to-read MY_COLLECTION \
                 --collection-to-write SURFACE_OCEAN_MAGS \
                 --report-file rename.txt \
                 --call-MAGs \
                 --min-completion-for-MAG 70
{{ codestop }}

Now, the collection `SURFACE_OCEAN_MAGS` will include  `SURFACE_OCEAN_MAG_00001`, `SURFACE_OCEAN_MAG_00002`, `SURFACE_OCEAN_MAG_00003`, and `SURFACE_OCEAN_Bin_00004`. These are exactly the same bins that the collection contained before, but now the names differenciate the wheat from the chaff.

Now, let's make that same collection (still called `SURFACE_OCEAN_MAGS`) that doesn't include `SURFACE_OCEAN_Bin_00003` as a MAG, since the redundency is too high for what we want to look at right now.

{{ codestart }}
anvi-rename-bins -c %(contigs-db)s \
                 -p %(profile-db)s \
                 --prefix SURFACE_OCEAN \
                 --collection-to-read MY_COLLECTION \
                 --collection-to-write SURFACE_OCEAN_MAGS \
                 --report-file rename.txt \
                 --min-completion-for-MAG 70 \
                 --max-redundancy-for-MAG 30 \
                 --call-MAGs
{{ codestop }}

Now `SURFACE_OCEAN_MAGS`   will include  `SURFACE_OCEAN_MAG_00001`  `SURFACE_OCEAN_MAG_00002`,  `SURFACE_OCEAN_Bin_00003`, and `SURFACE_OCEAN_Bin_00004`.

You also have the option to only classify bins above a certain minimum size as MAGs.

### Example 3: An example use case in a workflow

For an example use case, on [this page](http://merenlab.org/tutorials/infant-gut/#renaming-bins-in-your-collection-from-chaos-to-order), anvi-rename-bins is used to create a new collection called `MAGs` that contains differenciates bins that have a completion stat of more than 70 percent, and renames all of those bins with the prefix `IGD` (which stands for infant gut dataset).
The purpuse of this program is to import a %(collection)s into an anvi'o database.

The input to this program, a %(collection-txt)s, may either have been generated by another anvi'o pprogram (such as %(anvi-export-collection)s), or may have been generated by the user manually. To import a collection into a database, you can run the following command, 

{{ codestart }}
anvi-import-collection %(collection-txt)s \
                       -p %(profile-db)s \
                       -c %(contigs-db)s \
                       -C COLLECTION_NAME
{{ codestop }}

which would import the collection described in the input file formatted as a %(collection-txt)s into the %(profile-db)s with the name `COLLECTION_NAME`.

If your %(collection-txt)s describes contig names rather than split names, you will likely get an anvi'o error. You can fix that by adding the flag `--contigs-mode` to your command:

{{ codestart }}
anvi-import-collection %(collection-txt)s \
                       -p %(profile-db)s \
                       -c %(contigs-db)s \
                       --contigs-mode \
                       -C COLLECTION_NAME
{{ codestop }}The primary purpose of this script is to reduce the amount of labor required to generate %(external-genomes)s or %(internal-genomes)s files anvi'o typically uses to learn about your bins and/or genomes.

## Generating an external genomes file

If you provide an input directory and a name for the output file, then every %(contigs-db)s in that directory will get a line in the resulting %(external-genomes)s file:

```
anvi-script-gen-genomes-file --input-dir path/to/dir \
                             --output-file external_genomes.txt
```

Names for genomes in the the resulting external genomes file will be set based on the `project_name` variable, and the `contigs_db_path` column will contain absolute paths.

{:.notice}
You can learn the current `project_name` and/or change it for a given %(contigs-db)s using the program %(anvi-db-info)s. This variable is set by the program %(anvi-gen-contigs-database)s.

You can also instruct `anvi-script-gen-genomes-file` to include all subdirectories under a given directory path:

```
anvi-script-gen-genomes-file --input-dir path/to/dir \
                             --output-file external_genomes.txt \
                             --include-subdirs
```

## Generating an internal genomes file

To get an %(internal-genomes)s file containing all bins from a collection, provide a %(profile-db)s, its corresponding %(contigs-db)s, and the %(collection)s name:

{{ codestart }}
anvi-script-gen-genomes-file -c %(contigs-db)s \
                             -p %(profile-db)s \
                             -C %(collection)s \
                             --output-file internal-genomes.txt
{{ codestop }}

The name of each internal genome will be the same as the bin name, and the path columns will contain absolute paths.
This program takes a %(contigs-fasta)s and %(blast-table)s and removes sequences without BLAST hits of a certain level of confidence. 

For example, you could use this program to filter out sequences that do not have high-confidence taxonomy assignments before running a phylogenomic analysis. 

To run this program, you'll need to provide the %(contigs-fasta)s that you're planning to filter, the %(blast-table)s, a list of the column headers in your %(blast-table)s (as given to BLAST by `-outfmt`), and a `proper_pident` threshold at which to remove the sequences. This threshold will remove sequences less than the given percent of the query amino acids that were identical to the corresponding matched amino acids. Note that this diffres from the `pident` blast parameter because it doesn't include unaligned regions. 

For example, if you ran 

{{ codestart }}
anvi-script-filter-fasta-by-blast -f %(contigs-fasta)s \
                                  -o path/to/%(contigs-fasta)s \
                                  -b %(blast-table)s \
                                  -s qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qlen slen \
                                  -t 30
{{ codestop }}
        
Then the output file would be a %(contigs-fasta)s that contains only the sequences in your input file that have a hit in your blast table with more than 30 percent of the amino acids aligned. 
This is a multi-talented program that seamlessly updates any anvi'o database to the latest version.

You can provide one or more anvi'o databases as command line parameters to this program, and it will migrate each one. However, you must choose whether to migrate the databases safely, or quickly.

If you choose to migrate safely, anvi'o will first make a copy of each database and save it as a backup. In case something goes wrong during the migration, it let you know what happened and will restore your original database from the copy it made. Then you can go on your merry way. (The copy is deleted after the migration script is finished running.)

This is how you migrate safely:
```
anvi-migrate --migrate-dbs-safely *.db
```

Of course, we will always suggest that migrating safely is better, because fewer people get angry at us when we do that. In practice though, making those backup copies takes up extra time and it is unlikely that the migration will fail anyway, so if you have a lot of databases to migrate and are okay with a bit of risk, you have the option to migrate quickly instead. In this case, anvi'o will _not_ copy your databases before starting the migration.
```
anvi-migrate --migrate-dbs-quickly *.db
```
Please remember that by living life in the fast lane, you forego your safety net. On the rare occasion that the migration does fail, this program will let you know what happened, leave you with a database that has a `.broken` file extension, and sassily remind you that this all could have been avoided if you chose the other option. In this unlikely event, you can always reach out to us. We will probably be sassy to you, too, but we will still see if we can help you unbreak things. :)

### Migrating to a specific version
If your database is a few versions behind the highest available version but for whatever reason you don't want to migrate it all the way, you can specify which version to update your database to. Just use the `-t` flag (note: migrating with this parameter only works on ONE database at a time):
```
anvi-migrate --migrate-dbs-safely -t 15 CONTIGS.db
```
Then anvi'o will update your database until it is whatever version you specified and stop. Of course, you cannot provide a version number that is higher than the highest available version. Nor can you provide a number that is lower than your database's current version (ie, backwards migration is not possible).

Not sure what your database's current version is? Try %(anvi-db-info)s.
Not sure what the highest available version is? Run any anvi'o command with the `-v` option to see the version information for all database types (we recommend `anvi-interactive -v` for no particular reason).
This program identifies the tRNA genes in a %(contigs-db)s and stores them in an %(hmm-hits)s. 

To run, just provide a %(contigs-db)s that you want to look through. 

{{ codestart }}
anvi-scan-trnas -c %(contigs-db)s
{{ codestop }}

### Customizing the cut off score

What counts as a tRNA gene? That could be up to you. 

The default minimum score for a gene to be counted is 20.  However, you can set this cutoff to anywhere between 0-100. This value is actually used by the module tRNAScan-SE, so view [their documentation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6768409/) for details. For example, to find more non-cononical tRNA genes, a user could lower the cutoff score to 10 as follows:

{{ codestart }}
anvi-scan-trnas -c %(contigs-db)s \
                --trna-cutoff-score 10
{{ codestop }}

### Other options 

- It is easy to modify where the outputs will go:

    - Use the parameter `--log-file` to provide a path for the output messages to go.
    
    - Use the parameter `--trna-hits-file` to provide a path for the raw tRNA scan data to go. 
    
- Like many anvi'o programs, you can use the tag `--just-do-it` to not have to look at questions or warnings

- You can also try to multithread whenever possible by setting the `--num-threads` parameter (it is 1 by default). This can be used to speed up runtime, but please be aware of your system and its limitations before trying this. 

### Understanding the output 

Essentially, the output of this program states the probability that each gene is a tRNA gene. See %(hmm-hits)s for more information. 
This script get the short reads (in the form of a %(short-reads-fasta)s) out of a %(bam-file)s.  

A basic run of this program is as follows: 

{{ codestart }}
anvi-get-short-reads-from-bam -o path/to/output \ 
                              BAM_FILE_1.bam BAM_FILE_2.bam
{{ codestop }}

This will get all of the short reads out of the provided bam files (`BAM_FILE_1.bam` and `BAM_FILE_2.bam`) and put them into a single file. 

### Narrowing the input 

You can choose to only return the short reads that are contained within a %(collection)s or %(bin)s, as so:

{{ codestart }}
anvi-get-short-reads-from-bam -o path/to/output \ 
                              -c %(contigs-db)s \
                              -p %(profile-db)s \
                              -C %(collection)s \
                              BAM_FILE_1.bam BAM_FILE_2.bam
{{ codestop }}

### Changing the output format

You can split the output based on the directionality of paired-end reads. Adding the tag `--split-R1-and-R2` causes the program to create three separate output files: one for R1 (sequences in the forward direction), one for R2 (sequences in the reverse direction; i.e. reverse complement of R1 sequences), and one for unparied reads. When doing this, you can name these three files with a prefix by using the flag `-O`.  

{{ codestart }}
anvi-get-short-reads-from-bam -o path/to/output \ 
                              --split-R1-and-R2 \ 
                              -O BAM_1_and_BAM_2 \
                              BAM_FILE_1.bam BAM_FILE_2.bam
{{ codestop }}

You can also compress the output by adding the flag `--gzip-output`

This program uses the user's similarity metric of choice to identify genomes that are highly similar to each other, and groups them together into redundant clusters. The program finds representative sequences for each cluster and outputs them into %(fasta)s files.


#### Input Options 

You have two options for the input to this program: 

- the results of %(anvi-compute-genome-similarity)s (a %(genome-similarity)s directory). If you used `fastANI` or `pyANI` when you ran %(anvi-compute-genome-similarity)s, provide this using the parameter `--ani-dir`; if you used sourmash, use the parameter `--mash-dir`. 

- an %(internal-genomes)s, %(external-genomes)s or a series of %(fasta)s files (each of which represents a genome), in which case anvi'o will run %(anvi-compute-genome-similarity)s for you.  When providing these inputs, you can also provide any of the parameters that %(anvi-compute-genome-similarity)s can take, including the `--program` you want to use (out of  [PyANI](https://github.com/widdowquinn/pyani), [fastANI](https://github.com/ParBLiSS/FastANI),  [sourmash](https://sourmash.readthedocs.io/en/latest/)) and their parameters. Details about all of this can be found in the help menu for %(anvi-compute-genome-similarity)s.

#### Output Format 

By default, the output of this program is a directory containing two descriptive text files (the cluster report and fasta report) and a subdirectory called `GENOMES`:

-The cluster report describes is a tab-delimited text file where each row describes a cluster. This file contains four columns: the cluster name, the number of genomes in the cluster, the representative genome of the cluster, and a list of the genomes that are in the cluster. Here is an example describing 11 genomes in three clusters:

    DEREPLICATION-0.97 $ head CLUSTER_REPORT.txt
    cluster    size    representative    genomes
    cluster_000001    1    G11_IGD_MAG_00001    G11_IGD_MAG_00001
    cluster_000002    8    G11_IGD_MAG_00012    G08_IGD_MAG_00008,G33_IGD_MAG_00011,G01_IGD_MAG_00013,G06_IGD_MAG_00023,G03_IGD_MAG_00021,G05_IGD_MAG_00014,G11_IGD_MAG_00012,G10_IGD_MAG_00010
    cluster_000003    2    G03_IGD_MAG_00011    G11_IGD_MAG_00013,G03_IGD_MAG_00011

-The subdirectory `GENOMES` contains fasta files describing the representative genome from each cluster. For example, if your original set of genomes had two identical genomes, this program would cluster them together, and the `GENOMES` folder would only include one of their sequences. 

-The fasta report describes the fasta files contained in the subdirectory `GENOMES`. By default, this describes the representative sequence of each of the final clusters. It tells you the genome name, its source, its cluster (and the representative sequence of that cluster), and the path to its fasta file in  `GENOMES`.  So, for the example above, the fasta report would look like this:

    DEREPLICATION-0.97 $ head FASTA_REPORT.txt
    name    source    cluster    cluster_rep    path
    G11_IGD_MAG_00001    fasta    cluster_000001    G11_IGD_MAG_00001    GENOMES/G11_IGD_MAG_00001.fa
    G11_IGD_MAG_00012    fasta    cluster_000002    G11_IGD_MAG_00012    GENOMES/G11_IGD_MAG_00012.fa
    G03_IGD_MAG_00011    fasta    cluster_000003    G03_IGD_MAG_00011    GENOMES/G03_IGD_MAG_00011.fa

You can also choose to report all genome fasta files (including redundant genomes) (with `--report-all`) or report no fasta files (with `--skip-fasta-report`). This would change the fasta files included in `GENOMES` and the genomes mentioned in the fasta report. The cluster report would be identical.

#### Required Parameters and Example Runs

You are required to set the threshold for two genomes to be considered redundant and put in the same cluster. 

For example, if you had the results from an %(anvi-compute-genome-similarity)s run where you had used `PyANI` and wanted the threshold to be 90 percent, you would run: 

{{ codestart }}
anvi-dereplictate-genomes --ani-dir %(genome-similarity)s \ 
                          -o path/to/output \
                          --similiarity-threshold 0.90
{{ codestop }}

If instead you hadn't yet run %(anvi-compute-genome-similarity)s and instead wanted to cluster the genomes in your %(external-genomes)s file with similarity 85 percent or more (no fasta files necessary) using sourmash, you could run: 

{{ codestart }}
anvi-dereplictate-genomes -e %(external-genomes)s \ 
                          --skip-fasta-report \
                          --program sourmash \
                          -o path/to/output \
                          --similiarity-threshold 0.85 
{{ codestop }}

#### Other parameters

You can change how anvi'o picks the representative sequence from each cluster with the parameter `--representative-method`. For this you have three options:

- `Qscore`: picks the genome with highest completion and lowest redundancy
- `length`: picks the longest genome in the cluster
- `centrality` (default): picks the genome with highest average similiarty to every other genome in the cluster

You can also choose to skip checking genome hashes (which will warn you if you have identical sequences in separate genomes with different names), provide a log path for debug messages or use multithreading (relevant only if not providing `--ani-dir` or `--mash-dir`).


This program, as one might think, allows you to export a %(collection)s. This allows you to take your binning results elsewhere (including into another Anvi'o project with the command %(anvi-import-collection)s). 

You can run this program on a %(profile-db)s or %(pan-db)s as follows: 

{{ codestart }}
anvi-export-collection -C my_favorite_collection \
                        -p %(profile-db)s 
{{ codestop }}

This will give you a %(collection-txt)s file that describes the collection `my_favorite_collection`. 

To list the collections available in this database, you can run 

{{ codestart }}
anvi-export-collection -p %(pan-db)s \
                        --list-colllections
{{ codestop }}

You can also add the flag `--include-unbinned` to have all unbinned contigs in the database show up at the end of your %(collection-txt)s file in a bin titled `UNBINNED`. 
Anvi-summarize lets you look at a **comprehensive overview of your %(collection)s** and its many statistics that anvi'o has calculated. 

It will create a folder called `SUMMARY` that contains many different summary files, including an HTML output that conviently displays them all for you. This folder will contain anything a future user might use to import your collection, so it's useful to send to others or transfer an entire anvi'o collection and all of its data. 

In a little more detail, this program will   
* generate %(fasta)s files containing your original contigs.   
* estimate various stats about each of your bins, including competition, redundacy, and information about all of your %(hmm-hits)s    
* generate various tab-delimited matrix files with information about your bins across your samples, including various statistics.   

## Running anvi-summarize 

### Running on a profile database

A standard run of anvi-summarize on a %(profile-db)s will look something like this:

{{ codestart }}
anvi-summarize -c %(contigs-db)s \
               -p %(profile-db)s \
               -o MY_SUMMARY \
               -C %(collection)s
{{ codestop }}

This will name the output directory `MY_SUMMARY` instead of the standard `SUMMARY`. 

When running on a profile database, you also have options to 
* output very accurate (but intensely processed) coverage and detection data for each gene (using `--init-gene-coverages`)
* edit your contig names so that they contain the name of the bin that the contig is in (using `--reformat-contig-names`)
* also display the amino acid sequeunces for your gene calls.  (using `--report-aa-seqs-for-gene-calls`)

### Running on a pan database

When running on a %(pan-db)s, you'll want to instead provide the associated genomes storage database. 

{{ codestart }}
anvi-summarize -g %(genomes-storage-db)s \
               -p %(pan-db)s \
               -C %(collection)s 
{{ codestop }}

You can also choose to display DNA sequences for your gene clusters instead of amino acid sequences with the flag `--report-DNA-sequences`

### Other notes

If you're unsure what collections are in your database, you can run this program with the flag `--list-collections` or by running %(anvi-show-collections-and-bins)s.

You can also use the flag `--quick-summary` to get a less comprehensive summary with a much shorter processing time. 
This program **finds, clusters, and organizes the genes** within a %(genomes-storage-db)s to create a %(pan-db)s. 

This is the program that does the brunt of the work when running a pangenomic workflow. Check out [the pangenomic tutorial](http://merenlab.org/2016/11/08/pangenomics-v2) for a more in-depth overview of the contents of this page and the capabilities of a %(pan-db)s. 

### Before running this program

Before running this program, you'll want to make sure your dependencies are all set, since this program requires some aditional dependencies than base anvi'o. If the following command runs without errors, then you're all good. 

{{ codestart }}
anvi-self-test --suite pangenomics
{{ codestop }}

If that command doesn't run smoothly, check out [this page](http://merenlab.org/2016/11/08/pangenomics-v2/#dependencies).

### What this program does

This program finds and organizes your gene clusters to give you all of the data that is displayed when you run %(anvi-pan-genome)s. Almost all of the work described in [this gif that explains the common steps involved in pangenomics](http://merenlab.org/momics/#pangenomics) is done by this program. 

In a little more detail, this program will do three major things for you:

* Calculate the similarity between the all of the gene calls in all of the genomes in your %(genomes-storage-db)s. By default this uses [DIAMOND](https://www.wsi.uni-tuebingen.de/lehrstuehle/algorithms-in-bioinformatics/software/diamond/) to do this, but Meren strongly recommends that you use the `--use-ncbi-blast` flag to use [`blastp`](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE=Proteins) instead.  

    *   When doing this, this will look at every genome in your %(genomes-storage-db)s (unless you use `--genome-names`) and will use every gene call, whether or not they are complete (unless you used `--exclude-partial-gene-calls`).   
    
    *   After doing this, it will use the minbit heuristic (originally from ITEP ([Benedict et al., 2014](https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-8)) to throw out weak matches. This removes a lot of noise before clustering. 
    
* Use the [MCL](http://micans.org/mcl/) algorithm to identify clusters in your search results.  

* Organize your gene clusters and genomes using their `euclidean` distance and `ward` linkage. 

This program is very smart, and if you're already run it, it will try to use the data that it's already calculated. This way you can change smaller parameters without all of the run time. However, this also means you need to tell it to rerun the process (if that's what you want) with the flag `--overwrite-output-destinations`. 

### Cool. How about some examples and specific parameters?

Who doesn't love a good example? The simplest way to run this is as follows:

{{ codestart }}
anvi-pan-genome -g %(genomes-storage-db)s
{{ codestop }}

But there are many parameters you can alter to your liking. For example, here's a run that specifies that it wants to use NCBI's blastp to find sequence similarities and muscle to align genes and defines its output 

{{ codestart }}
anvi-pan-genomes -g %(genomes-storage-db)s \
                 --align-with muscle \
                 --use-ncbi-blast \ 
                 -n MY_PROJECT_NAME \
                 --description description.txt \
                 -o PATH/TO/%(pan-db)s 
{{ codestop }}

Here's another example that only looks at the complete gene calls within a subset of the genomes, eliminates gene clusters that only have hits in a single genome, and uses DIAMOND but with the sensitive setting enabled:

{{ codestart }}
anvi-pan-genomes -g %(genomes-storage-db)s \
                 -n MY_PROJECT_NAME \
                 --genome-names GENOME_1,GENOME_2,GENOME_3 \
                 --exclude-partial-gene-calls \ 
                 --min-occurance 2 \
                 --sensitive \
                 -o PATH/TO/%(pan-db)s 
{{ codestop }}

Some other parameters available to you allow you to  

- Change the minimum minbit value to elimate weak matches. The default value is 0.5.
- Change the MCL inflation parameter. The default value is 2. 
- Specify a minimum percent identity between two sequences to give that link an edge in MCL clustering. 
- Skip or speed up the calculation of homogeneity values for your clusters
- Enable multithreading with `-T`
This program allows you to **export the sequences of your gene calls** from a %(contigs-db)s or %(genomes-storage-db)s in the form of a %(genes-fasta)s. 

If you want other information about your gene calls from a %(contigs-db)s, you can run %(anvi-export-gene-calls)s (which outputs a %(gene-calls-txt)s) or get the coverage and detection information with %(anvi-export-gene-coverage-and-detection)s.

### Running on a contigs database

You can run this program on a %(contigs-db)s like so:

{{ codestart }}
anvi-get-sequences-for-gene-calls -c %(contigs-db)s \
                                  -o path/to/output
{{ codestop }}

This is create a %(genes-fasta)s that contains every gene in your contigs database. If you only want a specific subset of genes, you can run the following: 

{{ codestart }}
anvi-get-sequences-for-gene-calls -c %(contigs-db)s \
                                  -o path/to/output \
                                  --gene-caller-ids 897,898,1312 \
                                  --delimiter ,
{{ codestop }}

Now the resulting %(genes-fasta)s will contain only those three genes. 

You also have the option to report the output in [gff3 format](https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md), report extended deflines for each gene, or report amino acid sequences instead of nucleotide sequences.

### Running on a genomes storage database

You can also get the sequences from gene calls in a %(genomes-storage-db)s, like so:

{{ codestart }}
anvi-get-sequences-for-gene-calls -g %(genomes-storage-db)s \
                                  -o path/to/output
{{ codestop }}

This will create a %(genes-fasta)s that contains every gene in your genomes storage database. To focus on only a subset of the genomes contained in your database, use the flag `--genome-names`. You can provide a comma-delimited list of genome names or a flat text file that contains one genome per line. Alternatively, you could provide a list of gene-caller-ids as specified above. 

You also have the option to report the output in [gff3 format](https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md), report extended deflines for each gene, or report amino acid sequences instead of nucleotide sequences.
This program computes the average nucleotide identity between reads in a single fasta file (using PyANI). 

To compute the ANI (or other genome distance metrics) between two genomes in different fasta files, use %(anvi-compute-genome-similarity)s. 

A default run of this program looks like this: 

{{ codestart }}
anvi-script-compute-ani-for-fasta -f %(fasta)s \ 
                                  -o path/to/output \
                                  --method ANIb
{{ codestop }}

By default, the PyANI method is ANIb (which aligns 1020 nt fragments of your sequences using BLASTN+). You can switch to ANIm, ANIblastall, or TETRA if desired. See the [PyANI documentation](https://github.com/widdowquinn/pyani) for more informaiton. 

You also have the option to change the distance metric (from the default "euclidean") or the linkage method (from the default "ward") or provide a path to a log file for debug messages. 
A helper script to process CheckM tree output to generate files compatible with %(anvi-interactive)s.

An example use:

{{ codestart }}
anvi-script-checkm-tree-to-interactive -t CheckM_concatenated.tree \
                                       -o OUTPUT_PATH
cd OUTPUT_PATH/
anvi-interactive -p PROFILE.db \
                 -t newick.tree \
                 -d view_data.txt \
                 --manual
{{ codestop }}
This program **produces a %(bam-stats-txt)s from one or more %(bam-file)s given a %(contigs-db)s**. It is designed to serve people who only need to process read recruitment data stored in a %(bam-file)s to recover coverage and detection statistics (along with others) for their genes and/or contigs, and will report what's going on nicely with memory usage information and estimated time of completion:

[![anvi-profile-blitz](../../images/anvi-profile-blitz.png){:.center-img}](../../images/anvi-profile-blitz.png)

There are other programs in anvi'o software ecosystem that are similar to this one:

* %(anvi-profile)s also takes a %(bam-file)s and profiles it. **They both require a %(contigs-db)s**. But while %(anvi-profile)s produces a %(single-profile-db)s for downstream analyses in anvi'o, %(anvi-profile-blitz)s produces text files for downstream analyses by the user (via R, Python, or other solutions). In contrast to %(anvi-profile)s, %(anvi-profile-blitz)s is orders of magnitude faster with similar memory usage.

* %(anvi-script-get-coverage-from-bam)s also takes a %(bam-file)s and profiles it. **They both produce text output files.** But while %(anvi-script-get-coverage-from-bam)s does not require a %(contigs-db)s, %(anvi-profile-blitz)s requires one to work. They will both run very rapidly, %(anvi-script-get-coverage-from-bam)s will work with much smaller amount of memory.

## Output files

For output file formats, please see %(bam-stats-txt)s.

## Running

You can use this program with one or more BAM files to recover minimal or extended statistics for contigs or genes in a %(contigs-db)s.

{:.warning}
Since the program will not be able to ensure the %(contigs-db)s was generated from the same %(contigs-fasta)s that was used for read recruitment that resulted in %(bam-file)ss for analysis, you can make serious mistakes unless you mix up your workflow and start profiling BAM files that have nothing to do with a %(contigs-db)s. If you make a mistake like that, in the best case scenario you will get an empty output file because the program will skip all contigs with non-matching name. In the worst case scenario you will get a file if some names in %(contigs-db)s incorrectly matches to some names in the %(bam-file)s. While this warning may be confusing, you can avoid all these if you use the SAME FASTA FILE both as reference for read recruitment and as input for %(anvi-gen-contigs-database)s.

### Contigs mode, default output

Profile contigs, produce a default output:

{{ codestart }}
anvi-profile-blitz %(bam-file)s \
                   -c %(contigs-db)s \
                   -o OUTPUT.txt
{{ codestop }}

This example is with a single BAM file, but you can also have multiple BAM files as a parameter by using wildcards,

{{ codestart }}
anvi-profile-blitz *.bam \
                   -c %(contigs-db)s \
                   -o OUTPUT.txt
{{ codestop }}

or by providing multiple paths:

{{ codestart }}
anvi-profile-blitz /path/to/SAMPLE-01.bam \
                   /path/to/SAMPLE-02.bam \
                   /another/path/to/SAMPLE-03.bam
                   -c %(contigs-db)s \
                   -o OUTPUT.txt
{{ codestop }}

### Contigs mode, minimal output

Profile contigs, produce a minimal output. This is the fastest option:

{{ codestart }}
anvi-profile-blitz %(bam-file)s \
                   -c %(contigs-db)s \
                   --report-minimal \
                   -o OUTPUT.txt
{{ codestop }}

### Genes mode, default output

Profile genes, produce a default output:

{{ codestart }}
anvi-profile-blitz %(bam-file)s \
                   -c %(contigs-db)s \
                   --gene-mode \
                   -o OUTPUT.txt
{{ codestop }}

### Genes mode, minimal output

Profile genes, produce a default output:

{{ codestart }}
anvi-profile-blitz %(bam-file)s \
                   -c %(contigs-db)s \
                   --gene-mode \
                   --report-minimal \
                   -o OUTPUT.txt
{{ codestop }}


## Performance

The memory use will be correlated linaerly with the size of the %(contigs-db)s, but once everything is loaded, the memory usage will not increase substantially over time.

With the flag `--report-minimal`, %(anvi-profile-blitz)s profiled on a laptop computer 100,000 contigs that contained 1 billion nts in 6 minutes and used  ~300 Mb memory. This contigs database had 1.5 million genes, and memory usage increased to 1.7 Gb when %(anvi-profile-blitz)s run in `--gene-mode`. The flag `--gene-mode` does not change time complexity dramatically.

Anvi'o has this program because [Emile Faure](https://twitter.com/faureemile) presented us with a [challenge](https://anvio.slack.com/archives/C8SFMGYF3/p1631723790065300): Emile had a ~140 Gb anvi'o %(contigs-db)s that contained nearly 70 million contig sequences from over 200 single-assembled metagenomes, and wanted to learn the coverages of each gene in the contigs database in 200 metagenomes individually. Yet the combination of %(anvi-profile)s and %(anvi-summarize)s jobs would take **more than 40 days** to complete. Since all Emile needed was to learn the coverages from BAM files, we implemented %(anvi-profile-blitz)s to skip the profiling step. The run took **8 hours to compute and report coverage values for 175 million genes in 70 million contigs**, and the memory use remained below 200 Gb.

This program takes the variability data stored within a %(profile-db)s and compiles it from across samples into a single matrix that comprehensively describes your SNVs, SCVs or SAAVs (a %(variability-profile-txt)s).  

This program is described on [this blog post](http://merenlab.org/2015/07/20/analyzing-variability/#the-anvio-way), so take a look at that for more details. 

## Let's talk parameters 

Here is a basic run with no bells or whisles: 

{{ codestart }}
anvi-gen-variability-profile -p %(profile-db)s \
                             -c %(contigs-db)s \ 
                             -C DEFAULT \
                             -b EVERYTHING
{{ codestop }}

Note that this program requires you to specify a subset of the databases that you want to focus on, so to focus on everything in the databases, run %(anvi-script-add-default-collection)s and use the resulting %(collection)s and %(bin)s, as shown above. 

You can add structural annotations by providing a %(structure-db)s. 

{{ codestart }}
anvi-gen-variability-profile -p %(profile-db)s \
                             -c %(contigs-db)s \
                             -C DEFAULT \
                             -b EVERYTHING \
                             -s %(structure-db)s 
{{ codestop }}

### Focusing on a subset of the input 

Instead of focusing on everything (providing the collection `DEFAULT` and the bin `EVERYTHING`), there are three ways to focus on a subset of the input: 

1. Provide a list of gene caller IDs (as a parameter with the flag `--gene-caller-ids` as shown below, or as a file with the flag `--genes-of-interest`)

    {{ codestart }}
    anvi-gen-variability-profile -p %(profile-db)s \
                                 -c %(contigs-db)s \
                                 --gene-caller-ids 1,2,3
    {{ codestop }}

2. Provide a %(splits-txt)s to focus only on a specific set of splits. 

    {{ codestart }}
    anvi-gen-variability-profile -p %(profile-db)s \
                                 -c %(contigs-db)s \
                                 --splits-of-intest %(splits-txt)s
    {{ codestop }}
    
3. Provide some other %(collection)s and %(bin)s. 

    {{ codestart }}
    anvi-gen-variability-profile -p %(profile-db)s \
                                 -c %(contigs-db)s \ 
                                 -C %(collection)s \
                                 -b %(bin)s
    {{ codestop }}

### Additional ways to focus the input 

When providing a %(structure-db)s, you can also limit your analysis to only genes that have structures in your database. 

{{ codestart }}
anvi-gen-variability-profile -p %(profile-db)s \
                             -c %(contigs-db)s \
                             -s %(structure-db)s \
                             --only-if-structure
{{ codestop }}

You can also choose to look at only data from specific samples by providing a file with one sample name per line. For example

{{ codestart }}
anvi-gen-variability-profile -p %(profile-db)s \
                             -c %(contigs-db)s \
                             -C %(collection)s \
                             -b %(bin)s \
                             --samples-of-interest my_samples.txt
{{ codestop }}

where `my_samples.txt` looks like this:

{{ codestart }}
DAY_17A
DAY_18A
DAY_22A
...
{{ codestop }}

### SNVs vs. SCVs vs. SAAVs 

Which one you're analyzing depends entirely on the `engine` parameter, which you can set to `NT` (nucleotides), `CDN` (codons), or `AA` (amino acids). The default value is nucleotides. Note that to analyze SCVs or SAAVs, you'll have needed to use the flag `--profile-SCVs` when you ran %(anvi-profile)s.

For example, to analyze SAAVs, run

{{ codestart }}
anvi-gen-variability-profile -p %(profile-db)s \
                             -c %(contigs-db)s \
                             -C %(collection)s \
                             -b %(bin)s \
                             --engine AA
{{ codestop }}

To analyze SCVs, run

{{ codestart }}
anvi-gen-variability-profile -p %(profile-db)s \
                             -c %(contigs-db)s \
                             -C %(collection)s \
                             -b %(bin)s \
                             --engine CDN
{{ codestop }}

### Filtering the output 

You can filter the output in various ways, so that you can get straight to the variability positions that you're most interested in. Here are some of the filters that you can set:

* The maximum number of variable positions that can come from a single split (e.g. to look at a max of 100 SCVs from each split, randomly sampled)
* The maximum and minimum departure from the reference or consensus
* The minimum coverage value in all samples (if a position is covered less than that value in _one_ sample, it will not be reported for _all_ samples)


### --quince-mode

You can also set `--quince-mode`, which reports the variability data across all samples for each position reported (even if that position isn't variable in some samples). For example, if nucleotide position 34 of contig 1 was a SNV in one sample, the output would contain data for nucleotide position 34 for all of your samples. 

### --kiefl-mode

The default behavior is to report codon/amino-acid frequencies only at positions where variation was reported during profiling (which by default uses some heuristics to minimize the impact of error-driven variation). Fair enough, but for some diabolical cases, you may want to report _even_ invariant positions. When this flag is used, all positions are reported, regardless of whether they contained variation in any sample. The reference codon for all such entries is given a codon frequency of 1. All other entries (aka those with legitimate variation to be reported) remain unchanged. This flag can only be used with `--engine AA` or `--engine CDN` and is incompatible wth `--quince-mode`.

This flag was added in this [pull request](https://github.com/merenlab/anvio/pull/1794) where you can read about all of the tests that were performed to ensure this mode is behaving properly.

### Adding additional information

You can also ask the program to report the contig names, split names, and gene-level coverage statistics, which appear as additional columns in the output.


This lets you inspect a single split across your samples. This interface can also be opened from the %(anvi-interactive)s interface by asking for details about a specific split.

From this view, you can clearly see the coverage and detection across your split, all SNVs, and the genes identified within your split and their functional annotations. You can also  easily compare all of this data across all of the samples that this split is present in.  

To run this program, just provide a %(profile-db)s and %(contigs-db)s pair and a single split name to inspect. 

{{ codestart }}
anvi-inspect -p %(profile-db)s \
             -c %(contigs-db)s \ 
             --split-name Day17a_QCcontig9_split_00003
{{ codestop }}

You can also choose to hide SNVs marked as outliers or configure the server in various ways. 
The input for this program is a %(contigs-fasta)s, which should contain one or more sequences. These sequences may belong to a single genome or could be contigs obtained from an assembly.

Make sure the input file matches the requirements of a %(contigs-fasta)s. If you are planning to use the resulting contigs-db with %(anvi-profile)s, it is essential that you convert your %(fasta)s file to a properly formatted %(contigs-fasta)s *before* you perform the read recruitment.

An anvi'o contigs database will keep all the information related to your sequences: positions of open reading frames, k-mer frequencies for each contig, functional and taxonomic annotation of genes, etc. The contigs database is one of the most essential components of anvi'o.

When run on a %(contigs-fasta)s this program will,

* **Compute k-mer frequencies** for each contig (the default is `4`, but you can change it using `--kmer-size` parameter if you feel adventurous).

* **Soft-split contigs** longer than 20,000 bp into smaller ones (you can change the split size using the `--split-length` flag). When the gene calling step is not skipped, the process of splitting contigs will consider where genes are and avoid cutting genes in the middle. For very, very large assemblies this process can take a while, and you can skip it with `--skip-mindful-splitting` flag.

* **Identify open reading frames** using [Prodigal](http://prodigal.ornl.gov/), UNLESS, (1) you have used the flag `--skip-gene-calling` (no gene calls will be made) or (2) you have provided %(external-gene-calls)s.


### Create a contigs database from a FASTA file

{{ codestart }}
anvi-gen-contigs-database -f %(contigs-fasta)s \
                          -o %(contigs-db)s
{{ codestop }}

### Create a contigs database with external gene calls

{{ codestart }}
anvi-gen-contigs-database -f %(contigs-fasta)s \
                          -o %(contigs-db)s \
                          --external-gene-calls %(external-gene-calls)s
{{ codestop }}

See %(external-gene-calls)s for the description and formatting requirements of this file.

If user-provided or anvi'o-calculated amino acid sequences contain internal stop codons, anvi'o will yield an error. The following command will persist through this error:

{{ codestart }}
anvi-gen-contigs-database -f %(contigs-fasta)s \
                          -o %(contigs-db)s \
                          --external-gene-calls %(external-gene-calls)s \
                          --ignore-internal-stop-codons
{{ codestop }}

This program predicts per-residue binding scores for genes in your %(contigs-db)s via the [InteracDome](https://interacdome.princeton.edu/) database.


The full process is detailed in [this blog post](https://merenlab.org/2020/07/22/interacdome/). In fact, ideally, all of that information should really be in this very document, but because the blogpost has preceded this document, it hasn't been translated over yet. So really, you should really be reading that blogpost if you want to get into the nitty gritty details. Otherwise, the quick reference herein should be sufficient.


In summary, this program runs an HMM search of the genes in your %(contigs-db)s to all the Pfam gene families that have been annotated with InteracDome binding frequencies. Then, it parses and filters results, associates binding frequencies of HMM match states to the user's genes of interest, and then stores the resulting per-residue binding frequencies for each gene into the %(contigs-db)s as %(misc-data-amino-acids)s.


Before running this program, you'll have to run %(anvi-setup-interacdome)s to set up a local copy of [InteracDome's tab-separated files](https://interacdome.princeton.edu/#tab-6136-4).



## Basic Usage

A basic run of this program looks like this:

{{ codestart }}
anvi-run-interacdome -c %(contigs-db)s -T 4
{{ codestop }}

In addition to storing per-residue binding frequencies as %(misc-data-amino-acids)s in your %(contigs-db)s, this also outputs additional files prefixed with `INTERACDOME` by default (the prefix can be changed with `-O`). These are provided as %(binding-frequencies-txt)s files named `INTERACDOME-match_state_contributors.txt` and `INTERACDOME-domain_hits.txt`. See %(binding-frequencies-txt)s for details.


## Parameters

[InteracDome](https://interacdome.princeton.edu/) offers two different binding frequency datasets that can be chosen with `--interacdome-dataset`.  Choose 'representable' to include Pfams that correspond to domain-ligand interactions that had nonredundant instances across three or more distinct PDB structures. InteracDome authors recommend using this collection to learn more about domain binding properties. Choose 'confident' to include Pfams that correspond to domain-ligand interactions that had nonredundant instances across three or more distinct PDB entries and achieved a cross-validated precision of at least 0.5. The default is 'representable', and you can change it like so:


{{ codestart }}
anvi-run-interacdome -c %(contigs-db)s \
                     --interacdome-dataset confident
{{ codestop }}

This progarm is multi-threaded, so be sure to make use of it:

{{ codestart }}
anvi-run-interacdome -c %(contigs-db)s \
                     --interacdome-dataset confident \
                     -T 8
{{ codestop }}

Additionally, there are numerous thresholds that you can set: 

1. [`--min-binding-frequency` to ignore very low frequencies](https://merenlab.org/2020/07/22/interacdome/#filtering-low-binding-frequency-scores). The InteracDome scale is from 0 (most likely not involved in binding) to 1 (most likely involved in binding). The default cutoff is 0.200000. 
2. [`--min-hit-fraction` to remove poor quality HMM hits]((https://merenlab.org/2020/07/22/interacdome/#filtering-partial-hits)). The default value is 0.5, so at least half of a profile HMM's length must align to your gene, otherwise the hit will be discarded.
3. [`--information-content-cutoff` to ignore low-qulaity domain hits](https://merenlab.org/2020/07/22/interacdome/#filtering-bad-hits-with-information-content). The default value is 4, which means every amino acid of your gene must match the consensus amino acid of the match state for each mate state with [information content](https://en.wikipedia.org/wiki/Sequence_logo) greater than 4. Decreasing this cutoff yields an increasingly stringent filter.


This program lets you export selections of your %(contigs-db)s around all occurances of a user-defined anchor gene. 

The output of this is a folder that contains a separate %(contigs-db)s for the region around each hit of the anchor gene. (In fact, you'll get a FASTA file, %(contigs-db)s, %(profile-db)s, and a copy of the runlog).

For example, you could specify the recognition site for a specific enzyme and use this program to pull out all potential sites where that enzyme could bind. 

### Required Parameters

You'll need to provide a %(contigs-db)s (of course), as well as the name of the output directory and a prefix to use when naming all of the output databases. 

You can define the region of interest either by defining the two flanking genes or by searching for an anchor gene and defining a number of genes around this gene that you want to look at. For example, if you set `num-genes` as 1, then each locus will contain the gene of interest, a gene upstream of it, and a gene downstream of it, for a total of three genes. 

### Defining the region of interest

There are four ways to indicate the desired anchor gene:

1. Provide a search term in the functional annotations of all of your genes. (If you're trying to find a gene with a vague function, you might want to use %(anvi-search-functions)s to find out which genes will show up first. Alternatively, you can you %(anvi-export-functions)s to look at a full list of the functional annotaitons in this database). 

    {{ codestart }}
    anvi-export-locus -c %(contigs-db)s \
                      --num-genes 2 \
                      -o GLYCO_DIRECTORY \
                      -O Glyco \
                      --search-term "Glycosyltransferase involved in cell wall bisynthesis" \ 
    {{ codestop }}
    
    You also have the option to specify an annotation source with the flag `--annotation source`

2.  Provide a specific gene caller ID. 

    {{ codestart }}
    anvi-export-locus -c %(contigs-db)s \
                      --num-genes 2 \
                      -o output_directory \
                      -O GENE_1 \
                      --gene-caller-ids 1
    {{ codestop }}

3. Provide a search term for the HMM source annotations. To do this, you must also specify an hmm-source. (You can use the flag `--list-hmm-sources` to list the available sources). 

    {{ codestart }}
    anvi-export-locus -c %(contigs-db)s \
                      --num-genes 2 \
                      -o Ribosomal_S20p \
                      -O Ribosomal_S20p \
                      --use-hmm \
                      --hmm-source Bacteria_71 \
                      --search-term Ribosomal_S20p
    {{ codestop }}
    
    4. Run in `flank-mode` and provide two flanking genes that define the locus region.
    
    {{ codestart }}
    anvi-export-locus -c %(contigs-db)s \
                      --flank-mode \
                      -o locus_output \
                      -O gyclo_to_acyl \
                      --search-term "Glycosyltransferase involved in cell wall bisynthesis","Acyl carrier protein" \ 
    {{ codestop }}

### Additional Options 

You can also remove partial hits, ignore reverse complement hits, or overwrite all files in a pre-existing output. 

This program uses the user's similarity metric of choice to calculate the similarity between the input genomes.

The currently available programs for calculating similarity metrics include, chosen can be chosen with `--program`:
- [PyANI](https://github.com/widdowquinn/pyani)) to calculate the average nucleotide identity (ANI) (i.e. what portion of orthologous gene pairs align)
- [fastANI](https://github.com/ParBLiSS/FastANI) also to calcualte the ANI but at a faster speed (at the drawback of a slight reduction in accuracy)
- [sourmash](https://sourmash.readthedocs.io/en/latest/) to calculate the mash distance between genomes.  Though we provide this option, we don't recommend using sourmash for genome comparisons--it excels at other tasks--yet it remains as a legacy option.

### Input/Output

The expected input is any combination of %(external-genomes)s, %(internal-genomes)s, and text files that contains paths to %(fasta)s files that describe each of your genomes. This is a tab-delimited file with two columns (`name` and `path` to the fasta files, each of which is assumed to be a single genome).


The program outputs a directory with %(genome-similarity)s data. The specific contents will depend on how similarity scores are computed (specified with `--program`), but generally contains tab-separated files of similarity scores between genomes and related metrics.


You also have the option to provide a %(pan-db)s, in which case the output data will additionally be stored in the database as %(misc-data-layers)s and %(misc-data-layer-orders)s data. This was done in the [pangenomic tutorial](http://merenlab.org/2016/11/08/pangenomics-v2/#computing-the-average-nucleotide-identity-for-genomes-and-other-genome-similarity-metrics-too).  

Here is an example run with pyANI from an %(external-genomes)s without any parameter changes: 

{{ codestart }}
anvi-compute-genome-similarity -e %(external-genomes)s \
                               -o path/for/%(genome-similarity)s \
                               --program pyANI
{{ codestop }}

### Genome similarity metrics: parameters

Parameters have been divided up based on which `--program` you use.

#### pyANI

You have the option to change any of the follow parameters:

- The method used for alignment. The options are:
    - `ANIb` (default): uses [BLASTN](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome)+ to align 1020 nt fragments of the inputs
    - `ANIm`: uses [MUMmer](http://mummer.sourceforge.net/) to align
    - `ANIblastall`: Uses legacy [BLASTN](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome) to align 1020 nt fragments
    - `TETRA`: Alignment free. This calculates similarity scores by comparing tetranucleotide frequencies for each input

- The minimum alignment fraction (all percent identity scores lower than this will be set to 0). The default is 0.


- If you want to keep alignments that are long, despite them not passing the minimum alignment fraction filter, you can supply a `--significant-alignment-length` to override `--min-alignment-fraction`.


- Similarly, you can discard all results less than some full percent identity (percent identity of aligned segments * aligned fraction).


#### fastANI

You can change any of the following fastANI parameters:

* The kmer size. The default is 16.

* The fragment length. The default is 30.

* The minimum number of fragments for a result to count. The default is 50.

#### sourmash

You have the option to change the `kmer-size`. This value should depend on the relationship between your samples. The default is 31 ([as recommended by sourmash for genus-level distances](https://sourmash.readthedocs.io/en/latest/using-sourmash-a-guide.html), but we found that 13 most closely parallels the results from an ANI alignment.  

You can also set the compression ratio for your fasta files. Decreasing this from the default (1000) will decrease sensitivity.  

### Other Parameters 

Once calculated, the similarity matrix is used to create dendrograms via hierarchical clustering, which are stored in the output directory (and in the %(pan-db)s, if provided). You can choose to change the distance metric or linkage algorithm used for this clustering.


If you're getting a lot of debug/output messages, you can turn them off with `--just-do-it` or helpfully store them into a file with `--log-file`.



This program outputs a file that denotes which contigs and splits are part of which %(collection-txt)s files. This just tells you which collections each of your contigs are a part of, which can be imported as  acategorical layer with %(anvi-import-misc-data)s. 

This is not super useful, but it is used in the Infant gut tutorial [here](http://merenlab.org/tutorials/infant-gut/#comparing-multiple-binning-approaches). 
This program allows you to import a %(state)s from a %(state-json)s.

You can run this program on a %(profile-db)s or %(pan-db)s like so: 

{{ codestart }}
anvi-import-state -p %(profile-db)s \
                  -s %(state-json)s \
                  -n MY_STATE
{{ codestop }}

This will import the state described in your %(state-json)s into your %(profile-db)s with the name `MY_STATE`. 
This program **analyzes a tRNA-seq library, generating de novo predictions of tRNA sequences, structures, and modification positions**.

A FASTA file of merged paired-end tRNA-seq reads is required as input. This file is produced by the initial steps of the %(trnaseq-workflow)s, in which [Illumina-utils](https://github.com/merenlab/illumina-utils), merges paired-end reads and %(anvi-script-reformat-fasta)s creates anvi'o-compliant deflines in the FASTA file.

The primary output of anvi-trnaseq is a %(trnaseq-db)s. Supplemental outputs are also produced -- an analysis summary, a tabular file of unique sequences not identified as tRNA, an a tabular file of 5' and 3' extensions trimmed off mature tRNA.

The `anvi-trnaseq --help` menu provides detailed explanations of the parameters controlling the multifacted analyses performed by the program.

## Examples

*Generate a %(trnaseq-db)s from a sample using 16 cores.*

{{ codestart }}
anvi-trnaseq -f %(trnaseq-fasta)s \
             -S SAMPLE_NAME \
             -o OUTPUT_DIRECTORY \
             -T 16
{{ codestop }}

*Generate a %(trnaseq-db)s from a sample flagged as being treated with demethylase. The output directory is overwritten if it already exists.*

{{ codestart }}
anvi-trnaseq -f %(trnaseq-fasta)s \
             -S SAMPLE_NAME \
             -o OUTPUT_DIRECTORY \
             -T 16 \
             --treatment demethylase \
             --overwrite-output-destinations
{{ codestop }}

## Parameterize tRNA feature profiling

Feature profiling parameters can be modified by the user by in an optional `.ini` file. For example, the user may want a more permissive definition of a tRNA (more false positive identifications of sequences as tRNA, fewer false negative failures to identify sequences as tRNA), increasing the number of unpaired nucleotides allowed in the T stem or increasing the number of unconserved canonical nucleotides allowed in the anticodon loop. Numerous structural parameters like these can be altered.

*Write the `.ini` file to `param.ini`.*

{{ codestart }}
anvi-trnaseq --default-feature-param-file PARAM.ini
{{ codestop }}

*Nicely display the `.ini` defaults that can be written to the file in standard output.*

{{ codestart }}
anvi-trnaseq --print-default-feature-params
{{ codestop }}
Suppose you have downloaded some genomes from NCBI (using [this](https://github.com/kblin/ncbi-genome-download) incredibly useful program) and you have a metadata table describing those genomes. This program will convert that metadata table into some useful files, namely: a FASTA file of contig sequences, an external gene calls file, and an external functions file for each genome you have downloaded; as well as a single tab-delimited fasta-txt file (like the one shown [here](https://merenlab.org/2018/07/09/anvio-snakemake-workflows/#fastatxt)) describing the path to each of these files for all downloaded genomes (that you can pass directly to a snakemake workflow if you need to). Yay.

### The metadata file

The prerequisite for running this program is to have a tab-delimited metadata file containing information about each of the genomes you downloaded from NCBI. Let's say your download command started like this: `ncbi-genome-download --metadata-table ncbi_metadata.txt -t ....` So for the purposes of this usage tutorial, your metadata file is called `ncbi_metadata.txt`.

In case you are wondering, that file should have a header that looks something like this:
```
assembly_accession	bioproject	biosample	wgs_master	excluded_from_refseq	refseq_category	relation_to_type_material	taxid	species_taxid	organism_name	infraspecific_name	isolate	version_status	assembly_level	release_type	genome_rep	seq_rel_dateasm_name	submitter	gbrs_paired_asm	paired_asm_comp	ftp_path	local_filename
```

### Basic usage

If you run this, all the output files will show up in your current working directory.

{{ codestart }}
anvi-script-process-genbank-metadata -m ncbi_metadata.txt
{{ codestop }}

### Choosing an output directory

Alternatively, you can specify a directory in which to generate the output:

{{ codestart }}
anvi-script-process-genbank-metadata -m ncbi_metadata.txt -o DOWNLOADED_GENOMES
{{ codestop }}

### Picking a name for the fasta-txt file

The default name for the fasta-txt file is `fasta-input.txt`, but you can change that with the `--output-fasta-txt` parameter.

{{ codestart }}
anvi-script-process-genbank-metadata -m ncbi_metadata.txt --output-fasta-txt ncbi_fasta.txt
{{ codestop }}

### Make a fasta-txt without the gene calls and functions columns

The default columns in the fasta-txt file are:
```
name	path	external_gene_calls	gene_functional_annotation
```

But sometimes, you don't want your downstream snakemake workflow to use those external gene calls or functional annotations files. So to skip adding those columns into the fasta-txt file, you can use the `-E` flag:
{{ codestart }}
anvi-script-process-genbank-metadata -m ncbi_metadata.txt --output-fasta-txt ncbi_fasta.txt -E
{{ codestop }}

Then the fasta-txt will only contain a `name` column and a `path` column.
This program gets the coverage values from a %(bam-file)s, and puts them into a %(coverages-txt)s. 

You must provide a BAM file, but there are three ways you can choose contigs to analyze within that file: 
1. Give a contig name. Here, you can only report coverage per nucleotide position (In this example, the user is specifically asking for this anyway with the `-m` flag)

    {{ codestart }}
    anvi-script-get-coverage-from-bam -b %(bam-file)s \ 
                                     -c NAME_OF_CONTIG \ 
                                     -m pos
    {{ codestop }}

2. Give a file that contains a list of contigs (one per line; same format as the `--contigs-of-interest` tag for %(anvi-profile)s). Here, you can ask for the contig averages (as in this example) or nucleotide position coverage. 

    {{ codestart }}
    anvi-script-get-coverage-from-bam -b %(bam-file)s \ 
                                     -l NAME_OF_FILE \
                                     -m contig
    {{ codestop }}

3. Give a %(collection-txt)s file for the program to determine the coverage for all contigs in those bins. Here, you can ask for the contig averages, nucleotide position coverage or coverage per bin (as in this example). 

    {{ codestart }}
    anvi-script-get-coverage-from-bam -b %(bam-file)s \ 
                                     -C %(collection-txt)s \
                                     -m bin
    {{ codestop }}

This program **lists the additional data** that is stored within a %(pan-db)s, %(profile-db)s or %(contigs-db)s. This is data that can be imported with %(anvi-import-misc-data)s and is displayed in the interactive interface. 

When run, this program will output to the terminal a list of all additional data tables that are stored within the database. If you want to export a specific element of these as a text file, see %(anvi-export-misc-data)s. 

### What is displayed? 

When running on a %(profile-db)s or %(pan-db)s, the output will display the following types of data:

- %(misc-data-items)s 
- %(misc-data-layers)s
- %(misc-data-layer-orders)s (by default, this will include orders like `abundance` and `mean_coverage (newick)`)

When running on a %(contigs-db)s, the output will display the following types of data:

- %(misc-data-nucleotides)s 
- %(misc-data-amino-acids)s 

These have no default values and will only contain data that has been imported with %(anvi-import-misc-data)s. 

You also have the option to specify a specific kind of additional data table with `-t`. For example, to view only %(misc-data-items)s in a %(profile-db)s, just call

{{ codestart }}
anvi-show-misc-data -p %(profile-db)s \
                    -t items 
{{ codestop }}

Similarly to importing and exporting additional data tables, you can also focus on a specific data group with the parameter `-D`.
This program lets you **bring additional information into your anvi'o databases** that will appear when you run %(anvi-interactive)s.   

With this, you can 
- **bring additional data about your items or layers into the anvi'o interactive interface** by putting it into a %(pan-db)s or %(profile-db)s
- **bring additional data about your nucleotides/amino acids** into a %(contigs-db)s 

You also have the option to associate keys with only a specific data group, or transpose the input before processing (in case you misformatted it). 

If you no longer want to see data you've added with this function, you can export it as the original text file with %(anvi-export-misc-data)s and delete it from the database with %(anvi-delete-misc-data)s.

## Items, Layers, and the Interactive Interface 

{:.notice}
This process, as well as the definition of an item and a layer, are described in more detail in [this blog post](http://merenlab.org/2017/12/11/additional-data-tables). 

Basically, you can add additional information to the interactive interface by running this program on the database you want to display and a text file containing your information. You can do this with three types of data (see their individual pages for more information on each): 

1. %(misc-data-items)s by providing a %(misc-data-items-txt)s. This contains information about *each of your items in the central tree* (whether those are contigs, bins, or genes), and will appear as **additional concentric circles** when you run %(anvi-interactive)s. 

    {{ codestart }}
    anvi-import-misc-data -p %(profile-db)s \
                          -t items \
                          %(misc-data-items-txt)s 
    {{ codestop }}
        
2. %(misc-data-layers)s by providing a %(misc-data-layers-txt)s. This contains information about *each layer (or concentric circle) of the interface* (which usually correspond to your samples), and will appear as **graphs in line with your circles of data** (on the right, similar to how to the titles of each layer are displayed at the top) when you run %(anvi-interactive)s. 

    {{ codestart }}
    anvi-import-misc-data -p %(pan-db)s \
                          -t layers \
                          %(misc-data-layers-txt)s                               
    {{ codestop }}

3. %(misc-data-layer-orders)s by providing a %(misc-data-layer-orders-txt)s. This contains information about *what order you want the concentric circles to be displayed in*  (which usually correspond to your samples), and will appear as **above the misc-data-layers graphs as a tree** when you run %(anvi-interactive)s. 

    {{ codestart }}
    anvi-import-misc-data -p %(profile-db)s \
                          -t layer_orders \
                          %(misc-data-layer-orders-txt)s 
    {{ codestop }}

## Nucleotides, Amino Acids, and Contigs Databases

This feature lets you import additional data about specfic residues or specific base pairs into your %(contigs-db)s. This is especially useful for strucutral analysis (so when running programs like %(anvi-display-structure)s) and will be very relevant to the InteracDome functionality when it's added in anvi'o v7 (curious readers can take a look at [this blog post](http://merenlab.org/2020/07/22/interacdome/)). 

When adding additional data, unlike with layers and items, you do not have to provide values for every single nucleotide in your database. With this program, you can easily provide data for only a select few. 

Basically, you can add two types of data to your contigs database:

1. %(misc-data-nucleotides)s by providing a %(misc-data-nucleotides-txt)s. This contains information about *specific nucleotides in your database.*

    {{ codestart }}
    anvi-import-misc-data -c %(contigs-db)s \
                          -t nucleotides \
                          %(misc-data-nucleotides-txt)s 
    {{ codestop }}
        
2. %(misc-data-amino-acids)s by providing a %(misc-data-amino-acids-txt)s. This contains information about *specific amino acid residues in your database*

    {{ codestart }}
    anvi-import-misc-data -c %(contigs-db)s \
                          -t amino_acids \
                          %(misc-data-amino-acids-txt)s                               
    {{ codestop }}
This program computes metabolic module enrichment across groups of genomes or metagenomes and returns a %(functional-enrichment-txt)s file (throughout this text, we will use the term genome to describe both for simplicity).

{:.warning}
For its sister programs, see %(anvi-compute-functional-enrichment-in-pan)s and %(anvi-compute-functional-enrichment-across-genomes)s.

## Module enrichment

To run this program, you must already have estimated the completeness of metabolic modules in your genomes using the program %(anvi-estimate-metabolism)s and obtained a "modules" mode output file (which is the default output mode of that program). In addition to that, you will need to provide a %(groups-txt)s file to declare which genome belongs to which group for enrichment analysis to consider.

### How does it work?

1. **Determine the presence of modules**. Each module in the "modules" mode output has a completeness score associated with it in each genome, and any module with a completeness score over a given threshold (set by `--module-completion-threshold`) will be considered to be *present* in that genome.

2. **Quantify the distribution of modules in each group of genomes**. The distribution of a given module across genomes in each group will determine its enrichment. This is done by fitting a generalized linear model (GLM) with a logit linkage function in `anvi-script-enrichment-stats`, and it produces a %(functional-enrichment-txt)s file.

{:.notice}
The script `anvi-script-enrichment-stats` was implemented by [Amy Willis](https://github.com/adw96), and described first in [this paper](https://doi.org/10.1186/s13059-020-02195-w).

### Basic usage

See %(kegg-metabolism)s or %(user-metabolism)s for more information on how to generate a "modules" mode output format from %(anvi-estimate-metabolism)s. Please note that the genome names in the modules file must match those that you will mention in the %(groups-txt)s file.

{{ codestart }}
anvi-compute-metabolic-enrichment -M MODULES.TXT \
                                  -G %(groups-txt)s \
                                  -o %(functional-enrichment-txt)s
{{ codestop }}

### Additional parameters

The default completeness threshold for a module to be considered 'present' in a genome is 0.75 (=75%%). If you wish to change this, you can do so by providing a different threshold between (0, 1], using the `--module-completion-threshold` parameter:

{{ codestart }}
anvi-compute-metabolic-enrichment -M MODULES.TXT \
                                  -G %(groups-txt)s \
                                  -o %(functional-enrichment-txt)s \
                                  --module-completion-threshold 0.9
{{ codestop }}

By default, the column containing genome names in your MODULES.TXT file will have the header `db_name`, **but there are certain cases in which you might have them in a different column name for your genomes or metagenomes** (such as those cases where you did not run %(anvi-estimate-metabolism)s in multi-mode). In those cases, you can tell this program to look for a *different* column name to find your genomes or metagenomes using the `--sample-header`. For example, if your metagenome names are listed under the `metagenome_name` column, you would do the following:

{{ codestart }}
anvi-compute-metabolic-enrichment -M MODULES.TXT \
                                  -G %(groups-txt)s \
                                  -o %(functional-enrichment-txt)s \
                                  --sample-header metagenome_name
{{ codestop }}

If you ran %(anvi-estimate-metabolism)s on a bunch of extra genomes but only want to include a subset of them in the %(groups-txt)s, that is fine. By default, any samples from the `MODULES.TXT` file that are missing from the %(groups-txt)s will be **ignored**. However, there is also an option to include those missing samples in the analysis, as one big group called 'UNGROUPED'. To do this, you can use the `--include-samples-missing-from-groups-txt` parameter. Just be careful that if you are also using the `--include-ungrouped` flag (see below), any samples without a specified group in the %(groups-txt)s will also be included in the 'UNGROUPED' group.

{{ codestart }}
anvi-compute-metabolic-enrichment -M MODULES.TXT \
                                  -G %(groups-txt)s \
                                  -o %(functional-enrichment-txt)s \
                                  --include-samples-missing-from-groups-txt
{{ codestop }}
This program finds all short reads from (%(bam-file)s) that align to a specific gene and returns them as a %(short-reads-fasta)s.

If instead you want to extract these short reads from a FASTQ file, get your gene sequence with %(anvi-export-gene-calls)s and take a look at %(anvi-script-get-primer-matches)s.

To run this program, just specify the bam files you're looking at and the gene of interest. To do this, name the %(contigs-db)s containing your gene and the gene caller ID (either directly through the parameter `--gene-caller-id` or through a file). Here is an example:

{{ codestart }}
anvi-get-short-reads-mapping-to-a-gene -c %(contigs-db)s \
                                       --gene-caller-id 2 \
                                       -i BAM_FILE_ONE.bam \
                                       -O GENE_2_MATCHES
{{ codestop }}

The output of this will be a file named `GENE_2_MATCHES_BAM_FILE_ONE.fasta` (prefix + bam file name), which will contain all short reads that aligned to gene 2 with more than 100 nucleotides.

You also have the option to provide multiple bam files; in this case, there will be an output files for each bam file inputted.

Additionally, you can change the number of nucleotides required to map to a short read for it to be reported. For example, to expand your search, you could decrease the required mapping length to 50 nucleotides, as so:

{{ codestart }}
anvi-get-short-reads-mapping-to-a-gene -c %(contigs-db)s \
                                       --gene-caller-id 2 \
                                       -i Bam_file_one.bam Bam_file_two.bam \
                                       -O GENE_2_MATCHES \
                                       --leeway 50
{{ codestop }}
This program **finds tRNA seed sequences from a set of tRNA-seq samples**.

This program follows %(anvi-trnaseq)s in the %(trnaseq-workflow)s. %(anvi-trnaseq)s is run on each tRNA-seq sample, producing sample %(trnaseq-db)ss. A tRNA-seq database contains predictions of tRNA sequences, structures, and modification sites in the sample. anvi-merge-trnaseq takes as input the tRNA-seq databases from a set of samples. It compares tRNAs predicted from the samples, finding those in common and calculating their sample coverages. The final tRNA sequences predicted from all samples are called **tRNA seeds** and function like contigs in metagenomic experiments. Seeds are stored in a %(trnaseq-contigs-db)s and sample coverages are stored in a %(trnaseq-profile-db)s. These databases are **variants** of normal %(contigs-db)ss and %(profile-db)ss, performing similar functions in the anvi'o ecosystem but containing somewhat different information.

Most of the heavy computational work in the %(trnaseq-workflow)s is performed by %(anvi-trnaseq)s. anvi-merge-trnaseq is meant run relatively quickly, allowing its parameters to be tuned to fit the dataset.

The `anvi-merge-trnaseq --help` menu provides detailed explanations of the parameters controlling the multifacted analyses performed by the program.

## Key parameters

### Number of reported seeds

One key parameter is the number of reported tRNA seed sequences (`--max-reported-trna-seeds`). The default value of 10,000 seeds is more appropriate for a complex microbial community than a pure culture of a bacterial isolate, which should yield a number of tRNA seeds equal to the number of expressed tRNAs, say ~30. Sequence artifacts may be reported in addition to the 30 actual tRNAs with a higher value like 10,000. Artifacts are relatively common despite intensive screening by %(anvi-trnaseq)s and anvi-merge-trnaseq due to nontemplated nucleotides and modification-induced mutations introduced into tRNA-seq reads by reverse transcription. In practice, artifacts are easy to distinguish from true tRNA seeds by analyzing seed coverage in %(anvi-interactive)s and checking seed homology to reference databases, among other measures.

### Modification filters

Other key parameters, `--min-variation` and `--min-third-fourth-nt`, determine the coverage cutoffs that distinguish predicted positions of modified nucleotides from single nucleotide variants. Compared to SNVs, modifications typically produce higher nucleotide variability to three or four different nucleotides. However, modification-induced mutations are often highly skewed to one other nucleotide rather than all three mutant nucleotides. Furthermore, the high coverage of seeds in many tRNA-seq libraries can uncover SNVs with a low-frequency third nucleotide rather than the expected two. Some SNVs that are wrongly called modifications can be easily spotted in %(anvi-interactive)s and the output of %(anvi-plot-trnaseq)s due to covariation at two positions in the seed as a result of base pairing. In other words, SNV frequencies are equivalent at the two base paired positions in every sample, where modification artifacts have no effect on nucleotide variability at another position across the molecule.

## Examples

*Merge two samples.*

{{ codestart }}
anvi-merge-trnaseq trnaseq_database_1 trnaseq_database_2 (...) \
                   -o OUTPUT_DIRECTORY \
                   -n PROJECT_NAME \
{{ codestop }}

*Merge two samples with and without demethylase treatment, giving priority to the demethylase split in calling the underlying nucleotide at modified positions.*

{{ codestart }}
anvi-merge-trnaseq untreated_trnaseq_database demethylase_trnaseq_database (...) \
                   -o OUTPUT_DIRECTORY \
                   -n PROJECT_NAME \
                   --preferred-treatment demethylase
{{ codestop }}
This program **downloads and sets up the search databases used for the scg-taxonomy workflow** (from [GTDB](https://gtdb.ecogenomic.org/)) so that you can run %(anvi-run-scg-taxonomy)s and %(anvi-estimate-scg-taxonomy)s. This program generates a %(scgs-taxonomy-db)s artifact, which is required to run both of those programs. 

For more information on that workflow, check out [this page](http://merenlab.org/2019/10/08/anvio-scg-taxonomy/)

You will only have to run this program once per anvi'o installation. 

Why is this not done by default? It just makes things easier downstream to build these databases with the DIAMOND installed on your computer to avoid incompatibility issues. Besides, it should take under a minute and is as simple as running

{{ codestart }}
anvi-setup-scg-taxonomy
{{ codestop }}

If you have already already run this program and are trying to redownload this data, run 

{{ codestart }}
anvi-setup-scg-taxonomy --reset
{{ codestop }}

You can also download a specific release of this database by providing its URL with the flag `--scg-taxonomy-remote-database-url`. 
This program allows you to export a %(state)s from a %(pan-db)s or %(profile-db)s. The output of this is a %(state-json)s, which you can import into another anvi'o project with %(anvi-import-state)s. 

You can run this program on a %(profile-db)s or %(pan-db)s as follows: 

{{ codestart }}
anvi-export-state -s %(state)s \
                  -p %(profile-db)s  \
                  -o path/to/output
{{ codestop }}

To list the collections available in this database, you can run 

{{ codestart }}
anvi-export-state -p %(pan-db)s \
                  --list-states
{{ codestop }}
This program **uses the taxonomy associates of your tRNA sequences to estimate the taxonomy for genomes, metagenomes, or %(collection)s stored in your %(contigs-db)s**. 

This is the final step in the trna-taxonomy workflow. Before running this program, you'll need to have run %(anvi-run-trna-taxonomy)s on the %(contigs-db)s that you're inputting to this program.

## Input options 

### 1: Running on a single genome

By default, this program will assume that your %(contigs-db)s contains only a single genome and will determine the taxonomy of that single genome.   

{{ codestart }}
anvi-estimate-trna-taxonomy -c %(contigs-db)s
{{ codestop }}

This will give you only the best taxonomy hit for your genome based on your tRNA data. If you want to look under the hood and see what results from %(anvi-run-trna-taxonomy)s it's using to get there, add the `--debug` flag. 

{{ codestart }}
anvi-estimate-trna-taxonomy -c %(contigs-db)s \
                           --debug 
{{ codestop }}

### 2: Running on a metagenome

In metagenome mode, this program will assume that your %(contigs-db)s contains multiple genomes and will try to give you an overview of the taxa within it.  To do this, anvi'o will determine which anticodon has the most hits in your contigs (for example `GGG`), and then will look at the taxnomy hits for tRNA with that anticodon across your contigs. 

{{ codestart }}
anvi-estimate-trna-taxonomy -c %(contigs-db)s \
                           --metagenome-mode 
{{ codestop }}

If instead you want to look at a specific anticodon, you can specify that with the `-S` parameter. For example, to look at `GGT`, just run the following: 

{{ codestart }}
anvi-estimate-trna-taxonomy -c %(contigs-db)s \
                           --metagenome-mode \
                           -S GGT
{{ codestop }}

### 3: Running on multiple metagenomes

You can use this program to look at multiple metagenomes by providing a %(metagenomes)s artifact. This is useful to get an overview of what kinds of taxa might be in your metagenomes, and what kinds of taxa they share. 

Running this

{{ codestart }}
anvi-estimate-trna-taxonomy --metagenomes %(metagenomes)s \
                           --output-file-prefix EXAMPLE
{{ codestop }}

will give you an output file containing all taxonomic levels found and their coverages in each of your metagenomes, based on their tRNA. 

### 4: Estimating the taxonomy of bins 

You can use this program to estimate the taxonomy of all of the %(bin)ss in a %(collection)s by providing the the %(collection)s and the associated %(profile-db)s. 

{{ codestart }}
anvi-estimate-trna-taxonomy -c %(contigs-db)s \
                           --C %(collection)s  \
                           --p %(profile-db)s 
{{ codestop }}

When doing this, you can also put the final results into your %(profile-db)s as a %(misc-data-layers)s with the flag `--update-profile-db-with-taxonomy`

### 5: I don't even have a contigs-db. Just a fasta file. 

This program can run the entire ad hoc sequence search without a %(contigs-db)s involved (just a fasta and number of target sequences as a percent of the total; default: 20 percent), but this is not recommended. However, if you provide other parameters, they will be ignored. 

{{ codestart }}
anvi-estimate-trna-taxonomy --dna-sequence %(fasta)s \
                           --max-num-target-sequences 10
{{ codestop }}

## The Output

Now that you've inputted your desired inputs, you think about whether you want an output and what it will look like. By default, this program won't give you an output (just %(genome-taxonomy)s information in your %(contigs-db)s. However, if you add any of these output options, it will instead produce a %(genome-taxonomy-txt)s. 

### Anticodon Frequencies

If you want to look at the anticodon frequencies before getting taxonomy info at all (for example because you can't decide which anticodon to use for input option 2), add the flag `--report-anticodon-frequencies`. This will report the anticodon frequencies to a tab-delimited file and quit the program. 

### A single output 

To get a single output (a fancy table for your viewing pleasure), just add the output file path. 

In this example, the input will be a single %(contigs-db)s (input option 1), 

{{ codestart }}
anvi-estimate-trna-taxonomy -c %(contigs-db)s \
                           -o path/to/output.txt  
{{ codestop }}

This will give you a tab-delimited matrix with all levels of taxonomic information for the genome stored in your %(contigs-db)s. Specifically, the output is a %(genome-taxonomy-txt)s. 

If you want to focus on a single taxonomic level, use the parameter `--taxonomic-level`, like so:

{{ codestart }}
anvi-estimate-trna-taxonomy -c %(contigs-db)s \
                           -o path/to/output.txt  \
                           --taxonomic-level genus 
{{ codestop }}

You can also simplify the taxonomy names in the table with the flag `--simplify-taxonomy-information`

If you're running on a %(profile-db)s, you can also choose to add the anticodon coverage to the output with `--compute-anticodon-coverages`. 

### Multiple outputs

If you have multiple outputs (i.e. you are looking at multiple metagenomes (input option number 3) or you are looking at each anticodon individually with `--per-anticodon-output-file`), you should instead provide a output filename prefix.  

{{ codestart }}
anvi-estimate-trna-taxonomy --metagenomes %(metagenomes)s \
                           --output-file-prefix EXAMPLE
{{ codestop }}

The rest of the options listed for the single output (i.e. focusing on a taxonomic level, simplifying taxonomy information, etc.) still apply. 
This program may be useful if you are interested in learning the insert size distribution in a given %(bam-file)s.

## Example run

The most straightforward way to run the program is the following:

{{ codestart }}
anvi-get-tlen-dist-from-bam %(bam-file)s
{{ codestop }}

Here is an example output in the terminal:

```
BAM file .....................................: ./INVERSION-TEST/CP_R03_CDI_C_07_POST.bam
Number of contigs ............................: 8
Number of reads ..............................: 2,331,062
Minimum template length frequency ............: 10
Maximum template length to consider ..........: 500,000


WARNING
===============================================
Some of your contigs, 2 of 8 to be precise, did not seem to have any template
lenght data. There are many reasons this could happen, including a very high
`--min-tlen-frequency` parameter for BAM files with small number of reads. But
since there are some contigs that seem to have proper paired-end reads with
template lengths, anvi'o will continue reporting and put zeros for contigs that
have no data in output files.

Output file ..................................: TEMPLATE-LENGTH-STATS.txt


âœ“ anvi-get-tlen-dist-from-bam took 0:00:05.483682
```

## Output file

The program will report a TAB-delimited output file with the following format:

|contig|length|num_reads_considered|mean|mean_Q2Q3|median|min|max|std|
|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|B_fragilis_ARW016_000000000001|5526948|2213634|367.6|392.5|393.0|32|71613|663.1|
|B_fragilis_ARW016_000000000002|3905|634|398.6|398.7|399.0|382|415|7.926|
|B_fragilis_ARW016_000000000003|4039|588|397.5|397.8|398.0|380|411|7.206|
|B_fragilis_ARW016_000000000004|3950|524|397.4|397.2|397.0|382|414|7.492|
|B_fragilis_ARW016_000000000005|911|0|||||||
|B_fragilis_ARW016_000000000006|647|0|||||||
|B_fragilis_ARW016_000000000007|12247|1860|394.9|396.7|397.0|99|419|23.61|
|B_fragilis_ARW016_000000000008|4861|528|396.7|396.7|397.0|384|410|6.746|

## Histogram

If you run the program with the flag `--plot`, it will attempt to plot a histogram for all contigs in the BAM file.

{:.warning}
The plotting function requires an additional Python library, [plotext](https://github.com/piccolomo/plotext), to be installed. While it is not a part of the default anvi'o distirbution, you can install it in your environment by running `pip install plotext`.

Here is an example run:

```
anvi-get-tlen-dist-from-bam CP_R03_CDI_C_07_POST.bam \
                            --plot \
                            --max-template-length-to-consider 5000 \
                            --min-template-length-frequency 2500
```

And the result in the terminal:

[![Example output](../../images/anvi-get-tlen-dist-from-bam.png){:.center-img}](../../images/anvi-get-tlen-dist-from-bam.png)

The histogram may require additional filters to avoid skewed displays due to outliers. The parameters `--max-template-length-to-consider` and/or `--min-template-length-frequency` may be useful for such adjustments. Please see the help menu for their details.

The best practice is likely to run the program without any of these parameters and without the `--plot` flag to generate a comprehensive TAB-delimited report, and then use the `--plot` flag to visualize trends.This program associates the tRNA reads found in your %(contigs-db)s with taxonomy information. 

Once these associations are stored in your %(contigs-db)s (represented by a %(trna-taxonomy)s artifact), you'll be able to run %(anvi-estimate-trna-taxonomy)s to use the associations to estimate taxonomy on a larger scale (i.e. for a genome or metagenome). 

To run this program, you'll need to have set up two things: 
1. a %(trna-taxonomy-db)s, which you can set up by running %(anvi-setup-trna-taxonomy)s.
2. the 'transfer-RNAs' HMM hits in your %(contigs-db)s, which you can set up by running %(anvi-scan-trnas)s

This program will then go through the tRNA hits in your contigs database and search them against the sequences in the [GTDB](https://gtdb.ecogenomic.org/) databases that you downloaded to assign them taxonomy. 

### Basic run

The following is a basic run of this program: 

{{ codestart }}
anvi-run-trna-taxonomy -c %(contigs-db)s
{{ codestop }}

If you have set up the two requirements listed above, this should run smoothly. 

### Additional Parameters

When changing these parameters, it might be a good idea to run %(anvi-estimate-trna-taxonomy)s with the `--debug` flag so that you can see what your results look like under the hood. 

1. `--max-num-target-sequences`: the number of hits that this program considers for each tRNA sequence before making a final decision for the taxonomy association. The default is 100, but if you want to ensure that you have accurate data at the expense of some runtime, you can increase it. 
2. `--min-percent-identity`: the minimum percent alignment needed to consider something a hit.  The default is 90, but if you're not getting any hits on a specific sequence, you can decrease it at the risk of getting some nonsense results. 

Finally, this program does not usually have an output file, but if desired you can add the parameter `--all-hits-output-file` to store the list of hits that anvi'o looked at to determine the consensus hit for each sequence. 
This program **provides information about each of the single copy core genes in your %(contigs-db)s**. 

Simply provide a %(contigs-db)s, and it will create a %(genes-stats)s file containing a variety of information about the single copy core genes in your database. 

{{ codestart }}
anvi-script-gen_stats_for_single_copy_core_genes.py -c %(contigs-db)s 
{{ codestop }}

The console output will tell you the total number of contigs, splits, and nucleotides in your %(contigs-db)s, while the text output will tell you the source, name, and e-value of each single-copy core gene. 

You can get information from only single-copy core genes from a specific source. To see what sources are availible in your %(contigs-db)s, run 

{{ codestart }}
anvi-script-gen_stats_for_single_copy_core_genes.py -c %(contigs-db)s \
                                                    --list-sources
{{ codestop }}
This program adds a new %(collection)s and %(bin)s to your %(pan-db)s or %(profile-db)s and %(contigs-db)s pair. This collection and bin will both contain all of your contigs. 

This way, you can perform collection and bin specfic operations without having to bin anything yourself. For example, running %(anvi-interactive)s in gene-mode requires you to specify a collection and bin (as is done [in the Infant Gut Tutorial](http://merenlab.org/tutorials/infant-gut/#the-gene-mode-studying-distribution-patterns-at-the-gene-level)). 

By default, the collection is named `DEFAULT` and the bin is named `EWVERYTHING`, but you can change these names with the `-C` and `-b` parameters respectively. 

Here is an example run on a %(profile-db)s: 

{{ codestart }}
anvi-script-add-default-collection -c %(contigs-db)s \ 
                                   -p %(profile-db)s \ 
                                   -C MY_COLLECTION \
                                   -b MY_BIN 
{{ codestop }}

Once this is run, your profile database will contain a collection called `MY_COLLECTION` with a single bin (called `MY_BIN`) which contains all of your contigs. 
This program computes functional enrichment across groups of genomes and returns a %(functional-enrichment-txt)s file.

{:.warning}
For its sister programs, see %(anvi-compute-functional-enrichment-in-pan)s and %(anvi-compute-metabolic-enrichment)s.

{:.notice}
Please also see %(anvi-display-functions)s which can both calculate functional enrichment, AND give you an interactive interface to display the distribution of functions.

## Functional enrichment

You can use this program by combining genomes described through %(external-genomes)s, %(internal-genomes)s, and/or stored in a %(genomes-storage-db)s. In addition to sources for your genomes, you will need to provide a %(groups-txt)s file to declare which genome belongs to which group for enrichment analysis to consider.

### How does it work?

1. **Aggregate functions from all sources**. Gene calls in each genome are tallied according to their functional annotations from the given annotation source.

2. **Quantify the distribution of functions in each group of genomes**. This information is then used by `anvi-script-enrichment-stats` to fit a GLM to determine (1) the level that a particular functional annotation is unique to a single group and (2) the percent of genomes it appears in in each group. This produces a %(functional-enrichment-txt)s file.

{:.notice}
The script `anvi-script-enrichment-stats` was implemented by [Amy Willis](https://github.com/adw96), and described first in [this paper](https://doi.org/10.1186/s13059-020-02195-w).


### Basic usage

You can use it with a single source of genomes:

{{ codestart }}
anvi-compute-functional-enrichment-across-genomes -i %(internal-genomes)s \
                                                  -o %(functional-enrichment-txt)s \
                                                  --annotation-source FUNCTION_SOURCE
{{ codestop }}

or many:

{{ codestart }}
anvi-compute-functional-enrichment-across-genomes -i %(internal-genomes)s\
                                                  -e %(external-genomes)s \
                                                  -g %(genomes-storage-db)s \
                                                  -o %(functional-enrichment-txt)s \
                                                  --annotation-source FUNCTION_SOURCE
{{ codestop }}

### Additional Parameters

You can get a tab-delimited matrix describing the occurrence (counts) of each function within each genome using the `--functional-occurrence-table-output` parameter:

{{ codestart }}
anvi-compute-functional-enrichment-across-genomes -i %(internal-genomes)s \
                                                  -o %(functional-enrichment-txt)s \
                                                  --annotation-source FUNCTION_SOURCE
                                                  --functional-occurrence-table-output FUNC_OCCURRENCE.TXT
{{ codestop }}
The main function of `anvi-merge` is to convert multiple %(single-profile-db)ss into a single %(profile-db)s (also called a merged profile database). Basically, this takes the alignment data from each sample (each contained in its own %(single-profile-db)s) and combines them into a single database that anvi'o can look through more easily. 

### Overview: How to run anvi-merge

1. Set up your %(contigs-db)s. See that page for more information

1. Use %(anvi-profile)s to create a %(single-profile-db)s for each of your samples (formatted into a %(bam-file)s) *(Note: for each of these runs, you'll need to use the same %(contigs-db)s and parameters)*

1. Use `anvi-merge` to merge those %(single-profile-db)ss into a single database, called a %(profile-db)s. This will look something like the following:

{{ codestart }}
anvi-merge -c cool_contigs.db \
            Single_profile_db_1 Single_profile_db_2 \
            -o cool_contigs_merge
{{ codestop }}
                    
This will put all of the output files (the final %(profile-db)s as well as a %(misc-data-items-order)s which is the result of your hierarchical clustering and describes the order to display your contigs in) into the folder `cool_contigs_merge `.
    

## Other Parameters

You must give `anvi-merge` your contigs database and single profile databases. However, you can also provide more information or give addtional instructions. Use the flag `-h` at any time to display the help menu.

### Hierarchical Clustering 

#### To run or not to run? 
* Use the flag `--skip-hierarchical-clustering` to turn hierarchical clustering off. This will save on computation time, but will skip out on creating the tree of contigs at the center of the interactive interface. If you have more than 25,000 splits in the final profile, this will be set automatically. 
* Use the flag `--enforce-hierarchical-clustering` to turn hierarchical clustering back on. This will take a long time, but will produce a lovely contigs tree for the interactive interface. 

#### Additional parameters
* Provide a custom distance metric for clustering using the flag `--distance.` (The default is euclidean)
* Provide a custom linkage method for clustering using the flag `--linkage.` (The default is ward)

### Providing additional information
* Provide the sample name using the flag `-S`. If you don't, anvi'o will come up with one, but it probably won't be any good. 
* Provide a text file in markdown to describe the project using the flag `--description`. This will show up when you later use the interactive interface to analyze your profile-db. 

### Output Information
* Provide an output destination with the flag `-o`.
* Add the flag `-W` to overwrite existing files in that directory. 
This aptly-named program **gets the sequences for the gene clusters stored in a %(pan-db)s and returns them as either a %(genes-fasta)s or a %(concatenated-gene-alignment-fasta)s** (which you can use to run %(anvi-gen-phylogenomic-tree)s). This gives you advanced access to your gene clusters, which you can take out of anvi'o, use for phylogenomic analyses, or do whatever you please with. 

You also have the option to output the sequences of your choice as a %(misc-data-items)s (with `add-into-items-additional-data-table`), which can be added to the %(interactive)s interface as additional layers. 

While the number of parameters may seem daunting, many of the options just help you specify exactly which gene clusters you want to get the sequences  from. 

### Running on all gene clusters

Here is a basic run, that will  export alignments for every single gene cluster found in the %(pan-db)s as amino acid sequences :

{{ codestart }}
anvi-get-sequences-for-gene-clusters -g %(genomes-storage-db)s \
                                     -p %(pan-db)s \
                                     -o %(genes-fasta)s
{{ codestop }}

To get the DNA sequences instead, just add `--report-DNA-sequences`. 

### Exporting only specific gene clusters

#### Part 1: Choosing gene clusters by collection, bin, or name

You can export only the sequences for a specific %(collection)s or %(bin)s with the parameters `-C` or `-b` respectively. You also have the option to display the collections and bins available in your %(pan-db)s with `--list-collections` or `--list-bins`

{{ codestart }}
anvi-get-sequences-for-gene-clusters -g %(genomes-storage-db)s \
                                     -p %(pan-db)s \
                                     -o %(genes-fasta)s \
                                     -C %(collection)s 
{{ codestop }}

Alternatively, you can export the specific gene clusters by name, either by providing a single gene cluster ID or a file with one gene cluster ID per line. For example: 

{{ codestart }}
anvi-get-sequences-for-gene-clusters -g %(genomes-storage-db)s \
                                     -p %(pan-db)s \
                                     -o %(genes-fasta)s \
                                     --gene-cluster-ids-file gene_clusters.txt
{{ codestop }}

where `gene_clusters.txt` contains the following:

    GC_00000618
    GC_00000643
    GC_00000729

#### Part 2: Choosing gene clusters by their attributes

These parameters are used to exclude gene clusters that don't reach certain thresholds and are applies on top of filters already applied (for example, you can use these to exclude clusters within a specific bin). 

Here is a list of the different filters that you can use to exclude some subsection of your gene clusters:

- min/max number of genomes that the gene cluster occurs in. 
- min/max number of genes from each genome. For example, you could exclude clusters that don't appear in every genome 3 times, or get single-copy genes by setting `max-num-genes-from-each-genome` to 1. 
- min/max [geometric homogenity index](http://merenlab.org/2016/11/08/pangenomics-v2/#geometric-homogeneity-index) 
- min/max [functional homogenity index](http://merenlab.org/2016/11/08/pangenomics-v2/#functional-homogeneity-index)
- min/max combined homogenity index 

For example, the following run on a %(genomes-storage-db)s that contains 50 genomes will report only the single-copy core genes with a functional homogenity index above 0.25:

{{ codestart }}
anvi-get-sequences-for-gene-clusters -g %(genomes-storage-db)s \
                                     -p %(pan-db)s \
                                     -o %(genes-fasta)s \
                                     --max-num-genes-from-each-genome 1 \
                                     --min-num-genomes-gene-cluster-occurs 50 \
                                     --min-functional-homogenity-index 0.25 
{{ codestop }}

You can also exclude genomes that are missing some number of the gene clusters that you're working with by using the paramter `--max-num-gene-clusters-missing-from-genome`. 

For each of these parameters, see the program's help menu for more information. 

### Fun with phylogenomics! 

To get a %(concatenated-gene-alignment-fasta)s (which you can use to run %(anvi-gen-phylogenomic-tree)s), use the parameter `--concatenate-gene-clusters`

{{ codestart }}
anvi-get-sequences-for-gene-clusters -g %(genomes-storage-db)s \
                                     -p %(pan-db)s \
                                     -o %(genes-fasta)s \
                                     --concatenate-gene-clusters
{{ codestop }}

Here, you also have the option to specify a specific aligner (or list the available aligners), as well as provide a NEXUS formatted partition file, if you so choose. 
This program **takes in a %(functions)s artifact to create a %(functions-txt)s.** Basically, if you want to take the information in your %(functions)s artifact out of anvi'o or give it to a fellow anvi'o user (for them to [import it](http://merenlab.org/software/anvio/help/programs/anvi-import-functions/) into their own project), you get that information using this command. 

Simply provide the %(contigs-db)s that has been annotated with %(functions)s: 

{{ codestart }}
anvi-export-functions -c %(contigs-db)s 
{{ codestop }}

You can also get annotations for only a specific list of sources. For example:

{{ codestart }}
anvi-export-functions -c %(contigs-db)s \
                      --annotation-sources source_1,source_2,source_3
{{ codestop }}


This program creates a %(structure-db)s either by (a) attempting to solve for the 3D structures of proteins encoded by genes in your %(contigs-db)s using DIAMOND and MODELLER, or (b) importing pre-existing structures provided by the user using an %(external-structures)s file.

### The basics of the pipeline

This section covers option (a), where the user is interested in having structures predicted for them.

DIAMOND first searches your sequence(s) against a database of proteins with a known structure.  This database is downloaded from the [Sali lab](https://salilab.org/modeller/supplemental.html), who created and maintain MODELLER, and contains all of the PDB sequences clustered at 95%% identity.

If any good hits are found, they are selected as templates, and their structures are nabbed either from [the RCSB directly](https://www.rcsb.org/), or from a local %(pdb-db)s database which you can create yourself with %(anvi-setup-pdb-database)s. Then, anvi'o passes control over to MODELLER, which creates a 3D alignment for your sequence to the template structures, and makes final adjustments to it based off of empirical distributions of bond angles. For more information, check [this blogpost](http://merenlab.org/2018/09/04/getting-started-with-anvio-structure/#how-modeller-works).

The output of this program is a %(structure-db)s, which contains all of the modelled structures. Currently, the primary use of the %(structure-db)s is for interactive exploration with %(anvi-display-structure)s. You can also export your structures into external .pdb files with %(anvi-export-structures)s, or incorporate structural information in the %(variability-profile-txt)s with %(anvi-gen-variability-profile)s.

### Basic standard run

Here is a simple run: 

{{ codestart }}
anvi-gen-structure-database -c %(contigs-db)s \
                            --gene-caller-ids 1,2,3 \
                            -o STRUCTURE.db 
{{ codestop }}

Following this, you will have the structures for genes 1, 2, and 3 stored in `STRUCTURE.db`, assuming reasonable templates were found. Alternatively, you can provide a file name with the gene caller IDs (one ID per line) with the flag `--genes-of-interest`.  

If you have already run %(anvi-setup-pdb-database)s and therefore have a local copy of representative PDB structures, make sure you use it by providing the `--offline` flag. If you put it in a non-default location, provide the path to your %(pdb-db)s: 

{{ codestart }}
anvi-gen-structure-database -c %(contigs-db)s \
                            --gene-caller-ids 1,2,3 \
                            --pdb-database %(pdb-db)s \
                            -o STRUCTURE.db 
{{ codestop }}

To quickly get a very rough estimate for your structures, you can run with the flag `--very-fast`. 

### Basic import run

If you already possess structures and would like to create a %(structure-db)s for downstream anvi'o uses such as %(anvi-display-structure)s, you should create a %(external-structures)s file. Then, create the database as follows:

{{ codestart }}
anvi-gen-structure-database -c %(contigs-db)s \
                            --external-structures %(external-structures)s \
                            -o STRUCTURE.db 
{{ codestop }}

{:.notice}
Please avoid using any MODELLER-specific parameters when using this mode, as they will be silently ignored.


### Advanced Parameters

Here, we will go through a brief overview of the MODELLER parameters that you are able to change. See [this page](http://merenlab.org/2018/09/04/getting-started-with-anvio-structure/#description-of-all-modeller-parameters) for more information. 

- The number of models to be simulated. The default is 1. 
- The standard deviation of atomic perturbation of the initial structure (i.e. how much you change the position of the atoms before fine tuning with other analysis). The default is 4 angstroms.
- The MODELLER database used. The default is `pdb_95`, which can be found [here](https://salilab.org/modeller/supplemental.html). This is the same database that is downloaded by %(anvi-setup-pdb-database)s.
- The scoring function used to compare potential models. The default is `DOPE_score`.
- The minimum percent identity cutoff for a template to be further considered.
- The minimum alignment fraction that the sequence is covered by the template in order to be further considered.
- The maximum number of templates that the program will consider. The default is 5. 
- The MODELLER program to use. The default is `mod9.19`, but anvi'o is somewhat intelligent and will
  look for the most recent version it can find.

For a case study on how some of these parameters matter, see [here](http://merenlab.org/2018/09/04/getting-started-with-anvio-structure/#a-quick-case-study-on-the-importance-of-key-parameters). 

You also have the option to

- Skip the use of DSSP, which predicts beta sheets, alpha helices, certain bond angles, and relative
  solvent acessibility of residues.
- Output **all** the raw data, just provide a path to the desired directory with the flag `--dump-dir`.


%(anvi-setup-kegg-kofams)s downloads and organizes data from KEGG for use by other programs, namely %(anvi-run-kegg-kofams)s and %(anvi-estimate-metabolism)s. It downloads HMM profiles from the [KOfam](https://academic.oup.com/bioinformatics/article/36/7/2251/5631907) database as well as metabolism information such as that stored in the [KEGG MODULES resource](https://www.genome.jp/kegg/module.html). The KOfam profiles are prepared for later use by the HMMER software, and the metabolism information is made accessible to other anvi'o programs as a %(modules-db)s. This program generates a directory with these files (%(kegg-data)s), which by default is located at `anvio/anvio/data/misc/KEGG/`.

### Default Usage

If you do not provide any arguments to this program, the KOfam profiles and KEGG information will be set up in the default KEGG data directory.

{{ codestart }}
anvi-setup-kegg-kofams
{{ codestop }}

**How does it work?**
By default, this program downloads a snapshot of the KEGG databases, already converted into an anvi'o-compatible format. The snapshot is a `.tar.gz` archive of a KEGG data directory that was generated around the time of the latest anvi'o release.  

After the default KEGG archive is downloaded, it is unpacked, checked that all the expected files are present, and moved into the KEGG data directory.

Doing it this way ensures that almost everyone uses the same version of KEGG data, which is good for reproducibility and makes it easy to share annotated datasets. The KEGG resources are updated fairly often, and we found that constantly keeping the KEGG data directory in sync with them was not ideal, because every time the data directory is updated, you have to update the KOfam annotations in all your contigs databases to keep them compatible with the current %(modules-db)s (unless you were smart enough to keep the old version of the KEGG data directory around somewhere). And of course that introduces a new nightmare as soon as you want to share datasets with your collaborators who do not have the same KEGG data directory version as you. With everyone using the same %(kegg-data)s by default, we can avoid these issues.

But the trade-off to this is that the default KEGG data version is tied to an anvi'o release, and it will not always include the most up-to-date information from KEGG. Luckily, for those who want the most updated version of KEGG, you can still use this program to generate the KEGG data directory by downloading directly from KEGG (see 'Generating an anvi'o compatible KEGG data directory from scratch' below).

### How to set up KEGG data in a non-default location

You can specify a different directory in which to put this data, if you wish:

{{ codestart }}
anvi-setup-kegg-kofams --kegg-data-dir /path/to/directory/KEGG
{{ codestop }}

This is helpful if you don't have write access to the default directory location, or if you want to keep several different versions of the KEGG data on your computer. Just remember that when you want to use this specific KEGG data directory with later programs such as %(anvi-run-kegg-kofams)s, you will have to specify its location with the `--kegg-data-dir` flag.

### Setting up an earlier KEGG snapshot

By default, the KEGG snapshot that will be installed is the latest one, which is up-to-date with your current version of anvi'o. If, however, you want a snapshot from an earlier version, you can run something like the following to get it:

{{ codestart }}
anvi-setup-kegg-kofams --kegg-data-dir /path/to/directory/KEGG --kegg-snapshot v2020-04-27
{{ codestop }}

Just keep in mind that you may need to migrate the MODULES.db from these earlier versions in order to make it compatible with the current metabolism code. Anvi'o will tell you if you do.

Not sure what KEGG snapshots are available for you to request? Well, you could check out the YAML file at `anvio/anvio/data/misc/KEGG-SNAPSHOTS.yaml` in your anvi'o directory, or you could just give something random to the `--kegg-snapshot` parameter and watch anvi'o freak out and tell you what is available:
{{ codestart }}
anvi-setup-kegg-kofams --kegg-snapshot hahaha
{{ codestop }}


### Generating an anvi'o compatible KEGG data directory from scratch

This program is also capable of downloading data directly from KEGG and converting it into an anvi'o-compatible format. In fact, this is how we generate the default KEGG archive. If you want the latest KEGG data instead of the default snapshot of KEGG, try the following:

{{ codestart }}
anvi-setup-kegg-kofams --download-from-kegg
{{ codestop }}

**How does it work?**
KOfam profiles are downloadable from KEGG's [FTP site](ftp://ftp.genome.jp/pub/db/kofam/) and all other KEGG data is accessible as flat text files through their [API](https://www.kegg.jp/kegg/rest/keggapi.html). When you run this program it will first get all the files that it needs from these sources, and then it will process them by doing the following:

- determine if any KOfam profiles are missing bitscore thresholds, and remove those from the standard profile location so that they are not used for annotation (if you want to see these, you will find them in the `orphan_data` folder in your KEGG data directory)
- concatenate all remaining KOfam profiles into one file and run `hmmpress` on them
- parse the flat text file for each KEGG module and store the information into the %(modules-db)s

An important thing to note about this option is that it has rigid expectations for the format of the KEGG data that it works with. Future updates to KEGG may break things such that the data can no longer be directly obtained from KEGG or properly processed. In the sad event that this happens, you will have to download KEGG from one of our archives instead.

**How do I share this data?**
Suppose you have been living on the edge and annotating your contigs databases with a non-default version of %(kegg-data)s, and you share these databases with a collaborator who wants to run downstream programs like %(anvi-estimate-metabolism)s on them. Your collaborator (who has a different version of %(kegg-data)s on their computer) will likely get version errors as detailed on the %(anvi-estimate-metabolism)s help page.

In order for your collaborator to be able to work with your dataset, they need to have the same %(kegg-data)s version as you did when you ran %(anvi-run-kegg-kofams)s. If you are very lucky and KEGG has not been updated since you set up your %(kegg-data)s, they may be able to run `anvi-setup-kegg-kofams -D` to get it. But if not, there are a few options for you to share your version of %(kegg-data)s:

1. You could send them your KEGG data directory. First, run `tar -czvf kegg_archive.tar.gz ./KEGG` on the data directory to compress and archive it before sending it over (this command _must_ be run from its parent directory so that the archive has the expected directory structure when it is unpacked). Then your collaborator can just run `anvi-setup-kegg-kofams --kegg-archive kegg_archive.tar.gz --kegg-data-dir ./KEGG_ARCHIVE` and be good to go. They would just have to use `--kegg-data-dir ./KEGG_ARCHIVE` when running downstream programs. The problem here is that even the archived %(kegg-data)s is quite large, ~4-5GB, and may be unfeasible for you to send.
2. You could share with your collaborator just the %(modules-db)s. If all they want to do is to run %(anvi-estimate-metabolism)s on databases annotated by your version of the KEGG data directory, this should be all they need. They would need to pass the folder containing your %(modules-db)s to %(anvi-estimate-metabolism)s using the `--kegg-data-dir` parameter.
3. If your collaborator also wants to be able to annotate other databases with your version of %(kegg-data)s, then they need to have the KOfam profiles as well. You can send them your %(modules-db)s and have them download the KOfam profiles most similar to the ones you have from the [KOfam archives](anvi-setup-kegg-kofams) (which are labeled by date). Then they would have to essentially construct their own KEGG data directory by copying the structure of the default one and putting the downloaded files (and the %(modules-db)s you sent them) into the correct locations. The KOfam profiles must be concatenated into a `Kofam.hmm` file and `hmmpress` must be run on that file to generate the required indices for `hmmsearch`. Your collaborator must also have the `ko_list.txt` file (which _should_ be downloaded with the profiles) in the right spot. Then they could pass their makeshift KEGG data directory to %(anvi-run-kegg-kofams)s using `--kegg-data-dir`, and they should be golden. (A word of warning: they may want to remove KOs without bitscore thresholds in the `ko_list.txt` before concatenating the profiles, otherwise they will likely get a lot of weak hits for these KOs.)

### Set up from archived KEGG data

If you have an archive (`.tar.gz`) of the KEGG data directory already on your computer (perhaps a colleague or Meren Lab developer gave you one), you can set up KEGG from this archive instead:

{{ codestart }}
anvi-setup-kegg-kofams --kegg-archive KEGG_archive.tar.gz
{{ codestop }}

This works the same way as the default, except that it bypasses the download step and instead uses the archive you have provided with `--kegg-archive`.
This program lets you convert the %(hmm-hits)s within a %(contigs-db)s into a %(functions-txt)s.

It is similar to %(anvi-export-functions)s, except it deals specifically with %(hmm-hits)s (which are generated by %(anvi-run-hmms)s; in contrast, %(anvi-export-functions)s works with the more abstract %(functions)s artifact. 

Here is an example run of this program:

{{ codestart }}
anvi-script-get-hmm-hits-per-gene-call -c %(contigs-db)s \ 
                                       -o path/to/%(functions-txt)s 
{{ codestop }}

You also have the option to specify a specific %(hmm-source)s, so that only hits from that source are outputted. For example: 

{{ codestart }}
anvi-script-get-hmm-hits-per-gene-call -c %(contigs-db)s \ 
                                       -o path/to/%(functions-txt)s \
                                       --hmm-source Bacteria_71
{{ codestop }}
This program, as one might think, allows you to export a %(misc-data-items-order)s, outputing a %(misc-data-items-order-txt)s. 

You can export one of the item orders in a %(profile-db)s or %(pan-db)s as follows: 

{{ codestart }}
anvi-export-items-order -p %(profile-db)s \
                        --name cov
{{ codestop }}

The `cov` here refers to the tree that is generated using only differential coverage. Almost all anvi'o profile databases will also have available an items-order based on the tetranucleotide frequency called `tnf`, and one based on both called `tnf-cov`. 

However, to list the item orders available in this database, just don't include the name flag.  

{{ codestart }}
anvi-export-items-order -p %(pan-db)s 
{{ codestop }}

You'll get a `Config Error` that will tell you what item orders are available. 
This program can work with anvi'o %(contigs-db)s, %(external-genomes)s, or %(internal-genomes)s files to return sequences for HMM hits identified through the default anvi'o %(hmm-source)ss (such as the domain-specific single-copy core genes) or user-defined %(hmm-source)ss (such as HMMs for specific antibiotic resistance gene families or any other targets).

Using it with single-copy core genes in default anvi'o HMMs make it a very versatile tool for phylogenomics as the user can define specific sets of genes to be aligned and concatenated.


### Learn available HMM sources

{{ codestart }}
anvi-get-sequences-for-hmm-hits -c %(contigs-db)s \
                                --list-hmm-sources

AVAILABLE HMM SOURCES
===============================================
* 'Bacteria_71' (type: singlecopy; num genes: 71)
* 'Archaea_76' (type: singlecopy; num genes: 76)
* 'Protista_83' (type: singlecopy; num genes: 83)
* 'Ribosomal_RNAs' (type: Ribosomal_RNAs; num genes: 12)
{{ codestop }}

### Get all sequences in a given HMM source

{{ codestart }}
anvi-get-sequences-for-hmm-hits -c %(contigs-db)s \
                                --hmm-source Bacteria_71 \
                                -o %(genes-fasta)s
{{ codestop }}

### Learn available genes in a given HMM source

Please note that the flag `--list-available-gene-names` will give you the list of genes in an **HMM collection** (for example, for `Bacteria_71` in the following use case), and it will not give you the list of genes in your genomes or metagenomes that are matching to them. You can generate a table of HMMs across your genomes or metagenomes with another program, %(anvi-script-gen-hmm-hits-matrix-across-genomes)s.

{{ codestart }}
anvi-get-sequences-for-hmm-hits -c %(contigs-db)s \
                                --hmm-source Bacteria_71 \
                                --list-available-gene-names

* Bacteria_71 [type: singlecopy]: ADK, AICARFT_IMPCHas, ATP-synt, ATP-synt_A,
Chorismate_synt, EF_TS, Exonuc_VII_L, GrpE, Ham1p_like, IPPT, OSCP, PGK,
Pept_tRNA_hydro, RBFA, RNA_pol_L, RNA_pol_Rpb6, RRF, RecO_C, Ribonuclease_P,
Ribosom_S12_S23, Ribosomal_L1, Ribosomal_L13, Ribosomal_L14, Ribosomal_L16,
Ribosomal_L17, Ribosomal_L18p, Ribosomal_L19, Ribosomal_L2, Ribosomal_L20,
Ribosomal_L21p, Ribosomal_L22, Ribosomal_L23, Ribosomal_L27, Ribosomal_L27A,
Ribosomal_L28, Ribosomal_L29, Ribosomal_L3, Ribosomal_L32p, Ribosomal_L35p,
Ribosomal_L4, Ribosomal_L5, Ribosomal_L6, Ribosomal_L9_C, Ribosomal_S10,
Ribosomal_S11, Ribosomal_S13, Ribosomal_S15, Ribosomal_S16, Ribosomal_S17,
Ribosomal_S19, Ribosomal_S2, Ribosomal_S20p, Ribosomal_S3_C, Ribosomal_S6,
Ribosomal_S7, Ribosomal_S8, Ribosomal_S9, RsfS, RuvX, SecE, SecG, SecY, SmpB,
TsaE, UPF0054, YajC, eIF-1a, ribosomal_L24, tRNA-synt_1d, tRNA_m1G_MT,
Adenylsucc_synt
{{ codestop }}

### Get sequences for some sequences in a given HMM source

{{ codestart }}
anvi-get-sequences-for-hmm-hits -c %(contigs-db)s \
                                --hmm-source Bacteria_71 \
                                --gene-names Ribosomal_L27,Ribosomal_L28,Ribosomal_L3 \
                                -o %(genes-fasta)s
{{ codestop }}

### Get HMM hits in bins of a collection

{{ codestart }}
anvi-get-sequences-for-hmm-hits -c %(contigs-db)s \
                                -p %(profile-db)s \
                                -C %(collection)s
                                --hmm-source Bacteria_71 \
                                --gene-names Ribosomal_L27,Ribosomal_L28,Ribosomal_L3 \
                                -o %(genes-fasta)s
{{ codestop }}

### Get amino acid sequences for HMM hits

{{ codestart }}
anvi-get-sequences-for-hmm-hits -c %(contigs-db)s \
                                -p %(profile-db)s \
                                -C %(collection)s
                                --hmm-source Bacteria_71 \
                                --gene-names Ribosomal_L27,Ribosomal_L28,Ribosomal_L3 \
                                --get-aa-sequences \
                                -o %(genes-fasta)s
{{ codestop }}

### Get HMM hits independently aligned and concatenated

The resulting file can be used for phylogenomics analyses via %(anvi-gen-phylogenomic-tree)s or through more sophisticated tools for curating alignments and computing trees.

{{ codestart }}
anvi-get-sequences-for-hmm-hits -c %(contigs-db)s \
                                -p %(profile-db)s \
                                -C %(collection)s
                                --hmm-source Bacteria_71 \
                                --gene-names Ribosomal_L27,Ribosomal_L28,Ribosomal_L3 \
                                --get-aa-sequences \
                                --concatenate-genes \
                                --return-best-hit
                                -o %(genes-fasta)s
{{ codestop }}


### Want to play?

You can play with this program using the anvi'o data pack for the [infant gut data](/tutorials/infant-gut) and by replacing the parameters above with appropriate ones in the following commands.

Download the latest version of the data from here:

[doi:10.6084/m9.figshare.3502445](https://doi.org/10.6084/m9.figshare.3502445)

Unpack it:

{{ codestart }}
tar -zxvf INFANTGUTTUTORIAL.tar.gz && cd INFANT-GUT-TUTORIAL
{{ codestop }}

Import the collection `merens`:

{{ codestart }}
%(anvi-import-collection)s additional-files/collections/merens.txt \
                       -p PROFILE.db \
                       -c CONTIGS.db \
                       -C merens
{{ codestop }}

Then run the program to

### Learn available HMM sources

{{ codestart }}
anvi-get-sequences-for-hmm-hits -p PROFILE.db \
                                -c CONTIGS.db \
                                -C merens \
                                -o OUTPUT.fa \
                                --hmm-source Campbell_et_al \
                                --gene-names Ribosomal_L27,Ribosomal_L28,Ribosomal_L3 \
                                --return-best-hit \
                                --get-aa-sequences \
                                --concatenate
{{ codestop }}
This program **associates genes in your %(contigs-db)s with functions using NCBI's [Clusters of Orthologus Groups (COGs) database](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC102395/).**

Before you run this program, you'll have to set up the COGs database on your computer with the program %(anvi-setup-ncbi-cogs)s.

To run, you'll need to provide a %(contigs-db)s. If you stored the %(cogs-data)s that you got from running %(anvi-setup-ncbi-cogs)s in a custom location, you'll need to provide that path as well. The output is a %(functions)s artifact.

{{ codestart }}
anvi-run-ncbi-cogs -c %(contigs-db)s \
            --cog-data-dir path/to/%(cogs-data)s
{{ codestop }}

Without the flag `--cog-data-dir`, anvi'o will just search in the default location.

By default, this program uses DIAMOND in the "fast" setting for database searching. To instead run in "sensitive" mode, just call:

{{ codestart }}
anvi-run-ncbi-cogs -c %(contigs-db)s \
            --sensitive
{{ codestop }}

You can also use blastp to search, by running:

{{ codestart }}
anvi-run-ncbi-cogs -c %(contigs-db)s \
            --search-with blastp
{{ codestop }}


This program uses a %(gene-taxonomy-txt)s to populate the taxonomic information for the genes in a %(contigs-db)s. 

Once finished, your gene taxonomy will appear as an additional layer if you open the %(contigs-db)s and an associated %(profile-db)s in %(anvi-interactive)s. 

There is an entire blogpost about different ways to do this [here](http://merenlab.org/2016/06/18/importing-taxonomy/). It outlines how to get your sequences using %(anvi-get-sequences-for-gene-calls)s than use either [Kaiju](https://github.com/bioinformatics-centre/kaiju) or [Centrifuge](https://github.com/infphilo/centrifuge) to get the taxonomy information for your genes. Finally, you bring that information back into anvi'o using this program.  
This program lets you associate your layers with taxonomic information through a %(single-profile-db)s. 

This information is displayed in the interactive interface at the same place as %(misc-data-layers)s, which is point (4) on [this page](http://merenlab.org/2017/12/11/additional-data-tables/#views-items-layers-orders-some-anvio-terminology). 

If instead you want the layers to *represent* taxonomic ranks, then you'll want to take a look at [this tutorial on phylogenomics](http://merenlab.org/2017/06/07/phylogenomics/).

Usually, the layers describe separate samples. However, when working with only one sample, you may break up different aspects of that sample to be represented in each layer, hence why you might want to associate them with taxonomic information. 

To run this program, simply provide a %(layer-taxonomy-txt)s

{{ codestart }}
anvi-import-taxonomy-for-layers -p %(single-profile-db)s \
                                -i %(layer-taxonomy-txt)s 
{{ codestop }}

You also have the option to change the minimum abundance cut off using `--min-abundance`. The default value is 0.1 percent. 
This program tells you about the %(collection)ss within a %(profile-db)s or %(pan-db)s. 

Just run it like so 

{{ codestart }}
anvi-show-collections-and-bins -p %(profile-db)s 
{{ codestop }}

and Anvi'o will output to your console the following information for each of the %(collection)ss in the database: 

* The name and ID of the collection
* The number of %(bin)ss within the collection, and each of their names
* The number of splits contained within those bins 
This program lets you export miscellaneous data of your choosing into a text file, which can be imported into another anvi'o project using %(anvi-import-misc-data)s. You can export the same types of data that you can import with that function. These are also listed below.

To see what misc-data is available in your database, use %(anvi-show-misc-data)s. 

If your misc-data is associated with a specific data group, you can provide that data group to this program with the `-D` flag. 

## Data types you can export 

### From a pan-db or profile-db: items, layers, layer orders

**From a %(pan-db)s or %(profile-db)s, you can export**

- items data (%(misc-data-items)s) into a %(misc-data-items-txt)s. 

{{ codestart }}
anvi-export-misc-data -p %(profile-db)s \
                      --target-data-table items 
{{ codestop }}

- layers data (%(misc-data-layers)s) into a %(misc-data-layers-txt)s.  

{{ codestart }}
anvi-export-misc-data -p %(pan-db)s \
                      --target-data-table layers 
{{ codestop }}

- layer orders data (%(misc-data-layer-orders)s) into a %(misc-data-layer-orders-txt)s. 

{{ codestart }}
anvi-export-misc-data -p %(profile-db)s \
                      --target-data-table layer_orders 
{{ codestop }}

### From a contigs-db: nucleotide and amino acid information

**From a %(contigs-db)s, you can export**

- nucleotide data (%(misc-data-nucleotides)s) into a %(misc-data-nucleotides-txt)s.

{{ codestart }}
anvi-export-misc-data -c %(contigs-db)s 
                      --target-data-table nucleotides
{{ codestop }}

- amino acid data (%(misc-data-amino-acids)s) into a %(misc-data-amino-acids-txt)s.

{{ codestart }}
anvi-export-misc-data -c %(contigs-db)s 
                      --target-data-table amino_acids
{{ codestop }}

## Basic usage 

This program creates a %(pdb-db)s local database that holds PDB structures from [this sequence database](https://salilab.org/modeller/supplemental.html), which is hosted by the [Sali lab](https://salilab.org/).  Their database comprises all PDB RCSB sequences that have been clustered at 95%% sequence similarity. They seem to update their database every couple of months (thank you guys!).


The purpose of %(anvi-setup-pdb-database)s to have a local copy of reference structures that can be used to, for example, get template structures for homology modelling when %(anvi-gen-structure-database)s is ran.


Running this program is easy:

{{ codestart }}
anvi-setup-pdb-database --just-do-it
{{ codestop }}

If you already have a %(pdb-db)s artifact and are trying to redownload this data, run 

{{ codestart }}
anvi-setup-pdb-database --reset
{{ codestop }}

Or if you just want to update your database, run 

{{ codestart }}
anvi-setup-pdb-database --update
{{ codestop }}

## Notes

The output %(pdb-db)s database is ~20GB and its contents may take several hours to download.

This program can use an anvi'o %(clustering-configuration)s file to access various data sources in anvi'o databases to produce a hierarchical clustering dendrogram for items.

It is especially powerful when the user wishes to create a hierarchical clustering of contigs or gene clusters using only a specific set of samples. If you would like to see an example usage of this program see the article on [combining metagenomics with metatranscriptomics](https://merenlab.org/2015/06/10/combining-omics-data/).

This program opens an interactive interface to explore single amino acid variants (SAAVs) and single codon variants (SCVs) in the context of predicted tertiary protein structures and binding sites.  There are many example uses [here](http://merenlab.org/2018/09/04/getting-started-with-anvio-structure/#display-metagenomic-sequence-variants-directly-on-predicted-structures) and you can work through an example as part of [the infant gut tutorial](http://merenlab.org/tutorials/infant-gut/#chapter-vii-from-single-amino-acid-variants-to-protein-structures) as well.  This is an integral program of anvi'o structure, which you can learn more about [here](https://merenlab.org/software/anvio-structure/).


In short, this program enables users to explore sequence variation in the context of 3D protein structure, which reveals insight that cannot be learned from purely sequence-based approaches.


### Before running 

To run this program, you'll need to have created a %(structure-db)s which can be easily done with a %(contigs-db)s and the program %(anvi-gen-structure-database)s.


You'll also need a %(profile-db)s that was created using %(anvi-profile)s's flag `--profile-SCVs`, which means that single codon variants (SCVs) have been profiled. Very sorry if this forces you to re-profile, but as of v6.2, this is now a very expedient process.


### Basic Run 

There are two ways to provide the variability information to this program.  

The first is to provide a %(contigs-db)s and %(profile-db)s pair, and let this program calculate SAAVs and SCVs as they are requested by the interface.


{{ codestart }}
anvi-display-structure -s %(structure-db)s \
                       -p %(profile-db)s \
                       -c %(contigs-db)s 
{{ codestop }}

The second is to use %(anvi-gen-variability-profile)s to create a %(variability-profile-txt)s. This way, you pre-load all of the variability data and don't have to wait for %(anvi-display-structure)s to calculate variability on-the-fly. This option is probably most convenient in instances where you have already generated a %(variability-profile-txt)s for other reasons. If you fall into this camp, you can run %(anvi-display-structure)s as so:


{{ codestart }}
anvi-display-structure -s %(structure-db)s \
                       -c %(contigs-db)s \
                       -v %(variability-profile-txt)s
{{ codestop }}

{:.notice}
You still must provide the %(contigs-db)s used to generate the %(variability-profile-txt)s, since it contains other necessary information such as functional annotations and ligand binding predictions.  You may optionally provide a %(profile-db)s if custom sample grouping is important to you.

{:.notice}
During %(anvi-gen-variability-profile)s, if you are _only_ interested in genes that have predicted structures, you may want to run %(anvi-gen-variability-profile)s with the flag `--only-if-structure`.

### Refining your search

You have several options to refine what proteins and variants you're looking at: 

- Provide a list of gene caller IDs to only display specific genes (this can be provided either directly as a parameter or as a file with one gene caller ID per line)
- Specify the minimum departure from the consensus sequence. This is a number from 0-1 that describes the threshold for a variability position to be displayed. For example, if this is set to 0.2, then all SAAVs and SCVs where less than 20 percent of the reads vary from the consensus sequence will not be displayed.
- Specify samples of interest. Those in your %(profile-db)s or %(variability-profile-txt)s that are not in the samples of interest will be filtered out.

If you're choosing to have %(anvi-display-structure)s calculate variability on-the-fly, you can speed things up by choosing to _only_ calculate SAAVs or _only_ calculate SCVs.


### Other parameters 

Power users can also change the server configuration (i.e. set the IP address, port number, browser path, server password, etc.)


This program extracts the data from a %(genbank-file)s and converts it into anvi'o friendly artifacts: namely, a %(contigs-fasta)s, %(external-gene-calls)s and a %(functions-txt)s.

The %(contigs-fasta)s and %(external-gene-calls)s can be given to %(anvi-gen-contigs-database)s to create a %(contigs-db)s, and then you can use %(anvi-import-functions)s to bring the function data (in the %(functions-txt)s) into the database. Then you'll have all of the data in your %(genbank-file)s converted into a single %(contigs-db)s, which you can use for a variety of anvi'o analyses.

The parameters of this program entirely deal with the outputs. Besides telling the program where to put them, you can also give the function annotation source (in the %(functions-txt)s) a custom name. 
This program **downloads and organizes a local copy of the data from EBI's [Pfam database](https://pfam.xfam.org/) for use in function annotation.** This program generates a %(pfams-data)s artifact, which is required to run the program %(anvi-run-pfams)s. 

### Set up Pfams data
{{ codestart }}
anvi-setup-pfams 
{{ codestop }}

By default, this data is stored at `anvio/data/misc/Pfam`. To set up this data in a non-default location, run 
{{ codestart }}
anvi-setup-pfams --pfam-data-dir path/to/location
{{ codestop }}

If you already have a %(pfams-data)s artifact and are trying to redownload this data, run 

{{ codestart }}
anvi-setup-pfams --reset
{{ codestop }}
%(anvi-search-sequence-motifs)s will search one or more sequence motifs in applicable anvi'o databases and will report their frequency. If you have more than one motif to search, you can list them as comma-separated sequences

In this context we assume a motif is a 4 to 10 nucleotide-long string, although, anvi'o will not impose any limit to length, and will search any motif it is given along with its reverse-complement across all sequences and report frequencies.

The most primitive output is a TAB-delimited text file, but anvi'o will store frequency information also into your databases like a pro if you use the `--store-in-db` flag.

The following subsections include some examples.

## A contigs database

The minimum amount of stuff you need to run this program is a motif sequence and a %(contigs-db)s:

{{ codestart }}
anvi-search-sequence-motifs -c %(contigs-db)s \
                            --motifs ATCG,TAAAT \
                            --output-file motifs.txt
{{ codestop }}

Running this will yield an output file with as many columns as the number of sequence motifs that show their frequencies across each contig found in the %(contigs-db)s. Here is an example:

|contig_name|ATCG|TAAAT|
|:--|:--:|:--:|
|204_10M_contig_1720|101|159|
|204_10M_contig_6515|64|31|
|204_10M_contig_878|435|3|

## Contigs database + profile database

If you provide this program with a %(profile-db)s, this time it will count your motif sequences in split sequences rather than contigs,

{{ codestart }}
anvi-search-sequence-motifs -c %(contigs-db)s \
                            -p %(profile-db)s
                            --motifs ATCG,TAAAT \
                            --output-file motifs.txt
{{ codestop }}

And the output will look like this:

|split_name|ATCG|TAAAT|
|:--|:--:|:--:|
|204_10M_contig_1720_split_00001|14|22|
|204_10M_contig_1720_split_00002|2|6|
|204_10M_contig_1720_split_00003|14|23|
|204_10M_contig_1720_split_00004|8|18|
|204_10M_contig_1720_split_00005|9|17|
|204_10M_contig_1720_split_00006|19|28|
|204_10M_contig_1720_split_00007|4|8|
|204_10M_contig_1720_split_00008|31|32|
|204_10M_contig_1720_split_00009|0|5|
|204_10M_contig_6515_split_00001|7|5|
|204_10M_contig_6515_split_00002|5|2|
|204_10M_contig_6515_split_00003|5|4|
|204_10M_contig_6515_split_00004|25|8|
|204_10M_contig_6515_split_00005|6|2|
|204_10M_contig_6515_split_00006|8|3|
|204_10M_contig_6515_split_00007|3|3|
|204_10M_contig_6515_split_00008|5|3|
|204_10M_contig_878_split_00001|17|0|
|204_10M_contig_878_split_00002|14|0|
|204_10M_contig_878_split_00003|108|1|
|204_10M_contig_878_split_00004|35|0|
|204_10M_contig_878_split_00005|7|0|
|204_10M_contig_878_split_00006|18|0|
|204_10M_contig_878_split_00007|42|0|
|204_10M_contig_878_split_00008|12|1|
|204_10M_contig_878_split_00009|13|0|
|204_10M_contig_878_split_00010|18|0|
|204_10M_contig_878_split_00011|28|0|
|204_10M_contig_878_split_00012|0|1|
|204_10M_contig_878_split_00013|24|0|
|204_10M_contig_878_split_00014|11|0|
|204_10M_contig_878_split_00015|33|0|
|204_10M_contig_878_split_00016|13|0|
|204_10M_contig_878_split_00017|2|0|
|204_10M_contig_878_split_00018|40|0|

{:.notice}
This output format may enable you to bin your splits based on their motif composition and use %(anvi-import-collection)s to import them as a new collection into your profile database, or use %(anvi-matrix-to-newick)s to cluster them based on this information to organize splits in the interface based on their motif composition.

You can also store this information into your profile database using the flag `--store-in-db`. When you do that, running %(anvi-interactive)s on this profile database will include additional layers where these frequencies are displayed. Here is an example:

{{ codestart }}
%(anvi-search-sequence-motifs)s -c %(contigs-db)s \
                             -p %(profile-db)s
                             --motifs ATCG,TAAAT \
                             --store-in-db
{{ codestop }}

And this is how things will look like in the interface:

{{ codestart }}
%(anvi-interactive)s -c %(contigs-db)s \
                  -p %(profile-db)s
{{ codestop }}

[![motifs](../../images/layers_for_sequence_motifs.png){:.center-img .width-50}](../../images/layers_for_sequence_motifs.png)

Layers for sequence motif frequencies will be automatically colored to a shade of blue (although the user can change this through the %(interactive)s interface and/or through %(state)s files).

## Contigs database + genes database

Instead of a profile database, this program can also run on an anvi'o %(genes-db)s and search sequence motifs for each gene rather than split or contig sequences.This program uses already assembled contigs to create a mock list of short reads. You can then use these short reads to reassemble your data in order to test alternative assembly programs or analysis methods as a positive control. 

Basically, this attempts to undo the assembly and produce a data set that could have been directly received from laboratory sequencing. While the computer's mock short reads won't be perfect, they can be used to make sure your analysis pipeline is working from step 1. 

## Example Usage

This program takes an INI file - a form of text file containing various information. For this program, the example provided in the anvi'o test suite looks like this: 

```ini
[general]
short_read_length = 10
error_rate = 0.05
coverage = 100
contig = CTGTGGTTACGCCACCTTGAGAGATATTAGTCGCGTATTGCATCCGTGCCGACAAATTGCCCAACGCATCGTTCCTTCTCCTAAGTAATTTAACATGCGT
```

Note that this file contains both the contig that you want to break down, and various information about the short reads that you want to create. To run this program, just call 

{{ codestart }}
anvi-script-gen-short-reads %(configuration-ini)s \
                            --output-file-path %(short-reads-fasta)s
{{ codestop }}
    
The resulting FASTA file with short reads will cover the `contig` with short reads that are 10 nts long at 100X coverage. There will also be an error-rate of 0.05, to mimic the sequencing errors you would get from sequencing in the wet lab. 
Stores %(hmm-hits)s for a given %(hmm-source)s in a %(contigs-db)s. In short, this is the program that will do a search for HMMs against a %(contigs-db)s and store that information into the contigs-db's %(hmm-hits)s.

This is one of the programs that users commonly run on newly generated %(contigs-db)s, along with %(anvi-scan-trnas)s, %(anvi-run-ncbi-cogs)s, %(anvi-run-scg-taxonomy)s, and so on.

### HMMs in the context of anvi'o

In a nutshell, [hidden Markov models](https://en.wikipedia.org/wiki/Hidden_Markov_model) are statistical models typically generated from known genes which enable 'searching' for similar genes in other sequence contexts.

The default anvi'o distribution includes numerous [curated HMM profiles](https://github.com/merenlab/anvio/tree/master/anvio/data/hmm) for single-copy core genes and ribosomal RNAs, and anvi'o can work with custom HMM profiles provided by the user. In anvi'o lingo, each of these HMM profiles, whether they are built-in or user defined, is called an %(hmm-source)s.

### Default Usage

To run this program with all default settings (against all default anvi'o %(hmm-source)s), you only need to provide a %(contigs-db)s:

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s
{{ codestop }}

Multithreading will dramatically improve the performance of `anvi-run-hmms`. If you have multiple CPUs or cores, you may parallelize your search:


{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              --num-threads 6
{{ codestop }}


You can also run this program on a specific built-in %(hmm-source)s:

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              -I Bacteria_71
{{ codestop }}

### User-defined HMMs

Running `anvi-run-hmms` with a custom model is easy. All you need to do is to create a directory with necessary files:

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              -H MY_HMM_PROFILE
{{ codestop }}

See the relevant section in the artifact %(hmm-source)s for details.

### Adding HMM hits as a functional annotation source

By default, HMM hits are not considered functional annotations and are kept in a distinct table (the 'hmm_hits' table) in the contigs database. However, there are certain cases when you may want them to be considered as functions instead. For instance, if you want to run %(anvi-estimate-metabolism)s on a set of user-defined metabolic pathways and you have a set of custom HMMs for their enzymes.

To treat the HMM hits as functional annotations and add them to the 'gene_functions' table in your database, you must use the `--add-to-functions-table` flag:

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              -H MY_HMM_PROFILE \
              --add-to-functions-table
{{ codestop }}

### Changing the HMMER program

By default, `anvi-run-hmms` will use [HMMER](http://hmmer.org/)'s `hmmscan` for amino acid HMM profiles, but you can use `hmmsearch` if you are searching a very large number of models against a relatively smaller number of sequences:

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              --hmmer-program hmmsearch
{{ codestop }}

{:.notice}
This flag has no effect when your HMM profile source is for nucleotide sequences (like any of the Ribosomal RNA sources). In those cases anvi'o will use `nhmmscan` exclusively.

### Saving the HMMER output

If you want to see the output from the HMMER program (eg, `hmmscan`) used to annotate your data, you can request that it be saved in a directory of your choosing. Please note that this only works when you are running on a single HMM source, as in the example below:

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              -I Bacteria_71 \
              --hmmer-output-dir OUTPUT_DIR
{{ codestop }}

If you do this, file(s) with the prefix `hmm` will appear in that directory, with the file extension indicating the format of the output file. For example, the table output format would be called `hmm.table`.

{:.warning}
These resulting files are not _exactly_ the raw output of HMMER because anvi'o does quite a bit of pre-processing on the raw input and output file(s) while jumping through some hoops to make the HMM searches multi-threaded. If this is causing you a lot of headache, please let us know.

#### Requesting domain table output

{:.notice}
Please also see %(anvi-script-filter-hmm-hits-table)s

No matter what, anvi'o will use the regular table output to annotate your contigs database. However, if you are using the `--hmmer-output-dir` to store the HMMER output, you can also request a domain table output using the flag `--domain-hits-table`.

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              -I Bacteria_71 \
              --hmmer-output-dir OUTPUT_DIR \
              --domain-hits-table
{{ codestop }}

In this case anvi'o will run [HMMER](http://hmmer.org) using the `--domtblout` flag to generate this output file.

{:.notice}
This flag will only work with HMM profiles made for amino acid sequences. Profiles for nucleotide sequences require the use of the program `nhmmscan`, which does not have an option to store domain output.

Please note that this output **won't be used to filter hits to be added to the contigs database**. But it will give you the necessary output file to investigate the coverage of HMM hits. But you can use the program %(anvi-script-filter-hmm-hits-table)s with this file to remove weak hits from your HMM hits table later.


### Other things anvi-run-hmms can do

* Add the tag `--also-scan-trnas` to basically run %(anvi-scan-trnas)s for you at the same time. It's very convenient. (But it only works if you are not using the `-I` or `-H` flags at the same time because reasons.)
This program generates a NEWICK-formatted phylogenomic tree (see %(phylogeny)s) based on a given %(concatenated-gene-alignment-fasta)s. 

As mentioned in the [phylogenetics tutorial](http://merenlab.org/2017/06/07/phylogenomics/), it currently only has the option to use [FastTree](http://microbesonline.org/fasttree/) to do so, but be aware that there are many other programs that you can do this with. Some of the options we are familiar with (and are not yet represented in `anvi-gen-phylogenomic-tree`) include [MrBayes](http://mrbayes.sourceforge.net/), [MEGA](http://www.megasoftware.net/), and PHYLIP, [among many others](http://evolution.genetics.washington.edu/phylip/software.html#methods), most of which will happily take a %(concatenated-gene-alignment-fasta)s. 

Anyway, running this program is simple. Just provide the %(concatenated-gene-alignment-fasta)s with all of the genes that you want to use and the output file path for your %(phylogeny)s:

{{ codestart }}
anvi-gen-phylogenomic-tree -f %(concatenated-gene-alignment-fasta)s \
                           -o PATH/TO/%(phylogeny)s
{{ codestop }}
This program returns the nucleotide-level coverage data for a specific set of the splits or gene in your %(profile-db)s. 

If you want to get the coverage data for all splits in your %(profile-db)s, run %(anvi-export-splits-and-coverages)s with the flag `--splits-mode`. 

Simply provide a %(profile-db)s and %(contigs-db)s pair and specify which splits, or gene, you want to look at. You have three ways to do this: 

1.  Provide a single split name. (You can list all splits available with `--list-splits`)

{{ codestart }}
anvi-get-split-coverages -p %(profile-db)s \
                         -c %(contigs-db)s \
                         -o %(coverages-txt)s \ 
                         --split-name Day17a_QCcontig9_split_00003
{{ codestop }}


2. Provide both the name of a %(bin)s and the %(collection)s it is contained in. 

{{ codestart }}
anvi-get-split-coverages -p %(profile-db)s \
                         -c %(contigs-db)s \
                         -o %(coverages-txt)s \ 
                         -b %(bin)s \
                         -C %(collection)s
{{ codestop }}

You can list all collections available with `--list-collections` or all bins in a collection with `--list-bins`. Alternatively, you could run %(anvi-show-collections-and-bins)s on your %(profile-db)s to get a more comprehensive overview. 

3. Provide a gene caller id and a flanking size (bp).

{{ codestart }}
anvi-get-split-coverages -p %(profile-db)s \
                         -c %(contigs-db)s \
                         -o %(coverages-txt)s \ 
                         --gene-caller-id 25961 \
                         --flank-length 500
{{ codestop }}
This program **calculates the pN/pS ratio** for each gene in a %(contigs-db)s and outputs it as a %(pn-ps-data)s artifact.

### What is the pN/pS ratio?

The pN/pS ratio (first described in [Schloissnig et al. 2012](https://doi.org/10.1038/nature11711))
is the ratio of 2 rates: the rates of non-synonymous (pN) and synonymous (pS) **polymorphism**. It is analogous to
dN/dS, which is the ratio of rates between non-synonymous (dN) and synonymous **substitutions** between 2
strains/species. We calculate pN/pS from allele frequency obtained through SCVs and SAAVs (see
[publication in preparation](FIXME)) for exact implementation details.

### Neat. How do I use this program?

Firstly, you'll need to run %(anvi-gen-variability-profile)s using the flag `--engine CDN` to get a %(variability-profile-txt)s for SCVs (single codon variants), which we'll name `SCVs.txt` in this example.

Then you can run this program like so:

{{ codestart }}
anvi-get-pn-ps-ratio -V SCVs.txt \
                     -c %(contigs-db)s \
                     -o output_dir
{{ codestop }}

A pN/pS value is calculated for each (gene, sample) combo. This will result in a directory called `output_dir` that contains several tables that describe each of your genes. See %(pn-ps-data)s for more information.

### Other parameters

This program has some default filtering choices that you should pay mind to. You can tune these filter options with the following variables:

- The minimum departure from consensus for a variable position (`--min-departure-from-consensus`).
- The minimum departure from reference for a variable position (`--min-departure-from-reference`).
- The minimum number of SCVs in a grouping (`--minimum-num-variants`).
- The minimum coverage at a variable position (`--min-coverage`).
This program **generates a %(genes-db)s, which stores the coverage and detection values for all of the genes in your %(contigs-db)s.** 

This information is usually calculated when it's needed (for example when running %(anvi-interactive)s in genes mode), but this program lets you break this process into two steps. This way, you can easily change the parameters of %(anvi-interactive)s without having to recalculate the gene-level statistics. 

Given a %(contigs-db)s and %(profile-db)s pair, as well as a %(collection)s, this program will calculate the stats for the genes in each of your %(bin)ss and give each bin its own %(profile-db)s that includes this information. 

For example, if a %(collection)s called `GENE_COLLECTION` contained the bins `bin_0001`, `bin_0002`, and `bin_0003` and you ran:

{{ codestart }}
anvi-gen-gene-level-stats-databases -c %(contigs-db)s \
                                    -p %(profile-db)s \
                                    -C %(collection)s 
{{ codestop }}

Then it will create a directory called `GENES` that contains three %(profile-db)s called `GENE_COLLECTION-bin_0001.db`, `GENE_COLLECTION-bin_0002.db`, and `GENE_COLLECTION-bin_0003.db`. In terms of output, this program is similar to %(anvi-split)s: each of these databases can now be treated as self-contained anvi'o projects but they also contain the gene-level information. Thus, you then could run %(anvi-interactive)s in genes mode on one of these profile databases. 

You also have the option to provide a list of %(bin)s (either as a file or as a string) to anlyze instead of a single %(collection)s. 

### Other Parameters

You can also change the definition of an outlier nucleotide position or switch calculations to use the [INSeq/Tn-Seq](https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/in-seq-tn-seq.html) statistical methods. 
This program converts a distance matrix (computed from a %(view-data)s artifact) into a %(dendrogram)s. 

It uses the numerical data in a %(view-data)s to compute a distance matrix behind the scenes, and then runs some hierarchical clustering to create a %(dendrogram)s for all of your items. 

With all default parameters, a run would look like this:

{{ codestart }}
anvi-matrix-to-newick -o path/for/%(dendrogram)s \ 
                      %(view-data)s 
{{ codestop }}

If your input file has your samples as rows instead of columns, just add the flag `--transpose`. 

You can also ask for an additional output file: the order of the items in the resulting dendrogram as a %(misc-data-items-order)s in LIST format. To get this, simply provide a path to its desired location  with `--items-order-file`. 

Additionally, for hierarchical clustering, you can change the distance metric (a full list of the available metrics can be found [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html)) or the linkage method (though this is not recommended, the list of options can be found [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html)).
Hi there :) This program is now deprecated. Please continue with one of these below instead:

* %(anvi-compute-metabolic-enrichment)s
* %(anvi-compute-functional-enrichment-in-pan)s
* %(anvi-compute-functional-enrichment-across-genomes)s
The purpose of %(anvi-display-metabolism)s is to interactively view metabolism estimation data.

This program internally uses %(anvi-estimate-metabolism)s to obtain this data for the provided %(contigs-db)s.

It is still under development.
This program integrates the information from an %(internal-genomes)s artifact into a %(pan-db)s, creating a metapangenome. 

A metapangenome contains both the information in a metagenome (i.e. their abundances in different samples as described in your %(profile-db)s) and the information in a pangenome (i.e. the gene clusters in your dataset). This is useful because you are able to observe which gene cluster patterns are present in certain environments. For an example of a metapangenomic workflow, take a look [here](http://merenlab.org/data/prochlorococcus-metapangenome/) (this tutorial was written before this program, but the insights persist). 

To use this program, provide a %(pan-db)s and %(genomes-storage-db)s pair, as well as an %(internal-genomes)s.

{{ codestart }}
anvi-meta-pan-genome -p %(pan-db)s \
                     -g %(genomes-storage-db)s \
                     -i %(internal-genomes)s 
{{ codestop }}

However, when integrating metagenomic and pangenomic data together, you'll get a lot of data. You can set two additional parameters to help you filter out data that doesn't mean certain standards:

- `--fraction-of-median-coverage`: this threshold removes genes with less than this fraction of the median coverage. The default is 0.25. So, for example, if the median coverage in your data was 100X, this would remove all genes with coverage less than 25X. 
- `--min-detection`: this threshold removes genomes with detection less than this value in all samples. The default is 0.5.
This program, as implied by the name, is used to delete a %(collection)s from a %(profile-db)s. 

When you do this, you'll lose the collection forever, as well as the %(bin)ss within it. It is generally a good idea to export your binning effort into a %(collection-txt)s using %(anvi-export-collection)s before deleting it, just to be safe. 

To list available collections in a database, call 

{{ codestart }}
anvi-delete-collection -p %(profile-db)s \
                       --list-collections
{{ codestop }}

Then, you can easily delete a collection with the command

{{ codestart }}
anvi-delete-collection -p %(profile-db)s \
                       -C %(collection)s
{{ codestop }}
Displays information about an anvi'o database, and allows users to modify that information when absolutely necessary.

This program is particularly useful for debugging, but also handy in a pinch if you want to check some facts about your database - to answer questions like "did I run HMMs on this %(contigs-db)s yet?" or "is this a merged %(profile-db)s?" This program can also be very dangerous when used to inappropriately modify database information, so if you want to change something, please proceed with caution.

### What information will I see?

All anvi'o databases contain a table of self-describing information known as the "self" table. It helps anvi'o keep track of critical facts such as the type of the database, its version number, and the date it was created. It also saves information about how the database was generated, what sorts of data it contains, what programs have been run on it, and so on. In general, this table exists so that anvi'o can make sure you are doing the right things with your data and that nothing will blow up. `anvi-db-info` will show you the contents of the self table when you run this program on an anvi'o database.

The information in the self table will be different depending on the kind of database you are looking at. For example, a %(contigs-db)s self table will indicate the number of contigs (and splits) in the database, whether or not gene calling was done (and with what gene callers), and which functional annotation sources have been used to annotate the genes. A %(profile-db)s self table will list which samples it contains mapping information for, how many reads where mapped from each sample, and whether or not SNVs have been profiled. A %(modules-db)s (see also %(kegg-data)s) self table will tell you how many KEGG modules are saved in the database and what is the hash value of the database contents. We could go on, but you probably get the picture.

### View information about a database

This is the only way that most people will use this program, and it is very simple. Just provide the path to any anvi'o database to this program, and check the output on your terminal screen:

{{ codestart }}
anvi-db-info path-to-DB.db
{{ codestop }}

Let's be even more specific and say you have a %(contigs-db)s called `CONTIGS.db`. To look at its self table, you would run the following:
{{ codestart }}
anvi-db-info CONTIGS.db
{{ codestop }}

That's it! Easy-peasy lemon-squeezy.

### Example output

Here is an example of what you might see for a %(contigs-db)s.

```
DB Info (no touch)
===============================================
Database Path ................................: CONTIGS.db
Description ..................................: No description is given
Type .........................................: contigs
Variant ......................................: None
Version ......................................: 20


DB Info (no touch also)
===============================================
contigs_db_hash ..............................: d51abf0a
split_length .................................: 20000
kmer_size ....................................: 4
num_contigs ..................................: 4189
total_length .................................: 35766167
num_splits ...................................: 4784
genes_are_called .............................: 1
splits_consider_gene_calls ...................: 1
creation_date ................................: 1466453807.46107
project_name .................................: Infant Gut Contigs from Sharon et al.
gene_level_taxonomy_source ...................:
scg_taxonomy_was_run .........................: 0
external_gene_calls ..........................: 0
external_gene_amino_acid_seqs ................: 0
skip_predict_frame ...........................: 0
scg_taxonomy_database_version ................: None
trna_taxonomy_was_run ........................: 0
trna_taxonomy_database_version ...............: None
modules_db_hash ..............................: 72700e4db2bc
gene_function_sources ........................: KEGG_Module,COG14_CATEGORY,COG14_FUNCTION,KEGG_Class,KOfam

* Please remember that it is never a good idea to change these values. But in some
cases it may be absolutely necessary to update something here, and a programmer
may ask you to run this program and do it. But even then, you should be
extremely careful.

AVAILABLE GENE CALLERS
===============================================
* 'prodigal' (32,265 gene calls)
* 'Ribosomal_RNAs' (9 gene calls)


AVAILABLE FUNCTIONAL ANNOTATION SOURCES
===============================================
* COG14_CATEGORY (21,121 annotations)
* COG14_FUNCTION (21,121 annotations)
* KEGG_Class (2,760 annotations)
* KEGG_Module (2,760 annotations)
* KOfam (14,391 annotations)


AVAILABLE HMM SOURCES
===============================================
* 'Archaea_76' (type 'singlecopy' with 76 models and 404 hits)
* 'Bacteria_71' (type 'singlecopy' with 71 models and 674 hits)
* 'Protista_83' (type 'singlecopy' with 83 models and 100 hits)
* 'Ribosomal_RNAs' (type 'Ribosomal_RNAs' with 12 models and 9 hits)
```

Most of this output is self-explanatory. But one thing that may not be quite obvious to some is that in many cases we use `0` to indicate 'False' and `1` to indicate 'True'. So for this example, you will see that SCG taxonomy was run on this database, but tRNA taxonomy was not.

### Modifying database information
We just need to start by saying - you probably shouldn't do this. Manually changing the values in the self table has the potential to break things downstream because it lets you avoid some of anvi'o's internal sanity checks which prevent you from doing things you shouldn't. If you change things and start running into ugly errors, do not be surprised.

That being said, sometimes you just need to live on the edge and do some hacking, and `anvi-db-info` will let you do that. If a programmer sent you here to update a value in the self table or if you are just foraging ahead on your own, this is how you would do it. Let's change the `project_name` value as an example because it is mostly descriptive and seems fairly safe:

{{ codestart }}
anvi-db-info --self-key project_name --self-value "test" CONTIGS.db
{{ codestop }}

If you run this, you will see a warning telling you what the current value of `project_name` is and what it will be changed to, but the value will not actually be changed just yet. If you are sure you want to do this, you then need to run:

{{ codestart }}
anvi-db-info --self-key project_name --self-value "test" CONTIGS.db  --just-do-it
{{ codestop }}

Then go on your merry adventuring way.
This program **creates smaller, self-contained anvi'o projects for each of the %(bin)ss in your project.** This is useful if you would like to share a subset of an anvi'o project. 

Simply provide either a %(contigs-db)s and %(profile-db)s pair or a %(genomes-storage-db)s and %(pan-db)s pair, as well as a %(collection)s, and it will create directories for each of your bins that contain their own databases and information. In other words, each of these directories will contain their own anvi'o projects that represent the contigs or genomes stored in that single bin. 

### An example run 

For example, let's say a %(profile-db)s has a %(collection)s with three bins, which are (very creatively) called `BIN_1`, `BIN_2`, and `BIN_3`.  

If you ran the following code: 

{{ codestart }}
anvi-split -p %(profile-db)s \
           -c %(contigs-db)s \
           -C %(collection)s \
           -o MY_PATH
{{ codestop }}

Then in the location `MY_PATH`, you would have three folders: `BIN_1`, `BIN_2`, and `BIN_3`.  Each one contains its own %(profile-db)s and %(contigs-db)s that only contains the contigs from that bin. You can then give a fellow anvi'o user just the `BIN_1` directory and they can get to work. 

Similarly, if you provide a %(genomes-storage-db)s and %(pan-db)s pair, the directories will contain their own smaller %(genomes-storage-db)s and %(pan-db)s pairs. 

### Other options 

You are also able to skip generating variability tables or compress the auxiliary data to save space. 
This program converts a gene call file from [AUGUSTUS](http://bioinf.uni-greifswald.de/augustus/) (as an %(augustus-gene-calls)s artifact) to an anvi'o %(external-gene-calls)s artifact. 

This essentially just reformats the data in the %(augustus-gene-calls)s artifact (for example, removing the UTR information) so that it can be read by other anvi'o programs. 

A run of this program will look something like this:

{{ codestart }}
anvi-script-augustus-output-to-external-gene-calls -i %(augustus-gene-calls)s
                                                   -o %(external-gene-calls)s
{{ codestop }}

Here is an example of what the resulting %(external-gene-calls)s file will look like (from the gff file used as an example on the %(augustus-gene-calls)s page):  

    gene_callers_id    contig       start    stop    direction    partial    call_type    source      version    aa_sequence
    0                  unnamed-1    56       1252    f            0          1            AUGUSTUS    v3.3.3     MSEGNAAGEPSTPGGPRPLLTGARGLIGRRPAPPLTPGRLPSIRSRDLTLGGVKKKTFTPNIISRKIKEEPKEEVTVKKEKRERDRDRQREGHGRGRGRPEVIQSHSIFEQGPAEMMKKKGNWDKTVDVSDMGPSHIINIKKEKRETDEETKQILRMLEKDDFLDDPGLRNDTRNMPVQLPLAHSGWLFKEENDEPDVKPWLAGPKEEDMEVDIPAVKVKEEPRDEEEEAKMKAPPKAARKTPGLPKDVSVAELLRELSLTKEEELLFLQLPDTLPGQPPTQDIKPIKTEVQGEDGQVVLIKQEKDREAKLAENACTLADLTEGQVGKLLIRKSGRVQLLLGKVTLDVTMGTACSFLQELVSVGLGDSRTGEMTVLGHVKHKLVCSPDFESLLDHKHR

This program takes in a %(short-reads-fasta)s file and tries to recreate what paired reads for the data in that fasta file might look like. 

An arbitrarily chosen half of the reads will be put into the R1 output, while the other half will be reverse complemented and put into the R2 output. 

For example, if you ran 

{{ codestart }}
anvi-script-gen-pseudo-paired-reads-from-fastq -f %(short-reads-fasta)s \
                                               -O MY_READS 
{{ codestop }}

Then you would end up with two files: 

- `MY_READS_1.fastq` which contains half of the reads straight out of your input file
- `MY_READS_2.fastq` which contains the reverse complement of the other half of the reads. 
This program is for filtering a %(hmm-source)s from a %(hmm-hits)s in a %(contigs-db)s using HMM alignment parameters such as query-coverage and target-coverage. Briefly, the program will remove all records from an %(hmm-source)s in the %(hmm-hits)s, then import a new %(hmm-hits)s table into the %(contigs-db)s that was filtered to your specifications.

For this, you first need to ask %(anvi-run-hmms)s to ask HMMER to report a domain hits table by including `--domain-hits-table` flag in your command:

{{ codestart }}
anvi-run-hmms -c %(contigs-db)s \
              -I Bacteria_71 \
              --hmmer-output-dir path/to/DOMTABLE.txt
              --domain-hits-table
{{ codestop }}

At the end of this run, your HMM hits will be stored in your contigs database as usual. But with the availability of the domain hits table from this run, you can filter out hits from your contigs database using thresholds for query or target coverage of each hit.

For instance following the command above, the command below will remove HMM hits from your contigs database for genes that had less than 90%% coverage of the target:

{{ codestart }}
anvi-script-filter-hmm-hits-table -c %(contigs-db)s \
                                  --hmm-source Bacteria_71 \
                                  --domain-hits-table path/to/DOMTABLE.txt \
                                  --target-coverage 0.9
{{ codestop }}
This program allows you to update the description of any anvi'o database with the push of a button (and the writing of an updated description). 

This descirption helps make UIs a little prettier by showing up when you run programs like %(anvi-interactive)s and %(anvi-summarize)s. 

Simply write out the description that you would prefer in a plain text file (with markdown syntax) and use this program to update the description of any %(pan-db)s, %(profile-db)s, %(contigs-db)s, or %(genomes-storage-db)s: 

{{ codestart }}
anvi-update-db-description --description my_description.txt \
                           %(contigs-db)s
{{ codestop }}

This program **gives you the coverage information in your %(profile-db)s as external files**. Basically, if you want to take that information in your %(profile-db)s out of anvio, this is for you. 

Once you input your %(profile-db)s and the %(contigs-db)s you used to generate it, it will create a %(contigs-fasta)s that lists your contigs for you, as well as a %(coverages-txt)s, which describes your coverage information. 

{{ codestart }}
anvi-export-splits-and-coverages -p %(profile-db)s \
                                 -c %(contigs-db)s
{{ codestop }}

If your coverages are skewed by outlier positions, consider using Q2Q3-coverages instead.

{{ codestart }}
anvi-export-splits-and-coverages -p %(profile-db)s \
                                 -c %(contigs-db)s \
                                 --use-Q2Q3-coverages
{{ codestop }}

### Contigs or splits?

*Wondering what the difference is? Check out [our vocab page](http://merenlab.org/vocabulary/#split).*

By default, this program will give you the sequences of your splits, but will look at coverage data in terms of the parent contig. If you want to get coverage information for your splits, use `--splits-mode`. Alternatively, you can ask the program to `--report-contigs` to look at contig sequences instead. 

This program generates a matrix of the pairwise fixation indices (F<sub>ST</sub>) between your samples.

### What's a fixation index?

As described [in the Infant Gut Tutorial](https://merenlab.org/tutorials/infant-gut/#measuring-distances-between-metagenomes-with-fst), the fixation index is a measure of the distance between two populations, based on their sequence variants (usually SNVs). Specifically, the fixation index is the ratio between the variance in allele frequency between subpopulations and the variance in the total population. 


The fixation index has its own [Wikipedia page](https://en.wikipedia.org/wiki/Fixation_index) and is a special case of [F-statistics](https://en.wikipedia.org/wiki/F-statistics). 


In anvi'o, the fixation index is calculated in accordance with [Schloissnig et al.  (2013)](https://doi.org/10.1038/nature11711)'s work to allow variant positions with multiple competing alleles.


## Anvi-gen-fixation-index 

There are two ways to run this program.  

### Input 1: Variability Profile 

The simplest one is the one shown [in the Infant Gut Tutorial](https://merenlab.org/tutorials/infant-gut/#measuring-distances-between-metagenomes-with-fst): just provide a %(variability-profile)s, like so: 

{{ codestart }}
anvi-gen-fixation-index-matrix --variability-profile %(variability-profile)s \
                               --output-file my_matrix.txt
{{ codestop }}

This will use the information in your %(variability-profile-txt)s to generate the fixation index for each of the pairwise sample comparisons, and store the results in a %(fixation-index-matrix)s named `my_matrix.txt`.  

### Input 2: Anvi'o databases

Instead of providing a %(variability-profile)s, you can instead provide the inputs to %(anvi-gen-variability-profile)s and let anvi'o do all of the work for you. Specifically, this means providing a %(contigs-db)s and %(profile-db)s pair to find your variability positions and a specific subset to focus on in any of these ways: 

- Provide a list of gene caller IDs (as a parameter with the flag `--gene-caller-ids` or in a file with one ID per line with the flag `--genes-of-interest`)
- Provide a list of splits (in a %(splits-txt)s)
- Provide a %(collection)s and %(bin)s

Additionally, you can add structural annotations by inputting a %(structure-db)s (and focus only on genes with structural annotations with the flag `--only-if-structure`) or choose to focus on only a subset of your samples by providing a file of samples of interest.  

When doing this, you can also set the variability engine to get the fixation index for SCVs (`--engine CDN`) or SAAVs (`--engine AA`). 

You can find more information about these parameters on the page for %(anvi-gen-variability-profile)s. 

### Additional Parameters

While a fixation index is usually between 0 and 1, it is possible for an index to be negative (usually because of out-breeding). By default, anvi'o sets these negative values to 0, but you can choose to keep the negative values with the flag `--keep-negatives` 

This script **converts a %(variability-profile-txt)s into %(vcf)s (Variant Call Format).** 

It is very easy to run: just provide the input and output paths as so:

{{ codestart }}
anvi-script-variability-to-vcf -i %(variability-profile-txt)s \ 
                               -o %(vcf)s 
{{ codestop }}

Note that to run this, you'll need to have run %(anvi-gen-variability-profile)s with the default nucleotide engine. 
This program **generates tabular files of tRNA-seq seed coverage and modification data that are easily manipulable by the user**.

anvi-tabulate-trnaseq is part of the %(trnaseq-workflow)s, and is run following the finalization of tRNA seeds by %(anvi-merge-trnaseq)s.

This program generates a table, %(seeds-specific-txt)s, containing the specific coverage of each nucleotide position in each seed in every sample. If a nonspecific %(trnaseq-profile-db)s is also provided, this program generates a table of nonspecific coverages, %(seeds-non-specific-txt)s. The distinction between specific and nonspecific coverage is explained in the %(trnaseq-profile-db)s artifact. These coverage tables have one row per seed per sample. They have three header rows for different ways of describing tRNA nucleotide positions: canonical position name (e.g., "discriminator_1"), canonical position (e.g., "73"), and "ordinal" position relative to all the other **possible** positions (e.g., "95").

anvi-tabulate-trnaseq also generates a table, %(modifications-txt)s, containing information on each predicted modification position in each seed, with one row per modification per seed per sample. This table includes four columns of position coverage counts of the four nucleotides.

All tables include taxonomic annotations of the seeds; annotations are added to the %(trnaseq-contigs-db)s by %(anvi-run-trna-taxonomy)s.
This program **converts a %(fasta)s file to a %(contigs-fasta)s.** In other words, it reformats your FASTA formatted file to meet the conditions required of a %(contigs-fasta)s, which is able to be used by other anvi'o programs.

{{ codestart }}
anvi-script-reformat-fasta %(fasta)s \
                           -o %(contigs-fasta)s \
                           --simplify-names
{{ codestop }}

{:.notice}
If you use the flag *--report-file*, it will also create a TAB-delimited file for you to keep track of which defline in the new file corresponds to which defline in the original file.

### Removing the short reads

Removing short contigs from a FASTA file will improve the performance of the %(contigs-db)s later. The example below runs the same command while also removing sequences that are shorter than 1,000 nts:

{{ codestart }}
anvi-script-reformat-fasta %(fasta)s \
                           -o %(contigs-fasta)s \
                           -l 1000 \
                           --simplify-names
{{ codestop }}

After you've added misc-data of some kind (%(misc-data-items)s, %(misc-data-layers)s, %(misc-data-layer-orders)s, %(misc-data-nucleotides)s, or %(misc-data-amino-acids)s) using %(anvi-import-misc-data)s, you can **delete that data and remove it from the interactive interface** using this program. 

This program will release your data into the ether, never to be seen again. If you would like to first export it into a text file (so that it can be seen again), you can do so with %(anvi-export-misc-data)s. 

This program only works on data that is listed as an available key (most often because it was previously imported by the user). To view available keys, call either

{{ codestart }}
anvi-delete-misc-data -p %(profile-db)s \
                      --target-data-table items|layers|layer_orders \
                      --list-available-keys
{{ codestop }}

or 

{{ codestart }}
anvi-delete-misc-data -c %(contigs-db)s \
                      --target-data-table nucleotides|amino_acids \
                      --list-available-keys
{{ codestop }}

where you choose the appropriate option for the `taget-data-table`. 

If your misc-data is associated with a specific data group, you can provide that data group to this program with the `-D` flag. 

## Data types you can delete 

### From a pan-db or profile-db: items, layers, layer orders

**From a %(pan-db)s or %(profile-db)s, you can delete**

- items data (%(misc-data-items)s) 

{{ codestart }}
anvi-delete-misc-data -p %(profile-db)s \
                      --target-data-table items \
                      --keys-to-remove key_1
{{ codestop }}

- layers data (%(misc-data-layers)s)

{{ codestart }}
anvi-delete-misc-data -p %(pan-db)s \
                      --target-data-table layers \
                      --keys-to-remove key_2,key_3
{{ codestop }}

- layer orders data (%(misc-data-layer-orders)s)

{{ codestart }}
anvi-delete-misc-data -p %(profile-db)s \
                      --target-data-table layer_orders \
                      --keys-to-remove key_4
{{ codestop }}

### From a contigs-db: nucleotide and amino acid data

**From a %(contigs-db)s, you can delete**

- nucleotide data (%(misc-data-nucleotides)s)

{{ codestart }}
anvi-delete-misc-data -c %(contigs-db)s \
                      --target-data-table nucleotides \
                      --keys-to-remove key_1
{{ codestop }}

- amino acid data (%(misc-data-amino-acids)s)

{{ codestart }}
anvi-delete-misc-data -c %(contigs-db)s \
                      --target-data-table amino_acids \
                      --keys-to-remove key_2
{{ codestop }}
This program, as implied by the name, is used to delete a %(state)s from a %(pan-db)s or %(profile-db)s. This way, you can remove states that are clogging up the state list in the interface. 

It is generally a good idea to export your state before deleting it, just in case ((anvi-export-state)s).

To list available %(state)ss in a database, call 

{{ codestart }}
anvi-delete-state -p %(pan-db)s \
                 --list-states
{{ codestop }}

Then, you can easily delete a %(state)s with the command

{{ codestart }}
anvi-delete-hmms -p %(profile-db)s \
                 -s %(state)s 
{{ codestop }}
This program takes an input %(fasta)s file with one or more sequences, then **corrects INDELs associated with homopolymer regions given a reference %(fasta)s file**, and reports edited sequences as a new %(fasta)s file.

{:.warning}
You must be extremely careful with this program since it reports edited sequences.

## Better alternatives

If you need a comprehensive solution to correct your long-read sequencing data for serious applications, you should not use this script, but resort to better alternatives designed to correct frameshift errors.

For instance, [Arumugam et al's solution](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-019-0665-y) leverages NCBI's nr protein database to correct frameshift errors through modified-DIAMOND alignments. Another solution, [homopolish](https://github.com/ythuang0522/homopolish) by Yao-Ting Huang et al, uses mash sketches to correct minION sequences. You may also want to check [proovframe](https://github.com/thackl/proovframe) by Thomas Hackl, which aims to correct frame-shift errors in long-read sequencing data.

## Motivation

We developed this tool largely to test the impact of INDEL errors associated with homopolymers Oxford Nanopore Technology yields. When there is a high-quality reference genome, this program can align a set of input sequences to the reference, and when it sees something like this in the alignment:

```
Input sequence ......: ... CGAAAAACG ...
Reference sequence ..: ... CGAAA--CG ...
```

It can correct the input sequence to look like this, since this would indicate that the additional `A` nucleotides after `AAA` were likely due to errors from the long-read sequencing:

```
Input sequence ......: ... CGAAACG ...
```

Similarly, if the program sees a case like this:

```
Input sequence ......: ... CGAAA--CG ...
Reference sequence ..: ... CGAAAAACG ...
```

The program would correct the input sequence this way, assuming that the lacking `A` nucleotides were likely due to errors from long-read sequencing:


```
Input sequence ......: ... CGAAAAACG ...
```

{:.warning}
Please note that INDEL errors associated with homopolymers are only a subset of errors that will casue frameshifts and impact amino acid sequences.

## Homopolymer length

The parameter `--min-homopolymer-length` helps the program to determine what to call a homopolymer region. Please read the help menu for this parameter carefully since it is not exactly intuitive.

The value `3` would be a stringent setting. But you may want to lower it to `2` if you promise to evaluate your output carefully.

The script includes some pre-aligned test sequences for you to see how `--min-homopolymer-length` influences things. For instance, here is the output for `--min-homopolymer-length 2`:

```
anvi-script-fix-homopolymer-indels --test-run \
                                   --min-homopolymer-length 2

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCG-AAATCGATCGATCG

GAPS BEFORE REPEATS OF "A"
===============================================
Query ........................................: AAA
Reference ....................................: -AA
Resolution ...................................: {'action': 'DEL', 'positions': [12], 'nt': 'A'}

Edited query sequence ........................: ATCGATCGATCGAAATCGATCGATCG
Query sequence edited correctly? .............: Yes

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAA-TCGATCGATCG

GAPS AFTER REPEATS OF "A"
===============================================
Query ........................................: AAA
Reference ....................................: AA-
Resolution ...................................: {'action': 'DEL', 'positions': [14], 'nt': 'A'}

Edited query sequence ........................: ATCGATCGATCGAAATCGATCGATCG
Query sequence edited correctly? .............: Yes

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAA-TCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAAAATCGATCGATCG

GAPS AFTER REPEATS OF "A"
===============================================
Query ........................................: AA-
Reference ....................................: AAA
Resolution ...................................: {'action': 'INS', 'positions': [15], 'nt': 'A'}

Edited query sequence ........................: ATCGATCGATCGAAAATCGATCGATCG
Query sequence edited correctly? .............: Yes

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: A-C-AT-GATCG-AAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAAAATCGATCGATCG

GAPS BEFORE REPEATS OF "A"
===============================================
Query ........................................: -AA
Reference ....................................: AAA
Resolution ...................................: {'action': 'INS', 'positions': [9], 'nt': 'A'}

Edited query sequence ........................: ACATGATCGAAAATCGATCGATCG
Query sequence edited correctly? .............: Yes

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAA-TCGATCGATCG

GAPS AFTER REPEATS OF "A"
===============================================
Query ........................................: AAA
Reference ....................................: AA-
Resolution ...................................: {'action': 'DEL', 'positions': [14], 'nt': 'A'}

Edited query sequence ........................: ATCGATCGATCGAATCGATCGATCG
Query sequence edited correctly? .............: Yes
```

The output for the same input sequences with `--min-homopolymer-length 3`:


```
anvi-script-fix-homopolymer-indels --test-run \
                                   --min-homopolymer-length 3


* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCG-AAATCGATCGATCG

GAPS BEFORE REPEATS OF "A"
===============================================
Query ........................................: AAAA
Reference ....................................: -AAA
Resolution ...................................: {'action': 'DEL', 'positions': [12], 'nt': 'A'}

Edited query sequence ........................: ATCGATCGATCGAAATCGATCGATCG
Query sequence edited correctly? .............: Yes

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAA-TCGATCGATCG
Edited query sequence ........................: ATCGATCGATCGAAAATCGATCGATCG
Query sequence edited correctly? .............: No

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAA-TCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAAAATCGATCGATCG

GAPS AFTER REPEATS OF "A"
===============================================
Query ........................................: AAA-
Reference ....................................: AAAA
Resolution ...................................: {'action': 'INS', 'positions': [15], 'nt': 'A'}

Edited query sequence ........................: ATCGATCGATCGAAAATCGATCGATCG
Query sequence edited correctly? .............: Yes

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: A-C-AT-GATCG-AAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAAAATCGATCGATCG

GAPS BEFORE REPEATS OF "A"
===============================================
Query ........................................: -AAA
Reference ....................................: AAAA
Resolution ...................................: {'action': 'INS', 'positions': [9], 'nt': 'A'}

Edited query sequence ........................: ACATGATCGAAAATCGATCGATCG
Query sequence edited correctly? .............: Yes

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAA-TCGATCGATCG
Edited query sequence ........................: ATCGATCGATCGAAATCGATCGATCG
Query sequence edited correctly? .............: No
```

The output for the same input sequences with `--min-homopolymer-length 4`:

```
anvi-script-fix-homopolymer-indels --test-run \
                                   --min-homopolymer-length 4

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCG-AAATCGATCGATCG
Edited query sequence ........................: ATCGATCGATCGAAAATCGATCGATCG
Query sequence edited correctly? .............: No

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAA-TCGATCGATCG
Edited query sequence ........................: ATCGATCGATCGAAAATCGATCGATCG
Query sequence edited correctly? .............: No

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAA-TCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAAAATCGATCGATCG
Edited query sequence ........................: ATCGATCGATCGAAATCGATCGATCG
Query sequence edited correctly? .............: No

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: A-C-AT-GATCG-AAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAAAATCGATCGATCG
Edited query sequence ........................: ACATGATCGAAATCGATCGATCG
Query sequence edited correctly? .............: No

* >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Query sequence ...............................: ATCGATCGATCGAAATCGATCGATCG
Reference sequence ...........................: ATCGATCGATCGAA-TCGATCGATCG
Edited query sequence ........................: ATCGATCGATCGAAATCGATCGATCG
Query sequence edited correctly? .............: No
```

## Tips and Warnings

As you correct your input sequences one round, the BLAST may produce new homopolymers. So you may want to re-run the tool by turning the output sequence into an input sequence. For instance, we had a genome reconstructed using long-read sequencing that matched to a gold-standard genome on NCBI.

Running the script the first time this way,

``` bash
anvi-script-fix-homopolymer-indels --input Genome_minION.fasta \
                                   --reference Genome_NCBI_REF.fasta \
                                   --output Genome_minION_CORRECTED.fasta
```

Produced the following output:

```
OVERALL & PER-SEQUENCE STATS
===============================================
Num input sequences ..........................: 1
Num homopolymers associated with INDELs ......: 529
Num actions ..................................: 597
Num insertions ...............................: 292
Num deletions ................................: 305

* contig_332_pilon
    - Homopolymers: 529
    - Insertions: 292
    - Deletions: 305

Corrected output FASTA .......................: Genome_minION_CORRECTED.fasta
```

Then copying the output file as the input file,

```
cp Genome_minION_CORRECTED.fasta Genome_minION.fasta
```

And re-running the script the same way multiple times gave the following outputs:

``` bash

# (first round)

* contig_332_pilon
    - Homopolymers associated with INDELs: 29
    - Insertions: 21
    - Deletions: 10

# (second round)

* contig_332_pilon
    - Homopolymers associated with INDELs: 17
    - Insertions: 9
    - Deletions: 13

# (third round)

* contig_332_pilon
    - Homopolymers associated with INDELs: 4
    - Insertions: 4
    - Deletions: 0

# (fourth round)

* contig_332_pilon
    - Homopolymers associated with INDELs: 0
    - Insertions: 0
    - Deletions: 0
```

At the end, there were no more homopolymers associated with INDELs.

**Please consider the following points**:

* If the input and reference genomes are not closely related enough (i.e., expected ANI if there were no sequencing errors > 98%%-99%%), this process may yield very incorrect outcomes. But it should work great for genomes reconstructed from the same culture.

* The iterative improvement of a given input genome may reach to a 'back-and-forth' situation where there is no overall improvement, but the homopolymers associated with INDELs do not reach to 0. This happens when there are repeats in the reference genome that are identical to each other expect the number of nucleotides in homopolymers.

* You can always add `--verbose` to your command to see every single case that is considered, and resolution anvi'o reached.

* The script cleans after itself. But if you add the flag `--debug` to your call, you will find the raw blast output in XML form, which is the primary file this script uses to identify and correct INDELS associated with homopolymers.

* Under all circumstances, it is important to double check your results, and make sure you keep in mind that anything you see outstanding in your downstream analyses may be due to this step.

## A real-world example

This example involves two circular bacterial genomes, `W01` and `W48`, both of which were reconstructed using minION long-reads that were assembled by [Flye](https://github.com/fenderglass/Flye) and polished by [Pilon](https://github.com/broadinstitute/pilon/wiki).

Although `W01` and `W48` were supposed to be near-identical genomes based on our understanding of the system, the pangenome contained a lot of gene clusters that were either found only in `W01` or only in `W48`, which was quite unexpected. We thought that the spurious gene clusters were in-part due to frame-shifts caused by INDELs associated with random and erroneous homopolymers that influenced both genomes.

The following GIF shows three pangenomes for (1) the uncorrected genomes, (2) `W01` corrected by `W02` using `--min-homopolymer-lenth 3` and (3) `W01` corrected by `W02` using `--min-homopolymer-lenth 2`. Please note that the sequence for `W48` is unchanged throughout these steps, but it is only `W01` that is modified:

![an anvi'o display](../../images/anvi-script-fix-homopolymer-indels-test.gif){:.center-img}

As this preliminary analysis shows, not only there is a reasonable reduction in spurious gene clusters, but also the homogeneity indices for core gene clusters display remarkable improvement. `--min-homopolymer-lenth 2` seems to be doing slightly better than `--min-homopolymer-lenth 3`. Overall, the script seems to be doing its job.

{:.warning}
Since in this example the 'reference genome', `W48` is also a genome with substantial homopolymer errors, the corrected sequences in `W01` do not necessarily yield amino acid sequences that are globally correct. But they are as incorrect as the ones in `W48` and not more. When a very closely related reference genome is used, the corrections will not only remove spurious gene clusters from pangenomes, but also yield more accurate amino acid sequences. 

For posterity, the following shell script shows how each pangenome shown in the GIF above is generated and displayed:


``` bash
###########################################################################################
# NO CORRECTION
###########################################################################################
anvi-gen-contigs-database -f W01.fa -o W01.db
anvi-gen-contigs-database -f W48.fa -o W48.db

anvi-gen-genomes-storage -e external-genomes-01.txt \
                         -o UNCORRECTED-GENOMES.db

anvi-pan-genome -g UNCORRECTED-GENOMES.db \
                -n UNCORRECTED \
                --num-threads 4

anvi-display-pan -g UNCORRECTED-GENOMES.db \
                 -p UNCORRECTED/UNCORRECTED-PAN.db \
                 --title "UNCORRECTED"

###########################################################################################
# W1 CORRECTED BY W48 --min-homopolymer-length 3
###########################################################################################

anvi-script-fix-homopolymer-indels -i W01.fa \
                                   -r W48.fa \
                                   --min-homopolymer-length 3 \
                                   -o W01_CBW48_MHL3.fa

anvi-gen-contigs-database -f W01_CBW48_MHL3.fa \
                          -o W01_CBW48_MHL3.db

anvi-gen-genomes-storage -e external-genomes-02.txt \
                         -o CORRECTED-BY-W48-MHL3-GENOMES.db

anvi-pan-genome -g CORRECTED-BY-W48-MHL3-GENOMES.db \
                -n CORRECTED-BY-W48-MHL3 \
                --num-threads 4

anvi-display-pan -g CORRECTED-BY-W48-MHL3-GENOMES.db \
                 -p CORRECTED-BY-W48-MHL3/CORRECTED-BY-W48-MHL3-PAN.db \
                 --title "W01 CORRECTED BY W48 w/MHL3"

###########################################################################################
# W1 CORRECTED BY W48 --min-homopolymer-length 2
###########################################################################################

anvi-script-fix-homopolymer-indels -i W01.fa \
                                   -r W48.fa \
                                   --min-homopolymer-length 2 \
                                   -o W01_CBW48_MHL2.fa

anvi-gen-contigs-database -f W01_CBW48_MHL2.fa \
                          -o W01_CBW48_MHL2.db

anvi-gen-genomes-storage -e external-genomes-03.txt \
                         -o CORRECTED-BY-W48-MHL2-GENOMES.db

anvi-pan-genome -g CORRECTED-BY-W48-MHL2-GENOMES.db \
                -n CORRECTED-BY-W48-MHL2 \
                --num-threads 4

anvi-display-pan -g CORRECTED-BY-W48-MHL2-GENOMES.db \
                 -p CORRECTED-BY-W48-MHL2/CORRECTED-BY-W48-MHL2-PAN.db \
                 --title "W01 CORRECTED BY W48 w/MHL2"
```
This program **quickly makes taxonomy estimates for genomes, metagenomes, or bins stored in your %(contigs-db)s.**

This is the final step in the scg-taxonomy workflow (described in its entirety [here](http://merenlab.org/2019/10/08/anvio-scg-taxonomy/)). Before running this program, you'll need to have run both %(anvi-setup-scg-taxonomy)s and %(anvi-run-scg-taxonomy)s on the %(contigs-db)s you're working with for this project. 

[This tutorial](http://merenlab.org/2019/10/08/anvio-scg-taxonomy/#estimating-taxonomy-in-the-terminal) also includes a comprehensive overview of what this program can do. See that page for more information on all of the features described below. 

Keep in mind that this uses single-copy core genes and their hits in  [GTDB](https://gtdb.ecogenomic.org/), so it will not work well in bins with low completion or for Eukaryotic organisms. 

This program is implicitly run in the interactive interface, when you turn on "Realtime taxonomy estimation for bins (whenever possible)." So, if you've ever wondered where those estimates were coming from, now you know. 

So, what can this program do?

### 1. Estimate the taxonomy of a single genome

By default, this program wll assume your %(contigs-db)s contains only one genome, and will try to use the single-copy core genes (that were associated with taxonomy when you ran %(anvi-run-scg-taxonomy)s) to try to identify the taxonomy of your genome. 

When you run 

{{ codestart }}
anvi-estimate-scg-taxonomy -c %(contigs-db)s
{{ codestop }}

It will give you the best taxonomy hit for your genome. If you would like to see how it got there (by looking at the hits for each of the single-copy core genes), just use the `--debug` flag to see more information, as so: 

{{ codestart }}
anvi-estimate-scg-taxonomy -c %(contigs-db)s \
                           --debug 
{{ codestop }}

### 2. Estimate the taxa within a metagenome 

By running this program in metagenome mode, it will assume that your %(contigs-db)s contains multiple genomes and will try to give you an overview of the taxa within it. To do this, it will determine which single-copy core gene has the most hits in your contigs (for example `Ribosomal_S6`), and then will look at the taxnomy hits for that gene across your contigs. The output will be this list of taxonomy results. 

{{ codestart }}
anvi-estimate-scg-taxonomy -c %(contigs-db)s \
                           --metagenome-mode 
{{ codestop }}

If you want to look at a specific gene (instead of the one with the most hits), you can also tell it to do that. For example, to tell it to look at Ribosomal_S9, run

{{ codestart }}
anvi-estimate-scg-taxonomy -c %(contigs-db)s \
                           --metagenome-mode  \
                           --scg-name Ribosomal_S9
{{ codestop }}

### 3. Look at relative abundance across multiple samples 

If you provide a %(profile-db)s or %(single-profile-db)s, then you'll be able to look at the relative abundance of your taxonomy hits (through a single-copy core gene) across your samples. Essentially, this adds additional columns to your output (one per sample) that descrbe the relative abundance of each hit in each sample. 

Running this will look something like this, 
{{ codestart }}
anvi-estimate-scg-taxonomy -c %(contigs-db)s \
                           --metagenome-mode  \
                           --p %(profile-db)s \
                           --compute-scg-coverages
{{ codestop }}

For an example output, take a look at [this page](http://merenlab.org/2019/10/08/anvio-scg-taxonomy/#contigs-db--profile-db).

### 4. Estimate the taxonomy of your bins 

This program basically looks at each of the %(bin)ss in your %(collection)s as a single genome and tries to assign it taxonomy information. To do this, simply provide a collection, like this:

{{ codestart }}
anvi-estimate-scg-taxonomy -c %(contigs-db)s \
                           --C %(collection)s
{{ codestop }}

You can also look at the relative abundances across your samples at the same time, by running something like this: 

{{ codestart }}
anvi-estimate-scg-taxonomy -c %(contigs-db)s \
                           --C %(collection)s  \
                           --p %(profile-db)s \
                           --compute-scg-coverages
{{ codestop }}

### 5. Look at multiple metagenomes at the same time

You can even use this program to look at multiple metagenomes by providing a %(metagenomes)s artifact. This is useful to get an overview of what kinds of taxa might be in your metagenomes, and what kinds of taxa they share. 

Running this

{{ codestart }}
anvi-estimate-scg-taxonomy --metagenomes %(metagenomes)s \
                           --output-file-prefix EXAMPLE
{{ codestop }}

will give you an output file containing all taxonomic levels found and their coverages in each of your metagenomes. 

For a concrete example, check out [this page](http://merenlab.org/2019/10/08/anvio-scg-taxonomy/#many-contigs-dbs-for-many-metagenomes). 
Initiates an interactive environment in your default browser.

Although it is generally associated with the typical concentric circles of 'oimcs data, the anvi'o interactive interface has many forms and off Anvi'o. Anvi'oers a vast amount of functionality, from manual reconstruction of genomes from metagenomes to refinement of metagenome-assembled genomes, displaying nucleotide-level coverage patterns, single-nucleotide variants, pangenomes, phylogenomic trees, and more. While the circular display is the default method for data presentation, you can also display your data in a rectangular from (as seen [here](http://merenlab.org/tutorials/interactive-interface/#lets-go-all-corners)).

In fact, the interface has many of its own blog posts, including a pretty comprehensive introductory tutorial [here](http://merenlab.org/tutorials/interactive-interface/) and a breakdown of its data types [here](http://merenlab.org/2016/02/27/the-anvio-interactive-interface/).

Here, we'll go through *some* things that the anvi'o interactive interface is capable of through this program. More information about most of this can be found by calling `anvi-interactive -h` or by checking out the additional resources at the bottom of this page.

Please makes sure you are familiar with the terminology that describes various parts of a given display, which are **explained in the %(interactive)s artifact**:

![an anvi'o display](../../images/interactive_interface/anvio_display_template.png){:.center-img}


## Running anvi-interactive on a profile database

One of the simplest ways to run the interactive interface (especially useful for manual binning) is just providing an anvi'o profile database and an anvi'o contigs database:

{{ codestart }}
anvi-interactive -p %(profile-db)s \
                 -c %(contigs-db)s
{{ codestop }}

For the central tree to display correctly, you'll need to have run hierarchical clustering at some point while making your profile database (either during %(anvi-merge)s, or, if this is a %(single-profile-db)s, while running %(anvi-profile)s). It is also possible to provide a phylogenetic tree or a clustering dendrogram from the command line using the `--tree` parameter.

If you do not have a %(state)s stored in your profile database named `default`, you will need to click the "Draw" button for anvi'o to provide you with an %(interactive)s display of your data.

### How to visualize things when you don't have a hierarchical clustering of your contigs?

Typically the %(interactive)s displays that will be initiated with `anvi-interactive` will require an items order to display all your contigs. There are multiple ways for anvi'o to generate dendrograms.

{:.notice}
Some advanced information you should feel free to skip: anvi'o uses a set of %(clustering-configuration)s files to decide which sources of data to use to cluster items. These recipes are essentially a set of configuration files for anvi'o to learn which information to use from %(contigs-db)s, %(profile-db)s, or %(pan-db)s type databases.

Some of the programs that generate dendrograms include %(anvi-merge)s, %(anvi-profile)s, and %(anvi-experimental-organization)s. But since hierarchical clustering is an extremely demanding process, anvi'o will skip this step during %(anvi-merge)s if there are more than 20,000 splits n the database. This is because the computational complexity of this process will get less and less feasible with increasing number of splits. You can force anvi'o to try to cluster your splits regardless of how many of them there are there by using the flag `--enforce-hierarchical-clustering`. However, we strongly advice against it especially if you have more than 30,000 splits since your process will likely to be killed by the operating system, or take a very very long time to finish (plus, if you have that many splits the performance of the interactive interface will be very low).

What happens if you don't have a hierarchical clustering dendrogram, but you still wish to have an overall understanding of your data, or visualize the coverages of some contigs of interest or any contig at all? There are multiple ways you can do that:

* You can use %(anvi-inspect)s to visualize nucleotide- and gene-level coverages and single-nucleotide variants on individual contigs,
* You can use %(anvi-cluster-contigs)s to create a collection for your contigs and initiate `anvi-interactive` in collection mode (see the subsection "[visualizing bins instead of contigs](#visualizing-bins-instead-of-contigs)" below.
* You can import external binning results using %(anvi-import-collection)s, or manually identify contigs of interest, and use %(anvi-import-collection)s to create a collection of a smaller number of contigs. You can then use %(anvi-refine)s to visualize contigs in a single bin, or use %(anvi-split)s to first generate a split profile for your contigs to visualize your smaller dataset using %(anvi-interactive)s.


### Visualizing *bins* instead of contigs

By default, when run on a profile database that resulted from a metagenomic workflow, %(anvi-interactive)s will initiate each contig as a separate item and organize them based on the clustering dendrograms provided to it (either automatically or by the user). But if there is a %(collection)s stored in the profile database, it is also possible to run %(anvi-interactive)s on a specific collection, during which anvi'o will use the underlying contig data to calculate summary statistics for each bin before displaying them. In collection mode, each item of your central plot will not represent a contig, but a bin within your collection. This is how the collection mode can be initialized in comparison to the default mode:

{{ codestart }}
anvi-interactive -p %(profile-db)s \
                 -c %(contigs-db)s \
                 -C %(collection)s
{{ codestop }}

The clustering of %(bin)ss in this case based on their distribution across samples will be done automatically on-the-fly. See the note on this mode in [the metagenomic workflow](http://merenlab.org/2016/06/22/anvio-tutorial-v2/#anvi-interactive) for more information.

### Visualizing *genes* instead of contigs

You can also start the interactive interface in "gene mode", in which each item of the central tree is a gene instead of a split or contig (or bin like in "collection mode").

To initiate the visualization in gene mode you need the following:

{{ codestart }}
anvi-interactive -p %(profile-db)s \
                 -c %(contigs-db)s \
                 -C %(collection)s \
                 -b %(bin)s \
                 --gene-mode
{{ codestop }}

If there isn't one already, this command will automatically generate an anvi'o %(genes-db)s under the `GENES` directory at the same level of the profile database. When the same command is run again, %(anvi-interactive)s will use the existing genes database.

In this view you can order genes based on their distributions patterns across metagenomes (*without paying attention to their synteny*) or by ordering them based on their synteny in a given genome (*without paying attention to their differential distribution*). [Figure 2 in this paper](https://peerj.com/articles/4320/) examples the latter, and [Figure 5 in this paper](https://stm.sciencemag.org/content/11/507/eaau9356) examples the former case, which is also shown below:

![](http://merenlab.org/images/gene-distribution-across-metagenomes.png)

You can also visit [this page](http://merenlab.org/tutorials/infant-gut/#the-gene-mode-studying-distribution-patterns-at-the-gene-level) to see another practical example from the Infant Gut tutorial.

## Running anvi-interactive in manual mode

You can initiate the anvi'o interactive interface in manual mode to run it on *ad hoc* data (here is [a tutorial on this](http://merenlab.org/tutorials/interactive-interface/)).

Anvi'o interactive interface is initiated with the flag `--manual-mode` and then by providing *any* of the following types of files individually or together:

- a TAB-delimited tabular data,
- a NEWICK formatted tree,

When doing this kind of run, anvi'o does not expect you to have a profile database, but it still needs you to provide a name for it. Anvi'o will simply create an empty one for you so you can store your state or collections in it for reproducibility.

## Extending anvi'o displays

You can extend any %(anvi-interactive)s display with additional data related to your project through the program %(anvi-import-misc-data)s. [This article](https://merenlab.org/2017/12/11/additional-data-tables/) describes a detailed use of this program.

While the use of %(anvi-import-misc-data)s is the most effective way to improve anvi'o displays, you can also use the parameter `--additional-layers` to provide a TAB-delimited file (%(misc-data-items-txt)s) that contains additional layers of information over your items.

If you want to add an entirely new view to the interface, you can do that too, as long as you provide a file containing all split names and their associated values. For more information, see the parameter `--additional-view`.

You can also provide the manual inputs even if you're using an anvi'o database. For example, if you provide your own NEWICK formatted tree, you will have the option to display it instead of the one in your database.


## Visualization Settings

In anvi'o, the visualization settings at a given time are called a %(state)s.

To open the interface in a specific state, you can use the `--state-autoload` flag or by importing a state using %(anvi-import-state)s.

You can also customize various aspects of the interactive interface. For example, you can change the preselected view, title, and taxonomic level displayed (for example, showing the class name instead of the genus name). You can also hide outlier single nucleotide variations or open only a specific collection.

## Password protection

Use `--password-protected` flag to limit access to your interactive instances, which is by default will be accessible to anyone on your network.


## Quick solutions for network problems

In a typical run, %(anvi-interactive)s initiates a local server to which you connect through your browser to visualize data. Which can yield unexpected problems if you are running anvi'o in virtual environments such as Windows Subsystem for Linux. If your browser does not show up, or you get cryptic errors such as "*tcgetpgrp failed: Not a tty*", you can always simplify things by manually setting network properties such as `--ip-address` and `--port-number`.

For instance you can start an interactive interface the following way:

{{ codestart }}
anvi-interactive -p %(profile-db)s \
                 -c %(contigs-db)s \
                 --ip-address 127.0.0.1 \
                 --port-number 8901 \
                 --server-only
{{ codestop }}

Which would not initiate your browser, but then you can open your browser and go to this address to work with the anvi'o interactive interface:

* [http://127.0.0.1:8901](http://127.0.0.1:8901)

## Other things

### Viewing your data

You can use this program to look at the available information in your databases, which is very convenient. For example, you can view all of the available

- views (using `--show-views`)
- states (using `--show-states`)
- collections (using `--list-collections`)

This program converts a %(linkmers-txt)s artifact into %(oligotypes)s data.

A %(linkmers-txt)s artifact describes each of your short reads that mapped to specific target nucleotide positions in a reference contig. This program counts the total occurance of each combination in those target positions within each of your samples. 

For example, if your %(linkmers-txt)s focused on two target positions, and you ran the following:

{{ codestart }}
anvi-oligotype-linkmers -i %(linkmers-txt)s 
{{ codestop }}

The output (which by default is called `oligotype-counts-001.txt`) might look like the following:

    key         AG   CA    CG    GA    GG    TA    TG   
    sample_001  0    320   12    2     0     3     579    
    sample_002  0    142   2     0     2     10    353  
    sample_003  3    404   1     1     0     2     610   
    sample_004  0    209   6     0     1     0     240

Note that combinations with zero reads in every sample are not included. 
This program **takes in a %(functions-txt)s to annotate your %(contigs-db)s with %(functions)s.** Basically, if you have already have the gene functions for the contigs in your %(contigs-db)s available in a file, you can import them into anvi'o using this command. 

You can find a really comprehesive walkthrough of this program on [this blog post about importing functions](http://merenlab.org/2016/06/18/importing-functions/), including information about built-in anvi'o parsers for InterProScan and the EggNOG database.

If you want to overwrite any function annotations you already have, just add the tag `--drop-previous-annotations`. 

This program **searches for keywords in the function annotations of your database.** 

You can use this program to look for specific functon keywords in a %(contigs-db)s, %(genomes-storage-db)s or %(pan-db)s. For example, say you wanted your %(contigs-db)s to search for genes that encoded some type of kinase. You could call 

{{ codestart }}
anvi-search-functions -c %(contigs-db)s \
                      --search-terms kinase
{{ codestop }}

By default, the output will be a fairly barren %(functions-txt)s, only telling you which contigs contain genes that matched your search. This will be most helpful as an additional layer in the anvi'o interactive interface, so you can quickly see where the kinase-encoding genes are in the genome. To do this, run %(anvi-interactive)s with the `--aditional-layer` parameter with the %(functions-txt)s. 

However, you can also request a much more comprehensive output that contains much more information, including the matching genes' caller id, functional annotation source and full function name. 

For example, to run the same search as above, but with a more comprehensive output, you could call 

{{ codestart }}
anvi-search-functions -c %(contigs-db)s \
                      --search-terms kinase \
                      --full-report kinase_information.txt \
                      --include-sequences \
                      --verbose
{{ codestop }}

Following this run, the file `kinase_information.txt` will contain comprehensive information about the matching genes, including their sequences. 

You can also search for multiple terms at the same time, or for terms from only specific annotation sources. For example, if you only wanted Pfam hits with functions related to kinases or phosphatases, you could call 

{{ codestart }}
anvi-search-functions -c %(contigs-db)s \
                      --search-terms kinase,phosphatase \
                      --annotation-sources Pfam \ 
                      --full-report kinase_phosphatase_information.txt
{{ codestop }}
This program creates a %(modules-db)s out of a set of user-defined metabolic modules, for use by %(anvi-estimate-metabolism)s.

It takes as input a directory containing module files for each user-defined module, formatted in the same way as KEGG modules are. It parses these modules into the `USER_MODULES.db` database. This directory of user-defined data is referred to as %(user-modules-data)s, and the help page for that artifact contains a detailed account of how to create your own module definitions and estimate their completeness.

This page will give a few details specific to running %(anvi-setup-user-modules)s.

### Default Usage

To run this program, you must provide an input directory containing your module definitions:

{{ codestart }}
anvi-setup-user-modules --user-modules /path/to/user/data/directory
{{ codestop }}

This input directory must have a specific format (see section below). The `USER_MODULES.db` will be generated in this directory, so you can use the same path to provide your data to %(anvi-estimate-metabolism)s when you want to estimate completeness for these modules.

### Input directory format

The directory you provide to the `--user-modules` parameter must have another folder inside of it, which must be called `modules`. Inside that `modules` folder, you should put text files containing the definitions of your metabolic modules - one file per module. The file should be named according to the identifier you want the module to have, and should not have any extension.

Here is an example schematic of a proper input directory:
```
MY_METABOLISM_DATA_DIR
  |
  |- modules
        |- U00001
        |- U00002
        |- U00003
        |- U00004
```
The `U0000x` files in the schematic above each contains a definition for one module. Running `anvi-setup-user-modules --user-modules MY_METABOLISM_DATA_DIR` will produce a `USER_MODULES.db` file in the `MY_METABOLISM_DATA_DIR` folder which contains 4 modules named U00001, U00002, U00003, and U00004 (assuming those files are formatted correctly).

### How do I format the module files?

We use KEGG's system for describing metabolic modules, so you will need to format your metabolic pathways in the same way. Here is an example, for a module file called `U00002` (like in the schematic above):
```
ENTRY       U00002
NAME        Nitrogen fixation (full Nif gene set)
DEFINITION  K02588+K02586+K02591-K00531 K02587 K02592 K02585
ORTHOLOGY   K02588  NifH
            K02586  NifD
            K02591  NifK
            K00531  anfG
            K02587  NifE
            K02592  NifN
            K02585  NifB
CLASS       User modules; Energy metabolism; Nitrogen metabolism
ANNOTATION_SOURCE  K02588  KOfam
                    K02586  KOfam
                    K02591  KOfam
                    K00531  KOfam
                    K02587  KOfam
                    K02592  KOfam
                    K02585  KOfam
///
```
As you can see, there are different data types in the file, named by the all-capital word at the beginning of the line (we call this the 'data name'). The second column of the file is the value corresponding to that type of information ('data value'). Some data names, like ORTHOLOGY and ANNOTATION_SOURCE, also have a 3rd column further defining the data value (which we call the 'data definition'). Each field in the file should be separated by _at least two spaces_. And the file must end with '///' on the last line (don't ask us why).

The data names you see in the example above are the minimum you should include to define the module. Here is a bit more information about each type of data:
- ENTRY: this is the identifier for the module. It can be anything you want, but should be just one word (underscores and dashes allowed). It should also be the same as the name of the module file. Importantly, this identifier should not be the same as any KEGG module, or you will get an error during setup.
- NAME: this is the name of the metabolic pathway, which can be any arbitrary string (spaces allowed)
- DEFINITION: this is the set of enzymes required for the reactions in the metabolic pathway. The enzymes should be identified by their accession numbers in their respective annotation source - in the example above, these are all KOfams, so the enzyme accessions are KO numbers. However, you can use enzymes from any annotation source you like (COGs, Pfams, custom HMMs, etc), as long as you have a way to annotate them in your contigs database. The rules for defining a metabolic pathway in the KEGG fashion are described in the [technical details section](https://merenlab.org/software/anvio/help/main/programs/anvi-estimate-metabolism/#what-data-is-used-for-estimation) of the help page for %(anvi-estimate-metabolism)s, so please read through that section for help with designing your pathway definition.
- ORTHOLOGY: this section maps the identifier for an enzyme (the second column, or data value) to the functional definition of that enzyme (the third column, or data definition). You need one of these lines for every enzyme in your module DEFINITION line.
- CLASS: this line categorizes the module. It must be one string with three sections, separated by semi-colons. The first section is the 'class' of the module, the second section is the 'category' of the module, and the third section is the 'sub-category'. Feel free to use the existing KEGG categories to describe your pathway, or to make up something entirely new. Or, if you don't care about this categorization at all, you could just put random strings in each section (as long as you have two semi-colons in the string, you will be golden).
- ANNOTATION_SOURCE: this section maps the identifier for an enzyme (the second column, or data value) to its annotation source (the third column, or data definition). You need one of these lines for every enzyme in your module DEFINITION line. The annotation source must match the functional annotation source in the contigs database that is associated with the enzyme's annotations. For instance, KOfams annotated with %(anvi-run-kegg-kofams)s have source 'KOfam' (as above), the 2020 COG source from %(anvi-run-ncbi-cogs)s is 'COG20_FUNCTION', the source for custom HMM profiles given to %(anvi-run-hmms)s is the `--hmm-source` directory name, and so on.

You can also define other data names, if you want. Some common ones that can be found in KEGG modules are COMPOUND, REACTION, PATHWAY, COMMENT, REFERENCE, and AUTHORS; but you are not limited by the ones used by KEGG.

Why must we format the module files this way, you ask? Well, to be honest, KEGG modules are formatted like this, and our infrastructure for working with that data has simply been adapted to work with arbitrary, user-defined data. KEGG makes the rules :)

### Specifying KEGG data to be used for sanity checking

If you haven't yet run %(anvi-setup-kegg-kofams)s on your computer, you will get an error when you try to run this program. This is because KEGG data is always used in addition to user-defined modules, and we need to be aware of which KEGG modules exist so we can make sure none of the user-defined modules have the same identifiers as these.

By default, this program looks for the KEGG data in the default location, so if you have set up KEGG data in a non-default directory, you should specify the path to that directory using the `--kegg-data-dir` parameter:

{{ codestart }}
anvi-setup-user-modules --user-modules /path/to/user/data/directory --kegg-data-dir /path/to/KEGG/data/directory
{{ codestop }}

If you have multiple KEGG data directories on your computer, you should specify the one that you intend to use (along with this user-defined data) for %(anvi-estimate-metabolism)s downstream. It will not make a difference if all of your modules have identifiers unique from KEGG ones, but just in case they overlap, it is better to catch this during setup rather than later during metabolism estimation. :)
This program gives you the **coverage and detection data** for all of the genes found in your %(contigs-db)s, using the short reads data in your %(profile-db)s. 

{{ codestart }}
anvi-export-gene-coverage-and-detection -c %(contigs-db)s \
                                        -p %(profile-db)s \
                                        -O MY_DATA
{{ codestop }}

This will give you a %(coverages-txt)s and a %(detection-txt)s whose file names will begin with `MY_DATA`
This program **helps you make sense of contigs in one or more %(contigs-db)ss**.

### Working with single or multiple contigs databases

You can use this program on a single contigs database the following way:

{{ codestart }}
anvi-display-contigs-stats CONTIGS-01.db
{{ codestop }}

Alternatively, you may use it to compare multiple contigs databases:

{{ codestart }}
anvi-display-contigs-stats CONTIGS-01.db \
                           CONTIGS-02.db \
                           (...)
                           CONTIGS-XX.db
{{ codestop }}

If you are comparing multiple, each contigs databse will become an individual column in all outputs.

### Interactive output

If you run this program on an anvi'o contigs database with default parameters,

{{ codestart }}
anvi-display-contigs-stats %(contigs-db)s
{{ codestop }}

it will open an interactive interface that looks like this:

![An example of the anvi'o interface for contigs stats](../../images/contigs-stats-interface-example.png)

At the top of the page are two graphs:

* The bars in the top graph represent every integer N and L statistic from 1 to 100. The y-axis is the respective N length and the x-axis is the percentage of the total dataset looked at (the exact L and N values can be seen by hovering over each bar). In other words, if you had sorted your contigs by length (from longest to shortest), and walked through each one, every time you had seen another 1 percent of your total dataset, you would add a bar to the graph showing the number of contigs that you had seen (the L statistic) and the length of the one you were looking at at the moment (the N statistic).

* The lower part of the graph tells you about which HMM hits your contigs database has. Each column is a gene in a specific %(hmm-source)s, and the graph tells you how many hits each gene has in your data. (Hover your mouse over the graph to see the specifics of each gene.) The sidebar shows you how many of the genes in this graph were seen exactly that many times. For example, in the graph above, for the Bacteria_71 %(hmm-source)s, a lot of genes were detected 9-11 times, so those bars are longer. This helps you estimate about how many of these genomes there are in your contigs database (so here, there is likely around 9-11 bacteria genomes in this contigs database).

Below the graphs are the **contigs stats** which are displayed in the following order:

- The total length of your contigs in nucleotides
- The number of contigs in your database
- The number of contigs that are of varying lengths. (for example "Num Contigs > 2.5 kb" gives you the number of contigs that are longer than 2500 base pairs)
- The length of the longest and shortest contig in your database in nucleotides
- The number of genes in your contigs (as predicted by [Prodigal](https://github.com/hyattpd/Prodigal))
- L50, L75, L90: If you ordered the contigs in your database from longest to shortest, these stats describe the *number of contigs* you would need to go through before you had looked at a certain percent of a genome. For example, L50 describes the number of contigs you would have to go through before you reached 50 percent of the entire dataset.
- N50, N75, N90:  If you ordered the contigs in your database from longest to shortest, these stats describe the *length of the contig* you would be looking when you had looked at a certain percent of a genome. For example, N50 describes the length of contig you would be on when you reached 50 percent of the entire genome length.
- The number of HMM hits in your contigs. This goes through every %(hmm-source)s and gives the number of hits its genes had in all of your contigs. Basically, this is the number of hits that is given in the lower graph at the top of the page.
- The number of genomes that anvi'o predicts are in your sample, based on how many hits the single copy core genes got from the various %(hmm-source)ss. See the description of the lower graph above, or [this blog post](http://merenlab.org/2015/12/07/predicting-number-of-genomes/) for more information.


### Text output

If you wish to report %(contigs-db)s stats as a supplementary table, a text output will be much more appropriate. If you add the flag `--report-as-text` anvi'o will not attempt to initiate an interactive interface, and instead will report the stats as a TAB-delmited file:

{{ codestart }}
anvi-display-contigs-stats %(contigs-db)s \
                          --report-as-text \
                          -o OUTPUT_FILE_NAME.txt
{{ codestop }}

There is also another flag you can add to get the output formatted as markdown, which makes it easier to copy-paste to GitHub or other markdown-friendly services. This is how you get a markdown output instead:

{{ codestart }}
anvi-display-contigs-stats %(contigs-db)s \
                          --report-as-text \
                          --as-markdown \
                          -o OUTPUT_FILE_NAME.md
{{ codestop }}

Here is an example output:

contigs_db|oral_HMW_4_1|oral_HMW_4_2|oral_HMW_4_1_SS|oral_HMW_4_2_SS
--|--|--|--|--
Total Length|531641122|759470437|306115616|288581831
Num Contigs|468071|1007070|104273|148873
Num Contigs > 5 kb|19626|24042|25014|20711
Num Contigs > 10 kb|6403|8936|3531|2831
Num Contigs > 20 kb|1269|2294|300|407
Num Contigs > 50 kb|34|95|3|10
Num Contigs > 100 kb|0|0|0|0
Longest Contig|73029|92515|57337|63976
Shortest Contig|56|51|80|85
Num Genes (prodigal)|676577|994050|350657|327423
L50|38513|62126|17459|17161
L75|143030|328008|33063|35530
L90|301803|670992|53293|70806
N50|2810|1929|6106|5594
N75|686|410|3536|2422
N90|394|275|1360|640
Archaea_76|1594|1697|930|805
Protista_83|6|1|1|0
Ribosomal_RNAs|901|1107|723|647
Bacteria_71|2893|3131|1696|1441
archaea (Archaea_76)|0|0|0|0
eukarya (Protista_83)|0|0|0|0
bacteria (Bacteria_71)|33|26|20|18

You can easily convert the markdown output into PDF or HTML pages using [pandoc](https://pandoc.org/). For instance running the following command in the previous output,

```
pandoc -V geometry:landscape \
       OUTPUT_FILE_NAME.md
       -o OUTPUT_FILE_NAME.pdf
```

will results in a PDF file that looks like this:

![an anvi'o display](../../images/display_contigs_stats_pandoc_output.png){:.center-img}
This program **creates a %(single-profile-db)s from a %(bam-file)s and %(contigs-db)s**. 

Once you have a %(single-profile-db)s, you can run programs like %(anvi-cluster-contigs)s, %(anvi-estimate-metabolism)s, and %(anvi-gen-gene-level-stats-databases)s, as well as use the interactive interface with %(anvi-interactive)s. If you want to run these same contigs against multiple BAM files (because you have multiple samples), you'll combine your %(single-profile-db)ss into a %(profile-db)s after you've created them all using %(anvi-merge)s. See the pages for %(single-profile-db)s or %(profile-db)s for more you can do with these artifacts. 

In short, this program runs various analyses on the contigs in your %(contigs-db)s and how they relate to the sample information stored in the %(bam-file)s you provided. It then stores this information into a %(single-profile-db)s. Specifically, this program calculates 
* coverage per nucleotide position (if you're unsure what coverage refers to, check out [this page](http://merenlab.org/vocabulary/#coverage))
* single-nucleotide, single-codon, and single-amino acid variants (You can find all of those terms on the vocab page linked above, as well as a more detailed explaination [here](http://merenlab.org/2015/07/20/analyzing-variability/#an-intro-to-single-nucleotidecodonamino-acid-variation))
* structural variants such as insertions or deletions 

## Basic Usage

### Inputs 

This program takes in an [indexed](https://merenlab.org/software/anvio/help/programs/anvi-init-bam) %(bam-file)s and a %(contigs-db)s. The BAM file contains the short reads from a single sample that will be used to create the profile database. Thus, here is a standard run with default parameters: 

{{ codestart }}
anvi-profile -i %(bam-file)s \
             -c %(contigs-db)s 
{{ codestop }}

Alternatively, if you lack mapping data, you can add the flag `--blank-profile` so that you can still get the functionality of a profile database. 

{{ codestart }}
anvi-profile -c %(contigs-db)s  \ 
            --blank-profile
{{ codestop }}

### Checking your BAM file: always a good idea 

If you want to first check your BAM file to see what contigs it contains, just use the flag `--list-contigs` to see a comprehensive list. 

### Profiling a subset of contigs

*Note: This describes how to profile a named subset of contigs. To profile a subset of contigs based on their characterists (for example, only contigs of a certain length or that have a certain coverage), see the section below on "contig specifications"*

By default, anvi'o will use every contig in your %(contigs-db)s. However, if you wish to focus specifically on a subset of these contigs, just provide a file that contains only the names of the contigs you want to analyze, one per line, using the tag `--contigs-of-interest`.

For example, you could run

{{ codestart }}
anvi-profile -c Ross_sea_contigs.db  \ 
             --blank-profile \
             --contigs-of-interest contigs_i_like.txt
{{ codestop }}

Where `contigs_i_like.txt` looks like this: 

    SF15-RossSeacontig4922
    SF15-RossSeacontig702

## Analysis Parameters
 
Changing these will affect the way that your sequences are analyzed. 

Keep in mind that if you plan to merge your resulting %(single-profile-db)s with others later in the project, you'll want to keep these parameters consistent. 

### Contig Specification 

To profile only contigs within a specific length, you can use the flags `--min-contig-length` and `-max-contig-length`. By default, the minimum length for analysis is 1000 and there is no maximum length. You can also profile only contigs that have a certain average coverage with the flag `--min-mean-coverage`. 

#### Specifications for your BAM file

You can also ignore reads in your BAM file with a percent identity to the reference less than some threshold using the flag `--min-percent-identity`.  By default, all reads are used. 

For example, the following code will only look at contigs longer than 2000 nts and will ignore BAM file reads with less than 95 percent identity to the reference:

{{ codestart }}
anvi-profile -c Ross_sea_contigs.db  \ 
            -i bam_file.bam \
            --min-contig-length 2000 \
            --min-percent-identity 95 
{{ codestop }}

### Hierarchical Clustering 

#### To cluster or not to cluster? 

By default, anvi'o will not try to cluster your splits (since it takes quite a bit of runtime) unless you are using the tag `--blank-profile`. If you don't want to run this, use the tag `--skip-hierarchical-clustering`. 

If you're planning to later merge this sample with others, it is better to perform clustering while running %(anvi-merge)s than at this stage. 

However, if you want to bin this single sample or otherwise want clustering to happen, just use the tag `--cluster-contigs`. 

If you do plan to cluster, you can set a custom distance metric or a custom linkage method. 

### Variability 

Anvi-profile will throw away variability data below certain thresholds to reduce noise. After all, if you have a single C read at a position with a 1000X coverage where all other reads are T, this is probably not a variant position that you want to investigate further. By default, it will not analyze positions with coverage less than 10X, and it will further discard variants based on [this criteria](https://merenlab.org/2015/07/20/analyzing-variability/#de-novo-characterization-and-reporting-of-snvs). 

However, you can change the coverage threshold using the  `--min-coverage-for-variability` flag. You can also report every variability position using the flag `--report-variability-full`. 

For example, if you wanted to view every variant, you would profile with the following:

{{ codestart }}
anvi-profile -c Ross_sea_contigs.db  \ 
            -i bam_file.bam \
            --min-coverage-for-variability 1 \
            --report-variability-full
{{ codestop }}

## Other Parameters 

You should provide the sample name with the flag `-S` and can provide a description of your project using the `--description` tag followed by a text file. These will help anvi'o name output files and will show up in the anvi'o interfaces down the line. 

You can characterize the codon frequencies of genes in your sample at the cost of some runtime. Despite time being money, codon frequency analysis can be helpful downstream. Simply add the tag `--profile-SCVs` and watch the magic happen.

{:.notice}
If you have prior experience with `--profile-SCVs` being slow, you will be surprised how fast it is
since v6.2

Alternatively, you can choose not to store insertion and deletion data or single nucleotide variant data.

If you know the limits of your system, you can also multithread this program. See the program help menu for more information.
This programs takes a %(variability-profile-txt)s and generates the information necessary to visualize its contents with %(anvi-interactive)s. 

Specifically, this program outputs a directory that contains a %(profile-db)s, a %(view-data)s artifact, and a %(dendrogram)s. For example, if you ran this program like so: 

{{ codestart }}
anvi-script-snvs-to-interactive -o OUTPUT_DIR \
                                %(variability-profile)s
{{ codestop }}

Then, you can open the interactive interface by running 

{{ codestart }}
anvi-interactive --manual-mode \
                 -p OUTPUT_DIR/profile.db \
                 --tree OUTPUT_DIR/tree.txt \
                 --view-data OUTPUT_DIR/view.txt
{{ codestop }}

## Other parameters 

### Using Only a Subset of the Input

By default, all variability positions in your variability profile are considered. However, if the input is too large (i.e. more than 25,000 variability positions), the runtime on this program will be very long and the results won't display well. So, there are several ways to remove variability positions from  the input to get under this threshold: 

1. Ignore positions with with certain departures from the consensus sequence (with `--min-departure-from-consensus` and `--max-departure-from-consensus`)
2. Ignore positions with with certain departures from the reference sequence (with `--min-departure-from-reference` and `--max-departure-from-reference`)
3. Ignore positions in all non-coding regions with the flag `--only-in-genes`. 

If you still have more positions than you can tell the program to pick a random subset of the input with the parameter `--random` followed by a seed integer.

### Modifying the Output

By the default, the output data will use the departure from consensus values. If instead you want to look at the departure from the reference, just add the falg `--display-dep-from-reference`
This program allows you to run [Snakemake](https://snakemake.readthedocs.io/en/stable/) workflows for common anvi'o processes. It is described fully in [this tutorial](https://merenlab.org/2018/07/09/anvio-snakemake-workflows/#contigs-workflow). 

Essentially, an anvi'o workflow will run several anvi'o programs for you in quick succession (based on a standard set of intiial steps that will allow you to quickly get to a point where you can ask novel questions). 

As of now, the available workflows are the %(contigs-workflow)s, the %(metagenomics-workflow)s, the %(pangenomics-workflow)s, the %(phylogenomics-workflow)s, and the %(trnaseq-workflow)s. 

### Before running the workflow

Each workflow requires a %(workflow-config)s: the file that details all of the parameters for the workflow. To get the %(workflow-config)s with the default parameters, just run 

{{ codestart }}
anvi-run-workflow -w WORKFLOW-NAME \
                  --get-default-config CONFIG.json
{{ codestop }}

Before running a workflow, it is also a good idea to check the required dependencies by running 

{{ codestart }}
anvi-run-workflow -w WORKFLOW-NAME \
                  --list-dependencies
{{ codestop }}

### The main run 

The main run of the workflow should look like this: 

{{ codestart }}
anvi-run-workflow -w WORKFLOW-NAME \
                  -c CONFIG.json
                  --save-workflow-graph
{{ codestop }}

The flag `--save-workflow-graph` creates a visual representation of the anvio programs that the workflow you're running used. 

You can also use the `-A` flag at the end of the parameter list to change other [Snakemake](https://snakemake.readthedocs.io/en/stable/) parameters. 
Essentially, this program uses the KEGG database to annotate functions and metabolic pathways in a %(contigs-db)s. More specifically, %(anvi-run-kegg-kofams)s annotates a %(contigs-db)s with HMM hits from KOfam, a database of KEGG Orthologs (KOs). You must set up these HMMs on your computer using %(anvi-setup-kegg-kofams)s before you can use this program.

Running this program is a pre-requisite for metabolism estimation with %(anvi-estimate-metabolism)s. Note that if you are planning to run metabolism estimation, it must be run with the same %(kegg-data)s that is used in this program to annotate KOfam hits.

### How does it work?
**1) Run an HMM search against KOfam**
Briefly, what this program does is extract all the gene calls from the %(contigs-db)s and checks each one for hits to the KOfam HMM profiles in your %(kegg-data)s. This can be time-consuming given that the number of HMM profiles is quite large, even more so if the number of genes in the %(contigs-db)s is also large. Multi-threading is a good idea if you have the computational capability to do so.

**2) Eliminate weak hits based on bitscore**
Many HMM hits will be found, most of them weak. The weak hits will by default be eliminated according to the bitscore thresholds provided by KEGG; that is, hits with bitscores below the threshold for a given KO profile will be discarded, and those with bitscores above the threshold will be annotated in the %(contigs-db)s. It is perfectly normal to notice that the number of raw hits found is many, many times larger than the number of annotated KO hits in your database.

**3) Add back valid hits that were missed**
There is one issue with this practice of removing _all_ KOfam hits below the KEGG bitscore threshold for a given profile. We (and others) have noticed that the KEGG thresholds can sometimes be too stringent, eliminating hits that are actually valid annotations. To solve this problem, we
have implemented the following heuristic for relaxing the bitscore thresholds and annotating genes that would otherwise go without a valid KO annotation:

For every gene without a KOfam annotation, we examine all the hits with an e-value below `X` and a bitscore above `Y` percent of the threshold. If those hits are all to a unique KOfam profile, then we annotate the gene call with that KO.

`X` and `Y` are parameters that can be modified (see below), but by default the e-value threshold (`X`) is 1e-05 and the bitscore fraction (`Y`) is 0.5.

Please note that this strategy is just a heuristic. We have tried to pick default parameters that seemed reasonable but by no means have we comprehensively tested and optimized them. This is why X and Y are mutable so that you can explore different values and see how they work for your data. It is always a good idea to double-check your annotations to make sure they are reasonable and as stringent as you'd like them to be. In addition, if you do not feel comfortable using this heuristic at all, you can always turn this behavior off and rely solely on KEGG's bitscore thresholds. :)

**3) Put annotations in the database**
In the %(contigs-db)s functions table, annotated KO hits (%(kegg-functions)s) will have the source `KOfam`.

### Standard usage

{{ codestart }}
anvi-run-kegg-kofams -c CONTIGS.db
{{ codestop }}

### Use a specific non-default KEGG data directory
If you have previously setup your KEGG data directory using `--kegg-data-dir` (see %(anvi-setup-kegg-kofams)s), or have moved the KEGG data directory that you wish to use to a non-default location (maybe you like keeping the older versions around when you update, we don't know how you roll), then you may need to specify where to find the KEGG data so that this program can use the right one. In that case, this is how you do it:

{{ codestart }}
anvi-run-kegg-kofams -c CONTIGS.db \
                     --kegg-data-dir /path/to/directory/KEGG
{{ codestop }}

### Run with multiple threads

{{ codestart }}
anvi-run-kegg-kofams -c CONTIGS.db -T 4
{{ codestop }}

### Use a different HMMER program
By default, %(anvi-run-kegg-kofams)s uses `hmmsearch` to find KO hits. If for some reason you would rather use a different program (`hmmscan` is also currently supported), you can do so.

{{ codestart }}
anvi-run-kegg-kofams -c CONTIGS.db \
                     --hmmer-program hmmscan
{{ codestop }}

### Keep all HMM hits
Usually, this program parses out weak HMM hits and keeps only those that are above the score threshold for a given KO. If you would like to turn off this behavior and keep all hits (there will be _a lot_ of weak ones), you can follow the example below:

{{ codestart }}
anvi-run-kegg-kofams -c CONTIGS.db \
                     --keep-all-hits
{{ codestop }}

### Modifying the bitscore relaxation heuristic
As described above, this program does its best to avoid missing valid annotations by relaxing the bitscore threshold for genes without any annotations. For such a gene, hits with e-value <= X and bitscore > (Y * KEGG threshold) that are all hits to the same KOfam profile are used to annotate the gene with that KO.

**Skip this step entirely**
If you don't want any previously-eliminated hits to be used for annotation, you can skip this heuristic by using the flag `--skip-bitscore-heuristic`. Then, _only_ hits with bitscores above the KEGG-provided threshold for a given KO will be used for annotation.

{{ codestart }}
anvi-run-kegg-kofams -c CONTIGS.db \
                     --skip-bitscore-heuristic
{{ codestop }}

**Modify the heuristic parameters**
If our default values are too stringent or not stringent enough for your tastes, you can change them! The e-value threshold (X, default: 1e-05) can be set using `-E` or `--heuristic-e-value` and the bitscore fraction (Y, default: 0.50) can be set using `-H` or `--heuristic-bitscore-fraction`. Like so:

{{ codestart }}
anvi-run-kegg-kofams -c CONTIGS.db \
                     -E 1e-15 \
                     -H 0.90
{{ codestop }}

This program exports the structures from a %(structure-db)s into the globally understood pdb format (%(protein-structure-txt)s), so they may be used for any follow-up analyses taking place outside of anvi'o.


To run, just provide a %(structure-db)s and an output path: 

{{ codestart }}
anvi-export-structures -s %(structure-db)s \
                       -o path/to/output
{{ codestop }}

You can also provide a list of gene caller IDs, either directly through the parameter `--gene-caller-ids` or through a file with one gene caller ID per line.


This program is used to add additional genes to or re-run the analysis of genes already within a %(structure-db)s.

For that reason, it is very similar to %(anvi-gen-structure-database)s and the parameters used to run that program (when you first generated your %(structure-db)s) will be automatically applied when you run this program. To know what MODELLER parameters are being used, you run this program on a %(structure-db)s with the flag `--list-modeller-params`. 

To run this program, just provide a %(contigs-db)s and %(structure-db)s, and name your genes of interest (either in a file or directly). If the named genes are not already in your %(structure-db)s, they will be added to the database. 

For example, if your %(structure-db)s already contains the genes with caller-IDs 1, 2 and 3, and you run

{{ codestart }}
anvi-update-structure-database -c %(contigs-db)s \
                               -s %(structure-db)s \
                               --gene-caller-ids 1,4,5
{{ codestop }}

Then the structural analysis for genes 4 and 5 will be added to your %(structure-db)s (assuming templates are found). Gene 1 will be ignored, since it is already present.

If instead you want to re-run the structural analysis on genes that are already in your %(structure-db)s, you'll need to specify that by adding the flag `--rerun-genes`

{{ codestart }}
anvi-update-structure-database -c %(contigs-db)s \
                               -s %(structure-db)s \
                               --gene-caller-ids 1,4,5 \
                               --rerun-genes
{{ codestop }}

Now, the program will rerun the analysis for gene 1 and will still add genes 4 and 5 to the %(structure-db)s. 

Both of these runs will have the same MODELLER parameters as your run of %(anvi-gen-structure-database)s. However, to get the raw outputs, you will need to use the parameter `--dump-dir`. You can also set a specific MODELLER program with `--modeller-executable`. Parameters for multi-threading would also have to be given again.
{:.notice}
Like %(anvi-gen-structure-database)s, this program also accepts %(external-structures)s.
This program tells you the completeness and redundency of single-copy gene sources available for your %(contigs-db)s. 

For example, some of the defaults are collections of single-copy core genes named  `Protista_83`, `Archaea_76`, and `Bacteria_71`. This program will give you a rough estimate of how many Protist, Archaeal, and Bacterial genomes are included in your dataset using these single-copy core genes. 

You can use the following run to list available completeness sources in your %(contigs-db)s:

{{ codestart }}
anvi-compute-completeness -c %(contigs-db)s \
                          --list-completeness-sources
{{ codestop }}
                              
Then you can run this program on a specifc source as folows:

{{ codestart }}
anvi-compute-completeness -c %(contigs-db)s \
                          --completeness-source Bacteria_71
{{ codestop }}
                              
You can also provide a %(splits-txt)s to focus on a specific set of splits, or declare a minimum e-value for a gene to count as a hit. The default is `1e-15`.
Reports sequences stored in a %(bam-file)s file that cover one of more specific nucleotide positions in a reference.

### Basic mode of operation

Assume you wish to recover reads stored in one or more BAM files, where the matching reads contain at least one nucleotide position that align to a nucleotide position `nucleotide_position_N` in a contig `contig_name_X`. In that case, the user would first generate a two column TAB-delmited file, for example `positions_for_linkmers.txt` with no header line,


<table>
  <tbody>
    <tr>
      <td> contig_name_X </td>
      <td> nucleotide_position_N </td>
    </tr>
  </tbody>
</table>

And run the program this way to recover the short reads from this way:

```
anvi-report-linkmers --contigs-and-positions positions_for_linkmers.txt \
                     -i SAMPLE_01.bam SAMPLE_02.bam SAMPLE_03.bam (...) \
                     -o linkmers.txt
```

The user can define multiple contigs in the input file, and one or more nucleotide positions for each one of them:

<table>
<tbody>
<tr>
      <td> contig_name_X </td>
      <td> nucleotide_position_01,nucleotide_position_02,nucleotide_position_03</td>
</tr>
<tr>
      <td> contig_name_Y </td>
      <td> nucleotide_position_04 </td>
</tr>
<tr>
      <td> contig_name_Z </td>
      <td> nucleotide_position_05,nucleotide_position_06 </td>
</tr>
</tbody>
</table>

The resulting %(linkmers-txt)s would include all short reads that match any of these critera

### Complete or incomplete links?

Using the `--only-complete-links` flag, the user can enforce whether only complete links should be reported where each reported short read must cover each nucleotide position for a given contig.

Please note that if the nucleotide positions chosen for a given contig are too distant from each other given the short read length, zero reads may satisfy the complete links criterion.

Having complete links, however, will enable [oligotyping](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12114) analyses on **metagenomic reads** through the anvi'o program %(anvi-oligotype-linkmers)s.

### See this program in action

[http://merenlab.org/2015/12/09/musings-over-commamox/](http://merenlab.org/2015/12/09/musings-over-commamox/)The purpose of this program is to exports your gene calls in a given %(contigs-db)s and a gene caller, in the form of a %(gene-calls-txt)s. 

To see the gene callers available in your contigs database, you can use %(anvi-db-info)s or use this program with the following flag: 

{{ codestart }}
anvi-export-gene-calls -c %(contigs-db)s \
                       --list-gene-callers
{{ codestop }}

Running this will export all of your gene calls identified by the gene caller [prodigal](https://github.com/hyattpd/Prodigal) (assuming it is in your %(contigs-db)s:

{{ codestart }}
anvi-export-gene-calls -c %(contigs-db)s \
                       --gene-caller Prodigal \
                       -o %(gene-calls-txt)s
{{ codestop }}

{:.notice}
You can export genes from more gene callers by providing a comma-separated list of gene caller names.

If you don't want to display the amino acid sequences of each gene (they can crowd the file very quickly if you don't want to see them), you can add the following flag:

{{ codestart }}
anvi-export-gene-calls -c %(contigs-db)s \
                       --gene-caller Prodigal \
                       --skip-sequence-reporting \
                       -o %(gene-calls-txt)s
{{ codestop }}

## Advanced uses

This program can take a lot of time and memory when working with very large %(contigs-db)s files (such as those that are more than 10 Gb in file size or more than 10 million contigs).

In that case you can export your gene calls the following way within minutes and a small memory space.

First open your %(contigs-db)s:

{{ codestart }}
sqlite3 %(contigs-db)s
{{ codestop }}

Then run these lines,

{{ codestart }}
.mode csv 
.headers on 
.out %(gene-calls-txt)s
select gene_callers_id, contig, start, stop, direction, partial from genes_in_contigs;
{{ codestop }}

You can also continue with these lines to get the amino acid sequences for them:

{{ codestart }}
.mode csv 
.headers on 
.out AMINO-ACID-SEQUENCES.txt
select * from genes_in_contigs;
{{ codestop }}
This program sorts and indexes your BAM files, essentially converting a %(raw-bam-file)s into a %(bam-file)s, which are ready to be used in anvi'o. 

If you're unsure what a BAM file is, check out the %(bam-file)s page or [this file](https://samtools.github.io/hts-specs/SAMv1.pdf), written by the developers of samtools. For a description of what indexing a BAM file does, check out the page for %(raw-bam-file)s. 

To run this program, just provide a path to the bam files that you want to index. For example, 

{{ codestart }}
anvi-init-bam %(raw-bam-file)s 
{{ codestop }}

You can also multithread this to shorten runtime with the flag `-T` followed by the desired number of threads if your system is capable of this. 

To see it in action (plus a description on how to run it on an entire folder), check out [this page](http://merenlab.org/2016/06/22/anvio-tutorial-v2/#anvi-init-bam). 
This program **associates the single-copy core genes in your %(contigs-db)s with taxnomy information.**  

Once this information is stored in your %(contigs-db)s (in the form of a %(scgs-taxonomy)s artifact), you can run %(anvi-estimate-scg-taxonomy)s or use the %(anvi-interactive)s and enable "Realtime taxonomy estimate for bins." Check out [this tutorial](http://merenlab.org/2019/10/08/anvio-scg-taxonomy/) for more information. 

In order to run this program, you'll need a %(scgs-taxonomy-db)s, which you can set up by running %(anvi-setup-scg-taxonomy)s. 

### What does this program do? 

In short, this program searches all of the single-copy core genes that it uses for this workflow (which are the 22 listed on [this page](https://github.com/merenlab/anvio/tree/master/anvio/data/misc/SCG_TAXONOMY/GTDB/SCG_SEARCH_DATABASES)) against the [GTDB](https://gtdb.ecogenomic.org/) databases that you downloaded, and stores hits in your %(contigs-db)s. In other words, it finds your single-copy core genes and assigns them taxonomy. This way, it can use these single-copy core genes later to estimate the taxnomy of larger groups of contigs that include these single-copy core genes when you run %(anvi-estimate-scg-taxonomy)s. 

### Sweet. How do I run it? 

{{ codestart }}
anvi-run-scg-taxonomy -c %(contigs-db)s
{{ codestop }}

In case you're running this on a genome and not getting any hits, you have the option to try lowering the percent identity required for a hit (as long as you're careful with it). The default value is 90 percent. 

{{ codestart }}
anvi-run-scg-taxonomy -c %(contigs-db)s \
                      --min-percent-identity 70
{{ codestop }}
This program **generates plots of groups of tRNA-seq seeds. The plots show seed coverages and the nucleotide frequencies at modification sites in each sample**.

The %(trnaseq-workflow)s predicts tRNA seeds and their nucleotide modifications from a set of samples. The inspect webpage in %(anvi-interactive)s displays information on a selected seed, including coverages, mutation frequencies at predicted modification sites, and indel frequencies. anvi-plot-trnaseq generates plots that similarly show seed coverages in each sample but otherwise differ in many ways from the inspect page.

This program generates plots for a user-defined group of seeds. Seeds may be grouped by tRNA taxonomy and/or amino acid/anticodon identity. All of the seeds in a taxonomic/anticodon group are represented on the same plot. For example, all Arg-ACG seeds resolving to family Lachnospiraceae can be displayed on a single plot. Each panel of the plot shows coverages of all the seeds in a given sample. If there are five Lachnospiraceae Arg-ACG seeds, then five coverage traces will be stacked atop each other in each subplot, the seed with the highest mean coverage on the bottom. Nucleotide frequencies at predicted modification positions are shown as bars, with sections of the bar for each of the four nucleotides. If three of the five seeds have a modification, say m1A22, then the total height of the bar will rise to the height of the summed coverage of the three seeds at position 22. The number of seeds represented by the group is displayed on the plot, and the mean and 3' (discriminator nucleotide) coverages of the group of seeds is displayed adjacent to each sample subplot.

Multiple groups may be specified at the same time, producing a set of plots. If **only** a taxonomic group is given, then plots for **every** isoacceptor will be produced, e.g., Lachnospiraceae Arg-ACG, Arg-CCG, Arg-GCG, etc. If a taxonomic **rank** and anticodon is given, then plots for each taxon will be produced, e.g., at the family level, Lachnospiraceae Arg-ACG, Ruminococcaceae Arg-ACG, Bacteroidaceae Arg-ACG, etc.

anvi-plot-trnaseq is interactive through the command prompt, allowing the required %(trnaseq-contigs-db)s, %(seeds-specific-txt)s, and %(modifications-txt)s to be loaded only once and plots to be generated on the fly. Aesthetic parameters of the plots can be tweaked through the program. A comprehensive help menu with examples appears upon starting the program.
This program **computes both the geometric homogeneity and functional homogeneity for the gene clusters in a %(pan-db)s.** 

*Geometric homogeneity* and *functional homogeneity* are anvi'o specific terms that describe how similar genes within a gene cluster are to each other in different ways. Briefly, geometric homogeneity compares the positions of gaps in the aligned residues without considering specific amino acids, and functional homogeneity examines point mutations to amino acids and compares how similar the resulting amino acids are chemically. See [this page](http://merenlab.org/2016/11/08/pangenomics-v2/#inferring-the-homogeneity-of-gene-clusters) for more details. 

You can run this program as so: 

{{ codestart }}
anvi-compute-gene-cluster-homogeneity -p %(pan-db)s \
                                      -g %(genomes-storage-db)s \
                                      -o path/to/output.txt \
                                      --store-in-db
{{ codestop }}

This run will put the output directly in the database, as well as provide it as a separate file as the specified output path. 

You also have the option to calculate this information about only specific gene clusters, either by providing a gene cluster ID, list of gene cluster IDs, %(collection)s or %(bin)s. 

To save on runtime, you can also enable `--quick-homogeneity`, which will not check for horizontal geometric homogenity (i.e. it will not look at alignments within a single gene). This will be less accurate for detailed analyses, but it will run faster. 

Here is an example run that uses this flag and only looks at a specific collection: 

{{ codestart }}
anvi-compute-gene-cluster-homogeneity -p %(pan-db)s \
                                      -g %(genomes-storage-db)s \
                                      -o path/to/output.txt \
                                      --store-in-db \ 
                                      -C %(collection)s \
                                      --quick-homogeneity 
{{ codestop }}

You can also use multithreading if you're familiar with that. 
This program **merges two or more %(bin)ss together** into a single %(bin)s.

To run this program, the bins that you want to merge must be contained within a single %(collection)s. Just provide the collection name, the %(pan-db)s or %(profile-db)s you're working with, the bins that you want to merge, and the name of the output bin. 

To check what collections and bins are contained in a database, you can either run this program with the flag `--list-collections` or `--list-bins`, or you can run %(anvi-show-collections-and-bins)s.

For example, if you wanted to merge the bins `first_third`, `middle_third`, and `last_third` in a pan-db into a single bin called `complete_bin`, just run 

{{ codestart }}
anvi-merge-bins -p %(pan-db)s \
                -C %(collection)s \
                -b first_third,middle_third,last_third \
                -B complete_bin
{{ codestop }}

Now your collection will contain the bin `complete_bin` and the original bins will be gone forever (unless you had run%(anvi-summarize)s, %(anvi-export-collection)s, or a similar program beforehand)
This program is a quicker, but less comprehensive, alternative to %(anvi-summarize)s. It is used to summarize basic read recruitment statistics (like detection and coverage) from many single profiles that are all associated with the same %(contigs-db)s.

Given a list of samples (single profiles) and a collection, `anvi-summarize-blitz` will compute the per-sample weighted average of each statistic for each bin in the collection. This is an average of the statistic value over each split in the bin, _weighted by the split length_.

The output will be a text file, and you can find details about its format by clicking on %(quick-summary)s.

### Basic usage

In addition to your list of %(single-profile-db)ss, you must provide this program with their corresponding contigs database and a collection name.

{{ codestart }}
anvi-summarize-blitz PROFILE_1.db PROFILE_2.db PROFILE_3.db [...] \
                     -c %(contigs-db)s \
                     -C %(collection)s
{{ codestop }}

The program will summarize the same collection across all of your single profile databases. However, it will use only the first profile database in the argument list to learn about what is in the collection, so it is not exactly necessary to have this collection defined for all of the other profile databases (though one could argue that it is a good idea to do this regardless...). The collection name you provide to this program must be a collection that is present in at least the first profile database in the argument list. In the example above, only `PROFILE_1.db` is strictly required to include the collection you wish to summarize (though all other profiles must contain the same splits as this first profile, which should not be a problem if you generated them all in the same way).

### Choosing a different output prefix

If nothing is provided, the output file name will be the collection name, suffixed with `-SUMMARY-BLITZ.txt` (although the user can specify the output file name as they should using the parameter `--output-file`):

{{ codestart }}
anvi-summarize-blitz PROFILE_1.db PROFILE_2.db PROFILE_3.db [...] \
                     -c %(contigs-db)s \
                     -C %(collection)s \
                     -o OUTPUT.txt
{{ codestop }}

### Choosing which statistics to summarize

The default statistics that will be summarized are detection and something called 'mean_coverage_Q2Q3' (which is [this](https://merenlab.org/2017/05/08/anvio-views/#mean-overage-q2q3)). You can choose which statistics to summarize by providing them as a comma-separated list (no spaces in the list) to the `--stats-to-summarize`, or `-S`, parameter:

{{ codestart }}
anvi-summarize-blitz PROFILE_1.db PROFILE_2.db PROFILE_3.db [...] \
                     -c %(contigs-db)s \
                     -C %(collection)s \
                     -S std_coverage,mean_coverage,detection
{{ codestop }}

Each statistic will get its own column in the output file.

If you are not sure which statistics are available to choose from, just provide some ridiculous, arbitrary string (that cannot possibly be a name of a statistic) to this flag, and you will get an error message that includes a list of the available statistics. Or, you can just look at this example error message (but no guarantees that the list in this example will be the same as whatever you would get by doing it yourself. Just sayin'.)
```
Config Error: The statistic you requested, cattywampus, does not exist. Here are the options
              to choose from: std_coverage, mean_coverage, mean_coverage_Q2Q3, detection,
              abundance, variability
```

If you are curious about the statistics in the list, many of them have definitions in [this blog post](https://merenlab.org/2017/05/08/anvio-views).

## Common errors

### Existing file error

If the output file already exists, you will encounter the following error:
```
File/Path Error: AppendableFile class is refusing to open your file at test-quick_summary.txt
                 because it already exists. If you are a user, you should probably give Anvi'o a
                 different file name to work with. If you are a programmer and you don't want
                 this behavior, init this class with `fail_if_file_exists=False` instead.
```
You can either provide a different file prefix using the `-O` parameter, as the error message suggests, or you can simply delete the existing file and re-run your command.

### Missing table error

If you get an error that looks like this:
```
Config Error: The database at [PROFILE.db] does not seem to have a table named
              `detection_splits` :/ Here is a list of table names this database knows:
              [...]
```

That means your profile databases are not the correct version. The tables we are accessing in this program were introduced in profile database version 36. So the solution to this error is to update your databases to at least that version, using %(anvi-migrate)s. :)
Briefly, %(anvi-analyze-synteny)s counts %(ngrams)s by converting contigs into strings of annotations for a given user-defined source of gene annotation. A source annotation for %(functions)s **must** be provided to create %(ngrams)s, upon which anvi'o will use a sliding window of size `N` to deconstruct the loci of interest into %(ngrams)s and count their frequencies.

### Run for a given function annotation source

{{ codestart }}
anvi-analyze-synteny -g %(genomes-storage-db)s \
                     --annotation-source %(functions)s \
                     --ngram-window-range 2:3 \
                     -o %(ngrams)s
{{ codestop }}

For instance, if you have run %(anvi-run-ncbi-cogs)s on each %(contigs-db)s you have used to generate your %(genomes-storage-db)s, your `--annotation-source` can be `NCBI_COGS`:

{{ codestart }}
anvi-analyze-synteny -g %(genomes-storage-db)s \
                     --annotation-source NCBI_COGS \
                     --ngram-window-range 2:3 \
                     -o %(ngrams)s
{{ codestop }}


### Handling genes with unknown functions 

By default, %(anvi-analyze-synteny)s will ignore genes with unknown functions based on the annotation source of interest. However, this can be circumvented either by providing a %(pan-db)s, so the program would use gene cluster identities as function names:

{{ codestart }}
anvi-analyze-synteny -g %(genomes-storage-db)s \
                     -p %(pan-db)s \
                     --ngram-window-range 2:3 \
                     -o %(ngrams)s
{{ codestop }}

or by explicitly asking the program to consider unknown functions, in which case the program would not discard ngrams that include genes without functions:

{{ codestart }}
anvi-analyze-synteny -g %(genomes-storage-db)s \
                     --annotation-source %(functions)s \
                     --ngram-window-range 2:3 \
                     -o %(ngrams)s \
                     --analyze-unknown-functions
{{ codestop }}

The disadvantage of the latter strategy is that since all genes with unknown functions will be considered the same, the frequency of ngrams that contain genes with unknown functions may be inflated in your final results.

### Run with multiple annotations

If multiple gene annotation sources are provided (i.e., a pangenome for gene clusters identities as well as a functional annotation source), the user must define which annotation source will be used to create the %(ngrams)s using the parameter `--ngram-source`. The resulting %(ngrams)s will then be re-annotated with the second annotation source and also reported. 

{{ codestart }}
anvi-analyze-synteny -g %(genomes-storage-db)s \
                     -p %(pan-db)s \
                     --annotation-source %(functions)s \
                     --ngram-source gene_clusters \
                     --ngram-window-range 2:3 \
                     -o %(ngrams)s
{{ codestop }}

### Test cases for developers

If you are following the anvi'o master branch on your computer, you can create a test case for this program.

First, go to any work dirctory, and run the following commands:

``` bash
anvi-self-test --suite metagenomics-full \
               --output-dir TEST-OUTPUT

# make a external-genomesfile
echo -e "name\tcontigs_db_path\ng01\tTEST-OUTPUT/01.db\ng02\tTEST-OUTPUT/02.db\ng03\tTEST-OUTPUT/03.db" > TEST-OUTPUT/external-genomes-file.txt
```

Run one or more alternative scenarios and check output files:

```
anvi-analyze-synteny -e TEST-OUTPUT/external-genomes-file.txt \
                     --annotation-source COG_FUNCTION \
                     --window-range 2:3 \
                     -o TEST-OUTPUT/synteny_output_no_unknowns.tsv

anvi-analyze-synteny -e TEST-OUTPUT/external-genomes-file.txt \
                     --annotation-source COG_FUNCTION \
                     --window-range 2:3 \
                     -o TEST-OUTPUT/synteny_output_with_unknowns.tsv \
                     --analyze-unknown-functions

anvi-analyze-synteny -e TEST-OUTPUT/external-genomes-cps.txt \
                     --annotation-source COG_FUNCTION \
                     --window-range 2:3 \
                     -o TEST-OUTPUT/tsv.txt \
                     --analyze-unknown-functions
```
This program **displays the contents of a %(pan-db)s in the [anvi'o interactive interface](http://merenlab.org/2016/02/27/the-anvio-interactive-interface//#using-the-anvio-interactive-interface), much like %(anvi-interactive)s.**

Like you can see in the [pangenomics tutorial](http://merenlab.org/2016/11/08/pangenomics-v2/#displaying-the-pan-genome), this opens a window of the interactive interface where each item is a gene cluster and each layer represents one of your genomes. 

### A general run 

You can run it with only two parameters: 

{{ codestart }}
anvi-display-pan -p %(pan-db)s \
                 -g %(genomes-storage-db)s 
{{ codestop }}

There are several default layer orders to choose from, including organizing based on gene cluster presence/absense or gene cluster frequency. These will both group your core gene clusters and singletons separately. 

Beyond that, there are many different settings you can change in the side panel of the interface and you can import various additional data (primarily with the program %(anvi-import-misc-data)s). Once you're happy with the data displayed in the interface (and the prettiness of that data), you can  save those preferences in a %(state)s. 

### I want MORE data displayed 

There are several other data types you can additionally choose to display in this program. Namely, you can add:

- a title (very fancy I know) using `--title` 
- a NEWICK formatted tree (or import it as a %(misc-data-items-order-txt)s with %(anvi-import-items-order)s or as a %(misc-data-layer-orders)s with %(anvi-import-misc-data)s). 
- view data in a tab-delimited file
- an additional view (provide this in a tab-delimited matrix where each column corresponds to a sample and each row corresponds to a gene cluster)
- an additional layer in the form of a %(misc-data-layers-txt)s (or import it into your %(pan-db)s with %(anvi-import-misc-data)s

### How to minimize mouse clicks 

Wondering how to autoload specific aspects of the interface? You're in the right place. 

You have the option to specify quite a few aspects of the interface through the parameters to save you those sweet mouse clicks. 

- You can specify which view to start the interface with. Check which views are available with `--list-views`. 
- You can load a specific %(state)s (either a previous state or a state that you've imported with %(anvi-import-state)s). Check which states are available with the flag `--list-states`. 
- You can also load a specific %(collection)s with `--collection-autoload`. To check which collections are availible, use `--list-collections`. 

### Other parameters 

You can also skip processes like intializing functions or automatically ordering your items to save time, as well as configure the server to your heart's content. 
This program, as one might think, allows you to import a %(misc-data-items-order-txt)s to describe a specific order of items stored in a %(profile-db)s, %(pan-db)s, or %(genes-db)s.

{{ codestart }}
anvi-import-items-order -p %(profile-db)s \
                        -i %(misc-data-items-order-txt)s
{{ codestop }}

It may also be nice to give it a good name, so that it's easy to find in the interface.

{{ codestart }}
anvi-import-items-order -p %(profile-db)s \
                        -i %(misc-data-items-order-txt)s \
                        --name ORDER_NAME
{{ codestop }}
This program computes the detection of genes (inputted as a %(bin)s) across your samples, so that you can visualize them in the %(interactive)s interface. 

This program is used in [the metapangenomic workflow](https://merenlab.org/data/prochlorococcus-metapangenome/#classification-of-genes-as-ecgs-and-eags-by-the-distribution-of-genes-in-a-genome-across-metagenomes) on genes with metagenomes as samples to visually identify the environmental core genes and accessory genes. 

### Inputs  

Essentially, you provide a %(contigs-db)s and %(profile-db)s pair, as well as the %(bin)s you want to look at, and this program will  search each gene in your bin against the samples denoted in your %(profile-db)s: 

{{ codestart }}
anvi-script-gen-distribution-of-genes-in-a-bin -c %(contigs-db)s \ 
                                               -p %(profile-db)s \
                                               -C %(collection)s \
                                               -b %(bin)s 
{{ codestop }}

There are two other parameters that you can set to focus the genes that you're looking at: 
- The minimum detection required for a gene to be included (by default, a gene must have a detection value of `0.5` in at least one of your samples)
-The minimum coverage required for a gene to be included (by default, a gene must have a total coverage of `0.25` times the mean total coverage in your data) 

### Outputs

This program will produce two outputs: 

1. `[your bin name]-GENE-COVs.txt`, which is a %(view-data)s artifact. This is a matrix where each row represents a gene, each column represents one of your samples, and the cells each contain a coverage value. 
2. `[your bin name]-ENV-DETECTION.txt`, which is a %(misc-data-layers)s. It is a two-column file, where each row is a gene and and the second column describes whether or not that gene is systematically detected in your samples. Thus, this can be added as an additional layer in the interface that describes describes which genes are detected in your samples. (as an example, see the outermost layer [here](https://merenlab.org/data/prochlorococcus-metapangenome/#classification-of-genes-as-ecgs-and-eags-by-the-distribution-of-genes-in-a-genome-across-metagenomes))

Thus, after running this program on a bin with name `BIN_NAME`, you can run 

{{ codestart }}
%(anvi-interactive)s -d BIN_NAME-GENE-COVs.txt \
                 -A BIN_NAME-ENV-DETECTION.txt \
                 --manual \
                 -p %(profile-db)s
{{ codestop }}                                                   

This will visually show you the coverage and detection of your genes across your samples in the %(interactive)s interface (simlarly to [this figure](https://merenlab.org/data/prochlorococcus-metapangenome/#classification-of-genes-as-ecgs-and-eags-by-the-distribution-of-genes-in-a-genome-across-metagenomes)). 
This is a script that transposes tab-delimited files. That's it. 

It's helpful to get your inputs to line up with the types of inputs that anvi'o expects. Some programs have the `--transpose` flag, which will run this program for you, but some don't, and that's when you'll have to run it yourself. 

For example, anvi'o expects %(view-data)s to have each column representing a sample. If the file that you want to integrate into your anvi'o project has the samples as rows and the data attribute as the columns, then you'll need to %(anvi-script-transpose-matrix)s it. 

### An Example Run 

If you have an input ile `INPUT.txt` that looks like this: 

    1   2   3   
    4   5   6   
    7   8   9
    10  11  12
    
And you run this:

{{ codestart }}
anvi-script-transpose-matrix -o INPUT_transposed.txt \
                             -i INPUT.txt 
{{ codestop }}

You'll get a file called `INPUT_transposed.txt` that looks like 

    1   4   7   10
    2   5   8   11
    3   6   9   12
    

This program **opens the anvi'o interactive interface** to let the user **refine what contigs are contained in a specific %(bin)s or manually split one bin into several.**

In the %(interactive)s interface, any bins that you create will overwrite the bin that you originally opened.  If you don't provide any names, the new bins' titles will be prefixed with the name of the original bin, so that bin will continue to live on in spirit. 

Essentially, it is like running %(anvi-interactive)s, but disposing of the original bin when you're done. 

### Potential Use Cases 

There are several reasons you might want to use anvi-refine: 

- Your dataset is just really big. 

    This process has its own [dedicated blog post](http://merenlab.org/2015/05/11/anvi-refine/), but, in short, the interactive interface and analysis, like all things, has its limits. Instead of trying to actively analyze all of your data at once, which will be very computationally heavy and might limit the types of analysis you'll even be able to do, it will be helpful to split your data into several smaller bins first. Then you can use anvi-refine on each one to replace those temporary bins with your final bins. 
    
- You want to refine a bin generated by automated binning software.   
    
    After automated binning (which you can do in anvi'o with %(anvi-cluster-contigs)s), you might see an awkward bin or two. These programs often have difficultly separating bins in some scenarios, as well as sorting out prophages, mobile genetic elements, and other things that you might want to have in their own bin. You can take these out of your MAGs and put them in their own bins, split bins with high redundency, or just refine them in any way you please, using anvi-refine. 
    
- You're just not happy with one of your bins. 
    
    Happens to everyone. Maybe the redundency is just a little too high and you want to take a closer look, or maybe you just want to split up two contigs giving you different taxonomy results. Feel free to go in and take specfic contigs out or split one bin into several. 
    
If you just want to look at the contents of partiuclarly glorious bin, you should probably just use %(anvi-interactive)s for that, since you don't want to risk overwriting your bin. 
This program clusters the contigs stored in a %(profile-db)s using your binning algorithm of choice and stores the results in several %(bin)ss. 

This is a quick alternative to manually binning your contigs, but it might miss some details that a human doing manual binning would find. After running this, you might want to run %(anvi-summarize)s on the resulting %(collection)s to look through your bins, and, if necessary, use %(anvi-refine)s to change the contents of them. 

You have to option to use several different clustering algorithms, which you'll specify with the `driver` parameter: [concoct](https://github.com/BinPro/CONCOCT/blob/develop/doc/source/index.rst), [metabat2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6662567/), [maxbin2](https://academic.oup.com/bioinformatics/article/32/4/605/1744462), [dastool](https://github.com/cmks/DAS_Tool), and [binsanity](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5345454/). 

So, a run of this program will look like the following:

{{ codestart }}
anvi-cluster-contigs -p %(profile-db)s \
                     -c %(contigs-db)s \ 
                     -C %(collection)s \ 
                     --driver concoct
{{ codestop }}

Once you specify an algorithm, there are many algorithm specific parameters that you can change to your liking. When this program is set up, these parameters will appear in the help menu for the algorithms that anvi'o can find. 
---
name: Feature Request
about: Suggest something you wish anvi'o could do.
title: "[FEATURE REQUEST] Replace this text with a concise description of the feature you propose"
labels: ''
assignees: ''

---

## The need

Replace this text with the feature you wish to see in anvi'o.

## The solution

Describe the best solution to address this need. If you don't have any solution, please remove this section.

## Beneficiaries

Speculate who would most benefit from this solution. Any anvi'o user? Anyone who uses a particular function?
---
name: Start a Discussion
about: Start a discussion on anything microbial 'omics or anvi'o.
title: "[DISCUSSION] Replace this text with a short but descriptive title"
labels: ''
assignees: ''

---
---
name: Bug Report
about: Report a bug or technical problem.
title: "[BUG] Replace this text with a short but descriptive title"
labels: ''
assignees: ''

---

## Short description of the problem

Replace this text with a single-sentence description of the problem.

## anvi'o version

Replace this text with the output of this command:

```
anvi-self-test --version
```

## System info

Please tell us which operating system you are using, and how did you install anvi'o.

## Detailed description of the issue

Replace this text with a clear description of what you expected to happen. Feel free to include screenshots :) If you don't think you need additional description of the problem and your short description is sufficient, please remove this section.

## Files to reproduce

If you have files that you can share with us to reproduce the issue (i.e., a contigs database, a profile database, a BAM file, etc), they may help us dramatically. Please put them in a single directory, compress the directory, upload it to Dropbox (or any other comparable service), and share with us a direct download link along with instructions on how to reproduce the error.

If you don't have files to share, please remove thi section.
