---
title: 'Cellocity: A Python package for analysis of confluent cell layer dynamics'
tags:
  - Python
  - microscopy
  - dynamics
  - confluent cell layer
authors:
  - name: Jens Eriksson^[Corresponding author]
    orcid: 0000-0002-8945-2665
    affiliation: 1
  - name: Daniel Styrström
    affiliation: 2
  - name: Mikael E. Sellin
    orcid: 0000-0002-8355-0803
    affiliation: 1
affiliations:
 - name: Science for Life Laboratory, Department of Medical Biochemistry and Microbiology, Uppsala University
   index: 1
 - name: Daniel Styrström Consulting
   index: 2
date: 24 August 2020
bibliography: paper.bib

---

# Summary

Studying the coordinated cell and tissue movements within confluent cell layers can give insights into diverse biological phenomena, such as wound healing, cancer cell metastasis, and host cell responses to infection. Cellular dynamics studies typically rely on analysis of time lapse images, generated by live cell microscopy. As a result of recent progress in stem cell and developmental biology, it is now often possible to generate confluent cell layers of primary cells that recapitulate central features of intact tissues [@Dutton2019]. However, one disadvantage of such primary cell model systems is that it remains technically challenging to generate and image fluorescently labeled live samples. This complicates the use of segmentation and single-particle tracking as a means to study cellular movements [@Danuser2006]. Consequently, optical flow-based analysis of bright field (black and white) microscopy images provides a competitive method to extract cell dynamics information from such sensitive and low-contrast experimental model systems [@Vig2016]. Because the study of confluent cell layer dynamics lies at the intersection of biophysics and cell biology, two research communities with different emphasis on mathematics, there is a need for a simple and easy-to-use framework that performs and visualizes Optical Flow analysis of microscopy data. We here present Cellocity, a Python package for Optical Flow and Particle Image Velocimetry (PIV) analysis, specifically catering to the bioimaging community.          


# Statement of need

To date, Optical Flow and PIV analysis of microscopy data has primarily relied on different plugins for ImageJ, such as [PIV analyser](https://imagej.net/PIV_analyser), or on MATLAB scripts [@Vig2016]. However, these methods are limited in their accessibility, analysis capacity, metadata handling, and data visualization capabilities. Optical Flow and PIV are commonly used in the fields of fluid dynamics [@Taylor2010] and computer vision [@Bradski2000], and several open source frameworks exist to service these communities, e.g., [openPIV](http://www.openpiv.net/), [JPIV](https://eguvep.github.io/jpiv/index.html) and [OpenCV](https://opencv.org/) [@Bradski2000]. A corresponding framework for bioimaging and cell biology applications has so far been lacking.

Cellocity is an Python-based bioimage analysis tool for quantifying cell and tissue dynamics. It has been developed as a flexible framework for researchers interested in investigating dynamic behaviors within confluent cell layers, and to address the Optical Flow/PIV needs unique to the microscopy community. Cellocity allows users to test and evaluate a diverse set of preprocessing steps, analysis algorithms, packages, and parameters on their experimental data. It provides a uniform programming interface to work with the many aspects in a cell dynamics analysis pipeline, from reading and preprocessing raw microscopy data, to creating flow visualizations and figures with the help of [Matplotlib](https://matplotlib.org/) [@Hunter2007]. [Numpy](https://numpy.org/) [@vanderWalt2011] is used extensively by Cellocity for array processing, [OpenPIV-python](http://www.openpiv.net/openpiv-python/) [@Liberzon2020] provides the PIV analysis backbone, and the OpenCV implementation of Gunnar Farenbäck's optical flow algorithm [@farneback03] is the basis of the optical flow analysis.

One unique feature of microscopy data is that the spatial resolution (pixel size) can be known to a high degree of accuracy, and together with frame time-stamps this can be used to calculate accurate flow velocities. A major problem when performing preprocessing of time lapse microscopy data, for example through temporal median filtering, is that such operations sometimes can change the time interval between frames and/or the pixel size. Cellocity is by design keeping track of and recalculating time and space units during operations, so as to not report back erroneous output data to the user. It is possible to configure Cellocity to give output in different units, such as µm/min or µm/h, depending on the time scale of the experiment being analyzed. Moreover, Cellocity can calculate derived parameters, including the i) Instantaneous Order Parameter [@Malinverno2017], ii) Alignment Index [@Malinverno2017], and/or iii) 5-sigma correlation length [@Laang2018], and thereby provides the user with a comprehensive tool box to describe confluent cell layer dynamics phenomena.   

# Validation of the software

To validate and test the different modules and components of Cellocity, a validation dataset has been constructed. The dataset has been deposited in the BioStudies database under the accession number [S-BSST461](https://www.ebi.ac.uk/biostudies/studies/S-BSST461). It is comprised of a collection of files that were generated by translating and imaging a fixed monolayer of murine primary gut epithelium on a high-precision linear microscope stage, using a wide selection of magnifications. 10 images were acquired with the stage translated 1um in either the X, Y, or both directions simultaneously between frames. The dataset is described in detail in the [validation section](https://cellocity.readthedocs.io/en/latest/validation.html) of the Cellocity documentation. Downloading this dataset allows users and contributors (to Cellocity and other software) to validate and test their installations and custom modules against a standard, comprised of real-world data where the flow is known and uniform, and the data has not been synthetically generated, but has passed through the optical transfer function (OTF) of an actual microscope setup.

The main advantages of Cellocity is its ability work on unlabeled Bright field time lapse microscopy data, and to both quantify and visualize abstract Optical Flow analyses to the user. Cellocity aims to make Optical Flow-based analysis of microscopy data easily accessible, by providing a framework that keeps track of image metadata, performs common pre-processing steps, and implements previously published analysis algorithms [@Malinverno2017; @Laang2018]. The architecture of Cellocity is designed with extensibility and modularity in mind. Implementing new analysis modules, image readers, and visualizations is straight forward with the help of Cellocity's [developer guide](https://cellocity.readthedocs.io/en/latest/developer.html) and [API](https://cellocity.readthedocs.io/en/latest/api.html).

# Acknowledgements

We thank Pilar Samperio Ventayol for preparing the fixed murine intestinal epithelial monolayer used to generate the validation dataset. This work was financed by the SciLifeLab Fellows program and the Swedish Foundation for Strategic Research (ICA16-0031). We also acknowledge support from the Knut and Alice Wallenberg Foundation (2016.0063) and the Malin and Lennart Philipson Foundation (L.P. Award 2018) that enabled development of the imaging technology used in this study. 

# References
# Cellocity

Cellocity is a python package that allows the user to perform Optical Flow and PIV analysis on microscopy data. It is intended to be helpful in both the exploratory and in the data acquisition phases of a cell layer dynamics project. In the exploratory phase, several different algorithms, settings, and preprocessing functions can be evaluated. In the acquisition phase, a pipeline can be "hard coded" for processing of multiple data sets through a pre-determined series of steps.   

## Velocity and vector analysis of microscopy data

Cellocity can create vector field visualizations, speed graphs, and multiple advanced vector field analyses, such as calculating the instantaneous order parameter, alignment index and correlation lengths of migrating cells.

## Documentation & Software validation

Documentation is available at [Read the Docs](https://cellocity.readthedocs.io/en/latest/).
There you can also find an extensive chapter on the validation of the Cellocity software.

## Citing Cellocity
If you want to cite Cellocity in your work you can use our JOSS publication [![DOI](https://joss.theoj.org/papers/10.21105/joss.02818/status.svg)](https://doi.org/10.21105/joss.02818)
Contributions are welcome and appreciated. Simply fork the GitHub repository and create a [pull request](https://github.com/Oftatkofta/cellocity/pulls). Information on how to do so can be found [here](https://github.com/MarcDiethelm/contributing/blob/master/README.md). Before you do so, please make sure that the documentation strings are written in reStructuredText so that [Sphinx-autodoc](https://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html) can generate automatic API documentation. It would also be greatly appreciated if the general architecture of ``Channel``, ``Analyzer``, and ``Analysis`` objects is maintained. You can read more about the organization and functionality of these objects [here](https://cellocity.readthedocs.io/en/latest/introduction.html#cellocity-architecture).
---
name: Bug report
about: Create a report to improve Cellocity
title: "[BUG]"
labels: bug
assignees: Oftatkofta

---

**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Python Version [e.g. 3.8]
 - OpenCV Version
 - tifffile Verson

**Additional context**
Add any other context about the problem here.
---
name: Feature request
about: Suggest an idea for this project
title: "[FEATURE]"
labels: enhancement
assignees: Oftatkofta

---

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.
Developer Information
=====================

This section contains information relevant for developing and extending Cellocity functionality. It also contains random tidbits of general information that I have uncovered during the development process of this framework. I present it here in the hope that someone may find it useful.


Contributing to Cellocity
-------------------------

Contributions are welcome and appreciated. Just fork the Github repository and create a `pull request <https://github.com/Oftatkofta/cellocity/pulls>`_. Information on how to do so can be found `here <https://github.com/MarcDiethelm/contributing/blob/master/README.md>`_. Before you do so, please make sure that the documentation strings are written in reStructuredText so that `Sphinx-autodoc <https://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html>`_ can generate automatic API documentation. It would also be greatly appreciated if the general architecture of ``Channel``, ``Analyzer``, and ``Analysis`` objects is maintained.


Bug reports and feature requests
--------------------------------

Bug reposts and feature requests can be submitted `through Github <https://github.com/Oftatkofta/cellocity/issues/new/choose>`_.



A note on metadata and file formats
-----------------------------------

It goes without saying that you need to have a well calibrated microscope that
writes correct metadata into your image files, in order to perform meaningful cell dynamics analysis. The minimal amount of information needed is data on the pixel size and the time resolution between frames. Image format specific metadata, such as Micromanager-metadata and IJmetadata contain this information and constitute the primary source used throughout Cellocity.

Micromanager saves its metadata in a private IFD tag (51123), which ``Tifffile`` reads in as a ``dict``, accessible via ``tif.micromanager_metadata``. The structure of the dictionary is, annoyingly, slightly different between the 1.4.23, 2.0-beta, and 2.0-gamma branches of Micromanager. In 1.4.23 and 2.0-gamma the frame interval is stored in ``tif.micromanager_metadata['Summary']['Interval_ms']``, but in 2.0-beta it is stored in ``tif.micromanager_metadata['Summary']['WaitInterval']``. The discrepancy is probably due to the fact that this value records the wait interval time between frames of the acquisition, not the *actual* frame interval. It is possible to setup an acquisition with a frame interval that the microscope physically cannot keep up with. Therefore, Cellocity performs an additional sanity check of the individual time stamps of the frames (see ``Channel.doFrameIntervalSanityCheck()``), in order to make sure you do not run into this problem during analysis. 


Pixel resolution in Micromanager vs ImageJ .tif files
-----------------------------------------------------

Relevant standard tags in the `TIFF specification <https://www.adobe.io/open/standards/TIFF.html>`_ are **XResolution**, **YResolution**, and **ResolutionUnit**. The resolution tags are rational numbers, meaning they are generated by dividing two 32-bit integer values. **ResolutionUnit** is specified as being either *None*, *Inch* or *Centimeter*. No other units are specified.

When Micromanager saves an ome.tif it writes a rounded off value into the XResolution and YResolution tif tags, and it sets the **ResolutionUnit** tag to CENTIMETER. This value carries less precision than the 'PixelSizeUm' entry in the custom TIFF-tag 'MicroManagerMetadata', but the TIFF is correctly readable with roughly intact size calibration data in any reader obeying the TIFF standard.

When ImageJ (v. 1.52p) saves a Hyperstack as tif, it writes the 'Pixel Width' and 'Pixel Height' values into the **XResolution** and **YResolution** tags with higher precision. However, it sets the **ResolutionUnit** tag to *None*, probably because microns, the standard micrograph unit, are not specified in the TIFF standard.


Creating your own image format reader
-------------------------------------

If you want to develop your own reader for your microscope raw data, I suggest you look up the `Tiffile project <https://pypi.org/project/tifffile/>`_. It already implements reading of many common tif-formats from multiple microscope vendors. It is a trivial addition to tweak the Channel object and create your own subclass version specific to your file format, since Channel objects are basically extensions of Tifffile objects.

Pragmatically, the easiest way to get your non-supported image data set into Cellocity is to open it in FIJI with the Bioformats importer and thereafter resave it as a hyperstack tif (making sure that the relevant image properties are set correctly). Then, you can use the ImageJ-reading capabilities built in to Cellocity and tiffile.


Detailed description of the 5-:math:`{\sigma}` correlation length analysis algorithm
------------------------------------------------------------------------------------

The 5-:math:`{\sigma}` correlation length was defined as the largest distance, :math:`r`, where the average angle between two velocity vectors :math:`r` micrometers apart was :math:`<90°` with a statistical significance level of 5 :math:`\sigma` :math:`(p=3×10^{−7})`.

The algorithm steps:
++++++++++++++++++++

1. Select each of the :math:`N` vectors along the top left to bottom right diagonal of the ``FlowAnalyzer`` output velocity vector array as :math:`\mathbf{v}_0`.
2. For each :math:`\mathbf{v}_0`, expand linearly, one row/column position at a time, along the cardinal directions (up/down/left/right) and calculate the angle between :math:`\mathbf{v}_0` and each of the vectors :math:`\mathbf{v}_r`, at each position. Do not include masked positions, or positions outside of the array. The angles :math:`\theta` for each :math:`\mathbf{v}_0` are calculated with the formula: :math:`\cos \theta = \frac{{\left\langle {{\mathbf{v}}_0 \ast {\mathbf{v}}_{{{r}}}} \right\rangle }}{{\left\langle {\left| {{\mathbf{v}}_0} \right| \ast \left| {{\mathbf{v}}_{{{r}}}} \right|} \right\rangle }}.`
3. Record all the angles and distances between :math:`\mathbf{v}_0` and :math:`\mathbf{v}_r` for each :math:`N`, and for each time point, :math:`t`.
4. For each distance :math:`r`, and time point :math:`t`, average all the angles recorded at this distance: :math:`\theta \left( r \right) = \frac{1}{N} \ast \mathop {\sum }\limits_{i = 1}^N \cos ^{ - 1}\left( {\frac{{\left\langle {{\mathbf{v}}_0 \ast {\mathbf{v}}_{{{r}}}} \right\rangle }}{{\left\langle {\left| {{\mathbf{v}}_0} \right| \ast \left| {{\mathbf{v}}_{{{r}}}} \right|} \right\rangle }}} \right).`
5. Compute the angular velocity correlation length at each time point. This is defined as the maximum distance where :math:`\theta` is :math:`<90°` with a statistical significance of 5 :math:`\sigma`: :math:`C_{vv}\left( t \right) = \mathop{\max }\limits_{r \to \infty }\left( r \right)\left\{ {\mathrm{AVG}\left( \theta \right)\left( {\it r} \right) + 5 \ast \mathrm{SEM}(\theta ({\it r})) < 90^\circ } \right\}`


Validation of the Cellocity Software
====================================

Validation dataset
------------------

In order to validate the underlying analyzers in Cellocity we have generated a “ground truth”, real-world microscopy dataset.
The dataset was generated by translating and imaging, with DIC contrast, a fixed monolayer of primary gut epithelium on a high precision linear microscope stage, using a wide selection of magnifications.
10 images were acquired  with the stage translated 1 :math:`{\mu m}` in either the X, Y or both directions simultaneously between frames. Images were acquired on a Nikon Eclipse Ti-2 microscope, equipped with a Photometrics Prime 95B camera (1608x1608, 11 um pixel size).
The general structure of the dataset is outlined in the table below.

+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Objective                       | Tube lens | Total         | Pixel Size (um) | X translation (um) | Y translation (um) | Filename                                                   |
|                                 |           | magnification |                 |                    |                    |                                                            |
+=================================+===========+===============+=================+====================+====================+============================================================+
| Nikon 10X/0.45 Air Pln.Apo.Lmbd | 1X        | 10X           | 1.1235          | 0                  | 1                  | fixed_monolayer_DIC_10X_dX-0um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 10X/0.45 Air Pln.Apo.Lmbd | 1X        | 10X           | 1.1235          | 1                  | 0                  | fixed_monolayer_DIC_10X_dX-1um_dY-0um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 10X/0.45 Air Pln.Apo.Lmbd | 1X        | 10X           | 1.1235          | 1                  | 1                  | fixed_monolayer_DIC_10X_dX-1um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 10X/0.45 Air Pln.Apo.Lmbd | 1.5X      | 15X           | 0.749           | 0                  | 1                  | fixed_monolayer_DIC_15X_dX-0um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 10X/0.45 Air Pln.Apo.Lmbd | 1.5X      | 15X           | 0.749           | 1                  | 0                  | fixed_monolayer_DIC_15X_dX-1um_dY-0um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 10X/0.45 Air Pln.Apo.Lmbd | 1.5X      | 15X           | 0.749           | 1                  | 1                  | fixed_monolayer_DIC_15X_dX-1um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 40X/0.6 Air S.Pln.Fl.     | 1X        | 40X           | 0.286           | 0                  | 1                  | fixed_monolayer_DIC_40X_dX-0um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 40X/0.6 Air S.Pln.Fl.     | 1X        | 40X           | 0.286           | 1                  | 0                  | fixed_monolayer_DIC_40X_dX-0um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 40X/0.6 Air S.Pln.Fl.     | 1X        | 40X           | 0.286           | 1                  | 1                  | fixed_monolayer_DIC_40X_dX-0um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 40X/0.6 Air S.Pln.Fl.     | 1.5X      | 60X           | 0.191           | 0                  | 1                  | fixed_monolayer_DIC_60Xopt_dX-0um_dY-1um_1_MMStack.ome.tif |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 40X/0.6 Air S.Pln.Fl.     | 1.5X      | 60X           | 0.191           | 1                  | 0                  | fixed_monolayer_DIC_60Xopt_dX-1um_dY-0um_1_MMStack.ome.tif |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 40X/0.6 Air S.Pln.Fl.     | 1.5X      | 60X           | 0.191           | 1                  | 1                  | fixed_monolayer_DIC_60Xopt_dX-1um_dY-1um_1_MMStack.ome.tif |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 60X/0.7 Air S.Pln.Fl.     | 1X        | 60X           | 0.125           | 0                  | 1                  | fixed_monolayer_DIC_60X_dX-0um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 60X/0.7 Air S.Pln.Fl.     | 1X        | 60X           | 0.125           | 1                  | 0                  | fixed_monolayer_DIC_60X_dX-1um_dY-0um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+
| Nikon 60X/0.7 Air S.Pln.Fl.     | 1X        | 60X           | 0.125           | 1                  | 1                  | fixed_monolayer_DIC_60X_dX-1um_dY-1um_1_MMStack.ome.tif    |
+---------------------------------+-----------+---------------+-----------------+--------------------+--------------------+------------------------------------------------------------+

This dataset allowed us compare the "golden standard" of cell layer dynamics analysis, Particle Image Velocimetry (PIV) analysis, with the less frequently used Optical Flow analysis.
Our conclusion mirror what was found in [#vig]_, which is that Optical Flow analysis is indeed superior to PIV analysis, both with respect to accuracy and efficiency.
The following section will substantiate this finding. All analyses were run on a early 2020 Dell XPS 15 7590 laptop, running Windows 10.

Downloading the validation dataset
----------------------------------

The dataset has been deposited into the BioStudies database with the accession number `S-BSST461 <https://www.ebi.ac.uk/biostudies/studies/S-BSST461>`_ and can be downloaded from there.

Performing the validation on your local installation
----------------------------------------------------

All the validation figures can be re-generated on your local install by running the following code:

.. code-block:: python
	
	from cellocity import validation
	from pathlib import Path
	
	inpath = Path("path/to/S-BSST641/")
	outpath = Path("path/to/output/folder")
	
	validation.run_base_validation(inpath, outpath)
	
Alternatively the validation code can be run as a script found in /tests:

.. code-block::

	>>python run_base_validation.py -i "path/to/S-BSST641/" -o "path/to/output/folder"
   

After some time you should have generated the 3 figures below in this chapter in your chosen output folder. To test the 5-sgigma analysis run the following code:

.. code-block:: python
	
	from cellocity import validation
	from pathlib import Path
	
	inpath = Path("path/to/S-BSST641/")
	outpath = Path("path/to/output/folder")
	
	validation.run_5sigma_validation(inpath, outpath)


Alternatively the validation code can be run as a script found in /tests:

.. code-block::

	>>python run_5sigma_validation.py -i "path/to/S-BSST641/" -o "path/to/output/folder"
   

First we'll start by looking at the base validation.

Process time
------------

.. figure:: _static/process_time_compare.png
    :align: left
    :alt: Figure comparing processing time Optical Flow vs PIV
    
    Figure showing violin plots of processing times for individual files in the test dataset. Process time is in seconds and denotes time to run either the ``OpenPivAnalyzer`` or the ``FarenbackAnalyzer`` on both a ``Channel`` and a ``MedianChannel`` object created from each file in the dataset. Each file is a 10x1608x1608 16-bit array.

Optical Flow is clearly faster to process all files by a factor of ~3-4X. Now, let's compare overall accuracy.
Since the dataset was created by translating a high precision stage on a well calibrated microscope, we know that the speed of the apparent flow is dependent on the translation distance.
In our case we translated the stage 1 :math:`{\mu m}` between images, and if we set the frame interval to 1 second, then the speed should be 1 :math:`{\mu m/s}` for the X and Y translation
and :math:`\sqrt{2} = 1.42` :math:`{\mu m/s}` for the X+Y translation.

Analysis of flow speeds
-----------------------

.. figure:: _static/avg_speed_compare.png
    :align: left
    :alt: Figure comparing average speed calculated from Optical Flow vs PIV
    
    Figure showing box plots of average speeds for each frame for each file in the test dataset. y-axis denotes the speed in :math:`{\mu m/s}`, as read out by the ``.calculateAverageSpeeds()`` method of ``FlowSpeedAnalyser``. 

Both ``Analyzers`` produce results close to the expected, but the ``OpenPivAnalyzer`` has a tendency to underestimate the speed and has greater variance.

Cell monolayers grown on loose hydrogel support, as those used in our validation dataset here, are seldom completely planar and portions are often out of focus during imaging. This phenomenon has also been captured in the analysis. If we draw a visualization of the flow generated superimposed on the background ``Channel``, we can study this phenomenon in more detail.

Qualitative vector field comparison
-----------------------------------

.. figure:: _static/40X_vector_panels_compare.png
    :align: left
    :alt: Figure comparing vector visualization from Optical Flow vs PIV
    

    Figure showing flow vector visualization of a 600x600 crop from the bottom right corner of the final frame from the 40X magnification files in the dataset. Images were generated using the ``.draw_all_flow_frames_superimposed()`` method common to all ``FlowAnalysis`` objects. Horizontal scale bar denotes a flow of 1 :math:`{\mu m/s}` .

Studying the above figure allows us to get a deeper understanding of why optical flow and PIV differ. Note that the area in the bottom right corner is not properly focused. This causes the PIV algorithm problems in accurately determining the flow, as illustrated by the inhomogeneities in the vector field.
This error can be quantified by calculating the alignment index, a measurement on how well each component vector aligns with the average flow. In our test dataset the flow should be close to completely uniform, giving an expected alignment index of 1.0.

Quantitative vector field comparison
------------------------------------

.. figure:: _static/alignment_index_compare.png
    :align: left
    :alt: Figure comparing average frame alignment index from Optical Flow vs PIV
    
    Figure showing box plots of average alignment indexes for each frame for each file in the test dataset. y-axis denotes the Alignment Index (dimensionless), as read out by the ``.getAvgAlignIdxs()`` method of ``AlignmentIndexAnalysis``.

Quantifying how well the vector field is aligned allows us to confirm our intital observation that PIV analysis does produce more variability in the direction of the flow vectors. Optical Flow generates alignment indexes very close to the expected value of 1.0, even after temporal median filtering.    

.. figure:: _static/iop_compare.png
    :align: left
    :alt: Figure comparing the average frame instantaneous order parameter from Optical Flow vs PIV
    
    Figure showing box plots of average instantaneous order parameters (iop) for each frame for each file in the test dataset. y-axis denotes the iop (dimensionless), as read out by the ``.getIops()`` method of ``IopAnalysis``.

The instantaneous order parameter is a measure of how ordered a vector field is, 0 represents a completely random field and 1 represents a comletely homogenous field, where all vectors have the same direction and magnitude. The expected value for the test data set is 1. 

.. figure:: _static/60X_diagonal_compare.gif
    :align: left
    :alt: Figure comparing vector visualization from Optical Flow vs PIV
    

    Figure showing flow vector visualization of the diagonal translation at 60X magnification. Images were generated using the ``.draw_all_flow_frames_superimposed()`` method common to all ``FlowAnalysis`` objects, ``OpenPivAnalyzer`` (left) and ``FarenbackAnalyzer`` (right). Horizontal scale bar denotes a flow of 1 :math:`{\mu m/s}` .


Lastly, let's have a look at the 5-:math:`{\sigma}` correlation length analysis. 5-:math:`{\sigma}` correlation length is a way to measure the correlation length in large vector fields. The algorithm finds the average distance at which the direction of velocities are no longer significantly different at a level of 5 standard deviations (:math:`{\sigma}`). The algorithm was originally presented and utilized in [#Laang2018]_. A more detailed description can be found in the :doc:`developer`.

.. figure:: _static/5sigma_lcorr_compare.png
    :align: left
    :alt: Figure comparing how well the calculated 5-sigma correlation lengths agree with the theoretical between Optical Flow and PIV data.

    Figure showing box plots of how well the calculated 5-:math:`{\sigma}` correlation lengths agree with the theoretical maximum value. The value is expressed as a fraction of the calculated correlation length and the theoretical maximum value, which is given by the magnification. Figure generated by passing either ``OpenPivAnalyzer`` (right) or ``FarenbackAnalyzer`` (left) objects to ``FiveSigmaAnalysis``  and calling the ``calculateCorrelationAllFrames()`` metod with (orange) and without (blue) temporal median filtering of raw input data.

Once again we see an advantage in utilizing optical flow when compared to PIV. In the figure above the calculated correlation lengths for each file and frame are divided by the size of the field of view (FOV), giving us a metric to compare across magnifications. Optical flow captures almost all of the "true" correlation length, while PIV is only able to capture ~80-85% of the "true" correlation length. Besides being less accurate on this type of data, PIV analysis also downsamples the images, which gives the ``FiveSigmaAnalysis`` fewer vectors to use as a basis for correlation length calculations. This is also evident in the average frame processing time (below).

.. figure:: _static/5sigma_process_time_compare.png
    :align: left
    :alt: Figure comparing average frame 5-sigma correlation length calculation time between Optical Flow and PIV data.
    

    Figure showing a box plot of processing times for individual frames in the test dataset. Process time is in seconds and denotes time to run the ``FiveSigmaAnalysis`` on one frame of input data on either ``FarenbackAnalyzer`` data (left) or ``OpenPivAnalyzer`` data (right).

Here we see an advantage in using PIV because processing times are orders of magnitude lower for the PIV data. The complexity of the 5-:math:`{\sigma}` correlation length analysis algorithm is :math:`O(n)`, meaning processing time grows liearly with input size. It is possible to reduce the processing time of optical flow data by tweaking the ``r_step`` parameter of the ``._get_all_angles()`` metod of ``FiveSigmaAnalysis``. The default value is 1, which means that the comparison is growing outwards by 1 pixel per step, but a value of 2 would halve the number of comparisons calculated with little expected effect on the final result.

In conclusion
-------------

Optical Flow and PIV analysis of transmitted light microscopy time-lapse data is commonly used in studies of confluent cell layer dynamics phenomena, for example collective cell migration and wound healing.
This is particularly relevant for studies of primary cells, due to the difficulty in reliably labelling these for cell tracking.
To our knowledge, there has not been a systematic evaluation of different pre-processing modalities and optical flow analysis algorithms on actual real-world, non-simulated, microscopy data. We therefore anticipate that others will find this software package and the validation dataset described in this chapter useful.


References
----------

..  [#vig] Dhruv K. Vig, Alex E. Hamby and Charles W. Wolgemuth. On the Quantification of Cellular Velocity Fields. *Biophysical Journal*, 110:1469-1475, 2016. `doi:10.1016/j.bpj.2016.02.032. <https://doi.org/10.1016/j.bpj.2016.02.032>`_

.. [#Laang2018] Emma Lång, Anna Połeć, Anna Lång, Marijke Valk, Pernille Blicher, Alexander D. Rowe, Kim A. Tønseth, Catherine J. Jackson, Tor P. Utheim, Liesbeth M. C. Janssen, Jens Eriksson and Stig Ove Bøe. Coordinated collective migration and asymmetric cell division in confluent human keratinocytes without wounding. *Nature communications*, 1:2041-1723, 2018. `doi:10.1038/s41467-018-05578-7. <https://doi.org/10.1038/s41467-018-05578-7>`_  

Cellocity Tutorial
==================

Step-by-step guide
------------------

This tutorial will show you how to:

1. Load a file and create a :class:`cellocity.channel.Channel` object. 
2. Preprocess the ``Channel`` object.
3. Prepare for analysis by creating an :class:`cellocity.analysis.Analyzer` object from the ``Channel`` object.
4. Extract data by creating an :class:`cellocity.analysis.Analysis` object.

Load a file and create a ``Channel`` object
+++++++++++++++++++++++++++++++++++++++++++
 .. code-block:: python
    
    from cellocity.channel import Channel
    import tifffile
    
    my_filename = "2_channel_micromanager_timelapse.ome.tif"
    chToAnalyze = 0  # 0-based indexing of channels
    
    #safely load file
    with tifffile.TiffFile(my_filename, multifile=False) as tif:
    
        #strips ome.tif from filename
        label = my_filename.split(".")[0]
        channelName = label + "_Ch" + str(chToAnalyze + 1)
        channel_0 = Channel(chToAnalyze, tif, name=channelName)

 .. warning::

    Cellocity assumes that it can hold all Channel data in RAM.
    
    A ``Tifffile`` does not load all its image data into RAM when created, however
    upon accessing data during ``Channel`` creation some of it will be cached, thus
    increasing its size somewhat. ``Channel`` objects store all image data in RAM and
    can get quite hefty for long time lapses.

Preprocess ``Channel`` object
+++++++++++++++++++++++++++++
First, we will check if the frame interval stated in the metadata is in agreement with
the time stamps of the individual frames in the channel (within 1%). This is done with the
``Channel.doFrameIntervalSanityCheck(maxDiff=0.01)`` method. If there is an discrepancy between
the actual frame intervals and the intended, if can be fixed by calling the 
``Channel.fixFrameInterval()`` method, which overwrites the intended frame interval with the actual
average frame interval.

  .. code-block:: python

	if not channel_0.doFrameIntervalSanityCheck():
		channel_0.fixFrameInterval()

  .. note::
	Checking and fixing the frame interval is currently only possible on MicroManager ome.tif files. Individual frame timestamps are lost when saving .tif files in ImageJ.

``Channel`` objects have convenient preprocessing methods, such as trimming frames
and temporal median filtering. Let's start by trimming our newly created channel to
frames 10-60, meaning we discard frames 0-9 and from frame 60 onward to the end.

 .. code-block:: python
	
	#Trim channel to include frame 10-59
	channel_0.trim(10,60)

Now let's employ a temporal median filter, meaning we do a median filtering over time.
This will have the effect of filtering out fast moving free-floating debris, thus 
greatly reducing the noise in the final analysis. This is done by creating a child :class:`cellocity.channel.MedianChannel`
object. Median filtering can be done with a gliding window (default), or by binning the frames.
``MedianChannel`` takes care of properly recalculating frame intervals in either case. The default 
frame sampling interval is 3.

.. code-block:: python
	
	from cellocity.channel import MedianChannel
	
	gliding_median_channel_0 = MedianChannel(channel_0)
	
	binned_4frame_median_channel_0 = MedianChannel(channel_0,
							doGlidingProjection=False,
							frameSamplingInterval=4)


``MedianChannel`` objects can also be created by calling the ``.getTemporalMedianChannel()`` method on a ``Channel``.
The following code gives identical results to the above example:

.. code-block:: python
	
	arguments ={doGlidingProjection = True,
			frameSamplingInterval=3,
			startFrame=0,
			stopFrame=None
			}
	gliding_median_channel_0 = channel_0.getTemporalMedianChannel(arguments)
		
	arguments = {doGlidingProjection = False,
			frameSamplingInterval=4,
			startFrame=0,
			stopFrame=None}
	binned_4frame_median_channel_0 = channel_0.getTemporalMedianChannel(arguments)

Prepare for Analysis by creating an ``Analyzer`` object
+++++++++++++++++++++++++++++++++++++++++++++++++++++++

Now let's perform an optical flow analysis of our preprocessed ``Channel``. This is done
by instantiating an ``Analyzer`` object with a ``Channel`` as argument. In this case we
will perform an optical flow analysis using the Farenback flow analysis from OpenCV. This
is handled by a ``FarenbackAnalyzer``, which is a specific subtype ``FlowAnalyzer`` of ``Analyzer``.

``FarenbackAnalyzer`` takes two arguments, one ``Channel`` and one **unit**. **unit** is a string
indicating the unit that we want the output to be in. Currently only "um/s", "um/min", and "um/h" are
implemented. Cellocity handles all unit conversions automatically in the background.


.. code-block:: python

	from cellocity.analysis import FarenbackAnalyzer
	
	fb_analyzer_ch0 = FarenbackAnalyzer(channel = gliding_median_channel_0, unit = "um/h")
	fb_analyzer_ch0.doFarenbackFlow()

.. note::
  Quite a lot of effort has gone in to selecting sensible default parameters that work well for microscopy data for the ``FlowAnalyzer`` objects ``FarenbackAnalyzer`` and ``OpenPivAnalyzer``, as is demonstrated in the :doc:`validation` section. 


Extract data by creating an ``Analysis`` object.
++++++++++++++++++++++++++++++++++++++++++++++++

Great, now we have calculated the optical flow of channel_0 with the default parameters. Now its
time to extract data. This is done by creating ``Analysis`` objects. In our case we want to analyse
the flow speeds of our channel. To do this we can utilize the ``FlowSpeedAnalysis`` class, which works on
``FlowAnalyzer`` objects.

.. code-block:: python
	
	from cellocity.analysis import FlowSpeedAnalysis
	
	speed_analysis_ch0 = FlowSpeedAnalysis(fb_analyzer_ch0)
	speed_analysis_ch0.calculateSpeeds()
	speed_analysis_ch0.calculateAverageSpeeds()

When speeds have been calculated the results can be stored either as a 32-bit tif, where pixel values represent
flow speeds in the location of the pixel, or the average speed of each frame can be saved as a .csv file for further
processing.

.. code-block:: python

	from pathlib import Path
	
	savepath = Path("path/to/save/folder")
	
	speed_analysis_ch0.saveArrayAsTif(outdir=savepath):
	speed_analysis_ch0.saveCSV(outdir=savepath, fname="mySpeeds.csv", tunit="s")

That's it! If you want more detailed information, please check the :doc:`api` , the :doc:`validation` contains more examples of different ``Analysis`` objects in use, and the :doc:`developer` contains information on how to submit a bug report.
	
	



.. Cellocity documentation master file, created by
   sphinx-quickstart on Thu Mar 12 14:03:28 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to Cellocity's documentation!
=====================================

.. toctree::
   :maxdepth: 3
   :caption: Contents:

   introduction
   tutorial
   validation
   developer
   api

Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`
Introduction to Cellocity
=========================

A 30 second pitch
-----------------

Cellocity is a bioimage analysis tool for quantifying confluent cell layer dynamics. The main advantages of Cellocity is its ability to work on unlabeled Brightfield time lapse microscopy data, and to both quantify and visualize abstract optical flow analyses to the user.

.. figure:: _static/spinning_logo.gif
    :align: left
    :alt: Example output
    
    Figure showing simulated raw data (left), a vector field visualization (center), and a heat map encoding speeds (right).

Installing Cellocity
--------------------

Cellocity is available on the Python package index and the latest release can be installed using pip::
	
    pip install cellocity


You can also clone the Github repository if you are interested in getting the current development version of Cellocity::

    git clone https://github.com/Oftatkofta/cellocity.git cellocity
    cd cellocity
    pip install -e .

Cellocity requires Python (>3.7), tifffile (2020.5.5), python-OpenCV (4.2.0.34), OpenPIV (0.21.3), Numpy (1.18.4), Pandas (1.0.3) to function correctly. Additionally, you need Matplotlib (3.2.1) and Seaborn (0.10.1) in order to visualize the validation output. If you perform a pip install from PyPi, all dependencies will be installed automatically.

Citing Cellocity
----------------

If you have found Cellocity useful in your project and want to cite it, you can use our JOSS publication [![DOI](https://joss.theoj.org/papers/10.21105/joss.02818/status.svg)](https://doi.org/10.21105/joss.02818)


Cellocity development history
-----------------------------

Cellocity has been developed over multiple years and several projects. The nucleus was developed in `Stig Ove Bøe's <https://ous-research.no/home/boe/Group+members/10831>`_ research group at Oslo University Hospital and at the `Nanoscopy Gaustad <https://www.med.uio.no/english/research/core-facilities/advanced-light-microscopy-gaustad/>`_ imaging core facility at the University of Oslo. Many of Cellocity's core algorithm implementations and methods, such as the 5-sigma correlation length analysis, were presented in a `Nature Communications <https://www.nature.com/articles/s41467-018-05578-7>`_ publication in 2018 :cite:`Laang2018`.

The framework is currently being used and further developed as the analysis backbone for studies of microbial interactions with the gut epithelium in the `Sellin Laboratory <https://www.imbim.uu.se/research-groups/infection-and-immunity/sellin-mikael/>`_ at Uppsala University.


Cellocity backbone
------------------

Cellocity is built on top of  Christoph Gohlke's `Tifffile library <https://pypi.org/project/tifffile/>`_ and uses the ``Tifffile`` object to read input and write output files. Cellocity also relies heavily on `OpenCV <https://opencv.org/>`_ :cite:`Bradski2000` and `OpenPIV <http://www.openpiv.net/>`_ :cite:`Taylor2010` for optical flow analysis and output visualizations. `NumPy <https://numpy.org/>`_ :cite:`vanderWalt2011` is used internally for image data manipulation in the form of ``numpy.ndarrays``, and `matplotlib <https://matplotlib.org/>`_ is used to generate output plots :cite:`Hunter2007`.

Cellocity architecture
----------------------
The core element in Cellocity is the ``Channel`` object, which represents one Z-plane of one time lapse image channel. ``Channel`` objects also handle image pre-processing, such as temporal or spatial median filtering. ``Channel`` objects are given as input to ``Analyzer`` objects, which perform specific analyses on the data. ``Analyzer`` objects can then, in turn, be given to ``Analysis`` objects, which take care of performing further analyses, such as calculating the alignment index, instantaneous order parameter (:math:`{\psi}`), and correlation length.

.. figure:: _static/cellocity_architecture.png
    :align: left
    :alt: Overview of Cellocity architecture
    
    Figure showing the overall object architecture of Cellocity.


Examples of algorithms and vector field quantifications implemented
-------------------------------------------------------------------
Instantaneous Order Parameter (:math:`{\psi}`)
   :math:`{\psi}` = 1 corresponds to a perfectly uniform velocity field, where all the cells move in the same direction and with the same speed, while :math:`{\psi}` :math:`{\approx}` 0 is expected for a randomly oriented velocity field. See :cite:`Malinverno2017` for details.

Alignment Index
  The Alignment Index describes how well each vector in a vector field aligns with the average velocity vector.
  See :cite:`Malinverno2017` for further details.

5-:math:`{\sigma}` correlation length
  5-:math:`{\sigma}` correlation length is a way to measure the correlation length in large vector fields. It finds the average distance at which the direction of velocities are no longer significantly different at a level of 5 standard deviations (:math:`{\sigma}`). The algorithm was originally presented and utilized in :cite:`Laang2018`. A more detailed description can be found in the :doc:`developer`.



Examples
--------

Simple file loading example::

    from cellocity.channel import Channel
    from tifffile import Tiffile
    
    tif = Tifffile(myFile)
    channel_1 = Channel(0, tif, "channel name") #0-indexed channels, meaning ch1 in ImageJ

Simple pre-processing example::
    
    from cellocity.channel import MedianChannel
    
    #Trim Channel to frame 2-40
    channel_1.trim(2, 41)
    #3-frame gliding temporal median projection by default
    channel_1_median = MedianChannel(channel_1)

Simple optical flow calculation example::
    
    from cellocity.analysis import FarenbackAnalyzer
    
    flow_Ch1 = FarenbackAnalyzer(channel_1_median, "um/min")
    flow_Ch1.doFarenbackFlow()

Simple analysis data readout example::

    from cellocity.analysis import FlowSpeedAnalysis
	
	speed_analysis_Ch1 = FlowSpeedAnalysis(flow_Ch1)
	speed_analysis_Ch1.calculateAverageSpeeds()
	speed_analysis_Ch1.saveCVS("/path/to/savefolder")

For more detailed examples please check out the tutorial section.


Support
-------

If something is unclear or if you are in need of support, please contact the developer by creating a new `support issue <https://github.com/Oftatkofta/cellocity/issues>`_.

References
----------
.. bibliography:: ../paper.bib
   :style: plain
   :cited:

The Cellocity API Reference
===========================

.. automodule:: cellocity 
   :members:

The channel module
-------------------

.. automodule:: cellocity.channel 
   :members: 

The analysis module
--------------------

.. automodule:: cellocity.analysis 
   :members: 

The validation module
----------------------

.. automodule:: cellocity.validation 
   :members: 
