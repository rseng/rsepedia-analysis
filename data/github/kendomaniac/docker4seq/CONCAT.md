---
title: " Supplementary data SeqBox: RNAseq/ChIPseq reproducible analysis on a consumer game computer"
author: "Marco Beccuti, Francesca Cordero, Maddalena Arigoni, Riccardo Panero, Susanna Donatelli and Raffaele A Calogero"
date: "7/14/2017"
output: pdf_document
toc: true
fig_caption: true
---



## Introduction
The docker4seq package was developed to facilitate the use of computing demanding applications in the field of NGS data analysis.

The docker4seq package uses [docker](https://www.docker.com/what-docker) [containers](https://www.docker.com/what-container) that embed demanding computing tasks, e.g. short reads mapping. 

This approach provides multiple advantages: 

- user does not need to install all the software on its local server

- results generated by different containers can be organized in pipelines

- reproducible research is guarantee by the possibility of sharing the docker containers used for the analysis 

## Requirements
The minimal hardware requirements are a 4 core 64 bits linux computer, 32 Gb RAM, one SSD 250GB, with a folder with read/write permission for any users (chmod 777), and [docker](https://www.docker.com/) installed.

[**docker4seq**](https://github.com/kendomaniac/docker4seq) and its graphical interface [**4SeqGUI**](https://github.com/mbeccuti/4SeqGUI) can fit ideally in the [NUC6I7KYK, Intel mini-computer](https://www.intel.com/content/www/us/en/products/boards-kits/nuc/kits/nuc6i7kyk.html) equipped with Kingston Technology HyperX Impact 32GB Kit (2x16GB), 2133MHz DDR4 CL13 260-Pin SODIMM and Samsung 850 EVO - 250GB - M.2 SATA III Internal SSD.


**MANDATORY:** The first time *docker4seq* is installed the **downloadContainers** function needs to be executed to download in the local repository the docker containers that are needed by *docker4seq*.


```r
library(docker4seq)
downloadContainers(group="docker")
```


## Dockers containers

At the present time all functions requiring some sort of calculation are embedded in the following docker containers:

- docker.io/rcaloger/annotate.2017.01 used by rnaseqCounts, rsemanno 

- docker.io/rcaloger/bwa.2017.01 used by bwaIndexUcsc, bwa 

- docker.io/rcaloger/chipseq.2017.01 used by chipseqCounts, chipseq

- docker.io/rcaloger/r332.2017.01 used by experimentPower, sampleSize, wrapperDeseq2

- docker.io/rcaloger/mirnaseq.2017.01 used by mirnaCounts

- docker.io/rcaloger/rsemstar.2017.01 used by rnaseqCounts, rsemstarIndex, rsemstarUscsIndex

- docker.io/rcaloger/skewer.2017.01 used by skewer

### docker container nomenclature

In case of updates required to solve bugs, which do not affect the calculation docker.io/rcaloger/XXXXX.YYYY.ZZ the fiels ZZ will be updated.

In case of updates which affect the calculation, e.g. new release of Bioconductor libraries, the field YYYY will be updated. Previous versions will be maintained to allow reproducibility.

### Reproducibility

Within any folder generated with docker4seq functions it is saved the file **containers.txt**, which indicates the containers available in the local release of docker4seq.

In case, user would like to download a set of dockers containers different from those provided as part of the package those needs to be described in a file with the following format, **docker.repository/user/docker.name** which is passed to downloadContainers:


```r
downloadContainers(group="docker", containers.file="my_containers.txt")
#an example of the my_containers.txt file content
docker.io/rcaloger/bwa.2017.01
docker.io/rcaloger/chipseq.2017.01
docker.io/rcaloger/r340.2017.01
```








## Available workflows
At the present time are available the following workflows:

- **mRNAseq**, which allows:
    + adapter trimming with [skewer](https://github.com/relipmoc/skewer)
    + mapping with [STAR](https://github.com/alexdobin/STAR)
    + counting genes and isoforms with [RSEM](http://deweylab.github.io/RSEM/)
    + ENSEMBL gene annotation.
    + organizing the output of RSEM in tables to be used for differential expression analysis
    + visualizing experiment data with PCA
    + evaluating experiment power and sample size
    + detecting differentially expressed genes/isoforms
- **miRNAseq**, which executes the workflow described in Cordero et al. PLoS One. 2012;7(2):e31630, embedding the following steps:
    + trimming adapters with [cutadapt](http://cutadapt.readthedocs.io/en/stable/guide.html)
    + miRNAs mapping on [mirbase](http://www.mirbase.org/) hairpins using [SHRiMP](http://compbio.cs.toronto.edu/shrimp/)
    + quantification of mature miRNAs.
    + visualizing experiment data with PCA
    + evaluating experiment power and sample size
    + detecting differentially expressed miRNAs
- **ChIPseq**, which allows:
    + adapter trimming with [skewer](https://github.com/relipmoc/skewer)
    + mapping with [BWA](http://bio-bwa.sourceforge.net/bwa.shtml)
    + peak calling using either MACS v 1.4 or SICER v 1.1
    + associating peaks to the nearest gene, UCSC annotation
    + full annotation of the nearest gene


The most computing expensive steps of the analyses are embedded in the following docker4seq functions: **rnaseqCounts**, **mirnaCounts**, **chipseqCounts**. These functions are also the only one that have RAM and computing power requirements not usually available in consumer computers. Below its shown the time required to run the above three functions increasing the number of sequenced reads.

### rnaseqCounts performances on different hardware configurations

The conversion between fastq files to counts is the most time consuming step in RNAseq data analysis and it normally requires high-end server. We tested **rnaseqCounts** on different hardware:

    + SeqBox: NUC6I7KYK CPU i7-6770HQ 3.5 GHz (1 core, 8 threads), 32 Gb RAM, HD 250 Gb SSD
    + SGI UV200 server: CPU E5-4650 v2 2.40GHz (8 cores, 160 threads), 1 Tb RAM, RAID 6, 100 Tb SATA


We run respctively 26, 52, 78, and 105 million reads increasing the number of threads till reaching the limit of the hardware or up to 64 threads, i.e. vaules shown in parenthesis in next figure. It is notable that SeqBox, mapping in 5 hours more than 100 milion reads, is able to handle can handle, in 20 hours, the throughput of the Illumina benchtop sequencer NextSeq 500, which produces up to 400 milion reads in a 30 hours run.
    
![rnaseqCounts overall performance](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/mrna_performace.jpg)


### mirnaCounts performances on different hardware configurations

We run resepctively 3, 6, 12, and 24 miRNA samples in parallel using **mirnaCounts**, increasing the number of threads till reaching the limit of the hardware or 24 threads, i.e. vaules shown in parenthesis in next figure.
    
![mirnaCounts overall performance](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/mirna_performace.jpg) 



### chipseqCounts performances on different hardware configurations

We run resepctively 37, 70, 111, and 149 million reads increasing the number of threads till reaching the limit of the hardware or up to 64 threads, i.e. vaules shown in parenthesis in next figure.
    
![chipseqCounts overall performance](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/chipseq_performance.jpg) 



From the point of view of parallelization the **rnaseqCounts** is the one that embeds the most parallelized tools: i) mapping with STAR and ii) quantifying transcripts with RSEM. Both these tools have a massive I/O requirement. On the basis of the results shown above parallelization does not improve very much the overall performaces, but compensate the poor I/O of the RAID based on SATA disk array. On the other side the presence of an SSD with very high I/O compensate in the limited amount of cores of SeqBox.

In the case of **mirnaCounts** and **chipseqCounts** the parallelization is very little and it is only available for the reads mapping procedure. On the otherside both functions have a massive I/O. The reduced parallelization of these two analyses combined with the higher I/O of the SSD with respect to the SATA array makes SeqBox extremely effective even with very high number of reads to be processed.

## RNAseq workflow: Howto

The mRNAseq workflow can be run using **4SeqGUI** graphical interface (linux/MAC):

![mRNAseq workflow](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/rnaseq1.jpeg)

Sample quantification is made of these steps:

- Creating a genome index for STAR (see end of this paragraph)

- Running removing sequencing adapters

- Mapping reads to the reference genome

- Quantify gene and transcript expression level

- Annotating genes.

All the parameters can be setup using 4SeqGUI

### Creating a STAR index file for mRNAseq:

The index can be easily created using the graphical interface:

![Creating a STAR genome index](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/rnaseq2.jpeg)

A detailed description of the parameters is given below.

#### Creating a STAR index file by line command

\fontsize{8}{8}\selectfont

```r
rsemstarIndex(group="docker",genome.folder="/data/scratch/hg38star",
ensembl.urlgenome="ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz",
ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.gtf.gz")
```

In brief, **rsemstarIndex** uses ENSEMBL genomic data. User has to provide the URL (**ensembl.urlgenome**) for the file XXXXX_dna.toplevel.fa.gz related to the organism of interest, the URL (**ensembl.urlgtf**) for the annotation GTF XXX.gtf.gz and the path to the folder where the index will be generated (**genome.folder**). The parameter **threads** indicate the number of cores dedicated to this task.


### Quantifying genes/isoforms:

![Gene, Isoform counting](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/rnaseq3.jpeg)

A detailed description of the parameters is given below.

#### Sample quantification by line command

The sample quantification can be also executed using R and it is completely embedded in a single function:


```r
#test example
system("wget http://130.192.119.59/public/test.mrnaCounts.zip")
unzip("test.mrnaCounts.zip")
setwd("./test.mrnaCounts")
library(docker4seq)
rnaseqCounts(group="docker",fastq.folder=getwd(), scratch.folder=getwd(),
adapter5="AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT",
adapter3="AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT",
seq.type="se", threads=8,  min.length=40,
genome.folder="/data/scratch/mm10star", strandness="none", save.bam=FALSE,
org="mm10", annotation.type="gtfENSEMBL")
```


User needs to create the **fastq.folder**, where the fastq.gz file(s) for the sample under analysis are located. 
The **scratch.folder** is the location where temporary data are created. The results will be then saved in the **fastq.folder**.

User needs to provide also the sequence of the sequencing adapters, **adapter5** and **adapter3** parameters. In case Illumina platform is used the adapters sequences can be easily recovered [**here**](https://support.illumina.com/content/dam/illumina-support/documents/documentation/chemistry_documentation/experiment-design/illumina-adapter-sequences_1000000002694-01.pdf). 

**seq.type** indicates if single end (se) or pair-end (pe) data are provided, **threads** indicates the max number of cores used by *skewer* and *STAR*, all the other steps are done on a single core.

The **min.length** refers to the minimal length that a reads should have after adapters trimming. Since today the average read length for a RNAseq experiment is 50 or 75 nts would be better to bring to 40 nts the min.length parameter to increase the precision in assigning the correct position on the genome.

The **genome.folder** parameter refers to the location of the genomic index generated by STAR using the *docker4seq* function **rsemstarIndex**.
The generation of the genome index is very simple and it is highlited at the end of this paragraph.

**strandness**, is a parameter referring to the kit used for the library prep. If the kit does not provide strand information it is set to "none", if provides strand information is set to "forward" for  Illumina stranded kit and it set to "reverse" for Illumina ACCESS kit. **save.bam** set to TRUE indicates that genomic bam file and transcriotomic bam files are also saved at the end of the analysis. **annotation.type** refers to the type of available gene-level annotation. At the present time is only available ENSEMBL annotation defined by the gtf downloaded during the creation of the indexed genome files, see paragraph *at the end*Creating a STAR index file for mRNAseq*.


### Sample quantification output files

The mRNAseq workflow produces the following output files: 

    + XXXXX-trimmed.log, containing the information related to the adapters trimming
    + gtf_annotated_genes.results, the output of RSEM gene quantification with gene-level annotation
    + Log.final.out, the statistics of the genome mapping generated by STAR  
    + rsem.info, summary of the parameters used in the run
    + genes.results, the output of RSEM gene quantification
    + isoforms.results, the output of RSEM isoform quantification
    + run.info, some statistics on the run
    + skewerd_xxxxxxxxxxxx.log, log of the skewer docker container
    + stard.yyyyyyyyyyyy.log, log of the star docker container

![gtf_annotated_genes.results](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/rnaseq7.jpeg)

The first column in **gtf_annotated_genes.results** is the ensembl gene id, the second is the [biotype](http://www.ensembl.org/Help/Faq?id=468), 
the 3rd is the annotation source, the 4th contains the set of transcripts included in the ensembl gene id. Then there is the length of the gene, the lenght of the gene to which is subtracted the average length of the sequenced fragments, the expected counts are the couts to be used for differentiual expression analysis. [TPM](https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) and [FPM](https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) are normalized gene quantities to be used only for visualization purposes.

### From samples to experiment

The RSEM output is sample specific, thus it is necessary to assemble the single sample in an experiment table including in the header of the column both the covariates and the batch, if any.
The header sample name is separated by the covariate with an underscore, e.g. mysample1\_Cov1, mysample2\_Cov2. 

![counts table with covariates](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/counts1.jpeg)


In case also a batch is present also this is separated by a further underscore, e.g. mysample1\_Cov1\_batch1, mysample2\_Cov\_batch2.

![counts table with covariates and batch](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/counts2.jpeg)

The addition of the covariates to the various samples can be done using the **4seqGUI** using the button: *From samples to experiment*.
Covariates are added to the column name, i.e. sample name, using \_, e.g. mysample\_Cov.1. Batches are added after covariates with \_, e.g. mysample\_Cov.1_batch.1.

![generating a table with covariates](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/counts3.jpeg)

#### From samples to experiments by line command


```r
#test example
system("wget http://130.192.119.59/public/test.samples2experiment.zip")
unzip("test.samples2experiment.zip")
setwd("test.samples2experiment")
library(docker4seq)
sample2experiment(sample.folders=c("./e1g","./e2g","./e3g",
"./p1g", "./p2g", "./p3g"),
covariates=c("Cov.1","Cov.1","Cov.1","Cov.2","Cov.2","Cov.2"),
bio.type="protein_coding", output.prefix=".")
```

User needs to provide the paths of the samples, **sample.folder** parameter, a vector of the covariates, **covariates**, and the biotype(s) of interest, **bio.type** parameter. The parameter **output.prefix** refers to the path where the output will be created, as default this is the actual R working folder.

#### From samples to experiments output files

The samples to experiments produces the following output files: 

    + _counts.txt: gene-level raw counts table for differential expression analysis
    + _isoforms_counts.txt: isoform-level raw counts table for differential expression analysis
    + _isoforms_log2TPM.txt: isoform-level log2TPM for visualization purposes
    + _log2TPM.txt: gene-level log2TPM for visualization purposes
    + _isoforms_log2FPKM.txt: isoform-level log2FPKM for visualization purposes
    + _log2FPKM.txt: gene-level log2FPKM for visualization purposes
    + XXXXX.Rout: logs of the execution



### Visualizing experiment data with PCA

[PCA](https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/) finds the principal components of data. Principal components are the underlying structure in the data. They are the directions where there is the most variance, the directions where the data is most spread out.
**4SeqGUI** provides an interface to the generation experiment samples PCA

![PCA](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/pca1.jpeg)

The plot is saved in **pca.pdf** in the selected folder.

#### PCA by line command


```r
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
pca(experiment.table="_log2FPKM.txt", type="FPKM", legend.position="topleft", covariatesInNames=FALSE, principal.components=c(1,2), pdf = TRUE, output.folder=getwd())
```

User needs to provide the paths of experiment table, **experiment.table** parameter, i.e. the file generated using the samples2experiment function. The **type** parameter indicates if FPKM, TPM or counts are used for the PCA geenration. The parameter **legend.position** defines where to locate the covariates legend. The parameter **covariatesInNames** indicates if the header of the experiment table contains or not covariate information. The parameter **principal.components** indicates which principal components should be plotted. **output.folder** indicates where to save the pca.pdf file.

![pca.pdf](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/pca2.jpeg)

The values in parentesis on x and y axes are the amount of variance explained by each principal component.

IMPORTANT: The above analysis is suitable also for miRNAseq data

### Evaluating experiment power and sample size

[RnaSeqSampleSize](https://www.ncbi.nlm.nih.gov/pubmed/25246651) Bioconductor package provides the possibility to calculate, from a pilot experiment, the statistical power and to define the optimal sample size.
**4SeqGUI** provides an interface to sample size estimation: 

![sample size estimation](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/ss.jpeg)

and to statistical power estimation:

![stat power estimation](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/es.jpeg)


#### Sample size estimation by line command

Sample size estimation is an important issue in the design of RNA sequencing experiments. We have implemented a wrapper function for sample size estimation using the bioconductor package RnaSeqSampleSize.


```r
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
sampleSize(group="docker", filename="_counts.txt", power=0.80, FDR=0.1, genes4dispersion=200, log2fold.change=1)
```

The requested parameters are the path to the counts experiment table generated by **samples2experiment** function. The param **power** indicates the expecte fraction of differentially expressed gene, e.g 0.80. **FDR** and **log2fold.change**  are the two thresholds used to define the set of differentially expressed genes of interest. 

The output file is **sample_size_evaluation.txt** is saved in the R working folder, below an example of the file content:

![sample_size_evaluation.txt](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/samplesize1.jpeg)

IMPORTANT: The above analysis is suitable also for miRNAseq data


#### Experiment statistical power estimation by line command

Experiment power provides an indication of which is the fraction of differentially expressed genes that can be detected given a specific number of samples and differential expression detection thresholds. We have implemented a wrapper function for experiment power estimation using the bioconductor package RnaSeqSampleSize.


```r
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
experimentPower(group="docker", filename="_counts.txt",replicatesXgroup=7, FDR=0.1, genes4dispersion=200, log2fold.change=1)
```


The requested parameters are the path to the counts experiment table generated by **samples2experiment** function. The param **replicatesXgroup** indicates the number of sample associated to each of the two covariates. **FDR** and **log2fold.change**  are the two thresholds used to define the set of differentially expressed genes of interest. **genes4dispersion** indicates the number of genes used in estimation of read counts and dispersion distribution.

The output file is **power_estimation.txt** is saved in the R working folder, below an example of the file content: 

![power_estimation.txt](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/expp1.jpeg)

IMPORTANT: The above analysis is suitable also for miRNAseq data

### Differential expression analysis with DESeq2

A basic task in the analysis of count data from RNA-seq is the detection of differentially expressed genes.
**4SeqGUI** provides an interface to DESeq2 to simplify differential expression analysis.

![DESeq2](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/de1.jpeg)

The output files are:

**DEfull.txt** containing the full set of results generated by DESeq2

![DEfull.txt](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/de2.jpeg)


**DEfiltered_log2fc_X_fdr_Y.Y.txt** containing the set of differentially expressed genes passing the indicated thresholds

![DEfiltered_log2fc_1_fdr_0.1.txt](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/de3.jpeg)


**genes4david.txt** a file containing only the gene symbols to be used as input for [DAVID](https://david.ncifcrf.gov/) or [ENRICHR](http://amp.pharm.mssm.edu/Enrichr/)

log2normalized_counts.txt, DESeq2 log2 library size normalized counts to be used for visualizaiton only instead of log2 FPKM or log2 TPM.

#### DESeq2 by line command


```r
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
wrapperDeseq2(output.folder=getwd(), group="docker", experiment.table="_counts.txt", log2fc=1, fdr=0.1, ref.covar="Cov.1", type="gene", batch=FALSE)
```


User needs to provide experiment table, **experiment.table** param, i.e. the counts table generated with **samples2experiment** function, the thresholds for the differential expression analysis, **log2fc** and **fdr** params, the reference covariate, **ref.covar** param, i.e. the covariate that is used as reference for differential expression detection, the **type** param, whihc refers to the type of experiment table in use: *gene*, *isoform*, *mirna*, **batch** parameter that indicates, it it is set to **TRUE** that the header of the experiment table also contains the extra information for the batch effect (see above). 

IMPORTANT: the above analysis can be also applied to miRNAseq data.

## miRNAseq workflow 

The miRNAseq workflow can be run using **4SeqGUI** graphical interface:

![miRNAseq workflow](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/mirna1.jpeg)
  
  
The miRNAseq docker container executes the following steps:


![miRNAseq workflow](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/mirna3.jpeg)

The full workflow is described in [Cordero et al. Plos ONE 2012](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0031630). In brief, fastq files are trimmed using [cutadapt](https://github.com/marcelm/cutadapt) and the trimmed reads are mapped on miRNA precursors, i.e. harpin.fa file, from [miRBase](http://www.mirbase.org/ftp.shtml) using [SHRIMP](http://compbio.cs.toronto.edu/shrimp/). Using the location of the mature miRNAs in the precursor, countOverlaps function, from the Bioconductor package GenomicRanges is used to quantify the reads mapping on mature miRNAs. 


All the parameters needed to run the miRNAseq workflow can be setup using 4SeqGUI

![miRNAseq parameters](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/mirna2.jpeg)
 
 
A detailed description of the parameters is given below.

### miRNAseq workflow by line command

The miRNAseq workflow can be also executed using R and it is completely embedded in a unique function:


```r
#test example
system("wget 130.192.119.59/public/test.mirnaCounts.zip")
unzip("test.mirnaCounts.zip")
setwd("test.mirnaCounts")
library(docker4seq)
mirnaCounts(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch", 
            mirbase.id="hsa",download.status=FALSE, adapter.type="NEB", trimmed.fastq=FALSE)
```

User needs to create the **fastq.folder**, where the fastq.gz files for all miRNAs under analysis are located. 
The **scratch.folder** is the location where temporary data are created. The results will be then saved in the **fastq.folder**.
User needs to provide also the identifier of the miRBase organism, e.g. **hsa** for Homo sapiens, **mmu** for Mus musculus.  If the **download.status** is set to FALSE, mirnaCounts uses miRBase release 21, if it is set to TRUE the lastest version of precursor and mature miRNAs will be downloaded from miRBase. Users need to provide the name of the producer of the miRNA library prep kit to identify which adapters need to be provided to cutadapt, **adapter.type** parameter. The available adapters are NEB and Illumina, but, upon request, we can add other adapters. Finally, if the **trimmed.fastq** is set to FALSE the trimmed fastq are not saved at the end of the analysis.


### miRNAseq workflow output files

The miRNAseq workflow produces the following output files: 

    + README: A file describing the content of the data folder
    + all.counts.txt: miRNAs raw counts, to be used for differential expression analysis
    + trimmimg.log: adapters trimming statistics
    + shrimp.log: mapping statistics
    + all.counts.Rda: miRNAs raw counts ready to be loaded in R.
    + analysis.log: logs of the full analysis pipeline
  
  
## Adding covariates and batches to mirnaCounts output: all.counts.txt

The funnction **mirnaCovar** add to the header of all.counts.txt covariates and batches or covariates only.


```r
#test example
system("wget 130.192.119.59/public/test.mirna.analysis.zip")
unzip("test.mirna.analysis.zip")
setwd("test.mirna.analysis")
library(docker4seq)
mirnaCovar(experiment.folder=getwd(),
     covariates=c("Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.1", 
                  "Cov.2", "Cov.2", "Cov.2", "Cov.2", "Cov.2", "Cov.2"),
     batches=c("bath.1", "bath.1", "bath.2", "bath.2", "batch.1", "batch.1", 
               "batch.2", "batch.2","batch.1", "batch.1","bath.2", "bath.2"))
```


## chipseq workflow

The chipseq workflow can be run using **4SeqGUI** graphical interface:

![ChIPseq workflow](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/chipseq0.jpeg)


The ChIPseq is made of two main steps:

- Creating a genome index for BWA (see end of this paragraph)

- Running MACS or SICER analysis

### Creating a BWA index file for Chipseq:


The index can be easily created using the graphical interface:

![Creating a BWA index with Genome indexing BWA](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/chipseq1.jpeg)


```r
bwaIndexUcsc(group="sudo",genome.folder="/sto2/data/scratch/mm10bwa", uscs.urlgenome=
"http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz",
gatk=FALSE)
```

In brief, **bwaIndexUcsc** uses UCSC genomic data. User has to provide the URL (**uscs.urlgenome**) for the file chromFa.tar.gz related to the organism of interest and the path to the folder where the index will be generated (**genome.folder**). The parameter **gatk** has to be set to FALSE because is not used for a genomic index used for ChIPseq.


### Calling peaks and annotating:

All the parameters needed to run MACS or SICER can be setup using 4SeqGUI

![MACS and SICER analysis](/Users/raffaelecalogero/Dropbox/data/docker/stable/docker4seq/inst/img/chipseq3.jpeg)

A detailed description of the parameters is given below.

### Chipseq workflow by line command

The chipseq workflow can be also executed using R and it is completely embedded in a unique function:


```r
system("wget 130.192.119.59/public/test.chipseqCounts.zip")
unzip("test.chipseqCounts.zip")
setwd("test.chipseqCounts")
library(docker4seq)
chipseqCounts(group = "docker", output.folder = "./prdm51.igg",
  mock.folder="./igg", test.folder="./prdm51", scratch.folder=getwd(),
  adapter5 = "AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT",
  adapter3 = "AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT",
  threads = 8, min.length = 30, genome.folder,
  mock.id = "igg", test.id = "tf", genome, read.size = 50,
  tool = "macs", macs.min.mfold = 10, macs.max.mfold = 30,
  macs.pval = "1e-5", sicer.wsize = 200, sicer.gsize = 200,
  sicer.fdr = 0.1, tss.distance = 0, max.upstream.distance = 10000,
  remove.duplicates = "N")
```

Specifically user needs to create three folders:

    + mock.folder, where the fastq.gz file for the control sample is located. For control sample we refer to ChIP with IgG only or input DNA.
    + test.folder, where the fastq.gz file for the ChIP of the sample to be analysed.
    + output.folder, where the R script embedding the above script is located.

The **scratch.folder** can be the same as the **output.folder**. However, if the system in use has a high speed disk for temporary calculation, e.g. a SSD disk, the location of the scratch.folder on the SSD will reduce significantly the computing time.

User needs to provide also the sequence of the sequencing adapters, **adapter5** and **adapter3** parameters. In case Illumina platform is used the adapters sequences can be easily recovered [here](https://support.illumina.com/content/dam/illumina-support/documents/documentation/chemistry_documentation/experiment-design/illumina-adapter-sequences_1000000002694-01.pdf). 

**Threads** indicates the max number of cores used by *skewer* and *bwa*, all the other steps are done on a single core.
The **min.length** refers to the minimal length that a reads should have after adapters trimming. Since today the average read length for a ChIP experiment is 50 or 75 nts would be better to bring to 40 nts the min.length parameter to increase the precision in assigning the correct position on the genome.

The **genome.folder** parameter refers to the location of the genomic index generated by bwa using the *docker4seq* function **bwaIndexUcsc**.
The generation of the genome index for ChIP experiment is very simple and it is highlited at the end of this paragraph.

**mock.id** and **test.id** identify the type of sample and are assigned to the ID parameter in the RG field of the bam file.

**genome** is the parameter referring to the annotation used to associate ChIP peaks to genes. In the present implemetation are available hg38, hg19 for human and mm10 and mm9 for mouse annotations.

**read.size** is a parameter requested by MACS and SICER for their analysis. 
**macs.min.mfold**, **macs.max.mfold**, **macs.pval**  are the deafult parameters requested for  peaks definition for more info please refer to the documetation of MACS 1.4.
**sicer.wsize**, **sicer.gsize**, **sicer.fdr** are the deafult parameters requested for  peaks definition for more info please refer to the documetation ofSICER 1.1.
**Important**: The optimal value for **sicer.gsize** in case of H3K4Me3 ChIP is 200 and in case of ChIP H3K27Me3 is 600.   

**tss.distance** and **max.upstream.distance** are parameters required by ChIPseqAnno, which is the bioconducto package used to assign the peaks to specific genes. Specifically max.upstream.distance refers to the max distance in nts that allow to associate a peak to a gene.

**remove.duplicates** is the parameter that indicates if duplicates need to be removed or not. It has two options: **N** duplicates are not removed, **Y** duplicates are removed.


### Chipseq workflow output files

The chipseq workflow produces the following output files: 

    + README: A file describing the content of the data folder
    + mypeaks.xls: All detected peaks alongside the nearest gene and its annotation
    + mytreat.counts: The total reads count for the provided treatment file
    + mycontrol.counts: The total reads count for the provided control/background file
    + peak_report.xls: Aggregate information regarding the peak and their position relative to the nearest gene
    + chromosome_distribution.pdf: Barplot of the distribution of the peaks on the chromosomes
    + relative_position_distribution.pdf: Barplot of the distribution of the peaks positions relative to their nearest gene
    + peak_width_distribution.pdf: Histogram of the distribution of the width of the peaks
    + distance_from_nearest_gene_distribution.pdf: Histogram of the distribution of the distance of each peak from its nearest gene
    + cumulative_coverage_total.pdf: Cumulative normalized gene coverage
    + cumulative_coverage_chrN.pdf: Cumulative normalized gene coverage for the specific chromosome
    + mycontrol_sorted.bw: bigWig file for UCSC Genome Browser visualization
    + mytreat_sorted.bw: bigWig file for UCSC Genome Browser visualization
     




# Reproducible Bioinformatics Community

The aim of Reproducible Bioinformatics project is the creation of easy to use Bioinformatics workflows that fullfill the following roles ([Sandve et al. PLoS Comp Biol. 2013](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285)):

    1 For Every Result, Keep Track of How It Was Produced
    2 Avoid Manual Data Manipulation Steps
    3 Archive the Exact Versions of All External Programs Used
    4 Version Control All Custom Scripts
    5 Record All Intermediate Results, When Possible in Standardized Formats
    6 For Analyses That Include Randomness, Note Underlying Random Seeds
    7 Always Store Raw Data behind Plots
    8 Generate Hierarchical Analysis Output, Allowing Layers of Increasing Detail to Be Inspected
    9 Connect Textual Statements to Underlying Results
    10 Provide Public Access to Scripts, Runs, and Results

Reproducible Bioinformatics is a non-profit and open-source project.

We are a group of Bioinformaticians interested to simplify the use of bioinformatics tools to Biologists w/wo scripting ability. At the same time we are interested in providing robust and reproducible workflows.

For this reason we have developed the docker4seq package.

At the present time a total of three workflows are available in the stable version of docker4seq package (more info below in the text):

    - RNAseq workflow
    - miRNAseq workflow
    - ChIPseq workflow

Under development are:

    - PDX workflow: variants calling in patient derived xenograft (PDX) from RNAseq and EXOMEseq data
    - Single cell analysis workflow
    - Metagenomics workflow

All workflows are controlled by a set of R fuctions, part of docker4seq package, and the algorithms used are all encapsulated into Docker images and stored at docker.io/repbioinfo repository.

More info on docker4seq: [docker4seq web page](https://kendomaniac.github.io/docker4seq/index.html)


### How to be part of the Reproducible Bioinformatics Project community


Any bioinformatician interested to embed specific applications in the available workflows or interested to develop a new workflow is requested to embed the application(s) in a docker image, save it in a public repository and configure one or more R functions that can be used to interact with the docker image. The module/workflow needs to fullfil at least the first 6 Sandve's rules.

Steps required to submit a new application/workflow:

- Edit the [skeleton.R](https://github.com/kendomaniac/docker4seq/blob/devel/R/skeleton.R) function and the ubuntu docker image (docker.io/repbioinfo/ubuntu) to create the new application.


    + Please have a look at: [Controlling jobs in a docker image, a brief tutorial](https://kendomaniac.github.io/docker4seq/articles/skeleton.html).


- Create a public docker repository for the docker image, e.g. at [docker.com](http://docker.com).

- Create a workflow.Rmd vignette using RStudio and publish it via RStudio. As example of a vignette see [docker4seq vignette](https://kendomaniac.github.io/docker4seq/).

- Once the docker image, the function(s) and vignette are ready please fill this [submission form](http://goo.gl/bb42EN).

    + If your module/workflow passes the validation analysis, you will be inserted as developer of the docker4seq package, and you will add your module and vignette to the docker4seq github repository.

    + If your module will not satisfy some of the validation points we will help you in fixing the issues and having your module compliant to the requirements of the Reproducible-bioinformatics Project. Mantainers will be responsable of the maintainance of their application(s).


### docker4seq

**docker4seq** is registed with RRID SCR_017006 at [*SciCrunch*](scicrunch.org). *docker4seq** is part of  [*Elixir bio.tools*](https://bio.tools/).

A collection of functions to execute NGS computing demanding applications, e.g reads mapping and counting, wrapped in docker containers.
To install it you can use use **devtools**:

```
install.packages("devtools")
library(devtools)
install_github("kendomaniac/docker4seq", ref="master")
```

#### Requirements
You need to have docker installed on your machine, for more info see this document:
https://docs.docker.com/engine/installation/.
**docker4seq** package is expected to run on 64 bits linux machine with at least 4 cores.  32 Gb RAM are required only if mapping will be done with STAR. In case mapping is done with Salmon, only 16 Gb RAM are needed.
A scratch folder should be present, e.g. /data/scratch and it should be writable from everybody:

```
chmod 777 /data/scratch
```

The functions in docker4seq package require that user is sudo or part of a docker group.
See the following document for more info:
https://docs.docker.com/install/linux/linux-postinstall/

**IMPORTANT** The first time *docker4seq* is installed the **downloadContainers** needs to be executed  to download to the local repository the containers that are needed for the use of *docker4seq*

More info on the functionalities of the package are available at: [**docker4seq/4SeqGUI vignette**](https://kendomaniac.github.io/docker4seq/index.html)

- **docker4seq/4SeqGUI Video Tutorials:**

    + [HowTo run a full RNAseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRhTi9MYMysNI3O4fR0wt46D)

    + [HowTo run a full miRNAseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRix-Er5unoze68qE8vW46s-)

    + [HowTo run a full ChIPseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRhqjyPBGkDRTf0wNi4Y9Va2)


**testSeqbox**
In *docker4seq* library is now present the function *testSeqbox*, allowing to check if  the software required for docker4seq functionalities is properly installed. Check *?testSeqbox* to see how to use it.


#### Workflows compliance with Sandve rules:

- The **whole transcriptome workflow**, embedding annotatingByGtf.R, demultiplexing.R, experimentPower.R, fastqc.R, filterCounts.R, pca.R, rnaseqCounts.R, rsemAnnotate.R, rsemStar.R, rsemstarIndex.R, salmonAnnotation.R, salmonCounts.R, salmonIndex.R, samples2experiment.R, sampleSize.R, skewer.R, wrapperDeseq2.R, wrapperSalmon.R fullfils all [Sandve](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285) reproducibility rules.

- The **miRNAs analysis workflow**, embedding demultiplexing.R, experimentPower.R, fastqc.R, filterCounts.R, pca.R, mirnaCounts.R, mirnaCovar.R, sampleSize.R, wrapperDeseq2.R fullfils all [Sandve](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285) reproducibility rules.

- The **Xenome module**, which allows to discriminate between mouse and human reads in patient derived xenograft DNA/RNA sequenced samples, embedding xenome.R and xenomeIndex.R, fullfils all [Sandve](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285) reproducibility rules.

- The **inDrop single cell module**, which allows the single cell UMI counting generated with inDrop single cell sequencing technology, embedding indropCounts.R and demultiplexing.R fullfils all [Sandve](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285) reproducibility rules.

- The **Platypus module**, which allows haplotype-based variant calling for next generation sequence data, embedding demultiplexing.R, bwa.R and platypus.R fullfils all [Sandve](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285)

- The **Circular RNA identification module**, which allows the identification circRNAs, embedding starChipIndex.R, starChimeric.R and starchipCircle.R fullfils all [Sandve](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285)

- The **ChIPseq workflow** embedding demultiplexing.R, chipseq.R, chipseqCounts.R, bwa.R, bwaIndexUcsc.R does not satisfy Rule 4 (Version Control All Custom Scripts) because it download for annotation the latest version of ENSEMBL annotation. Thus, annotation executed at different time might differ because of the changes in the ENSEMBL downoaded information. We are working to fix this issue, expected fixing Q3 2018. Not all intermediate results are available as part of the final results (Sandve rule 5), expected fixing Q3 2018.

#### Diclaimer:
docker4seq developers have no liability for any use of docker4seq functions, including without limitation, any loss of data, incorrect results, or any costs, liabilities, or damages that result from use of docker4seq.

### 4SeqGUI Project

[4SeqGUI](https://github.com/mbeccuti/4SeqGUI) is the GUI that can control the docker4seq functionalities. It represents the graphical interface used in SeqBox project (see below).

Video tutorials for 4SeqGUI:

[HowTo run a full RNAseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRhTi9MYMysNI3O4fR0wt46D)

[HowTo run a full miRNAseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRix-Er5unoze68qE8vW46s-)

[HowTo run a full ChIPseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRhqjyPBGkDRTf0wNi4Y9Va2)


### The SeqBox Project

Short reads sequencing technology has been used for more than a decade now. However, the analysis of RNAseq and ChIPseq data is still computational demanding and the simple access to raw data does not guarantee results reproducibility between laboratories. To address these two aspects, we developed SeqBox, a cheap, efficient and reproducible RNAseq/ChIPseq hardware/software solution based on NUC6I7KYK mini-PC (an Intel consumer game computer with a fast processor and a high performance SSD disk), and Docker container platform. In SeqBox the analysis of RNAseq and ChIPseq data is supported by a friendly GUI. This allows access to fast and reproducible analyses also to scientists with/without scripting experience.

More info on SeqBox characteristics and cost are available at [www.seqbox.com](http://www.seqbox.com)


**IMPORTANT** The first time *docker4seq* is installed the **downloadContainers** needs to be executed  to download to the local repository the containers that are needed for the use of *docker4seq*

More info on the functionalities of the package are available at: [docker4seq/4seqGUI vignette](http://rpubs.com/rcaloger/279935)

- **docker4seq/4SeqGUI Video Tutorials:**

    + [HowTo run a full RNAseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRhTi9MYMysNI3O4fR0wt46D)

    + [HowTo run a full miRNAseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRix-Er5unoze68qE8vW46s-)

    + [HowTo run a full ChIPseq analysis](https://www.youtube.com/playlist?list=PLN48SoNXrLRhqjyPBGkDRTf0wNi4Y9Va2)



## Diclaimer:
docker4seq developers have no liability for any use of docker4seq functions, including without limitation, any loss of data, incorrect results, or any costs, liabilities, or damages that result from use of docker4seq.
## Steps required to submit a new application/workflow:

- Edit the skeleton.R function and the ubuntu docker image (docker.io/repbioinfo/ubuntu) to create the new application.

    + Please have a look at: [Controlling jobs in a docker image, a brief tutorial](http://rpubs.com/rcaloger/300960).
    
- Create a public docker repository for the docker image, e.g. at docker.com.
    
- Create a workflow.Rmd vignette using RStudio and publish it via RStudio. As example of a vignette see [docker4seq vignette](http://rpubs.com/rcaloger/293366).
    
- Once the docker image, the function(s) and vignette are ready please contact info@reproducible-bioinformatics.org. 

    + We will test and incorporate the code in docker4seq package. 
    
    + Mantainers will be responsable of the maintainance of their application(s).


If you are interested to participate to the project or if you need more information please contact info@reproducible-bioinformatics.org
---
title: "Skeleton tutorial"
author: "Raffaele A Calogero"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::knitr}
  %\VignetteIndexEntry{Skeleton tutorial}
  %\VignetteEncoding{UTF-8}   

header-includes:
- \usepackage{makeidx}
- \makeindex
- \usepackage{setspace}\doublespacing
- \usepackage{pdfpages}


fig_caption: true
---

\newpage
\tableofcontents



## Dissecting the skeleton.R

The skeleton function allows to control a bash script, **skeleton.sh**, located in docker.io/repbioinfo/ubuntu image in /bin.

The skeleton function has three parameters:


```r
skeleton(group="docker", scratch.folder, data.folder)
```

- **group**, a character string. Two options: *sudo* or *docker*, depending to which group the user belongs

- **scratch.folder**, a character string indicating the path of the scratch folder. In principle the scratch folder is a temporary folder located in a disk with high I/O, e.g. a SSD disk, but if the fast disk is not available it represents only a temporary folder where the data generated by the application are saved.

- **data.folder**, a character string indicating the folder where input data are located and where output will be written

The first step in the skeleton function is storing the working folder and grabbing the process time for  subsequent performance evaluation.

```r
  #storing the position of the home folder  
  home <- getwd()
  #running time 1
  ptm <- proc.time()
```

Then, it is tested if docker demon is running,

```r
  #testing if docker is running
  test <- dockerTest()
  if(!test){
    cat("\nERROR: Docker seems not to be installed in your system\n")
    return()
  }
```

checking if data folder exists and setting it as working folder,

```r
  #setting the data.folder as working folder
  if (!file.exists(data.folder)){
    cat(paste("\nIt seems that the ",data.folder, " folder does not exist\n"))
    return(2)
  }
  setwd(data.folder)
```

checking if scratch folder exists and creating a temporary folder.

```r
  #check  if scratch folder exist
  if (!file.exists(scratch.folder)){
    cat(paste("\nIt seems that the ",scratch.folder, " folder does not exist\n"))
    return(3)
  }
  tmp.folder <- gsub(":","-",gsub(" ","-",date()))
  scrat_tmp.folder=file.path(scratch.folder, tmp.folder)
  writeLines(scrat_tmp.folder,paste(data.folder,"/tempFolderID", sep=""))
  cat("\ncreating a folder in scratch folder\n")
  dir.create(file.path(scrat_tmp.folder))
```

Executing the docker command:

* first is created a parameter string, which is made of:

    + --cidfile creates in data.folder the dockerID file that contains the docker job ID

    + -v the temporary folder, created in the scratch folder, is mounted as /scratch

    + -v the data folder is mounted as /data

    + -d docker.io/repbioinfo/ubuntu sh /bin/skeleton.sh is the command that executes the skeleton.sh script.

* the parameter string is passed to the runDocker that execute the job. runDocker check if docker is running and return **false** when is finished


```r
  #executing the docker job
  if(group=="sudo"){
    params <- paste("--cidfile ",data.folder,"/dockerID -v ",scrat_tmp.folder,":/scratch -v ", data.folder, ":/data -d docker.io/repbioinfo/ubuntu sh /bin/skeleton.sh", sep="")
    resultRun <- runDocker(group="sudo", params=params)
  }else{
    params <- paste("--cidfile ",data.folder,"/dockerID -v ",scrat_tmp.folder,":/scratch -v ", data.folder, ":/data -d docker.io/repbioinfo/ubuntu sh /bin/skeleton.sh", sep="")
    resultRun <- runDocker(group="docker", params=params)
  }
```


The **skeleton.sh** scripts in docker.io/repbioinfo/ubuntu is the following:


```bash
#!/bin/bash
echo "skeleton 0.0.1"
#setting the scratch folder as workinng directory
SCRATCH_FOLDER=/scratch
DATA_FOLDER=/data
#moving to scratch folder
cd $SCRATCH_FOLDER
#adding information to run.info file or creating a run.info file
file="run.info"
if [ -f "$file" ]
then
        echo "skeleton 0.0.1" >> $SCRATCH_FOLDER/run.info
else
        echo "skeleton 0.0.1" > $SCRATCH_FOLDER/run.info
fi
#writing the result file helloworld in data scratch
echo "hello world" > $SCRATCH_FOLDER/helloworld.txt
# creating the out.info file indicating that run is finished
echo "analysis is finished" > $SCRATCH_FOLDER/out.info
#changing the properties of files and folders in /data/scratch
chmod 777 -R $SCRATCH_FOLDER/*

```

It writes hello world in the **helloworld.txt** and moves **helloworld.txt** to the data folder together with the **run.info** file, used to store information about the run, and the **out.info**, used to tell to the R script when the doker job is finished.
The **skeleton.sh** scripts is a prototype for the handling of docker application(s).

Lets go back to the skeleton.R dissection:

The **resultRun** is used to check when the docker job is finished. The log of the docker job is saved with a name made of the first 12 letters of the docker job ID. Then, the docker container is deleted as well as the temporary folder and few other files: out.info, dockerID, tempFolderID. Finally the home folder is restored as working directory.


```r
 #when container ends
 if(resultRun=="false"){
   #everything is copied to the input folder
    system(paste("mv ", scrat_tmp.folder,"/* ",data.folder, sep=""))
     #saving log and removing docker container
    container.id <- readLines(paste(data.folder,"/dockerID", sep=""), warn = FALSE)
    system(paste("docker logs ", substr(container.id,1,12), " &> ", substr(container.id,1,12),".log", sep=""))
    system(paste("docker rm ", container.id, sep=""))
    #removing temporary folder
    cat("\n\nRemoving the temporary file ....\n")
    system(paste("rm -R ",scrat_tmp.folder))
    system("rm -fR out.info")
    system("rm -fR dockerID")
    system("rm  -fR tempFolderID")
    system(paste("cp ",paste(path.package(package="docker4seq"),"containers/containers.txt",sep="/")," ",data.folder, sep=""))
 }
```

Then, the computing time is estimated and saved in the run.info file

```r
  #running time 2
  ptm <- proc.time() - ptm
  dir <- dir(data.folder)
  dir <- dir[grep("run.info",dir)]
  if(length(dir)>0){
    con <- file("run.info", "r")
    tmp.run <- readLines(con)
    close(con)
    tmp.run[length(tmp.run)+1] <- paste("user run time mins ",ptm[1]/60, sep="")
    tmp.run[length(tmp.run)+1] <- paste("system run time mins ",ptm[2]/60, sep="")
    tmp.run[length(tmp.run)+1] <- paste("elapsed run time mins ",ptm[3]/60, sep="")
    writeLines(tmp.run,"run.info")
  }else{
    tmp.run <- NULL
    tmp.run[1] <- paste("run time mins ",ptm[1]/60, sep="")
    tmp.run[length(tmp.run)+1] <- paste("system run time mins ",ptm[2]/60, sep="")
    tmp.run[length(tmp.run)+1] <- paste("elapsed run time mins ",ptm[3]/60, sep="")
    writeLines(tmp.run,"run.info")
  }
```




```r
  setwd(home)
```
---
title: "An Introduction to docker4seq package and 4SeqGUI"
author: "Raffaele A Calogero"
output:
  rmarkdown::html_vignette:

    fig_caption: yes

vignette: >
  %\VignetteIndexEntry{An Introduction to docker4seq package and 4SeqGUI}
  %\VignetteEngine{knitr::knitr}
  %\usepackage[utf8]{inputenc}

---



## Introduction

The docker4seq package was developed to facilitate the use of computing demanding applications in the field of NGS data analysis.

The docker4seq package uses [docker](https://www.docker.com/what-docker) [containers](https://www.docker.com/what-container) that embed demanding computing tasks (e.g. short reads mapping) into isolated containers.

This approach provides multiple advantages:

- user does not need to install all the software on its local server;

- results generated by different containers can be organized in pipelines;

- reproducible research is guarantee by the possibility of sharing the docker images used for the analysis.

## Requirements

The minimal hardware requirements are a 4 cores 64 bits linux computer, 32 Gb RAM, one SSD 250GB, with a folder with read/write permission for any users (chmod 777), and [docker](https://www.docker.com/) installed.

### Setup

[**docker4seq**](https://github.com/kendomaniac/docker4seq) and its graphical interface (optional) [**4SeqGUI**](https://github.com/mbeccuti/4SeqGUI) can fit ideally in the [NUC6I7KYK, Intel mini-computer](https://www.intel.com/content/www/us/en/products/boards-kits/nuc/kits/nuc6i7kyk.html) equipped with Kingston Technology HyperX Impact 32GB Kit (2x16GB), 2133MHz DDR4 CL13 260-Pin SODIMM and Samsung 850 EVO - 250GB - M.2 SATA III Internal SSD.


**MANDATORY:** The first time *docker4seq* is installed the **downloadContainers** function needs to be executed to download, in the local repository, the docker images that are needed by *docker4seq*.


```r
library(docker4seq)
downloadContainers(group="docker")
```


## Dockers containers

At the present time all functions requiring some sort of calculation are embedded in the following docker images:

- docker.io/repbioinfo/demultiplexing.2017.01 used by demultiplexing

- docker.io/repbioinfo/annotate.2017.01 used by rnaseqCounts, rsemanno

- docker.io/repbioinfo/bwa.2017.01 used by bwaIndexUcsc, bwa, wrapperPdx

- docker.io/repbioinfo/chipseq.2017.01 used by chipseqCounts, chipseq

- docker.io/repbioinfo/r332.2017.01 used by experimentPower, sampleSize, wrapperDeseq2

- docker.io/repbioinfo/mirnaseq.2017.01 used by mirnaCounts

- docker.io/repbioinfo/rsemstar.2017.01 used by rnaseqCounts, rsemstarIndex, rsemstarUscsIndex

- docker.io/repbioinfo/skewer.2017.01 used by skewer, rnaseqCounts, wrapperPdx

- docker.io/repbioinfo/xenome.2017.01 used by xemone, xenomeIndex, wrapperPdx

### docker container nomenclature

In case of updates required to solve bugs, which do not affect the calculation docker.io/rcaloger/XXXXX.YYYY.ZZ the fiels ZZ will be updated.

In case of updates which affect the calculation, e.g. new release of Bioconductor libraries, the field YYYY will be updated. Previous versions will be maintained to  guarantee  the reproducibility of any previous analisys.

### Reproducibility

The file **containers.txt**, which indicates the Docker images available in the local release of docker4seq is saved within any folder generated with docker4seq functions.

In case, user would like to download a set of dockers images different from those provided as part of the package, then these images must be specified in a file with the following format **docker.repository/user/docker.name**, which has to be passed to downloadContainers function:


```r
downloadContainers(group="docker", containers.file="my_containers.txt")
#an example of the my_containers.txt file content
docker.io/rcaloger/bwa.2017.01
docker.io/rcaloger/chipseq.2017.01
docker.io/rcaloger/r340.2017.01
```


## Available workflows
At the present time are available the following workflows:

- **mRNAseq**, which allows:
    + adapter trimming with [skewer](https://github.com/relipmoc/skewer)
    + mapping with [STAR](https://github.com/alexdobin/STAR)
    + counting genes and isoforms with [RSEM](http://deweylab.github.io/RSEM/)
    + as option to STAR/RSEM it is possible to use **SALMON**, which is does reference-free transcripts quantification.
    + ENSEMBL gene annotation.
    + organizing the output of RSEM in tables to be used for differential expression analysis
    + visualizing experiment data with PCA
    + evaluating experiment power and sample size
    + detecting differentially expressed genes/isoforms
    + subsetting counts/FPKM and TPM table to have only differentially expressed genes, suitable for heatmaps generation.
- **miRNAseq**, which executes the workflow described in Cordero et al. PLoS One. 2012;7(2):e31630, embedding the following steps:
    + trimming adapters with [cutadapt](http://cutadapt.readthedocs.io/en/stable/guide.html)
    + miRNAs mapping on [mirbase](http://www.mirbase.org/) hairpins using [SHRiMP](http://compbio.cs.toronto.edu/shrimp/)
    + quantification of mature miRNAs.
    + visualizing experiment data with PCA
    + evaluating experiment power and sample size
    + detecting differentially expressed miRNAs
- **ChIPseq**, which allows:
    + adapter trimming with [skewer](https://github.com/relipmoc/skewer)
    + mapping with [BWA](http://bio-bwa.sourceforge.net/bwa.shtml)
    + peak calling using either MACS v 1.4 or SICER v 1.1
    + associating peaks to the nearest gene, UCSC annotation
    + full annotation of the nearest gene
- **PDX Exomeseq**, which allows:
     + mouse sequence removal with [xenome](https://github.com/data61/gossamer)
     + adapter trimming with [skewer](https://github.com/relipmoc/skewer)
     + mapping with [BWA](http://bio-bwa.sourceforge.net/bwa.shtml)
     + annotating the output of oncoSNP


The most expensive computing  steps of the analyses are embedded in the following docker4seq functions: **rnaseqCounts**, **mirnaCounts**, **chipseqCounts**. These functions are also the only having RAM and computing power requirements not usually available in consumer computers. Hereafter it is shown the time required to run the above three functions increasing the number of sequenced reads.

### testSeqbox
In *docker4seq* is now present the function *testSeqbox*, which allows to evaluate if the software required for docker4seq functionalities is properly installed. Results of the tests are saved in testSeqBox.out file.

### rnaseqCounts performances

Counts generation from fastq files  is the most time consuming step in RNAseq data analysis and it is usually calculated using high-end servers. We compare the behabiour of **rnaseqCounts** on SeqBox and on a high-end server:

    + SeqBox: NUC6I7KYK CPU i7-6770HQ 3.5 GHz (1 core, 8 threads), 32 Gb RAM, HD 250 Gb SSD
    + SGI UV200 server: CPU E5-4650 v2 2.40GHz (8 cores, 160 threads), 1 Tb RAM, RAID 6, 100 Tb SATA


We run respectively 26, 52, 78, and 105 million reads using different number of threads, values shown in parenthesis in figure below. It is notable that SeqBox, mapping in 5 hours more than 100 milion reads, it is able to handle in 20 hours the throughput of the Illumina benchtop sequencer NextSeq 500, which produces up to 400 milion reads in a run of 30 hours.

<img src="../inst/img/mrna_performance_bis.jpg" title="rnaseqCounts overall performance" alt="rnaseqCounts overall performance" width="70%" style="display: block; margin: auto;" />




### mirnaCounts performances

We run respectively 3, 6, 12, and 24 miRNA samples in parallel using **mirnaCounts**, with different number of threads, values shown in parenthesis in figure below.

<img src="../inst/img/mirnaseq_performance_bis.jpg" title="mirnaCounts overall performance" alt="mirnaCounts overall performance" width="70%" style="display: block; margin: auto;" />


### chipseqCounts performances

We run respectively 37, 70, 111, and 149 million reads using different number of threads, values shown in parenthesis in figure below.

<img src="../inst/img/chipseq_performance_bis.jpg" title="chipseqCounts overall performance" alt="chipseqCounts overall performance" width="70%" style="display: block; margin: auto;" />


From the point of view of parallelization the **rnaseqCounts** is the one that embeds the most computing demanding tools: i) mapping with STAR and ii) quantifying transcripts with RSEM. Both these tools were design to take advantage of multiple cores hardware architecture and they also require massive I/O. On the basis of the results shown in *Figure 1* parallelization does not improve very much the overall performances, even if it can mitigate the gap w.r.t. SeqBox due to the poor I/O performance of the SATA disk array. On the other side the presence of a SSD with very high I/O performance can remedy the limited amount of cores of SeqBox.

In the case of **mirnaCounts** and **chipseqCounts** the parallelization is very little and it is only available for the reads mapping procedure. Moreover, both functions have a massive I/O. The reduced parallelization of these two analyses combined with the higher I/O throughput of the SSD with respect to the SATA array makes SeqBox extremely effective even with very high number of reads to be processed, *Figure 2  and 3*.

## Test sets

A folder including a set do dataset to test each of the workflows available in docker4seq/4SeqGUI can be found [**here**](http://130.192.119.59/public/test.zip)



## RNAseq workflow: Howto

### Demultiplexing

*demultiplexing* function is used to convert in fastq bcl files generated by an Illumina sequencer. The function requires that in the bcl folder the SampleSheet.csv is present. An example fo SampleSheet for a pair-end run is present in docker4seq examples folder. The function require that the full path to the bcl file folder is provided, **data.folder**, the scratch folder where temporary analysis is run and the number of cores that will be used by the program.


```r
demultiplexing(group="docker",
      data.folder="/home/calogero/Documents/data/lollini/3a_run/170712_NB501050_0097_AH3FGNBGX3",
      scratch.folder="/data/scratch", threads=24)
```

The function will return, in the folder containing the bcl files folder, e.g. \/home\/calogero\/Documents\/data\/lollini\/3a_run\/, the fastq files generated by the analysis.

This function is not implemented in **4SeqGUI** because this step is generally done by a core lab. Thus only a limited group of users require the use of this function.

The **mRNAseq workflow**, that can be handled using **4SeqGUI** graphical interface (linux/MAC) (figure below), starts from the availability of fastq files .

<img src="../inst/img/rnaseq1.jpeg" title="mRNAseq workflow" alt="mRNAseq workflow" width="100%" style="display: block; margin: auto;" />


Sample quantification is made of these steps:

- Creating a genome index for STAR (see end of this paragraph)

- Running removing sequencing adapters

- Mapping reads to the reference genome

- Quantify gene and transcript expression level

- Annotating genes.

All the parameters can be setup using 4SeqGUI

### Creating a STAR index file for mRNAseq

The index can be easily created using the graphical interface:

<img src="../inst/img/rnaseq2.jpeg" title="Creating a STAR genome index" alt="Creating a STAR genome index" width="100%" style="display: block; margin: auto;" />


A detailed description of the parameters is given below.

#### Creating a STAR index file by line command

\fontsize{8}{8}\selectfont

```r
rsemstarIndex(group="docker",genome.folder="/data/scratch/hg38star",
ensembl.urlgenome="ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz",
ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.gtf.gz")
```

In brief, **rsemstarIndex** uses ENSEMBL genomic data. User has to provide the URL (**ensembl.urlgenome**) for the file XXXXX_dna.toplevel.fa.gz related to the organism of interest, the URL (**ensembl.urlgtf**) for the annotation GTF XXX.gtf.gz and the path to the folder where the index will be generated (**genome.folder**). The parameter **threads** indicate the number of cores dedicated to this task.

Precompiled index folders are available:

- [hg38star](http://130.192.119.59/public/hg38star.tar.gz)

- [mm10star](http://130.192.119.59/public/mm10star.tar.gz)



### Quantifying genes/isoforms


<img src="../inst/img/rnaseq3.jpeg" title="Gene, Isoform counting" alt="Gene, Isoform counting" width="100%" style="display: block; margin: auto;" />


A detailed description of the parameters is given below.

#### Sample quantification by line command

The sample quantification can be also executed using R and it is completely embedded in a single function:


```r
#test example
system("wget http://130.192.119.59/public/test.mrnaCounts.zip")
unzip("test.mrnaCounts.zip")
setwd("./test.mrnaCounts")
library(docker4seq)
rnaseqCounts(group="docker",fastq.folder=getwd(), scratch.folder=getwd(),
adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
seq.type="se", threads=8,  min.length=40,
genome.folder="/data/scratch/mm10star", strandness="none", save.bam=FALSE,
org="mm10", annotation.type="gtfENSEMBL")
```


User needs to create the **fastq.folder**, where the fastq.gz file(s) for the sample under analysis are located.
The **scratch.folder** is the location where temporary data are created. The results will be then saved in the **fastq.folder**.

User needs to provide also the sequence of the sequencing adapters, **adapter5** and **adapter3** parameters. In case Illumina platform the adapters sequences can be easily recovered [**here**](https://support.illumina.com/downloads/illumina-customer-sequence-letter.html).

**seq.type** indicates if single-end (se) or pair-end (pe) data are provided, **threads** indicates the max number of cores used by *skewer* and *STAR*, all the other steps are done on a single core.

The **min.length** refers to the minimal length that a reads should have after adapters trimming. Since today the average read length for a RNAseq experiment is 50 or 75 nts would be better to bring to 40 nts the min.length parameter to increase the precision in assigning the correct position on the genome.

The **genome.folder** parameter refers to the location of the genomic index generated by STAR using the *docker4seq* function **rsemstarIndex**, see above paragraph.


**strandness**, is a parameter referring to the kit used for the library prep. If the kit does not provide strand information it is set to "none", if provides strand information is set to "forward" for  Illumina stranded kit and it set to "reverse" for Illumina ACCESS kit. **save.bam** set to TRUE indicates that genomic bam file and transcriotomic bam files are also saved at the end of the analysis. **annotation.type** refers to the type of available gene-level annotation. At the present time is only available ENSEMBL annotation defined by the gtf downloaded during the creation of the indexed genome files, see paragraph *at the end*Creating a STAR index file for mRNAseq*.


### Salmon, reference free alignment

Recently Zhang and coworkers (BMC Genomics 2017, 18,583) compared, at transcript level, alignment-dependent tools (Salmon_aln, eXpress, RSEM and TIGAR2) and aligner-free methods (Salmon, Kallisto Sailfish). In their paper, STAR was used as mapping tool for all alignment-dependent tools. In terms of isoform quantification, the authors indicated that there is strong concordance among quantification results from RSEM, Salmon, Salmon_aln, Kallisto and Sailfish (R2 > 0.89), suggesting that the impact of mappers on isoform quantification is small. Furthermore, the paper of Teng and coworkers (Genome Biology 2016, 17,74) reported that,in term of gene-level quantification, differences between alignment-dependent tools and aligner-free methods are shrinking with respect to transcripts level analysis.
On the basis of the above papers it seems that from the quantification point of view the difference between alignment free and alignment-dependent tools is very limited.
However, aligner-free methods have low memory requirements and we added Salmon in docker4seq.

#### Creating a Salmon quasi-reference file for mRNAseq

The quasi-reference can be created using cDNA fasta files available at ENSEMBL. The corresponding genomics GTF is required for the gene level annotation:


<img src="../inst/img/salmonIndex.jpeg" title="Salmon reference" alt="Salmon reference" width="100%" style="display: block; margin: auto;" />



```r
#running salmonIndex human
salmonIndex(group="docker", index.folder=getwd(),
       ensembl.urltranscriptome="ftp://ftp.ensembl.org/pub/release-90/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz",
       ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-90/gtf/homo_sapiens/Homo_sapiens.GRCh38.90.gtf.gz",
       k=31)
```


#### Quantifying isoforms and genes with Salmon

Salmon quantification function *wrapperSalmon* has the same structure of *rnaseqCounts*. It performs adapters trimming, transcripts quantification, genes quantification and annotation.  The output of wrapperSalmon is identical to the output of rnaseqCounts for what concern the files **isoforms.results** and **gtf_annotated_genes.results**, which can be used by *samples2experiment* to generate the tables for differential expression analysis:


<img src="../inst/img/salmonCounts.jpeg" title="Salmon quantification" alt="Salmon quantification" width="100%" style="display: block; margin: auto;" />



```r
system("wget http://130.192.119.59/public/test_R1.fastq.gz")
system("wget http://130.192.119.59/public/test_R2.fastq.gz")

#running salmonCounts
wrapperSalmon(group="docker", scratch.folder="/data/scratch/",
         fastq.folder=getwd(), index.folder="/data/genome/salmonhg38/",
         threads=8, seq.type="pe", adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
         adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT", min.length=40, strandness="none")
```


**IMPORTANT**: Salmon produces only isoforms-level counts, thus we quantified gene-level counts as described by RSEM:

- Gene counts are gived by the sum of the counts associated to all transcripts associated to the gene locus.

- Gene-length is given by the mean length of the transcripts having counts greater than 0 or by the mean of all the transcripts annotated in the gene locus in case all transcripts have counts equal to 0.

However, there are some differences between the information present in RSEM and Salmon annotation:

|                       |  RSEM  | SALMON |
|:---------------------:|:------:|:------:|
| Annotated transcripts | 197898 | 164819 |
|    Annotated genes    |  57955 |  34912 |
|        Biotypes       |   43   |   24   |

The biotypes lacking in Salmon are 20, because the pseudo-reference is build using ENSEMBL cDNA fasta file:

processed_transcript, antisense, lincRNA, sense_intronic, sense_overlapping, 3prime_overlapping_ncRNA, bidirectional_promoter_lncRNA, snRNA,
miRNA, misc_RNA, snoRNA, rRNA, ribozyme, TEC, scRNA, scaRNA, vaultRNA, sRNA, macro_lncRNA, non_coding.

Furthermore, the data generated by SALMON do not overlap perfectly to RSEM output:


<img src="../inst/img/salmon_rsem.jpg" title="RSEM versus SALMON" alt="RSEM versus SALMON" width="100%" style="display: block; margin: auto;" />

Panel A above indicates that although there is a limited correlation between SALMON and RSEM expected counts (black) at transcript-level, **R2=0.35**, some transcripts are detected with more counts by SALMON, see vertical spikes. SALMON TPMs are generally higher of those estimated in RSEM (Panel A, red). This behavior is still present at gene-level (Panel B) and the R2 for the expected counts is **0.56**. The correlation between SALMON and RSEM at counts level (transcripts/genes) is always better of that observed at FPKM or TPM level.
It is notable that length estimation between SALMON and RSEM is well correlated only for transcripts/genes bigger than 100 nts (Panels C, D).



### Sample quantification output files

The mRNAseq workflow produces the following output files:

    + XXXXX-trimmed.log, containing the information related to the adapters trimming
    + gtf_annotated_genes.results, the output of RSEM gene quantification with gene-level annotation
    + Log.final.out, the statistics of the genome mapping generated by STAR  
    + rsem.info, summary of the parameters used in the run
    + genes.results, the output of RSEM gene quantification
    + isoforms.results, the output of RSEM isoform quantification
    + run.info, some statistics on the run
    + skewerd_xxxxxxxxxxxx.log, log of the skewer docker container
    + stard.yyyyyyyyyyyy.log, log of the star docker container

<img src="../inst/img/rnaseq7.jpeg" title="gtf_annotated_genes.results" alt="gtf_annotated_genes.results" width="100%" style="display: block; margin: auto;" />


In the figure above, the first column in **gtf_annotated_genes.results** is the ensembl gene id, the second is the [biotype](http://www.ensembl.org/Help/Faq?id=468),
the 3rd is the annotation source, the 4th contains the set of transcripts included in the ensembl gene id. Then there is the length of the gene, the lenght of the gene to which is subtracted the average length of the sequenced fragments, the expected counts are the counts to be used for differential expression analysis. [TPM](https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) and [FPM](https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) are normalized gene quantities to be used only for visualization purposes.

### From samples to experiment

The RSEM output is sample specific, thus it is necessary to assemble the single sample in an experiment table including in the header of the column both the covariates and the batch, if any.
The header sample name is separated by the covariate with an underscore, e.g. mysample1\_Cov1, mysample2\_Cov2:

<img src="../inst/img/counts1.jpeg" title="counts table with covariates" alt="counts table with covariates" width="100%" style="display: block; margin: auto;" />


In case also a batch is present also this is added to the sample name through a further underscore, e.g. mysample1\_Cov1\_batch1, mysample2\_Cov\_batch2:

<img src="../inst/img/counts2.jpeg" title="counts table with covariates and batch" alt="counts table with covariates and batch" width="100%" style="display: block; margin: auto;" />


The addition of the covariates to the various samples can be done using the **4seqGUI** using the button: *From samples to experiment*:

<img src="../inst/img/counts3.jpeg" title="generating a table with covariates" alt="generating a table with covariates" width="100%" style="display: block; margin: auto;" />


#### From samples to experiments by line command


```r
#test example
system("wget http://130.192.119.59/public/test.samples2experiment.zip")
unzip("test.samples2experiment.zip")
setwd("test.samples2experiment")
library(docker4seq)
sample2experiment(sample.folders=c("./e1g","./e2g","./e3g",
"./p1g", "./p2g", "./p3g"),
covariates=c("Cov.1","Cov.1","Cov.1","Cov.2","Cov.2","Cov.2"),
bio.type="protein_coding", output.prefix=".")
```

User needs to provide the paths of the samples, **sample.folder** parameter, a vector of the covariates, **covariates**, and the biotype(s) of interest, **bio.type** parameter. The parameter **output.prefix** refers to the path where the output will be created, as default this is the current R working folder.

#### From samples to experiments output files

The samples to experiments produces the following output files:

    + _counts.txt: gene-level raw counts table for differential expression analysis
    + _isoforms_counts.txt: isoform-level raw counts table for differential expression analysis
    + _isoforms_log2TPM.txt: isoform-level log2TPM for visualization purposes
    + _log2TPM.txt: gene-level log2TPM for visualization purposes
    + _isoforms_log2FPKM.txt: isoform-level log2FPKM for visualization purposes
    + _log2FPKM.txt: gene-level log2FPKM for visualization purposes
    + XXXXX.Rout: logs of the execution



### Visualizing experiment data with PCA

[PCA](https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. This transformation is defined in such a way that the first principal component accounts for as much of the variability in the data as possible, and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components.
**4SeqGUI** provides an interface to the generation experiment samples PCA:

<img src="../inst/img/pca1.jpeg" title="PCA" alt="PCA" width="100%" style="display: block; margin: auto;" />


The plot is saved in **pca.pdf** in the selected folder.

#### PCA by line command


```r
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
pca(experiment.table="_log2FPKM.txt", type="FPKM", legend.position="topleft", covariatesInNames=FALSE, principal.components=c(1,2), pdf = TRUE, output.folder=getwd())
```

User needs to provide the paths of experiment table, **experiment.table** parameter, i.e. the file generated using the samples2experiment function. The **type** parameter indicates if FPKM, TPM or counts are used for the PCA generation. The parameter **legend.position** defines where to locate the covariates legend. The parameter **covariatesInNames** indicates if the header of the experiment table contains or not covariate information. The parameter **principal.components** indicates which principal components should be plotted. **output.folder** indicates where to save the pca.pdf file:

<img src="../inst/img/pca2.jpeg" title="pca.pdf" alt="pca.pdf" width="100%" style="display: block; margin: auto;" />


The values in parentesis on x and y axes are the amount of variance explained by each principal component.

IMPORTANT: The above analysis is suitable also for miRNAseq data

### Evaluating sample size and experiment power

Sample size estimation is an important issue in the design of RNA sequencing experiments. Furthermore, experiment power provides an indication of which is the fraction of differentially expressed genes that can be detected given a specific number of samples and differential expression detection thresholds.
[RnaSeqSampleSize](https://www.ncbi.nlm.nih.gov/pubmed/25246651) Bioconductor package provides the possibility to calculate, from a pilot experiment, the statistical power and to define the optimal sample size.
We have implemented wrapper functions to  RnaSeqSampleSize sample size and experiment power estimation.


**4SeqGUI** provides an interface to sample size estimation:

<img src="../inst/img/ss.jpeg" title="sample size estimation" alt="sample size estimation" width="100%" style="display: block; margin: auto;" />

and to statistical power estimation:

<img src="../inst/img/es.jpeg" title="experiment power estimation" alt="experiment power estimation" width="100%" style="display: block; margin: auto;" />


#### Sample size estimation by line command


```r
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
sampleSize(group="docker", filename="_counts.txt", power=0.80, FDR=0.1, genes4dispersion=200, log2fold.change=1)
```

The requested parameters are the path to the counts experiment table generated by **samples2experiment** function. The param **power** indicates the expected fraction of differentially expressed gene, e.g 0.80. **FDR** and **log2fold.change**  are the two thresholds used to define the set of differentially expressed genes of interest.

The output file is **sample_size_evaluation.txt** is saved in the R working folder, below an example of the file content:

<img src="../inst/img/samplesize1.jpeg" title="sample_size_evaluation.txt" alt="sample_size_evaluation.txt" width="100%" style="display: block; margin: auto;" />

IMPORTANT: The above analysis is suitable also for miRNAseq data


#### Experiment statistical power estimation by line command


```r
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
experimentPower(group="docker", filename="_counts.txt",replicatesXgroup=7, FDR=0.1, genes4dispersion=200, log2fold.change=1)
```


The requested parameters are the path to the counts experiment table generated by **samples2experiment** function. The param **replicatesXgroup** indicates the number of sample associated with each of the two covariates. **FDR** and **log2fold.change**  are the two thresholds used to define the set of differentially expressed genes of interest. **genes4dispersion** indicates the number of genes used in the estimation of read counts and dispersion distribution.

The output file is **power_estimation.txt** is saved in the R working folder, below an example of the file content:

<img src="../inst/img/expp1.jpeg" title="power_estimation.txt" alt="power_estimation.txt" width="100%" style="display: block; margin: auto;" />


IMPORTANT: The above analysis is suitable also for miRNAseq data

### Differential expression analysis with DESeq2

A basic task in the analysis of count data from RNA-seq is the detection of differentially expressed genes.
**4SeqGUI** provides an interface to DESeq2 to simplify differential expression analysis:

<img src="../inst/img/de1.jpeg" title="DESeq2" alt="DESeq2" width="100%" style="display: block; margin: auto;" />

The output files are:

**DEfull.txt** containing the full set of results generated by DESeq2:

<img src="../inst/img/de2.jpeg" title="DEfull.txt" alt="DEfull.txt" width="100%" style="display: block; margin: auto;" />

**DEfiltered_log2fc_X_fdr_Y.Y.txt** containing the set of differentially expressed genes passing the indicated thresholds:

<img src="../inst/img/de3.jpeg" title="DEfiltered_log2fc_1_fdr_0.1.txt" alt="DEfiltered_log2fc_1_fdr_0.1.txt" width="100%" style="display: block; margin: auto;" />

**genes2go.txt** a file containing only the gene symbols to be used as input for [DAVID](https://david.ncifcrf.gov/) or [ENRICHR](http://amp.pharm.mssm.edu/Enrichr/)

log2normalized_counts.txt, log2 library size normalized counts, calculated by DESeq2, that can be used for visualization purposes.

#### DESeq2 by line command


```r
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
wrapperDeseq2(output.folder=getwd(), group="docker",
      experiment.table="_counts.txt", log2fc=1, fdr=0.1,
      ref.covar="Cov.1", type="gene", batch=FALSE)
```


User has to provide experiment table, **experiment.table** param, i.e. the counts table generated with **samples2experiment** function, the thresholds for the differential expression analysis, **log2fc** and **fdr** params, the reference covariate, **ref.covar** param, i.e. the covariate that is used as reference for differential expression detection, the **type** param, which refers to the type of experiment table in use: *gene*, *isoform*, *mirna*, **batch** parameter that indicates, if it is set to **TRUE** that the header of the experiment table also contains the extra information for the batch effect (see above).

IMPORTANT: the above analysis can be also applied to miRNAseq data.

### Subsetting counts/FPKM/TPM with differentially expressed genes

The function *filterCounts* allows to generate counts/FPKM/TPM tables that contains only differentially expressed genes. These tables can be used for visualization purposes, e.g. hetmaps generation with [**ClustVis**](https://biit.cs.ut.ee/clustvis/):

<img src="../inst/img/filtercounts.jpeg" title="Count Filter" alt="Count Filter" width="100%" style="display: block; margin: auto;" />

#### filterCounts


```r
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
     wrapperDeseq2(output.folder=getwd(), group="docker", experiment.table="_counts.txt", log2fc=1,
     fdr=0.1, ref.covar="Cov.1", type="gene", batch=FALSE))

    filterCounts(data.folder=getwd(), type="gene")
```

IMPORTANT: the above analysis can be also applied to miRNAseq data, using for the type parameter **mirna**. In this case also mean centered CPMs are calculated (**NOTE: DE filtered CPM are log2 transformed!**).

The outputs of **filterCounts** function start with **DEfiltered**.  Mean centered data indicates that for each gene count is divided by the mean of that gene over all samples. This representation is more convenient to observe changes between experimental groups.


### RNAseq workflow Tutorial

[**Tutorial experiment downloadable here**](http://130.192.119.59/public/test.mrnaCounts_full.zip):

    + Three replicates for two experimental conditions

    + single-end mode sequencing

    + 1 million reads for each sample

**Experiment description**:

    + 4T1 mouse cell line grown in standard DMEM medium (e) is compared with the same cells grown in low attachment medium (p)

The following data are available for download:

- [Fastq files for 3 samples grown in standard DMEM medium (e) and for 3 samples grown in low attachment medium (p) to be used to calculate samples counts](http://130.192.119.59/public/test.mrnaCounts_full.zip).

    + This data set allows running all the steps required to detect differentially expressed genes. The first step is the quantification of genes and isoforms via mapping reads to the reference genome via STAR and using this mapping information to quantify genes and transcripts using RSEM, i.e. *this section*.

    + The RSEM counts table, generated for all samples, are combined in a unique table, see *From samples to experiment* section. This table is used for differential expression genes detection. For visualization purposes  log2 FPKM and log2 TPM tables are also generated, see *From samples to experiment* section. More info on the FPKM and TPM are available [here](http://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/).

    + Subsequently the overall characteristics of the dataset can be explore via [PCA](https://www.youtube.com/watch?v=BfTMmoDFXyE), *Visualizing experiment data with PCA* section.

    + It is also possible to evaluate which is the statistical power of the experiment, i.e. identifying the fraction of genes/transcripts that can be identify giving the statistical structure of the experiment, or identify the optimal number of samples required to detect differentially expressed genes. More info in *Evaluating sample size and experiment power* section.

    + Differential expression can be then evaluate using the DESeq2 module, *Differential expression analysis with DESeq2*.


- Furthermore, also intermediate results are provided:

    + [The counts tables generated by STAR+RSEM analysis to be used to assemble counts, TPM and FPKM experiment tables](http://130.192.119.59/public/test.samples2experiment.zip)

    + [The experiment tables that can be used to study samples organization via PCA or the statistical characteristics of the experiment, i.e. the statistical power and the optimal sample size of the experiment](http://130.192.119.59/public/test.analysis.zip)

    + The above data set can be used also to detect differentially expressed genes and isoforms using the DESeq2 module.



## miRNAseq workflow

The miRNAseq workflow can be run using **4SeqGUI** graphical interface:

<img src="../inst/img/mirna1.jpeg" title="miRNAseq workflow" alt="miRNAseq workflow" width="100%" style="display: block; margin: auto;" />

The miRNAseq docker container executes the following steps:

<img src="../inst/img/mirna3.jpeg" title="miRNAseq workflow" alt="miRNAseq workflow" width="50%" style="display: block; margin: auto;" />

The full workflow is described in [Cordero et al. Plos ONE 2012](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0031630). In brief, fastq files are trimmed using [cutadapt](https://github.com/marcelm/cutadapt) and the trimmed reads are mapped on miRNA precursors, i.e. harpin.fa file, from [miRBase](http://www.mirbase.org/ftp.shtml) using [SHRIMP](http://compbio.cs.toronto.edu/shrimp/). Using the location of the mature miRNAs in the precursor, countOverlaps function, from the Bioconductor package GenomicRanges is used to quantify the reads mapping on mature miRNAs.


All the parameters needed to run the miRNAseq workflow can be setup using 4SeqGUI:

<img src="../inst/img/mirna2.jpeg" title="miRNAseq parameters" alt="miRNAseq parameters" width="100%" style="display: block; margin: auto;" />

A detailed description of the parameters is given below.

### miRNAseq workflow by line command

The miRNAseq workflow can be also executed using R and it is completely embedded in a unique function:


```r
#test example
system("wget 130.192.119.59/public/test.mirnaCounts.zip")
unzip("test.mirnaCounts.zip")
setwd("test.mirnaCounts")
library(docker4seq)
mirnaCounts(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
            mirbase.id="hsa",download.status=FALSE, adapter.type="NEB", trimmed.fastq=FALSE)
```

User has to create the **fastq.folder**, where the fastq.gz files for all miRNAs under analysis are located.
The **scratch.folder** is the location where temporary data are created. The results will be then saved in the **fastq.folder**.
User has to provide also the identifier of the miRBase organism, e.g. **hsa** for Homo sapiens, **mmu** for Mus musculus.  If the **download.status** is set to FALSE, mirnaCounts uses miRBase release 21, if it is set to TRUE the lastest version of precursor and mature miRNAs will be downloaded from miRBase. Users need to provide the name of the producer of the miRNA library prep kit to identify which adapters need to be provided to cutadapt, **adapter.type** parameter. The available adapters are NEB and Illumina, but, upon request, we can add other adapters. Finally, if the **trimmed.fastq** is set to FALSE the trimmed fastq are not saved at the end of the analysis.


### miRNAseq workflow output files

The miRNAseq workflow produces the following output files:

    + README: A file describing the content of the data folder
    + all.counts.txt: miRNAs raw counts, to be used for differential expression analysis
    + trimmimg.log: adapters trimming statistics
    + shrimp.log: mapping statistics
    + all.counts.Rda: miRNAs raw counts ready to be loaded in R.
    + analysis.log: logs of the full analysis pipeline


### Adding covariates and batches to mirnaCounts output: all.counts.txt

**4SeqGUI** provides an interface to add covariates and batches to all.counts.txt:

<img src="../inst/img/mirna_covars.jpeg" title="miRNAseq covariates and batches" alt="miRNAseq covariates and batches" width="100%" style="display: block; margin: auto;" />

The function **mirnaCovar** add to the header of all.counts.txt covariates and batches or covariates only.


```r
#test example
system("wget 130.192.119.59/public/test.mirna.analysis.zip")
unzip("test.mirna.analysis.zip")
setwd("test.mirna.analysis")
library(docker4seq)
mirnaCovar(experiment.folder=paste(getwd(), "all.counts.txt", sep="/"),
     covariates=c("Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.1",
                  "Cov.2", "Cov.2", "Cov.2", "Cov.2", "Cov.2", "Cov.2"),
     batches=c("bath.1", "bath.1", "bath.2", "bath.2", "batch.1", "batch.1",
               "batch.2", "batch.2","batch.1", "batch.1","bath.2", "bath.2"), output.folder=getwd())
```


The output of **mirnaCovar**, i.e. w\_covar\_batch\_all.counts.txt, is compliant with PCA, Sample size estimator, Experiment stat. power and DEseq2 analysis.

### miRNAseq workflow Tutorial

[**Tutorial experiment downloadable here**](http://130.192.119.59/public/test.mirnaCounts.zip):

- Six specimens for two experimental conditions

- single-end mode sequencing,

- 1 million reads for each sample.

**Experiment description**:

- Six blood circulating exosomes miRNA samples from healthy donors (hd) and six blood circulating exosomes miRNA samples from tumor patients (tum)

- from 1 to 3 hd and tum samples were harvested on day 1, from 5 to 6 hd and tum samples were harvested on day 2. Thus the data are require the addition of the batch effect in differential expression analysis.

The following data are available for download:

- [Fastq files for 6 miRNA samples from healthy donors (hd), and six miRNA samples from tumor patients (tum) to be used to calculate samples counts and organize them in a counts table](http://130.192.119.59/public/test.mrnaCounts_full.zip).

    + This data set allows running all the steps required to detect differentially expressed genes. The first step is the quantification of mature annotated miRNA and the generation of counts table to be used for differential expression, i.e. *this section*.

    + The covariates and batch effects can be added to the counts table (all.counts.txt), see *From samples to experiment* section. This table is used for differential expression genes detection.  

    + Subsequently the overall characteristics of the dataset can be explore via [PCA](https://www.youtube.com/watch?v=BfTMmoDFXyE), *Visualizing experiment data with PCA* section.

    + It is also possible to evaluate which is the statistical power of the experiment, i.e. identifying the fraction of genes/transcripts that can be identify giving the statistical structure of the experiment, or identify the optimal number of samples required to detect differentially expressed genes. More info in *Evaluating sample size and experiment power* section.

    + Differential expression can be then evaluate using the DESeq2 module, *Differential expression analysis with DESeq2*.


## chipseq workflow

The chipseq workflow can be run using **4SeqGUI** graphical interface:

<img src="../inst/img/chipseq0.jpeg" title="ChIPseq workflow" alt="ChIPseq workflow" width="100%" style="display: block; margin: auto;" />

The ChIPseq is made of two main steps:

- Creating a genome index for BWA (see end of this paragraph)

- Running MACS or SICER analysis

### Creating a BWA index file for Chipseq


The index can be easily created using the graphical interface:

<img src="../inst/img/chipseq1.jpeg" title="Creating a BWA index with Genome indexing BWA" alt="Creating a BWA index with Genome indexing BWA" width="100%" style="display: block; margin: auto;" />



```r
bwaIndexUcsc(group="sudo",genome.folder="/sto2/data/scratch/mm10bwa", uscs.urlgenome=
"http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz",
gatk=FALSE)
```

In brief, **bwaIndexUcsc** uses UCSC genomic data. User has to provide the URL (**uscs.urlgenome**) for the file chromFa.tar.gz related to the organism of interest and the path to the folder where the index will be generated (**genome.folder**). The parameter **gatk** has to be set to FALSE, it is not required for ChIPseq genomic index creation.

Precompiled index folders are available:

- [mm10bwa](http://130.192.119.59/public/mm10bwa.tar.gz)


### Calling peaks and annotating

All the parameters needed to run MACS or SICER can be setup using 4SeqGUI:

<img src="../inst/img/chipseq3.jpeg" title="MACS and SICER analysis" alt="MACS and SICER analysis" width="100%" style="display: block; margin: auto;" />

A detailed description of the parameters is given below.

### Chipseq workflow by line command

The chipseq workflow can be also executed using R and it is completely embedded in a unique function:


```r
system("wget 130.192.119.59/public/test.chipseqCounts.zip")
unzip("test.chipseqCounts.zip")
setwd("test.chipseqCounts")
library(docker4seq)
chipseqCounts(group = "docker", output.folder = "./prdm51.igg",
  mock.folder="./igg", test.folder="./prdm51", scratch.folder=getwd(),
  adapter5 = "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
  adapter3 = "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
  threads = 8, min.length = 30, genome.folder,
  mock.id = "igg", test.id = "tf", genome, read.size = 50,
  tool = "macs", macs.min.mfold = 10, macs.max.mfold = 30,
  macs.pval = "1e-5", sicer.wsize = 200, sicer.gsize = 200,
  sicer.fdr = 0.1, tss.distance = 0, max.upstream.distance = 10000,
  remove.duplicates = "N")
```

Specifically user needs to create three folders:

    + mock.folder, where the fastq.gz file for the control sample is located. For control sample we refer to ChIP with IgG only or input DNA.
    + test.folder, where the fastq.gz file for the ChIP of the sample to be analysed.
    + output.folder, where the R script embedding the above script is located.

The **scratch.folder** can be the same as the **output.folder**. However, if the system has a high speed disk for temporary calculation, e.g. a SSD disk, the location of the scratch.folder on the SSD will reduce significantly the computing time.

User needs to provide also the sequence of the sequencing adapters, **adapter5** and **adapter3** parameters. In case Illumina platform  the adapters sequences can be easily recovered [here](https://support.illumina.com/content/dam/illumina-support/documents/documentation/chemistry_documentation/experiment-design/illumina-adapter-sequences_1000000002694-01.pdf).

**Threads** indicates the max number of cores used by *skewer* and *bwa*, all the other steps are done on a single core.
The **min.length** refers to the minimal length that a reads should have after adapters trimming. Since today the average read length for a ChIP experiment is 50 or 75 nts would be better to bring to 40 nts the min.length parameter to increase the precision in assigning the correct position on the genome.

The **genome.folder** parameter refers to the location of the genomic index generated by bwa using the *docker4seq* function **bwaIndexUcsc**.

**mock.id** and **test.id** identify the type of sample and are assigned to the ID parameter in the RG field of the bam file.

**genome** is the parameter referring to the annotation used to associate ChIP peaks with genes. In the present implementation  hg38, hg19 for human and mm10 and mm9 for mouse annotations are available.

**read.size** is a parameter requested by MACS and SICER for their analysis.
**macs.min.mfold**, **macs.max.mfold**, **macs.pval**  are the default parameters requested for  peaks definition for more info please refer to the documentation of MACS 1.4.
**sicer.wsize**, **sicer.gsize**, **sicer.fdr** are the default parameters requested for  peaks definition for more info please refer to the documentation of SICER 1.1.
**IMPORTANT**: The optimal value for **sicer.gsize** in case of H3K4Me3 ChIP is 200 and in case of ChIP H3K27Me3 is 600.   

**tss.distance** and **max.upstream.distance** are parameters required by ChIPseqAnno, which is the Bioconductor package used to assign the peaks to specific genes. Specifically max.upstream.distance refers to the max distance in nts that allows the association of a peak to a specific gene.

**remove.duplicates** is the parameter that indicates if duplicates have to be removed or not. It has two options: **N** duplicates are not removed, **Y** duplicates are removed.


### Chipseq workflow output files

The chipseq workflow produces the following output files:

    + README: A file describing the content of the data folder
    + mypeaks.xls: All detected peaks alongside the nearest gene and its annotation
    + mytreat.counts: The total reads count for the provided treatment file
    + mycontrol.counts: The total reads count for the provided control/background file
    + peak_report.xls: Aggregate information regarding the peak and their position relative to the nearest gene
    + chromosome_distribution.pdf: Barplot of the distribution of the peaks on the chromosomes
    + relative_position_distribution.pdf: Barplot of the distribution of the peaks positions relative to their nearest gene
    + peak_width_distribution.pdf: Histogram of the distribution of the width of the peaks
    + distance_from_nearest_gene_distribution.pdf: Histogram of the distribution of the distance of each peak from its nearest gene
    + cumulative_coverage_total.pdf: Cumulative normalized gene coverage
    + cumulative_coverage_chrN.pdf: Cumulative normalized gene coverage for the specific chromosome
    + mycontrol_sorted.bw: bigWig file for UCSC Genome Browser visualization
    + mytreat_sorted.bw: bigWig file for UCSC Genome Browser visualization

### ChIPseq workflow tutorial

[**Tutorial experiment downloadable here**](http://130.192.119.59/public/test.chipseqCounts.zip):

    + Two ChIPseq one IgG control and an other Prdm5 TF moAb (mouse)

    + single-end mode sequencing,

    + 1 million reads for each sample.

**Experiment description**:

- PRDM family members are transcriptional regulators involved in tissue specific differentiation. PRDM5 has been reported to predominantly repress transcription, but a characterization of its molecular functions in a relevant biological context is lacking. Prdm5 controls both Collagen I transcription and fibrillogenesis by binding inside the Col1a1 gene body and maintaining RNA polymerase II occupancy (Galli et al. PLoS Genet. 2012,e1002711).

- The toy experiment is organized in three folders: i. one for IgG (igg, containing the igg pool down fastq); ii. one for Prdm5 (prdm5, containing the Prdm5 pool down fastq) and iii. the other for analysis output prdm5.igg, where MACS results will be located. The execution of the ChIPseq workflow using GUI or line command will provide the final annotated table of peaks (mypeaks.xls)





## PDX Exomeseq workflow

Patient derived tumor xenografts (PDTX) are created when cancerous tissue from a patient's primary tumor is implanted directly into an immunodeficient mouse. PDTX models are providing solutions to the challenges that researchers face in cancer drug research such as positive tumor responses in mouse models but not translating over when the study is implemented in humans. As a result, PDTX cancer models are popular models to use in cancer drug research.
Exome sequencing is an importnat step of the PCX characterization. IN PDX we have the human tumor mixex with the mouse stroma and it is necessary to remove the mouse information from the exome data.
One way of removing the mouse component is the use of [xenome](https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bts236), which performs fast, accurate and specific classification of xenograft-derived sequence read data [gossamer](https://github.com/data61/gossamer/blob/master/docs/xenome.md).

### Creating Xenome index files


The index can be easily created using the the following function:



```r
xenomeIndex(group="docker",xenome.folder="/data/scratch/hg19.mm10",
    hg.urlgenome="http://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz",
    mm.urlgenome="http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz", threads=8)
```

In brief, **xenomeIndex** uses UCSC genomic data. User has to provide the **hg.urlgenome** for the human chromFa.tar.gz, the **mm.urlgenome** for the mouse chromFa.tar.gz and the path to the folder where the index will be generated (**xenome.folder**). The parameter **threads** indicates how many threads the user would like to use.


### Running Xenome

Xenome classification can be run using the following code:


```r
system("wget http://130.192.119.59/public/mcf7_mouse_1m_R1.fastq.gz")
system("wget http://130.192.119.59/public/mcf7_mouse_1m_R2.fastq.gz")
#running xenome
xenome(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
         xenome.folder="/data/scratch/hg19.mm10", seq.type="pe",
         threads=8)
```

In brief, **xenome.folder** is the location of the output generated by **xenomeIndex**. The **scratch.folder** is the folder where temporary data are created. **seq.type** indicates if it is a pair-end **pe** or a single-end **se** sequence. The parameter **threads** indicates how many threads the user would like to use. **fastq.folder** is the folder were input fastq are located and where the output of xenome will be located.

## PDX data preprocessing HowTo

PDX data preprocessing is done stating from the fastq.gz file of a sample present in a user defined folder **fastq.folder**. Data preprocessing is done by **wrapperPdx** with embeds:

- **xenome** for mouse stromal data removal,

- **skewer** for adapter trimming,

- **bwa** for mapping and duplicates marking.

**IMPORTANT** In case the mutect v1 will be used it is necessary to use, a genome reference for **bwa** the following archive (61 GB):


```r
system("wget http://130.192.119.59/public/hg19_exome.tar.gz)
```

### wrapperPdx

PDX fastq preprocessing can be done with **wrapperPdx**.
These are the parameters to be passed:


```r
#example set made of 1 million reads of MCF7 exome data and 1 million reads of mouse genomic DNA pulled down with Illumina Nextera Rapid Capture Exome kit.

system("wget http://130.192.119.59/public/mcf7_mouse_1m_R1.fastq.gz")
system("wget http://130.192.119.59/public/mcf7_mouse_1m_R2.fastq.gz")

#running wrapperPdx
wrapperPdx(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
     xenome.folder="/data/scratch/hg19.mm10", seq.type="pe", threads=24,
     adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
     adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"
     min.length=40, genome.folder="/data/scratch/hg19_exome", sample.id="sampleX")
```

In brief, **xenome.folder** is the location of the output generated by **xenomeIndex**. The **scratch.folder** is the folder where temporary data are created. **seq.type** indicates if it is a pair-end **pe** or a single-end **se** sequence. The parameter **threads** indicates how many threads the user would like to use. **fastq.folder** is the folder were input fastq are located and where the output of xenome will be located.
User needs to provide also the sequence of the sequencing adapters, **adapter5** and **adapter3** parameters. In case Illumina platform the adapters sequences can be easily recovered [**here**](https://support.illumina.com/content/dam/illumina-support/documents/documentation/chemistry_documentation/experiment-design/illumina-adapter-sequences_1000000002694-01.pdf).
The **min.length** refers to the minimal length that a reads should have after adapters trimming. Since today the average read length for a RNAseq experiment is 50 or 75 nts would be better to bring to 40 nts the min.length parameter to increase the precision in assigning the correct position on the genome.
The **genome.folder** parameter refers to the location of the genomic index [**hg19_exome**](http://130.192.119.59/public/hg19_exome.tar.gz) required for **bwa**, see above.
**Sample.id** is a character string indicating the unique id to be associated to the bam that will be created.

### wrapperPdx output

The output of the function are three files:

- **xenome_folder**, which contains xeno_ambiguous_ (difficult to be classified as human or mouse),  xeno_both_ (classified in both mouse and human), xeno_mm_ (mouse specific reads), xeno_neither_ (not human or mouse, possibly adapter sequences) files.

- **xeno_hs_R1.fastq.gz**, xeno_hs_R2.fastq.gz, hg19 human associated reads, produced by xenome analysis and further processed by **wrapperPdx** to generated bam, bai and stats files.

- One or two gzip fastq files ending with **trimmed-pair1.fastq.gz** and **trimmed-pair1.fastq.gz**, a log file of the trimming with the extensione **trimmed.log**

- **dedup_reads.bam**, which is sorted and duplicates marked bam file generated by **bwa**,

- **dedup_reads.bai**, which is the index of the dedup_reads.bam generated by **bwa**,

- **dedup_reads.stats**, which provides mapping statistics generated by **bwa**.

### oncoSNP

The output of [oncoSNP](https://sites.google.com/site/oncosnp/) is used to associate to gene symbols the detected CN, rank 5 ([see oncoSNP help](https://sites.google.com/site/oncosnp/user-guide/interpreting-oncosnp-output)). This association is done using the *oncosnpAnnotation* function. The function requirements are the folder where the ouptut of oncoSNP is saved, i.e. where the file with extension .cnvs are located, and the folder where the ENSEMBL genome.gtf is located. The analysis returns for each .cnvs a file annotation_XXXXXX.cnvs.txt, which contains the genes location, gene symbol and CN and LOH ([see oncoSNP help](https://sites.google.com/site/oncosnp/user-guide/interpreting-oncosnp-output)). Please note


```r
system("wget http://130.192.119.59/public/test_oncosnp.zip")
system("unzip test_oncosnp.zip")

oncosnpAnnotation(group="docker", data.folder="./test_oncosnp/oncosnp_out", genome.folder="./test_oncosnp/hg19")
```
---
title: "Skeleton tutorial"
author: "Raffaele A Calogero"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::knitr}
  %\VignetteIndexEntry{Skeleton tutorial}
  %\VignetteEncoding{UTF-8}   

header-includes:
- \usepackage{makeidx}
- \makeindex
- \usepackage{setspace}\doublespacing
- \usepackage{pdfpages}


fig_caption: true
---

\newpage
\tableofcontents

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Dissecting the skeleton.R

The skeleton function allows to control a bash script, **skeleton.sh**, located in docker.io/repbioinfo/ubuntu image in /bin.

The skeleton function has three parameters:

```{r, echo=TRUE,eval=FALSE}
skeleton(group="docker", scratch.folder, data.folder)
```

- **group**, a character string. Two options: *sudo* or *docker*, depending to which group the user belongs

- **scratch.folder**, a character string indicating the path of the scratch folder. In principle the scratch folder is a temporary folder located in a disk with high I/O, e.g. a SSD disk, but if the fast disk is not available it represents only a temporary folder where the data generated by the application are saved.

- **data.folder**, a character string indicating the folder where input data are located and where output will be written

The first step in the skeleton function is storing the working folder and grabbing the process time for  subsequent performance evaluation.
```{r, echo=TRUE,eval=FALSE}
  #storing the position of the home folder  
  home <- getwd()
  #running time 1
  ptm <- proc.time()
```

Then, it is tested if docker demon is running,
```{r, echo=TRUE,eval=FALSE}
  #testing if docker is running
  test <- dockerTest()
  if(!test){
    cat("\nERROR: Docker seems not to be installed in your system\n")
    return()
  }
```

checking if data folder exists and setting it as working folder,
```{r, echo=TRUE,eval=FALSE}
  #setting the data.folder as working folder
  if (!file.exists(data.folder)){
    cat(paste("\nIt seems that the ",data.folder, " folder does not exist\n"))
    return(2)
  }
  setwd(data.folder)
```

checking if scratch folder exists and creating a temporary folder.
```{r, echo=TRUE,eval=FALSE}
  #check  if scratch folder exist
  if (!file.exists(scratch.folder)){
    cat(paste("\nIt seems that the ",scratch.folder, " folder does not exist\n"))
    return(3)
  }
  tmp.folder <- gsub(":","-",gsub(" ","-",date()))
  scrat_tmp.folder=file.path(scratch.folder, tmp.folder)
  writeLines(scrat_tmp.folder,paste(data.folder,"/tempFolderID", sep=""))
  cat("\ncreating a folder in scratch folder\n")
  dir.create(file.path(scrat_tmp.folder))
```

Executing the docker command:

* first is created a parameter string, which is made of:

    + --cidfile creates in data.folder the dockerID file that contains the docker job ID

    + -v the temporary folder, created in the scratch folder, is mounted as /scratch

    + -v the data folder is mounted as /data

    + -d docker.io/repbioinfo/ubuntu sh /bin/skeleton.sh is the command that executes the skeleton.sh script.

* the parameter string is passed to the runDocker that execute the job. runDocker check if docker is running and return **false** when is finished

```{r, echo=TRUE,eval=FALSE}
  #executing the docker job
  if(group=="sudo"){
    params <- paste("--cidfile ",data.folder,"/dockerID -v ",scrat_tmp.folder,":/scratch -v ", data.folder, ":/data -d docker.io/repbioinfo/ubuntu sh /bin/skeleton.sh", sep="")
    resultRun <- runDocker(group="sudo", params=params)
  }else{
    params <- paste("--cidfile ",data.folder,"/dockerID -v ",scrat_tmp.folder,":/scratch -v ", data.folder, ":/data -d docker.io/repbioinfo/ubuntu sh /bin/skeleton.sh", sep="")
    resultRun <- runDocker(group="docker", params=params)
  }
```


The **skeleton.sh** scripts in docker.io/repbioinfo/ubuntu is the following:

```{bash, echo=TRUE, eval=FALSE}
#!/bin/bash
echo "skeleton 0.0.1"
#setting the scratch folder as workinng directory
SCRATCH_FOLDER=/scratch
DATA_FOLDER=/data
#moving to scratch folder
cd $SCRATCH_FOLDER
#adding information to run.info file or creating a run.info file
file="run.info"
if [ -f "$file" ]
then
        echo "skeleton 0.0.1" >> $SCRATCH_FOLDER/run.info
else
        echo "skeleton 0.0.1" > $SCRATCH_FOLDER/run.info
fi
#writing the result file helloworld in data scratch
echo "hello world" > $SCRATCH_FOLDER/helloworld.txt
# creating the out.info file indicating that run is finished
echo "analysis is finished" > $SCRATCH_FOLDER/out.info
#changing the properties of files and folders in /data/scratch
chmod 777 -R $SCRATCH_FOLDER/*

```

It writes hello world in the **helloworld.txt** and moves **helloworld.txt** to the data folder together with the **run.info** file, used to store information about the run, and the **out.info**, used to tell to the R script when the doker job is finished.
The **skeleton.sh** scripts is a prototype for the handling of docker application(s).

Lets go back to the skeleton.R dissection:

The **resultRun** is used to check when the docker job is finished. The log of the docker job is saved with a name made of the first 12 letters of the docker job ID. Then, the docker container is deleted as well as the temporary folder and few other files: out.info, dockerID, tempFolderID. Finally the home folder is restored as working directory.

```{r, echo=TRUE, eval=FALSE}
 #when container ends
 if(resultRun=="false"){
   #everything is copied to the input folder
    system(paste("mv ", scrat_tmp.folder,"/* ",data.folder, sep=""))
     #saving log and removing docker container
    container.id <- readLines(paste(data.folder,"/dockerID", sep=""), warn = FALSE)
    system(paste("docker logs ", substr(container.id,1,12), " &> ", substr(container.id,1,12),".log", sep=""))
    system(paste("docker rm ", container.id, sep=""))
    #removing temporary folder
    cat("\n\nRemoving the temporary file ....\n")
    system(paste("rm -R ",scrat_tmp.folder))
    system("rm -fR out.info")
    system("rm -fR dockerID")
    system("rm  -fR tempFolderID")
    system(paste("cp ",paste(path.package(package="docker4seq"),"containers/containers.txt",sep="/")," ",data.folder, sep=""))
 }

```

Then, the computing time is estimated and saved in the run.info file
```{r, echo=TRUE, eval=FALSE}
  #running time 2
  ptm <- proc.time() - ptm
  dir <- dir(data.folder)
  dir <- dir[grep("run.info",dir)]
  if(length(dir)>0){
    con <- file("run.info", "r")
    tmp.run <- readLines(con)
    close(con)
    tmp.run[length(tmp.run)+1] <- paste("user run time mins ",ptm[1]/60, sep="")
    tmp.run[length(tmp.run)+1] <- paste("system run time mins ",ptm[2]/60, sep="")
    tmp.run[length(tmp.run)+1] <- paste("elapsed run time mins ",ptm[3]/60, sep="")
    writeLines(tmp.run,"run.info")
  }else{
    tmp.run <- NULL
    tmp.run[1] <- paste("run time mins ",ptm[1]/60, sep="")
    tmp.run[length(tmp.run)+1] <- paste("system run time mins ",ptm[2]/60, sep="")
    tmp.run[length(tmp.run)+1] <- paste("elapsed run time mins ",ptm[3]/60, sep="")
    writeLines(tmp.run,"run.info")
  }
```



```{r, echo=TRUE, eval=FALSE}
  setwd(home)
```
---
title: "An Introduction to docker4seq package and 4SeqGUI"
author: "Raffaele A Calogero"
output:
  rmarkdown::html_vignette:

    fig_caption: yes

vignette: >
  %\VignetteIndexEntry{An Introduction to docker4seq package and 4SeqGUI}
  %\VignetteEngine{knitr::knitr}
  %\usepackage[utf8]{inputenc}

---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'h')
```

## Introduction

The docker4seq package was developed to facilitate the use of computing demanding applications in the field of NGS data analysis.

The docker4seq package uses [docker](https://www.docker.com/what-docker) [containers](https://www.docker.com/what-container) that embed demanding computing tasks (e.g. short reads mapping) into isolated containers.

This approach provides multiple advantages:

- user does not need to install all the software on its local server;

- results generated by different containers can be organized in pipelines;

- reproducible research is guarantee by the possibility of sharing the docker images used for the analysis.

## Requirements

The minimal hardware requirements are a 4 cores 64 bits linux computer, 32 Gb RAM, one SSD 250GB, with a folder with read/write permission for any users (chmod 777), and [docker](https://www.docker.com/) installed.

### Setup

[**docker4seq**](https://github.com/kendomaniac/docker4seq) and its graphical interface (optional) [**4SeqGUI**](https://github.com/mbeccuti/4SeqGUI) can fit ideally in the [NUC6I7KYK, Intel mini-computer](https://www.intel.com/content/www/us/en/products/boards-kits/nuc/kits/nuc6i7kyk.html) equipped with Kingston Technology HyperX Impact 32GB Kit (2x16GB), 2133MHz DDR4 CL13 260-Pin SODIMM and Samsung 850 EVO - 250GB - M.2 SATA III Internal SSD.


**MANDATORY:** The first time *docker4seq* is installed the **downloadContainers** function needs to be executed to download, in the local repository, the docker images that are needed by *docker4seq*.

```{r, echo=TRUE, eval=FALSE}
library(docker4seq)
downloadContainers(group="docker")
```


## Dockers containers

At the present time all functions requiring some sort of calculation are embedded in the following docker images:

- docker.io/repbioinfo/demultiplexing.2017.01 used by demultiplexing

- docker.io/repbioinfo/annotate.2017.01 used by rnaseqCounts, rsemanno

- docker.io/repbioinfo/bwa.2017.01 used by bwaIndexUcsc, bwa, wrapperPdx

- docker.io/repbioinfo/chipseq.2017.01 used by chipseqCounts, chipseq

- docker.io/repbioinfo/r332.2017.01 used by experimentPower, sampleSize, wrapperDeseq2

- docker.io/repbioinfo/mirnaseq.2017.01 used by mirnaCounts

- docker.io/repbioinfo/rsemstar.2017.01 used by rnaseqCounts, rsemstarIndex, rsemstarUscsIndex

- docker.io/repbioinfo/skewer.2017.01 used by skewer, rnaseqCounts, wrapperPdx

- docker.io/repbioinfo/xenome.2017.01 used by xemone, xenomeIndex, wrapperPdx

### docker container nomenclature

In case of updates required to solve bugs, which do not affect the calculation docker.io/rcaloger/XXXXX.YYYY.ZZ the fiels ZZ will be updated.

In case of updates which affect the calculation, e.g. new release of Bioconductor libraries, the field YYYY will be updated. Previous versions will be maintained to  guarantee  the reproducibility of any previous analisys.

### Reproducibility

The file **containers.txt**, which indicates the Docker images available in the local release of docker4seq is saved within any folder generated with docker4seq functions.

In case, user would like to download a set of dockers images different from those provided as part of the package, then these images must be specified in a file with the following format **docker.repository/user/docker.name**, which has to be passed to downloadContainers function:

```{r, echo=TRUE, eval=FALSE}
downloadContainers(group="docker", containers.file="my_containers.txt")
#an example of the my_containers.txt file content
docker.io/rcaloger/bwa.2017.01
docker.io/rcaloger/chipseq.2017.01
docker.io/rcaloger/r340.2017.01
```


## Available workflows
At the present time are available the following workflows:

- **mRNAseq**, which allows:
    + adapter trimming with [skewer](https://github.com/relipmoc/skewer)
    + mapping with [STAR](https://github.com/alexdobin/STAR)
    + counting genes and isoforms with [RSEM](http://deweylab.github.io/RSEM/)
    + as option to STAR/RSEM it is possible to use **SALMON**, which is does reference-free transcripts quantification.
    + ENSEMBL gene annotation.
    + organizing the output of RSEM in tables to be used for differential expression analysis
    + visualizing experiment data with PCA
    + evaluating experiment power and sample size
    + detecting differentially expressed genes/isoforms
    + subsetting counts/FPKM and TPM table to have only differentially expressed genes, suitable for heatmaps generation.
- **miRNAseq**, which executes the workflow described in Cordero et al. PLoS One. 2012;7(2):e31630, embedding the following steps:
    + trimming adapters with [cutadapt](http://cutadapt.readthedocs.io/en/stable/guide.html)
    + miRNAs mapping on [mirbase](http://www.mirbase.org/) hairpins using [SHRiMP](http://compbio.cs.toronto.edu/shrimp/)
    + quantification of mature miRNAs.
    + visualizing experiment data with PCA
    + evaluating experiment power and sample size
    + detecting differentially expressed miRNAs
- **ChIPseq**, which allows:
    + adapter trimming with [skewer](https://github.com/relipmoc/skewer)
    + mapping with [BWA](http://bio-bwa.sourceforge.net/bwa.shtml)
    + peak calling using either MACS v 1.4 or SICER v 1.1
    + associating peaks to the nearest gene, UCSC annotation
    + full annotation of the nearest gene
- **PDX Exomeseq**, which allows:
     + mouse sequence removal with [xenome](https://github.com/data61/gossamer)
     + adapter trimming with [skewer](https://github.com/relipmoc/skewer)
     + mapping with [BWA](http://bio-bwa.sourceforge.net/bwa.shtml)
     + annotating the output of oncoSNP


The most expensive computing  steps of the analyses are embedded in the following docker4seq functions: **rnaseqCounts**, **mirnaCounts**, **chipseqCounts**. These functions are also the only having RAM and computing power requirements not usually available in consumer computers. Hereafter it is shown the time required to run the above three functions increasing the number of sequenced reads.

### testSeqbox
In *docker4seq* is now present the function *testSeqbox*, which allows to evaluate if the software required for docker4seq functionalities is properly installed. Results of the tests are saved in testSeqBox.out file.

### rnaseqCounts performances

Counts generation from fastq files  is the most time consuming step in RNAseq data analysis and it is usually calculated using high-end servers. We compare the behabiour of **rnaseqCounts** on SeqBox and on a high-end server:

    + SeqBox: NUC6I7KYK CPU i7-6770HQ 3.5 GHz (1 core, 8 threads), 32 Gb RAM, HD 250 Gb SSD
    + SGI UV200 server: CPU E5-4650 v2 2.40GHz (8 cores, 160 threads), 1 Tb RAM, RAID 6, 100 Tb SATA


We run respectively 26, 52, 78, and 105 million reads using different number of threads, values shown in parenthesis in figure below. It is notable that SeqBox, mapping in 5 hours more than 100 milion reads, it is able to handle in 20 hours the throughput of the Illumina benchtop sequencer NextSeq 500, which produces up to 400 milion reads in a run of 30 hours.

```{r fig.1, fig.cap="rnaseqCounts overall performance", echo=FALSE, eval=TRUE, out.width="70%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/mrna_performance_bis.jpg')

```




### mirnaCounts performances

We run respectively 3, 6, 12, and 24 miRNA samples in parallel using **mirnaCounts**, with different number of threads, values shown in parenthesis in figure below.

```{r fig.2, fig.cap="mirnaCounts overall performance", echo=FALSE, eval=TRUE, out.width="70%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/mirnaseq_performance_bis.jpg')

```


### chipseqCounts performances

We run respectively 37, 70, 111, and 149 million reads using different number of threads, values shown in parenthesis in figure below.

```{r fig.3, fig.cap="chipseqCounts overall performance", echo=FALSE, eval=TRUE, out.width="70%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/chipseq_performance_bis.jpg')

```


From the point of view of parallelization the **rnaseqCounts** is the one that embeds the most computing demanding tools: i) mapping with STAR and ii) quantifying transcripts with RSEM. Both these tools were design to take advantage of multiple cores hardware architecture and they also require massive I/O. On the basis of the results shown in *Figure 1* parallelization does not improve very much the overall performances, even if it can mitigate the gap w.r.t. SeqBox due to the poor I/O performance of the SATA disk array. On the other side the presence of a SSD with very high I/O performance can remedy the limited amount of cores of SeqBox.

In the case of **mirnaCounts** and **chipseqCounts** the parallelization is very little and it is only available for the reads mapping procedure. Moreover, both functions have a massive I/O. The reduced parallelization of these two analyses combined with the higher I/O throughput of the SSD with respect to the SATA array makes SeqBox extremely effective even with very high number of reads to be processed, *Figure 2  and 3*.

## Test sets

A folder including a set do dataset to test each of the workflows available in docker4seq/4SeqGUI can be found [**here**](http://130.192.119.59/public/test.zip)



## RNAseq workflow: Howto

### Demultiplexing

*demultiplexing* function is used to convert in fastq bcl files generated by an Illumina sequencer. The function requires that in the bcl folder the SampleSheet.csv is present. An example fo SampleSheet for a pair-end run is present in docker4seq examples folder. The function require that the full path to the bcl file folder is provided, **data.folder**, the scratch folder where temporary analysis is run and the number of cores that will be used by the program.

```{r,  echo=TRUE, eval=FALSE}
demultiplexing(group="docker",
      data.folder="/home/calogero/Documents/data/lollini/3a_run/170712_NB501050_0097_AH3FGNBGX3",
      scratch.folder="/data/scratch", threads=24)
```

The function will return, in the folder containing the bcl files folder, e.g. \/home\/calogero\/Documents\/data\/lollini\/3a_run\/, the fastq files generated by the analysis.

This function is not implemented in **4SeqGUI** because this step is generally done by a core lab. Thus only a limited group of users require the use of this function.

The **mRNAseq workflow**, that can be handled using **4SeqGUI** graphical interface (linux/MAC) (figure below), starts from the availability of fastq files .

```{r fig.4, fig.cap="mRNAseq workflow", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/rnaseq1.jpeg')

```


Sample quantification is made of these steps:

- Creating a genome index for STAR (see end of this paragraph)

- Running removing sequencing adapters

- Mapping reads to the reference genome

- Quantify gene and transcript expression level

- Annotating genes.

All the parameters can be setup using 4SeqGUI

### Creating a STAR index file for mRNAseq

The index can be easily created using the graphical interface:

```{r fig.5, fig.cap="Creating a STAR genome index", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/rnaseq2.jpeg')

```


A detailed description of the parameters is given below.

#### Creating a STAR index file by line command

\fontsize{8}{8}\selectfont
```{r,  echo=TRUE, eval=FALSE}
rsemstarIndex(group="docker",genome.folder="/data/scratch/hg38star",
ensembl.urlgenome="ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz",
ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.gtf.gz")
```

In brief, **rsemstarIndex** uses ENSEMBL genomic data. User has to provide the URL (**ensembl.urlgenome**) for the file XXXXX_dna.toplevel.fa.gz related to the organism of interest, the URL (**ensembl.urlgtf**) for the annotation GTF XXX.gtf.gz and the path to the folder where the index will be generated (**genome.folder**). The parameter **threads** indicate the number of cores dedicated to this task.

Precompiled index folders are available:

- [hg38star](http://130.192.119.59/public/hg38star.tar.gz)

- [mm10star](http://130.192.119.59/public/mm10star.tar.gz)



### Quantifying genes/isoforms


```{r fig.6, fig.cap="Gene, Isoform counting", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/rnaseq3.jpeg')

```


A detailed description of the parameters is given below.

#### Sample quantification by line command

The sample quantification can be also executed using R and it is completely embedded in a single function:

```{r, echo=TRUE, eval=FALSE}

#test example
system("wget http://130.192.119.59/public/test.mrnaCounts.zip")
unzip("test.mrnaCounts.zip")
setwd("./test.mrnaCounts")
library(docker4seq)
rnaseqCounts(group="docker",fastq.folder=getwd(), scratch.folder=getwd(),
adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
seq.type="se", threads=8,  min.length=40,
genome.folder="/data/scratch/mm10star", strandness="none", save.bam=FALSE,
org="mm10", annotation.type="gtfENSEMBL")

```


User needs to create the **fastq.folder**, where the fastq.gz file(s) for the sample under analysis are located.
The **scratch.folder** is the location where temporary data are created. The results will be then saved in the **fastq.folder**.

User needs to provide also the sequence of the sequencing adapters, **adapter5** and **adapter3** parameters. In case Illumina platform the adapters sequences can be easily recovered [**here**](https://support.illumina.com/downloads/illumina-customer-sequence-letter.html).

**seq.type** indicates if single-end (se) or pair-end (pe) data are provided, **threads** indicates the max number of cores used by *skewer* and *STAR*, all the other steps are done on a single core.

The **min.length** refers to the minimal length that a reads should have after adapters trimming. Since today the average read length for a RNAseq experiment is 50 or 75 nts would be better to bring to 40 nts the min.length parameter to increase the precision in assigning the correct position on the genome.

The **genome.folder** parameter refers to the location of the genomic index generated by STAR using the *docker4seq* function **rsemstarIndex**, see above paragraph.


**strandness**, is a parameter referring to the kit used for the library prep. If the kit does not provide strand information it is set to "none", if provides strand information is set to "forward" for  Illumina stranded kit and it set to "reverse" for Illumina ACCESS kit. **save.bam** set to TRUE indicates that genomic bam file and transcriotomic bam files are also saved at the end of the analysis. **annotation.type** refers to the type of available gene-level annotation. At the present time is only available ENSEMBL annotation defined by the gtf downloaded during the creation of the indexed genome files, see paragraph *at the end*Creating a STAR index file for mRNAseq*.


### Salmon, reference free alignment

Recently Zhang and coworkers (BMC Genomics 2017, 18,583) compared, at transcript level, alignment-dependent tools (Salmon_aln, eXpress, RSEM and TIGAR2) and aligner-free methods (Salmon, Kallisto Sailfish). In their paper, STAR was used as mapping tool for all alignment-dependent tools. In terms of isoform quantification, the authors indicated that there is strong concordance among quantification results from RSEM, Salmon, Salmon_aln, Kallisto and Sailfish (R2 > 0.89), suggesting that the impact of mappers on isoform quantification is small. Furthermore, the paper of Teng and coworkers (Genome Biology 2016, 17,74) reported that,in term of gene-level quantification, differences between alignment-dependent tools and aligner-free methods are shrinking with respect to transcripts level analysis.
On the basis of the above papers it seems that from the quantification point of view the difference between alignment free and alignment-dependent tools is very limited.
However, aligner-free methods have low memory requirements and we added Salmon in docker4seq.

#### Creating a Salmon quasi-reference file for mRNAseq

The quasi-reference can be created using cDNA fasta files available at ENSEMBL. The corresponding genomics GTF is required for the gene level annotation:


```{r fig.7, fig.cap="Salmon reference", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/salmonIndex.jpeg')

```


```{r, echo=TRUE, eval=FALSE}

#running salmonIndex human
salmonIndex(group="docker", index.folder=getwd(),
       ensembl.urltranscriptome="ftp://ftp.ensembl.org/pub/release-90/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz",
       ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-90/gtf/homo_sapiens/Homo_sapiens.GRCh38.90.gtf.gz",
       k=31)

```


#### Quantifying isoforms and genes with Salmon

Salmon quantification function *wrapperSalmon* has the same structure of *rnaseqCounts*. It performs adapters trimming, transcripts quantification, genes quantification and annotation.  The output of wrapperSalmon is identical to the output of rnaseqCounts for what concern the files **isoforms.results** and **gtf_annotated_genes.results**, which can be used by *samples2experiment* to generate the tables for differential expression analysis:


```{r fig.8, fig.cap="Salmon quantification", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/salmonCounts.jpeg')

```


```{r, echo=TRUE, eval=FALSE}

system("wget http://130.192.119.59/public/test_R1.fastq.gz")
system("wget http://130.192.119.59/public/test_R2.fastq.gz")

#running salmonCounts
wrapperSalmon(group="docker", scratch.folder="/data/scratch/",
         fastq.folder=getwd(), index.folder="/data/genome/salmonhg38/",
         threads=8, seq.type="pe", adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
         adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT", min.length=40, strandness="none")

```


**IMPORTANT**: Salmon produces only isoforms-level counts, thus we quantified gene-level counts as described by RSEM:

- Gene counts are gived by the sum of the counts associated to all transcripts associated to the gene locus.

- Gene-length is given by the mean length of the transcripts having counts greater than 0 or by the mean of all the transcripts annotated in the gene locus in case all transcripts have counts equal to 0.

However, there are some differences between the information present in RSEM and Salmon annotation:

|                       |  RSEM  | SALMON |
|:---------------------:|:------:|:------:|
| Annotated transcripts | 197898 | 164819 |
|    Annotated genes    |  57955 |  34912 |
|        Biotypes       |   43   |   24   |

The biotypes lacking in Salmon are 20, because the pseudo-reference is build using ENSEMBL cDNA fasta file:

processed_transcript, antisense, lincRNA, sense_intronic, sense_overlapping, 3prime_overlapping_ncRNA, bidirectional_promoter_lncRNA, snRNA,
miRNA, misc_RNA, snoRNA, rRNA, ribozyme, TEC, scRNA, scaRNA, vaultRNA, sRNA, macro_lncRNA, non_coding.

Furthermore, the data generated by SALMON do not overlap perfectly to RSEM output:


```{r fig.9, fig.cap="RSEM versus SALMON", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/salmon_rsem.jpg')

```

Panel A above indicates that although there is a limited correlation between SALMON and RSEM expected counts (black) at transcript-level, **R2=0.35**, some transcripts are detected with more counts by SALMON, see vertical spikes. SALMON TPMs are generally higher of those estimated in RSEM (Panel A, red). This behavior is still present at gene-level (Panel B) and the R2 for the expected counts is **0.56**. The correlation between SALMON and RSEM at counts level (transcripts/genes) is always better of that observed at FPKM or TPM level.
It is notable that length estimation between SALMON and RSEM is well correlated only for transcripts/genes bigger than 100 nts (Panels C, D).



### Sample quantification output files

The mRNAseq workflow produces the following output files:

    + XXXXX-trimmed.log, containing the information related to the adapters trimming
    + gtf_annotated_genes.results, the output of RSEM gene quantification with gene-level annotation
    + Log.final.out, the statistics of the genome mapping generated by STAR  
    + rsem.info, summary of the parameters used in the run
    + genes.results, the output of RSEM gene quantification
    + isoforms.results, the output of RSEM isoform quantification
    + run.info, some statistics on the run
    + skewerd_xxxxxxxxxxxx.log, log of the skewer docker container
    + stard.yyyyyyyyyyyy.log, log of the star docker container

```{r fig.10, fig.cap="gtf_annotated_genes.results", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/rnaseq7.jpeg')

```


In the figure above, the first column in **gtf_annotated_genes.results** is the ensembl gene id, the second is the [biotype](http://www.ensembl.org/Help/Faq?id=468),
the 3rd is the annotation source, the 4th contains the set of transcripts included in the ensembl gene id. Then there is the length of the gene, the lenght of the gene to which is subtracted the average length of the sequenced fragments, the expected counts are the counts to be used for differential expression analysis. [TPM](https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) and [FPM](https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) are normalized gene quantities to be used only for visualization purposes.

### From samples to experiment

The RSEM output is sample specific, thus it is necessary to assemble the single sample in an experiment table including in the header of the column both the covariates and the batch, if any.
The header sample name is separated by the covariate with an underscore, e.g. mysample1\_Cov1, mysample2\_Cov2:

```{r fig.11, fig.cap="counts table with covariates", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/counts1.jpeg')

```


In case also a batch is present also this is added to the sample name through a further underscore, e.g. mysample1\_Cov1\_batch1, mysample2\_Cov\_batch2:

```{r fig.12, fig.cap="counts table with covariates and batch", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/counts2.jpeg')

```


The addition of the covariates to the various samples can be done using the **4seqGUI** using the button: *From samples to experiment*:

```{r fig.13, fig.cap="generating a table with covariates", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/counts3.jpeg')

```


#### From samples to experiments by line command

```{r, echo=TRUE, eval=FALSE}
#test example
system("wget http://130.192.119.59/public/test.samples2experiment.zip")
unzip("test.samples2experiment.zip")
setwd("test.samples2experiment")
library(docker4seq)
sample2experiment(sample.folders=c("./e1g","./e2g","./e3g",
"./p1g", "./p2g", "./p3g"),
covariates=c("Cov.1","Cov.1","Cov.1","Cov.2","Cov.2","Cov.2"),
bio.type="protein_coding", output.prefix=".")

```

User needs to provide the paths of the samples, **sample.folder** parameter, a vector of the covariates, **covariates**, and the biotype(s) of interest, **bio.type** parameter. The parameter **output.prefix** refers to the path where the output will be created, as default this is the current R working folder.

#### From samples to experiments output files

The samples to experiments produces the following output files:

    + _counts.txt: gene-level raw counts table for differential expression analysis
    + _isoforms_counts.txt: isoform-level raw counts table for differential expression analysis
    + _isoforms_log2TPM.txt: isoform-level log2TPM for visualization purposes
    + _log2TPM.txt: gene-level log2TPM for visualization purposes
    + _isoforms_log2FPKM.txt: isoform-level log2FPKM for visualization purposes
    + _log2FPKM.txt: gene-level log2FPKM for visualization purposes
    + XXXXX.Rout: logs of the execution



### Visualizing experiment data with PCA

[PCA](https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. This transformation is defined in such a way that the first principal component accounts for as much of the variability in the data as possible, and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components.
**4SeqGUI** provides an interface to the generation experiment samples PCA:

```{r fig.14, fig.cap="PCA", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/pca1.jpeg')

```


The plot is saved in **pca.pdf** in the selected folder.

#### PCA by line command

```{r, echo=TRUE, eval=FALSE}
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
pca(experiment.table="_log2FPKM.txt", type="FPKM", legend.position="topleft", covariatesInNames=FALSE, principal.components=c(1,2), pdf = TRUE, output.folder=getwd())

```

User needs to provide the paths of experiment table, **experiment.table** parameter, i.e. the file generated using the samples2experiment function. The **type** parameter indicates if FPKM, TPM or counts are used for the PCA generation. The parameter **legend.position** defines where to locate the covariates legend. The parameter **covariatesInNames** indicates if the header of the experiment table contains or not covariate information. The parameter **principal.components** indicates which principal components should be plotted. **output.folder** indicates where to save the pca.pdf file:

```{r fig.15, fig.cap="pca.pdf", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/pca2.jpeg')

```


The values in parentesis on x and y axes are the amount of variance explained by each principal component.

IMPORTANT: The above analysis is suitable also for miRNAseq data

### Evaluating sample size and experiment power

Sample size estimation is an important issue in the design of RNA sequencing experiments. Furthermore, experiment power provides an indication of which is the fraction of differentially expressed genes that can be detected given a specific number of samples and differential expression detection thresholds.
[RnaSeqSampleSize](https://www.ncbi.nlm.nih.gov/pubmed/25246651) Bioconductor package provides the possibility to calculate, from a pilot experiment, the statistical power and to define the optimal sample size.
We have implemented wrapper functions to  RnaSeqSampleSize sample size and experiment power estimation.


**4SeqGUI** provides an interface to sample size estimation:

```{r fig.16, fig.cap="sample size estimation", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/ss.jpeg')

```

and to statistical power estimation:

```{r fig.17, fig.cap="experiment power estimation", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/es.jpeg')

```


#### Sample size estimation by line command

```{r, echo=TRUE, eval=FALSE}
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
sampleSize(group="docker", filename="_counts.txt", power=0.80, FDR=0.1, genes4dispersion=200, log2fold.change=1)

```

The requested parameters are the path to the counts experiment table generated by **samples2experiment** function. The param **power** indicates the expected fraction of differentially expressed gene, e.g 0.80. **FDR** and **log2fold.change**  are the two thresholds used to define the set of differentially expressed genes of interest.

The output file is **sample_size_evaluation.txt** is saved in the R working folder, below an example of the file content:

```{r fig.18, fig.cap="sample_size_evaluation.txt", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/samplesize1.jpeg')

```

IMPORTANT: The above analysis is suitable also for miRNAseq data


#### Experiment statistical power estimation by line command

```{r, echo=TRUE, eval=FALSE}
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
experimentPower(group="docker", filename="_counts.txt",replicatesXgroup=7, FDR=0.1, genes4dispersion=200, log2fold.change=1)

```


The requested parameters are the path to the counts experiment table generated by **samples2experiment** function. The param **replicatesXgroup** indicates the number of sample associated with each of the two covariates. **FDR** and **log2fold.change**  are the two thresholds used to define the set of differentially expressed genes of interest. **genes4dispersion** indicates the number of genes used in the estimation of read counts and dispersion distribution.

The output file is **power_estimation.txt** is saved in the R working folder, below an example of the file content:

```{r fig.19, fig.cap="power_estimation.txt", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/expp1.jpeg')

```


IMPORTANT: The above analysis is suitable also for miRNAseq data

### Differential expression analysis with DESeq2

A basic task in the analysis of count data from RNA-seq is the detection of differentially expressed genes.
**4SeqGUI** provides an interface to DESeq2 to simplify differential expression analysis:

```{r fig.20, fig.cap="DESeq2", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/de1.jpeg')

```

The output files are:

**DEfull.txt** containing the full set of results generated by DESeq2:

```{r fig.21, fig.cap="DEfull.txt", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/de2.jpeg')

```

**DEfiltered_log2fc_X_fdr_Y.Y.txt** containing the set of differentially expressed genes passing the indicated thresholds:

```{r fig.22, fig.cap="DEfiltered_log2fc_1_fdr_0.1.txt", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/de3.jpeg')

```

**genes2go.txt** a file containing only the gene symbols to be used as input for [DAVID](https://david.ncifcrf.gov/) or [ENRICHR](http://amp.pharm.mssm.edu/Enrichr/)

log2normalized_counts.txt, log2 library size normalized counts, calculated by DESeq2, that can be used for visualization purposes.

#### DESeq2 by line command

```{r, echo=TRUE, eval=FALSE}
#test example
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
wrapperDeseq2(output.folder=getwd(), group="docker",
      experiment.table="_counts.txt", log2fc=1, fdr=0.1,
      ref.covar="Cov.1", type="gene", batch=FALSE)
```


User has to provide experiment table, **experiment.table** param, i.e. the counts table generated with **samples2experiment** function, the thresholds for the differential expression analysis, **log2fc** and **fdr** params, the reference covariate, **ref.covar** param, i.e. the covariate that is used as reference for differential expression detection, the **type** param, which refers to the type of experiment table in use: *gene*, *isoform*, *mirna*, **batch** parameter that indicates, if it is set to **TRUE** that the header of the experiment table also contains the extra information for the batch effect (see above).

IMPORTANT: the above analysis can be also applied to miRNAseq data.

### Subsetting counts/FPKM/TPM with differentially expressed genes

The function *filterCounts* allows to generate counts/FPKM/TPM tables that contains only differentially expressed genes. These tables can be used for visualization purposes, e.g. hetmaps generation with [**ClustVis**](https://biit.cs.ut.ee/clustvis/):

```{r fig.23, fig.cap="Count Filter", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/filtercounts.jpeg')

```

#### filterCounts

```{r, echo=TRUE, eval=FALSE}
system("wget 130.192.119.59/public/test.analysis.zip")
unzip("test.analysis.zip")
setwd("test.analysis")
library(docker4seq)
     wrapperDeseq2(output.folder=getwd(), group="docker", experiment.table="_counts.txt", log2fc=1,
     fdr=0.1, ref.covar="Cov.1", type="gene", batch=FALSE))

    filterCounts(data.folder=getwd(), type="gene")

```

IMPORTANT: the above analysis can be also applied to miRNAseq data, using for the type parameter **mirna**. In this case also mean centered CPMs are calculated (**NOTE: DE filtered CPM are log2 transformed!**).

The outputs of **filterCounts** function start with **DEfiltered**.  Mean centered data indicates that for each gene count is divided by the mean of that gene over all samples. This representation is more convenient to observe changes between experimental groups.


### RNAseq workflow Tutorial

[**Tutorial experiment downloadable here**](http://130.192.119.59/public/test.mrnaCounts_full.zip):

    + Three replicates for two experimental conditions

    + single-end mode sequencing

    + 1 million reads for each sample

**Experiment description**:

    + 4T1 mouse cell line grown in standard DMEM medium (e) is compared with the same cells grown in low attachment medium (p)

The following data are available for download:

- [Fastq files for 3 samples grown in standard DMEM medium (e) and for 3 samples grown in low attachment medium (p) to be used to calculate samples counts](http://130.192.119.59/public/test.mrnaCounts_full.zip).

    + This data set allows running all the steps required to detect differentially expressed genes. The first step is the quantification of genes and isoforms via mapping reads to the reference genome via STAR and using this mapping information to quantify genes and transcripts using RSEM, i.e. *this section*.

    + The RSEM counts table, generated for all samples, are combined in a unique table, see *From samples to experiment* section. This table is used for differential expression genes detection. For visualization purposes  log2 FPKM and log2 TPM tables are also generated, see *From samples to experiment* section. More info on the FPKM and TPM are available [here](http://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/).

    + Subsequently the overall characteristics of the dataset can be explore via [PCA](https://www.youtube.com/watch?v=BfTMmoDFXyE), *Visualizing experiment data with PCA* section.

    + It is also possible to evaluate which is the statistical power of the experiment, i.e. identifying the fraction of genes/transcripts that can be identify giving the statistical structure of the experiment, or identify the optimal number of samples required to detect differentially expressed genes. More info in *Evaluating sample size and experiment power* section.

    + Differential expression can be then evaluate using the DESeq2 module, *Differential expression analysis with DESeq2*.


- Furthermore, also intermediate results are provided:

    + [The counts tables generated by STAR+RSEM analysis to be used to assemble counts, TPM and FPKM experiment tables](http://130.192.119.59/public/test.samples2experiment.zip)

    + [The experiment tables that can be used to study samples organization via PCA or the statistical characteristics of the experiment, i.e. the statistical power and the optimal sample size of the experiment](http://130.192.119.59/public/test.analysis.zip)

    + The above data set can be used also to detect differentially expressed genes and isoforms using the DESeq2 module.



## miRNAseq workflow

The miRNAseq workflow can be run using **4SeqGUI** graphical interface:

```{r fig.24, fig.cap="miRNAseq workflow", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/mirna1.jpeg')

```

The miRNAseq docker container executes the following steps:

```{r fig.25, fig.cap="miRNAseq workflow", echo=FALSE, eval=TRUE, out.width="50%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/mirna3.jpeg')

```

The full workflow is described in [Cordero et al. Plos ONE 2012](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0031630). In brief, fastq files are trimmed using [cutadapt](https://github.com/marcelm/cutadapt) and the trimmed reads are mapped on miRNA precursors, i.e. harpin.fa file, from [miRBase](http://www.mirbase.org/ftp.shtml) using [SHRIMP](http://compbio.cs.toronto.edu/shrimp/). Using the location of the mature miRNAs in the precursor, countOverlaps function, from the Bioconductor package GenomicRanges is used to quantify the reads mapping on mature miRNAs.


All the parameters needed to run the miRNAseq workflow can be setup using 4SeqGUI:

```{r fig.26, fig.cap="miRNAseq parameters", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/mirna2.jpeg')

```

A detailed description of the parameters is given below.

### miRNAseq workflow by line command

The miRNAseq workflow can be also executed using R and it is completely embedded in a unique function:

```{r, echo=TRUE, eval=FALSE}
#test example
system("wget 130.192.119.59/public/test.mirnaCounts.zip")
unzip("test.mirnaCounts.zip")
setwd("test.mirnaCounts")
library(docker4seq)
mirnaCounts(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
            mirbase.id="hsa",download.status=FALSE, adapter.type="NEB", trimmed.fastq=FALSE)

```

User has to create the **fastq.folder**, where the fastq.gz files for all miRNAs under analysis are located.
The **scratch.folder** is the location where temporary data are created. The results will be then saved in the **fastq.folder**.
User has to provide also the identifier of the miRBase organism, e.g. **hsa** for Homo sapiens, **mmu** for Mus musculus.  If the **download.status** is set to FALSE, mirnaCounts uses miRBase release 21, if it is set to TRUE the lastest version of precursor and mature miRNAs will be downloaded from miRBase. Users need to provide the name of the producer of the miRNA library prep kit to identify which adapters need to be provided to cutadapt, **adapter.type** parameter. The available adapters are NEB and Illumina, but, upon request, we can add other adapters. Finally, if the **trimmed.fastq** is set to FALSE the trimmed fastq are not saved at the end of the analysis.


### miRNAseq workflow output files

The miRNAseq workflow produces the following output files:

    + README: A file describing the content of the data folder
    + all.counts.txt: miRNAs raw counts, to be used for differential expression analysis
    + trimmimg.log: adapters trimming statistics
    + shrimp.log: mapping statistics
    + all.counts.Rda: miRNAs raw counts ready to be loaded in R.
    + analysis.log: logs of the full analysis pipeline


### Adding covariates and batches to mirnaCounts output: all.counts.txt

**4SeqGUI** provides an interface to add covariates and batches to all.counts.txt:

```{r fig.27, fig.cap="miRNAseq covariates and batches", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/mirna_covars.jpeg')

```

The function **mirnaCovar** add to the header of all.counts.txt covariates and batches or covariates only.

```{r, echo=TRUE, eval=FALSE}
#test example
system("wget 130.192.119.59/public/test.mirna.analysis.zip")
unzip("test.mirna.analysis.zip")
setwd("test.mirna.analysis")
library(docker4seq)
mirnaCovar(experiment.folder=paste(getwd(), "all.counts.txt", sep="/"),
     covariates=c("Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.1",
                  "Cov.2", "Cov.2", "Cov.2", "Cov.2", "Cov.2", "Cov.2"),
     batches=c("bath.1", "bath.1", "bath.2", "bath.2", "batch.1", "batch.1",
               "batch.2", "batch.2","batch.1", "batch.1","bath.2", "bath.2"), output.folder=getwd())
```


The output of **mirnaCovar**, i.e. w\_covar\_batch\_all.counts.txt, is compliant with PCA, Sample size estimator, Experiment stat. power and DEseq2 analysis.

### miRNAseq workflow Tutorial

[**Tutorial experiment downloadable here**](http://130.192.119.59/public/test.mirnaCounts.zip):

- Six specimens for two experimental conditions

- single-end mode sequencing,

- 1 million reads for each sample.

**Experiment description**:

- Six blood circulating exosomes miRNA samples from healthy donors (hd) and six blood circulating exosomes miRNA samples from tumor patients (tum)

- from 1 to 3 hd and tum samples were harvested on day 1, from 5 to 6 hd and tum samples were harvested on day 2. Thus the data are require the addition of the batch effect in differential expression analysis.

The following data are available for download:

- [Fastq files for 6 miRNA samples from healthy donors (hd), and six miRNA samples from tumor patients (tum) to be used to calculate samples counts and organize them in a counts table](http://130.192.119.59/public/test.mrnaCounts_full.zip).

    + This data set allows running all the steps required to detect differentially expressed genes. The first step is the quantification of mature annotated miRNA and the generation of counts table to be used for differential expression, i.e. *this section*.

    + The covariates and batch effects can be added to the counts table (all.counts.txt), see *From samples to experiment* section. This table is used for differential expression genes detection.  

    + Subsequently the overall characteristics of the dataset can be explore via [PCA](https://www.youtube.com/watch?v=BfTMmoDFXyE), *Visualizing experiment data with PCA* section.

    + It is also possible to evaluate which is the statistical power of the experiment, i.e. identifying the fraction of genes/transcripts that can be identify giving the statistical structure of the experiment, or identify the optimal number of samples required to detect differentially expressed genes. More info in *Evaluating sample size and experiment power* section.

    + Differential expression can be then evaluate using the DESeq2 module, *Differential expression analysis with DESeq2*.


## chipseq workflow

The chipseq workflow can be run using **4SeqGUI** graphical interface:

```{r fig.28, fig.cap="ChIPseq workflow", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/chipseq0.jpeg')

```

The ChIPseq is made of two main steps:

- Creating a genome index for BWA (see end of this paragraph)

- Running MACS or SICER analysis

### Creating a BWA index file for Chipseq


The index can be easily created using the graphical interface:

```{r fig.29, fig.cap="Creating a BWA index with Genome indexing BWA", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/chipseq1.jpeg')

```


```{r,  echo=TRUE, eval=FALSE}
bwaIndexUcsc(group="sudo",genome.folder="/sto2/data/scratch/mm10bwa", uscs.urlgenome=
"http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz",
gatk=FALSE)
```

In brief, **bwaIndexUcsc** uses UCSC genomic data. User has to provide the URL (**uscs.urlgenome**) for the file chromFa.tar.gz related to the organism of interest and the path to the folder where the index will be generated (**genome.folder**). The parameter **gatk** has to be set to FALSE, it is not required for ChIPseq genomic index creation.

Precompiled index folders are available:

- [mm10bwa](http://130.192.119.59/public/mm10bwa.tar.gz)


### Calling peaks and annotating

All the parameters needed to run MACS or SICER can be setup using 4SeqGUI:

```{r fig.30, fig.cap="MACS and SICER analysis", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/chipseq3.jpeg')

```

A detailed description of the parameters is given below.

### Chipseq workflow by line command

The chipseq workflow can be also executed using R and it is completely embedded in a unique function:

```{r, echo=TRUE, eval=FALSE}

system("wget 130.192.119.59/public/test.chipseqCounts.zip")
unzip("test.chipseqCounts.zip")
setwd("test.chipseqCounts")
library(docker4seq)
chipseqCounts(group = "docker", output.folder = "./prdm51.igg",
  mock.folder="./igg", test.folder="./prdm51", scratch.folder=getwd(),
  adapter5 = "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
  adapter3 = "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
  threads = 8, min.length = 30, genome.folder,
  mock.id = "igg", test.id = "tf", genome, read.size = 50,
  tool = "macs", macs.min.mfold = 10, macs.max.mfold = 30,
  macs.pval = "1e-5", sicer.wsize = 200, sicer.gsize = 200,
  sicer.fdr = 0.1, tss.distance = 0, max.upstream.distance = 10000,
  remove.duplicates = "N")
```

Specifically user needs to create three folders:

    + mock.folder, where the fastq.gz file for the control sample is located. For control sample we refer to ChIP with IgG only or input DNA.
    + test.folder, where the fastq.gz file for the ChIP of the sample to be analysed.
    + output.folder, where the R script embedding the above script is located.

The **scratch.folder** can be the same as the **output.folder**. However, if the system has a high speed disk for temporary calculation, e.g. a SSD disk, the location of the scratch.folder on the SSD will reduce significantly the computing time.

User needs to provide also the sequence of the sequencing adapters, **adapter5** and **adapter3** parameters. In case Illumina platform  the adapters sequences can be easily recovered [here](https://support.illumina.com/content/dam/illumina-support/documents/documentation/chemistry_documentation/experiment-design/illumina-adapter-sequences_1000000002694-01.pdf).

**Threads** indicates the max number of cores used by *skewer* and *bwa*, all the other steps are done on a single core.
The **min.length** refers to the minimal length that a reads should have after adapters trimming. Since today the average read length for a ChIP experiment is 50 or 75 nts would be better to bring to 40 nts the min.length parameter to increase the precision in assigning the correct position on the genome.

The **genome.folder** parameter refers to the location of the genomic index generated by bwa using the *docker4seq* function **bwaIndexUcsc**.

**mock.id** and **test.id** identify the type of sample and are assigned to the ID parameter in the RG field of the bam file.

**genome** is the parameter referring to the annotation used to associate ChIP peaks with genes. In the present implementation  hg38, hg19 for human and mm10 and mm9 for mouse annotations are available.

**read.size** is a parameter requested by MACS and SICER for their analysis.
**macs.min.mfold**, **macs.max.mfold**, **macs.pval**  are the default parameters requested for  peaks definition for more info please refer to the documentation of MACS 1.4.
**sicer.wsize**, **sicer.gsize**, **sicer.fdr** are the default parameters requested for  peaks definition for more info please refer to the documentation of SICER 1.1.
**IMPORTANT**: The optimal value for **sicer.gsize** in case of H3K4Me3 ChIP is 200 and in case of ChIP H3K27Me3 is 600.   

**tss.distance** and **max.upstream.distance** are parameters required by ChIPseqAnno, which is the Bioconductor package used to assign the peaks to specific genes. Specifically max.upstream.distance refers to the max distance in nts that allows the association of a peak to a specific gene.

**remove.duplicates** is the parameter that indicates if duplicates have to be removed or not. It has two options: **N** duplicates are not removed, **Y** duplicates are removed.


### Chipseq workflow output files

The chipseq workflow produces the following output files:

    + README: A file describing the content of the data folder
    + mypeaks.xls: All detected peaks alongside the nearest gene and its annotation
    + mytreat.counts: The total reads count for the provided treatment file
    + mycontrol.counts: The total reads count for the provided control/background file
    + peak_report.xls: Aggregate information regarding the peak and their position relative to the nearest gene
    + chromosome_distribution.pdf: Barplot of the distribution of the peaks on the chromosomes
    + relative_position_distribution.pdf: Barplot of the distribution of the peaks positions relative to their nearest gene
    + peak_width_distribution.pdf: Histogram of the distribution of the width of the peaks
    + distance_from_nearest_gene_distribution.pdf: Histogram of the distribution of the distance of each peak from its nearest gene
    + cumulative_coverage_total.pdf: Cumulative normalized gene coverage
    + cumulative_coverage_chrN.pdf: Cumulative normalized gene coverage for the specific chromosome
    + mycontrol_sorted.bw: bigWig file for UCSC Genome Browser visualization
    + mytreat_sorted.bw: bigWig file for UCSC Genome Browser visualization

### ChIPseq workflow tutorial

[**Tutorial experiment downloadable here**](http://130.192.119.59/public/test.chipseqCounts.zip):

    + Two ChIPseq one IgG control and an other Prdm5 TF moAb (mouse)

    + single-end mode sequencing,

    + 1 million reads for each sample.

**Experiment description**:

- PRDM family members are transcriptional regulators involved in tissue specific differentiation. PRDM5 has been reported to predominantly repress transcription, but a characterization of its molecular functions in a relevant biological context is lacking. Prdm5 controls both Collagen I transcription and fibrillogenesis by binding inside the Col1a1 gene body and maintaining RNA polymerase II occupancy (Galli et al. PLoS Genet. 2012,e1002711).

- The toy experiment is organized in three folders: i. one for IgG (igg, containing the igg pool down fastq); ii. one for Prdm5 (prdm5, containing the Prdm5 pool down fastq) and iii. the other for analysis output prdm5.igg, where MACS results will be located. The execution of the ChIPseq workflow using GUI or line command will provide the final annotated table of peaks (mypeaks.xls)





## PDX Exomeseq workflow

Patient derived tumor xenografts (PDTX) are created when cancerous tissue from a patient's primary tumor is implanted directly into an immunodeficient mouse. PDTX models are providing solutions to the challenges that researchers face in cancer drug research such as positive tumor responses in mouse models but not translating over when the study is implemented in humans. As a result, PDTX cancer models are popular models to use in cancer drug research.
Exome sequencing is an importnat step of the PCX characterization. IN PDX we have the human tumor mixex with the mouse stroma and it is necessary to remove the mouse information from the exome data.
One way of removing the mouse component is the use of [xenome](https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bts236), which performs fast, accurate and specific classification of xenograft-derived sequence read data [gossamer](https://github.com/data61/gossamer/blob/master/docs/xenome.md).

### Creating Xenome index files


The index can be easily created using the the following function:


```{r,  echo=TRUE, eval=FALSE}
xenomeIndex(group="docker",xenome.folder="/data/scratch/hg19.mm10",
    hg.urlgenome="http://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz",
    mm.urlgenome="http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz", threads=8)
```

In brief, **xenomeIndex** uses UCSC genomic data. User has to provide the **hg.urlgenome** for the human chromFa.tar.gz, the **mm.urlgenome** for the mouse chromFa.tar.gz and the path to the folder where the index will be generated (**xenome.folder**). The parameter **threads** indicates how many threads the user would like to use.


### Running Xenome

Xenome classification can be run using the following code:

```{r,  echo=TRUE, eval=FALSE}
system("wget http://130.192.119.59/public/mcf7_mouse_1m_R1.fastq.gz")
system("wget http://130.192.119.59/public/mcf7_mouse_1m_R2.fastq.gz")
#running xenome
xenome(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
         xenome.folder="/data/scratch/hg19.mm10", seq.type="pe",
         threads=8)
```

In brief, **xenome.folder** is the location of the output generated by **xenomeIndex**. The **scratch.folder** is the folder where temporary data are created. **seq.type** indicates if it is a pair-end **pe** or a single-end **se** sequence. The parameter **threads** indicates how many threads the user would like to use. **fastq.folder** is the folder were input fastq are located and where the output of xenome will be located.

## PDX data preprocessing HowTo

PDX data preprocessing is done stating from the fastq.gz file of a sample present in a user defined folder **fastq.folder**. Data preprocessing is done by **wrapperPdx** with embeds:

- **xenome** for mouse stromal data removal,

- **skewer** for adapter trimming,

- **bwa** for mapping and duplicates marking.

**IMPORTANT** In case the mutect v1 will be used it is necessary to use, a genome reference for **bwa** the following archive (61 GB):

```{r, echo=TRUE, eval=FALSE}
system("wget http://130.192.119.59/public/hg19_exome.tar.gz)
```

### wrapperPdx

PDX fastq preprocessing can be done with **wrapperPdx**.
These are the parameters to be passed:

```{r, echo=TRUE, eval=FALSE}
#example set made of 1 million reads of MCF7 exome data and 1 million reads of mouse genomic DNA pulled down with Illumina Nextera Rapid Capture Exome kit.

system("wget http://130.192.119.59/public/mcf7_mouse_1m_R1.fastq.gz")
system("wget http://130.192.119.59/public/mcf7_mouse_1m_R2.fastq.gz")

#running wrapperPdx
wrapperPdx(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
     xenome.folder="/data/scratch/hg19.mm10", seq.type="pe", threads=24,
     adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
     adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"
     min.length=40, genome.folder="/data/scratch/hg19_exome", sample.id="sampleX")
```

In brief, **xenome.folder** is the location of the output generated by **xenomeIndex**. The **scratch.folder** is the folder where temporary data are created. **seq.type** indicates if it is a pair-end **pe** or a single-end **se** sequence. The parameter **threads** indicates how many threads the user would like to use. **fastq.folder** is the folder were input fastq are located and where the output of xenome will be located.
User needs to provide also the sequence of the sequencing adapters, **adapter5** and **adapter3** parameters. In case Illumina platform the adapters sequences can be easily recovered [**here**](https://support.illumina.com/content/dam/illumina-support/documents/documentation/chemistry_documentation/experiment-design/illumina-adapter-sequences_1000000002694-01.pdf).
The **min.length** refers to the minimal length that a reads should have after adapters trimming. Since today the average read length for a RNAseq experiment is 50 or 75 nts would be better to bring to 40 nts the min.length parameter to increase the precision in assigning the correct position on the genome.
The **genome.folder** parameter refers to the location of the genomic index [**hg19_exome**](http://130.192.119.59/public/hg19_exome.tar.gz) required for **bwa**, see above.
**Sample.id** is a character string indicating the unique id to be associated to the bam that will be created.

### wrapperPdx output

The output of the function are three files:

- **xenome_folder**, which contains xeno_ambiguous_ (difficult to be classified as human or mouse),  xeno_both_ (classified in both mouse and human), xeno_mm_ (mouse specific reads), xeno_neither_ (not human or mouse, possibly adapter sequences) files.

- **xeno_hs_R1.fastq.gz**, xeno_hs_R2.fastq.gz, hg19 human associated reads, produced by xenome analysis and further processed by **wrapperPdx** to generated bam, bai and stats files.

- One or two gzip fastq files ending with **trimmed-pair1.fastq.gz** and **trimmed-pair1.fastq.gz**, a log file of the trimming with the extensione **trimmed.log**

- **dedup_reads.bam**, which is sorted and duplicates marked bam file generated by **bwa**,

- **dedup_reads.bai**, which is the index of the dedup_reads.bam generated by **bwa**,

- **dedup_reads.stats**, which provides mapping statistics generated by **bwa**.

### oncoSNP

The output of [oncoSNP](https://sites.google.com/site/oncosnp/) is used to associate to gene symbols the detected CN, rank 5 ([see oncoSNP help](https://sites.google.com/site/oncosnp/user-guide/interpreting-oncosnp-output)). This association is done using the *oncosnpAnnotation* function. The function requirements are the folder where the ouptut of oncoSNP is saved, i.e. where the file with extension .cnvs are located, and the folder where the ENSEMBL genome.gtf is located. The analysis returns for each .cnvs a file annotation_XXXXXX.cnvs.txt, which contains the genes location, gene symbol and CN and LOH ([see oncoSNP help](https://sites.google.com/site/oncosnp/user-guide/interpreting-oncosnp-output)). Please note

```{r, echo=TRUE, eval=FALSE}
system("wget http://130.192.119.59/public/test_oncosnp.zip")
system("unzip test_oncosnp.zip")

oncosnpAnnotation(group="docker", data.folder="./test_oncosnp/oncosnp_out", genome.folder="./test_oncosnp/hg19")
```
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circrnaReformat.R
\name{circrnaReformat}
\alias{circrnaReformat}
\title{Running circRNA reformat script}
\usage{
circrnaReformat(
  group = c("sudo", "docker"),
  scratch.folder,
  input.folder,
  output.folder,
  tool = c("acfs", "circexplorer", "circexplorer2", "circrnafinder", "ciri", "ciri2",
    "dcc", "findcirc2", "knife", "starchip", "uroborus")
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{input.folder, }{string indicating the path of the folder which contains the input files to be reformatted}

\item{output.folder, }{string indicating the path to the reformatted circRNA prediction files}

\item{tool, }{string indicating the tool used to create the input files. Supported tools are: acfs, circexplorer, circexplorer2, circrnafinder, ciri, ciri2, dcc, findcirc2, knife, starchip, uroborus}
}
\value{
A circRNA list reformatted in a tab-delimited file storing the circRNA genomic coordinates
}
\description{
This function executes the docker container docker4circ to reformat circRNA prediction file produced by a certain tool in a common format to further analysis.
}
\examples{
\dontrun{
}
}
\author{
Nicola Licheri
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/skewerXSergio.R
\name{skewerXSergio}
\alias{skewerXSergio}
\title{Running skewer, an adapter trimmer application, Jiang et al BMC Bioinformatics201415:182}
\usage{
skewerXSergio(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  adapter5,
  adapter3,
  seq.type = c("se", "pe"),
  threads = 1,
  min.length = 18
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{adapter5, }{a character string indicating the fwd adapter}

\item{adapter3, }{a character string indicating the rev adapter}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing.}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{min.length, }{a number indicating minimal length required to return a trimmed read}
}
\value{
One or two gzip fastq files ending with trimmed-pair1.fastq.gz and trimmed-pair1.fastq.gz, a log file of the trimming with the extensione trimmed.log, run.info file descring the analysis steps done by the docker. The latter file is useful to understand where the docker stop in case of unexpected end
}
\description{
This function executes the docker container skewer1 to remove sequencing adapters from RNAseq reads
}
\examples{
\dontrun{
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    system("wget http://130.192.119.59/public/test_R2.fastq.gz")
    skewer(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
    adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
    adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
    seq.type="pe", threads=10,  min.length=40)
}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bwa.R
\name{bwa}
\alias{bwa}
\title{Running bwa, Li and Durbin Bioinformatics, 2009 Jul 15;25(14):1754-60}
\usage{
bwa(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  genome.folder,
  seq.type = c("se", "pe"),
  threads = 1,
  sample.id,
  circRNA = FALSE
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for bwa is located}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{sample.id, }{a character string indicating the unique id to be associated to the bam that will be created}

\item{circRNA, }{a boolean variable indicating whether the analysis concerns a circRNA prediction or not.}
}
\value{
three files: dedup_reads.bam, which is sorted and duplicates marked bam file, dedup_reads.bai, which is the index of the dedup_reads.bam, and dedup_reads.stats, which provides mapping statistics
}
\description{
This function executes the docker container bwa1 where BWA is installed BWA is a read alignment package that efficiently align short sequencing reads against a large reference sequence This aligner provides optimal results with DNA-seq data
}
\examples{
\dontrun{
    #downloading fastq files
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    #running bwa
    bwa(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
    genome.folder="/data/scratch/hg19bwa", seq.type="se",
    threads=24, sample.id="exome")

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/snvPreprocessing.R
\name{snvPreprocessing}
\alias{snvPreprocessing}
\title{Running indel relignment and quality recalibration on bam generated by bwa function NOT READY TO GO ON STABLE}
\usage{
snvPreprocessing(
  group = c("sudo", "docker"),
  bam.folder = getwd(),
  scratch.folder = "/data/scratch",
  genome.folder,
  threads = 8,
  gatk.file
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{bam.folder, }{a character string indicating where bam file generated by bwa is located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the index reference genome for bwa is located}

\item{threads, }{a number indicating the number of cores to be used by the application}

\item{gatk.file, }{a character string for GenomeAnalysisTK-X.Y.tar.bz2, this file should be located in the bam.folder}
}
\value{
bam and bai after indel relignment and quality recalibration.
}
\description{
This function executes the docker container snvPreprocessing. IMPORTANT: the working folder require the presence of GenomeAnalysisTK.tar.bz2 files
}
\examples{
\dontrun{
    #downloading examples 1 million reads of mcf7 exome mixed with 1 million of mouse derived by human exome capturing
    system("wget http://130.192.119.59/public/hs1m_mm1m_R1.fastq.gz")
    system("wget http://130.192.119.59/public/hs1m_mm1m_R2.fastq.gz")
    
    #required for bwa 61Gb At the present time this is required to run mutect1
    system("wget http://130.192.119.59/public/hg19_exome.tar.gz")
    #this genome index is prepared to be used for indel realignment and quality recalibration
    
    #running snvPreprocessing
    snvPreprocessing(group="docker",bam.folder=getwd(), 
               scratch.folder="/data/scratch",
               genome.folder="/data/scratch/hg19_exome", 
               threads=24, gatk.file="GenomeAnalysisTK-3.7.tar.bz2")

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/star.R
\name{star}
\alias{star}
\title{Running Star two steps for variant calls}
\usage{
star(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  genome.folder,
  groupid,
  threads = 1,
  version = 2
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR is located.}

\item{groupid, }{a character string to be inserted in the bam as identifier for the sample}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{version, }{a number indicating version in use}
}
\value{
three files: sorted_reads.bam, which is sorted and duplicates marked bam file, sort_reads.bai, and sort_reads.stats, which provides mapping statistics
}
\description{
This function executes the two steps STAR as sugested by best practice GATK for calling variants on RNAseq data only PE data are accepted
}
\examples{
\dontrun{
    #downloading fastq files
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    system("wget http://130.192.119.59/public/test_R2.fastq.gz")
    #running star nostrand pe
    star(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
    genome.folder="/data/scratch/hg38star", groupid="test", threads=12)

}
}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bowtie2Index.R
\name{bowtie2Index}
\alias{bowtie2Index}
\title{Generating bowtie2 genome index}
\usage{
bowtie2Index(
  group = c("sudo", "docker"),
  genome.folder = getwd(),
  ensembl.urlgenome = NULL,
  ensembl.urlgtf = NULL,
  threads = 1
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for Bowtie will be located}

\item{ensembl.urlgenome, }{a character string indicating the URL from ENSEMBL ftp for the unmasked genome sequence of interest}

\item{ensembl.urlgtf, }{a character string indicating the URL from ENSEMBL ftp for the GTF for genome of interest}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
The indexed Bowtie genome reference sequence
}
\description{
This function executes the docker container bowtie2 where bowtie2-2.2.9 is installed. The index is created using ENSEMBL genome fasta file. User needs to provide the URL for ENSEMBL genome located in the ENSEMBL ftp
}
\examples{
\dontrun{
    #running rsemstar index for human
    bowtie2Index(group="docker",genome.folder="/data/scratch/hg38bowtie2",
    ensembl.urlgenome=
    "ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz",
    ensembl.urlgtf=
    "ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.gtf.gz",
    threads=8)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/experimentPower.R
\name{experimentPower}
\alias{experimentPower}
\title{A wrapper function for experiment_power from RnaSeqSampleSize Bioconductor package}
\usage{
experimentPower(
  group = c("sudo", "docker"),
  filename,
  replicatesXgroup = 3,
  FDR = 0.1,
  genes4dispersion = 200,
  log2fold.change = 1,
  output.folder = getwd()
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{filename, }{a character string indicating the name of the count table file}

\item{replicatesXgroup, }{an integer indicating the number of samples used in each group}

\item{FDR, }{false discovery rate}

\item{genes4dispersion, }{an integer indicating the number of genes used in estimation of read counts and dispersion distribution}

\item{log2fold.change, }{an integer indicating the minimum log2 fold change for prognostic genes between two groups}

\item{output.folder, }{a string indicating the path where to save the output file}
}
\value{
a string with the requested informations. The string is also saved in a file: power_evaluation.txt
}
\description{
This function evaluate the statistical power of a pilot experiment
}
\examples{
\dontrun{
 system("wget 130.192.119.59/public/test.analysis.zip")
 unzip("test.analysis.zip")
 setwd("test.analysis")
 library(docker4seq)
 experimentPower(group="docker",filename="_counts.txt",replicatesXgroup=7,
 FDR=0.1, genes4dispersion=200, log2fold.change=1)
}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trimFasta.R
\name{trimFasta}
\alias{trimFasta}
\title{A function to execute seqtk trimming}
\usage{
trimFasta(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder,
  min.length = 300
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}

\item{min.length, }{min nucleotide lenght of each fasta seq}
}
\value{
Returns a fasta file colled trimmed.fasta.gz
}
\description{
This function executes a ubuntu docker that remove reads shorter of a specific threshold
}
\examples{
\dontrun{
    #running fastq2fasta
    trimfasta(group="docker", scratch.folder="/data/scratch", data.folder=getwd(), min.length=300)
}

}
\author{
Raffaele A Calogero, raffaele.calogero [at] unito [dot] it, University of Torino. Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapperDeseq2.R
\name{wrapperDeseq2}
\alias{wrapperDeseq2}
\title{A wrapper function for deseq2 for two groups only}
\usage{
wrapperDeseq2(
  output.folder,
  group = c("sudo", "docker"),
  experiment.table,
  log2fc = 1,
  fdr = 0.1,
  ref.covar = "0",
  type = c("gene", "isoform", "mirna"),
  batch = FALSE
)
}
\arguments{
\item{output.folder, }{a character string indicating where the tables generated by samples2experiment are located and were results will be placed}

\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{experiment.table, }{a character string indicating the counts table generated with sample3experiment with addition of covariates}

\item{log2fc, }{log2fc threshold for differetially expressed genes}

\item{fdr, }{fdr threshold}

\item{ref.covar, }{covariate to be used as reference}

\item{type, }{character with three options: gene, isoform, mirna. if gene is used two files are generated for geneset enrichment, the filtered Gene symbols and the background that contains all gene simbols.}

\item{batch, }{logical FALSE, TRUE}
}
\value{
Returns a full table of differentially expressed genes (prefix DEfull), a filtered table of differentially expressed genes (prefix DEfiltered) and the normalized counts table (prefix normalized)
}
\description{
This function runs deseq2 on a table genrated with sample2experiment having the covariates added in the names of the columns, separated by the names with underscore.
}
\examples{
\dontrun{
    system("wget 130.192.119.59/public/test.analysis.zip")
    unzip("test.analysis.zip")
    setwd("test.analysis")
    library(docker4seq)
    wrapperDeseq2(output.folder=getwd(), group="docker", experiment.table="_counts.txt", log2fc=1,
    fdr=0.1, ref.covar="Cov.1", type="gene", batch=FALSE)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fastqc.R
\name{fastqc}
\alias{fastqc}
\title{A function to handle a docker containier executing fastqc}
\usage{
fastqc(group = c("sudo", "docker"), data.folder, large = FALSE)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}

\item{large, }{boolenan if FALSE uses 10000 reads to make fastq statistics if TRUe uses 1 milion reads}
}
\description{
This function executes a ubuntu docker that produces as output FASTQCstdin_fastqc.html and stdin_fastqc.zip files
}
\examples{
\dontrun{
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    #running fastqc
    fastqc(group="docker", data.folder=getwd(), large=FALSE)
}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, University of Torino
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/starChipIndex.R
\name{starChipIndex}
\alias{starChipIndex}
\title{Preparing the bed file required by starchip to detect circular RNAs on paired-end sequences}
\usage{
starChipIndex(group = c("sudo", "docker"), genome.folder = getwd())
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR is located.}
}
\value{
the bed files of the reference genome for STARChip analysis
}
\description{
This function prepare the genome bed file for starchip, the GTF must be the one used by starChimeric
}
\examples{
\dontrun{
    starChipIndex(group="docker", genome.folder="/data/genomes/hg38star")
}
}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/platypus.R
\name{platypus}
\alias{platypus}
\title{Platypus analysis NOT READY TO GO ON STABLE missing test set}
\usage{
platypus(
  group = c("sudo", "docker"),
  data.folder = getwd(),
  scratch.folder,
  pathRef,
  nameRef,
  threads,
  GQ,
  minSampGQ,
  NR,
  minSampNR,
  NV,
  minSampNV,
  normal_samples,
  GT_normal,
  minSampGT_normal,
  tumoral_samples,
  GT_tumoral,
  minSampGT_tumoral,
  stringent_filter = 0,
  annotation = c("hg19", "mm10")
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{data.folder, }{a character string indicating the folder where bams and vcf files are located and where output will be written}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{pathRef, }{Path of the foldert that contains the fasta file of the genome}

\item{nameRef, }{name of the fasta file inside pathRef, the fastq has to be indexed with samtools faidx}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{GQ, }{min GQ value to consider (extreme included)}

\item{minSampGQ, }{min number of samples with GQ value (extreme included), usually we start with 85\% of the samples}

\item{NR, }{min NR value to consider (extreme included), the number of reads covering the SNV region}

\item{minSampNR, }{min number of samples with NR value (extreme included), usually we start with 85\% of the samples}

\item{NV, }{min NV value to consider (extreme included), the n of reads with the SNV}

\item{minSampNV, }{min number of samples with NV value (extreme included)}

\item{normal_samples, }{string with names (group names of bam files) of normal samples separated by hash, write NULL if you do not want to use GT filter in normal samples}

\item{GT_normal, }{GT value in normal samples to consider, type "NO" if you do not want to use this filter, else e.g. you might use 0/0}

\item{minSampGT_normal, }{min number of normal samples with GT value}

\item{tumoral_samples, }{string with names (group names of bam files) of tumoral samples separated by &, write NULL if you do not want to use GT filter in normal samples}

\item{GT_tumoral, }{GT value in tumoral samples to consider, type "NO" if you do not want to use this filter. Type e.g. 0/0 if you do not want to consider this genotype.}

\item{minSampGT_tumoral, }{min number of tumoral samples in which the GT value is NOT present}

\item{stringent_filter, }{To enable the filter (it keeps only the variants with "PASS" value or the variants that have only the "alleleBias" value) use 1 or 0 to disable it}

\item{annotation, }{hg19 and mm10 are actually available for the annotation of the detected SNVs}
}
\description{
This function executes Platypus: A Haplotype-Based Variant Caller For Next Generation Sequence Data. Platypus requires as input bam and bai files. In case vcf.gz and vcf.idx files are located in the bam folder  platypus will use only those positions for SNV calling
}
\examples{
\dontrun{
    #running platypus with some threshold provided by sottoriva analysis
 platypus(group="docker", data.folder="/archive/home/rcaloger/data/platypus_tests/hg19UCSC", 
        scratch.folder="/scratch/users/rcaloger/", pathRef="/archive/home/rcaloger/hg19_exome", 
        nameRef="hg19_clean.fasta", threads=96, GQ=10, minSampGQ=2, NR=10, minSampNR=2, NV=3, 
        minSampNV=1, normal_samples="475blood", GT_normal="0/0", 
        minSampGT_normal=1, tumoral_samples="1864p1#1864p22", GT_tumoral="0/0", 
        minSampGT_tumoral=1, stringent_filter=0, annotation="hg19")
 platypus(group="docker", data.folder="/archive/home/rcaloger/data/platypus_tests/hg19ENSEMBL", 
        scratch.folder="/scratch/users/rcaloger/", pathRef="/archive/home/rcaloger/hg19star", 
        nameRef="genome.fa", threads=96,GQ=10, minSampGQ=2, NR=10, minSampNR=2, NV=3, 
        minSampNV=1, normal_samples="5275001-HS", GT_normal="0/0", 
        minSampGT_normal=1, tumoral_samples="5275001-LSG1#5275001-LSGIII", 
        GT_tumoral="0/0", minSampGT_tumoral=1, stringent_filter=0, annotation="hg19")
 platypus(group="docker", data.folder="/archive/home/rcaloger/data/platypus_tests/mm10ENSEMBL", 
        scratch.folder="/scratch/users/rcaloger/", pathRef="/archive/home/rcaloger/mm10star", 
        nameRef="genome.fa", threads=96, GQ=10, minSampGQ=2, NR=10, minSampNR=2, NV=3, 
        minSampNV=1, normal_samples="MAMBO43", GT_normal="0/0", 
        minSampGT_normal=1, tumoral_samples="MAMBO43TRT#MAMBO43TRNT", GT_tumoral="0/0", 
        minSampGT_tumoral=1, stringent_filter=0, annotation="mm10")
}
}
\author{
Riccardo Panero, riccardo.panero[at]gmail[dot]com, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ciri2.R
\name{ciri2}
\alias{ciri2}
\title{Running CIRI v2 tool for circRNAs prediction}
\usage{
ciri2(
  group = c("sudo", "docker"),
  scratch.folder,
  sam.file,
  genome.file,
  annotation.file = NA,
  max.span = 2e+05,
  stringency.value = c("high", "low", "zero"),
  quality.threshold = 10,
  threads = 1
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{sam.file, }{a character string indicating the path to the RNA-Seq alignment SAM file from BWA}

\item{genome.file, }{a character string indicating the path to the Fasta file of the reference genomic sequence (it should be the same reference indexed for the BWA alignment)}

\item{annotation.file, }{a character string indicating the path to the GTF/GFF file reporting the reference gene annotations}

\item{max.span, }{an integer reporting the maximum spanning distance of a circRNA (default = 200000 bp)}

\item{stringency.value, }{the selected stringency level of the analysis. Three possible options are available: "high" (high stringency, default), in which CIRI2 only provides circRNAs supported by more than 2 distinct Paired Chiastic Clipping (PCC) signals; "low" (low stringency), CIRI2 only provides circRNAs supported by more than 2 junction reads; "zero", CIRI2 provides all circRNAs regardless junction read counts or PCC signals}

\item{quality.threshold, }{integer indicating the threshold for mapping quality of each segment of junction reads (default=10)}

\item{threads, }{integer indicating the number of threads used for the analysis (default=1)}
}
\value{
The list of CIRI 2 predicted circRNAs
}
\description{
This function executes the docker container ciri2 where CIRI v2.0.6 is installed and it provides the list of circRNAs predicted from a RNA-Seq experiment. For CIRI 2 tool detail refer to: "Gao, Y., Zhang, J., & Zhao, F. (2017). Circular RNA identification based on multiple seed matching. Brief Bioinform. 2018 Sep 28;19(5):803-810."
}
\examples{
\dontrun{

    #retrieve the example data
    system("wget https://sourceforge.net/projects/ciri/files/CIRI2/CIRI_v2.0.6.zip") #retrieve the example data
    system("unzip CIRI_v2.0.6.zip")

    #running ciri2 function
    ciri2(group="docker", scratch.folder="/data/scratch", sam.file=paste(getwd(),"/CIRI_v2.0.6/data/sample.sam", sep=""), genome.file=paste(getwd(),"/CIRI_v2.0.6/data/chr1.fa", sep=""), annotation.file="", max.span=200000, stringency.value="high", quality.threshold=10, threads=1)
}

}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chipseqCounts.R
\name{chipseqCounts}
\alias{chipseqCounts}
\title{Running MACS & SICER workflow NOT READY FOR STABLE check it!}
\usage{
chipseqCounts(
  group = c("sudo", "docker"),
  output.folder = getwd(),
  mock.folder,
  test.folder,
  scratch.folder,
  adapter5 = "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
  adapter3 = "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
  threads = 8,
  seq.type = "se",
  min.length = 30,
  genome.folder,
  mock.id = "igg",
  test.id = "tf",
  genome,
  read.size = 50,
  tool = "macs",
  macs.min.mfold = 10,
  macs.max.mfold = 30,
  macs.pval = "1e-5",
  sicer.wsize = 200,
  sicer.gsize = 200,
  sicer.fdr = 0.1,
  tss.distance = 0,
  max.upstream.distance = 10000,
  remove.duplicates = "N"
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{output.folder, }{a character string indicating where final results will be saved}

\item{mock.folder, }{a character string indicating where gzip fastq file for unspecific ChIP is located}

\item{test.folder, }{a character string indicating where gzip fastq file for specific ChIP is located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{adapter5, }{a character string indicating the fwd adapter}

\item{adapter3, }{a character string indicating the rev adapter}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. One options: \code{"se"} for single end sequencing}

\item{min.length, }{a number indicating minimal length required to return a trimmed read}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome is located}

\item{mock.id, }{a character string indicating the unique id to be associated to the mock bam that will be created}

\item{test.id, }{a character string indicating the unique id to be associated to the test bam that will be created}

\item{genome, }{a character string indicating the genome used as reference for data generation. Available options: hg19, hg38, mm9, mm10}

\item{read.size, }{an integer indicating the length of the sequenced reads}

\item{tool, }{a character string indicating the peaks calling algorith. Available options: macs and sicer. Macs, v 1.14, is used to call TF peaks, as instead sicer, v 1.1, is used to call histone mark peaks}

\item{macs.min.mfold, }{an integer indicating the minimum enrichment ratio against background}

\item{macs.max.mfold, }{an integer indicating the maximum enrichment ratio against background}

\item{macs.pval, }{a character string, indicationg the pvalue cutoff to be used to filter peaks with low statistical significance.The number must be provided in scientific notation as the default value shows}

\item{sicer.wsize, }{an integer indicating the windows size to be used by sicer}

\item{sicer.gsize, }{an integer indicating the gap size to be used by sicer. Suggested values: H3K4Me3=200; H3K27Me3=600}

\item{sicer.fdr, }{an integer indicating the pvalue cutoff to be used to filter peaks with low statistical significance}

\item{tss.distance, }{an integer indicating the distance of TSS with respect to gene start}

\item{max.upstream.distance, }{an integer indicating the maximum distance to associate a gene ID to a peak}

\item{remove.duplicates, }{a character string indicating if duplicated reads have to be removed. Available options: Y, to remove douplicates, N to keep duplicates}
}
\value{
Returns the output of skewer, bwa, chipseq
}
\description{
This function executes a set of docker containers allowing the detection of TFs and Histon marks peaks.
#params skewer
}
\examples{
\dontrun{
system("wget 130.192.119.59/public/test.chipseqCounts.zip")
unzip("test.chipseqCounts.zip")
setwd("test.chipseqCounts")
library(docker4seq)
chipseqCounts(group = "docker", output.folder = "/data/tests/chipseqCounts/test.chipseqCounts/prdm51.igg",
             mock.folder="/data/tests/chipseqCounts/test.chipseqCounts/igg",
             test.folder="/data/tests/chipseqCounts/test.chipseqCounts/prdm51", scratch.folder="/data/scratch/",
             adapter5 = "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
             adapter3 = "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
             threads = 8, min.length = 30, genome.folder="/data/genomes/mm10bwa",
             mock.id = "igg", test.id = "tf", genome="mm10", read.size = 50,
             tool = "macs", macs.min.mfold = 10, macs.max.mfold = 30,
             macs.pval = "1e-5", sicer.wsize = 200, sicer.gsize = 200,
             sicer.fdr = 0.1, tss.distance = 0, max.upstream.distance = 10000,
             remove.duplicates = "N")
}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/annotatingByGtf.R
\name{rsemannoByGtf}
\alias{rsemannoByGtf}
\title{Annotating RSEM gene.results using ENSEMBL gtf and refGenome CRAN package}
\usage{
rsemannoByGtf(group = "docker", rsem.folder = getwd(), genome.folder)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{rsem.folder, }{a character string indicating where gene.results file is located}

\item{genome.folder, }{a character string indicating the folder for the genome reference used for mapping and counting with \code{"rsemstar"} function. In this folder is present the GTF used for by RSEM}
}
\value{
one file: annotated_genes.results, which is the annotated version of gene.results.
}
\description{
This function executes the docker container annotate.1, where refGenome is used to annotated gene.results and isoforms.results outputs from RSEM using ENSEMBL GTF annotation
}
\examples{
\dontrun{
    #downloading fastq files
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    system("wget http://130.192.119.59/public/test_R2.fastq.gz")
    library(docker4seq)
   #running rsemstar nostrand pe
   rsemstar(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch/",
         genome.folder="/data/genomes/hg38star/", seq.type="pe", strandness="none",
         threads=8, save.bam = FALSE)
    #running rsemannoByGtf
    rsemannoByGtf(group="docker", rsem.folder=getwd(), genome.folder="/data/scratch/hg38star")
}

}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/macs2.R
\name{macs2}
\alias{macs2}
\title{A function to handle a MACS2 containier}
\usage{
macs2(
  group = c("sudo", "docker"),
  control.bam,
  chipseq.bam,
  experiment.name,
  histone.marks = FALSE,
  broad.cutoff = 0.1,
  qvalue = 0.05,
  organism = c("hs", "mm")
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{control.bam, }{a character string indicating the path to the control bam file. IMPORTANT control.bam and chipseq.bam are in the same folder}

\item{chipseq.bam, }{a character string indicating the path to the chipseq bam file. IMPORTANT control.bam and chipseq.bam are in the same folder}

\item{experiment.name, }{a character string indicating the prefix for MCS2 output}

\item{histone.marks, }{boolean if TRUE activate the broad option to call histone marks}

\item{broad.cutoff, }{if histone.mark is TRUE broad.cutoff can be set, default 0.1}

\item{qvalue, }{The qvalue (minimum FDR) cutoff to call significant regions. Default is 0.05. For broad marks, you can try 0.05 as cutoff.}

\item{organism, }{required to select the correct genome size avaialble options hs, mm}
}
\value{
NAME_peaks.xls, which is a tabular file which contains information about called peaks. You can open it in excel and sort/filter using excel functions. Information include: chromosome name, start position of peak, end position of peak, length of peak region, absolute peak summit position, pileup height at peak summit, -log10(pvalue) for the peak summit (e.g. pvalue =1e-10, then this value should be 10), fold enrichment for this peak summit against random Poisson distribution with local lambda, -log10(qvalue) at peak summit. NAME_peaks.narrowPeak is BED6+4 format file which contains the peak locations together with peak summit, pvalue and qvalue. You can load it to UCSC genome browser. Definition of some specific columns are: 5th: integer score for display calculated as int(-10*log10qvalue). Please note that currently this value might be out of the [0-1000] range defined in UCSC Encode narrowPeak format, 7th: fold-change, 8th: -log10pvalue, 9th: -log10qvalue, 10th: relative summit position to peak start. NAME_peaks.broadPeak is in BED6+3 format which is similar to narrowPeak file.
}
\description{
This function executes a MACS2 docker that produces as output peaks call
}
\examples{
\dontrun{
    #running MACS for conventional peaks
    macs2(group="docker", control.bam=paste(getwd(),"igg_dedup_reads.bam", sep="/"), 
            chipseq.bam=paste(getwd(),"prdm51_dedup_reads.bam", sep="/"), 
            experiment.name="prdm51_igg", histone.marks=FALSE, qvalue=0.05, 
            organism="mm")
            
    #running MACS for histone marks
    macs2(group="docker", control.bam=paste(getwd(),"igg_dedup_reads.bam", sep="/"), 
            chipseq.bam=paste(getwd(),"prdm51_dedup_reads.bam", sep="/"), 
            experiment.name="prdm51_igg", histone.marks=TRUE, broad.cutoff=0.1, 
            organism="mm")     
}

}
\author{
raffaele.calogero [at] unito [dot] it, University of Torino
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/downloadGeneInfo.R
\name{getInfo}
\alias{getInfo}
\title{Downloading the full set of genes information from HGNC}
\usage{
getInfo(
  group = c("sudo", "docker"),
  data.folder = getwd(),
  url,
  type = c("pubmed", "omim")
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{data.folder, }{a character string indicating where downloaded data will be stored}

\item{url, }{the url to download the full dataset}

\item{type, }{PUBMED or OMIM}
}
\value{
one file files: gene_with_protein_product.txt
}
\description{
This function retrieves the full table of curated genes annotations
}
\examples{
\dontrun{
    getInfo(group="docker",data.folder=getwd(),
    url="ftp.ebi.ac.uk/pub/databases/genenames/new/tsv/locus_types/gene_with_protein_product.txt", type="pubmed")

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/starchipCircle.R
\name{starchipCircle}
\alias{starchipCircle}
\title{Running starchip to detect circular RNAs on paired-end sequences}
\usage{
starchipCircle(
  group = c("sudo", "docker"),
  scratch.folder,
  genome.folder,
  samples.folder,
  reads.cutoff,
  min.subject.limit,
  threads,
  do.splice = c(TRUE, FALSE),
  cpm.cutoff = 0,
  subjectCPM.cutoff = 0,
  annotation = c(TRUE, FALSE)
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR is located.}

\item{samples.folder, }{the folder where are located all the folders of the samples processed with starChimeric}

\item{reads.cutoff, }{Integer. Minimum number of reads crossing the circRNA backsplice required.}

\item{min.subject.limit, }{Integer. Minimum number of individuals with readsCutoff reads required to carry forward a circRNA for analysis}

\item{threads, }{Integer. Number of threads to use}

\item{do.splice, }{true false. The splices within the circRNA be detected and reported. Linear splices are searched within each circRNA in each individual. Any linear splice with >= 60\% of the read count of the cRNA is considered a splice within the circRNA. Two files are then created, .consensus with most common splice pattern, and .allvariants with all reported splice patterns.}

\item{cpm.cutoff, }{Float. Reads counts are loaded into R and log2(CountsPerMillion) is calculated using the limma package. With cpmCutoff > 0, circRNAs with log2(CPM) below this value will be filtered from this analysis}

\item{subjectCPM.cutoff, }{Integer. See above. This value is the lower limit for number of individuals required to have the circRNAs expressed at a value higher than cpmCutoff.}

\item{annotation, }{true/false. circRNAs are provided with gene annotations}
}
\value{
1. Count matrices : raw cRNA backsplice counts: circRNA.cutoff[readthreshold]reads.[subjectthreshold]ind.countmatrix log2CPM of above: norm_log2_counts_circRNA.[readthreshold]reads.[subjectthreshold]ind.0cpm_0samples.txt Maximum Linear Splices at Circular Loci: rawdata/linear.[readthreshold]reads.[subjectthreshold]ind.sjmax 2. Info about each circRNA:  Consensus Information about Internal Splicing: Circs[reads].[subjects].spliced.consensus Complete Gene Annotation: circRNA.[readthreshold]reads.[subjectthreshold]ind.annotated Consise Gene Annotation + Splice Type:  circRNA.[readthreshold]reads.[subjectthreshold]ind.genes 3. Images: PCA plots: circRNA.[readthreshold]reads.[subjectthreshold]ind.0cpm_0samples_variance_PCA.pdf Heatmap: circRNA.[readthreshold]reads.[subjectthreshold]ind.heatmap.pdf
}
\description{
This function execute starchip on a set of folders containing the output of starChimeric. It requires a specific bed generated with starChipIndex in the genome folder used by starChimeric
}
\examples{
\dontrun{
    #downloading fastq files
    starchipCircle(group="docker", genome.folder="/data/genomes/hg38star", scratch.folder="/data/scratch",
                       samples.folder=getwd(), reads.cutoff=1, min.subject.limit=2, threads=8,
                       do.splice = TRUE, cpm.cutoff=0, subjectCPM.cutoff=0, annotation=TRUE)
}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circrnaAnnotations.R
\name{circrnaAnnotations}
\alias{circrnaAnnotations}
\title{Annotation of a list of circRNAs}
\usage{
circrnaAnnotations(
  group = c("sudo", "docker"),
  scratch.folder,
  ciri.file,
  annotation.sources = c("circbase", "tscd", "cscd", "exorbase", "circ2disease",
    "circfunbase"),
  assembly = c("hg18", "hg19", "hg38", "mm9", "mm10")
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{ciri.file, }{a list of circRNAs derived from a circRNAs prediction analysis}

\item{annotation.sources, }{a vector of character strings indicating the circRNA databases to analyse. Compatible databases id: circbase, cscd, exorbase, circ2disease, circfunbase, tscd.}

\item{assembly, }{a character string indicating the reference genome assembly. The function currently work with the hg18, hg19, and hg38, mm9, and mm10 genome assemblies.}
}
\value{
The annotations of a list of circRNAs from different databases
}
\description{
This function executes the docker container ciri2 in the annotation mode to overlap a list of circRNAs with the annotations from circBase, CSCD, ExoRBase, Circ2Disease, CircFunBase, and TSCD
}
\examples{
\dontrun{

# Retrieve the example data
    system("wget https://github.com/carlo-deintinis/circhunter/archive/master.zip")
    system("unzip master.zip")

# Run the circAnnotations function
 circAnnotations(group = "docker", scratch.folder="/data/scratch", ciri.file=paste(getwd(),"/circhunter-master/CircHunter/data/circRNA_CRC.bed", sep=""), assembly="hg19")

circAnnotations()
}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/downloadContainers.R
\name{downloadContainers}
\alias{downloadContainers}
\title{Download for the first time all containers embedded in the workflows}
\usage{
downloadContainers(group = "docker", containers.file = "all")
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{containers.file, }{a character string with the name of the file which indicate which are the initial set of containers to be downloaded. Initally the set is given by a file located in the folder containers of docker4seq package: "all", "rnaseq", "ncrnaseq", "chipseq"}
}
\description{
This is a functin that preapre the docker environment to be used for the first time the docker4seq is installed.
}
\examples{
\dontrun{
    #running runDocker
     downloadContainers(group="docker", containers.file)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gatkDna.R
\name{gatkDNA}
\alias{gatkDNA}
\title{Running realignment and recalibration, GATK}
\usage{
gatkDNA(
  group = c("sudo", "docker"),
  bam.folder = getwd(),
  scratch.folder = "/data/scratch",
  gatk.filename,
  genome.folder,
  threads = 1
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{bam.folder, }{a character string indicating where bam files generated with bwa.R are located. In this folder should be loacted also the GATK file GenomeAnalysisTK-X.X-0.tar.bz2.}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{gatk.filename, }{a character string for GenomeAnalysisTK-X.X-0.tar.bz2.}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for bwa is located}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
three files: dedup_reads.bam, which is sorted and duplicates marked bam file, dedup_reads.bai, which is the index of the dedup_reads.bam, and dedup_reads.stats, which provides mapping statistics
}
\description{
This function executes the docker container snv.1 where GATK software is used to do INDEL realignment and quality recalibration. This analysis is required only to run mutect1. The bwa index has to be prepared with bwaIndex
}
\examples{
\dontrun{
    #downloading fastq files
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    system("wget http://130.192.119.59/public/test_R2.fastq.gz")
    #running bwa
    gatkDNA(group="sudo",bam.folder=getwd(), scratch.folder="/data/scratch",
    gatk.filename="GenomeAnalysisTK-3.7.tar.bz2"
    genome.folder="/data/scratch/hg19_bwa", threads=24)
}
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/salmonAnnotation.R
\name{salmonAnnotation}
\alias{salmonAnnotation}
\title{A function to annotate salmon output}
\usage{
salmonAnnotation(group = c("sudo", "docker"), fastq.folder, index.folder)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating the folder where input data are located and where output will be written, it should contain quant.sf file generated by salmonCounts}

\item{index.folder, }{a character string indicating the folder where Salmon transcriptome index was created with salmonIndex.}
}
\description{
This function executes a docker that convert the transcripts count file generated by Salmon quasi-alignment in the same format of isoforms.result, geness.result of  RSEM and add the ENSEMBL GTF based annotation
}
\examples{
\dontrun{
system("wget http://130.192.119.59/public/test_R1.fastq.gz")
system("wget http://130.192.119.59/public/test_R2.fastq.gz")
library(docker4seq)
#running salmonCounts
library(docker4seq)
wrapperSalmon(group="docker", scratch.folder="/data/scratch/",
              fastq.folder=getwd(), index.folder="/data/genomes/hg38salmon",
              threads=8, seq.type="pe", adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
              adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT", min.length=40, strandness="none")
#converting in a format identical to rsem isoform.results
salmonAnnotation(group="docker", fastq.folder=getwd(),
                 index.folder="/data/genomes/hg38salmon")

}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/demultiplexing.R
\name{demultiplexing}
\alias{demultiplexing}
\title{Generating running bcl2fastq}
\usage{
demultiplexing(group = c("sudo", "docker"), data.folder, threads = 8)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{data.folder, }{a character string indicating the Illumina folder where the Samplesheet.csv is located, and example of Samplesheet.cvs is in inst/examples folder}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
Fastq files
}
\description{
This function executes the Illumina bcl2fastq program
}
\examples{
\dontrun{
    #running rsemstar index for human
    demultiplexing(group="docker",
    data.folder="/home/calogero/Documents/data/lollini/3a_run/170712_NB501050_0097_AH3FGNBGX3",
    threads=24)

}
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rsemAnnotate.R
\name{rsemanno}
\alias{rsemanno}
\title{Annotating RSEM gene.results using ENSEMBL annotation}
\usage{
rsemanno(
  group = c("sudo", "docker"),
  rsem.folder = getwd(),
  scratch.folder = "/data/scratch",
  org = c("hg19", "hg38", "mm10", "mm9"),
  truncating.expected.counts = FALSE,
  protein.anno = FALSE
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{rsem.folder, }{a character string indicating where gene.results and isoforms.results are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{org, }{a character string indicating the genome assembly used for mapping and counting with \code{"rsemstar"} function}

\item{truncating.expected.counts, }{a boolean logical variable indicating if the expected counts calculated by RSEM need to be converted in integer to be compliant with differnetial expression Bioconductor packages as DESeq2. Default is FALSE}

\item{protein.anno, }{a boolean logical variable indicating if instead of gene SYMBOL SWISSPROT symbol are used. This option is useful for integrating transcriptomics data with proteomics data}
}
\value{
one file: annotated_genes.results, which is the annotated version of gene.results.
}
\description{
This function executes the docker container annotate.1, where Bioconductor is used to annotated gene.results output of RSEM using ENSEMBL annotation
}
\examples{
\dontrun{
    #downloading fastq files
    system("wget http://130.192.119.59/public/genes.results.gz")
    gzip -d genes.results.gz
    #running rsemanno
    rsemanno(group="docker",rsem.folder=getwd(), scratch.folder="/data/scratch",
    org="hg38", truncating.expected.counts=FALSE,
    protein.anno=FALSE)

}
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pubmedNet.R
\name{pubmedNet}
\alias{pubmedNet}
\title{Creating networks on the basis of the links between genes ids and pubmedid}
\usage{
pubmedNet(group = c("sudo", "docker"), file)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{file, }{a character string indicating the output of DESeq or ANOVAlike to be used. In the same folder must be present also genes.edges file.}
}
\value{
one graph plot
}
\description{
This function build networks using the genes.edges generated by getInfo function and create a graph using the genes present in a file generated by DESeq or ANOVAlike
}
\examples{
\dontrun{
    pubmedNet(group="docker", file=paste(getwd(),"DE_anova_rankedBySD_filteredByPositivePatient.txt", sep="/"))

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bwaIndexUcsc.R
\name{bwaIndexUcsc}
\alias{bwaIndexUcsc}
\title{Generating bwa genome index for GATK variant call}
\usage{
bwaIndexUcsc(
  group = c("sudo", "docker"),
  genome.folder = getwd(),
  uscs.urlgenome = NULL,
  dbsnp.file = NULL,
  g1000.file = NULL,
  gatk = FALSE
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for bwa will be located}

\item{uscs.urlgenome, }{a character string indicating the URL from uscs download web page for the unmasked genome sequence of interest}

\item{dbsnp.file, }{a character string indicating the name of dbSNP vcf located in the genome folder. The dbSNP vcf, dbsnp_138.b37.vcf.gz and dbsnp_138.hg19.vcf.idx.gz, can be downloaded from ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37}

\item{g1000.file, }{a character string indicating the name of 1000 genome vcf located in the genome folder. The 1000 genomes vcf, Mills_and_1000G_gold_standard.indels.b37.vcf.gz and Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx.gz, can be downloaded from ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/}

\item{gatk, }{a boolean TRUE and FALSE that indicate if the index will be used for GATK analysis}
}
\value{
The indexed bwa genome reference sequence
}
\description{
This function executes the docker container bwa1 where BWA is installed. The index is created using GATK bundle data genome fasta file. User needs to dowload the file in the genome folder from ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle
}
\examples{
\dontrun{
    #running bwa index
    bwaIndexUcsc(group="sudo",genome.folder="data/genomes/hg19_bwa", uscs.urlgenome=
    "http://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz",
    dbsnp.file="dbsnp_138.hg19.vcf.gz", g1000.file="Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz",
    gatk=TRUE)

    #running bwa index
    bwaIndexUcsc(group="sudo",genome.folder="/data/genomes/mm10bwa", uscs.urlgenome=
    "http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz",
    gatk=FALSE)


}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/star2steps.R
\name{star2steps}
\alias{star2steps}
\title{Running Star two steps for variant calls}
\usage{
star2steps(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  genome.folder,
  groupid,
  threads = 1,
  opossum.preprocessing = FALSE
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR is located.}

\item{groupid, }{a character string to be inserted in the bam as identifier for the sample}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{opossum.preprocessing, }{a boolean TRUE or FALSE to use opossum for RNAseq data preprocessing https://wellcomeopenresearch.org/articles/2-6/v1}
}
\value{
three files: dedup_reads.bam, which is sorted and duplicates marked bam file, dedup_reads.bai, which is the index of the dedup_reads.bam, and dedup_reads.stats, which provides mapping statistics
}
\description{
This function executes the two steps STAR as sugested by best practice GATK for calling variants on RNAseq data only PE data are accepted
}
\examples{
\dontrun{
    #downloading fastq files
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    system("wget http://130.192.119.59/public/test_R2.fastq.gz")
    #running star2step nostrand pe
    star2steps(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
    genome.folder="/data/scratch/hg38star", groupid="test", threads=8, opossum.preprocessing=FALSE)

}
}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rsemStar.R
\name{rsemstar}
\alias{rsemstar}
\title{Running RSEM, Li and Dewey BMC Bioinformatics 2011 12:323}
\usage{
rsemstar(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  genome.folder,
  seq.type = c("se", "pe"),
  strandness = c("none", "forward", "reverse"),
  threads = 1,
  save.bam = TRUE
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR is located. IMPORTANT the present function only suport genomic indexes made using ensembl genom and the corresponding gtf}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing}

\item{strandness, }{a character string indicating the type ofsequencing protocol used for the analysis. Three options: \code{"none"}, \code{"forward"}, \code{"reverse"} respectively for non strand selection, forward for Illumina strandness protocols, reverse for ACCESS Illumina protocol}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{save.bam, }{a boolean TRUE FALSE to decide if bam files are saved}
}
\value{
three files: dedup_reads.bam, which is sorted and duplicates marked bam file, dedup_reads.bai, which is the index of the dedup_reads.bam, and dedup_reads.stats, which provides mapping statistics
}
\description{
This function executes the docker container rsemstar1, where RSEM is used to calculate gene/isoforms counts using as mapper STAR, Dubin et al. Bioinformatics. 2013 Jan 1;29(1):15-21
}
\examples{
\dontrun{
    #downloading fastq files
system("wget http://130.192.119.59/public/test_R1.fastq.gz")
system("wget http://130.192.119.59/public/test_R2.fastq.gz")
library(docker4seq)
#running rsemstar nostrand pe
rsemstar(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch/",
         genome.folder="/data/genomes/hg38star/", seq.type="pe", strandness="none",
         threads=8, save.bam = FALSE)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circrnaPrepareFiles.R
\name{circrnaPrepareFiles}
\alias{circrnaPrepareFiles}
\title{Function to prepare the CircHunter reference annotations}
\usage{
circrnaPrepareFiles(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder,
  assembly = "hg19",
  version = NULL
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{data.folder, }{a character string indicating the data folder where the output files will be saved}

\item{assembly, }{string indicating the reference human genome assembly. Compatible assemblies: hg19 (default), hg18, hg38, mm9, mm10, rn6, dm6, ce11}

\item{version, }{Ensembl database version used for the analysis. If no version number is provided, the last version is considered}
}
\value{
Two tab-delimited tables reporting the exons and the transcript isoforms annotations of an user-selected human genome assembly
}
\description{
This function executes the docker container circhunter by running the circRNA classification module of CircHunter starting from a set of circRNAs. For CircHunter algorithm detail please refer to: https://github.com/carlo-deintinis/circhunter/tree/master/CircHunter.
}
\examples{
\dontrun{
    #Download the example data
    system("wget https://github.com/carlo-deintinis/circhunter/archive/master.zip")
    system("unzip master.zip")

    #running the circrnaPrepareFiles function
    circrnaPrepareFiles(group="docker", scratch.folder="/data/scratch", data.folder="/data/output", assembly="hg19")

}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sampleSize.R
\name{sampleSize}
\alias{sampleSize}
\title{A wrapper function for sample_size_distribution function from RnaSeqSampleSize Bioconductor package}
\usage{
sampleSize(
  group = c("sudo", "docker"),
  filename,
  power = 0.8,
  FDR = 0.1,
  genes4dispersion = 200,
  log2fold.change = 1,
  output.folder = getwd()
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{filename, }{a character string indicating the name of the count table file}

\item{power, }{expected statistical power required to detect prognostic genes}

\item{FDR, }{false discovery rate}

\item{genes4dispersion, }{an integer indicating the number of genes used in estimation of read counts and dispersion distribution}

\item{log2fold.change, }{an integer indicating the minimum log2 fold change for prognostic genes between two groups}

\item{output.folder, }{a string indicating the path where to save the output file}
}
\value{
a string with the requested informations. the string is also saved in a file: sample_size_evaluation.txt , power_evaluation.txt
}
\description{
This function executes sample_size_distribution to identify the number of samples x group needed to obtain a specific statistical power
}
\examples{
\dontrun{
   system("wget 130.192.119.59/public/test.analysis.zip")
   unzip("test.analysis.zip")
   setwd("test.analysis")
   library(docker4seq)
   sampleSize(group="docker", filename="_counts.txt", power=0.80, FDR=0.1,
   genes4dispersion=200, log2fold.change=1)
}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rsemBw.R
\name{rsemBw}
\alias{rsemBw}
\title{Creating a bigwig using RSEM}
\usage{
rsemBw(
  group = c("sudo", "docker"),
  bam.folder = getwd(),
  scratch.folder = "/data/scratch"
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{bam.folder, }{a character string indicating where BAM SORTED file is located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}
}
\value{
output.bw, which is the bigwig
}
\description{
This function executes the docker container rsemstar where RSEM is installed and create a bigwig file for genomic data visualization
}
\examples{
\dontrun{
    #downloading fastq files
    rsemBw(group="docker",bam.folder=getwd(), scratch.folder="/data/scratch")


}
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/heatmaply.R
\name{heatmaply}
\alias{heatmaply}
\title{Function to produce an interactive heatmap using plot.ly}
\usage{
heatmaply(
  group = c("docker", "sudo"),
  scratch.folder,
  count.table,
  gene.list,
  output.folder,
  separator = c("TAB", "COMMA", "SPACE"),
  status = c("raw", "log"),
  color.palette = c("viridis", "BrBG", "magma", "plasma", "cividis")
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{count.table, }{a character string indicating the path of the counts table file}

\item{gene.list, }{a character string indicating the path of the file containing the genes to include in the heatmap}

\item{output.folder, }{a character string indicating the path of the output folder}

\item{separator, }{a character string indicating the separator character in the count table. Allowed characters are TAB, COMMA  and SPACE}

\item{status, }{a character string, 'raw' if the data are raw counts, 'log' otherwise}

\item{color.palette, }{a string indicating the color palette to be used in the heatmap. Available palettes are Viridis, BrBG, magma, plasma and cividis}
}
\value{
A html file containing the interactive heatmap produced using plot.ly
}
\description{
This function generates an heatmap using a count table and a specific gene list
}
\examples{
\dontrun{

}
}
\author{
Nicola Licheri, nicola [dot] licheri [at] unito [dot] it, University of Turin
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapperSalmon.R
\name{wrapperSalmon}
\alias{wrapperSalmon}
\title{A function to estimate counts using Salmon quasi-alignment}
\usage{
wrapperSalmon(
  group = c("sudo", "docker"),
  scratch.folder,
  fastq.folder,
  index.folder,
  threads = 24,
  seq.type = c("se", "pe"),
  adapter5,
  adapter3,
  min.length,
  strandness = c("none", "forward", "reverse")
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{fastq.folder, }{a character string indicating the folder where input data are located and where output will be written}

\item{index.folder, }{a character string indicating the folder where transcriptome index was created with salmonIndex.}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{seq.type, }{a character string indicating the type of reads to be generated by the sequencer. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing. Strandness is inferred by salmon.}

\item{adapter5, }{a character string indicating the fwd adapter}

\item{adapter3, }{a character string indicating the rev adapter}

\item{min.length, }{a number indicating minimal length required to return a trimmed read}

\item{strandness, }{a character string indicating the type ofsequencing protocol used for the analysis. Three options: \code{"none"}, \code{"forward"}, \code{"reverse"} respectively for non strand selection, reverse for Illumina strandness protocols, reverse for ACCESS Illumina protocol}
}
\description{
This function executes a docker that produces as output the transcripts count file generated by Salmon quasi-alignment and convert it  the same format of isoforms.result of  RSEM
}
\examples{
\dontrun{
system("wget http://130.192.119.59/public/test_R1.fastq.gz")
system("wget http://130.192.119.59/public/test_R2.fastq.gz")
library(docker4seq)
#running salmonCounts
wrapperSalmon(group="docker", scratch.folder="/scratch/users/rcaloger/",
        fastq.folder=getwd(), index.folder="/archive/home/rcaloger/data/seqbox/salmonIndex.R",
        threads=24, seq.type="pe", adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
        adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT", min.length=40, strandness="none")
}


}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mirnaCounts.R
\name{mirnaCounts}
\alias{mirnaCounts}
\title{Counting miRNAs, Cordero et al. PLoS One. 2012;7:e31630}
\usage{
mirnaCounts(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  mirbase.id = c("hsa", "mmu"),
  download.status = FALSE,
  adapter.type = c("ILLUMINA", "NEB"),
  trimmed.fastq = FALSE
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where mirna fastq are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{mirbase.id, }{a character string indicating the mirbase prefix for the organism of interest, e.g. hsa for human or mmu for mouse}

\item{download.status, }{a boolean logical variable indicating if the latest mirbase database will be downloaded or the local mirbase 21 will be used. Default is FALSE}

\item{adapter.type, }{a character string. Two options: \code{"ILLUMINA"} or \code{"NEB"}, depending to which miRNA library prep was used: ILLUMINA or NEB}

\item{trimmed.fastq, }{a boolean logical variable indicating if trimmed fastq are saved. Default is FALSE}
}
\value{
one file: annotated_genes.results, which is the annotated version of gene.results.
}
\description{
This function executes the docker container mrna8, which allows miRNAs counting.
}
\examples{
\dontrun{
   system("wget 130.192.119.59/public/test.mirnaCounts.zip")
   unzip("test.mirnaCounts.zip")
   setwd("test.mirnaCounts")
   library(docker4seq)
   mirnaCounts(group="docker",fastq.folder=getwd(),
             scratch.folder="/data/scratch",
             mirbase.id="hsa",download.status=FALSE,
             adapter.type="NEB", trimmed.fastq=FALSE)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/samples2experiment.R
\name{sample2experiment}
\alias{sample2experiment}
\title{generating counts, FPKM and TPM tables from rnaseqCounts outuputs}
\usage{
sample2experiment(
  sample.folders,
  covariates,
  batch = NULL,
  bio.type = c("protein_coding", "unitary_pseudogene", "unprocessed_pseudogene",
    "processed_pseudogene", "transcribed_unprocessed_pseudogene", "processed_transcript",
    "antisense", "transcribed_unitary_pseudogene", "polymorphic_pseudogene", "lincRNA",
    "sense_intronic", "transcribed_processed_pseudogene", "sense_overlapping",
    "IG_V_pseudogene", "pseudogene", "TR_V_gene", "3prime_overlapping_ncRNA",
    "IG_V_gene", "bidirectional_promoter_lncRNA", "snRNA", "miRNA", "misc_RNA", "snoRNA",
    "rRNA", "IG_C_gene", "IG_J_gene",      "TR_J_gene", "TR_C_gene", "TR_V_pseudogene",
    "TR_J_pseudogene", "IG_D_gene", "ribozyme", "IG_C_pseudogene", "TR_D_gene", "TEC",
    "IG_J_pseudogene", "scRNA", "scaRNA", "vaultRNA", "sRNA", "macro_lncRNA",
    "non_coding", "IG_pseudogene"),
  output.prefix = "."
)
}
\arguments{
\item{sample.folders, }{a character string indicating the paths of rnaseqCouts output folders}

\item{covariates, }{a character string indicating the covariates associated to each sample. Covariates are required for differnetial expression analysis}

\item{batch, }{a character string indicating the batch associated to each sample}

\item{bio.type, }{a character string indicating the ensemb bio.type. Options: "protein_coding","unitary_pseudogene","unprocessed_pseudogene","processed_pseudogene", "transcribed_unprocessed_pseudogene","processed_transcript","antisense","transcribed_unitary_pseudogene","polymorphic_pseudogene","lincRNA","sense_intronic","transcribed_processed_pseudogene","sense_overlapping","IG_V_pseudogene","pseudogene","TR_V_gene","3prime_overlapping_ncRNA","IG_V_gene","bidirectional_promoter_lncRNA","snRNA","miRNA","misc_RNA","snoRNA","rRNA","IG_C_gene","IG_J_gene","TR_J_gene","TR_C_gene","TR_V_pseudogene","TR_J_pseudogene","IG_D_gene","ribozyme","IG_C_pseudogene","TR_D_gene","TEC","IG_J_pseudogene","scRNA","scaRNA","vaultRNA","sRNA","macro_lncRNA","non_coding","IG_pseudogene"}

\item{output.prefix, }{a character value indicating the output folder path}
}
\value{
Returns counts, fpkm, tpm data frames for gene and isoforms, save data frames in experiment.tables.Rda, in counts.txt, log2fpkm.txt and in log2TPM
}
\description{
This function generates counts, FPKM and TPM tables from rnaseqCounts outuputs.
}
\examples{
\dontrun{
  system("wget http://130.192.119.59/public/test.samples2experiment.zip")
  unzip("test.samples2experiment.zip")
  setwd("test.samples2experiment")
  library(docker4seq)
  sample2experiment(sample.folders=c("./e1g","./e2g","./e3g",
                 "./p1g", "./p2g", "./p3g"),
                 covariates=c("Cov.1","Cov.1","Cov.1",
                 "Cov.2","Cov.2","Cov.2"),
                 bio.type="protein_coding", output.prefix=".")
}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/oncosnpAnnotation.R
\name{oncosnpAnnotation}
\alias{oncosnpAnnotation}
\title{A function to associate CNV generated by oncSNP starting from log R ratio and B allel frequences, generated by SNP arrays, to gene symbols}
\usage{
oncosnpAnnotation(group = c("sudo", "docker"), data.folder, genome.folder)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{data.folder, }{a character string indicating the folder where input data (.cnvs) generated with oncoSNP are located and where output will be written}

\item{genome.folder, }{a character string indicating the path of the folder where ENSEMBL genome.gtf is located, IMPORTANT use the same genome assembly used to design the array.}
}
\value{
a file for each .cnvs, e.g. annotation_XXXX.cnvs.txt
}
\description{
This function executes a ubuntu docker that uses as input the cnvs files produced by oncoSNP and add CN and LOH (check oncoSNP readme for more info) fields (rank 5 only) to the genes characterized by having genomics cohordinates included in the CNV region
}
\examples{
\dontrun{
    #running oncosnpAnnotation
system("wget http://130.192.119.59/public/test_oncosnp.zip")
system("unzip test_oncosnp.zip")
oncosnpAnnotation(group="docker", data.folder="./test_oncosnp/oncosnp_out", genome.folder="./test_oncosnp/hg19")
}

}
\author{
Raffaele Calogero, raffaele.calogero[at]unito[dot]it, University of Torino, Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chipseq.R
\name{chipseq}
\alias{chipseq}
\title{Detection and annotation of TF binding sites and histone marks, based on the workflow used in Galli et al Mol Cell. 2015 Oct 15;60(2):328-37}
\usage{
chipseq(
  group = c("sudo", "docker"),
  bam.folder = getwd(),
  sample.bam,
  ctrl.bam,
  scratch.folder = "/data/scratch",
  genome = c("hg19", "hg38", "mm9", "mm10"),
  read.size,
  tool = c("macs", "sicer"),
  macs.min.mfold = 10,
  macs.max.mfold = 30,
  macs.pval = "1e-5",
  sicer.wsize = 200,
  sicer.gsize = c(200, 600),
  sicer.fdr = 0.1,
  tss.distance = 0,
  max.upstream.distance = 10000,
  remove.duplicates = c("Y", "N")
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{bam.folder, }{a character string indicating where bam files are located}

\item{sample.bam, }{a character string indicating the chipseq file under analysis}

\item{ctrl.bam, }{a character string indicating the control file, e.g. unspecific IgG, input DNA, etc.}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome, }{a character string indicating the genome used as reference for data generation. Available options: hg19, hg38, mm9, mm10}

\item{read.size, }{an integer indicating the length of the sequenced reads}

\item{tool, }{a character string indicating the peaks calling algorith. Available options: macs and sicer. Macs, v 1.14, is used to call TF peaks, as instead sicer, v 1.1, is used to call histone mark peaks}

\item{macs.min.mfold, }{an integer indicating the minimum enrichment ratio against background}

\item{macs.max.mfold, }{an integer indicating the maximum enrichment ratio against background}

\item{macs.pval, }{a character string, indicationg the pvalue cutoff to be used to filter peaks with low statistical significance.The number must be provided in scientific notation as the default value shows}

\item{sicer.wsize, }{an integer indicating the windows size to be used by sicer}

\item{sicer.gsize, }{an integer indicating the gap size to be used by sicer. Suggested values: H3K4Me3=200; H3K27Me3=600}

\item{sicer.fdr, }{an integer indicating the pvalue cutoff to be used to filter peaks with low statistical significance}

\item{tss.distance, }{an integer indicating the distance of TSS with respect to gene start}

\item{max.upstream.distance, }{an integer indicating the maximum distance to associate a gene ID to a peak}

\item{remove.duplicates, }{a character string indicating if duplicated reads have to be removed. Available options: Y, to remove douplicates, N to keep duplicates}
}
\value{
three files: dedup_reads.bam, which is sorted and duplicates marked bam file, dedup_reads.bai, which is the index of the dedup_reads.bam, and dedup_reads.stats, which provides mapping statistics
}
\description{
This function executes the docker container chipseq.8 and requires as input two bam files, one for the chipseq of interest and the other for control, e.g. mock, which can be generated with bwa function.
}
\examples{
\dontrun{
    system("wget http://130.192.119.59/public/SRR1172111.bam")#TEAD
    system("wget http://130.192.119.59/public/SRR1172110.bam")#igg
    system("wget http://130.192.119.59/public/SRR1592211.bam")#H3K27ac
    #running chipseq for macs
    chipseq(group="sudo",bam.folder=getwd(), sample.bam="SRR1172111.bam", ctrl.bam="SRR1172110.bam",
    scratch.folder="/data/scratch", genome="hg19", read.size=50,
    tool="macs", macs.min.mfold=10, macs.max.mfold=30, macs.pval="1e-5",
    sicer.wsize=200, sicer.gsize=200, sicer.fdr=0.10, tss.distance=0, max.upstream.distance=10000,
    remove.duplicates="N")

    #running chipseq for sicer H3K4Me3
    chipseq(group="sudo",bam.folder=getwd(), sample.bam="SRR1592211.bam", ctrl.bam="SRR1172110.bam",
    scratch.folder="/data/scratch", genome="hg19", read.size=50,
    tool="sicer", sicer.wsize=200, sicer.gsize=200, sicer.fdr=0.10,
    tss.distance=0, max.upstream.distance=10000,remove.duplicates="N")
}
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/testSeqBox.R
\name{testSeqbox}
\alias{testSeqbox}
\title{Testing the SeqBox basic installation}
\usage{
testSeqbox()
}
\value{
testSeqBox.out file containing the results of the tests
}
\description{
This function executes a set of scripts to check if SeqBox installation is OK. It requests the existence of the following folders: /data/genomes, /data/scratch, /data/tests. /data/genomes folder must contain the following folders: hg38star  mm10bwa  mm10star
}
\examples{
\dontrun{
    #downloading in /data/genomes
    setwd("/data/genomes")
    system("wget http://130.192.119.59/public/hg38star.tar.gz")
    system("wget http://130.192.119.59/public/mm10star.tar.gz")
    system("wget http://130.192.119.59/public/mm10bwa.tar.gz")
    system("wget http://130.192.119.59/public/hg38salmon.tar.gz")
    system("gzip -d *.gz")
    system("tar xvf *.tar")
    setwd("/data/")
    system("wget http://130.192.119.59/public/tests.tar.gz")
    system("gzip -d tests.tar.gz")
    system("tar xvf tests.tar")
    system("rm tests.tar")
    #running test SeqBox
    library(docker4seq)
    testSeqbox()

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mergeData.R
\name{mergeData}
\alias{mergeData}
\title{Function to merge different circRNA lists from CIRI 2}
\usage{
mergeData(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder,
  samples.ids,
  covariates,
  covariate.order,
  extension,
  column_index
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{data.folder, }{a character string indicating the data folder where the file to merge are located}

\item{samples.ids, }{a character vector indicating the identifiers of the samples}

\item{covariates, }{a character vector indicating the classes of the samples}

\item{covariate.order, }{a character vector indicating a vector reporting the covariate classes ordered as desidered in the output file}

\item{extension, }{a character string indicating the filename extension of the files that have to merge}

\item{column_index, }{an integer value > 1 indicating which column values have to been reported in the output file}
}
\value{
Two tab-delimited tables reporting the BS supporting reads and the coordinates of the filtered circRNAs are reported
}
\description{
This function executes the docker container ciri2merge by running the merge of different lists of circRNAs predicted by CIRI2  following a sample data files provided by the user. The function executes also a filter based on the number of back-splicing reads computed in each experiment and across replicates of the same biological condition.
}
\examples{
\dontrun{

}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/expandsReformat.R
\name{prepare4expands}
\alias{prepare4expands}
\title{A function to handle a docker containier preparing the file needed for expanse}
\usage{
prepare4expands(group = c("sudo", "docker"), data.folder)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}
}
\value{
cnv.txt and snv.txt
}
\description{
This function executes a ubuntu docker that produces the cnv.txt and snv.txt needed for expanse
}
\examples{
\dontrun{
    system("wget http://130.192.119.59/public/prepare4expanse.zip")
    system("unzip prepare4expanse.zip")
    prepare4expands(group="docker", data.folder=paste(getwd(), "prepare4expanse", sep="/"))
}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, University of Torino
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/skewer.R
\name{skewer}
\alias{skewer}
\title{Running skewer, an adapter trimmer application, Jiang et al BMC Bioinformatics201415:182}
\usage{
skewer(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  adapter5,
  adapter3,
  seq.type = c("se", "pe"),
  threads = 1,
  min.length = 18
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{adapter5, }{a character string indicating the fwd adapter}

\item{adapter3, }{a character string indicating the rev adapter}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing.}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{min.length, }{a number indicating minimal length required to return a trimmed read}
}
\value{
One or two gzip fastq files ending with trimmed-pair1.fastq.gz and trimmed-pair1.fastq.gz, a log file of the trimming with the extensione trimmed.log, run.info file descring the analysis steps done by the docker. The latter file is useful to understand where the docker stop in case of unexpected end
}
\description{
This function executes the docker container skewer1 to remove sequencing adapters from RNAseq reads
}
\examples{
\dontrun{
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    system("wget http://130.192.119.59/public/test_R2.fastq.gz")
    skewer(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
    adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
    adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
    seq.type="pe", threads=10,  min.length=40)
}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circrnaBSJunctions.R
\name{circrnaBSJunctions}
\alias{circrnaBSJunctions}
\title{Running CircHunter circRNA backsplicing sequence reconstruction module}
\usage{
circrnaBSJunctions(
  group = c("sudo", "docker"),
  scratch.folder,
  circrna.data,
  exon.data,
  assembly = "hg19"
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{circrna.data, }{string indicating the path to the list of circRNAs}

\item{exon.data, }{string indicating the path to the exon annotation file}

\item{assembly, }{string indicating the reference human genome assembly. Compatible assemblies: hg19 (default), hg18, hg38, mm9, mm10, rn6, dm6, ce11.}
}
\value{
A fasta file reporting the sequence of circRNA back-splice junctions
}
\description{
This function executes the docker container circhunter by running the circRNA back-splicing sequence reconstruction module of CircHunter starting from a set of circRNAs. For CircHunter algorithm detail please refer to: https://github.com/carlo-deintinis/circhunter/tree/master/CircHunter.
}
\examples{
\dontrun{

    #retrieve the example data
    system("wget https://github.com/carlo-deintinis/circhunter/archive/master.zip")
    system("unzip master.zip")

    #running the circrnaBSJunctions function
    circrnaBSJunctions(group="docker", scratch.folder="/data/scratch", circrna.data=paste(getwd(),"/circhunter-master/CircHunter/toyexample/toy_circRNA", sep=""), exon.data=paste(getwd(),"/circhunter-master/CircHunter/toyexample/toy_genome", sep=""), assembly="hg19")

}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cutadapt.R
\name{cutadapt}
\alias{cutadapt}
\title{Function to execute Cutadapt on RNA-Seq reads}
\usage{
cutadapt(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder,
  adapter.type = c("ILLUMINA", "NEB"),
  threads = 1
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{data.folder, }{a character string indicating where fastq files are located}

\item{adapter.type, }{a character string. Two options: \code{"ILLUMINA"} or \code{"NEB"}, depending to which miRNA library prep was used: ILLUMINA or NEB}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
The fastq files of the trimmed sequencing reads
}
\description{
This function executes the docker container  by running CutAdapt algorithm a the input RNA-Seq dataset to remove the sequencing adapters.
}
\examples{
\dontrun{
...
}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circexplorer2.R
\name{CIRCexplorer2}
\alias{CIRCexplorer2}
\title{Running CIRCexplorer2 parse command for circRNAs prediction from STAR or BWA alignment output}
\usage{
CIRCexplorer2(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder,
  fusion.file,
  used.aligner = c("STAR", "BWA")
)
}
\arguments{
\item{group, }{a string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a string indicating the scratch folder where docker container will be mounted}

\item{data.folder, }{a string indicating the path of the output folder}

\item{fusion.file, }{a string indicating the path of the fusion file. If the used aligner was BWA, the fusion file is the resulting sam file, whereas the used aligner was STAR, the fusion file is the Chimeric.out.junction file}

\item{used.aligner, }{a string indicating the aligner used to generate the junctions.file. Supported aligners are STAR and BWA}
}
\description{
This function executes the circexplorer2 docker container which parses the fusion file generated by STAR or BWA and extracts circRNA coordinates
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rsemstarUcscIndex.R
\name{rsemstarUscsIndex}
\alias{rsemstarUscsIndex}
\title{Generating rsem-star genome index}
\usage{
rsemstarUscsIndex(
  group = c("sudo", "docker"),
  genome.folder = getwd(),
  uscs.urlgenome = NULL,
  uscs.gtf = NULL,
  uscs.urlknownIsoforms = NULL,
  uscs.urlknownToLocusLink = NULL,
  threads = 1
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome will be located}

\item{uscs.urlgenome, }{a character string indicating the URL from uscs download web page for the unmasked genome sequence of interest}

\item{uscs.gtf, }{a character string indicating the path of the GTF file for genome of interest}

\item{uscs.urlknownIsoforms, }{a character string indicating the URL from uscs download web page for the knowisoforms file for genome of interest}

\item{uscs.urlknownToLocusLink, }{a character string indicating the URL from uscs download web page for the knownToLocusLink file for genome of interest}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
The indexed genome reference sequence
}
\description{
This function executes the docker container rsem-star1 where RSEM and STAR are installed. The index is created using ENSEMBL genome fasta file. User needs to provide the URL for ENSEMBL genome located in the ENSEMBL ftp
}
\examples{
\dontrun{
    #running rsemstar index for human
    rsemstarUscsIndex(group="sudo",genome.folder="/data/scratch/hg19UCSCstar",
    uscs.urlgenome=
    "http://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz",
    uscs.gtf=
    "/Users/raffaelecalogero/Desktop/hg19_ucsc.gtf.gz",
    uscs.urlknownIsoforms=
    "http://hgdownload.soe.ucsc.edu/goldenPath/hg19/database/knownIsoforms.txt.gz",
    uscs.urlknownToLocusLink=
    "http://hgdownload.soe.ucsc.edu/goldenPath/hg19/database/knownToLocusLink.txt.gz",
    threads=24)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bwaIndex.R
\name{bwaIndex}
\alias{bwaIndex}
\title{Generating bwa genome index}
\usage{
bwaIndex(
  group = c("sudo", "docker"),
  genome.folder = getwd(),
  genome.url = NULL,
  gtf.url = NULL,
  dbsnp.file = NULL,
  g1000.file = NULL,
  mode = c("General", "GATK", "miRNA", "ncRNA"),
  mb.version = NULL,
  mb.species = NULL,
  rc.version = NULL,
  rc.species = NULL,
  length = NULL
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for bwa will be located}

\item{genome.url, }{a character string indicating the URL from download web page for the genome sequence of interest}

\item{gtf.url, }{a character string indicating the URL from ENSEMBL ftp for the GTF for genome of interest}

\item{dbsnp.file, }{a character string indicating the name of dbSNP vcf located in the genome folder. The dbSNP vcf, dbsnp_138.b37.vcf.gz and dbsnp_138.hg19.vcf.idx.gz, can be downloaded from ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37}

\item{g1000.file, }{a character string indicating the name of 1000 genome vcf located in the genome folder. The 1000 genomes vcf, Mills_and_1000G_gold_standard.indels.b37.vcf.gz and Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx.gz, can be downloaded from ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/}

\item{mode, }{a character string indicating the required type of analysis. Compatible analyses mode are "General", "GATK", "miRNA", and "ncRNA". In "General" mode the url of any online fasta file ("genome.url" argument) can be provided and indexed, only canonical cromosopmes are kept see id.fa after end of indexing. In the GATK analysis mode, the list of variants from dbsnp ("dbsnp.file" argument) and g1000 ("dbsnp.file" argument) are required in addition to the url of the genome fasta ("genome.url" argument). In "miRNA" analysis mode, the version ("mb.version" argument) and species prefix ("mb.species" argument) of miRBase are required. In "ncRNA" analysis mode, the version ("rc.version" argument) and species prefix ("rc.species" argument) of RNA Central are required. This mode require also a desidered maximum length of the studied RNA annotations ("length" argument).}

\item{mb.version, }{a character string indicating the required version of miRBase database. Visit http://www.mirbase.org to select the proper version number.}

\item{mb.species, }{a character string indicating the name of a species annotated in miRBase (e.g. "hsa" for human miRNAs). Please refer to http://www.mirbase.org/help/genome_summary.shtml to proper species name.}

\item{rc.version, }{a character string indicating the required version of RNA Central database. Visit ftp://ftp.ebi.ac.uk/pub/databases/RNAcentral/releases/ to select the proper version number.}

\item{rc.species, }{a character string indicating the name of a species annotated in RNA Central (e.g. "Homo sapiens" for human ncRNAs). Please refer to NCBI taxonomy annotations at https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi to proper species name.}

\item{length, }{an integer corresponding on the length threshold selected to define the ncRNA reference from RNA Central.}
}
\value{
The indexed bwa reference sequence
}
\description{
This function executes the docker container bwa1 where BWA is installed. Optionally, the index can be created also for GATK bundle data genome fasta file.
}
\examples{
\dontrun{

    #running generic bwa index
    bwaIndex(group="docker", genome.folder="/data/genomes/mm10bwa", genome.url="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.fna.gz", mode="General")
    #running bwa index for gatk
    bwaIndex(group="docker", genome.folder="/data/genomes", genome.url="http://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz", dbsnp.file="dbsnp_138.hg19.vcf.gz", g1000.file="Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz", mode="GATK")

    #running bwa index for miRNA analysis
    bwaIndex(group="docker", genome.folder="/data/genomes", mb.version="22", mb.species="hsa", mode="miRNA")

    #running bwa index for ncRNA analysis
    bwaIndex(group="docker", genome.folder="/data/genomes/hg19_bwa", rc.version="9", rc.species="Homo sapiens", length=80, mode="ncRNA")
}
}
\author{
Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fasterq.dump.R
\name{sraDownload}
\alias{sraDownload}
\title{A function to handle fasterq-dumper SRA to download SRA fastq files}
\usage{
sraDownload(
  group = c("sudo", "docker"),
  sra.name,
  data.folder,
  scratch.folder,
  threads = 8
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{sra.name, }{a character string indicating the name of the SRA object to be download}

\item{data.folder, }{a character string indicating the working folder where output folder will be written}

\item{scratch.folder, }{a character string indicating the temporary folder for data preprocessing}

\item{threads, }{a integer indicating the number of threads to be used from fasterq-dumper}
}
\description{
This function executes a ubuntu docker that produces as output FASTQCstdin_fastqc.html and stdin_fastqc.zip files
}
\examples{
\dontrun{
    #running sraDownload
    sraDownload(group="docker", sra.name="SRR7762358", data.folder=getwd(), scratch.folder="/data/scratch", threads=8)
    system("mv ./SRR7762358/SRR7762358.fastq.gz ./SRR7762358/SRR7762358_S1_L001_R1_001.fastq.gz")
}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, University of Torino
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/platypusFilter.R
\name{platypusFilter}
\alias{platypusFilter}
\title{Platypus filter analysis NOT READY TO GO ON STABLE to be used in case the full platypus workflow fail.}
\usage{
platypusFilter(
  group = c("sudo", "docker"),
  data.folder = getwd(),
  scratch.folder,
  GQ,
  minSampGQ,
  NR,
  minSampNR,
  NV,
  minSampNV,
  normal_samples,
  GT_normal,
  minSampGT_normal,
  tumoral_samples,
  GT_tumoral,
  minSampGT_tumoral,
  stringent_filter,
  annotation
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{data.folder, }{a character string indicating the folder where bams and vcf files are located and where output will be written}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{GQ, }{min GQ value to consider (extreme included)}

\item{minSampGQ, }{min number of samples with GQ value (extreme included), usually we start with 85\% of the samples}

\item{NR, }{min NR value to consider (extreme included), the number of reads covering the SNV region}

\item{minSampNR, }{min number of samples with NR value (extreme included), usually we start with 85\% of the samples}

\item{NV, }{min NV value to consider (extreme included), the n of reads with the SNV}

\item{minSampNV, }{min number of samples with NV value (extreme included)}

\item{normal_samples, }{string with names (group names of bam files) of normal samples separated by hash, write NULL if you do not want to use GT filter in normal samples}

\item{GT_normal, }{GT value in normal samples to consider, type "NO" if you do not want to use this filter, else e.g. you might use 0/0}

\item{minSampGT_normal, }{min number of normal samples with GT value}

\item{tumoral_samples, }{string with names (group names of bam files) of tumoral samples separated by &, write NULL if you do not want to use GT filter in normal samples}

\item{GT_tumoral, }{GT value in tumoral samples to consider, type "NO" if you do not want to use this filter. Type e.g. 0/0 if you do not want to consider this genotype.}

\item{minSampGT_tumoral, }{min number of tumoral samples in which the GT value is NOT present}

\item{stringent_filter, }{To enable the filter (it keeps only the variants with "PASS" value or the variants that have only the "alleleBias" value) use 1 or 0 to disable it}

\item{annotation, }{hg19 and mm10 are actually available for the annotation of the detected SNVs}
}
\description{
This function executes platypusFilter filtering the single_variants.vcf generated by platypys function.
}
\examples{
\dontrun{
    #filtering platypus results 
 platypusFilter(group="docker", data.folder="/archive/home/rcaloger/data/platypus_tests/mm10ENSEMBL", 
        scratch.folder="/scratch/users/rcaloger/",
        GQ=10, minSampGQ=2, NR=10, minSampNR=2, NV=3, 
        minSampNV=1, normal_samples="MAMBO43", GT_normal="0/0", 
        minSampGT_normal=1, tumoral_samples="MAMBO43TRT#MAMBO43TRNT", GT_tumoral="0/0", 
        minSampGT_tumoral=1, stringent_filter=0, annotation="mm10")
}
}
\author{
Riccardo Panero, riccardo.panero[at]gmail[dot]com, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rnaseqCounts.R
\name{rnaseqCounts}
\alias{rnaseqCounts}
\title{Running RNAseq counting workflow for a single sample}
\usage{
rnaseqCounts(
  group = "sudo",
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  threads = 4,
  adapter5,
  adapter3,
  seq.type = "pe",
  min.length = 40,
  genome.folder = "/data/genomes/hg38star",
  strandness = "none",
  save.bam = TRUE,
  org = "hg38",
  annotation.type = "gtfENSEMBL"
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{adapter5, }{a character string indicating the fwd adapter}

\item{adapter3, }{a character string indicating the rev adapter}

\item{seq.type, }{a character string indicating the type of reads to be generated by the sequencer. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing.}

\item{min.length, }{a number indicating minimal length required to return a trimmed read
#params rsemstar}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome is located. IMPORTANT the present function only suport genomic indexes made using ensembl genom and the corresponding gtf}

\item{strandness, }{a character string indicating the type ofsequencing protocol used for the analysis. Three options: \code{"none"}, \code{"forward"}, \code{"reverse"} respectively for non strand selection, reverse for Illumina strandness protocols, reverse for ACCESS Illumina protocol}

\item{save.bam, }{a boolean value, TRUE or FALSE, to save also BAM files generated by STAR and RSEM
#params rsemanno}

\item{org, }{a character string indicating the genome assembly used for mapping and counting with \code{"rsemstar"} function only required for biocENSEMBL based annotation}

\item{annotation.type, }{a character string. Two options: \code{"biocENSEMBL"} or \code{"gtfENSEMBL"}. \code{"biocENSEMBL"} will annotate by Bioconductor only protein coding genes. \code{"gtfENSEMBL"} will annotate all RNAs described in \code{"annotation.type"}}
}
\value{
Returns the output of skewer, rsemstar, rsemannos' functions
}
\description{
This function executes a set of docker containers allowing the generation of gene and isoforms counts for a single sample.
#params skewer
}
\examples{
\dontrun{
system("wget http://130.192.119.59/public/test_R1.fastq.gz")
library(docker4seq)
rnaseqCounts(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch/",
            adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
            adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
            seq.type="se", threads=24,  min.length=40,
            genome.folder="/data/genomes/hg38star", strandness="none", save.bam=FALSE,
            org="hg38", annotation.type="gtfENSEMBL")
}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mirnaCovar.R
\name{mirnaCovar}
\alias{mirnaCovar}
\title{Adding covariates and batch information to miRNAseq raw counts output}
\usage{
mirnaCovar(experiment.folder, covariates = NULL, batches = NULL, output.folder)
}
\arguments{
\item{experiment.folder, }{a character string indicating the full paths to miRNAseq input file, i.e. including the name of the file}

\item{covariates, }{a character vector indicating the covariates associated to each sample, e.g. c("Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.2", "Cov.2", "Cov.2", "Cov.2"). Covariates are required for differential expression analysis}

\item{batches, }{a character vector indicating the covariates associated to each sample, e.g. c("bath.1", "bath.1", "bath.2", "bath.2", "batch.1", "batch.1", "batch.2", "batch.2"). Batch info might be required for differential expression analysis}

\item{output.folder, }{a character vector indicating the paths to miRNAseq output folder}
}
\value{
Returns 0 and a count file, i.e. all.counts.txt, with the prefix "w_covar" or w_covar_batch depending if only covariates were added or also batch info were added
}
\description{
This function modifies the all.counts.txt table generated from miRNAseq adding covariates and batch information
}
\examples{
\dontrun{
   system("wget 130.192.119.59/public/test.mirna.analysis.zip")
   unzip("test.mirna.analysis.zip")
   setwd("test.mirna.analysis")
   library(docker4seq)
   mirnaCovar(experiment.folder=paste(getwd(), "all.counts.txt", sep="/"),
          covariates=c("Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.1", "Cov.1",
                       "Cov.2", "Cov.2", "Cov.2", "Cov.2", "Cov.2", "Cov.2"),
          batches=c("bath.1", "bath.1", "bath.2", "bath.2", "batch.1", "batch.1",
                    "batch.2", "batch.2","batch.1", "batch.1","bath.2", "bath.2"), output.folder=getwd())
}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/skeleton.R
\name{skeleton}
\alias{skeleton}
\title{A skeleton function to handle a docker containier}
\usage{
skeleton(group = c("sudo", "docker"), scratch.folder, data.folder)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}
}
\description{
This function executes a ubuntu docker that produces as output helloworld.txt file
}
\examples{
\dontrun{
    #running skeleton
    skeleton(group="docker", scratch.folder="/Users/raffaelecalogero/Desktop/scratch", 
    data.folder=getwd())
}

}
\author{
Name Family name, myemail [at] somewhere [dot] org, Affiliation
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bowtie2.R
\name{bowtie2}
\alias{bowtie2}
\title{Running bowtie2}
\usage{
bowtie2(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  genome.folder,
  seq.type = c("se", "pe"),
  strandness = c("none", "forward", "reverse"),
  threads = 1
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR is located. IMPORTANT the present function only suport genomic indexes made using ensembl genom and the corresponding gtf}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing}

\item{strandness, }{a character string indicating the type ofsequencing protocol used for the analysis. Three options: \code{"none"}, \code{"forward"}, \code{"reverse"} respectively for non strand selection, forward for Illumina strandness protocols, reverse for ACCESS Illumina protocol}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
sorted.bam, sorted.bam.bai
}
\description{
This function executes the docker container bowtie2
}
\examples{
\dontrun{
    #downloading fastq files
system("wget http://130.192.119.59/public/test_R1.fastq.gz")
system("wget http://130.192.119.59/public/test_R2.fastq.gz")
library(docker4seq)
#running bowtie nostrand pe
bowtie2(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch/",
         genome.folder="/data/genomes/hg38bowtie2/", seq.type="pe", strandness="none",
         threads=8)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/heatmapBase.R
\name{heatmapBase}
\alias{heatmapBase}
\title{hfc, heatmap for clustering}
\usage{
heatmapBase(
  group = c("sudo", "docker"),
  scratch.folder,
  file,
  status = 0,
  lower.range = -1,
  upper.range = 1
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{file, }{a character string indicating the path of the file, with counts.table name and extension included}

\item{status, }{0 if is raw count, 1 otherwise}

\item{lower.range, }{the lower range of signal in the heatmap.}

\item{upper.range, }{the upper range of signal in the heatmap.}
}
\value{
A heatmap.
}
\description{
This function generate heatmap and other plot based on clustering and on a specific gene list
}
\examples{
\dontrun{
system("wget http://130.192.119.59/public/heatmap_test.zip")
system("unzip heatmap_test.zip")
setwd("heatmap_test")
heatmapBase(group="docker",scratch.folder="/data/scratch",file=paste(getwd(),"DEfiltered__log2TPM.txt", sep="/"), status=1, lower.range=-1, upper.range=1)
}
}
\author{
Luca Alessandri , alessandri [dot] luca1991 [at] gmail [dot] com, University of Torino
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cdhit.R
\name{cdhit}
\alias{cdhit}
\title{A function to execute CD-HIT}
\usage{
cdhit(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder,
  identity.threshold = 0.9,
  memory.limit = 30000,
  threads = 0,
  word.length = 7
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}

\item{identity.threshold, }{sequence identity threshold, default 0.9, this is the default cd-hit's global sequence identity calculated as: number of identical bases in alignment divided by the full length of the shorter sequence}

\item{memory.limit, }{memory limit in MB for the program, default 30000. 0 for unlimitted}

\item{threads, }{number of threads, default 0; with 0, all CPUs will be used}

\item{word.length, }{7 for thresholds between 0.88 and 0.9 for other option see user manual cdhit}
}
\value{
Returns two files: a fasta file of representative sequences and a text file of list of clusters
}
\description{
This function executes a ubuntu docker that cluster minION sequences using CD-HIT
}
\examples{
\dontrun{
    #running fastq2fasta
    cdhit(group="docker", scratch.folder="/data/scratch", data.folder=getwd(), identity.threshold=0.90, memory.limit=8000, threads=0, word.length=7)
}

}
\author{
Raffaele A Calogero, raffaele.calogero [at] unito [dot] it, University of Torino. Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapperSTARChip.R
\name{wrapperSTARChip}
\alias{wrapperSTARChip}
\title{Wrapper function for circRNAs prediction using STARChip}
\usage{
wrapperSTARChip(
  group = c("sudo", "docker"),
  scratch.folder,
  genome.folder,
  samples.folder,
  threads,
  chimSegmentMin,
  chimJunctionOverhangMin,
  reads.cutoff,
  min.subject.limit,
  do.splice,
  cpm.cutoff,
  subjectCPM.cutoff,
  annotation
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR is located.}

\item{samples.folder, }{the folder where are located all the subfolders of the samples processed with starChimeric}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{chimSegmentMin, }{is a positive integer indicating the minimal length of the overlap of a read to the chimeric element}

\item{chimJunctionOverhangMin, }{is a positive integer indicating the minimum overhang for a chimeric junction}

\item{reads.cutoff, }{Integer. Minimum number of reads crossing the circRNA backsplice required.}

\item{min.subject.limit, }{Integer. Minimum number of individuals with readsCutoff reads required to carry forward a circRNA for analysis}

\item{do.splice, }{true false. The splices within the circRNA be detected and reported. Linear splices are searched within each circRNA in each individual. Any linear splice with >= 60\% of the read count of the cRNA is considered a splice within the circRNA. Two files are then created, .consensus with most common splice pattern, and .allvariants with all reported splice patterns.}

\item{cpm.cutoff, }{Float. Reads counts are loaded into R and log2(CountsPerMillion) is calculated using the limma package. With cpmCutoff > 0, circRNAs with log2(CPM) below this value will be filtered from this analysis}

\item{subjectCPM.cutoff, }{Integer. See above. This value is the lower limit for number of individuals required to have the circRNAs expressed at a value higher than cpmCutoff.}

\item{annotation, }{true/false. circRNAs are provided with gene annotations}
}
\value{
1. Count matrices : raw cRNA backsplice counts: circRNA.cutoff[readthreshold]reads.[subjectthreshold]ind.countmatrix log2CPM of above: norm_log2_counts_circRNA.[readthreshold]reads.[subjectthreshold]ind.0cpm_0samples.txt Maximum Linear Splices at Circular Loci: rawdata/linear.[readthreshold]reads.[subjectthreshold]ind.sjmax 2. Info about each circRNA:  Consensus Information about Internal Splicing: Circs[reads].[subjects].spliced.consensus Complete Gene Annotation: circRNA.[readthreshold]reads.[subjectthreshold]ind.annotated Consise Gene Annotation + Splice Type:  circRNA.[readthreshold]reads.[subjectthreshold]ind.genes 3. Images: PCA plots: circRNA.[readthreshold]reads.[subjectthreshold]ind.0cpm_0samples_variance_PCA.pdf Heatmap: circRNA.[readthreshold]reads.[subjectthreshold]ind.heatmap.pdf
}
\description{
This function calls sequentially the docker containers for FASTQC, STAR, and STARChip to predict the list of circRNAs starting from the raw RNA-Seq reads
}
\examples{
\dontrun{

    #retrieve the example data
    system("wget https://github.com/carlo-deintinis/circhunter/archive/master.zip") #retrieve the data of the indexed genome (chromosome 21 of hg38 human genome assembly)
    system("unzip master.zip")
    system("unzip ./circhunter-master/CircHunter/data/hg38.chr21.fa.zip")
    system("wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR582/001/SRR5824251/SRR5824251_1.fastq.gz") #retrieve the RNA-Seq data
    system("wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR582/001/SRR5824251/SRR5824251_2.fastq.gz") #retrieve the RNA-Seq data

    #running the wrapperSTARChip function
wrapperSTARChip(group = "docker", scratch.folder="/data/scratch", genome.folder="./circhunter-master/CircHunter/data/", samples.folder=getwd(), threads = 8, chimSegmentMin = 20, chimJunctionOverhangMin = 15, reads.cutoff = 5, min.subject.limit = 1, do.splice = FALSE, cpm.cutoff = 0, subjectCPM.cutoff = 0, annotation = FALSE) 

}
}
\author{
Nicola Licheri, nicola [dot] licheri [at] unito [dot] it, University of Turin, Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pca.R
\name{pca}
\alias{pca}
\title{generating a PCA from counts, FPKM and TPM tables from rnaseqCounts outuputs}
\usage{
pca(
  experiment.table = "./_counts.txt",
  type = c("counts", "FPKM", "TPM"),
  covariatesInNames = FALSE,
  samplesName = TRUE,
  principal.components = c(1, 2),
  legend.position = c("bottom", "bottomleft", "left", "topleft", "top", "topright",
    "right", "center"),
  pdf = TRUE,
  output.folder = getwd()
)
}
\arguments{
\item{experiment.table, }{a character string indicating the counts, FPKM or TPM table file name and its path}

\item{type, }{a character value indicating the content of the file: counts, FPKM or TPM}

\item{covariatesInNames, }{a boolean value indicating if covariates are inserted after \_ in the filename}

\item{samplesName, }{a boolean value indicating if in the plot samples names are plotted or not}

\item{principal.components, }{a numerical vector with two values indicating the principal components to be plotted}

\item{legend.position, }{a character string indicating the location of the covariates legend}

\item{pdf, }{a boolean value indicating if results has to be saved in a pdf}

\item{output.folder, }{output folder}
}
\value{
Returns a PCA plot
}
\description{
This function generates PCA plot from counts, FPKM and TPM tables from rnaseqCounts outuputs.
}
\examples{
\dontrun{
  system("wget 130.192.119.59/public/test.analysis.zip")
  unzip("test.analysis.zip")
  setwd("test.analysis")
  library(docker4seq)
  pca(experiment.table="./_log2FPKM.txt", type="FPKM",
      legend.position="topleft", covariatesInNames=FALSE, samplesName=TRUE,
      principal.components=c(1,2), pdf = TRUE,
      output.folder=getwd())

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/starChimeric.R
\name{starChimeric}
\alias{starChimeric}
\title{Running Star to detect chimeric transcripts on paired-end sequences}
\usage{
starChimeric(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder,
  genome.folder,
  threads = 1,
  chimSegmentMin = 20,
  chimJunctionOverhangMin = 15
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR is located.}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{chimSegmentMin, }{is a positive integer indicating the minimal length of the overlap of a read to the chimeric element}

\item{chimJunctionOverhangMin, }{is a positive integer indicating the minimum overhang for a chimeric junction}
}
\value{
the set of chimeric transcripts identified by STAR chimeric
}
\description{
This function executes STAR to detect chimeric transcripts
}
\examples{
\dontrun{
    #downloading fastq files
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")
    system("wget http://130.192.119.59/public/test_R2.fastq.gz")
    #running star2step nostrand pe
    starChimeric(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
    genome.folder="/data/scratch/hg38star", threads=8, chimSegmentMin=20, chimJunctionOverhangMin=15)

}
}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/filterCounts.R
\name{filterCounts}
\alias{filterCounts}
\title{Filter a count table using a table of DE from wrapperDeseq2}
\usage{
filterCounts(data.folder, type = c("gene", "isoform", "mirna"))
}
\arguments{
\item{data.folder, }{a character string indicating the paths of rnaseqCounts/mirnaCounts output folders}

\item{type, }{character with three options: gene, isoform, mirna.}
}
\value{
Returns counts, fpkm, tpm data frames for gene and isoforms in countsDE.txt, log2fpkmDE.txt and in log2TPMDE.txt
}
\description{
This function generates counts, FPKM and TPM tables including only the differentially expressed genes present in the set of DE generated with wrapperDeseq2.
}
\examples{
\dontrun{
    system("wget 130.192.119.59/public/test.analysis.zip")
    unzip("test.analysis.zip")
    setwd("test.analysis")
    library(docker4seq)
    wrapperDeseq2(output.folder=getwd(), group="docker", experiment.table="_counts.txt", log2fc=1,
    fdr=0.1, ref.covar="Cov.1", type="gene", batch=FALSE))

    filterCounts(data.folder=getwd(), type="gene")

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapperCiri.R
\name{wrapperCiri}
\alias{wrapperCiri}
\title{Wrapper function for circRNAs prediction using CIRI 2}
\usage{
wrapperCiri(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder,
  genome.file,
  seq.type = c("se", "pe"),
  sample.id,
  threads = 1,
  annotation.file = "",
  max.span = 2e+05,
  stringency.value = c("high", "low", "zero"),
  quality.threshold = 10
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{data.folder, }{a character string indicating where gzip fastq files are located}

\item{genome.file, }{a character string indicating the path to the Fasta file of the reference genomic sequence (it should be the same reference indexed for the BWA alignment)}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing}

\item{sample.id, }{a character string indicating the unique id to be associated to the bam that will be created}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{annotation.file, }{a character string indicating the path to the GTF/GFF file reporting the reference gene annotations}

\item{max.span, }{an integer reporting the maximum spanning distance of a circRNA (default = 200000 bp)}

\item{stringency.value, }{the selected stringency level of the analysis. Three possible options are available: "high" (high stringency, default), in which CIRI2 only provides circRNAs supported by more than 2 distinct PCC signals; "low" (low stringency), CIRI2 only provides circRNAs supported by more than 2 junction reads; "zero", CIRI2 provides all circRNAs regardless junction read counts or PCC signals}

\item{quality.threshold, }{integer indicating the threshold for mapping quality of each segment of junction reads (default=10)}
}
\value{
The list of circRNAs predicted by CIRI starting from the raw RNA-Seq datasets
}
\description{
This function calls sequentially the docker containers for FASTQC, BWA, and CIRI to predict the list of circRNAs starting from the raw RNA-Seq reads
}
\examples{
\dontrun{

    #retrieve the example data
    system("wget https://github.com/carlo-deintinis/circhunter/archive/master.zip") #retrieve the data of the indexed genome (chromosome 21 of hg38 human genome assembly)
    system("unzip master.zip")
    system("unzip ./circhunter-master/CircHunter/data/hg38.chr21.fa.zip")
    system("wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR582/001/SRR5824251/SRR5824251_1.fastq.gz") #retrieve the RNA-Seq data
    system("wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR582/001/SRR5824251/SRR5824251_2.fastq.gz") #retrieve the RNA-Seq data

    #running the wrapperCiri function
wrapperCiri(group = "docker", scratch.folder="/data/scratch", data.folder=getwd(), genome.file="./circhunter-master/CircHunter/data/hg38.chr21.fa", seq.type = "pe", sample.id="test", threads = 1, max.span = 200000, stringency.value = "high", quality.threshold = 10) 

}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circrnaQuantification.R
\name{circrnaQuantification}
\alias{circrnaQuantification}
\title{Running CircHunter circRNA quantification module}
\usage{
circrnaQuantification(
  group = c("sudo", "docker"),
  scratch.folder,
  rnaseq.data,
  backsplicing_junctions.data,
  hc.params
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{rnaseq.data, }{string indicating the path to the fastq file of the RNA-Seq dataset to analyse}

\item{backsplicing_junctions.data, }{string indicating the path to the fasta file of the circRNA back-splicing sequences to search in the RNA-Seq dataset}

\item{hc.params, }{vector of six parameters to set the analysis. The element of the vector indicate in order: the k-mer size, the thread number, the dimension of the hash table, the dimension of the collision list, the number of k-mers that must be matched to the sequence to consider the sequence itself as represented in the RNA-Seq data, and the number of perfect matches required in the k-mer to consider it matched to a sequence.}
}
\value{
A count table reporting the number of RNA-Seq reads supporting specific circRNA back-splice junctions
}
\description{
This function executes the docker container circhunter by running the circRNA quantification module of CircHunter to quantify the level of expression of a set of circRNA BS sequences in a given RNA-Seq experiment. For CircHunter algorithm detail please refer to: https://github.com/carlo-deintinis/circhunter/tree/master/CircHunter.
}
\examples{
\dontrun{

    #retrieve the example data
    system("wget https://github.com/carlo-deintinis/circhunter/archive/master.zip") #'     system("unzip master.zip")
    system("gzip ./circhunter-master/CircHunter/data/test_rna-seq.fastq.gz")

    #running the circrnaQuantification function
    circrnaQuantification(group="docker", scratch.folder="/data/scratch", rnaseq.data=paste(getwd,"/circhunter-master/CircHunter/data/test_rna-seq.fastq.gz", sep=""), backsplicing_junctions.data=paste(getwd,"/circhunter-master/CircHunter/data/CRC_circRNA_backsplicing_sequences.fasta", sep=""), hc.params=c(27, 40, 1000000, 1000000, 17, 30))

}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ciri_as.R
\name{ciriAS}
\alias{ciriAS}
\title{Running CIRI_AS tool for circRNAs structure prediction}
\usage{
ciriAS(
  group = c("sudo", "docker"),
  scratch.folder,
  sam.file,
  ciri.file,
  genome.file,
  annotation.file = NA
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{sam.file, }{a character string indicating the path to the RNA-Seq alignment SAM/BAM file from BWA}

\item{ciri.file, }{string indicating the path to the list of circRNAs}

\item{genome.file, }{a character string indicating the path to the Fasta file of the reference genomic sequence (it should be the same reference indexed for the BWA alignment)}

\item{annotation.file, }{a character string indicating the path to the GTF/GFF file reporting the reference gene annotations}
}
\value{
The function returns the list of alternative circRNAs internal structures
}
\description{
This function executes the docker container docker4circ where CIRI_AS is installed
}
\examples{
\dontrun{

    #Download the example data
    system("wget https://sourceforge.net/projects/ciri/files/CIRI-AS/test_data_CIRI_AS.zip/download")

    system("mv download test_data_CIRI_AS.zip")
    system("unzip test_data_CIRI_AS.zip")

 # Run the ciriAS function
ciriAS(group = "docker", scratch.folder="/data/scratch", sam.file=paste(getwd,"/test_data_CIRI_AS/test.sam",sep=""), ciri.file=paste(getwd,"/test_data_CIRI_AS/test.ciri", genome.file=paste(getwd,"/test_data_CIRI_AS/chr1.fa", sep=""), annotation.file = paste(getwd,"/test_data_CIRI_AS/chr1.gtf", sep="")
}

}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circrnaOverlapResults.R
\name{circrnaOverlapResults}
\alias{circrnaOverlapResults}
\title{Running circRNA prediction overlap}
\usage{
circrnaOverlapResults(
  group = c("sudo", "docker"),
  scratch.folder,
  input.folder,
  output.folder,
  min_support
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{input.folder, }{string indicating the path of the folder containing the samples to overlap}

\item{output.folder, }{string indicating the path of the output folder}

\item{min_support, }{an integer representing the minimum number of algorithms detecting the circRNA.}
}
\value{
The list of circRNAs detected in at least the user-defined number of algorithms
}
\description{
This function executes the docker container docker4circ to overlap circRNA predictions obtained from multiple tools
}
\examples{
\dontrun{
}
}
\author{
Nicola Licheri
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sncRNA.R
\name{sncRNA}
\alias{sncRNA}
\title{Running small RNA-seq single-end reads alignment and quantification using BWA and custom scripts}
\usage{
sncRNA(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder,
  mode,
  reference,
  threads = 1,
  mb.version = NULL,
  mb.species = NULL,
  adapter.type = c("ILLUMINA", "NEB", "QIAGEN"),
  trimmed.fastq = FALSE
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where trimmed fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{mode, }{a character string indicating the required type of analysis. Compatible analyses mode are "miRNA" and "ncRNA". In "miRNA" analysis mode, the version ("mb.version" argument) and species prefix ("mb.species" argument) of miRBase are required. This mode require also the "reference" argument. In the "ncRNA" mode only the "reference" argument is required.}

\item{reference, }{a character string indicating the path to the reference fasta file used to create the BWA index}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{mb.version, }{a character string indicating the required version of miRBase database. Visit ftp://mirbase.org/pub/mirbase/ to select the proper version id.}

\item{mb.species, }{a character string indicating the three-letter prefix of a species annotated in miRBase (e.g. "hsa" for human miRNAs). Please refer to http://www.mirbase.org/help/genome_summary.shtml to obtain the proper species prefix.}

\item{adapter.type, }{a character string. Two options: \code{"ILLUMINA"} or \code{"NEB"}, depending to which miRNA library prep was used: ILLUMINA or NEB}

\item{trimmed.fastq, }{a boolean logical variable indicating if trimmed fastq are saved. Default is FALSE}
}
\value{
Read count table of RNA-Seq reads aligned miRNA or non-miRNA annotations
}
\description{
This function executes the docker container where BWA is installed. BWA is a read alignment package that efficiently align short sequencing reads against a large reference sequence. Alignment is performed against annotations of human small RNAs. Read count is performed by GenomicAlignments R package and custom Python and bash commands.
}
\examples{
\dontrun{
    #downloading fastq files
    system("wget http://130.192.119.59/public/test_R1.fastq.gz")

    #running miRNAs quantification pipeline
    bwaIndex(group="docker", genome.folder="/data/genomes", mb.version="22", mb.species="hsa", mode="miRNA")
    sncRNA(group="docker", fastq.folder=getwd(), scratch.folder="/data/scratch", mode="miRNA", reference="/data/genome/hairpin_hsa_miRBase_22.fa", threads=8, mb.version="22", mb.species="hsa")

    #running non miRNA ncRNAs quantification pipeline
    bwaIndex(group="docker", genome.folder="/data/genomes/", rc.version="9.0", rc.species="Homo sapiens", length=80, mode="ncRNA")
    sncRNA(group="docker", fastq.folder=getwd(), scratch.folder="/data/scratch", mode="ncRNA", reference="/data/genome/ncRNA_Homo_sapiens_RNA_Central_9.0_len_80.fa", threads=8)

}
}
\author{
Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/oncosnpIllumina.R
\name{oncosnp}
\alias{oncosnp}
\title{A function to handle a docker containier executing CNV calculation. Only supporting hg19}
\usage{
oncosnp(
  group = c("sudo", "docker"),
  data.folder,
  scratch.folder,
  sample.name = NULL,
  blood.name = NULL
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}

\item{scratch.folder, }{a character string indicating the scratch folder for temporary operations}

\item{sample.name, }{a character string indicating snp data file name}

\item{blood.name, }{a character string indicating snp data file name for blood snp}
}
\value{
cnv1.cnvs, cnv2,cnvs and other oncosnp elements, see oncosnp help page for further information
}
\description{
This function executes a ubuntu docker that produces as output oncosnp and request as input a tabl delimited file with Name	Chromosome	Position	Log R Ratio	B Allele Freq, where Name is the snp id from Illumina arrays, Chromosome is the chr, POsition is the SNP location in the chr Log R Ratio	B Allele Freq are genrated from genomestudio
}
\examples{
\dontrun{
    system("wget http://130.192.119.59/public/testcnv.zip")
    #running fastqc
    oncosnp(group="docker", data.folder=getwd(), scratch.folder="/data/scratch", sample.name="sampleXX.txt", blood.name=NULL)
}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, University of Torino
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xenome.R
\name{xenome}
\alias{xenome}
\title{Running xenome, https://github.com/data61/gossamer/}
\usage{
xenome(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  xenome.folder,
  seq.type = "pe",
  threads = 1
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{xenome.folder, }{a character string indicating the folder where the indexed reference genomes generated by xenome  are locates}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
ambiguous, both, neither, hs and mm fastq.gz files. xeno_hs_R1.fastq.gz and xeno_hs_R2.fastq.gz are fastq file free of mouse reads and are used for further analysis.
}
\description{
This function executes the docker container bwa1 where BWA is installed BWA is a read alignment package that efficiently align short sequencing reads against a large reference sequence This aligner provides optimal results with DNA-seq data
}
\examples{
\dontrun{
    #downloading examples 1 million reads of mcf7 exome mixed with 1 million of mouse derived by human exome capturing
    system("wget http://130.192.119.59/public/hs1m_mm1m_R1.fastq.gz")
    system("wget http://130.192.119.59/public/hs1m_mm1m_R2.fastq.gz")
    #running xenome
    xenome(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
    xenome.folder="/data/scratch/hg19.mm10", seq.type="pe",
    threads=24)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circrnaClassification.R
\name{circrnaClassification}
\alias{circrnaClassification}
\title{Running CircHunter circRNA classification module}
\usage{
circrnaClassification(
  group = c("sudo", "docker"),
  scratch.folder,
  circrna.data,
  exon.data,
  isoform.data,
  assembly = "hg19"
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{circrna.data, }{string indicating the path to the list of circRNAs}

\item{exon.data, }{string indicating the path to the exon annotation file}

\item{isoform.data, }{string indicating the path to the isoform annotation file}

\item{assembly, }{string indicating the reference human genome assembly. Compatible assemblies: hg19 (default), hg18, hg38, mm9, mm10, rn6, dm6, ce11}
}
\value{
Two tab-delimited tables reporting the transcript- and gene-level classification of a list of circRNAs
}
\description{
This function executes the docker container circhunter by running the circRNA classification module of CircHunter starting from a set of circRNAs. For CircHunter algorithm detail please refer to: https://github.com/carlo-deintinis/circhunter/tree/master/CircHunter.
}
\examples{
\dontrun{

    #retrieve the example data
    system("wget https://github.com/carlo-deintinis/circhunter/archive/master.zip") #retrieve the example data
    system("unzip master.zip")

    #running the circrnaClassification function
    circrnaClassification(group="docker", scratch.folder="/data/scratch", circrna.data=paste(getwd(),"/circhunter-master/CircHunter/toyexample/toy_circRNA", sep=""), exon.data=paste(getwd(),"/circhunter-master/CircHunter/toyexample/toy_genome", sep=""), isoform.data=paste(getwd(),"/circhunter-master/CircHunter/toyexample/toy_isoformdata", sep=""), assembly="hg19")

}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/anovaLike.R
\name{anovaLike}
\alias{anovaLike}
\title{A function allowing the identification of differentially expressed genes if multiple groups are provided.}
\usage{
anovaLike(
  group = c("sudo", "docker"),
  file,
  logFC.threshold = 1,
  FDR.threshold,
  logCPM.threshold = 4,
  plot = c(TRUE, FALSE)
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{file, }{a character string indicating the path of the file, with counts.table name and extension included}

\item{logFC.threshold, }{minimal logFC present in at least one of the comparisons with respect to reference covariate}

\item{FDR.threshold, }{minimal FDR present in at least one of the comparisons with respect to reference covariate}

\item{logCPM.threshold, }{minimal average abundance}

\item{plot, }{TRUE if differentially expressed genes are represented in a plot.}
}
\description{
This function executes in a docker edgeR for the identification of differentially expressed genes in bulk RNAseq. IMPORTANT the filename shoould not have any '.' in the name unless .txt
}
\examples{
\dontrun{
    #running deDetection
    anovaLike(group="docker", file=paste(getwd(),"annotated_lorenz_buettner_counts_noSymb.txt", sep="/"),
       logFC.threshold=1, FDR.threshold=0.05, logCPM.threshold=4)
}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, University of Torino, Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rsemstarIndex.R
\name{rsemstarIndex}
\alias{rsemstarIndex}
\title{Generating rsem-star genome index}
\usage{
rsemstarIndex(
  group = c("sudo", "docker"),
  genome.folder = getwd(),
  ensembl.urlgenome = NULL,
  ensembl.urlgtf = NULL,
  threads = 1
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for STAR will be located}

\item{ensembl.urlgenome, }{a character string indicating the URL from ENSEMBL ftp for the unmasked genome sequence of interest}

\item{ensembl.urlgtf, }{a character string indicating the URL from ENSEMBL ftp for the GTF for genome of interest}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
The index of the reference genomic sequence for STAR analysis
}
\description{
This function executes the docker container rsem-star1 where RSEM and STAR are installed. The index is created using ENSEMBL genome fasta file. User needs to provide the URL for ENSEMBL genome located in the ENSEMBL ftp
}
\examples{
\dontrun{
    #running rsemstar index for human
    rsemstarIndex(group="sudo",genome.folder="/data/scratch/hg38star",
    ensembl.urlgenome=
    "ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz",
    ensembl.urlgtf=
    "ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.gtf.gz",
    threads=24)

    #running rsemstar index for mouse
    rsemstarIndex(group="docker",genome.folder="/data/scratch/mm10star",
    ensembl.urlgenome="ftp://ftp.ensembl.org/pub/release-87/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna.toplevel.fa.gz",
    ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-87/gtf/mus_musculus/Mus_musculus.GRCm38.87.gtf.gz",
    threads=24)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xenomeIndex.R
\name{xenomeIndex}
\alias{xenomeIndex}
\title{Generating xenome genome indexes}
\usage{
xenomeIndex(
  group = c("sudo", "docker"),
  xenome.folder = getwd(),
  hg.urlgenome = NULL,
  mm.urlgenome = NULL,
  threads = 8
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{xenome.folder, }{a character string indicating the folder where the indexed reference genomes for xenome will be located}

\item{hg.urlgenome, }{a character string indicating the URL from uscs download web page for the unmasked human genome sequence of interest}

\item{mm.urlgenome, }{a character string indicating the URL from uscs download web page for the unmasked mouse genome sequence of interest}

\item{threads, }{an integer indicating how many threads are used by xenome}
}
\value{
The indexed xenome genomes references
}
\description{
This function executes the docker container xenome.2017.01 where xenome is installed.
}
\examples{
\dontrun{
    #running xenome index
    xenomeIndex(group="docker",xenome.folder="/data/scratch/test", hg.urlgenome=
    "http://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz",
    mm.urlgenome="http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz")

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deeptoolBwig.R
\name{deeptoolBwig}
\alias{deeptoolBwig}
\title{Create a bigWig from the output of bowtie2}
\usage{
deeptoolBwig(
  group = c("sudo", "docker"),
  fastq.folder = getwd(),
  scratch.folder = "/data/scratch",
  threads
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where bam, bai files  are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\value{
sorted.bw
}
\description{
This function executes the docker container bowtie2 embedding deeptools the output of bowtie2 sorted.bam is used to generate the bigWig
}
\examples{
\dontrun{
    #downloading fastq files
system("wget http://130.192.119.59/public/test_R1.fastq.gz")
system("wget http://130.192.119.59/public/test_R2.fastq.gz")
library(docker4seq)
deeptoolBwig(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch/", threads=8)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/salmonIndex.R
\name{salmonIndex}
\alias{salmonIndex}
\title{A function to create a Salmon pseudo reference}
\usage{
salmonIndex(
  group = c("sudo", "docker"),
  index.folder,
  ensembl.urltranscriptome,
  ensembl.urlgtf,
  k = 31
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{index.folder, }{a character string indicating the folder where transcriptime index will be created.}

\item{ensembl.urltranscriptome, }{a character string indicating the URL from ENSEMBL ftp for the transcripts fasta file of interest}

\item{ensembl.urlgtf, }{a character string indicating the URL from ENSEMBL ftp for the GTF for genome of interest}

\item{k, }{a number indicating the k-mers length, 31 eems to work well for reads of 75bp or longer, but you might consider a smaller k if dealing with shorter reads.}
}
\description{
This function executes the Salmon docker that produces as output a transcripts index file.
}
\examples{
\dontrun{
    #running salmonIndex mouse
    salmonIndex(group="docker", index.folder=getwd(), 
    ensembl.urltranscriptome="ftp://ftp.ensembl.org/pub/release-90/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz",
    ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-90/gtf/mus_musculus/Mus_musculus.GRCm38.90.gtf.gz", 
    k=31)
    #running salmonIndex human
    library(docker4seq)
    salmonIndex(group="docker", index.folder=getwd(), 
           ensembl.urltranscriptome="ftp://ftp.ensembl.org/pub/release-90/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz",
           ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-90/gtf/homo_sapiens/Homo_sapiens.GRCh38.90.gtf.gz", 
           k=31)
    
}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fastq2fasta.R
\name{fastq2fasta}
\alias{fastq2fasta}
\title{A function to handle the conversion from fastq to fasta}
\usage{
fastq2fasta(group = c("sudo", "docker"), scratch.folder, data.folder)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}
}
\value{
Returns sample.fasta file in the data.folder
}
\description{
This function executes a ubuntu docker that convert a fastq.gz file in a fasta file using seqtk
}
\examples{
\dontrun{
    #running fastq2fasta
    fastq2fasta(group="docker", scratch.folder="/data/scratch", data.folder=getwd())
}

}
\author{
Raffaele A Calogero, raffaele.calogero [at] unito [dot] it, University of Torino. Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kraken.R
\name{kraken}
\alias{kraken}
\title{A function executing kraken}
\usage{
kraken(
  group = "docker",
  scratch.folder,
  fastq.folder,
  genome.folder,
  fastq.prefix,
  threads
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{fastq.folder, }{a character string indicating the folder where input fastq(s) are located and where output will be written}

\item{genome.folder, }{a character string indicating the folder where the indexed kraken db is located}

\item{fastq.prefix, }{a character string indicating the PREFIX of the fastq file(s): e.g. prova_R1.fastq.gz fastq.prefix="prova"}

\item{threads, }{a number indicating the number of cores to be used from the application}
}
\description{
This function executes a ubuntu docker that embed kraken2
}
\examples{
\dontrun{
    #running skeleton
    kraken(group="docker", scratch.folder="/data/scratch", 
    fastq.folder=getwd(), genome.folder="/data/genomes/minikraken",
    fastq.prefix="unmapped", threads=8)
}

}
\author{
Raffaele A Calogero, raffaele.calogero [at] unito [dot] it, University of Torino
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/runDocker.R
\name{runDocker}
\alias{runDocker}
\title{Run docker container}
\usage{
runDocker(group = "docker", params = NULL, DockerSwarm = FALSE)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{params, }{a character string containing all parameters needed to tun the docker container}

\item{DockerSwarm, }{a bolean value used to enable docker execution in swarm mode.}
}
\value{
0 if success, 1 if parameters are missing, 2 if the group is neither sudo or docker, 3 if docker execution fails.
}
\description{
This is an internal function executing a docker container. Not to be used by users.
}
\examples{
\dontrun{
    #running runDocker
     runDocker(group="docker", params=NULL)

}
}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/annotatingByGtfchipseq.R
\name{annoByGtfchipseq}
\alias{annoByGtfchipseq}
\title{Annotating RSEM gene.results using ENSEMBL gtf and refGenome CRAN package}
\usage{
annoByGtfchipseq(
  group = "docker",
  peaks.file = getwd(),
  gtf.file,
  extension = 10000
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{peaks.file, }{a character string indicating the MACS peak file, extension _peaks.xls, with full path}

\item{gtf.file, }{a character string indicating the file, with full path for the genome gtf}

\item{extension, }{a number defining how many nucleotides should be expandend the extremes of the targetr gene to find an overlap with peaks, default 10000}
}
\value{
one file: MACS2 peaks annotated
}
\description{
This function executes the docker container annotate.1, where refGenome is used to annotated gene.results and isoforms.results outputs from RSEM using ENSEMBL GTF annotation
}
\examples{
\dontrun{
    #downloading fastq files
    #running rsemannoByGtfchipseq
    annoByGtfchipseq(group="docker", peaks.file=paste(getwd(),"h3k9me1_igg_peaks.xls", sep="/"), 
               gtf.file=paste("/Users/raffaelecalogero/Dropbox/courses/DUKENUS_JUL2019/course/course/datasets/genomes/mm10bwa","Mus_musculus.GRCm38.97.gtf", sep="/"), extension=10000)
}

}
\author{
Raffaele Calogero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/circrnaMergePredictions.R
\name{circrnaMergePredictions}
\alias{circrnaMergePredictions}
\title{Function to merge different circRNA lists predicted from one of the supported circRNA prediction tools.}
\usage{
circrnaMergePredictions(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder,
  samples.list,
  covariates.list,
  covariate.order,
  min_reads = 2,
  min_reps = 0,
  min_avg = 10,
  used.tool = c("acfs", "ciri", "ciri2", "circexplorer", "circexplorer2",
    "circrnafinder", "dcc", "findcirc2", "knife")
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{data.folder, }{a character string indicating the data folder where the circRNA  output files are located}

\item{samples.list, }{a character vector indicating the identifiers of the samples}

\item{covariates.list, }{a character vector indicating the classes of the samples}

\item{covariate.order, }{a character vector indicating the order of covariates in the output files}

\item{min_reads, }{the minimum number of back-splicing reads supporting a circRNA and detected in at least min_reps number of biological replicates of the same experimental condition (default = 2)}

\item{min_reps, }{the minimum number of replicates associated with at least min_reads supporting a circRNA (default = 0)}

\item{min_avg, }{the average number of back-splicing reads across biological replicates of the same experimental condition that shall support a circRNA (default = 10)}

\item{used.tool, }{the tool used to predict the circRNAs. Supported tools are: ACFS, CIRI, CIRI2, CIRCexplorer, CIRCexplorer2, CircRNA_Finder, DCC, Find_Circ2, KNIFE, Uroborus.}
}
\value{
Two tab-delimited tables reporting the BS supporting reads and the coordinates of the filtered circRNAs are reported
}
\description{
This function executes the docker container ciri2merge by running the merge of different lists of circRNAs predicted by one of the supported tools following a sample data files provided by the user. The function executes also a filter based on the number of back-splicing reads computed in each experiment and across replicates of the same biological condition.
}
\examples{
\dontrun{

    #retrieve the example data
    system("wget https://github.com/carlo-deintinis/circhunter/archive/master.zip") #retrieve the example data
    system("unzip master.zip")
    system("unzip ./circhunter-master/CircHunter/data/CIRI_predictions.zip")

    #running the circrnaMergePredictions function
    circrnaMergePredictions(group="docker", scratch.folder="/data/scratch", data.folder="./circhunter-master/CircHunter/data/CIRI_predictions", groups.file="./circhunter-master/CircHunter/data/CIRI_predictions/SampleData.tsv", min_reads = 2, min_reps = 2, min_avg = 10, used.tool="ciri2")
}
}
\author{
Nicola Licheri and Giulio Ferrero
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/multiQC.R
\name{multiQC}
\alias{multiQC}
\title{A function to handle a docker containier executing MultiQC}
\usage{
multiQC(group = c("sudo", "docker"), data.folder)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}
}
\description{
This function executes MultiQC docker (Ewels et al., 2016. Bioinformatics. 32(19):3047-8) returning the multiqc_report.html file and the content of multiqc_data/ folder
}
\examples{
\dontrun{
    #running skeleton
    multiQC(group="docker", data.folder=getwd())
}

}
\author{
Giulio Ferrero, giulio.ferrero [at] unito [dot] it, University of Torino
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hashclone.R
\name{hashclone}
\alias{hashclone}
\title{HashClone running A function to handle a hashclone docker container NOT READY for STABLE RELEASE, YET}
\usage{
hashclone(
  group = c("sudo", "docker"),
  scratch.folder,
  data.folder = getwd(),
  kmer,
  hash,
  coll,
  threshold = 0.1,
  type,
  spike = "null",
  input.files
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{data.folder, }{a character string indicating the folder where input data are located and where output will be written}

\item{kmer, }{an integer that define the size of the substrings (k-mer) encoded in the hash table (this must be a value between 1 and 32)}

\item{hash, }{a prime number indicating the size of the hash table. Increasing this value reduces the execution time but increases the memory utilization. Ideally, this value should be close to the number of different k-mers stored in the hash table;}

\item{coll, }{an integer that define the maximum number of different k-mers that the tool might need to store in the hash table.}

\item{threshold, }{(tau) this value is the threshold used to select significant k-mers. We suggest to set tau equal to 1}

\item{type, }{IGH (immunoglobulin heavy chain) or  IGK (immunoglobulin kappa locus)}

\item{spike, }{a character string indicating the path of the spike in file (if you don't want the spike in research, please set this parameter as 'null')}

\item{input.files, }{a character string indicating the path of the input files}
}
\description{
This function executes  HashClone algorithm developed to identify the set of clonality markers during the patient follow-up in order to quantify the minimal residual disease.
}
\examples{
\dontrun{
library(docker4seq)
downloadContainers(group="docker","docker.io/qbioturin/hashclone")
hashclone(group="docker",scratch.folder="/home/scratch_folder", data.folder="/home/output_folder", kmer=26, hash=10999997, coll=10999997, threshold=1, type= IGH, spike="/home/spike_in.fa", input.files=c('/home/input_file1.fastq', '/home/input_file2.fastq'))
}


}
\author{
Beccuti Marco, Greta Romano, Francesca Cordero, Raffaele Calogero, beccuti[at]di[dot]unito[dot]it, Computer Science Department Univ. of Turin.
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/testDocker.R
\name{dockerTest}
\alias{dockerTest}
\title{Testing if Docker is installed}
\usage{
dockerTest()
}
\value{
a character string indicating the version of the docker installed in the system
}
\description{
This function check that docker is installed
}
\examples{
 dockerTest()
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/salmonCounts.R
\name{salmonCounts}
\alias{salmonCounts}
\title{A function to handle a salmon docker container}
\usage{
salmonCounts(
  group = c("sudo", "docker"),
  scratch.folder,
  fastq.folder,
  index.folder,
  threads = 8,
  seq.type = c("se", "pe"),
  strandness = c("none", "forward", "reverse")
)
}
\arguments{
\item{group, }{a character string. Two options: sudo or docker, depending to which group the user belongs}

\item{scratch.folder, }{a character string indicating the path of the scratch folder}

\item{fastq.folder, }{a character string indicating the folder where input data are located and where output will be written}

\item{index.folder, }{a character string indicating the folder where transcriptome index was created with salmonIndex.}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{seq.type, }{a character string indicating the type of reads to be generated by the sequencer. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing. Strandness is inferred by salmon.}

\item{strandness, }{a character string indicating the type ofsequencing protocol used for the analysis. Three options: \code{"none"}, \code{"forward"}, \code{"reverse"} respectively for non strand selection, reverse for Illumina strandness protocols, reverse for ACCESS Illumina protocol}
}
\description{
This function executes a docker that produces as output the transcripts count file generated by Salmon quasi-alignment
}
\examples{
\dontrun{
system("wget http://130.192.119.59/public/test_R1.fastq.gz")
system("wget http://130.192.119.59/public/test_R2.fastq.gz")
library(docker4seq)
wrapperSalmon(group="docker", scratch.folder="/data/scratch/",
              fastq.folder=getwd(), index.folder="/data/genomes/hg38salmon",
              threads=24, seq.type="pe", adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
              adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT", min.length=40, strandness="none")
}

}
\author{
Raffaele Calogero, raffaele.calogero [at] unito [dot] it, Bioinformatics and Genomics unit, University of Torino Italy
}
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapperPdx.R
\name{wrapperPdx}
\alias{wrapperPdx}
\title{Running PDX data preprocessing TO BE REVISED}
\usage{
wrapperPdx(
  group = c("sudo", "docker"),
  fastq.folder,
  scratch.folder,
  xenome.folder,
  seq.type,
  threads,
  adapter5 = "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
  adapter3 = "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
  min.length = 40,
  genome.folder = "/data/scratch/hg19_exome",
  sample.id = "sampleX"
)
}
\arguments{
\item{group, }{a character string. Two options: \code{"sudo"} or \code{"docker"}, depending to which group the user belongs}

\item{fastq.folder, }{a character string indicating where gzip fastq files are located}

\item{scratch.folder, }{a character string indicating the scratch folder where docker container will be mounted}

\item{xenome.folder, }{a character string indicating the folder where the indexed reference genomes generated by xenome  are locates}

\item{seq.type, }{a character string indicating the type of reads to be trimmed. Two options: \code{"se"} or \code{"pe"} respectively for single end and pair end sequencing}

\item{threads, }{a number indicating the number of cores to be used from the application}

\item{adapter5, }{a character string indicating the fwd adapter}

\item{adapter3, }{a character string indicating the rev adapter}

\item{min.length, }{a number indicating minimal length required to return a trimmed read}

\item{genome.folder, }{a character string indicating the folder where the indexed reference genome for bwa is located}

\item{sample.id, }{a character string indicating the unique id to be associated to the bam that will be created. IMPORTANT it is necessary to have a sample.id for each sample for further analysis.}
}
\value{
three files: dedup_reads.bam, which is sorted and duplicates marked bam file, dedup_reads.bai, which is the index of the dedup_reads.bam, and dedup_reads.stats, which provides mapping statistics
}
\description{
This function executes xenome, to remove mouse data, skewer, to trim adapters, bwa, to map reads to hg19 and to mark duplicates. IMPORTANT to prepare data for mutect v1 analysis it is mandatory to download the hg19 index archive indicated in the example.
}
\examples{
\dontrun{
    #downloading examples 1 million reads of mcf7 exome mixed with 1 million of mouse derived by human exome capturing
    system("wget http://130.192.119.59/public/hs1m_mm1m_R1.fastq.gz")
    system("wget http://130.192.119.59/public/hs1m_mm1m_R2.fastq.gz")

    #required for bwa 61Gb At the present time this is required to run mutect1
    system("wget http://130.192.119.59/public/hg19_exome.tar.gz")

    #running wrapperPdx
    wrapperPdx(group="docker",fastq.folder=getwd(), scratch.folder="/data/scratch",
    xenome.folder="/data/scratch/hg19.mm10", seq.type="pe", threads=24,
    adapter5="AGATCGGAAGAGCACACGTCTGAACTCCAGTCA",
    adapter3="AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
    min.length=40, genome.folder="/data/scratch/hg19_exome", sample.id="sampleX")

}
}
\author{
Raffaele Calogero
}
